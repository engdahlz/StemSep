# UVR/MDX/Demucs/GSEP Guide (Indexed)

## Source

- **PDF**: `docs/vendor/library/uvr_mdx_demucs_gsep_guide/pdf/Instrumental, vocal & other stems separation & mix_master guide - UVR_MDX_Demucs_GSEP & others.pdf`
- **SHA256**: `0bf044d3c519acb5c33615c1f329b69f72e8e036c9dcb182e5f96a895f992872`
- **Pages**: `642`
- **Indexed at**: `2026-01-02T18:18:37+01:00`

## Files

- `txt/fulltext.txt` (all pages)
- `txt/pages/page_###.txt` (one file per page)

## Outline / Table of Contents

- **edit. 02.01.26** (p.1)
-   **Last updates and news** (p.1)
-     **- (MVSEP) “I added new Karaoke model: "BS Roformer by MVSep Team (SDR: 10.41)" it's available under option "MVSep MelBand Karaoke (lead/back vocals)". Metrics.** (p.21)
-     **In contrast with other Karaoke models, it returns 3 stems: "lead", "back" and "instrumental".** (p.21)
-     **Example: https://mvsep.com/result/20250915192251-53be20aa17-10seconds-song.wav” - ZFTurbo** (p.21)
-     **- (MVSEP) “We’ve added a mirror of MVSep (big thanks to okhostok): https://mirror.mvsep.com** (p.21)
-     **If you have a problem with upload/download speed or can't reach the main site then try the mirror.** (p.21)
-     **Report please if it helped you to speed things up.” - ZFTurbo** (p.21)
-     **- Gabox released BS_ResurrectioN model | yaml** (p.22)
-     **“It is a finetune of BS Roformer Resurrection Inst but with higher fullness (like v1e for example), it needs [MVSEP’s] BS 2025.07 (as a source/reference) phase fix [so you “should process the instrumental result using BS 2025.07 then put [it] as source in UVR GUI phase fix tool”]. I requested it because I found some songs where Resur Inst was producing muddy instrum results (...) I requested it not just for me because I saw other people were looking for something like v1e++” - dca** (p.22)
-     **- anvuew released BS-Roformer Dereverb Room model | Colab** (p.22)
-     **“specifically for mono vocal room reverb.” as most are recorded in mono.** (p.22)
-     **- BS-Roformer Karaoke model by becruily & frazer released | MVSEP | uvronline​Metrics better than even fused model gabox + aufr33/viperx and SCNet IHF below).** (p.23)
-     **Make sure you don’t have the option “Vocals only” checked in UVR.** (p.23)
-     **- (MVSEP) “New Karaoke model based on SCNet XL IHF was added on site in "MVSep MelBand Karaoke (lead/back vocals)". Name of model "SCNet XL IHF by becruily (SDR: 9.53, metrics)". It has slightly worse metrics than the top Roformer model, but since it's different architecture it can give better results in some cases where the Rofo failed.** (p.24)
-     **Demo: https://mvsep.com/result/20250908072226-f0bb276157-mixture.wav” - ZFTurbo** (p.24)
-     **- (MVSEP) Four “new models for independent instruments were added:** (p.24)
-     **1) MVSep Viola (viola, other) Demo: https://mvsep.com/result/20250907234931-f0bb276157-mixture.wav** (p.24)
-     **2) MVSep Cello (cello, other) Demo: https://mvsep.com/result/20250907235225-f0bb276157-mixture.wav** (p.24)
-     **3) MVSep Trumpet (trumpet, other) Demo: https://mvsep.com/result/20250907235543-f0bb276157-mixture.wav** (p.24)
-     **The SDR has increased significantly compared to the previous MDX23C model, from 3.84 to 5.41. It is currently the best model on the leaderboard: https://mvsep.com/quality_checker/leaderboard/strings/?sort=strings” - ZFTurbo** (p.25)
-     **- anvuew released experimental BS-Roformer vocal model (nfft 4096, stft_hop_length 1024 “so not that large”) with 12 SDR measured on musdb18hq dataset. Might be worth checking: download.** (p.25)
-     **11.60 SDR on the same test set was previously achieved by one of the first Mel-Roformers trained by Bytedance on musdbhq + 500 songs (paper), although it wasn't nfft 4096.** (p.25)
-     **- introC released a python script to get rid of vocal leakage in v1e+ model** (p.25)
-     **- iZotope released Ozone 12. Separation still has Spleeter-like quality, but “it's unclear what they use” - Spleeter references disappeared from their readme (jarredou).** (p.25)
-     **- Ableton received its own stem separation feature in Live 12.3. It’s made in cooperation with Moises.ai. https://www.youtube.com/watch?v=uSahY-HGKt4** (p.25)
-     **- Thanks to Essid, metrics for following instrumental models were added to the models list:​INSTV7N, inst_fv8 (v2), inst_gabox3, Rifforge model, older mesk’s metal model, FVX, Bv1, Bv2 (b - bleedless, v - for version)** (p.26)
-     **- “New Wind model based on BS Roformer has been added in MVSep Wind (wind, other):** (p.26)
-     **Demo: https://mvsep.com/result/20250829230056-f0bb276157-mixture.wav** (p.26)
-     **Results on quality checker: https://mvsep.com/quality_checker/entry/8933** (p.26)
-     **It increased SDR +2.5 comparing to previous best model.” - ZFTurbo** (p.26)
-     **- Suno now has stem separation feature “t's generative, so the separation isn't exact. Also, you apparently can't use it on like famous songs because they'll get flagged.” - Musicalman** (p.26)
-     **- Gabox released experimental inst Mel-Roformer model (yaml) called just “fullness”.** (p.26)
-     **- (MVSEP) “We added 2 new algorithms for Acoustic Guitar (based on BS Roformer) and for Flute (based on SCNet XL)** (p.26)
-     **1) `MVSep Acoustic Guitar (acoustic-guitar, other)` Example: https://mvsep.com/result/20250825095613-f0bb276157-mixture.wav”** (p.26)
-     **“2) `MVSep Flute (fulte, other)` Example: https://mvsep.com/result/20250825095856-f0bb276157-mixture.wav” - ZFTurbo** (p.26)
-     **- We have the first lucky person on the server who succeeded to actually use the new NVIDIA’s upscaler, and their messy AF code on Windows using Docker.** (p.27)
-     **- Unwa released BS-Roformer-Inst-FNO model (incompatible with UVR, use MSST and read special model installation instruction below).** (p.27)
-   **- BS/Mel-Roformer UVR beta patch** (p.94)
-   **For GPU acceleration, UVR currently supports: ​CUDA (NVIDIA GPUs)/DirectML (AMD and Intel GPUs; previously misnamed as OpenCL)/MPS (Mac M1 [ARM]/x86-64),​and even old CPUs (AMD A6-9225 Dual-Core or Intel Core 2 Quad [models with SSE4.1 tested]). DirectML is not supported for Apollo, Bandit (also incompatible with MPS), SCNet and probably Demucs 2 archs - CPU will be used automatically.​​Model architectures supported: ​MDX-Net, MDX23C (archs by kuielab), VR (voice-remover by tsurumeso, v. 4, 5 [UVR fork], 5.1), Demucs (arch by Meta; v. 1-4, only models trained on OG code, not MSST ones), BS-Roformer, Mel-Roformer (arch by Bytedance & impl. by lucidrains; issues on Linux explained later), SCNet, Apollo (in Tools; for upscaling, no DirectML acceleration), BandIt (SFX, no DirectML).** (p.94)
-   **It has also a feature of ensemble MDX models with different archs like MDX23C/v3 or Roformers, VR.​Demudder added in newer patches (currently not on Linux).** (p.94)
-   **Models for Roformers/SCNet/Bandit arch are located altogether in the MDX-Net menu.** (p.94)
-   **Apollo upscaler (Apollo) is located in Tools.​​Don’t forget to enable GPU Conversion - if it works, it speeds up separation hugely.​​- Min. 4GB VRAM GPUs tested (with chunk_size = 112455 in model yaml for Roformers; more below), On AMD, 16GB VRAM recommended (so no config modifications are required). ​- Min. NVIDIA Maxwell/900 series GPUs/compute compatibility 5 is the minimum requirement for UVR to work (at least NVIDIA GTX 650 and GT 700 series and older are unsupported returning: “AssertionError: "" Traceback Error:” or "CUDNN_STATUS_NOT_INITIALIZED), although DirectML should be theoretically supported by all DX12 GPUs.​- For AMD, at least RX 4GB models tested (not sure about R9 200 4GB GPUs - either if on newer modded Radeon-ID drivers and/or with downgraded DirectML.dll attached with drivers, copied to UVR\torch_directml folder, but seems like someone had occasional memory issues on HD 7870 2GB, but GPU Conversion still worked). “AssertionError: "" Traceback Error:” also exist when 1.9.1.0 library).** (p.94)
-     **Instructions for UVR Roformer patches and installing custom models** (p.104)
-     **Overlap comparisons for Roformers** (p.106)
-     **Most common issues** (p.107)
-   **Ensembling impossible - model not visible in vocal splitter in UVR** (p.108)
-   **- If user-imported Roformers aren't recognized in "instrumental/vocals" in ensemble or in vocal splitter, but are in "multi-stem ensemble":​“The .yaml associated with the model usually needs to be updated to match UVR's stem naming conventions. For example, if your config shows the instruments as "other" and "vocals", it will need to be updated to "Instrumental" and "Vocals" (case-sensitive)” - Anjok** (p.108)
-     **- Roformers might be sometimes slow/stuck/give memory allocation error during separation on AMD/Intel GPUs with VRAM lower than 16GB, if you don’t lower default “chunk_size” during importing the model, or in the corresponding yaml in: models\MDX_Net_Models\model_data\mdx_c_configs ​or in Choose Model>Edit Models Config>Change Parameters>Edit Model Param.​Start with min. chunk_size = 112455 (dim_t 256 equivalent) and increase it depending on GPU or model size till you start getting errors to get the best possible SDR.** (p.109)
-     **For older beta 1-9 and 4GB VRAM GPUs, lower dim_t at the bottom of the yaml (not at the top) to e.g. 256 or 201, sometimes 301 - some Roformers will require lower dim_t/chunk_size - the higher, the better till 1101, or training chunks value in the config.** (p.109)
-     **So since patch #10 “new beta version[s] doesn't rely on 'inference.dim_t' value anymore (if you were using edited "dim_t" value).** (p.109)
-   **Memory issues - chunk_size table** (p.109)
-   **'use_amp' “Key error”** (p.110)
-   **“”’norm’”” attributeError using e.g. unwa beta 5e model in UVR** (p.111)
-   **Layers errors - general** (p.112)
-   **TypeError: (...) freqs_per_bands** (p.112)
-   **- Stable 5.6 OpenCL (DirectML) version of UVR 5 GUI for Windows** (p.129)
-   **Supporting AMD and Intel GPUs acceleration but no Roformers yet** (p.129)
-     **- AudioSep has been released** (p.131)
-     **- RemFX for detection and removal of the following effects: chorus, delay, distortion, dynamic range compression, and reverb. Huggingface (currently stopped working) | Samples** (p.138)
- **- (no longer necessary) Fork of UVR GUI and How to install - support for AMD and Intel GPUs appeared (works only for VR and MDX architectures), Besides W11, also W10 confirmed working, MDX achieves speeds of i5-4460s using 6700 XT, while for VR, speeds are v. fast and comparable to CUDA, so CPU processing might be slower in VR, but for MDX you might want to stick with the official UVR5 GUI.** (p.155)
-   **General reading advice** (p.156)
- **______________________________________________________________** (p.158)
-   **The best models** (p.160)
-   **for specific stems** (p.160)
-     **> for instrumentals (click here for vocal models)** (p.160)
-     **Recent bleedless models** (p.166)
-     **- Gabox BS_ResurrectioN model | yaml** (p.168)
-     **“It is a fine-tune of BS Roformer Resurrection Inst but with higher fullness (like v1e for example), it needs [MVSEP’s] BS 2025.07 (as a source/reference) phase fix** (p.168)
-     **I requested it because I found some songs where Resur Inst was producing muddy instrum results (...) I requested it not just for me because I saw other people were looking for something like v1e++” - dca** (p.168)
-     **Higher fullness (but with more noise)** (p.168)
-     **Higher bleedless (not so full)​** (p.171)
-     **Ensembles** (p.175)
-     **Muddier but cleaner single models (Roformer vocal models with fewer instrumental residues vs instrumental models without necessity of using phase fixer)** (p.183)
-     **Models for older archs** (p.187)
-     **> for vocals** (p.192)
-     **(click here for Karaoke, or here for instrumentals)** (p.192)
-     **Ensembles** (p.200)
-     **RVC models choice by AI Hub (subject to change;​read their current docs too)** (p.201)
-     **Fast inference models** (p.202)
-     **- Gabox BS_ResurrectioN (model | yaml, 204 MB)** (p.203)
-     **Other services (multipurpose)** (p.208)
-     **Speech separation** (p.209)
-     **The list by Musicalman (mostly from before the Gabox models release, check vocals too)** (p.210)
-     **Can’t find a model?** (p.210)
-     **UVR models repository** (p.211)
-     **Debleeding/cleaning vocals/instrumentals/inverts** (p.217)
-     **How to check whether a model in UVR5 GUI is vocal or instrumental?** (p.220)
-     **Keeping only backing vocals in a song (lead vocal extractor):** (p.221)
-     **>Karaoke** (p.221)
-     **- BS-Roformer Karaoke model by becruily & frazer | metrics | MVSEP | uvronline** (p.221)
-     **- MVSEP’s BS Roformer by MVSep Team (SDR: 10.41)** (p.222)
-     **under option "MVSep MelBand Karaoke (lead/back vocals)", metrics. Might be a fine-tune. Use the option extract vocals first.** (p.222)
-     **(“In contrast with other Karaoke models, it returns 3 stems: "lead", "back" and "instrumental".)** (p.222)
-     **- Advanced chain processing chart (image)** (p.229)
-       **>Keeping only lead vocals** (p.230)
-       **in a song** (p.230)
-       **Harmonies** (p.233)
-       **For two singers in a duet from one song** (p.234)
-       **Various speakers' isolation (from e.g. podcast or movie)​​- MVSEP Male/Female SCNet model** (p.236)
-       **- Aufr33 BS-Roformer Male/Female beta model | config | Colab (based on the model below)** (p.236)
-       **- Male/female BS-Roformer model by Sucial | config for UVR | tensor match error fix​(if they sing at intervals [one by one] they cannot be separated)** (p.236)
-       **> 4-6 stems (drums, bass, others, vocals + opt. guitar, piano):​- Currently when used on AI-generated music, usually hihats will be left behind.** (p.237)
-       **>Sep. parts of drums** (p.244)
-       **Electric guitar​“For better results you might try first removing vocals.”** (p.246)
-       **Acoustic guitar** (p.246)
-       **Wind instruments and wind noises​(trumpet/saxophone/brass/woodwinds/flute/trombone/horn/clarinet/oboe/harmonica/bagpipes/bassoon/tuba/kazoo/piccolo/fluge/horn/ocarina/shakuhachi/melodica/reeds/didgeridoo/mussette/gaida/farts)** (p.247)
-       **- MVSep Wind BS Roformer (2025.08) (more robust and cleaner than the Mel and detects instruments better, +2.5 SDR)​- Wind BS-Roformer on x-minus.pro by viperx (big step forward vs the old UVR model)** (p.247)
-       **Piano** (p.249)
-       **Crowd** (p.250)
-       **SFX** (p.251)
-       **Any other stem/instrument/sample if not listed above** (p.253)
-       **De-reverb** (p.254)
-       **- Mel-Roformer de-reverb by anvuew v2 (a.k.a. 19.1729 SDR) | DL | config | Colab​Probably the best de-reverb for now.** (p.254)
-       **- and RX11's dialogue isolate for de-echo.​** (p.254)
-       **“anvuew's models can remove reverb effect only from vocals, “captures early reflections a little”. Old FoxJoy's model works with full track.”** (p.254)
-       **- anvuew BS-Roformer Dereverb Room model | Colab | MVSEP ​(doesn’t work in UVR, use MSST, If you have stereo errors using MSST on stereo files, update MSST [git clone and git pull commands] or see below.** (p.254)
-       **“specifically for mono vocal room reverb.” as most are recorded in mono.** (p.254)
-       **Free apps/VSTs for de-reverb/de-echo/denoise** (p.258)
-       **Denoising (vinyl noise/white noise/general)** (p.261)
-     **Plugins (different types of noise)** (p.264)
-       **De-clippping/de-limitter/de-compression of dynamics (for loud or brickwalled songs with overly used compressor/clipper/limiter/distortion - transients/peaks recovery)​** (p.265)
-       **Mixing/mastering** (p.268)
-       **AI audio upscalers list** (p.270)
-       **Blending with RVC model ​(by Gabox & dubpluris a.k.a. Mark | Avalaunch - text)** (p.272)
-       **More descriptions of models** (p.273)
-     **“UVR BVE v2 model [currently on x-minus] is actually full band. There is, however, a small nuance. This model uses MDX VocFT preprocessing, which is not full band. MDX VocFT model is rebalancing the song. The music is slightly mixed with the vocals (25% music + 100% vocals). This mix is then processed by the BVE model. A small amount of music can help the model better understand the context (it's important for harmony separation). We train the model on a rebalanced dataset. It contains 25% of music.” aufr33** (p.276)
-     **MDX settings & ens. explanations in UVR5​(and also Demucs/VR/MDX v2/23C inferencing parameters)** (p.276)
-       **Ensemble algorithm explanations​​Ensemble - a way to use multiple models to potentially get better results.** (p.277)
-       **4-5 max ensemble models rule** (p.280)
-       **Q: Why I shouldn’t use more than 4-5 models for UVR ensemble (in most cases)** (p.280)
-       **MDX v2 parameters (e.g. HQ_1-5, Kim inst, Inst 1-3, NET, Crowd)​(self.n_fft /  dim_f / dim_t inference parameters later below)** (p.281)
-       **Overlap** (p.289)
-     **[Tips to enhance separation results]** (p.289)
-     **24. arigato78 method for lead vocal acapella** (p.295)
-       **35. Debleeding of drums in vocals by Sam Hocking** (p.299)
-     **SDR leaderboard** (p.307)
- **Bleedness and fullness leaderboard​​Python evaluation script by jarredou (prob. mirror), Torch version (with Bas Curtiz),​used on Quality Checker** (p.310)
-   **Instrumental models sorted by instrumental bleedless metric:** (p.312)
-     **Vocal models/ensembles sorted by instrumental bleedless metric:​(more muddy; Gabox and Unwa’s Revive models not evaluated yet):** (p.313)
-     **Other ensembles for UVR5** (p.316)
-     **Mateus Contini's methods** (p.320)
-     **#1 (old)** (p.320)
-   **Karaoke / Backing Vocals** (p.326)
-     **Table of content** (p.329)
-   **50 models sorted by SDR** (p.331)
-     **Similarity/Phantom Center/Mid channel Extractor** (p.337)
-     **Separating people in recording** (p.342)
-   **UVR5 GUI (MDX, VR, Demucs 2-4 and UVR team models)** (p.343)
-     **GUI FAQ & troubleshooting for UVR** (p.345)
-       **Separation times chart by Bas Curtiz (various CPUs and GPUs, model cut-off examination)** (p.349)
-     **- Chunks may alter separation results** (p.356)
-       **(older) UVR & x-minus.pro updates/news (2021-2023)** (p.357)
-       **Online sites and Colabs for separation - the best quality freebies you can currently get** (p.363)
-       **MSST / MSST-GUI by ZFTurbo** (p.372)
-       **MVSEP models from UVR5 GUI explained** (p.378)
-     **Manual ensemble Colab** (p.380)
-     **Joining frequencies from two models** (p.382)
-     **DAW ensemble** (p.383)
-     **Manual ensemble in UVR5 GUI from single models (e.g. from inference Colabs or online sites)** (p.384)
-     **Model fusion** (p.384)
- **UVR’s VR architecture models** (p.385)
-   **(settings and recommendations;​mostly outdated arch for all vocals and instrumental models)** (p.385)
-   **VR Colab by HV** (p.385)
-   **VR settings** (p.386)
-   **VR models settings and list** (p.388)
-   **VR ensemble settings** (p.392)
-   **VR Colab troubleshooting** (p.399)
-     **MDX-Net Colab by HV (March 2025)​Models trained by UVR team models (aufr33 & Anjok)** (p.402)
- **First vocal models trained by UVR for MDX-Net arch:** (p.402)
- **9.703 model is UVR-MDX-NET 1, UVR-MDX-NET 2 is UVR_MDXNET_2_9682, NET 3 is 9662, all trained at 14.7kHz** (p.402)
-   **(the old) Google Colab by HV** (p.403)
-   **(defunt) Upd. by KoD & DtN & Crusty Crab & jarredou, HV (12.06.23)​(probably now requires !pip install numpy==1.26 and restarting env)​It might have more models than above (e.g. some beta HQ ones)** (p.403)
- **Demucs 3** (p.412)
- **Demucs 4 (+ Colab) (4, 6 stem)** (p.413)
- **Gsep (2, 4, 5, 6 stem, karaoke)** (p.419)
- **dango.ai** (p.425)
- **music.ai** (p.426)
- **MDX23 by ZFTurbo (jarredou fork) - 2, 4 stems** (p.426)
- **KaraFan by Captain FLAM** (p.439)
- **Ripple/Capcut/SAMI-Bytedance/Volcengine/BS-RoFormer (2-4 stem)** (p.444)
-   **Ripple on Windows or MacOS** (p.448)
- **Drumsep - single percussion instruments separation** (p.453)
-   **Mel-Roformer MVSEP drumsep models** (p.453)
-   **SCNet MVSEP drumsep models** (p.454)
-   **(newer) MDX23C 5 stem drumsep by jarredou** (p.454)
-   **(older) MDX23C 6 stem drumsep by jarredou/Aufr33** (p.455)
-   **Older drumsep by Inagoy** (p.458)
-   **Moises.ai drumsep** (p.460)
-   **FactorSynth** (p.460)
-   **Regroover** (p.460)
-   **UnMixingStation** (p.461)
-   **LarsNet** (p.461)
-   **VirtualDJ 2023/Stems 2.0 (kick, hi-hat)** (p.462)
-   **RipX DeepAudio (-||-) (6 stems [piano, guitar])** (p.462)
-   **Spectralayers 10** (p.462)
- **USS-Bytedance (any; esp. SFX)** (p.463)
- **Zero Shot (any sample; esp. instruments)** (p.464)
- **AudioSep** (p.466)
-   **Medley Vox (different vocalists)** (p.466)
-     **About other services:** (p.469)
-     **Spleeter** (p.469)
-     **Izotope RX-8/9/10** (p.469)
-     **phonicmind** (p.469)
-     **melody.ml** (p.469)
-     **ByteDance Ripple/CapCut** (p.469)
-   **real-time** (p.469)
-     **Serato** (p.469)
-     **Stems 2.0** (p.470)
-     **Acon Digital Remix** (p.470)
-     **FL Studio (Demucs)** (p.470)
-     **djay Pro 5.x** (p.470)
-     **Neutone VST** (p.470)
-     **Peel Stems** (p.471)
-     **Fadr.com from SongtoStems.com** (p.471)
-     **Apple Music Sing** (p.471)
-     **Voxless** (p.471)
-     **Ozone 11 Master Rebalance** (p.471)
-     **Music to MIDI transcribers/converters** (p.472)
-     **Piano2Notes** (p.472)
-     **Audioshake** (p.473)
-     **Lalal.ai** (p.474)
-     **DeMIX Pro V3** (p.475)
-     **Hit'n'Mix RipX DeepAudio** (p.476)
-     **Moises.ai** (p.476)
-       **___UVR settings for ensemble (section deprecated, see the section above)__** (p.477)
-       **___Good UVR accapella models______** (p.477)
-       **__How to remove artefacts from an inverted acapella?_____** (p.478)
-       **Utagoe (English version with guide and error messages translated by Anjok) - if the invert isn't good, then try utagoe, but it’s not the best.** (p.479)
- **__Sources of FLACs for the best quality for separation process__** (p.480)
-   **Various versions of the same song** (p.481)
-   **Sometimes the same track you may try to isolate can exist in few versions: e.g.** (p.481)
-   **1) single version - in the old days, single versions contained official instrumentals or accapella which not always invert with original mixture to get instrumental if it wasn’t available (but if it inverts at least partially it might give you better result - always try lossless files - lossy might not invert well)** (p.481)
-   **- on CD - sometimes contain different track list than on vinyl, extra tracks, remixes, etc.** (p.481)
-   **(rarely available on streamings in this form now) - always refer to Discogz to find all releases of your interest** (p.481)
-   **2) deluxe edition/reissue/remastered (sometimes separated instrumentals from remastered versions can be crispier than leaked multitracks which are rarely even mastered; also, different remasters might be available on streaming platforms or fan-made ones on YT or on the internet)** (p.482)
-   **Most importantly -** (p.483)
-   **Feel free to experiment with different versions and find the best result with a specific version of your song, although 24 bit FLAC should be the best (although not everyone might notice the difference).** (p.483)
-   **If you have seemingly the same FLAC Audio CD rip from before streaming services times (~<2013), it can happen that a lossless file taken from a streaming service may be slightly different in most cases (same length but slight changes in Spek across the whole track which normally don’t exist when comparing FLACs from various streaming services which have the same Audio MD5 checksums - also sometimes track finishes in slightly different place). Sometimes it can sound better, sometimes worse** (p.483)
-   **([outdated - there are no longer MQA files on Tidal] and we’re talking about situation that it’s not MQA 16 bit like "Master" quality files on Tidal [but lots are 24 bit as well, though it's better to get them from e.g. Qobuz if 24 bit for some track is available, or at least compare both, because it can give slightly different results]).** (p.483)
-   **Also, it can happen that 24 bit MQA on Tidal will sound better for whatever reason than seemingly better FLAC on Qobuz - it might be possibly due to different files sent to streaming services by the provider/labe.** (p.483)
-   **Sites and rippers** (p.484)
-   **Besides trial, you can go for Tidal Hi-Fi cheap subscription to: https://www.hotukdeals.com/vouchers/tidal.com or pepper.pl or mydealz.de which always have some free or almost free giveaways (linked to a ready search). Then install the desktop Tidal app and log in and open the downloader. It might automate the login process in the downloader** (p.490)
-   **Dolby Atmos ripping** (p.497)
-     **> from Tidal (with orpheus_dl_tidal installed over orpheusDL; max 5.1[.4?])** (p.498)
-     **> from Tidal (with https://github.com/exislow/tidal-dl-ng)** (p.499)
-   **360 Reality Audio FAQ** (p.502)
- **___AI mastering services___** (p.504)
-   **___Best quality on YouTube for your audio uploads____** (p.513)
- **___Best quality from YouTube and Soundcloud - how to squeeze out the most from the music taken from YT for separation___** (p.515)
-   **_____Custom UVR models__________** (p.518)
-   **__Repository of old Colab notebooks__** (p.519)
-   **__Google Colab troubleshooting (old)_** (p.522)
-   **-​Error of authorisation during mounting:** (p.522)
-   **TL:DR - you need to log into the same account in Colab you want to mount drive later, or just change your Colab account.** (p.522)
-   **It was introduced to Colab at some point. Once I tried to log into another account during mounting, it displayed a new window with only one account, where the wanted account didn't appear, and when I manually signed in to it, Colab showed an error on Colab, something about unsuccessful authorisation. When I changed account in the right corner this time for the same account I wanted to choose when mounting, everything went fine as it always used to be. Full list of accounts appeared. HV Colabs already have the new mount method implemented, so the old one doesn’t cause error, but in UVR notebook you can choose between the new (default) and the old one (just in case Google changed something again).** (p.523)
-   **Repository of stems/multitracks from music to create your own dataset** (p.524)
- **List of cloud services with a lot of space** (p.536)
- **or for temporary storage** (p.536)
- **AI-killing tracks - difficult ones to get instrumentals (or vocals) - a lot of e.g. vocal (or instrumental) leftovers in current models** (p.546)
- **Training models guide** (p.560)
-   **Creating dataset - guide by Bas Curtiz** (p.568)
-     **Leading architectures** (p.572)
-       **Colab for training MDX23C model (on free T4)** (p.578)
-       **BS-Roformer** (p.579)
-       **More hints/FAQ for training Roformers** (p.584)
-       **Setting up training on your local machine​(read also mesk’s guide)​​“Make sure you have all dependencies installed for ZFTurbo's Training & Inference script:** (p.595)
-       **How to get fast GPUs for training** (p.598)
-         **Other archs** (p.604)
-     **Local SDR testing script** (p.620)
-     **Best ensemble finder for a song script** (p.620)
-     **Universal function to make different types of ensembles by ZFTurbo** (p.622)
-       **Volume compensation for MDX v2 models** (p.622)
-         **UVR-MDX parameters & hashes decoded by Bas Curtiz** (p.624)
-         **UVR model hash decode** (p.625)
-       **Voice Cloning** (p.626)
-       **Stable Audio Open Gen** (p.627)
-       **Links for research on separation** (p.627)
-       **Anjok’s interview on YT** (p.632)
-         **Demudder** (p.635)
-         **Simpler demudder** (p.636)
-         **UVR Demudders released in beta Roformer patch** (p.637)
-         **Phase fixer/swapper​(decreases vocal residues in instrumentals)** (p.638)
-         **Phase-fixed output used in UVR’s Manual ensemble** (p.638)
-         **Pitch shifting algorithms' comparison** (p.640)
-         **Restoring hi-end in pitched-down tracks - click** (p.641)

## Notes

- This index is auto-generated from the PDF using `pypdf`.
- If the outline is missing in the PDF, only extracted text is available.

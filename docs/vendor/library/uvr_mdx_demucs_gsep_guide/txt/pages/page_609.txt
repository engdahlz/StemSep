[page 609/642]
    [YOUR  DATASET]  --valid_path  [YOUR  VALIDATION  DATASET]  --dataset_type  [TYPE  
1/2/3/4/5]
 
--num_workers
 
8
 
--device_ids
 
0
 
--metric_for_scheduler
 
sdr
 
--metrics
 
fullness
 
bleedless
 
l1_freq
 change  these  accordingly:  >data_path  >valid_path  >dataset_type   On  the  side.   ZLUDA  is  a  translation  layer  for  CUDA  allowing  to  use  any  CUDA-written  app  to  be  used  
with
 
AMD
 
(and
 
formerly
 
Intel)
 
GPUs,
 
and
 
without
 
any
 
modifications
 
to
 
such
 
app.
 Weaker  GPUs  than  7900  XT  might  show  its  weeknesses  considerably,  compared to  better  GPUs.  The  example  came  from  ZLUDA  in  Blender,  but  rather  from  AMD  period  code,  so  
before
 
the
 
takedown
 
and
 
rollback
 
to
 
pre-AMD
 
codebase
 
so
 
now
 
ZLUDA
 
is
 
more
 
crippled.
 
 
With
 
never
 
released
 
code,
 
at
 
certain
 
point
 
it
 
was
 
even
 
made
 
to
 
support
 
Batman
 
Arkham
 
Knight,
 
with
 
general
 
plans
 
to
 
support
 
DLSS,
 
but
 
it
 
will
 
probably
 
never
 
see
 
a
 
day
 
light.
 Maybe  this repo  still  has  the  old  base  forked  -  version  3  codebase  is  still  being  updated  there.  Utilizing  it  on  6700  XT  in  stable-diffusion-webui-amdgpu,  it  was  performing  slowly  like  DirectML,  but  on  7900  XT  it  sped  up  the  process  from  3-4  to  ~1  minute.  The  first  execution  
can
 
be
 
slow
 
due
 
to
 
need
 
of
 
creating
 
cache.
 
Then
 
it
 
can
 
surpass
 
ROCm
 
performance-wise
 
if
 
you
 
manage
 
to
 
make
 
it
 
work.
 
Plus,
 
ZLUDA
 
works
 
on
 
Windows
 
and
 
supports
 
older
 
AMD
 GPUs,  like  even  RX  500  series  (use  lshqqytiger’s  repo,  check  e.g.  ROCm  5  version  if  your  app  doesn’t  start,  but  it  might  crash  anyway),  while  for  ROCm  on  Linux  and  older  GPUs,  e.g.  RX  5700  XT  should  work  with  some  quirks  (e.g.  HIP  5.7  and  ROCm  around  5.2.*  -  src,  although  you  can  try  out  6.21  or  6.2.x  to  ensure,  as  it  could  happen  that  some  earlier  6.x  
wasn’t
 
supporting
 
RX
 
5700
 
XT
 
correctly,
 
while
 
e.g.
 
for
 
RX
 
6000
 
ROCm
 
6.24
 
should
 
be
 
used
 
at
 
the
 
moment).
 
 
It
 
could
 
be
 
interesting
 
to
 
see
 
utilizing
 
training
 
repo
 
using
 
ZLUDA
 
e.g.
 
on
 
Windows
 
instead
 
of
 
ROCm
 
Pytorch
 
on
 
Linux
 
but
 
Unwa
 
notice
 
in
 
the
 
ZLUDA
 
repo
 
fork,
 
“PyTorch:
 
torch.stft
 
does
 
not
 
always
 
return
 
correct
 
result.”
 
and
 
it
 
might
 
be
 
problematic
 
during
 
training,
 
so
 
ZLUDA
 
might
 
be
 
not
 
a
 
good
 
solution
 
for
 
training
 
currently,
 
but
 
who
 
knows
 
whether
 
for
 
inferencing
 
on
 
e.g.
 
Windows
 
using
 
MSST
 
or
 
UVR,
 
although
 
the
 
latter
 
crashes
 
for
 
me
 
during
 
separation
 
with
 
nvcuda.dll.
 
But
 
I
 
haven't
 
tried
 
messing
 
with
 
HIP
 
SDK
 
mentioned
 
in
 
the
 
release
 
page
 
or
 
other
 
fork's
 
ZLUDA
 
versions
 
than
 
the
 
newest.
 
I
 
don't
 
even
 
have
 
anything
 
in
 
C:\Program
 
Files\AMD\ROCm
 
(if
 
it
 
wasn’t
 
even
 
futile
 
without
 
it),
 
but
 
I
 
have
 
amdhip64.dll
 
v.
 
5.5
 
in
 
system32
 
(if
 
5.7
 
isn’t
 
shipped
 
with
 
newer
 
drivers
 
and
 
required).
 Also,  didn't  follow  these  instructions  yet,  and  they  might  be  useful  and  contain  some  older  
GPUs
 
workaround:
 https://github.com/vladmandic/sdnext/wiki/ZLUDA All  gfx  names  with  corresponding  GPU  models:  https://llvm.org/docs/AMDGPUUsage.html#processors More  ZLUDA  research  and  workarounds  (may  work  for  UVR,  not  have  too):   
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 433/642]
    Overlap  is  doing  almost  the  same  thing  but  at  audio  chunks  level,  instead  of  full  audio,  and  
the
 
way
 
overlap
 
is
 
implemented
 
(in
 
MVSEP-MDX23),
 
f.e.
 
with
 
overlap=0.99,
 
first
 
audio
 
chunk
 
will
 
have
 
1
 
pass,
 
2nd
 
audio
 
chunk
 
will
 
have
 
2
 
passes,
 
etc...
 
until
 
99th
 
audio
 
chunk
 
and
 
following
 
ones
 
will
 
have
 
99
 
passes.
 
With
 
BigShifts,
 
the
 
whole
 
audio
 
is
 
processed
 
with
 
the
 
same
 
number
 
of
 
passes.
  So  BigShifts  shifts  the  audio  forward  one  second  each  time.  Overlap  computing  is  different  between  MDXv2  models  and  the  other  ones  in  the  fork:  For  MDXv2  models  (like  VOC-FT),  it  uses  the  new  code  from  UVR  and  goes  from  0  to  0.99.  For  MDXv3  (InstVoc)  &  VitLarge  models  [introduced  in  v2.3]  it  uses  code  from  ZFTurbo  (based  on  MDXv3  code  from  KUIELab,  https://arxiv.org/abs/2306.09382)  and  it  goes  from  1  to  whatever.   I'm  using  low  overlap  values  in  the  fork  because  it's  kinda  redundant  with  the  BigShifts  
experimental
 
feature
 
I've
 
added
 
and
 
which
 
is
 
based
 
on
 
Demucs'
 
"shift
 
trick"
 
(described
 
here
 https://arxiv.org/pdf/1911.13254.pdf,  chapter  4.4).  But  instead  of  doing  shifts  between  0  and  0.5  sec  like  Demucs  by  adding  silence  before  input,  BigShifts  are  much  larger  (and  related   
to
 
input
 
length).
 
Having
 
larger
 
time
 
shifting
 
gives
 
more
 
amplitude
 
in
 
possible
 
results.
 Instead  of  adding  silence  before  input  to  shift  it,  which  would  be  a  waste  of  time  &  resources  
as
 
BigShifts
 
can
 
be
 
above
 
30s
 
or
 
1
 
min
 
of
 
shifting,
 
instead,
 
it
 
changes
 
the
 
shifted
 
part
 
position
 
in
 
audio
 
input
 
(like
 
move
 
the
 
1st
 
minutes
 
of
 
audio
 
at
 
the
 
end
 
of
 
the
 
file
 
before
 
processing
 
and
 
restores
 
it
 
after
 
processing).
 Then  like  Demucs  original  trick  all  shifted  &  restored  results  are  merged  together  and  
averaged.
  From  my  tests,  it  can  influence  results  from  -2  SDR  to  +2  SDR  for  each  shifted  results,  
depending
 
on
 
input
 
and
 
BigShifts
 
value.
 
It's
 
not
 
linear!
  Using  BigShifts=1  (disabled)  and  high  overlap  value  probably  gives  more  stable  results,  in  
the
 
other
 
end,
 
but
 
maybe
 
not
 
always
 
as
 
high
 
and/or
 
fast
 
as
 
what
 
BigShifts
 
can
 
give.
  Weights  have  been  indeed  evaluated  on  MVSep's  multisong  dataset.  I  haven't  tried  every  
possible
 
settings,
 
but
 
default
 
values
 
should
 
be
 
not
 
far
 
away
 
from
 
optimal
 
settings,
 
if
 
not
 
optimal
 
[already].
 
  Q:  Wasn't  the  BigShifts  trick  in  the  MDX23  Colab  relying  on  a  slowed-down  and  sped-up  
separation
 
ensembling?
 I  think  increasing  the  parameter  too  much  rather  tends  to  increase  bleeding.   A:  It's  unrelated  to  bigshifts,  but  it  was  doing  that  for  MDX2  models  with  a  cutoff  around  
16-17khz
 
(to
 
get
 
fullband
 
results
 
from
 
them)
 
but
 
since
 
it's
 
using
 
only
 
fullband
 
models,
 
I've
 
removed
 
that
 
part
 
(in
 
v2.2
 
iirc)
  There  are  a  few  other  "tricks"  used  in  the  fork:  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
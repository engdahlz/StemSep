[page 597/642]
    but  it's  def  working“   Troubleshooting  of  ZFTurbo’s  training  code  by  Vinctekan   Issue:  GPU  isn't  available,  using  CPU  instead  it  will  be  very  slow   “Turns  out  that  the  group  and  order  of  specific  python  packages  that  Turbo  listed  in  the  [.txt]  
is
 
pretty
 
cursed.
  At  the  very  end,  pip  just  decides  to  remove  your  previous  instances  of  torch,  torchvision,  and  
torhcaudio
 
for
 
some
 
reason,
 
and
 
replaces
 
it
 
with
 
the
 
CPU
 
versions,
 
even
 
if
 
you
 
decide
 
to
 
install
 
pytorch
 
CUDA
 
beforehand.
 
Tried
 
removing
 
torch==2.0.1
 
from
 
the
 
requirements
 
but
 
somehow
 
it
 
still
 
stuck.
 If  you  try  to  install  pytorch  CUDA  AFTER  installing  the  requirements,  then  it  register  as  
already
 
installed.
 
I
 
thought
 
about
 
it
 
for
 
a
 
while
 
as
 
to
 
how
 
could
 
that
 
be
 
possible,
 
but
 
I
 
slowly
 
figured
 
out
 
that
 
the
 
CPU
 
versions
 
were
 
installed
 
because
 
of
 
it.
  The  way  I  found  the  fix  is  by  pip  uninstalling  all  3  packages,  and  then  reinstalling  pytorch  
with
 
the
 
command
 
on
 
the
 
website.
 
It
 
ultimately
 
does
 
not
 
matter
 
if
 
it's
 
118
 
or
 
121.”
  Q:  if  I  change  something  in  the  audio,  model,  training  augmentations,  inference  section,  or  if  
I
 
decide
 
to
 
remove
 
augmentations
 
entirely,
 
will
 
that
 
still
 
start
 
training
 
from
 
where
 
it
 
left
 
off,
 
or
 
is
 
it
 
going
 
to
 
start
 
all
 
over
 
again?
 
 A:  “as  long  as  you  provide  a  starting  checkpoint  in  the  training  code,  it  will  continue  where  it  
left
 
off”
 
becruily
 A:  “Don't  change  "audio",  "model"  config,  this  must  be  the  same  as  base  checkpoint  when  
resuming/fine-tuning,
 
I
 
think,
 
but
 
for
 
"augmentations"
 
part,
 
you
 
can
 
edit
 
as
 
you
 
want
 
as
 
it's
 
pre-processing
 
of
 
the
 
audio
 
and
 
done
 
on
 
the
 
fly.
 
mp3
 
encoding,
 
pitchshifting
 
and
 
timestretching
 
are
 
quite
 
resource
 
heavy
 
augmentations
 
and
 
can
 
slow
 
down
 
training,
 
other
 
type
 
of
 
augmentations
 
are
 
more
 
lightweighted.
  For  "inference",  you  can  reduce  overlap  value  if  you  want  the  validation  step  between  each  
epoch
 
to
 
be
 
a
 
bit
 
faster
 
(overlap=1
 
will
 
create
 
clicks
 
at
 
chunk
 
boundaries
 
[fixed
 
in
 
newer
 
MSST
 
code])
 
 "Training"  part,  you'll  probably  have  to  edit  batch_size  to  find  the  max  value  your  GPU  can  
handle.”
 
jarredou
 Q:  Isn't  changing  chunk  size  in  audio  fine  as  long  as  it's  divisible  by  the  hop  length?  I  recently  tried  a  lower  chunk  size  while  keeping  everything  the  same  (for  melband)  to  help  
with
 
VRAM
 
issues,
 
and
 
it
 
seemed
 
to
 
work
 
(didn't
 
train
 
for
 
long,
 
just
 
wanted
 
to
 
try)
 A:  I  have  never  tried,  but  yeah,  I  think  you're  right,  that's  probably  why  we  can  also  use  
different
 
chunk_size/dim_t
 
values
 
for
 
inference
 
and
 
the
 
models
 
are
 
still
 
working.
 
  
___
  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
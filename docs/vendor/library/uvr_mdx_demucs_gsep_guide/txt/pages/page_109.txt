[page 109/642]
    -  Roformers  might  be  sometimes  slow/stuck/give  memory  allocation  error  during  separation  
on
 
AMD/Intel
 
GPUs
 
with
 
VRAM
 
lower
 
than
 
16GB,
 
if
 
you
 
don’t
 
lower
 
default
 
“chunk_size”
 
during
 
importing
 
the
 
model,
 
or
 
in
 
the
 
corresponding
 
yaml
 
in:
 
models\MDX_Net_Models\model_data\mdx_c_configs
 
 
or
 
in
 
Choose
 
Model>Edit
 
Models
 
Config>Change
 
Parameters>Edit
 
Model
 
Param.
 
Start
 
with
 
min.
 
chunk_size
 
=
 
112455
 
(dim_t
 
256
 
equivalent)
 
and
 
increase
 
it
 
depending
 
on
 
GPU
 
or
 
model
 
size
 
till
 
you
 
start
 
getting
 
errors
 
to
 
get
 
the
 
best
 
possible
 
SDR.
  For  older  beta  1-9  and  4GB  VRAM  GPUs,  lower  dim_t  at  the  bottom  of  the  yaml  (not  at  the  
top)
 
to
 
e.g.
 
256
 
or
 
201,
 
sometimes
 
301
 
-
 
some
 
Roformers
 
will
 
require
 
lower
 
dim_t/chunk_size
 
-
 
the
 
higher,
 
the
 
better
 
till
 
1101,
 
or
 
training
 
chunks
 
value
 
in
 
the
 
config.
 
 So  since  patch  #10  “new  beta  version[s]  doesn't  rely  on  'inference.dim_t'  value  anymore  (if  
you
 
were
 
using
 
edited
 
"dim_t"
 
value).
 Now  you  have  to  edit  audio.chunk_size  now  “In  model  yaml  config  file,  at  top  of  it,  
chunk_size
 
is
 
first
 
parameter
 
(...)
 
you
 
can
 
edit
 
model
 
config
 
files
 
directly
 
inside
 
UVR
 
now.
  
Memory  issues  -  chunk_size  table   dim_t  to  chunk_size  conversion  for  Roformers  and  hop_length  =  441  in  the  model’s  yaml  -  useful  if  you  see  insufficient  memory  error  The  formula  is:  chunk_size  =  (dim_t  -  1)  *  hop_length   dim_t  =  1700  is  chunk_size  =  749259  (17s)  -  used  by  inst  resurrection  dim_t  =  1333  is  chunk_size  =  587412  (13,32s)  dim_t  =  1201  is  chunk_size  =  529200  (12s)  -  used  by  some  newer  models  dim_t  =  1101  is  chunk_size  =  485100  (11.00s)  -  that  dim_t  value  was  giving  the  highest  SDR  
for
 
models
 
trained
 
with
 
8s
 
chunks,
 
at
 
least
 
in
 
times
 
of
 
models
 
released
 
in
 
beta
 
Roformer
 
beta
 
patch
 
#2
 
period,
 
it’s
 
default
 
for
 
e.g.
 
duality
 
models
 dim_t  =  801  is  chunk_size  =  352800  (8.00s)  -  default  for  most  models,  max  working  on  
Intel/AMD
 
8GB
 
GPUs
 
on
 
900MB
 
models
 dim_t  =  556  is  chunk_size  =  244755  (5,5s)  dim_t  =  501  is  chunk_size  =  220500  (5s)  -  also,  as  below,  but  separation  time  slightly  
increased
 
with
 
at
 
least
 
a
 
few
 
browser
 
tabs
 
opened,
 
higher
 
crashes
 
no
 
matter
 
what
 dim_t  =  456  is  chunk_size  =  200655  (4,5s)  -  works  with  Resurrection  inst  on  4GB  AMD  GPU  dim_t  =  401  is  chunk_size  =  176400  (4s)   dim_t  =  356  is  chunk_size  =  156555  (3,55s)  -  max  supported  dim_t  for  some  becruily  inst  
and
 
AMD
 
4GB
 
VRAM
 
(when
 
in
 
previous
 
beta,
 
dim_t
 
needed
 
to
 
correspond
 
with
 
overlap
 
to
 
avoid
 
stem
 
misalignment,
 
so
 
probably
 
halves
 
caused
 
misalignment
 
before),
 it  can  be  more  muddy  in  certain  parts  of  songs  vs  256,  the  highest  working  value  with  
becruily
 
instrumental
 
on
 
AMD
 
4GB
 
VRAM
 
GPU
 dim_t  =  301  is  chunk_size  =  132300  (3s)  dim_t  =  256  is  chunk_size  =  112455  (2,55s)  -  max  working  with  e.g.  becruily  and  smaller  
unwa’s
 
400MB
 
exp.
 
models
 
on
 
4GB
 
AMD
 
GPU
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
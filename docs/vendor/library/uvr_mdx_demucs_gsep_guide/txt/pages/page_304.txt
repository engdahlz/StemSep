[page 304/642]
    https://imgur.com/a/BFGqN7P  jarredou’s  hint:  That's  a  case  where  I  would  go  SpectraLayers  as  while  the  2  vocals  are  not  
on
 
the
 
same
 
pitch,
 
you
 
can
 
separate
 
them
 
manually
 
(with
 
harmonic
 
selection
 
tool).
 
At
 
least
 
for
 
that
 
small
 
part
 
shown
 
here.
 In  SpectraLayers,  you  can  change  FFT  resolution,  higher  value  will  give  you  more  defined  
freq
 
"picture",
 
and
 
it
 
can
 
help
 
when
 
2
 
parts
 
are
 
really
 
close
 
in
 
pitch,
 
like
 
here.
 The  downside  is  that  with  high  FFT  values,  you  lose  time  resolution.  So  to  use  
SpectraLayers
 
manual
 
selection
 
efficiently,
 
you
 
often
 
need
 
to
 
switch
 
that
 
FFT
 
resolution
 
value
 
depending
 
on
 
the
 
elements
 
you
 
are
 
targeting,
 
like
 
you
 
would
 
zoom/dezoom
 
in
 
photoshop
 
while
 
editing
 
a
 
picture.
 
  56.  Sequential  stem  separation  (by  dynamic64/isling)   With  single  stem  models,  feel  free  to  experiment  with  sequential  stem  separation  -  Instrumental  model  first,  then  drums  or  bass,  piano  or  guitar,  strings  or  horns.  It  depends  on  
the
 
song
 
whether
 
better
 
results
 
will
 
give
 
e.g.
 
drums
 
or
 
bass
 
when
 
separated
 
first,
 
the
 
same
 
to
 
piano
 
vs
 
guitar
 
and
 
strings
 
vs
 
horns
 
first.
  57.  Advanced  chain  processing  chart  (image)   It’s  a  method  utilizing  old  models,  and  e.g.  Kim  Vocals  2  can  be  potentially  replaced  by  unwa’s  BS/Mel-Roformer  models  in  beta  UVR (or  other  good  method  for  vocals)  or  ensembles  mentioned  in  this  document.  Check  the  best  current  methods  for  vocals  in  one  
stem
 
to
 
find
 
what
 
works
 
the
 
best
 
for
 
your
 
song
 
to
 
get
 
all
 
vocals
 
before
 
splitting
 
to
 
other
 
stems
 
using
 
this
 
diagram.
 htdemucs  v4  above  can  be  replaced  by  htdemucs_ft,  as  it's  the  fine-tuned  version  of  the  model  (or  MDX23  Colab).  Even  better,  you  can  use  some  of  the  methods  for  4  stems in  this  GDoc  (like  drums  on  x-minus).  De-echo  and  reverb  models  can  be  potentially  replaced  by  some  better  paid  plugins  like:  DeVerberate  by  Acon  Digital,  Accentize  DeRoom  Pro  (more  in  the  de-reverb section).  UVR  Denoise  can  be  potentially  replaced  by  less  aggressive  Aufr33  model  on  x-minus.pro  
(used
 
when
 
aggressiveness
 
is
 
set
 
to
 
minimum),
 
and
 
there’s
 
also
 
newer
 
Mel-Roformer
 
(read
 de-reverb section).  As  for  Karaoke models,  there's  e.g.  a  Mel-Roformer  model  on  x-minus.pro  for  premium  users  or  MVSEP/jarredeou  inference  Colab.   "If  the  vocals  don't  contain  harmonies,  this  model  (Mel)  is  better.  In  other  cases,  it  is  better  to  
use
 
the
 
MDX+UVR
 
Chain
 
ensemble
 
for
 
now.".
 
It
 
is
 
possible
 
to
 
recreate
 
to
 
some
 
extent
 
this
 
approach
 
while
 
not
 
using
 
BVE
 
v2
 
models,
 
by
 
processing
 
the
 
output
 
of
 
main
 
vocal
 
model
 
by
 
one
 
of
 
Karaoke/BVE
 
models
 
in
 
UVR
 
(possibly
 
VR
 
model
 
as
 
the
 
latter)
 
using
 
Settings>Additional
 
Settings>Vocal
 
Splitter
 
Options,
 
so
 
it
 
separates
 
using
 
one
 
model,
 
then
 
it
 
uses
 
the
 
result
 
as
 
input
 
for
 
the
 
next
 
model
 
(see
 
the
 
Karaoke
 
section).
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
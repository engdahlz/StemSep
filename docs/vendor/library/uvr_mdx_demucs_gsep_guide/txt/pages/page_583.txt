[page 583/642]
    sami-bytedance-v.0.1.1  result  (which  was  actually  multistem  model  iirc),  achieving  16.9279  
for
 
instrumental,
 
and
 
10.6204
 
for
 
vocals.
 With  epoch  162,  they  achieved  16.9746  and  10.6671,  which  for  instrumental,  is  now  only  
0,0017
 
difference
 
in
 
SDR
 
vs
 
v.0.11
 
result.
  Training  settings:  chunk_size  7.99s  dim  512  /  depth  12  Total  params:  159,758,796  batch_size  16  gradient_accumulation_steps:  1   Since  epoch  74  there  were  “added  +126  songs  to  my  dataset”   Training  progress:  https://ibb.co/1zfFX82  Source:  https://web.archive.org/web/20240126220641/https://mvsep.com/quality_checker/multisong_leaderboard?sort=instrum https://web.archive.org/web/20240126220559/https://mvsep.com/quality_checker/entry/5883  It  sounds  similarly  to  the  Ripple  model.   "7  days  training  on  8xA100-80GB":  7\*24\*15.12  (runpod  8xa100  pricing)  =  $2540.16”   viperx  trained  on  dataset  type  2,  meaning  that  he  had  2  folders:  vocals  and  other  and  no  augmentations   “For  more  detailed  infos,  you  can  read  ZFTurbo's  doc  about  dataset  types  handled  by  his  
script
 https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/dataset_types.md”   viperx  trained  on  faster  Mel-Roformer  arch  variant  before,  and  on  epoch  3005  trained  40  
days
 
on
 
2xA100-40GB
 
with
 
4500
 
songs,
 
he
 
achieved
 
only
 
16.0136
 
for
 
instrumentals,
 
and
 
9.7061
 
which
 
is
 
in
 
pair
 
with
 
MDX-Net
 
voc_ft
 
model
 
(2021
 
arch).
 
 “Each  epoch  [in  Mel-Roformer]  with  600  steps  took  approximately  7  to  10  minutes,  while  
epochs
 
with
 
1000
 
steps
 
took
 
around
 
14
 
to
 
15
 
minutes.
 
These
 
are
 
estimated
 
times.
 Initially,  I  suspected  that  the  SDR  was  not  improving  due  to  using  only  2xA100-  40GB   
GPUs.
 
After
 
conducting
 
tests
 
with
 
8
 
x
 
80GB
 
A100
 
GPUs,
 
I
 
observed
 
that
 
the
 
SDR
 
remained
 
stagnant,
 
suggesting
 
that
 
the
 
issue
 
might
 
be
 
related
 
to
 
an
 
error
 
in
 
the
 
implementation
 
of
 
the
 Mel-Roformer  architecture.”  More  info (copy).  Probably  it  was  the  issue  (at  least  partially?)  fixed  by  Kim  config  tweaks.  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 6/642]
    Just  had  another  song  where  fv7beta1  was  fuller  than  fv7beta3,  but  it  was  also  a  lot  noisier  large  majority  of  the  songs  I  tested,  fv7beta3  was  fuller...  I  think  fv7beta3  is  usually  a  bit  
noisier
 
than
 
fv7beta1?
 
But
 
also
 
sounds
 
fuller
 
in
 
those
 
cases,
 
I'd
 
say
 
it's
 
generally
 
worth
 
it
 instrumental  bleed,  usually  worse  with  fv7beta3  versus  fv7beta1,  but  it  depends  fv7beta2  is  always  less  full/less  noise,  but  only  slightly  less  instrumental  bleed  than  
fv7beta1”
 
-
 
rainboomdash
  Mel  inst_fv7b |  yaml Inst.  fullness  27.07  |  bleedless  47.49  |  SDR  16.71  “this  may  be  the  last  beta  before  the  final  model”  -  Gabox  The  highest  bleedless  metric  out  of  all  instrumental  models  so  far.  But  fullness  is  worse  than  
even
 
most
 
vocal
 
Mel-Roformers
 
(including
 
BS-RoFormer
 
SW
 
and
 
Mel
 
Kim
 
OG
 
model).
 “On  the  fuller  side,  somewhere  around  inst  v1e+,  maybe  a  tiny  bit  below.  The  main  thing  I  
notice
 
is
 
it
 
captures
 
more
 
instruments
 
than
 
v1e+,
 
but
 
isn't
 
muddy
 
like
 
[inst
 
Resurrection]
 
(which
 
also
 
captures
 
more
 
instruments)
 
(...)
 
It
 
can
 
add
 
a
 
lot
 
of
 
crackling
 
noise,
 
though,
 
more
 
than
 
v1e+
 
(...)
 
can
 
be
 
a
 
little
 
on
 
the
 
noisy
 
side
 
sometimes...
 
but
 
it
 
at
 
least
 
isn't
 
muddy
 
and
 
sounds
 
natural
 
(...)
 
I'd
 
still
 
ensemble
 
if
 
you
 
want
 
the
 
noise
 
reduced
 
-
 
rainboomdash
 (src)   -  Unwa  released  BS-Roformer-HyperACE instrumental  model  |  separate  Colab Inst.  fullness  36.91  |  bleedless  38.77  |  SDR  17.27  (less  fullness  than  v1e+:  37.89,  but  more  bleedless:  36.53,  SDR:  16.65)  Note:  It  uses  its  own  inference  script.  “You  can  use  this  model  by  replacing  the  MSST  
repository's
 
models/bs_roformer.py
 
with
 
the
 
repository's
 
bs_roformer.py.”
 To  not  affect  functionality  of  other  BS-Roformer  models  by  it,  you  can  add  it  as  new  model_type  by  editing  utils/settings.py  and  models/bs_roformer/init.py  here (thx  anvuew).  For  error  while  installing  the  py  file  for  HyperACE  model  in  Sucial’s  WebUI:  from  models.bs_roformer.attend  import  Attend  ModuleNotFoundError:  No  module  named  'models'"  The  fix:  “SUC-DriverOld/MSST-WebUI  use  the  name  "modules"  and  
ZFTurbo/Music-Source-Separation-Training
 
use
 
the
 
name
 
"models".
 
And
 
Unwa's
  
bs_roformer.py
 
that
 
you
 
replace
 
with,
 
also
 
use
 
"models".
 
So
 
you'll
 
have
 
to
 
do
 
some
 
coding
 
and
 
symlink
 
to
 
make
 
it
 
work.”
 
-
 
fjordfish
 “Currently,  this  model  holds  the  highest  aura_mrstft  score  on  the  instrumental  side  of  the  
Multisong
 
dataset.
 
(...)
 Some  components  in  the  SegmModel  module  were  implemented  based  on  this  paper:  https://arxiv.org/abs/2506.17733 Simply  put,  it's  a  module  that  utilizes  hypergraphs  to  capture  global  relationships  and  
standard
 
convolutions
 
to
 
capture
 
local
 
relationships,
 
thereby
 
generating
 
the
 
final
 
“Correlation-Enhanced”
 
feature
 
map.
 This  weight  is  based  on  the  following  weights.  Thank  you,  anvuew!  https://huggingface.co/anvuew/BS-RoFormer”  -  unwa  -  The  inference  file  got  updated  to  fix  error  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
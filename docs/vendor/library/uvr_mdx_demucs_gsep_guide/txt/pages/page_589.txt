[page 589/642]
    Q:  Is  the  speed  also  faster  despite  the  use  of  gradient  checkpointing  because  memory  
bandwidth
 
was
 
the
 
bottleneck?
 A:  I  don't  know,  maybe  yes.  Now  we  need  to  ensure  it  doesn't  affect  the  training  process.  
And
 
the
 
quality
 
of
 
models
 
stays
 
the
 
same.
 So  there  is  no  need  to  decrease  mlp_expansion_factor  from  4  to  1  currently  (may  be  later  for  
train
 
new
 
models).
 I  will  add  possibility  to  train  with  low  mem  in  my  repo  in  several  minutes  I  think  speed  up  is  because  of  the  benefits  of  large  matrix  multiplication  (because  it's  
calculated
 
for
 
40
 
images
 
at
 
the
 
same
 
time).
 Q:  Can  the  gradient  checkpointing  be  applied  to  other  architectures?  For  example  SCNet  A:  I  think  yes,  but  maybe  with  lower  benefits.   -  “One  thing  to  keep  in  mind  too,  is  that  Rofos  are  using  flash  attention  by  default,  which  is  
not
 
compatible
 
with
 
all
 
GPUs
 
(not
 
with
 
small
 
ones),
 
and
 
this
 
flash
 
attention
 
is
 
greatly
 
reducing
 
training
 
duration,
 
from
 
what
 
I
 
get.
 
Non-compatible
 
GPUs
 
use
 
lower
 
performing
 
attention.
 https://github.com/Dao-AILab/flash-attention”  Supported  GPUs:  https://imgur.com/a/QGtSuKR (src -  half  a  year  later,  Flash  Attention  2  is  still  unsupported  on  RTX  2000  series,  and  FA3  beta  is  available  for  Hopper  GPUs  (e.g.  
H100)
 Q:  The  training  script  defaults  to  memory  efficiency  unless  you  use  A100  though,  does  this  
mean
 
ZF
 
didn't
 
implement
 
flash
 
att
 
for
 
the
 
other
 
GPUs
 
listed
 
there
 A:  I  don't  know,  I  think  it's  more  related  to  the  custom  flash  attention  module  made  by  
lucidrains,
 
he
 
doesn't
 
use
 
this
 
flash
 
attention
 
repo.
 
frazer
 
and
 
unwa
 
had
 
a
 
discussion
 
about
 
that
 
in
 
devtalk
 
some
 
days
 
ago,
 
I
 
didn't
 
understand
 
everything,
 
just
 
learnt
 
that
 
it
 
was
 
custom
 
implementation
 anvuew  made  a  pull  request  (“Enable  flash  attention  for  compute  capability  >=  8.0”  so  GPUs  
from
 
RTX
 
3000
 
onward)
 https://github.com/ZFTurbo/Music-Source-Separation-Training/pull/52 (merged  already)   Q:  Is  adam  or  adamw  better  for  Mel-Roformer?  A:  “This  is  not  particularly  relevant  if  weight  decay  is  not  used.  In  Adam  it  was  implemented  with  L2  normalization;  in  AdamW  it  is  implemented  in  its  original  
form.”
 
-
 
unwa
 
Bas
 
Curtiz
 
later
 
conducted
 
some
 
experiments
 
on
 
the
 
best
 
optimizer,
 
and
 
the
 
winner
 
is:
 
Prodigy
 
(with
 
LR
 
1.0)
 
on
 
the
 
same
 
amount
 
of
 
steps
 
(~14K)
 
and
 
~20
 
hours
 
in
 
(at
 
least
 
when
 training  from  scratch).  More  
-
 
Unwa’s
 
 “1)  v1e  model  was  trained  with  a  custom  loss,  if  you  don't  use  the  same  or  similar  multi  
resolution
 
loss,
 
your
 
results
 
will
 
be
 
bad
 2)  because  of  [the]  1[st],  SDR  is  not  the  best  metric  to  keep  track  of  how  good  the  model  is,  
SDR
 
will
 
be
 
lower
 
when
 
training
 
with
 
mrstft
 
losses
 3)  you  must  set  the  target  instrument  to  other,  and  yes  you  need  more  vocals”  becruily  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
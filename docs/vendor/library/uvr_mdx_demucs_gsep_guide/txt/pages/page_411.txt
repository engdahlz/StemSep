[page 411/642]
    If  you  want  to  get  rid  of  some  artifacts,  you  can  further  process  output  vocal  track  from  MDX  
through
 
Demucs
 
3.
  Options  in  the  old  HV  MDX  Colab/or  kae  fork  Colab  (from  the  very  top)   Demucs  model  in  the  older  MDX-Net  Colab  When  it's  enabled,  it  sounds  better  to  me,  used  with  the  old  narrowband  9.X  and  newer  vocal  
models,
 
as
 
Demucs
 
2
 
model
 
is
 
fullband,
 
but
 
opinions
 
on
 
superiority
 
of
 
this
 
option
 
are
 
divided,
 
and
 
MVSEP
 
dev
 
made
 
some
 
SDR
 
calculation
 
where
 
it
 
achieved
 
worse
 
results
 
with
 
Demucs
 
enabled.
 
But
 
be
 
aware,
 
that
 
inverted
 
results
 
from
 
narrowband
 
are
 
still
 
fullband
 
despite
 
the
 
narrowband
 
training
 
frequency,
 
as
 
there’s
 
no
 
cutoff
 
matching
 
present
 
in
 
Colab,
 
as
 
it’s
 
implemented
 
in
 
UVR
 
GUI
 
as
 
a
 
separate
 
option.
 
Using
 
such
 
cutoff
 
matching
 
training
 
frequency
 
(which
 
can
 
be
 
observed
 
in
 
non-inverted
 
stem)
 
might
 
lead
 
to
 
less
 
noise
 
and
 
residues
 
in
 
the
 
results.
 
Demucs
 
model
 
will
 
work
 
correctly
 
only
 
with
 
vocal
 
models
 
in
 
Colabs
 
(we
 
didn’t
 
have
 
any
 
MDX
 
instrumental
 
models
 
back
 
then,
 
so
 
naming
 
scheme
 
is
 
reversed
 
for
 
these
 
models,
 
hence
 
Demucs
 
model
 
with
 
instrumental
 
model
 
produces
 
distorted
 
sound,
 
it
 
mixes
 
vocals
 
with
 
instrumental
 
in
 
a
 
weird
 
way).
  “The  --shifts=SHIFTS  performs  multiple  predictions  with  random  shifts  (a.k.a.  the  shift  trick)  
of
 
the
 
input
 
and
 
average
 
them.
 
This
 
makes
 
prediction
 
SHIFTS
 
times
 
slower
 
but
 
improves
 
the
 
accuracy
 
of
 
Demucs
 
by
 
0.2
 
points
 
of
 
SDR.
 
It
 
has
 
limited
 
impact
 
on
 
Conv-Tasnet
 
as
 
the
 
model
 
is
 
by
 
nature
 
almost
 
time
 
equivariant.
 
The
 
value
 
of
 
10
 
was
 
used
 
on
 
the
 
original
 
paper,
 
although
 
5
 
yields
 
mostly
 
the
 
same
 
gain.
 
It
 
is
 
deactivated
 
by
 
default,
 
but
 
it
 
does
 
make
 
vocals
 
a
 
bit
 
smoother.
  The  --overlap  option  controls  the  amount  of  overlap  between  prediction  windows  (for  
Demucs
 
one
 
window
 
is
 
10
 
seconds).
 
Default
 
is
 
0.25
 
(i.e.
 
25%)
 
which
 
is
 
probably
 
fine.”
 You  can  even  try  out  0.1,  but  for  Demucs  4  it  decreases  SDR  in  ensemble  if  you’re  trying  to  
separate
 
a
 
track
 
containing
 
vocals.
 
If
 
it’s
 
instrumental,
 
then
 
0.1
 
is
 
the
 
best
 
(e.g.
 
for
 
drums).
  (outdated/for  offline  use/added  to  Colab)   Here's  the  new  MDX-B  Karokee  model!  https://mega.nz/file/iZgiURwL#jDKiAkGyG1Ru6sn21MkIwF90C-fGD0o-Ws58Mn3O7y8 The  archive  contains  two  versions:  normal  and  aggressive.  The  second  removes  the  lead  
vocals
 
more.
 
The
 
model
 
was
 
trained
 
using
 
a
 
dataset
 
that
 
I
 
completely
 
created
 
from
 
scratch.
 
There
 
are
 
610
 
songs
 
in
 
total.
 
We
 
ask
 
that
 
you
 
please
 
credit
 
us
 
if
 
you
 
decide
 
to
 
use
 
these
 
models
 
in
 
your
 
projects
 
(Anjok,
 
aufr33).
 
   __________________________________________________________________   
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
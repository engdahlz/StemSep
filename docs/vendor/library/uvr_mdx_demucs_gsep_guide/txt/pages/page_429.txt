[page 429/642]
    best  ensembles  in  UVR.  Versions  2.4  and  newer  started  to  utilize  BS-Roformer  arch,  which  
is
 
pretty
 
muddy
 
itself,
 
but
 
deprived
 
of
 
the
 
majority
 
of
 
vocal
 
residues.
  -  For  instrumentals,  I’d  rather  stick  to  instrum2  results  (so  sum  of  all  3  stems  instead  of  
inversion
 
with
 
e.g.
 
inst
 
only
 
enabled)
 
but
 
some
 
fragments
 
can
 
sound
 
better
 
in
 
instrum
 
and
 
it
 
also
 
slightly
 
better
 
SDR,
 
so
 
e.g.
 
instrum
 
can
 
give
 
louder
 
snares
 
at
 
times,
 
while
 
instrum2
 
is
 
muddier
 
but
 
sometimes
 
less
 
noisy/harsh.
 
It
 
can
 
all
 
depend
 
on
 
a
 
song.
 
Most
 
people
 
can’t
 
tell
 
a
 
difference
 
between
 
both.
  -  If  you  stuffer  from  some  vocal  residues  in  v.  2.2.2,  try  out  these  settings  BigShifts_MDX:  0  overlap_MDX:  0.65  overlap_MDXv3:  10  overlap  demucs:  0.96  output_format:  float  vocals_instru_only:  disabled  (it  will  additionally  give  instrum2  output  file  for  less  vocal  
residues
 
in
 
some
 
cases)
  -  You  can  manipulate  with  weights.  E.g.  different  weight  balance,  in  2.2  with  less  MDXv3  and  more  VOC-FT.   -  For  vocals  in  2.2 you  can  test  out  these (dead  link)  settings  (21,  0,  20,  6,  5,  2,  0.8)  -  In  older  versions  of  the  Colab  Overlap  large  and  small  control  overlap  of  song  during  
processing.
 
The
 
larger
 
value,
 
the
 
slower
 
processing
 
but
 
better
 
quality
 
(for
 
both),
 
but
 
bad
 
setting
 
will
 
crash
 
your
 
separation
 
at
 
least
 
on
 
certain
 
songs.
 Q:  is  it  possible  to  use  v.2.5  for  Melband  inference  without  the  need  to  run  the  BS  model?  A:  You  can  comment  out  the  model(s)  you  don't  want  to  disable  them  L621-627  in  
inference.py
 
[in
 
the
 
line
 
called
 
“vocals_model_names”
 Probably,  you  could  also  set  BS  weight  to  0,  but  it  might  trigger  separation  of  that  model  
anyway,
 
making
 
it
 
slower.]
  -  To  experiment  with  parameters  for  just  4  stems  separation,  you  can  use:  a)  "overlap_demucs"  in  the  Colab  (not  sure  how  in  this  Colab,  but  for  demucs_ft,  shifts  
10
 
and
 
overlap
 
0.1
 
worked
 
the
 
best
 
for
 
original
 
instrumentals
 
as
 
input)
 b)  shifts  for  demucs  are  in  line  probably  511  (formerly  618  in  some  other  versions  iirc):  https://github.com/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/inference.py  -  In  order  to  bypass  models  for  2  stem  separation  to  use  just  instrumentals  as  input  for  4  
stem
 
separation,
 
“comment
 
out/delete
 
the
 
name
 
of
 
the
 
models
 
you
 
want
 
to
 
bypass”
 
in
 
the
 line  621  (screen).  “If  you  want  to  use  only  VOCFT,  you  have  to  activate  InstVoc  too,  else  it  will  crash  (as  it's  using  InstVoc  to  fill  the  spectrum  part  that  is  missing  because  of  VOCFT  
cutoff)”
 
-
 
jarredou
   
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 83/642]
    author  said  it  worked  as  expected  using  ZF  training  script  https://github.com/starrytong/SCNet/issues/1#issuecomment-2063025663)”   The  author:  “All  our  experiments  are  conducted  on  8  Nvidia  V100  GPUs.  When  training  solely  on  the  MUSDB18-HQ  dataset,  the  model  is  trained  for  130  epochs  with  the  Adam  [22]  optimizer  with  an  initial  learning  rate  of  5e-4  and  batch  size  of  4  for  each  GPU.  Nevertheless,  we  adjust  the  learning  rate  to  3e-4  when  introducing  additional  data  to  mitigate  potential  gradient  explosion.”   “Q:  So  that  mean  that  you  have  to  modulate  the  learning  rate  depending  on  the  size  of  the  
dataset?
 I  think  it's  the  first  time  I  read  something  in  that  way.  A:  Yea,  I  suppose  because  the  dataset  is  larger  you  need  to  ensure  the  model  sees  the  
whole
 
distribution
 
instead
 
of
 
just
 
learning
 
the
 
first
 
couple
 
of
 
batches”
 -  jarredou/frazer   SCNet  paper:  https://arxiv.org/abs/2401.13276 On  the  same  dataset  (MUSDB18-HQ),  it  performs  a  lot  better  than  Demucs  4  (Demucs  HT).   “Melband  is  still  SOTA  cause  if  you  increase  the  feature  dimensions  and  blocks  it  gets  better  you  can't  scale  up  scnet  cause  it  isn't  a  transformer.  It's  a  good  cheap  alt  version  tho”  Still,  it  might  potentially  give  interesting  results  when  training  will  be  mastered  to  the  point  
when
 
e.g.
 
SDR
 
will
 
be
 
in
 
pair
 
with
 
at
 
least
 
MDX-Net
 
models
 
as
 
they
 
can
 
still
 
be
 
better
 
than
 
Roformers
 
for
 
instrumentals
 
in
 
many
 
cases
 
(e.g.
 
MDX-Net
 
tend
 
to
 
have
 
less
 
muddy
 
instrumentals
 
-
 
every
 
arch
 
can
 
have
 
its
 
own
 
unique
 
sound
 
characteristics
 
and
 
might
 
be
 
potentially
 
useful
 
for
 
ensembling).
  -  (jarredou)  “I've  released  the  Drums  Separation  model  trained  by  aufr33  (on  my  not-that-clean  drums  dataset).   Stems:  kick,  snare,  toms,  hihat,  ride,  crash   It  can  already  be  used,  but  training  is  not  fully  finished  yet.  The  config  allows  training  on  not  so  big  GPUs  [n_fft  2048  instead  of  8096],  it's  open  to  
anyone
 
to
 
resume/fine-tune
 
it.
  For  now,  it's  struggling  a  bit  to  differentiate  ride/hh/crash  correctly,  kick/snare/toms  are  more  
clean.
  Download   [attached  config  includes  also  necessary  training  parameters  for  training  further  using  ZFTurbo  repo]:  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 591/642]
    It  is  a  relatively  new  time-domain  metric  over  SDR  and  SI-SDR  that  is  not  overly  sensitive  to  
low
 
frequencies
 
like
 
SDR
 
and
 
can
 
accurately
 
evaluate
 
silent
 
intervals.
 In  addition,  time-domain  metrics  can  be  evaluated  for  both  amplitude  and  phase.”    -  LoRA  training  repository  by  frazer  -  for  only  Mel  and  BS  models  at  the  moment  (merged  into  ZFTurbo’s  MSST  training  repo  already)  https://github.com/fmac2000/Music-Source-Separation-Training-Models/tree/lora  “LoRA  could  specialize  in  a  particular  singer  or  genre.”  “You  can  use  LoRA  as  a  replacement  for  full-weight  fine-tuning  for  now,  all  I  can  say  is  that  it'll  be  faster  to  train  and  way  more  memory  efficient  than  
fine-tuning
 
-
 
whether
 
the
 
performance
 
competes
 
with
 
full
 
fine-tuning
 
up
 
is
 
yet
 
to
 
be
 
determined”
 “did  a  small  test,  and  it  achieved  results  in  hours  that  took  me  days  to  achieve  with  A100”  “I  trained  it  for  a  week  -  180  epochs   I  took  Kim  Melband  and  just  trained  a  LoRA  on  the  standard  MUSDB  -  it  took  SDR  vocals  
from
 
11
 
to
 
around
 
12.3
 
after
 
100
 
epochs
 
on
 
batch_size
 
=
 
1.
 
I
 
didn't
 
save
 
each
 
epoch
 
so
 
that
 
100
 
epoch
 
voc12.3
 
isn't
 
there.
 (...)  my  bets  it  sucks  ass  since  it's  overtrained”  frazer   -  Bytedance  and  Asriver  prepared  some  enhancements  for  Roformer  arch,  and  already  
published
 
white
 
paper
 
which
 
will
 
be
 
presented
 
on
 
ISMIR2024:
 https://arxiv.org/abs/2409.04702 Iirc,  sami-bytedance-v.1.1  model  is  already  some  derivative  of  above  with  higher  
parameters,
 
settings
 
and
 
from
 
what
 
I
 
remember,
 
trained
 
on
 
16xA100,
 
which
 
cannot
 
be
 
even
 
rented.
 
Bas
 
tried
 
to
 
train
 
a
 
model
 
(model_mel_band_roformer_ep_617_sdr_11.5882)
 
better
 
than
 
that,
 
by
 
just
 
training
 
purely
 
on
 
mutlisong
 
dataset,
 
but
 
he
 
couldn’t
 
surpass
 
that
 
score.
  -  At  the  end  of  December  2024,  Lucidrains  implemented  " Value  Residual  Learning "  into  his  BS-Roformer  repo,  based  on  the  following  paper:  https://arxiv.org/abs/2410.17897 “The  paper  argues  that  this  mechanism  can  reduce  the  over-focus  of  attention  and  further  
reduce
 
the
 
vanishing
 
gradient
 
problem.”
 Unwa  trained  a  small  400MB  experimental  instrumental  model  based  on  it.  Doesn’t  work  in  UVR.  Now  it’s  also  added  into  ZFTurbo  MSST  repo.   -  CFM  Before  the  middle  of  2025,  somewhere  in  probably  #dev-talk  of  our  Discord  server,  jarredou   “posted  a  repo  from  the  ByteDance  team  which  explained  a  method  but  didn't  implement  it  in  
the
 
code”
  Becruily:  “Gemini  did  a  quick  pseudo  implementation,  and  it  trains  4  times  slower”  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
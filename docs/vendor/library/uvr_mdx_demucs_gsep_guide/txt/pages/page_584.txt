[page 584/642]
     Later,  the  viperx’  BS-Roformer  model  was  further  trained  from  checkpoint  by  ZFTurbo,  and  it  
surpassed
 
all
 
the
 
previously
 
released
 
models,
 
and
 
even
 
ensembles,
 
at
 
least
 
SDR-wise.
 
Then
 
it
 
was
 
finetuned
 
on
 
different
 
dataset.
 
Still,
 
as
 
all
 
Roformers,
 
it
 
might
 
share
 
some
 
characteristic
 
features,
 
like
 
occasional
 
muddiness,
 
and
 
filtered
 
sound
 
at
 
times,
 
but
 
Mel
 
variant
 
seems
 
to
 
be
 
less
 
muddy.
  More  insides:  https://github.com/lucidrains/BS-RoFormer/issues/4#issuecomment-1738604015 https://media.discordapp.net/attachments/708579735583588366/1156700109682262129/image.png?ex=6516952c&is=651543ac&hm=988a5acc32f075988c1701d41c2090321a25955c4ffedd64516e0062fa1002e0 https://cdn.discordapp.com/attachments/708579735583588366/1156700305069707315/image.png?ex=6516955b&is=651543db&hm=bf5737f95f3a93fd3e3a23a679e2ad0031e0feb6c622fbb85eafa053ed483e08 https://media.discordapp.net/attachments/708579735583588366/1156700453585829898/image.png?ex=6516957e&is=651543fe&hm=06ed766b39c3c7f4a8329420a22bcc572e856116a6e1cea030d158c984c46825   More  hints/FAQ  for  training  Roformers   
ZFTurbo:
 "1)  Best  [BS-Roformer]  model  with  the  best  parameters  can  be  trained  only  on  A100,  and  
you
 
need
 
several
 
GPUs.
 
The
 
best
 
is
 
use
 
8.
 
It
 
reduces
 
possibilities
 
of
 
training
 
by
 
enthusiasts.
 
 [later  it  was  found  out  that  checkpointing  decreased  VRAM  usage  allowing  using  probably  
more
 
modest
 
GPUs]
 All  other  models  like  HTDemucs  or  MDX23C  can  be  trained  on  single  GPU.  Lower  
parameter
 
BS-Roformers
 
don't
 
give
 
the
 
best
 
results.
 
But
 
maybe
 
it's
 
possible.
 
Solution:
 
 We  need  to  try  train  smaller  version  which  will  be  equal  to  current  big  version.  Lower  depth,  
lower
 
dim,
 
less
 
chunk_size.
 
We
 
need
 
to
 
achieve
 
at
 
least
 
batch
 
4
 
for
 
single
 
GPU.
 
Having
 
such
 
model
 
can
 
be
 
useful
 
as
 
starting
 
point
 
for
 
fine-tuning
 
for
 
other
 
tasks/stems
 [perhaps  Unwa’s  400MB  exp  value  residue  model  meets  that  requirements).  2)  I  also  noticed  a  strange  problem  I  didn't  solve  yet.  If  you  try  to  finetune  version  trained  on  
A100
 
on
 
some
 
cards
 
other
 
than
 
A100
 
then
 
SDR
 
drops
 
to
 
zero
 
after
 
first
 
epoch.
 
Looks
 
like
 
"Flash
 
attention"
 
has
 
some
 
differences
 
(???).
 3)  Training  is  extremely  slow.  And  I  noticed  BS-Roformer  more  sensitive  to  some  errors  in  
dataset.
  [probably  for  4090]  chunk_size:  131584  dim:  256  depth:  6   
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 288/642]
    “most  of  the  time  using  higher  chunk_size  than  the  one  used  during  training  gives  a  bit  better  
SDR
 
score,
 
until
 
a
 
peak
 
value,
 
and
 
then
 
quality
 
degrades.
 For  Roformers  trained  with  8  sec  chunk_size,  11  sec  is  giving  best  SDR  (then  it  degrades  
with
 
higher
 
chunk
 
size)
 For  MDX23C,  when  trained  with  ~6  sec  chunks,  iirc,  peak  SDR  value  was  around  24  sec  
chunks
 
(I
 
think
 
it
 
was
 
same
 
for
 
vit_large,
 
you
 
could
 
make
 
chunks
 
4
 
times
 
longer)
 How  much  chunk_size  can  be  extended  during  inference  seems  to  be  arch  dependant.”  -  
jarredou
  Be  aware  that  increasing  chunk_size  consumes  much  more  VRAM,  and  for  4GB  VRAM  
AMD/Intel
 
GPUs,
 
the
 
max
 
supported
 
will
 
be
 
chunk_size
 
=
 
112455
 
(2,55s),
 
sometimes
 
chunk_size
 
=
 
132300
 
(3s).
 
CUDA
 
has
 
garbage
 
collector
 
which
 
might
 
make
 
VRAM
 
usage
 
more
 
efficient.
  “Conversion  between  dim_t  and  chunk_size  [dim_t  was  used  in  the  old  Roformer  beta  2  
UVR
 
patch]
 
  dim_t  =  801  is  chunk_size  =  352800  (8.00s)  -  maximum  value  working  on  AMD/Intel  8GB  
GPUs
 
and
 
900MB,
 
at
 
least
 
Mel
 
models
 dim_t  =  1101  is  chunk_size  =  485100  (11.00s)  dim_t  =  256  is  chunk_size  =  112455  (2,55s)  -  maximum  value  for  AMD/Intel  4GB  GPUs  dim_t  =  1333  is  chunk_size  =  587412  (13,32s)   The  formula  is:  chunk_size  =  (dim_t  -  1)  *  hop_length)”  -  jarredou   Unless  you  turn  off  Segment  default  in  Options>Advanced  MDX-Net>Multi  Network  Options,  
chunk_size
 
is
 
being
 
read
 
from
 
the
 
yaml
 
of
 
the
 
model.
  Inference  mode   Can  be  found  in  the  menu  Multi  Network  Options  menu  above.  Turning  it  off  will  fix  the  issue  
of
 
silent
 
separations
 
on
 
older
 
GTX
 
GPUs
 
(iirc
 
GTX
 
900
 
and
 
older),
 
but
 
it
 
might
 
make
 
separation
 
slower
 
for
 
other,
 
at
 
least
 
Nvidia
 
GPUs.
 It  was  implemented  in  one  of  the  latest  beta  Roformer  patches,  so  if  you  noticed  any  
slowdowns
 
since
 
updating
 
UVR,
 
try
 
enabling
 
it
 
(now
 
it’s
 
disabled
 
by
 
default).
  batch_size   Inference  Colab  by  jarredou  forces  1  (clicks  with  that  setting  were  fixed  in  MSST  later),  and  
using
 
above
 
2
 
might
 
increase
 
VRAM
 
usage.
 
In
 
newer
 
patches,
 
Anjok
 
started
 
to
 
use
 
MSST
 
inference
 
code
 
for
 
Roformers
 
and
 
MDX23C,
 
hence
 
it
 
might
 
have
 
inherited
 
its
 
usage.
  Technical  explanation  how  it  works  near  the  end of  this  document  (scroll  down  a  bit).   
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 308/642]
    the  top,  and  experiment.  
Apart
 
from
 
bleedless/fullness
 
metric,
 
models
 
with
 
bigger
 
SDR
 
than
 
others
 
might
 
pick
 
up
 
instruments
 
better
 
(e.g.
 
less
 
wind
 
instruments
 
recognized
 
as
 
voice).
 Also,  “The  way  I  see  high  SDR  is  it  indicates  the  lower  frequencies  will  be  more  accurate  to  
the
 
original
 
stem,
 
and
 
be
 
more
 
free
 
of
 
distortion
 
or
 
noise.
 
And
 
I
 
also
 
see
 
it
 
sometimes
 
indicates
 
better
 
quality
 
of
 
fundamental
 
frequencies
 
(closer
 
to
 
the
 
original
 
gain/phase,
 
more
 
consistent
 
separation),
 
but
 
I
 
don’t
 
know
 
much
 
beyond
 
that
 
lol”
 
-
 
stephanie
  -  For  specific  songs,  different  ensemble  configurations  can  give  better  results  than  for  others.   -  "Since  the  SDR  [on  MVSEP’s]  synth  dataset  is  flawed  from  the  get-go  due  to  the  dataset  
being
 
used
 
isn't
 
really
 
music,
 
but
 
sample-based,
 
don't
 
get
 
your
 
hopes
 
up
 
too
 
much.".
 But  it  generally  reflects  in  greater  extent  differences  between  models,  e.g.  used  in  Demixing  
Challenge
 
2021,
 
so
 
it's
 
not
 
totally
 
bad
 
and
 
multisong
 
dataset
 
might
 
be
 
even
 
better
 
(and
 
still
 
not
 
perfect)
 
-
 
just
 
be
 
aware
 
that
 
different
 
settings
 
can
 
give
 
you
 
better
 
results
 
for
 
your
 
particular
 
song
 
rather
 
than
 
average
 
best
 
combination
 
of
 
models
 
on
 
the
 
SDR
 
chart.
 
-
 
Bas
 
Curtiz
 
conducted
 
some
 
tests
 
with
 
commercial
 
music
 
as
 
evaluation
 
dataset,
 
and
 
it
 
turned
 
out
 
that
 
only
 
models
 
already
 
close
 
in
 
SDR
 
switched
 
ranks,
 
and
 
most
 
models
 
kept
 
the
 same.  So  in  conclusion,  multisong  dataset  can  be  considered  as  still  reliable  (although  bleedless  and  fullness  metric  is  more  suitable  for  our  tasks  now  -  more  below).   About  SDR  evaluation  on  MVSEP  and  how  important  factor  is  that  to  the  final  result     It  still  depends  on  the  specific  song,  what  bag  of  models/ensemble  or  what  specific  models  
will
 
come
 
out
 
the
 
best
 
in
 
specific
 
scenarios.
 
Suggesting
 
by
 
SDR
 
of
 
at
 
least
 
multisong
 
dataset
 
can
 
be
 
misleading.
 
For
 
example,
 
the
 
metric
 
doesn’t
 
really
 
reflect
 
the
 
differences
 
between
 
e.g.
 
HQ_3
 
and
 
MDX23C
 
fullband
 
model
 
in
 
case
 
of
 
bleeding
 
in
 
instrumentals
 
occurring
 
in
 
lots
 
of
 
contemporary
 
songs.
 
Although,
 
the
 
bleeding
 
issue
 
doesn’t
 
always
 
occur,
 
and
 
then,
 
HQ_3
 
results
 
can
 
be
 
more
 
muffled,
 
so
 
in
 
this
 
case,
 
SDR
 
metric
 
would
 
be
 
more
 
accurate
 
to
 
human
 
listening
 
scenario
 
where
 
MDX23C
 
models
 
gets
 
better
 
metric,
 
so
 
it
 
can
 
be
 
misleading,
 
because
 
SDR
 
can
 
vary
 
very
 
much
 
from
 
song
 
to
 
song.
 
 
“The
 
thing
 
is
 
that
 
SDR
 
evaluates
 
at
 
the
 
same
 
time
 
how
 
"full"
 
the
 
stem
 
separation
 
is
 
and
 
how
 
much
 
bleed
 
there
 
is
 
in
 
the
 
separated
 
stem.
 
You
 
can't
 
know,
 
only
 
based
 
on
 
SDR
 
score,
 
which
 
of
 
"fullness"
 
or
 
"bleedless"
 
is
 
impacting
 
the
 
score
 
the
 
more”
 
-
 
jarredou
 Also,  according  to  some  SDR  evaluations  conducted  by  Bas  Curtiz,  it  turned  out  that  
permanent
 
bleeding
 
don’t
 
have
 
more
 
impact
 
on
 
SDR
 
than
 
occasional
 
bursts
 
of
 
bleeding
 
here
 
and
 
there.
 Still,  in  some  scenarios  SDR  metric  of  multisong  dataset  on  MVSEP  can  be  a  safe  approach,  
giving
 
you
 
some
 
reassurance
 
that
 
the
 
result
 
in
 
a
 
strict
 
test
 
scenario
 
will
 
be
 
at
 
least
 
decent
 
in
 
some
 
respects,
 
although
 
you
 
can
 
(or
 
even
 
should
 
when
 
some
 
instruments
 
are
 
missing)
 
still
 
experiment
 
trying
 
to
 
get
 
a
 
better
 
result,
 
but
 
it
 
doesn't
 
have
 
to
 
be
 
reflected
 
in
 
SDR.
 
 
To
 
sum
 
up,
 
SDR
 
evaluation
 
is
 
only
 
kind
 
of
 
averaging
 
toward
 
a
 
specific
 
dataset
 
of
 
songs,
 
and
 
it’s
 
unpredictable
 
based
 
on
 
just
 
SDR
 
how
 
certain
 
model
 
will
 
behave
 
on
 
specific
 
song,
 
plus
 
its
 
algorithm
 
is
 
limited
 
vs
 
human
 
ears
 
too.
 
For
 
example,
 
if
 
you
 
could
 
measure
 
SDR
 
for
 
a
 
specific
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 530/642]
    -  Jarredou’s  (@rigo2)  dataset  with  screaming,  cheering,  applause,  whistling,  mumble,  etc...  
collected
 
from
 
all
 
the
 
sources
 
I've
 
found,
 
to
 
help
 
model
 
creation:
  +5000  stereo  wav  files,  44100hz  ~37  hours  of  audio  data   -  ”Ultimate  laugh  tracks  for  sitcoms,  game  shows,  talk  shows,  and  comedy  projects  (available  on  Amazon  Music  and  Apple  Music  (ripped,  YT  upload  has  similarly  looking  spectrograms)  -  Laughter-Crowd  Dataset  #2.zip  https://terabox.com/s/1xLuZWvpGX0LTQypO1p7u_g  https://multitracks.pages.dev/ (only  a  list,  no  DL  links)  English  and  Spanish  multitracks   -  Around  30GB  of  T.Swft  stems  (1 (not  necessarily  mirror)  |  2)   -  There  is  768.44  GB  of  K-pop  stems  somewhere  in  the  wild  (maybe  ask  .mikeyyyyy)   -  Gabox  karaoke  dataset  (2GB)  https://gofile.io/d/TyzaH8 (dead;  “i  won't  upload  it  again  since  becruily  told  me  that  dataset  type  4  (iirc)  was  the  best  for  karaoke”)  “(may  need  a  check,  iirc  there  were  songs  without  bv,  also  it  doesn't  have  the  vocals  part)”   -  RawStems  https://huggingface.co/datasets/yongyizang/RawStems (DL)   https://github.com/yongyizang/music-source-restoration/blob/main/preprint.pdf (paper)  “A  dataset  annotation  of  578  songs  with  unprocessed  source  signals  organized  into  8  
primary
 
and
 
17
 
secondary
 
instrument
 
groups,
 
totaling
 
354.13
 
hours.
 
To
 
the
 
best
 
of
 
our
 
knowledge,
 
RawStems
 
is
 
the
 
first
 
dataset
 
that
 
contains
 
unprocessed
 
music
 
stems
 
with
 
hierarchical
 
categories”.
  -  Expressive  Anechoic  Recordings  of  Speech  ( EARS )  dataset.  ●  100  h  of  speech  data  from  107  speakers  ●  high-quality  recordings  at  48  kHz  in  an  anechoic  chamber  ●  high  speaker  diversity  with  speakers  from  different  ethnicities  and  age  range  
from
 
18
 
to
 
75
 
years
 ●  full  dynamic  range  of  human  speech,  ranging  from  whispering  to  yelling  ●  18  minutes  of  freeform  monologues  per  speaker  ●  sentence  reading  in  7  different  reading  styles  (regular,  loud,  whisper,  high  pitch,  
low
 
pitch,
 
fast,
 
slow)
 ●  emotional  reading  and  freeform  tasks  covering  22  different  emotions  for  each  
speaker
 https://github.com/facebookresearch/ears_dataset _____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
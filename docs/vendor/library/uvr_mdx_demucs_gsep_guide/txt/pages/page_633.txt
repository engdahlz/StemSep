[page 633/642]
    e.g.  different  archs  could  be  coded  into  UVR  by  different  developers.  It  was  a  stressful  period  
of
 
time,
 
because
 
Anjok
 
intended
 
to
 
make
 
the
 
software
 
which
 
is
 
free
 
of
 
bugs,
 
and
 
still
 
not
 
fully
 
rely
 
on
 
the
 
community
 
in
 
terms
 
of
 
bug
 
reporting.
  Then  the  Mac  version  came  out  and  M1/M2/M3  support  for  faster  GPU  acceleration.  Anjok  
found
 
out
 
in
 
Demucs
 
repo
 
a
 
part
 
of
 
the
 
code,
 
making
 
it
 
easier
 
to
 
port
 
UVR
 
to
 
Macs,
 
and
 
it
 
is
 
used
 
by
 
every
 
model.
 
Music
 
community
 
is
 
pretty
 
Mac-centered,
 
and
 
he
 
devoted
 
a
 
considerable
 
amount
 
of
 
time
 
to
 
make
 
it
 
work
 
reliably
 
on
 
Macs
 
too.
  In  the  new  UVR  version  there's  a  planned  demudder  to  be  introduced  (described  later),  and  
possibly
 
translations.
 Anjok  currently  trains  a  new  model  coming  in  several  weeks.  It's  intended  to  be  a  little  smaller  in  order  to  be  not  so  resource  intensive,  but  also  better  than  
the
 
best
 
current
 
MDX-Net
 
model.
 Update  01.03.24  “I'm  going  to  allow  HQ4  to  continue  training  beyond  1500+  epochs  as  an  experiment  (it's  
currently
 
at
 
1200),
 
and
 
interestingly,
 
the
 
SDR
 
has
 
been
 
steadily
 
increasing.
 
It
 
has
 
significantly
 
surpassed
 
HQ3
 
in
 
terms
 
of
 
SDR
 
and
 
listening
 
tests,
 
and
 
it
 
also
 
outperformed
 
MDXC23
 
in
 
listening
 
tests,
 
though
 
not
 
in
 
SDR
 
(yet!).
 
The
 
most
 
recent
 
evaluation
 
on
 
the
 
multi-dataset
 
showed
 
a
 
score
 
of
 
15.85,
 
using
 
the
 
default
 
settings.
 
Clearly,
 
there's
 
a
 
limit
 
to
 
how
 
much
 
further
 
training
 
can
 
enhance
 
performance,
 
but
 
up
 
to
 
this
 
point,
 
improvements
 
are
 
still
 
being
 
observed.
 
This
 
model
 
has
 
been
 
in
 
training
 
since
 
October!
 
I'm
 
chipping
 
away
 
at
 
the
 
next
 
GUI
 
update
 
as
 
well,
 
and
 
the
 
demudder
 
will
 
be
 
in
 
it.”
 The  model  was  released,  with  already  HQ_5  scheduled  in  following  month/s.    The  archs  in  UVR  and  their  technicalities  summarized   VR   VR  uses  audio  spectrograms  and  converts  them  to  FFT  spectrograms.  VR  uses  only  magnitude  spectrograms,  not  phase.  Phase  represents  timing  where  the  data  is,  while  magnitude  represents  the  intensity  of  each  
frequency.
 Phase  is  much  harder  to  predict.  Actually  VR  uses  original  phase  from  the  mixture  and  saves  it  during  the  process  "and  it  just  
does
 
the
 
magnitude".
 That's  the  reason  why  VR  tends  to  have  more  artefacts  in  it.  The  smearing  in  instrumentals  
of
 
VR
 
is
 
because
 
the
 
phase
 
from
 
the
 
mixture
 
is
 
still
 
in
 
there.
  Aufr33  later  introduced  4  bands  support  for  UVR.  Let's  say  for  first  of  three  bands  between  0-700Hz  there  will  be  different  resolution,  for  all  
other
 
frequency
 
ranges
 
there
 
will
 
be
 
different.
 
E.g.
 
knowing
 
that
 
vocals
 
are
 
in
 
specific
 
frequency
 
range,
 
you
 
can
 
optimize
 
it
 
further.
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 374/642]
    turns  out  that  if  you  do:  export  TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1  it  uses  waay  less  VRAM  and  processes  even  faster  inst_V1e_plus  batch_size=2  overlap=3  chunk_size=  485100,  51.78s/it   [3:50  of  audio  in  61  
seconds]
  For  ROCm  6.x  (a  tad  slower,  might  work  on  more  GPUs):  torch  2.9.0+rocm6.3  torchvision0.24.0+rocm6.3  [--index-url  
https://download.pytorch.org/whl/rocm6.3]
 Thanks,  fr4z49.   Official  support  for  PyTorch  on  RX  400/500  (a.k.a.  Polaris/GCN  4/GFX803)  GPUs  was  dropped,  but  you  can  follow  this Ubuntu  guide  for  unofficial  ROCm  6  support  (it  might  even  potentially  work  from  Windows  using  WSL  with  almost  no  GPU  performance  overhead).  Or  for  ROCm  5,  read  this Ubuntu  guide.  Also,  there  seems  to  be  some  Arch  Linux  community  package  to  install  Pytorch  still  compatible  for  these  GPUs  (click).   
Or
 
optionally
 
also
 
might
 
be
 
potentially
 
supported
 
with
 
some
 
other
 
specific
 
versions
 
of
 
ROC,
 
e.g.
 
5.7.2
 
and
 
also
 
described
 
above:
 export  ROC_ENABLE_PRE_VEGA=1  (deprecated  in  ROCm  6;  might  help  for  lacking  
dependencies
 
or
 
wheel
 
building
 
issues).
 
Or
 
also
 
check
 
out
 
this:
 https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/10435#issuecomment-1555399844,  or  alternatively  follow  below  instructions:  https://pytorch.org/get-started/locally/ and  then  execute:  pip3  install  torch  torchvision  torchaudio  --index-url  https://download.pytorch.org/whl/rocm5.4.2   4.  If  you  have  SageAttention  error,  you  need  an  arch  corresponding  to  e.g.:  RTX  5000,  4000,  
3000,
 
H100,
 
H200
 
(Ada
 
Lovelace,
 
Hopper,
 
Ampere,
 
Blackwell)
 
which
 
will
 
probably
 
work
 
out
 
of
 
the
 
box.
 
Otherwise,
 
it
 
will
 
probably
 
fall
 
back
 
to
 
CPU.
 
To
 
fix
 
it,
 
make
 
sure
 
you
 
have
 
installed
 
CUDA/Torch/Torchvision/Torchaudio
 
compatible
 
with
 
your
 
GPU
 (probably  it  will  work  down  to  Maxwell  GPUs  (not  sure  about  Kepler):   “For  the  [GTX]  1660  the  minimum  [CUDA]  version  is  10”  E.g.  minimum  compatible  CUDA  
version
 
requirement
 
for
 
GTX
 
1660
 
is
 
10
 
(on
 
GTX
 
1060,
 
Torch
 
2.5.1+cu121
 
can
 
be
 
used),
 
but
 
pip
 
doesn’t
 
find
 
such
 
a
 
package
 
of
 
Torch
 
(and
 
usually
 
it
 
fixes
 
issues
 
when
 
CPU
 
is
 
only
 
used
 
on
 
those
 
GPUs).
  Check  out  index-url  method  described  later  below:  pip  install  torch  torchvision  torchaudio  --index-url  https://download.pytorch.org/whl/cu118  or  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 564/642]
    residues  in  instrumentals  than  MDX-Net  v2,  but  can  give  a  bit  more  clarity),  MDX-Net  v2  
2021
 
(instrumentals
 
can
 
get
 
a
 
bit
 
muddy
 
even
 
in
 
fullband
 
models,
 
still
 
more
 
residues
 
than
 
in
 
Roformers),
 
Demucs
 
HT
 
a.k.a.
 
Demucs
 
4
 
(Anjok
 
failed
 
at
 
training
 
single
 
stem
 
model
 
for
 
it),
 
vocal-remover
 
(VR)
 
by
 
tsurumeso
 
5
 
(good
 
for
 
specific
 
tasks
 
like
 
Karaoke/BVE
 
models
 
or
 
dereverb,
 
and
 
for
 
instrumentals
 
it
 
leaves
 
lots
 
of
 
unpleasant
 
residues),
 
VR
 
6
 
(now
 
takes
 
phase
 
under
 
consideration,
 
so
 
there
 
should
 
be
 
less
 
residues,
 
but
 
it’s
 
outperformed
 
by
 
newer
 
archs),
 
VitLarge
 
(probably
 
the
 
fastest),
 
SCNet
 
(still
 
faster
 
than
 
Roformers).
  I  think  on  example  of  HQ_3  and  16.xx  models,  it’s  safe  to  say  that  MDX-Net  v2  fullband  
models
 
have
 
less
 
vocal
 
residues
 
in
 
instrumentals
 
than
 
newer
 
MDX23C
 
arch,
 
but
 
it
 
is
 
also
 
much
 
more
 
muffled,
 
and
 
it
 
depends
 
on
 
specific
 
song
 
what
 
arch
 
will
 
fit
 
the
 
best.
  About  BS-Roformer,  e.g.  the  model  trained  by  Bytedance  didn’t  include  other  stem  and  is  
obtained
 
by
 
inversion,
 
and
 
initially
 
the
 
results
 
had
 
lots
 
of
 
vocal
 
residues
 
in
 
instrumentals
 
or
 
instruments
 
in
 
other
 
stem,
 
but
 
it
 
can
 
be
 
alleviated
 
by
 
decreasing
 
volume
 
of
 
input
 
file
 
for
 
separation
 
by
 
3dB
 
(the
 
best
 
SDR
 
among
 
lots
 
of
 
tested
 
values).
 
Generally,
 
viperx
 
models
 
sounds
 
similar
 
to
 
Ripple.
 
The
 
arch
 
itself
 
has
 
potential
 
for
 
the
 
best
 
SDR
 
currently
 
(although
 
currently
 
there’s
 
a
 
small
 
difference
 
between
 
the
 
two
 
best
 
Mel
 
and
 
Rofo
 
models
 
SDR-wise
 
-
 
2024.08.07
 
and
 
2024.10
 
on
 
MVSep.com,
 
while
 
BS
 
models
 
are
 
more
 
muddy).
  There  are  other  good  archs  like  BSRNN  which  is  already  better  than  Demucs,  and  later  
released
 
SCNet
 
(but
 
the
 
results
 
weren’t
 
as
 
good
 
as
 
Roformers,
 
they
 
had
 
more
 
noise,
 
and
 
training
 
wasn’t
 
that
 
straightforward
 
as
 
initially
 
thought).
 
It's
 
faster,
 
than
 
BS-Roformer,
 
but
 
probably
 
due
 
to
 
arch
 
differences,
 
rather
 
not
 
better,
 
although
 
it
 
might
 
be
 
still
 
decent
 
in
 
some
 
cases
 
(you
 
can
 
hear
 
the
 
results
 
on
 
MVSEP).
  Viperx  trained  on  far  more  demanding  arch  (BS-Roformer)  with  8xA100-80GB  (half  of  what  
ByteDance
 
used),
 
on
 
4500
 
songs,
 
and
 
only
 
on
 
epoch
 
74
 
they
 
already
 
surpassed
 
all
 
previous
 
UVR
 
and
 
ZFTurbo’s/MVSEP
 
models,
 
including
 
ensembles/weighted
 
results
 
(more
 
info
 
on
 
that
 
later
 
below).
  Viperx  made  a  private  model  with  Mel-Roformer  which  reached  an  epoch  of  around  even  
3100.
 
He
 
uploaded
 
the
 
SDR
 
results
 
to
 
MVSEP,
 
but
 
it
 
has
 
been
 
taken
 
down
 
since
 
[presumably
 
by
 
viperx
 
himself].
 
And
 
even
 
then,
 
the
 
result
 
was
 
not
 
above
 
9.7
 
unfortunately,
 
achieving
 
results
 
not
 
much
 
better
 
than
 
MDX23C
 
SDR-wise,
 
but
 
with
 
probably
 
bigger
 
dataset.
 
  Later  Kim  fixed  the  issues  with  low  SDR  in  Mel  with  her  config  and  released  the  model  which  
become
 
the
 
base
 
of
 
all
 
the
 
fine-tunes
 
by
 
Unwa/Gabox/Syh-Aname-Super-YH
 
(more
 
below).
  -  “as  training  progresses,  the  metrics  will  improve  slower  and  slower  until  a  point  where  it's  
too
 
slow
 
=
 
stop
 
training”
 
-
 
becruily
 -  I  always  stop  when  [loss,  avg_loss=]  nan   
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
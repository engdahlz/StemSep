[page 271/642]
    If  you're  not  afraid  of  learning  a  new  DAW,  Sound  Forge  Cleaning  Lab  4 has  great  and  easy  built-in  restoration  plugins  too  (Brilliance,  Sound  Clone>Brighten  Internet  Sources)  with  
complete
 
mastering
 
chain
 
to
 
push
 
even
 
further
 
what
 
you
 
already
 
got
 
with
 
Unchirp
 
and
 
Stereo
 
Tool.
 
 Izotope  RX  Editor  and  its  Spectral  Recovery  may  turn  out  to  be  just  not  enough,  but  the  rest  
of
 
RX
 
plugins
 
also
 
available
 
as
 
VST
 
can
 
become
 
handy,
 
although
 
Cleaning
 
Lab
 
has
 
lots
 
of
 
substitutes
 
for
 
filtering
 
various
 
kinds
 
of
 
noise.
 
Working
 
comfortably
 
in
 
real-time
 
with
 
all
 
the
 
plugins
 
opened
 
simultaneously
 
while
 
combined
 
is
 
more
 
comfortable
 
than
 
RX
 
Editor
 
workflow.
 
But
 
you
 
can
 
use
 
some
 
plugins
 
from
 
RX
 
Editor
 
as
 
separate
 
VSTs
 
in
 
other
 
DAWs
 
including
 
Lab
 
4.
 
Ozone
 
Advanced
 
might
 
turn
 
out
 
useful
 
too.
 Actually,  once  you  finish  using  the  plugins  above,  now  you  can  try  out  some  of  the  mastering  
services
 
and
 
not
 
in
 
the
 
opposite
 
way
 
(although
 
you
 
might
 
want
 
to
 
meet
 
some
 
basic
 
requirements
 
of
 
AI
 
mastering
 
services
 
to
 
get
 
the
 
best
 
results
 
first,
 
e.g.
 
in
 
terms
 
of
 
volume).
  Q:   AI  vocal  remover  did  not  "normalize"  (I  don't  think  it's  the  right  word)  the  track  on  the  
moment
 
where
 
the
 
vocal
 
was
 
removed,
 
so
 
it's
 
noticeable,
 
especially
 
on
 
instrument-heavy
 
moments.
 
  I  make  things  better  by  created  backup  echo  track  by  combining  stereo  tracks  with  inverted  
ones
 
and
 
adding
 
this
 
to
 
the
 
main
 
track
 
with
 
-5db,
 
but
 
it's
 
still
 
not
 
good
 
enough.
 
Are
 
there
 
any
 
technics
 
that
 
separate
 
track
 
with
 
not
 
noticeable
 
effects
 
or
 
maybe
 
there
 
is
 
some
 
good
 
restoration
 
algorithm
 
that
 
I
 
can
 
use
  A:  If  vocals  are  cancelled  by  AI,  such  a  moment  stands  out  from  the  instrumental  parts  of  the  
song.
  Sometimes  you  can  rearrange  your  track  in  a  way  that  it  will  use  instrumental  parts  of  the  
song
 
when
 
there
 
are
 
no
 
vocals,
 
instead
 
of
 
leaving
 
AI
 
separated
 
fragments.
 
Sometimes
 
it's
 
not
 
possible,
 
because
 
it
 
will
 
lack
 
some
 
fragments
 
(then
 
you
 
can
 
use
 
only
 
filtered
 
moments
 
at
 
times),
 
and
 
even
 
then,
 
you
 
will
 
need
 
to
 
take
 
care
 
about
 
coherence
 
of
 
the
 
final
 
result
 
in
 
the
 
matter
 
of
 
sound
 
as
 
you
 
said.
  At  times,  even  fade  outs  at  the  ends  of  tracks  can  have  decent  amounts  of  instrumentals  
which
 
you
 
can
 
normalize
 
and
 
then
 
use
 
in
 
rearrangement
 
of
 
the
 
track.
 
E.g.
 
you
 
normalize
 
every
 
snare
 
or
 
kick
 
and
 
everything
 
later
 
in
 
fade
 
out,
 
and
 
then
 
till
 
the
 
end,
 
so
 
it
 
will
 
sound
 
completely
 
clean.
 
  Generally  it's  all  time-consuming,  not  always  possible,  and  then  you  really  have  to  be  
creative
 
using
 
normal
 
mastering
 
chain
 
to
 
fit
 
filtered
 
fragments
 
to
 
regular
 
unfiltered
 
fragments
 
of
 
the
 
track.
 
 You  can  also  try  out  layering,  e.g.  specific  snare  found  in  a  good  quality  in  the  track.  May  
work
 
easier
 
for
 
tracks
 
made
 
with
 
quantization,
 
so
 
when
 
the
 
pattern
 
of
 
drums
 
is
 
consistent
 
throughout
 
the
 
track.
 
Also,
 
you
 
can
 
use
 
4
 
stem
 
Demucs
 
ft
 
or
 
MDX23
 
and
 
overlap
 
drums
 
from
 
a
 
fragment
 
where
 
you
 
donâ€™t
 
hear
 
vocals
 
yet,
 
so
 
drums
 
are
 
still
 
crispy
 
there.
 
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
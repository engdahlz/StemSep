[page 15/642]
    “Pretty  impressive.  Besides  it  being  more  full  than  other  piano  models  (in  most  cases),  it's  
also
 
by
 
far
 
the
 
only
 
piano
 
model
 
that
 
doesn’t
 
mistakenly
 
pick
 
up
 
other
 
instruments
 
like
 
tubular
 
bells
 
as
 
piano.”
 “From  what  i  tested  is  more  for  midi  piano,  i  tested  with  some  tracks  with  that  kind  of  midi  
sound
 
and
 
it
 
worked
 
way
 
better
 
that
 
SW.”
  -  (training)  Becruily  made  a  modification  of  dTTnet  arch  working  in  MSST  (DL).  “They  report  very  good  performance  on  vocals  with  low  parameters”  -  Kim  Back  in  the  end  of  2023,  one  indie  pop  song  from  multisong  dataset  (of  the  two  there)  
received
 
the
 
best
 
SDR
 
-
 
Bas
 
Curtiz
 “Better  than  SCNet  imo,  remains  to  see  if  it  can  beat  rofos”  -  Becruily  “Not  fast  to  train.  I'm  back  with  vanilla  mdx23c.  Trying  a  config  to  train  model  with  less  than  
4GB
  
VRAM,
 
(...)
 
with
 
my
 
1080Ti
 
and
 
batch_size=1,
 
chunk_size
 
is
 
around
 
1.5sec)”
 
-
 
jarreou
 Installation  instruction:  “In  the  latest  MSST  [at  least  for  13.10.25]  add  the  ddtnet  folder  to  "models"  and  replace  your  settings  file  in  utils  with  this”  The  mod  breaks  compatibility  with  the  authors'  checkpoint.   “The  weird  thing  is,  it  sounds  like  a  fullness  model  despite  not  being  one,  I  barely  can  find  dips  in  instrumentals.  ddtnet  vs  kim  melband,  if  anyone  is  curious”  -  bcr  “Also  keep  in  mind  authors  trained  with  l1  loss  only,  default  in  MSST  is  masked  loss”  “l1  loss  when  dataset  is  noisy,  mse  loss  when  dataset  is  clean”  “the  loss  is  defined  from  msst,  but  in  the  original  dttnet  it  was  in  the  code  itself  you  can  just  --loss  l1_loss”  @jarredou  “I  copied  your  tfc  and  tfc_tdf  classes  to  my  files  (and  used  that  latest  stft/istft  I  
sent)
 
-
 
and
 
seems
 
to
 
be
 
better,
 
just
 
like
 
the
 
og
 
dttnet
 
 the  tfc/tdf  fixed  the  nan  issue  for  me  (...)  Keep  in  mind,  ddtnet  was  trained  only  with  musdb  and  has  10-20x  less  params  while  being  
comparable
 
in
 
quality”
 “the  authors  checkpoints  had  16khz  cutoff  because  dim_f  was  smaller  than  nfft/2  if  you  want  to  train  model  with  cutoff  it's  fine,  if  you  want  fullband  then  dim_f  must  be  half  of  
nfft
 
+
 
1”
 
-
 
becruily
 Hit  our  #dev-talk for  more.   -  New  sites  added  to  Site  and  rippers (deezmate.com and  tidal.qqdl.site).  Qubuz  remains  or  defunct/problematic  for  now.   -  We  have  numerous  reports  about  some  models  like  Unwa  Resurrection  inst  having  
problems
 
on
 
AMD
 
(and
 
probably
 
Intel
 
GPUs)
 
in
 
UVR,
 
returning
 
“Invalid
 
parameter”
 
error.
 
In
 
that
 
case,
 
uncheck
 
GPU
 
Conversion
 
(but
 
it
 
will
 
be
 
slower).
 
If
 
you
 
find
 
a
 
fix,
 
please
 
let
 
us
 
know
 
on
 
the
 
Discord
 
(link
 
at
 
the
 
top
 
of
 
the
 
doc).
  -  if  you  deal  with  slow  separation  times  on  becruily  &  Frazer  karaoke  model,  decrease  
chunk_size
 
to
 
160000
 
on
 
8GB
 
GPUs.
 
As
 
long
 
as
 
decreasing
 
chunk_size
 
on
 
CUDA
 
(NVIDIA)
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
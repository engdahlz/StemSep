[page 576/642]
    you  can  ask  her  (@)KimberleyJSN.    MDX-Net  2023  (v3)  a.k.a.  MDX23C  (not  always  better  than  v2)  https://github.com/ZFTurbo/Music-Source-Separation-Training  OG  repo:  https://github.com/kuielab/sdx23  Lots  of  general  optimizations  to  the  quality  while  keeping  decent  training  and  separation  
performance.
 
Theoretically
 
the
 
go-to
 
architecture
 
over
 
MDX-Net
 
v2,
 
although
 
currently
 
SAMI
 
Bytedance
 
reimplementation
 
(under
 
VR
 
section
 
below)
 
has
 
much
 
less
 
bleedy
 
results
 
for
 
much
 
more
 
compute
 
intensiveness.
 
It
 
was
 
used
 
for
 
trained
 
models
 
by
 
ZFTurbo.
 
On
 
the
 
same
 
if
 
not
 
better
 
dataset
 
than
 
previous
 
V1
 
models,
 
it
 
received
 
not
 
much
 
worse
 
SDR
 
than
 
V1
 
arch
 
for
 
narrowband,
 
but
 
with
 
much
 
fuller
 
vocals,
 
although
 
with
 
more
 
bleeding
 
(also
 
in
 
instrumentals).
 
For
 
fullband,
 
SDR
 
was
 
high
 
enough
 
to
 
surpass
 
previous
 
models,
 
but
 
SDR
 
stopped
 
reflecting
 
bleeding
 
on
 
multisong
 
dataset.
  "It  doesn't  need  pairs  anymore.  This...  is  HUGE.  It  randomizes  chunks  of  6  seconds  from  random  instrumental  and  random  vocal  to  learn  
from.
 In  other  words,  no  more  need  to  find  the  instrumental+vocal  for  track  x.  Just  plump  in  any  proper  acapella  or  instrumental  u  can  find.  The  downside  so  far  is  the  validation.  It  takes  way  longer."  so  you  might  be  able  to  perform  evaluation  per  only,  e.g.  50  epochs.   Dataset  structure  looks  like   -  train  folder  >  folders  with  pairs  >  other.wav  +  vocals.wav  -  validation  folder  >  folders  with  pairs  >  other.wav  +  vocals.wav  +  mixture.wav"   Libsnd  can  read  FLACs  when  renamed  to  WAV.  It  can  save  a  lot  of  space.    I  think  in  the  old  MDX-Net,  we  didn't  have  a  model  with  not  worse  SDR  than  epoch  greater  
than
 
464,
 
although
 
496
 
with
 
lower
 
SDR
 
also
 
had
 
its
 
own
 
unique
 
qualities
 
(though
 
more
 
vocal
 
residues
 
at
 
times).
 
Also,
 
frequently
 
training
 
is
 
ended
 
on
 
epoch
 
300,
 
and
 
might
 
not
 
progress
 
SDR-wise
 
for
 
a
 
long
 
time
 
(maybe
 
till
 
400+).
 https://cdn.discordapp.com/attachments/911050124661227542/1136258986677645362/image.png (dead)   (written  before  Roformers)  We  may  already  be  hitting  the  wall  SDR-wise,  as  Bas  once  
conducted
 
an
 
experiment
 
with
 
training
 
a
 
model
 
consisting
 
dataset
 
made
 
of
 
the
 
dataset
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 110/642]
    dim_t  =  201  is  chunk_size  =  88200  (2s)  -  required  value  for  some  more  
resource-hungry/bigger
 
Roformers
 
on
 
AMD
 
4GB
 
VRAM
 
(some
 
models
 
only
 
worked
 
with
 
that
 
dim_t
 
with
 
earlier
 
beta
 
patches
 
and
 
here’s
 
it’s
 
probably
 
the
 
same
 
or
 
with
 
256
 
equivalent),
 
but
 
is
 
still
 
not
 
low
 
enough
 
for
 
most
 
Roformers
 
when
 
demudder
 
is
 
used,
 
and
 
give
 
“Could
 
not
 
allocate
 
tensor”
 
while
 
single
 
model
 
separation
 
previously
 
worked
 
with
 
even
 
bigger
 
chunk
 
setting.
 
You
 
shouldn’t
 
go
 
lower
 
with
 
that
 
parameter,
 
as
 
even
 
a
 
2
 
seconds
 
chunk
 
might
 
sometimes
 
give
 
audio
 
skips
 
every
 
two
 
seconds,
 
at
 
least
 
on
 
UVR
 
Roformer
 
patch
 
#2.
 
2
 
or
 
2,5
 
seconds
 
will
 
be
 
rather
 
bare
 
minimum.”
 
-
 
jarredou
 
(DTN
 
edit)
  All  inst/voc  Roformers  seem  to  use  hop_length:  441  (but  ensure  in  yaml),  so  you  always  
multiply
 
that
 
hop
 
value
 
by
 
the
 
desired
 
dim_t
 
-
 
1
 
to
 
get
 
correct
 
chunk_size
 
(e.g.
 
corresponding
 
with
 
old
 
dim_t
 
values
 
you
 
were
 
using
 
in
 
older
 
beta
 
patches)
  -  We  have  some  reports  about  user  custom  ensemble  presets  from  older  versions  no  longer  
working
 
(since
 
11/17/24
 
patch).
 
 -  Sadly,  you  need  to  get  rid  of  them  (don’t  restore  their  files  manually)  or  the  ensemble  will  
not
 
work
 
and
 
model
 
choice
 
will
 
be
 
greyed
 
out.
 
You
 
need
 
to
 
start
 
from
 
scratch
   Errors  troubleshooting  
 “got  an  unexpected  keyword  argument  'linear_transformer_depth’  ” 
In
 
case
 
of
 
the
 
error
 
with
 
any
 
external
 
Roformer
 
model:
 
  -  delete  “linear_transformer_depth:  0”  line  from  the  YAML  file   -  To  fix  issues  with  BS  variant  of  e.g.  anvuew’s  de-reverb  model  in  UVR,  additionally  to  the  
above,
 
also
 
change
 
the
 
following
 
in
 
the
 
yaml
 
file:
 “stft_hop_length:  512  to  stft_hop_length:  441  so  it  matches  the  hop_length  above”  (thx  lew).   If  that  line  is  not  present  in  your  model’s  yaml  config  file,  go  to  the  settings,  then  choose  
MDX
 
In
 
the
 
Advanced
 
menu,
 
and
 
click
 
the
 
"Clear
 
auto-set
 
cache"
 
button.
 Then  go  back  to  the  main  settings,  click  "Reset  all  settings  to  default"  and  restart  the  app  
(thx
 
santilli_).
  These  issues  don’t  happen  in  the  ZFTurbo’s  CML  inference  code  of:  https://github.com/ZFTurbo/Music-Source-Separation-Training/ 
'use_amp'  “Key  error”  using  the  GH  repo  above,  and  referencing  (separating)  some  models:    
-
 
“add:
 use_amp:  true   in  the  training  part  of  [models’  yaml]  config  file  (it's  missing)”  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
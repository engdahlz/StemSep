[page 241/642]
    Multisong  dataset  SDR  9.93:  bass:  11.94,  drums:  11.58,  other:  6.49,  vocals:  9.69   -  SCNet  XL model  (4  stems)  by  ZFTurbo  (Colab |  MSST-GUI |  MSST |  UVR  beta  patch)  Multisong  dataset  SDR  9.72:  bass:  11.87,  drums:  11.49,  other:  6.19,  vocals:  9.32  Better  metrics  than  the  starrytong  model  but  “downgrade  to  the  Large  model  since  it  
produces
 
a
 
f***
 
ton
 
of
 
buzzing”
 
due
 
to
 
undertraining.
 Only  bass  is  better  in  Demucs_ft  -  12.24,  although  drums  might  be  still  better  in  demucs_ft.  2  stem  model  on  MVSEP  is  further  trained  iirc.   -  BS-Roformer model  (4  stems)  by  ZFTurbo  |  MSST-GUI Multisong  dataset  SDR  9.38:  bass:  11.08,  drums:  11.29,  other:  5.96,  vocals:  9.19  
Trained
 
on
 
MUSDB18HQ
  -  Mel-Roformer  models (4  stems)  by  Aname  a)  Large  (4GB):  multisong  dataset  SDR  drums:  9.72,  bass:  9.40,  other:  5.11  b)  XL  (7GB):  Despite  lower  AVG  SDR  on  musdb18  dataset  (8.54  vs  9),  it  seems  to  outperform  demucs_ft  
model
 
(only
 
other
 
stem
 
has
 
better
 
SDR
 
in
 
demucs_ft
 
-
 
all
 
other
 
metrics
 
are
 
better
 
in
 
SCNet/XL/BS-Roformer).
  
 XL  is  “heavy  and  slow,  without  giving  a  quality  boost  compared  to  existing  public  4  stems  
models
 
trained
 
on
 
musdb18
 
by
 
ZFTurbo
 
and
 
starrytong
 
(BsRofo
 
and
 
SCNet
 
large/XL
 
[above])”
 
-
 
jarredou
 
(maybe
 
minus
 
buzzing
 
in
 
the
 
public
 
XL
 
model).
 “Drums  are  sounding  really  good  in  particular,  tested  a  couple  songs  with  the  large  model  
after
 
using
 
unwa's
 
v1e+
 
for
 
instrumental”
 
“drums
 
are
 
absolutely
 
the
 
standout”.
 “The  bass  stem  is  definitely  the  weakest  one  from  this  new  model.  Very,  very  muddy  and  
inconsistent.”
 
-
 
santilli_
  “Large  [variant]  works  in  like  99%  use  case”  “Large  split  sounds  amazing  so  far  tho”  XL  “result  would  take  so  much  longer,  but  the  large  results  sounded  better  IMO”  -  5B  XL  model  won’t  work  with  default  settings  on  Colab,  and  very  slow  on  e.g.  RTX  3060,  “on  
4070
 
Super
 
it
 
took
 
like
 
6
 
mins
 
on
 
XL
 
4
 
stems
 
compared
 
to
 
30
 
seconds
 
on
 
Large
 
4
 
stems”
 
  -  SCNet  Tran a.k.a.  small  model  (4  stems)  by  ZFTurbo  Multisong  dataset  SDR  bass:  10.99,  drums:  10.87,  other:  5.63,  vocals:  8.42   Outperformed  by  the  above  models  at  least  SDR-wise.  Cannot  be  used  in  UVR.  -  KUIELab-MDXNET23C (4  stems)  -  its  first  scores  were  probably  from  ensemble  of  its  five  models,  and  in  that  configuration  it  had  better  SDR  than  demucs_ft  on  its  own,  and  drums  
had
 
better
 
SDR
 
than
 
“SCNet-large_starrytong”
 
above
 
(so
 
single
 
models’
 
score
 
of
 
any
 
of
 
these
 
MDX23C
 
models
 
is
 
probably
 
lower
 
than
 
in
 
demucs_ft).
 
 
-
 
Lighter
 
“model1”
 
drums
 
sounds
 
surprisingly
 
better
 
than
 
htdemucs
 
non_ft
 
v4
 
on
 
previously
 
separated
 
instrumental.
 
It
 
handles
 
trap
 
really
 
well
 
and
 
preserves
 
hi-hats
 
correctly,
 
but
 
in
 
cost
 
of
 
other
 
stem
 
bleeding.
 
v4
 
model
 
can
 
be
 
used
 
to
 
clean
 
it
 
a
 
bit
 
further,
 
but
 
at
 
least
 
using
 
GPU
 
Conversion
 
on
 
AMD
 
and
 
older
 
directml.dll
 
for
 
some
 
GPUs,
 
it
 
adds
 
more
 
noise/artefacts,
 
so
 
use
 
CPU
 
in
 
that
 
case
 
(tested
 
on
 
Roformer
 
as
 
preprocessor
 
for
 
instrumental).
 
It’s
 
relatively
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 384/642]
    The  app  at  least  vertically  doesn’t  show  master  fader,  so  you  cannot  control  the  output  
volume
 
meter.
 
Probably
 
the
 
same
 
in
 
horizontal
 
view.
 
Plus,
 
the
 
app
 
doesn't
 
give
 
the
 
possibility
 
to
 
adjust
 
the
 
gain
 
precisely,
 
e.g.
 
to
 
9dB
 
instead
 
of
 
-9,5dB,
 
so
 
to
 
use
 
single
 
files
 
with
 
found
 gain  values  in  Wavacity,  to  mix  them  without  crashes,  you  can  use  the  manual  ensemble  Colab.   If  you  want  to  just  listen  to  stems  offline,  change  their  volume,  panning,  solo,  mute,  you  can  download  this html  (by  cypha_sarin)  and  run  it  locally  in  your  browser.  
Manual  ensemble  in  UVR5  GUI  from  single  models  (e.g.  from  inference  Colabs  or  
online
 
sites)
  "You  can  use  Colabs  to  make  individual  model  separations  and  then  use  the  manual  
ensemble
 
tool
 
from
 
UVR5
 
GUI
 
to
 
merge
 
them
 
together
 
(you
 
don't
 
need
 
special
 
CPU/GPU
 
to
 
use
 
that
 
tool
 
and
 
it's
 
fast!
 
15-year-old
 
computers
 
can
 
handle
 
it).
  In  UVR  GUI  >  process  method  =  Audio  Tools,  then  choose  "Manual  Ensemble"  and  the  
desired
 
ensembling
 
method."
  Combine  input  is  even  more  aggressive  than  Max  Spec.  E.g.  it  takes  two  -15  ilufs  songs,  and  makes  pretty  loud  -10  ilufs  result.  To  potentially  deal  with  harshness  of  such  output,  you  can  set  quality  in  options  to  64  bit  
(sic!),
 
or
 
possibly
 
manually
 
decrease
 
volume
 
of
 
ensembled
 
files
 
before
 
passing
 
through
 
UVR
 
Combine
 
Inputs.
 Combine  input  was  good  for  ensembling  KaraFan  results  of  preset  with  the  least  amounts  of  
residues,
 
and
 
preset
 
5
 
for
 
more
 
clarity,
 
but
 
a
 
bit
 
more
 
residues.
 
The
 
instrumental
 
result
 
was
 
fuller
 
sound,
 
better
 
snares
 
and
 
clarity.
 The  downside  is,  you  cannot  control  gain  of  ensembled  stems  precisely  like  in  DAW,  or  using  
Colab.
  
Model  fusion   You  can  perform  fusion  of  models  using  ZFTurbo  script
(src)
 or  Sucial  script (they’re  similar  if  not  the  same).  “I  think  the  models  need  to  have  at  least  the  same  dim  and  depth,  but  I'm  not  
sure
 
about
 
that”
 
-
 
mesk.
 They  allow  creating  one  model  out  of  weighted  models  with  specified  parameters,  so  only  
one
 
model
 
is
 
needed
 
to
 
inference
 
instead
 
of
 
two
 
or
 
more.
   How  to  separate  in  UVR  using  multiple  models  in  batch  to  compare  the  results  for  the  best  
manual
 
ensemble?
  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
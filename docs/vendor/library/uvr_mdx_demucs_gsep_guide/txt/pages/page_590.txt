[page 590/642]
     Unwa  “reduced  mask  estimator  depth  from  3  to  2,  and  he  said  that  it  didn't  hurt  the  quality  
but
 
reduced
 
the
 
size
 
significantly.
 
also
 
there's
 
some
 
additional
 
line
 
'mlp_expansion_factor:
 
1'
 
in
 
his
 
small
 
model
 
config.
 
Maybe
 
that
 
helped
 
somehow
 
too.”
 
“The
 
mask
 
estimator
 
is
 
already
 
2
 
by
 
default
 
on
 
Kim
 
model
 
for
 
example
 
(and
 
in
 
bort's
 
config
 
too)”
 
“I
 
have
 
unwa's
 
beta
 
and
 
duality
 
models
 
and
 
on
 
batch
 
size
 
1
 
they
 
don't
 
eat
 
that
 
much
 
memory”
 
“inference
 
maxes
 
out
 
the
 
GPU
 
mem
 
and
 
sits
 
at
 
0%
 ckpt  file  is  3GB.  Moral  of  this  story  is  try  running  inference  before  you  get  to  epoch  80”  
 
Q:
 
Does
 
anyone
 
here
 
know
 
how
 
much
 
VRAM
 
is
 
required
 
to
 
train
 
a
 
Roformer
 
model
 
with
 
the
 
same
 
specs
 
as
 
Unwa's
 
and
 
Kim's
 
models?
 A:  ZFTurbo  has  made  this  small  benchmark  some  months  ago  with  BS-Roformer:  https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/bs_roformer_info.md  and  newer one  for  Mel-Roformer   ZFTurbo  experimented  with  4  stems  Mel  model  creation  on  MUSDB18,  and  struggled  with  getting  good  results  like  in  the  paper.  Here he  evaluated  various  parameters  and  achieved  SDR.  Eventually,  he  released  checkpoint  with  different  parameters  here.  Later,  he  trained  BS-Roformer  4  stem  model  on  MUSDB18.   Q:  Is  it  not  possible  to  emphasize  both  SDR  and  Aura  scores?  A:  “Training  the  model  using  [l1_freq  and  AuraMRSTFT]  metrics  is  prone  to  phase  problems.  
Like
 
my
 
5e
 
and
 
v1e
 
models”
 
Unwa
  -  “You  can  enable  spectral  phase  with  auraloss  (never  really  tried)”  J.  A:  It  makes  it  less  stable  in  training;  Loss  is  more  likely  to  be  NaN  It  is  difficult  to  optimize  a  phase  spectrogram  that  looks  like  noise.   A:  “You  don't  emphasize  a  model  with  them,  they're  just  metrics,  and  you're  tracking  how  
well
 
each
 
epoch
 
scores
 the  metrics  will  go  up  and  down,  but  it  doesn't  specifically  emphasize  the  chosen  metric  B.”   “Phase  also  has  a  significant  impact  on  sound  quality  and  cannot  be  ignored.  However,  
these
 
metrics
 
ignore
 
phase;
 
models
 
that
 
emphasize
 
fullness
 
are
 
those
 
that
 
compromise
 
phase
 
optimization
 
to
 
some
 
degree
 
in
 
favor
 
of
 
optimizing
 
the
 
amplitude
 
spectrogram,
 
and
 
clearly
 
these
 
metrics
 
favor
 
such
 
models.
  I  would  endorse  the  log_wmse  metric.  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
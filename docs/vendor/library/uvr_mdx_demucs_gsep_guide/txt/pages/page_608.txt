[page 608/642]
    https://github.com/junyuchen-cjy/DTTNet-Pytorch “They  report  very  good  performance  on  vocals  with  low  parameters”  -  Kim  Back  in  the  end  of  2023,  one  indie  pop  song  from  multisong  dataset  (of  the  two  there)  
received
 
the
 
best
 
SDR
 
-
 
Bas
 
Curtiz
 “better  than  scnet  imo,  remains  to  see  if  it  can  beat  rofos”  “not  fast  to  train.  I'm  back  with  vanilla  mdx23c  Trying  a  config  to  train  model  with  less  than  4GB   VRAM,  almost  at  7  SDR  for  vocals  in  8  
hours
 
of
 
training
 
(on
 
moisesdb+musdb18,
 
and
 
using
 
musdb18
 
eval,
 
with
 
my
 
1080Ti
 
and
 
batch_size=1,
 
chunk_size
 
is
 
around
 
1.5sec)
 
”
  Modification  of  the  training  code  for  MSST  by  becruily  (DL;  old).  Breaks  compatibility  with  the  authors'  checkpoint.   “Also  keep  in  mind  authors  trained  with  l1  loss  only,  default  in  msst  is  masked  loss”  “from  what  I  read,  l1  loss  when  dataset  is  noisy,  mse  loss  when  dataset  is  clean”  “the  loss  is  defined  from  msst,  but  in  the  original  dttnet  it  was  in  the  code  itself  you  can  just  --loss  l1_loss”  @jarredou  “I  copied  your  tfc  and  tfc_tdf  classes  to  my  files  (and  used  that  latest  stft/istft  I  
sent)
 
-
 
and
 
seems
 
to
 
be
 
better,
 
just
 
like
 
the
 
og
 
dttnet
 
 the  tfc/tdf  fixed  the  nan  issue  for  me”  -  becruily   Installation  instruction:  “In  the  latest  MSST  [at  least  for  13.10.25]  add  the  ddtnet  folder  to  "models"  and  replace  your  settings  file  in  utils  with  this”   “The  weird  thing  is,  it  sounds  like  a  fullness  model  despite  not  being  one,  I  barely  can  find  
dips
 
in
 
instrumentals
 ddtnet  vs  kim  melband,  if  anyone  is  curious  https://drive.google.com/drive/folders/12an8wnKC-FKE48gVu9pHvUaLSxzpC6C8?usp=sharing Keep  in  mind  ddtnet  was  trained  only  with  musdb  and  has  10-20x  less  params  while  being  
comparable
 
in
 
quality”
 “the  authors  checkpoints  had  16khz  cutoff  because  dim_f  was  smaller  than  nfft/2  if  you  want  to  train  model  with  cutoff  it's  fine,  if  you  want  fullband  then  dim_f  must  be  half  of  
nfft
 
+
 
1”
  “I’ve  found  the  issue  in  my  DTTNet  version  leading  to  the  "noisy"  outputs.  It  was  just  the  *  changed  to  a  +   in  forward  here”  -  jarredou  Everything  uploaded  at  the  top.    Mesk’s  config  for  training  instrumental  model  (achieved  from  SDR  6  to  9.3  in  a  third  epoch  
[counting
 
the
 
first
 
as
 
0]:
 
 python  train.py  --model_type  dttnet  --config_path  config-ddtnet-other.yaml  
--start_check_point
 
results/vocalsg32_ep4082.ckpt
 
--results_path
 
results/
 
--data_path
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
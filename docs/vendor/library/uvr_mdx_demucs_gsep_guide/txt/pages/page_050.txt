[page 50/642]
     -  Apart  from  new  drumsep  models  on  MVSEP,  also  moises.ai  has  their  own  drumsep  model  
(paid).
 
Probably
 
their
 
base
 
drums
 
model
 
used
 
for
 
drumsep
 
is
 
not
 
better
 
than
 
other
 
solutions,
 
so
 check  this section  of  the  doc  to  get  better  drums  to  separate  first  to  test  it  out,  although  one  user  reported  that  moises’  drums  model  (free),  probably  vs  Mel-Roformer  on  MVSEP  or  
x-minus
 
(not
 
sure)
 
can
 
give
 
“better
 
results
 
(...)
 
if
 
the
 
input
 
material
 
is
 
for
 
example
 
cassette-tape
 
sourced
 
or
 
post-FM).
  -  Joseph  made  the  SESA  Colab  private  till  some  stuff  will  be  fixed  in  the  future.  Consider  using  this Colab  with  newer  models  added  at  this  time.   -  (x-minus)  Inst  V7  model  by  Gabox  replaced  v1e  model  by  Unwa.  It  can  be  still  accessed  by  these  links:  https://uvronline.app/ai?hp&test (premium)  https://uvronline.app/ai?test (free)   (v1e  might  be  still  fuller,  and  impair  fewer  instruments  in  cost  of  more  noise,  also  be  aware  
that
 
separation
 
on
 
x-minus
 
might
 
differ
 
from
 
Colabs,
 
MSST
 
or
 
UVR,
 
possibly
 
due
 
to
 
different
 
inference
 
parameters)
  -  Training  (and  inferencing)  locally  on  Radeon  using  MSST,  specifically  RX  7900  XTX,  was  confirmed  to  work  by  Unwa  on  Ubuntu  24.04  LTS  using  Pytorch  2.6  for  ROCm  6.3.3.  Currently,  officially  supported consumer  GPUs  with  ROCm  are:   RX  7900  XTX,  RX  7900  XT,  RX  7900  GRE  and  AMD  Radeon  VII.  But  in  fact,  there  are  more  
consumer
 
Radeons
 
confirmed
 
to
 
work
 
already
 
too.
 “No  special  editing  of  the  code  was  necessary.  All  we  had  to  do  was  install  a  
ROCm-compatible
 
version
 
of
 
the
 
OS,
 
install
 
the
 
AMD
 
driver,
 
create
 
a
 
venv,
 
and
 
install
 ROCm-compatible  PyTorch,  Torchaudio,  and  other  dependencies  on  it.”  More  “So  far  I  have  not  had  any  problems.  Running  the  same  thing  appears  to  use  a  little  more  
VRAM
 
than
 
when
 
running
 
on
 
the
 
NVIDIA
 
GPU,
 
but
 
this
 
is
 
not
 
a
 
problem
 
since
 
my
 
budget
 
is
 
not
 
that
 
large
 
and
 
if
 
I
 
choose
 
NVIDIA
 
I
 
end
 
up
 
with
 
16GB
 
of
 
VRAM
 
(4070
 
Ti
 
S/4080
 
S).
 Processing  speeds  are  also  noticeably  faster,  but  I  did  not  record  the  results  on  the  previous  GPU,  so  I  can't  compare  them  exactly.“  More  -  Inst_GaboxFVX model  was  released  (which  is  “instv7+3”  -  so  probably  fuller  than  instv3)  and    -  INSTV7N (so  more  noisy  than  INSTV7;  “it's  [even]  closer  to  fv7  than  inst3”)  yaml  -  Gabox  Karaoke  model  got  updated  (links  have  been  replaced,  and  the  old  deleted  from  the  
repo),
 
 -  and  also  final  INSTV7 was  released  (“I  hear  less  noise  compared  to  v1e,  but  it  has  worse  bleedless  metric”)  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
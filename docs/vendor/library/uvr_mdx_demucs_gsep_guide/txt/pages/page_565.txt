[page 565/642]
    Q:  it  went  back  to  SDR  20  again  
A:
 
“that
 
progress
 
on
 
valid
 
updates
 
per
 
track,
 
so
 
some
 
tracks
 
are
 
20
 
SDR
 
some
 
will
 
be
 
like
 
2
 
SDR”
 
(frazer)
 Q:  yea,  some  are  still  at  11  etc  A:  “train  until  either  avg  loss  nan  or  fixed  sdr  (example:  14  for  me)  with  5.0e-05  use  best  checkpoint  from  that  run  with  1.0e-05  to  get  some  boost  idk  why  it  works  (and  if  it  works  im  at  step  1  rn  xD)”  -  mesk  Q:  is  it  normal  that  when  i  use  a  checkpoint  with  12.53  sdr,  then  restart  training,  the  results  at  
epoch
 
0
 
and
 
1
 
drop
 
back
 
to
 
11.77?
 A:  yes  only  if  u  restart  with  a  higher  LR  so  i  had  a  checkpoint  that  was  12SDR  trained  with  5e-5,  then  if  i  trained  that  with  1e-5,  youd  
expect
 
it
 
to
 
start
 
at
 
like
 
11.Xsdr
 if  i  had  a  checkpoint  12SDR  trained  1e-5,  and  i  train  with  5e-5,  id  expect  it  to  either  start  at  
12,
 
then
 
drop,
 
then
 
start
 
to
 
increase
 keep  it  going  5e-5  for  literally  as  long  as  u  can  this  is  called  overfitting  -  just  make  sure  it  doesnt  do  this  its  the  point  where  the  model  begins  to  not  generalize  but  memorize  the  training  set  -  
happens
 
on
 
finetuning
 
if
 
u
 
train
 
too
 
long
 what  u  do  is  just  keep  the  redline  score  if  u  still  have  it  (pic)  -  frazer   Preparing  dataset   Let’s  get  started.  First,  check  the  -   Repository  of  stems  -  section of  this  document.   There  you  will  find  out  that  most  stems  are  not  equal  in  terms  of  loudness  to  contemporary  
standards,
 
and
 
clip
 
when
 
mixed
 
together.
 
  About  sidechain  stem  limiting  guide  by  Vinctekan   The  sidechain  limiting  method  might  be  not  so  beneficial  for  SDR  as  we  thought  initially,  irc  it’s  explained  in  the  interesting  links  section with  the  given  paper.  Other  useful  links:   https://arxiv.org/pdf/2110.09958.pdf https://github.com/darius522/dnr-utils/blob/main/config.py  “You  can  also  just  utilize  this  https://github.com/darius522/dnr-utils/blob/main/audio_utils.py and  make  a  script  suited  to  your  own,  the  one  already  on  this  repo  is  a  bit  difficult  to  
repurpose.
 I  just  concatenated  a  lot  of  sfx  music  and  speech  together  into  1hr  chunks  and  used  audacity  
tho
 
(set
 
LUFS
 
and
 
mix)
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
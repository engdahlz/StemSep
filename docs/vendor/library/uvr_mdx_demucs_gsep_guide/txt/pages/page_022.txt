[page 22/642]
     -  Gabox  released  BS_ResurrectioN  model |  yaml “It  is  a  finetune  of  BS  Roformer  Resurrection  Inst  but  with  higher  fullness  (like  v1e  for  
example),
 
it
 
needs
 
[MVSEP’s]
 
BS
 
2025.07
 
(as
 
a
 
source/reference)
 
phase
 
fix
 
[so
 
you
 
“should
 
process
 
the
 
instrumental
 
result
 
using
 
BS
 
2025.07
 
then
 
put
 
[it]
 
as
 
source
 
in
 
UVR
 
GUI
 
phase
 
fix
 
tool”].
 
I
 
requested
 
it
 
because
 
I
 
found
 
some
 
songs
 
where
 
Resur
 
Inst
 
was
 
producing
 
muddy
 
instrum
 
results
 
(...)
 
I
 
requested
 
it
 
not
 
just
 
for
 
me
 
because
 
I
 
saw
 
other
 
people
 
were
 
looking
 
for
 
something
 
like
 
v1e++”
 
-
 
dca
 
  -  anvuew  released  BS-Roformer  Dereverb  Room  model |  Colab “specifically  for  mono  vocal  room  reverb.”  as  most  are  recorded  in  mono.  Not  that  long  inference  compared  to  other  Roformers.  “Really  liking  the  fullness  in  the  noreverb  stem.  Virtually  all  dereverb  roformers  I've  tried  
sound
 
muddy,
 
but
 
this
 
one
 
is
 
just
 
the
 
opposite.
 
(...)
 
Other
 
noises
 
may
 
interfere,
 
and
 
in
 
my
 
experience,
 
makes
 
the
 
model
 
underestimate
 
the
 
reverb.
 
[The
 
previous
 
anvuew’s
 
mono
 
model]
 
is
 
way
 
different
 
[from]
 
this
 
one
 
in
 
every
 
way.
 
So,
 
like
 
I
 
say,
 
worth
 
a
 
shot.”
 
-
 
Musicalman.
 
“WOAH
 
this
 
is
 
insane.
 
This
 
would
 
go
 
viral
 
if
 
someone
 
implemented
 
in
 
a
 
plugin”
 
-
 
heuhew
 We  have  reports  about  errors  in  UVR  while  using  this  model.  Consider  using  MSST instead.  If  you  have  stereo  errors  using  MSST  on  stereo  files,  update  MSST  (git  clone  and  git  pull  
commands)
 
or:
 
(it
 
might
 
work
 
in
 
your
 
current
 
version
 
and
 
not
 
only
 
in
 
the
 
linked
 
repo
 
too,
 
but
 
potentially
 
the
 
code
 
will
 
be
 
located
 
in
 
a
 
different
 
line,
 
the
 
change
 
will
 
be
 
pushed
 
there
 
later)
 “Edit  inference.py  from  my  repo line  59:  Replace  :          #  Convert  mono  to  stereo  if  needed          if  len(mix.shape)  ==  1:              mix  =  np.stack([mix,  mix],  axis=0)   by  :          #  If  mono  audio  we  must  adjust  it  depending  on  model          if  len(mix.shape)  ==  1:              mix  =  np.expand_dims(mix,  axis=0)              if  'num_channels'  in  config.audio:                  if  config.audio['num_channels']  ==  2:                      print(f'Convert  mono  track  to  stereo...')                      mix  =  np.concatenate([mix,  mix],  axis=0)”      -  jarredou  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
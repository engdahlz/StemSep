[page 375/642]
    pip  install  torch==2.3.0+cu118  torchvision  torchaudio  —-extra-index-url  
https://download.pytorch.org/whl/cu118
 or  pip  install  torch==2.3.0+cu118  --extra-index-url  https://download.pytorch.org/whl/cu118  and  pip  install  torchaudio==2.3.0+cu118  --extra-index-url  https://download.pytorch.org/whl/cu118  Replacing  cu118  with  newer  cu121  seems  to  give  a  proper  working  URL  too.   Maybe  replacing  2.3.0  with  2.3.1  will  work  too.  cu126  is  the  latest  supported  for  GTX  1080,  
while
 
cu128
 
isn’t
 
(but
 
supports
 
RTX
 
5000
 
series),
 
although
 
it
 
works
 
with
 
torch
 
2.7.0
 
which
 
can
 
cause
 
unpickling
 
errors
 
with
 
some
 
models:
 
"pip
 
install
 
torch==2.7.0
 
torchvision
 
--upgrade
 
--index-url
 
https://download.pytorch.org/whl/cu126".
  JFYI,  the  official  PyTorch  page:  https://pytorch.org/get-started/previous-versions/ lacks  links  for  CUDA  10  compatible  versions  for  older  GPUs  other  than  v1.12.1  (which  is  
pretty
 
old,
 
and
 
might
 
be
 
a
 
bit
 
slower
 
if
 
even
 
compatible
 
at
 
all),
 
so
 
the
 
only
 
way
 
to
 
install
 
newer
 
versions
 
for
 
CUDA
 
10
 
is
 
--extra-index-url
 
trick,
 
as
 
executing
 
normally
 
“pip
 
install
 
torch==2.3.0+cu118”
 
will
 
end
 
up
 
with
 
the
 
version
 
not
 
found
 
error.
  Alternatively,  you  might  also  try  out  installing  it  from  wheels  from  here by  the  following  command:  “pip  install  SomePackage-1.0-py2.py3-none-any.whl”  -  providing  a  full  path  with  the  file  name  
should
 
do
 
the
 
trick.
 
Just
 
for
 
the
 
location
 
with
 
spaces,
 
you
 
also
 
need
 
"
 
".
 
On
 
GTX
 
1660
 
and
 
Turing
 
GPUs,
 
you
 
might
 
seek
 
for
 
e.g.
 
cu121/torch-2.3.1"
 
and
 
those
 
various
 
CP
 
wheels
 
(there
 
are
 
no
 
newer
 
versions).
 
But
 
the
 
-extra-index-url
 
trick
 
above
 
should
 
be
 
enough.
  4.1.  After  performing  all  of  these,  you  might  still  have  SageAttention  not  found  error  on  GPUs  
up
 
to
 
Turing
 
arch.
 
Then
 
perform
 
the
 
following:
 “Had  to  replace  cufft64_10.dll  from  
C:\Users\user\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\lib
 
 by  the  one  from  C:\Program  Files\NVIDIA  GPU  Computing  Toolkit\CUDA\v10.0\bin”  It  is  even  compatible  with  the  newest  Torch  2.8.0  (if  you  followed  the  instruction  to  fix  the  dict  
issue
 
above)
 
if
 
you
 
grab
 
that
 
apparently
 
“
 
fixed
 
version
 
of
 
cufft64_10.dll
 
from
 
CUDA
 
v10.0”
 
-
 
dca
  5.  If  you  write  Python  in  CMD,  and  it  wasn't  found,  start  with  method  2  described  here:  https://www.liquidweb.com/help-docs/server-administration/windows/adding-python-path-to-windows-10-or-11-path-environment-variable/ Or  make  sure  you've  checked   the  option  to  add  path  environmental  variable  during  Python  
installation.
 Also,  you  can  try  out  “disabling  the  python  executable  in  app  execution  aliases.”  -  neoculture   6.  For  state_dict  =  torch_load/unpickling_error  “add  the  following  line  above  torch.load  (at  utils/model_utils.py  line  479):  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
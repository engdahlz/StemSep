[page 224/642]
    The  difference  from  using  single  becruily  Kar  model  is  that,  here,  “you  get  the  third  track,  
backing
 
vocals.”.
  -  Becruily:  “Probably  too  resource-intensive,  but  you  could  try  adding  demudders  to  each  
step
  1)  Karaoke  model  +  demudding  2)  Separate  vocals  of  BGV  +  demudidng    But  not  sure  how  much  noise  this  will  bring   (Or  even  a  50:50  ensemble  with  BVE  OG)”   -  Mel-Roformer  Karaoke  by  becruily  model  file |  Colab |  MVSEP  |  x-minus  (back/main  vox/instrumental  -  3  stems)  Use  voc_fv4  vocal  model  before  running  it  (less  bleeding  than  voc_fv6)  or:  “first  extract  the  vocals  with  a  fullness  model  [it  was  Mel  becruily  vocal  back  then]  and  
combine
 
the
 
results
 
with
 
a
 
fullness
 
instrumental
 
model.”
 
-
 
becruily
  “It's  a  dual  model,  trained  for  both  vocals  and  instrumental.  It  sounds  fuller  +  understands  
better
 
what
 
is
 
lead
 
and
 
background
 
vocal,
 
 
and
 
to
 
me,
 
it
 
is
 
better
 
than
 
any
 
other
 
karaoke
 
model.
 
  Important  note:  This  is  not  a  duet  or  male/female  model.  If  2  singers  are  singing  
simultaneously
 
+
 
background
 
vocals,
 
it
 
will
 
count
 
both
 
singers
 
as
 
lead
 
vocals.
 
The
 
model
 
strictly
 
keeps
 
only
 
actual
 
background
 
vocals.
 
The
 
same
 
goes
 
for
 
"adlibs"
 
such
 
as
 
high
 
notes
 
or
 
other
 
overlapping
 
lead
 
vocals.
 The  model  is  not  foolproof.  Some  songs  might  not  sound  that  much  improved  compared  to  
others.
 
It's
 
very
 
hard
 
to
 
find
 
a
 
dataset
 
for
 
this
 
kind
 
of
 
task.
  Compared  to  Aufr33’s  Melband  model  below,  it  can  achieve  e.g.  cleaner  pronunciation  in  some  songs  (examples).   “Better  than  Mel  Kar,  UVR  BVE  v2,  lalal.ai,  Dango...”  “For  sure  better  than  [the]  older  Karaoke  (aufr's  model)  for  harmonies.  Though  I  can  say  
Dango
 
can
 
remain
 
useful
 
in
 
certain
 
situations”
 
-
 
dca
  On  x-minus  there’s  lead  vocal  panning  setting  added  for  Mel-RoFormer  Kar  by  becruily  
model.
 
It’s
 
to
 
“to
 
"tell"
 
the
 
AI
 
  where
 
the
 
main
 
vocals
 
are
 
located
 
(how
 
they
 
are
 
mixed).”.
 “doesn't  even  need  Lead  vocal  panning  a  lot  of  the  time,  [the]  ability  to  recognize  what  is  LV  
and
 
what
 
is
 
BV
 
[is]
 
impressive”
 
-
 
dca
 
“Sometimes
 
struggles
 
when
 
the
 
backing
 
vocals
 
are
 
the
 
same
 
notes
 
as
 
the
 
lead
 
vocals”
 
-
 
isling.
 
Seems
 
like
 
xminus
 
panning
 
can’t
 
solve
 
such
 
issues
 
either.
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
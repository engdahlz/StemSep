[page 580/642]
    MelBand-Roformer  and  BS-Roformer  may  also  be  considered  as  generative  objective  
models
 
in
 
a
 
sense.
 
The
 
goal
 
of
 
these
 
models
 
is
 
to
 
generate
 
a
 
mask
 
to
 
extract
 
the
 
desired
 
stem
 
from
 
the
 
mixed
 
source"
 
unwa
  https://github.com/lucidrains/BS-RoFormer (it  incorporates  both  BS  and  Mel  variants,  implemented  in  MSST  training  repo)  It’s  safe  to  say  it’s  SAMI  Bytedance  arch  from  MVSEP  chart  reimplemented  from  their  paper  
-
 
done
 
by
 
lucidrains.
 
 Arch  papers:  BS  (band  split):  https://arxiv.org/abs/2211.11917 Mel  (mel  scale):  https://arxiv.org/pdf/2310.01809.pdf  “Bytedance  didn't  give  any  info  of  training  duration  for  these  scores,  but  in  their  last  
[ISMIR2024]
 
paper
 
for
 
Mel-Roformer:
 https://arxiv.org/abs/2409.04702 with  L=12,  they  get  12.08  SDR  on  vocals  with  Musdb-only  by  using  :  8  Nvidia  A-100-80GB  GPUs  with  batch_size=64,  and  the  training  stopped  at  400K  steps  
(~40
 
days).”
  32x  V100  will  require  two  months  of  training  (most  likely  for  500  songs  only  +  MUSDBHQ)  “It’s  better  to  have  16-A100-80G”,  viperx  trained  BS-Roformer  with  4500  songs  on  
8xA100-80GB
 
and
 
after
 
4
 
days
 
achieved
 
epoch
 
74,
 
and
 
on
 
epoch
 
162
 
achieved
 
only
 
0,0467
 
better
 
SDR
 
for
 
instrumental.
  ZFTurbo  having  4x  A6000  gave  up  training  on  it,  having  to  face  1  year  of  training  time.   After  the  BS  variant,  Mel-Band  RoFormer based  on  the  band  split  was  released  (“Mel-Roformer  uses  a  Mel-Band  spectrogram  whereas  BS-Roformer  doesn't”),  which  is  
faster.
 
Initially
 
it
 
achieved
 
worse
 
SDR
 
than
 
BS-Roformer
 
than
 
on
 
the
 
paper.
 
But
 
it
 
was
 
till
 
Kimberley
 
Jensen
 
released
 
her
 
new
 
Mel
 
model,
 
and
 
by
 
the
 
occasion,
 
tweaked
 
config
 
in
 
a
 
way
 
that
 
it
 
made
 
the
 
SDR
 
on
 
pair
 
with
 
BS
 
variant,
 
but
 
presumably,
 
by
 
training
 
on
 
even
 
smaller
 
dataset.
 Later,  viperx  trained  drums  only  model,  both  on  BS  and  Mel-Roformer,  and  BS-Roformer  
was
 
still
 
slightly
 
better,
 
but
 
there
 
wasn’t
 
such
 
a
 
difference
 
between
 
both
 
anymore
 
(12.52
 
vs
 
12.40
 
SDR).
  “Main  diff  is  that  BandSplit  is  using  linear  Hertz  scale  for  frequency  splitting  while  MelBand  is  
using
 
Mel
 
scale
 
(which
 
is
 
a
 
more
 
close
 
representation
 
of
 
how
 
humans
 
are
 
hearing
 
frequency
 
distances
 
than
 
linear
 
Hertz
 
scale).
 MelBand  matrixing  is  by  design  using  overlapping  frequency  bands,  while  with  BS,  there's  no  
overlap
 
in
 
the
 
frequency
 
range.”
 
jarredou
 “remember,  just  because  the  melscale  is  more  perceptual,  it  doesn't  necessarily  translate  
into
 
the
 
neural
 
net
 
learning
 
the
 
representation
 
better.
 
It
 
might
 
be
 
a
 
good
 
idea
 
to
 
use
 
a
 
modified
 
zipformer”
 
frazer
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 601/642]
     A:  I’ve  trained  some  convtasnet  in  the  past  with  really  decent  times  [on  4070  8]  (the  new  Ada  
Lovelace
 
on
 
40
 
series
 
makes
 
faster
 
tensor
 
cores,
 
which
 
kinda
 
compensates
 
the
 
less
 
number
 
of
 
cores
 
compared
 
to
 
30
 
series)
  A:  [4070  8GB]  is  fine  for  non  transformers.   If  mamba  blocks  are  used  good  it  could  be  fine  TBF.  The  thing  with  transformers  is  that  it  is  really  reliant  on  VRAM.   A:  Depends  on  what's  inside  the  transformer,  if  it's  flashatten  then  you  need  Ada.  Mamba  has  custom  kernels,  but  I'm  pretty  sure  4090  can  run  it  -  what'll  be  cool  is  mamba  +  
reversible
 
net,
 
super
 
memory
 
efficient
 
in
 
training,
 
but
 
it
 
ends
 
up
 
being
 
slower
 
per
 
step
 
(around
 
2x
 
compared
 
to
 
backprop).
 I  guess  in  reversible  net  you  can  have  gigantic  batch  sizes  which  kinda  circumvent  the  
problem
 
of
 
a
 
slow
 
step
 
speed”
   There  is  a  potential  alternative  to  GPUs  -    Training  using  TPU  https://sites.research.google/trc/about/ “(...)  equivalent  in  performance  to  an  a100   I'm  not  sure  how  good  torch  xla  support  is  now  (...)”  Cyclcrclicly   Turns  out  total  usable  VRAM  for  Pro  is  sadly  16GB,  and  48GB  of  system  memory   24  hours  of  interrupted  training  is  possible,  and  12  hours  for  free  users.   It  turned  out  to  be  extremely  convoluted  to  fix  compatibility  issues.   Bcr:  models  need  to  be  rewritten  in  JAX,  I  think;  can't  just  train  like  this   Fr:  import  torch_xla  model.to('xla')     for  inputs,  labels  in  train_loader:  +     with  torch_xla.step():          inputs,  labels  =  inputs.to('xla'),  labels.to('xla')          model(blah  blah)        #after  above  epoch  is  finished  +   torch_xla.sync()   +     
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
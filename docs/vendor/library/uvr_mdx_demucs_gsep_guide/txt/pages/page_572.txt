[page 572/642]
    Q:  So  what  is  the  solution?  A:  My  model  ðŸ™‚  If...  you  want  clean  instrumental  output.   Q:  But  yours  bleeds  percussion/noise  in  the  vocal  output  though...  A:  Yes.  That's  the  side-effect  of  training  on  non-processed/cleaned  up  vocals,  I  think.   Q:  Solution?  A:  Fine-tune  my  model,  but  this  time  based  on  de-noised  vocals  (and  add  a  shitload  of  
percussion
 
samples).
  My  prediction  is  that  we  then  have  the  best  of  both  worlds:  The  current  model  as-is  =  great  for  instrumentals  (as  described  by  the  community  several  
times
 
due,
 
using
 
non-processed/cleaned
 
up
 
vocals
 
as
 
input)
 Another  fine-tune  based  on  my  current  model  =  great  for  vocals  (due  to  the  lack  of  noise/low  
rumble/no
 
bleed
 
percussion)
  Warning:  This  is  based  on  logic  and  gut-feeling.   Dill:  caught  it  going  to  nan  again  when  everything  was  going  smoothly  very  suddenly  
between
 
epochs|
 
ZFTurbo:
 
I
 
think
 
it's
 
never
 
happened
 
to
 
me
 
on
 
SCNet,
 
but
 
often
 
on
 
htdemucs
 
as
 
I
 
remember.
 use_amp:  false  can  help  After  you  can  switch  back  on  usage  Dry  Paint:  I  can  speak  from  experience  that  it  only  kinda  helps  I  have  the  exact  same  issue  with  SCNet  making  amp=false  does  solve  it  but  causes  the  loss  to  skyrocket  to  like  3.2e32  around  the  
same
 
time
 
nan
 
loss
 
would
 
appear
 
 
Q:
 
Can
 
I
 
put
 
a
 
4-hour
 
file
 
in
 
one
 
of
 
the
 
dataset's
 
songs?
 
Or
 
should
 
I
 
split
 
it?
 A:  During  training  the  script  uses  chunks  anyway,  so  yes  you  can  feed  it  a  4  hour  file  (in  
theory)
 
A:
 
I
 
did
 
this,
 
but
 
I
 
had
 
to
 
modify
 
the
 
training
 
code
 
to
 
check
 
the
 
file
 
length
 
without
 
loading
 
the
 
whole
 
thing
 
into
 
memory
  
Leading  architectures   MDX-Net  (2021)  architecture  (a.k.a.  v2)  (https://github.com/kuielab/mdx-net).  Old.  From  public  archs,  before  MDX  v3  2023,  it  gave  us  the  best  results  for  various  applications  
like
 
vocal,
 
instrumental,
 
single
 
instruments
 
models
 
compared
 
to
 
VR
 
arch.
 
But
 
denoise
 
and
 
dereverb/deecho
 
model
 
turned
 
to
 
be
 
better
 
using
 
VR
 
architecture,
 
the
 
same
 
goes
 
to
 
Karaoke/BVE
 
models
 
where
 
in
 
contrary
 
to
 
5/6_HP,
 
MDX
 
model
 
sometimes
 
does
 
nothing.
  _____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
[page 467/642]
    Currently,  we  have  a  duet/unison  model  238  (default  in  Colab),  and  main/rest  138  to  uncomment  in  Colab.  Recommended  model  is  located  in  vocals  238  folder  (non  ISR-net  one).  While:  “The  ISR_net  is  basically  just  a  different  type  of  model  that  attempts  to  make  audio  super  
resolution
 
and
 
then
 
separate
 
it.
 
I
 
only
 
trained
 
it
 
because
 
that's
 
what
 
the
 
paper's
 
author
 
did,
 
but
 
it
 
gives
 
worse
 
results
 
than
 
just
 
the
 
normal
 
fine-tuned.”
 
 
MedleyVox
 
is
 
also
 
available
 
on
 
MVSEP,
 
but
 
it
 
has
 
more
 
bleeding
 
and
 
“doesn't
 
work
 
as
 
well
 
as
 
the
 
Colab
 
iteration
 
with
 
duets”.
 
(Isling/Ryanz)
  The  "duet/unison  model  238"  will  be  used  by  default.  ``and  main/rest  138  to  uncomment  in  Colab``  if  you  need  it.  Then  go  to  the  first  cell  again.  To  "uncomment"  means  to  delete  the  "#"  from  the  beginning  of  
the
 
line
 
before
 
the
 
"!wget"
 
so
 
the
 
line
 
will
 
be
 
used
 
to
 
download
 
the
 
model
 
files.
 
 Do  it  for  both  pth  and  json  lines  (you  might  be  asked  whether  to  replace  existing  pth  and  json  files  by  the  alternative  model  
you
 
just
 
downloaded
 
in
 
the
 
place
 
of
 
the
 
previous
 
one)
 ``Recommended  model  is  located  in  vocals  238  folder  (non  ISR-net  one).``  That's  the  model  used  in  the  Colab  by  default.  You  can  ignore  that  information.  It's  for  users  
using
 
the
 
MV
 
on
 
their
 
own
 
machine.
  The  output  for  238  model  is  24kHz  sample  rate  (so  12kHz  model  in  Spek).  You  might  want  to  upscale  the  results  using  e.g.  AudioSR or  maybe  even  Lew’s  vocal  enhancer  location  further  below  the  linked  section.   The  output  is  mono.  You  might  want  to  create  a  "fake  stereo"  as  input  by  copying  the  same  channel  over  the  two,  
then
 
do
 
the
 
same
 
with
 
another
 
channel,
 
and
 
then
 
create
 
the
 
stereo
 
result
 
from
 
both
 
channels
 
processed
 
separately
 
in
 
dual
 
mono
 
with
 
MV.
 The  AI  will  create  a  downmix  from  both  input  channels  instead  of  processing  channels  
separately.
 Be  aware  that  “dual  mono  processing  with  AI  can  often  create  incoherencies  in  stereo  image  
(like
 
the
 
voice
 
will
 
be
 
recognized
 
in
 
some
 
part
 
only
 
in
 
left
 
channel
 
and
 
not
 
the
 
other,
 
as
 
they
 
are
 
processed
 
independently)”
 
jarredou
  "The  demos  sound  quite  good  (separating  different  voices,  including  harmonies  or  
background
 
[backing]
 
vocals)"
 It's  for  already  separated  or  original  acapellas.   The  model  is  trained  by  Cyrus.  The  problem  is,  it  was  trained  with  12kHz  cutoff…  “audiosr  
does
 
almost
 
perfect
 
job
 
[with
 
upscaling
 
it]
 
already,
 
but
 
the
 
hugging
 
page
 
doesn’t
 
work
 
with
 
full
 
songs,
 
it
 
runs
 
out
 
of
 
memory
 
pretty
 
fast”.
 
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
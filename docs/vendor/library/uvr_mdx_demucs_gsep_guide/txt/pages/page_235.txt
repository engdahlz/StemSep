[page 235/642]
    Spectral  painting:  -  ISSE (free,  you  can  figure  out  which  voice  is  who's  just  by  frequencies  alone;  use  on  e.g.  separated  vocals  too)  -  RX  Editor’s  brush  (video by  Bas)   -  Audacity  (image)  less  effective   -  Ampter  -  Filter-Artist -  AudioPaint  Notes  If  artists  sing  the  same  notes,  Karaoke  models  will  rather  not  work  in  this  case.    If  BVs  are  heard  in  the  center,  don't  use  the  MDX  karaoke  model  but  the  VR  karaoke  model  
instead.
  Use  the  chain  algorithm  with  mdx  (kar)  v2  on  x-minus  which  will  use  uvr  (kar)  v2  to  solve  the  
issue.
 
It
 
will
 
be
 
available
 
after
 
you
 
process
 
the
 
song
 
with
 
MDX.
 
(Aufr33/dca)
  “The  MDX  models  seem  to  have  a  cleaner  separation  between  lead  and  
backing/background
 
vocals,
 
but
 
they
 
often
 
don't
 
do
 
any
 
actual
 
separation,
 
meanwhile
 
the
 
VR
 
models
 
are
 
less
 
clean,
 
but
 
they
 
seem
 
to
 
be
 
better
 
at
 
detecting
 
lead
 
and
 
background”
  “MDX  models  basically  require  the  lead  to  be  completely  center  and  the  BV  to  be  stereo  whereas  VR  ones  don't  really  care  as  much  about  stereo  placement”   You  could  also  ask  playdasegunda/play  da  primeira/viperx  for  separation,  as  he  has  some  decent  private  method/models  for  double  vocals  better  than  becruily  model  (although  the  
latter
 
can
 
be
 
still
 
close),
 
although
 
newer
 
frazer
 
&
 
becruily
 
model
 
is
 
“no
 
way
 
inferior
 
to
 
the
 
ViperX
 
(Play
 
da
 
Segunda).
 
The
 
rumour
 
says,
 
viperx
 
model
 
on
 
Play
 
da
 
Segunda
 
was
 
trained
 
on
 
40GB
 
dataset
 
allegedly
 
(it
 
would
 
be
 
small),
 
and
 
the
 
model
 
can
 
be
 
bought
 
for
 
500$
 
when
 
you
 
contact
 
via
 
email.
 
It's
 
actually
 
a
 
set
 
of
 
models
 
used
 
for
 
the
 
final
 
inference.
 
 
For
 
the
 
record,
 
the
 
open-sourced
 
model
 
by
 
the
 
duo
 
costed
 
600$
 
on
 
compute
 
and
 
probably
 
used
 
a
 
bigger
 
dataset,
 
achieved
 
a
 
bit
 
smaller
 
SDR,
 
but
 
it’s
 
a
 
single
 
model.
  For  research:  “These  archs  are  [...]  really  promising  for  multiple  speakers  separation,  and  should  be  
working
 
for
 
multiple
 
singers
 
separation
 
if
 
trained
 
on
 
singing
 
voice:
 https://github.com/dmlguq456/SepReformer (current  SOTA)  https://github.com/JusperLee/TDANet https://github.com/alibabasglab/MossFormer2”   >  Separating  two  main  vocals   E.g.  one  panned  about  30%  left  and  the  other  right  -  “use  bve  v2  and  click  the  “lead  vocal  panning”  button”  on  x-minus  premium  
_____________________  For  help  and  discussion,  visit  our  Audio  Separation  Discord:  https://discord.gg/ZPtAU5R6rP |  Download  UVR or MSST-GUI  For  inst/voc  separation  in  cloud,  try  out  free  Colabs:  BS/Mel-Roformer
 |  MDX23 (2-4  stems)  |  MDX-Net |  VR |  Demucs  4 (2-6)  
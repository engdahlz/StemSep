<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_gfc2v9r4qc22-4>li:before{content:"-  "}.lst-kix_1v1216yy0n25-5>li:before{content:"-  "}.lst-kix_hsahb38tz2f5-0>li:before{content:"-  "}.lst-kix_5stj9b6acoxv-7>li{counter-increment:lst-ctn-kix_5stj9b6acoxv-7}.lst-kix_7vr84ges94ry-7>li:before{content:"-  "}.lst-kix_2r20t3tmnrwb-3>li:before{content:"-  "}.lst-kix_gvlgpawofwi7-3>li:before{content:"-  "}ol.lst-kix_84zf7o74c8s9-0.start{counter-reset:lst-ctn-kix_84zf7o74c8s9-0 0}.lst-kix_bnte1i3g4kjh-3>li:before{content:"-  "}.lst-kix_4i10vbfgn91y-4>li:before{content:"-  "}ol.lst-kix_23ct987xwu67-2.start{counter-reset:lst-ctn-kix_23ct987xwu67-2 0}.lst-kix_dvvzixfw64a1-7>li:before{content:"-  "}.lst-kix_g8jgbze430sv-3>li:before{content:"(" counter(lst-ctn-kix_g8jgbze430sv-3,decimal) ") "}.lst-kix_6o2cphkh2n8b-5>li:before{content:"-  "}.lst-kix_eme1x4epzdye-7>li:before{content:"-  "}.lst-kix_qw2h6jd8xi17-3>li:before{content:"-  "}ol.lst-kix_90bg3luq5inv-3.start{counter-reset:lst-ctn-kix_90bg3luq5inv-3 0}.lst-kix_svg8hnl23b1r-1>li:before{content:"-  "}ol.lst-kix_g8jgbze430sv-2.start{counter-reset:lst-ctn-kix_g8jgbze430sv-2 0}.lst-kix_ug10x97qcpi8-4>li:before{content:"-  "}.lst-kix_5djgwp8c9ig2-5>li{counter-increment:lst-ctn-kix_5djgwp8c9ig2-5}.lst-kix_u8nobwiguyj1-3>li{counter-increment:lst-ctn-kix_u8nobwiguyj1-3}.lst-kix_incqcf2p39ls-2>li{counter-increment:lst-ctn-kix_incqcf2p39ls-2}.lst-kix_n9q8wqas57a-2>li:before{content:"-  "}.lst-kix_ul22dko4fd2j-2>li:before{content:"-  "}.lst-kix_4xiv877yc8jl-8>li:before{content:"-  "}.lst-kix_x8ffawrvrcyq-1>li:before{content:"\0025cb   "}.lst-kix_mh5zhf27i4rj-4>li:before{content:"-  "}.lst-kix_co74fk70kphx-4>li:before{content:"-  "}.lst-kix_3nq914pozpi7-0>li:before{content:"-  "}.lst-kix_8ujam3zhcr3q-6>li:before{content:"-  "}.lst-kix_hmvj5t8yy8bx-4>li:before{content:"+  "}.lst-kix_ysfu1bl0kymd-0>li{counter-increment:lst-ctn-kix_ysfu1bl0kymd-0}.lst-kix_gaq1zvh4dcgb-3>li:before{content:"-  "}.lst-kix_yrg2qlcqvak1-2>li:before{content:"-  "}.lst-kix_lwlxuymndfyq-1>li:before{content:"-  "}.lst-kix_tt1bo8z9re67-4>li:before{content:"-  "}.lst-kix_o1voy78o4juz-4>li:before{content:"-  "}.lst-kix_mv77cg19299c-3>li:before{content:"-  "}.lst-kix_ofib0hkczw41-7>li:before{content:"-  "}.lst-kix_4qbfcta6cclt-6>li:before{content:"-  "}.lst-kix_aor1182clqbr-6>li:before{content:"-  "}.lst-kix_jhofo94iol1-4>li:before{content:"-  "}.lst-kix_q24qpifeknc3-7>li:before{content:"-  "}.lst-kix_wwm574aidb8n-7>li:before{content:"-  "}.lst-kix_x95t913s41kt-3>li:before{content:"-  "}ul.lst-kix_nlsa7flowwa1-4{list-style-type:none}ul.lst-kix_nlsa7flowwa1-3{list-style-type:none}ul.lst-kix_nlsa7flowwa1-6{list-style-type:none}.lst-kix_ukx3y28hag8h-2>li:before{content:"-  "}ul.lst-kix_nlsa7flowwa1-5{list-style-type:none}ul.lst-kix_nlsa7flowwa1-8{list-style-type:none}ul.lst-kix_nlsa7flowwa1-7{list-style-type:none}.lst-kix_d1gy3hy5r3qj-5>li{counter-increment:lst-ctn-kix_d1gy3hy5r3qj-5}.lst-kix_9a7xq1ie41tp-0>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-2>li{counter-increment:lst-ctn-kix_2foc6u9lzfq4-2}.lst-kix_ekasiajyrrvz-2>li:before{content:"-  "}.lst-kix_hngwf7orguk6-5>li:before{content:"-  "}.lst-kix_axy5kxvo2nx7-6>li:before{content:"-  "}.lst-kix_d7eif1vat32g-1>li:before{content:"-  "}ul.lst-kix_nlsa7flowwa1-0{list-style-type:none}.lst-kix_5nilpkhthb5t-6>li:before{content:"-  "}ul.lst-kix_nlsa7flowwa1-2{list-style-type:none}ul.lst-kix_nlsa7flowwa1-1{list-style-type:none}.lst-kix_x1xhkkpc69w2-0>li:before{content:"-  "}.lst-kix_x1xhkkpc69w2-8>li:before{content:"-  "}.lst-kix_njs8ubf1qesf-6>li:before{content:"-  "}.lst-kix_9a7xq1ie41tp-8>li:before{content:"-  "}ul.lst-kix_cd2o0cncsajm-6{list-style-type:none}ul.lst-kix_cd2o0cncsajm-7{list-style-type:none}ul.lst-kix_cd2o0cncsajm-8{list-style-type:none}.lst-kix_ellvdfsu2z7q-2>li:before{content:"-  "}ul.lst-kix_cd2o0cncsajm-2{list-style-type:none}ul.lst-kix_cd2o0cncsajm-3{list-style-type:none}ul.lst-kix_cd2o0cncsajm-4{list-style-type:none}ul.lst-kix_cd2o0cncsajm-5{list-style-type:none}.lst-kix_rcfi5jnwnxji-2>li:before{content:"-  "}ul.lst-kix_cd2o0cncsajm-0{list-style-type:none}.lst-kix_5stj9b6acoxv-2>li:before{content:"" counter(lst-ctn-kix_5stj9b6acoxv-2,lower-roman) ". "}ul.lst-kix_cd2o0cncsajm-1{list-style-type:none}ul.lst-kix_1xkx8gh1e8n7-2{list-style-type:none}ul.lst-kix_1xkx8gh1e8n7-1{list-style-type:none}ul.lst-kix_1xkx8gh1e8n7-4{list-style-type:none}.lst-kix_hytfj9icha07-3>li:before{content:"-  "}ul.lst-kix_1xkx8gh1e8n7-3{list-style-type:none}ul.lst-kix_3i5qlhg977l0-8{list-style-type:none}ul.lst-kix_1xkx8gh1e8n7-6{list-style-type:none}ul.lst-kix_3i5qlhg977l0-7{list-style-type:none}ul.lst-kix_1xkx8gh1e8n7-5{list-style-type:none}ul.lst-kix_3i5qlhg977l0-6{list-style-type:none}ul.lst-kix_1xkx8gh1e8n7-8{list-style-type:none}ul.lst-kix_3i5qlhg977l0-5{list-style-type:none}ul.lst-kix_1xkx8gh1e8n7-7{list-style-type:none}ul.lst-kix_3i5qlhg977l0-4{list-style-type:none}.lst-kix_x12ed5cs6o9z-2>li:before{content:"-  "}ul.lst-kix_3i5qlhg977l0-3{list-style-type:none}ul.lst-kix_3i5qlhg977l0-2{list-style-type:none}ul.lst-kix_3i5qlhg977l0-1{list-style-type:none}ul.lst-kix_3i5qlhg977l0-0{list-style-type:none}.lst-kix_qmx92jmkghx8-4>li:before{content:"-  "}ul.lst-kix_1xkx8gh1e8n7-0{list-style-type:none}.lst-kix_vie3q5oyli2z-0>li:before{content:"-  "}.lst-kix_nj8yy6k748x0-1>li:before{content:"-  "}.lst-kix_bv8sxewi94yp-5>li:before{content:"-  "}.lst-kix_dn04c4yafie0-4>li:before{content:"-  "}ul.lst-kix_fmkfhvl8yhfs-1{list-style-type:none}.lst-kix_vie3q5oyli2z-8>li:before{content:"-  "}.lst-kix_qccibyu36y2t-4>li:before{content:"-  "}.lst-kix_fmkfhvl8yhfs-1>li:before{content:"-  "}ul.lst-kix_fmkfhvl8yhfs-2{list-style-type:none}ul.lst-kix_fmkfhvl8yhfs-3{list-style-type:none}ul.lst-kix_fmkfhvl8yhfs-4{list-style-type:none}ul.lst-kix_fmkfhvl8yhfs-5{list-style-type:none}ul.lst-kix_fmkfhvl8yhfs-6{list-style-type:none}.lst-kix_qzg09ck6gr7w-2>li:before{content:"-  "}ul.lst-kix_fmkfhvl8yhfs-7{list-style-type:none}ul.lst-kix_fmkfhvl8yhfs-8{list-style-type:none}.lst-kix_rxgry66ibim8-0>li:before{content:"-  "}ul.lst-kix_fmkfhvl8yhfs-0{list-style-type:none}.lst-kix_ykhrv7u6blcs-3>li:before{content:"-  "}.lst-kix_t3rn73qejgkj-1>li{counter-increment:lst-ctn-kix_t3rn73qejgkj-1}.lst-kix_932mko8sjg0u-7>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-0>li:before{content:"" counter(lst-ctn-kix_ykhoydml7pv3-0,decimal) ") "}.lst-kix_ykhoydml7pv3-8>li:before{content:"" counter(lst-ctn-kix_ykhoydml7pv3-8,lower-roman) ". "}.lst-kix_y32h08wggx1t-7>li:before{content:"-  "}ol.lst-kix_hppu19i8fr2p-3{list-style-type:none}ol.lst-kix_hppu19i8fr2p-4{list-style-type:none}ol.lst-kix_hppu19i8fr2p-1{list-style-type:none}ol.lst-kix_hppu19i8fr2p-2{list-style-type:none}ol.lst-kix_hppu19i8fr2p-7{list-style-type:none}ol.lst-kix_hppu19i8fr2p-8{list-style-type:none}ol.lst-kix_hppu19i8fr2p-5{list-style-type:none}ol.lst-kix_hppu19i8fr2p-6{list-style-type:none}.lst-kix_8hf94791m5p0-4>li:before{content:"-  "}.lst-kix_owvy3cstzf0s-8>li:before{content:"-  "}ol.lst-kix_hppu19i8fr2p-0{list-style-type:none}.lst-kix_c7r1s55bmbei-5>li:before{content:"-  "}.lst-kix_fs1lzw38maxl-1>li:before{content:"-  "}.lst-kix_cpgerodpupjz-1>li:before{content:"-  "}.lst-kix_j32gjnxzdkip-5>li:before{content:"-  "}.lst-kix_xdqzm25ye8fb-0>li:before{content:"-  "}.lst-kix_7o5enrj2ko1w-5>li:before{content:"-  "}.lst-kix_jnfn9mx5o33t-1>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-2>li:before{content:"" counter(lst-ctn-kix_u8nobwiguyj1-2,lower-roman) ") "}.lst-kix_owvy3cstzf0s-0>li:before{content:"-  "}.lst-kix_22zpsclbl6ju-5>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-6>li{counter-increment:lst-ctn-kix_sxixw4iqsgzx-6}.lst-kix_cd2o0cncsajm-5>li:before{content:"-  "}.lst-kix_iupg79bv69ia-8>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-7>li:before{content:"" counter(lst-ctn-kix_ok1n37qarjzb-7,lower-roman) ". "}.lst-kix_9z31rmzc855z-7>li:before{content:"-  "}.lst-kix_6nc1nfac2wub-2>li:before{content:"-  "}.lst-kix_fm53cr9wmch0-6>li:before{content:"-  "}.lst-kix_3i5qlhg977l0-6>li:before{content:"-  "}.lst-kix_t9t3ckq2i2hz-1>li:before{content:"-  "}.lst-kix_6pgojrjbxqei-6>li:before{content:"\0025cf   "}.lst-kix_xx6ude5yqnkl-4>li:before{content:"\0025cb   "}.lst-kix_qb494lue4ahb-4>li:before{content:"-  "}.lst-kix_iupg79bv69ia-0>li:before{content:"-  "}.lst-kix_hkt83gwcgrvq-3>li:before{content:"-  "}.lst-kix_t6x6ie377r4u-7>li:before{content:"-  "}ol.lst-kix_yjf6dvvoob64-3.start{counter-reset:lst-ctn-kix_yjf6dvvoob64-3 0}.lst-kix_8euewcidoez8-0>li:before{content:"-  "}.lst-kix_8euewcidoez8-8>li:before{content:"-  "}.lst-kix_35hvjwgc3k2f-5>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-5>li:before{content:"" counter(lst-ctn-kix_2foc6u9lzfq4-5,lower-roman) ". "}.lst-kix_vayf18aqt55o-6>li:before{content:"" counter(lst-ctn-kix_vayf18aqt55o-6,lower-latin) ". "}.lst-kix_ld6rwbdri49-2>li:before{content:"-  "}.lst-kix_tdrf79x9zyr7-7>li:before{content:"-  "}.lst-kix_rt3ua1vpzay9-0>li:before{content:"-  "}.lst-kix_tc7vpn5ce0ra-8>li:before{content:"-  "}.lst-kix_s9h4llxy1yy0-7>li:before{content:"-  "}.lst-kix_8f3g26d9wonp-3>li:before{content:"-  "}.lst-kix_6m4qu83yomn7-7>li:before{content:"-  "}.lst-kix_jfoqdfq6uhww-2>li:before{content:"-  "}.lst-kix_rt3ua1vpzay9-8>li:before{content:"-  "}.lst-kix_6u6or33vx86s-6>li:before{content:"-  "}.lst-kix_qij6192l4p0g-4>li:before{content:"-  "}.lst-kix_oswsfzrgbvyb-7>li:before{content:"-  "}.lst-kix_i4nwb7g7qe41-0>li:before{content:"-  "}.lst-kix_4xiv877yc8jl-0>li:before{content:"-  "}.lst-kix_df6s37r8voak-3>li:before{content:"-  "}.lst-kix_3nq914pozpi7-8>li:before{content:"-  "}.lst-kix_fexdtgozkcsr-4>li:before{content:"-  "}.lst-kix_yhq927c05ak0-1>li:before{content:"-  "}.lst-kix_x6hb6vgwujyx-2>li:before{content:"-  "}.lst-kix_ksf6p4xm2w0d-7>li:before{content:"-  "}ul.lst-kix_ozrjmre97pex-0{list-style-type:none}.lst-kix_c73c2x77meqo-1>li:before{content:"-  "}.lst-kix_tc7vpn5ce0ra-0>li:before{content:"-  "}.lst-kix_xdqzm25ye8fb-8>li:before{content:"-  "}ul.lst-kix_ozrjmre97pex-7{list-style-type:none}ul.lst-kix_ozrjmre97pex-8{list-style-type:none}ul.lst-kix_ozrjmre97pex-5{list-style-type:none}ul.lst-kix_ozrjmre97pex-6{list-style-type:none}.lst-kix_om0x63wgf9wd-6>li:before{content:"-  "}ul.lst-kix_ozrjmre97pex-3{list-style-type:none}ul.lst-kix_ozrjmre97pex-4{list-style-type:none}.lst-kix_puc0azh4kjfq-4>li:before{content:"-  "}ul.lst-kix_ozrjmre97pex-1{list-style-type:none}ul.lst-kix_ozrjmre97pex-2{list-style-type:none}.lst-kix_ok1n37qarjzb-5>li{counter-increment:lst-ctn-kix_ok1n37qarjzb-5}.lst-kix_j60wooaeanf9-7>li:before{content:"-  "}.lst-kix_tjrvr4c0ezjq-4>li:before{content:"-  "}.lst-kix_st0egafmkg0z-6>li:before{content:"-  "}ol.lst-kix_vkdxjlf0kb6j-1.start{counter-reset:lst-ctn-kix_vkdxjlf0kb6j-1 0}.lst-kix_hsahb38tz2f5-8>li:before{content:"-  "}.lst-kix_6ltb10qoez57-1>li:before{content:"\0025cb   "}.lst-kix_8w7txqc6xq66-6>li:before{content:"-  "}.lst-kix_w97kncqyzxj3-3>li:before{content:"\0025cf   "}.lst-kix_qmryaqe19okh-6>li:before{content:"-  "}.lst-kix_cwjen7nun640-5>li:before{content:"-  "}.lst-kix_kxjfd2xlpmu-7>li:before{content:"-  "}.lst-kix_bo9wrgz88es4-7>li:before{content:"-  "}.lst-kix_194f2a56ajxk-8>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-8.start{counter-reset:lst-ctn-kix_ok1n37qarjzb-8 0}.lst-kix_oqibhsqlyfou-6>li:before{content:"-  "}.lst-kix_m31se2npgu2r-6>li:before{content:"-  "}.lst-kix_bdjoj2nf5hw9-0>li:before{content:"-  "}.lst-kix_qsto019ofcm1-7>li:before{content:"-  "}.lst-kix_194f2a56ajxk-0>li:before{content:"-  "}.lst-kix_s0nbf6s2np44-6>li:before{content:"-  "}.lst-kix_b7rulpv7obgl-7>li:before{content:"-  "}.lst-kix_3wddikkjnk2k-0>li:before{content:"-  "}.lst-kix_g9hblcm1l6tk-2>li:before{content:"-  "}.lst-kix_g2uanok8rp1g-1>li:before{content:"-  "}.lst-kix_rgd2g4si1ihs-5>li:before{content:"-  "}.lst-kix_90bg3luq5inv-6>li:before{content:"" counter(lst-ctn-kix_90bg3luq5inv-6,decimal) ". "}.lst-kix_7e64bsb5krip-5>li:before{content:"-  "}.lst-kix_3wddikkjnk2k-8>li:before{content:"-  "}.lst-kix_wz5gdx83jdla-5>li:before{content:"-  "}.lst-kix_x1n4jlo0gf1q-5>li:before{content:"-  "}ol.lst-kix_ykhoydml7pv3-7.start{counter-reset:lst-ctn-kix_ykhoydml7pv3-7 0}.lst-kix_wiijpxq0m5a-0>li:before{content:"-  "}.lst-kix_wiijpxq0m5a-8>li:before{content:"-  "}.lst-kix_nqtgcebhe8ii-5>li:before{content:"-  "}.lst-kix_rp6rf03vbelo-7>li:before{content:"-  "}ol.lst-kix_52jgzw489fhs-4.start{counter-reset:lst-ctn-kix_52jgzw489fhs-4 0}.lst-kix_nipj94pw11x6-4>li:before{content:"-  "}.lst-kix_h25uruhpfzux-2>li:before{content:"-  "}.lst-kix_3koi1cw13a0-7>li:before{content:"-  "}.lst-kix_i4nwb7g7qe41-8>li:before{content:"-  "}.lst-kix_ce3ho29dhteb-3>li:before{content:"-  "}.lst-kix_4pjeuglo4z6v-6>li:before{content:"-  "}.lst-kix_xyra4e5ffsud-7>li{counter-increment:lst-ctn-kix_xyra4e5ffsud-7}.lst-kix_2xixyk6jteti-4>li:before{content:"-  "}.lst-kix_g0lr2dxtnslc-4>li:before{content:"-  "}ol.lst-kix_3fc7x0lm2mmz-4{list-style-type:none}.lst-kix_incqcf2p39ls-2>li:before{content:"" counter(lst-ctn-kix_incqcf2p39ls-2,lower-roman) ") "}ol.lst-kix_3fc7x0lm2mmz-3{list-style-type:none}ol.lst-kix_3fc7x0lm2mmz-6{list-style-type:none}ol.lst-kix_3fc7x0lm2mmz-5{list-style-type:none}ol.lst-kix_3fc7x0lm2mmz-0{list-style-type:none}.lst-kix_ms6rbzn59hmq-2>li:before{content:"-  "}.lst-kix_9j3np3ow732h-6>li:before{content:"\0025cf   "}.lst-kix_bsvmcpoa86br-0>li:before{content:"-  "}ol.lst-kix_3fc7x0lm2mmz-2{list-style-type:none}ol.lst-kix_3fc7x0lm2mmz-1{list-style-type:none}.lst-kix_luixtz7s7e5x-5>li:before{content:"-  "}ol.lst-kix_3fc7x0lm2mmz-8{list-style-type:none}.lst-kix_zb3jq278pptw-3>li:before{content:"-  "}ol.lst-kix_3fc7x0lm2mmz-7{list-style-type:none}.lst-kix_kobinbwr4qr6-7>li:before{content:"-  "}.lst-kix_bsvmcpoa86br-8>li:before{content:"-  "}.lst-kix_8drpzle0jo7q-6>li:before{content:"\0025cf   "}.lst-kix_tl77ogq6q7u-6>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-7>li:before{content:"" counter(lst-ctn-kix_ysfu1bl0kymd-7,lower-latin) ". "}.lst-kix_d626gkjp4fou-7>li:before{content:"\0025cb   "}ul.lst-kix_aikphwux0ki0-8{list-style-type:none}ul.lst-kix_aikphwux0ki0-5{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-4{list-style-type:none}ul.lst-kix_aikphwux0ki0-4{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-3{list-style-type:none}ul.lst-kix_aikphwux0ki0-7{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-6{list-style-type:none}ul.lst-kix_aikphwux0ki0-6{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-5{list-style-type:none}ul.lst-kix_aikphwux0ki0-1{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-0{list-style-type:none}ul.lst-kix_aikphwux0ki0-0{list-style-type:none}.lst-kix_rf3bfhvmysmh-3>li:before{content:"-  "}ul.lst-kix_aikphwux0ki0-3{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-2{list-style-type:none}ul.lst-kix_aikphwux0ki0-2{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-1{list-style-type:none}.lst-kix_a62ncfcuapzo-4>li:before{content:"-  "}.lst-kix_dmxresnhzo8y-0>li:before{content:"-  "}.lst-kix_bttl6bm2dx1a-8>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-7>li{counter-increment:lst-ctn-kix_azgj6sn0lxuj-7}ul.lst-kix_m31se2npgu2r-1{list-style-type:none}ul.lst-kix_m31se2npgu2r-0{list-style-type:none}.lst-kix_ikdz4hpyto9o-1>li:before{content:"-  "}ul.lst-kix_m31se2npgu2r-3{list-style-type:none}ul.lst-kix_m31se2npgu2r-2{list-style-type:none}.lst-kix_3q7au8a3gwav-5>li:before{content:"-  "}ol.lst-kix_sxixw4iqsgzx-2.start{counter-reset:lst-ctn-kix_sxixw4iqsgzx-2 0}ul.lst-kix_m31se2npgu2r-8{list-style-type:none}ul.lst-kix_m31se2npgu2r-5{list-style-type:none}ul.lst-kix_m31se2npgu2r-4{list-style-type:none}ul.lst-kix_m31se2npgu2r-7{list-style-type:none}ul.lst-kix_m31se2npgu2r-6{list-style-type:none}.lst-kix_3mj3tp7kj9db-3>li:before{content:"(" counter(lst-ctn-kix_3mj3tp7kj9db-3,decimal) ") "}.lst-kix_r6uhbskcwxv5-2>li:before{content:"-  "}.lst-kix_qqbjjwnrc3l8-6>li:before{content:"-  "}.lst-kix_xktbtduo53bq-1>li{counter-increment:lst-ctn-kix_xktbtduo53bq-1}.lst-kix_dmxresnhzo8y-8>li:before{content:"-  "}.lst-kix_vgg0538grxk3-5>li:before{content:"(" counter(lst-ctn-kix_vgg0538grxk3-5,lower-roman) ") "}.lst-kix_bttl6bm2dx1a-0>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-7>li:before{content:"" counter(lst-ctn-kix_azgj6sn0lxuj-7,lower-latin) ". "}.lst-kix_3mj3tp7kj9db-0>li{counter-increment:lst-ctn-kix_3mj3tp7kj9db-0}.lst-kix_bp67ajcb7c38-3>li:before{content:"-  "}.lst-kix_unv0ib1v43rp-7>li:before{content:"-  "}.lst-kix_q95o92il1jwg-5>li:before{content:"-  "}.lst-kix_wn0yiryrov3h-3>li:before{content:"-  "}.lst-kix_qvomcnyqz8ao-1>li:before{content:"-  "}.lst-kix_rtczm6eelr4h-4>li:before{content:"-  "}.lst-kix_hssoi9jbujv-1>li:before{content:"-  "}.lst-kix_bb3pt2xtt0a5-2>li:before{content:"-  "}.lst-kix_chbthqdwx7gj-4>li:before{content:"-  "}.lst-kix_bdjoj2nf5hw9-8>li:before{content:"-  "}.lst-kix_iefjrs8t42tr-6>li:before{content:"-  "}.lst-kix_8nwtyhgsvjlm-5>li:before{content:"-  "}.lst-kix_rop4yg7lbfg8-4>li:before{content:"-  "}.lst-kix_mvektlca5c5q-6>li:before{content:"-  "}.lst-kix_pgnpvlxhai6o-4>li:before{content:"-  "}ol.lst-kix_vkdxjlf0kb6j-8{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-7{list-style-type:none}.lst-kix_axwe0nze7yft-5>li:before{content:"-  "}.lst-kix_o17eseb5cr8e-5>li:before{content:"-  "}.lst-kix_rxgry66ibim8-8>li:before{content:"-  "}.lst-kix_pxpm44v9ngyu-2>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-0.start{counter-reset:lst-ctn-kix_incqcf2p39ls-0 0}.lst-kix_dynlpr2uwt2p-1>li:before{content:"-  "}.lst-kix_ozrjmre97pex-5>li:before{content:"-  "}.lst-kix_5syfdd8x3l8s-3>li:before{content:"-  "}.lst-kix_x74x9xa8n5a0-4>li:before{content:"-  "}.lst-kix_pg2i9lis4p1v-6>li:before{content:"-  "}.lst-kix_i2q40uf7647f-0>li:before{content:"-  "}.lst-kix_11d94ps4c7wj-4>li:before{content:"-  "}.lst-kix_dyq7vlcdkqm5-3>li:before{content:"-  "}.lst-kix_of5ud22cn0qg-1>li:before{content:"-  "}.lst-kix_nlsa7flowwa1-1>li:before{content:"+  "}.lst-kix_urqiwn6svi1d-5>li:before{content:"-  "}.lst-kix_vhhvekoaa9d4-3>li:before{content:"\0025cf   "}.lst-kix_rxmcp67o7upe-4>li:before{content:"-  "}.lst-kix_tnd0p97rqwub-0>li:before{content:"-  "}.lst-kix_b3ghc04lfx9t-3>li:before{content:"-  "}.lst-kix_w3rscytwttbz-8>li:before{content:"-  "}.lst-kix_wnr3c516ni7j-1>li:before{content:"-  "}.lst-kix_wfyz8rmi0iq4-2>li:before{content:"-  "}.lst-kix_tw1wz6pba43e-8>li:before{content:"-  "}.lst-kix_i2q40uf7647f-8>li:before{content:"-  "}.lst-kix_x2lkon80l30j-6>li:before{content:"-  "}.lst-kix_73pnq2b8bo4n-7>li:before{content:"-  "}.lst-kix_tnd0p97rqwub-8>li:before{content:"-  "}.lst-kix_3wxxpxfz40sk-5>li:before{content:"-  "}.lst-kix_7o1va6u13ska-6>li:before{content:"-  "}.lst-kix_xyra4e5ffsud-3>li:before{content:"" counter(lst-ctn-kix_xyra4e5ffsud-3,decimal) ". "}.lst-kix_5rn2qrejqs3r-7>li:before{content:"-  "}ul.lst-kix_o7acnutkhp1w-0{list-style-type:none}ul.lst-kix_o7acnutkhp1w-1{list-style-type:none}ul.lst-kix_o7acnutkhp1w-2{list-style-type:none}ul.lst-kix_3wxxpxfz40sk-5{list-style-type:none}ul.lst-kix_3wxxpxfz40sk-6{list-style-type:none}.lst-kix_zag3ymt8mk2y-6>li:before{content:"-  "}ul.lst-kix_3wxxpxfz40sk-7{list-style-type:none}ul.lst-kix_3wxxpxfz40sk-8{list-style-type:none}ul.lst-kix_3wxxpxfz40sk-1{list-style-type:none}ul.lst-kix_o7acnutkhp1w-7{list-style-type:none}ul.lst-kix_3wxxpxfz40sk-2{list-style-type:none}ul.lst-kix_o7acnutkhp1w-8{list-style-type:none}ul.lst-kix_3wxxpxfz40sk-3{list-style-type:none}ul.lst-kix_3wxxpxfz40sk-4{list-style-type:none}ul.lst-kix_o7acnutkhp1w-3{list-style-type:none}.lst-kix_w3rscytwttbz-0>li:before{content:"-  "}.lst-kix_wlyv8o88ksmk-3>li:before{content:"-  "}ul.lst-kix_o7acnutkhp1w-4{list-style-type:none}ul.lst-kix_o7acnutkhp1w-5{list-style-type:none}ul.lst-kix_3wxxpxfz40sk-0{list-style-type:none}ul.lst-kix_o7acnutkhp1w-6{list-style-type:none}.lst-kix_k5hm652wcnm2-2>li:before{content:"-  "}.lst-kix_fhtxrv3nkyi7-3>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-7>li:before{content:"" counter(lst-ctn-kix_d1gy3hy5r3qj-7,lower-latin) ". "}.lst-kix_a2xq56ushw0p-3>li:before{content:"-  "}ul.lst-kix_bb3pt2xtt0a5-4{list-style-type:none}ul.lst-kix_bb3pt2xtt0a5-5{list-style-type:none}ul.lst-kix_bb3pt2xtt0a5-2{list-style-type:none}ul.lst-kix_bb3pt2xtt0a5-3{list-style-type:none}ul.lst-kix_bb3pt2xtt0a5-8{list-style-type:none}.lst-kix_arcio13zm8ud-6>li:before{content:"-  "}ul.lst-kix_bb3pt2xtt0a5-6{list-style-type:none}ul.lst-kix_bb3pt2xtt0a5-7{list-style-type:none}ol.lst-kix_d1gy3hy5r3qj-6.start{counter-reset:lst-ctn-kix_d1gy3hy5r3qj-6 0}.lst-kix_innl5fto9oyf-6>li:before{content:"-  "}ul.lst-kix_bb3pt2xtt0a5-0{list-style-type:none}ul.lst-kix_bb3pt2xtt0a5-1{list-style-type:none}.lst-kix_rrloltks13s-4>li:before{content:"-  "}.lst-kix_rog9deufml3h-6>li:before{content:"-  "}.lst-kix_awt45k7p90je-3>li:before{content:"-  "}.lst-kix_tw1wz6pba43e-0>li:before{content:"-  "}.lst-kix_g1rm1ujfok3h-8>li:before{content:"-  "}.lst-kix_43bwriak8ne4-4>li:before{content:"-  "}.lst-kix_4z9ptm6a4lke-5>li:before{content:"-  "}.lst-kix_z6rr709h3fky-0>li:before{content:"-  "}.lst-kix_5quy3fbj2mfg-1>li:before{content:"-  "}.lst-kix_7rlftcume51v-6>li:before{content:"-  "}.lst-kix_wzt7symqmcfu-0>li:before{content:"-  "}ul.lst-kix_5syfdd8x3l8s-0{list-style-type:none}ul.lst-kix_5syfdd8x3l8s-1{list-style-type:none}.lst-kix_q8ex99of35ig-0>li:before{content:"-  "}.lst-kix_khixc8f7o03u-6>li:before{content:"-  "}.lst-kix_ms4jfr9nudpc-2>li:before{content:"-  "}ul.lst-kix_iffqre5r12zx-1{list-style-type:none}.lst-kix_wzt7symqmcfu-8>li:before{content:"-  "}.lst-kix_f83agu4s4fw5-1>li:before{content:"-  "}ul.lst-kix_iffqre5r12zx-0{list-style-type:none}.lst-kix_t3rn73qejgkj-6>li:before{content:"" counter(lst-ctn-kix_t3rn73qejgkj-6,decimal) ". "}.lst-kix_q8ex99of35ig-8>li:before{content:"-  "}.lst-kix_bswxvn1l22fp-3>li:before{content:"-  "}ul.lst-kix_5syfdd8x3l8s-4{list-style-type:none}ul.lst-kix_iffqre5r12zx-8{list-style-type:none}ul.lst-kix_5syfdd8x3l8s-5{list-style-type:none}.lst-kix_z6rr709h3fky-8>li:before{content:"-  "}ul.lst-kix_iffqre5r12zx-7{list-style-type:none}.lst-kix_2ccdqvrbclt-1>li:before{content:"-  "}ul.lst-kix_5syfdd8x3l8s-2{list-style-type:none}.lst-kix_hrm7p8w30y7p-4>li:before{content:"-  "}ul.lst-kix_iffqre5r12zx-6{list-style-type:none}ul.lst-kix_5syfdd8x3l8s-3{list-style-type:none}ul.lst-kix_iffqre5r12zx-5{list-style-type:none}.lst-kix_1xkx8gh1e8n7-2>li:before{content:"-  "}ul.lst-kix_5syfdd8x3l8s-8{list-style-type:none}ul.lst-kix_iffqre5r12zx-4{list-style-type:none}.lst-kix_wf1o55flzq55-4>li:before{content:"-  "}ul.lst-kix_iffqre5r12zx-3{list-style-type:none}ul.lst-kix_5syfdd8x3l8s-6{list-style-type:none}ul.lst-kix_iffqre5r12zx-2{list-style-type:none}.lst-kix_p11gr83hik0e-3>li:before{content:"-  "}ul.lst-kix_5syfdd8x3l8s-7{list-style-type:none}.lst-kix_g1rm1ujfok3h-0>li:before{content:"-  "}ul.lst-kix_j60wooaeanf9-0{list-style-type:none}ul.lst-kix_j60wooaeanf9-1{list-style-type:none}.lst-kix_r8i1fgeyliey-7>li:before{content:"-  "}ul.lst-kix_j60wooaeanf9-8{list-style-type:none}ul.lst-kix_j60wooaeanf9-6{list-style-type:none}.lst-kix_yjf6dvvoob64-5>li{counter-increment:lst-ctn-kix_yjf6dvvoob64-5}ul.lst-kix_j60wooaeanf9-7{list-style-type:none}ul.lst-kix_j60wooaeanf9-4{list-style-type:none}ul.lst-kix_j60wooaeanf9-5{list-style-type:none}.lst-kix_38p7uzj3qds3-7>li:before{content:"-  "}ul.lst-kix_j60wooaeanf9-2{list-style-type:none}ul.lst-kix_j60wooaeanf9-3{list-style-type:none}.lst-kix_fy701w8ywepa-6>li:before{content:"-  "}.lst-kix_q7gxc7al9t7n-4>li:before{content:"-  "}.lst-kix_q7gxc7al9t7n-1>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-8>li{counter-increment:lst-ctn-kix_ok1n37qarjzb-8}ul.lst-kix_gaq1zvh4dcgb-0{list-style-type:none}ol.lst-kix_t3rn73qejgkj-4.start{counter-reset:lst-ctn-kix_t3rn73qejgkj-4 0}ul.lst-kix_gaq1zvh4dcgb-4{list-style-type:none}ul.lst-kix_gaq1zvh4dcgb-3{list-style-type:none}.lst-kix_eh8nesljbkpv-0>li:before{content:"-  "}ul.lst-kix_gaq1zvh4dcgb-2{list-style-type:none}ul.lst-kix_gaq1zvh4dcgb-1{list-style-type:none}.lst-kix_kp4gb6sd08f1-8>li:before{content:"-  "}.lst-kix_p11gr83hik0e-8>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-5>li{counter-increment:lst-ctn-kix_2foc6u9lzfq4-5}.lst-kix_lojd6plssn1-6>li:before{content:"-  "}.lst-kix_zew29xx7bzz-2>li:before{content:"-  "}.lst-kix_p9ucdfdvxyzl-6>li:before{content:"-  "}.lst-kix_sxznwwyc44x6-7>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-0>li:before{content:"" counter(lst-ctn-kix_3fc7x0lm2mmz-0,decimal) ") "}ul.lst-kix_g02ta87c1sqh-7{list-style-type:none}ul.lst-kix_g02ta87c1sqh-6{list-style-type:none}ul.lst-kix_g02ta87c1sqh-8{list-style-type:none}ul.lst-kix_g02ta87c1sqh-3{list-style-type:none}ul.lst-kix_g02ta87c1sqh-2{list-style-type:none}ul.lst-kix_g02ta87c1sqh-5{list-style-type:none}ul.lst-kix_g02ta87c1sqh-4{list-style-type:none}.lst-kix_tekivzgenz72-2>li:before{content:"-  "}.lst-kix_sxznwwyc44x6-4>li:before{content:"-  "}ul.lst-kix_g02ta87c1sqh-1{list-style-type:none}ul.lst-kix_g02ta87c1sqh-0{list-style-type:none}ol.lst-kix_ykhoydml7pv3-8.start{counter-reset:lst-ctn-kix_ykhoydml7pv3-8 0}.lst-kix_uwhnriglec8q-4>li:before{content:"-  "}.lst-kix_uwhnriglec8q-7>li:before{content:"-  "}ol.lst-kix_5stj9b6acoxv-6.start{counter-reset:lst-ctn-kix_5stj9b6acoxv-6 0}.lst-kix_l4d8unsm10a0-3>li:before{content:"-  "}.lst-kix_t3rn73qejgkj-4>li{counter-increment:lst-ctn-kix_t3rn73qejgkj-4}ul.lst-kix_gaq1zvh4dcgb-8{list-style-type:none}ul.lst-kix_gaq1zvh4dcgb-7{list-style-type:none}ul.lst-kix_gaq1zvh4dcgb-6{list-style-type:none}ul.lst-kix_gaq1zvh4dcgb-5{list-style-type:none}.lst-kix_ykhoydml7pv3-8>li{counter-increment:lst-ctn-kix_ykhoydml7pv3-8}.lst-kix_sgiyubx3nkay-4>li:before{content:"-  "}ul.lst-kix_voj7evacrpie-8{list-style-type:none}.lst-kix_xktbtduo53bq-2>li:before{content:"" counter(lst-ctn-kix_xktbtduo53bq-2,lower-roman) ". "}ul.lst-kix_voj7evacrpie-7{list-style-type:none}ul.lst-kix_voj7evacrpie-6{list-style-type:none}ul.lst-kix_voj7evacrpie-5{list-style-type:none}.lst-kix_v9cryi9ybo1n-1>li:before{content:"\0025cb   "}ul.lst-kix_voj7evacrpie-4{list-style-type:none}ul.lst-kix_voj7evacrpie-3{list-style-type:none}ul.lst-kix_voj7evacrpie-2{list-style-type:none}ul.lst-kix_voj7evacrpie-1{list-style-type:none}.lst-kix_85vz7a3ggeai-8>li:before{content:"-  "}ul.lst-kix_voj7evacrpie-0{list-style-type:none}ul.lst-kix_aor1182clqbr-7{list-style-type:none}ul.lst-kix_aor1182clqbr-8{list-style-type:none}.lst-kix_fy701w8ywepa-3>li:before{content:"-  "}.lst-kix_sgiyubx3nkay-1>li:before{content:"-  "}.lst-kix_85vz7a3ggeai-5>li:before{content:"-  "}ul.lst-kix_aor1182clqbr-0{list-style-type:none}ul.lst-kix_aor1182clqbr-1{list-style-type:none}ul.lst-kix_aor1182clqbr-2{list-style-type:none}ul.lst-kix_aor1182clqbr-3{list-style-type:none}ul.lst-kix_aor1182clqbr-4{list-style-type:none}.lst-kix_28q7sqckfj19-8>li:before{content:"-  "}ul.lst-kix_aor1182clqbr-5{list-style-type:none}ul.lst-kix_aor1182clqbr-6{list-style-type:none}.lst-kix_8hvuzyuchy3p-3>li:before{content:"-  "}.lst-kix_9ys95s420x24-2>li:before{content:"-  "}.lst-kix_f4168mxvziu2-8>li:before{content:"-  "}.lst-kix_d94n7or3b41v-4>li:before{content:"-  "}.lst-kix_vgg0538grxk3-8>li{counter-increment:lst-ctn-kix_vgg0538grxk3-8}.lst-kix_84zf7o74c8s9-6>li:before{content:"" counter(lst-ctn-kix_84zf7o74c8s9-6,decimal) ". "}.lst-kix_6217r3mhjywx-4>li:before{content:"-  "}ul.lst-kix_owvy3cstzf0s-2{list-style-type:none}ul.lst-kix_owvy3cstzf0s-3{list-style-type:none}ul.lst-kix_owvy3cstzf0s-4{list-style-type:none}ul.lst-kix_owvy3cstzf0s-5{list-style-type:none}ul.lst-kix_owvy3cstzf0s-0{list-style-type:none}.lst-kix_tlnfkrylyq1a-2>li:before{content:"-  "}ul.lst-kix_owvy3cstzf0s-1{list-style-type:none}ul.lst-kix_owvy3cstzf0s-6{list-style-type:none}.lst-kix_5djgwp8c9ig2-8>li{counter-increment:lst-ctn-kix_5djgwp8c9ig2-8}ul.lst-kix_owvy3cstzf0s-7{list-style-type:none}.lst-kix_2agzfikyhf8k-4>li:before{content:"-  "}ul.lst-kix_owvy3cstzf0s-8{list-style-type:none}.lst-kix_ht80gp8jxjfs-4>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-6>li{counter-increment:lst-ctn-kix_u8nobwiguyj1-6}.lst-kix_yob9gooqotb-1>li:before{content:"-  "}.lst-kix_tekivzgenz72-5>li:before{content:"-  "}ol.lst-kix_xktbtduo53bq-8.start{counter-reset:lst-ctn-kix_xktbtduo53bq-8 0}.lst-kix_g02ta87c1sqh-0>li:before{content:"\0025cf   "}.lst-kix_vkdxjlf0kb6j-8>li:before{content:"" counter(lst-ctn-kix_vkdxjlf0kb6j-8,lower-roman) ". "}.lst-kix_wf1o55flzq55-7>li:before{content:"-  "}.lst-kix_brqn5pq4e7i7-0>li:before{content:"-  "}.lst-kix_tvu7bmfefz32-8>li:before{content:"-  "}.lst-kix_f83agu4s4fw5-6>li:before{content:"-  "}.lst-kix_z6rr709h3fky-5>li:before{content:"-  "}.lst-kix_f2t507a7xjue-0>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-2>li{counter-increment:lst-ctn-kix_yjf6dvvoob64-2}.lst-kix_v6dv769q7bq3-5>li:before{content:"-  "}ol.lst-kix_xktbtduo53bq-7.start{counter-reset:lst-ctn-kix_xktbtduo53bq-7 0}.lst-kix_incqcf2p39ls-5>li{counter-increment:lst-ctn-kix_incqcf2p39ls-5}.lst-kix_u8nobwiguyj1-0>li{counter-increment:lst-ctn-kix_u8nobwiguyj1-0}ul.lst-kix_932mko8sjg0u-0{list-style-type:none}ul.lst-kix_932mko8sjg0u-1{list-style-type:none}ul.lst-kix_932mko8sjg0u-2{list-style-type:none}.lst-kix_vayf18aqt55o-4>li{counter-increment:lst-ctn-kix_vayf18aqt55o-4}ul.lst-kix_932mko8sjg0u-3{list-style-type:none}ul.lst-kix_xhhdon4tpeu0-4{list-style-type:none}ul.lst-kix_932mko8sjg0u-4{list-style-type:none}ul.lst-kix_xhhdon4tpeu0-5{list-style-type:none}ul.lst-kix_932mko8sjg0u-5{list-style-type:none}ul.lst-kix_xhhdon4tpeu0-2{list-style-type:none}ul.lst-kix_932mko8sjg0u-6{list-style-type:none}ul.lst-kix_xhhdon4tpeu0-3{list-style-type:none}ul.lst-kix_932mko8sjg0u-7{list-style-type:none}ul.lst-kix_xhhdon4tpeu0-0{list-style-type:none}ul.lst-kix_932mko8sjg0u-8{list-style-type:none}ul.lst-kix_xhhdon4tpeu0-1{list-style-type:none}.lst-kix_vuz55xpe5xjl-1>li:before{content:"-  "}.lst-kix_yvohqcnu3146-8>li:before{content:"" counter(lst-ctn-kix_yvohqcnu3146-8,lower-roman) ". "}.lst-kix_r8azi25kh461-6>li:before{content:"\0025cf   "}.lst-kix_kzw7lb63578w-6>li:before{content:"-  "}.lst-kix_p1rtf0e14360-4>li:before{content:"-  "}.lst-kix_4uak8dkv6vr8-6>li:before{content:"-  "}.lst-kix_6xh4bfg7mbxi-0>li:before{content:"-  "}.lst-kix_dyq7vlcdkqm5-6>li:before{content:"-  "}.lst-kix_67mv29rpwb23-0>li:before{content:"-  "}ol.lst-kix_xyra4e5ffsud-4.start{counter-reset:lst-ctn-kix_xyra4e5ffsud-4 0}.lst-kix_1pt1eqcq4ieh-2>li:before{content:"-  "}.lst-kix_gerk886qza0c-6>li:before{content:"-  "}.lst-kix_1pt1eqcq4ieh-5>li:before{content:"-  "}.lst-kix_urqiwn6svi1d-8>li:before{content:"-  "}.lst-kix_nlsa7flowwa1-4>li:before{content:"+  "}.lst-kix_w32pgwk3f0lb-2>li:before{content:"-  "}.lst-kix_mkfigeky21iv-3>li:before{content:"-  "}.lst-kix_waivoqs1cu5x-6>li:before{content:"-  "}ul.lst-kix_5l84eporjaw3-1{list-style-type:none}ul.lst-kix_5l84eporjaw3-2{list-style-type:none}ul.lst-kix_5l84eporjaw3-3{list-style-type:none}ul.lst-kix_5l84eporjaw3-4{list-style-type:none}.lst-kix_fifu4bguh6qm-5>li:before{content:"-  "}.lst-kix_11d94ps4c7wj-7>li:before{content:"-  "}ul.lst-kix_5l84eporjaw3-0{list-style-type:none}.lst-kix_d1gy3hy5r3qj-2>li{counter-increment:lst-ctn-kix_d1gy3hy5r3qj-2}ul.lst-kix_5l84eporjaw3-5{list-style-type:none}ul.lst-kix_5l84eporjaw3-6{list-style-type:none}ul.lst-kix_5l84eporjaw3-7{list-style-type:none}ul.lst-kix_5l84eporjaw3-8{list-style-type:none}.lst-kix_iyje40sgs3ri-7>li:before{content:"-  "}.lst-kix_90bg3luq5inv-1>li{counter-increment:lst-ctn-kix_90bg3luq5inv-1}.lst-kix_3ez3vzcedsa0-4>li:before{content:"-  "}.lst-kix_3ez3vzcedsa0-7>li:before{content:"-  "}.lst-kix_fifu4bguh6qm-8>li:before{content:"-  "}ol.lst-kix_5stj9b6acoxv-7.start{counter-reset:lst-ctn-kix_5stj9b6acoxv-7 0}.lst-kix_14k5lhtsu41k-0>li:before{content:"-  "}ul.lst-kix_dln561wj05xo-3{list-style-type:none}ul.lst-kix_dln561wj05xo-2{list-style-type:none}.lst-kix_3qppsihuuk4z-4>li:before{content:"-  "}ul.lst-kix_dln561wj05xo-1{list-style-type:none}ul.lst-kix_dln561wj05xo-0{list-style-type:none}ul.lst-kix_dln561wj05xo-7{list-style-type:none}ul.lst-kix_dln561wj05xo-6{list-style-type:none}ul.lst-kix_dln561wj05xo-5{list-style-type:none}ul.lst-kix_dln561wj05xo-4{list-style-type:none}.lst-kix_bttl6bm2dx1a-5>li:before{content:"-  "}.lst-kix_6n4varno3bjs-8>li:before{content:"-  "}.lst-kix_ht80gp8jxjfs-7>li:before{content:"-  "}ul.lst-kix_ltm9vv1op5tt-0{list-style-type:none}ul.lst-kix_ltm9vv1op5tt-1{list-style-type:none}.lst-kix_fnlxcectz7fi-2>li:before{content:"-  "}ul.lst-kix_ltm9vv1op5tt-4{list-style-type:none}.lst-kix_qqbjjwnrc3l8-1>li:before{content:"-  "}ul.lst-kix_ltm9vv1op5tt-5{list-style-type:none}ul.lst-kix_ltm9vv1op5tt-2{list-style-type:none}ul.lst-kix_ltm9vv1op5tt-3{list-style-type:none}ul.lst-kix_ltm9vv1op5tt-8{list-style-type:none}ul.lst-kix_ltm9vv1op5tt-6{list-style-type:none}.lst-kix_hc732m8hksyq-0>li:before{content:"-  "}ul.lst-kix_ltm9vv1op5tt-7{list-style-type:none}.lst-kix_3ug9en49p7ih-6>li:before{content:"-  "}.lst-kix_tlnfkrylyq1a-5>li:before{content:"-  "}.lst-kix_tfqdu2hgmdym-6>li:before{content:"-  "}.lst-kix_l4d8unsm10a0-0>li:before{content:"-  "}.lst-kix_tpw8rt3jm7dt-5>li:before{content:"-  "}ul.lst-kix_ro388iryhhf5-8{list-style-type:none}.lst-kix_yob9gooqotb-4>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-1>li:before{content:"" counter(lst-ctn-kix_yjf6dvvoob64-1,lower-latin) ". "}ul.lst-kix_ro388iryhhf5-1{list-style-type:none}ul.lst-kix_ro388iryhhf5-0{list-style-type:none}ul.lst-kix_ro388iryhhf5-3{list-style-type:none}ul.lst-kix_ro388iryhhf5-2{list-style-type:none}ul.lst-kix_ro388iryhhf5-5{list-style-type:none}ul.lst-kix_ro388iryhhf5-4{list-style-type:none}.lst-kix_7dqsuv1cdvcc-6>li:before{content:"-  "}ul.lst-kix_ro388iryhhf5-7{list-style-type:none}ol.lst-kix_yjf6dvvoob64-2.start{counter-reset:lst-ctn-kix_yjf6dvvoob64-2 0}ul.lst-kix_ro388iryhhf5-6{list-style-type:none}.lst-kix_267f3xfv5ddr-5>li{counter-increment:lst-ctn-kix_267f3xfv5ddr-5}ul.lst-kix_xhhdon4tpeu0-8{list-style-type:none}ul.lst-kix_xhhdon4tpeu0-6{list-style-type:none}ol.lst-kix_xyra4e5ffsud-5.start{counter-reset:lst-ctn-kix_xyra4e5ffsud-5 0}ul.lst-kix_xhhdon4tpeu0-7{list-style-type:none}.lst-kix_wsu1hpz6hqq4-1>li:before{content:"-  "}.lst-kix_f2t507a7xjue-3>li:before{content:"-  "}.lst-kix_vkdxjlf0kb6j-3>li{counter-increment:lst-ctn-kix_vkdxjlf0kb6j-3}.lst-kix_o45gwpewsvxw-6>li:before{content:"-  "}.lst-kix_ny5e869gaylo-3>li:before{content:"-  "}.lst-kix_axwe0nze7yft-8>li:before{content:"-  "}ul.lst-kix_dln561wj05xo-8{list-style-type:none}.lst-kix_ob04lr2u335p-1>li:before{content:"-  "}.lst-kix_5djgwp8c9ig2-0>li:before{content:"" counter(lst-ctn-kix_5djgwp8c9ig2-0,decimal) ". "}ol.lst-kix_267f3xfv5ddr-5.start{counter-reset:lst-ctn-kix_267f3xfv5ddr-5 0}.lst-kix_spt2hfceke6p-5>li:before{content:"-  "}.lst-kix_r8adx85jg0iz-6>li:before{content:"-  "}.lst-kix_3wddikkjnk2k-3>li:before{content:"-  "}.lst-kix_kxjfd2xlpmu-2>li:before{content:"-  "}.lst-kix_17yxihawuh4r-1>li:before{content:"-  "}.lst-kix_g2uanok8rp1g-6>li:before{content:"-  "}.lst-kix_7e64bsb5krip-8>li:before{content:"-  "}.lst-kix_vvjhovkzyen7-1>li:before{content:"-  "}.lst-kix_rxevvtxfoovc-4>li:before{content:"-  "}.lst-kix_ivmzvkm69gsd-8>li:before{content:"-  "}.lst-kix_nqtgcebhe8ii-8>li:before{content:"-  "}.lst-kix_2xixyk6jteti-1>li:before{content:"-  "}.lst-kix_dmn3lqzfmokk-2>li:before{content:"-  "}ol.lst-kix_90bg3luq5inv-2.start{counter-reset:lst-ctn-kix_90bg3luq5inv-2 0}.lst-kix_7vaamq35f1cc-2>li:before{content:"-  "}.lst-kix_zb3jq278pptw-6>li:before{content:"-  "}.lst-kix_i7kvy3cw4vsq-6>li:before{content:"-  "}.lst-kix_x424ckbm5jp1-6>li:before{content:"-  "}.lst-kix_a9h81iclzrpy-1>li:before{content:"-  "}.lst-kix_fld6w0ks1f0p-5>li:before{content:"-  "}.lst-kix_90bg3luq5inv-4>li{counter-increment:lst-ctn-kix_90bg3luq5inv-4}.lst-kix_9j3np3ow732h-3>li:before{content:"\0025cf   "}.lst-kix_lcru2cdgc87j-1>li:before{content:"-  "}.lst-kix_x424ckbm5jp1-3>li:before{content:"-  "}.lst-kix_rxevvtxfoovc-1>li:before{content:"-  "}.lst-kix_8drpzle0jo7q-3>li:before{content:"\0025cf   "}.lst-kix_w21i9d12ynhg-0>li:before{content:"-  "}.lst-kix_lcru2cdgc87j-4>li:before{content:"-  "}.lst-kix_zjjx8lb18sy-0>li:before{content:"-  "}.lst-kix_fld6w0ks1f0p-8>li:before{content:"-  "}.lst-kix_spt2hfceke6p-2>li:before{content:"-  "}.lst-kix_vvjhovkzyen7-4>li:before{content:"-  "}ul.lst-kix_9hby2lis2y9u-0{list-style-type:none}ul.lst-kix_9hby2lis2y9u-1{list-style-type:none}ul.lst-kix_9hby2lis2y9u-2{list-style-type:none}ul.lst-kix_9hby2lis2y9u-3{list-style-type:none}.lst-kix_3qppsihuuk4z-1>li:before{content:"-  "}ol.lst-kix_23ct987xwu67-3.start{counter-reset:lst-ctn-kix_23ct987xwu67-3 0}ol.lst-kix_90bg3luq5inv-4.start{counter-reset:lst-ctn-kix_90bg3luq5inv-4 0}ul.lst-kix_kobinbwr4qr6-8{list-style-type:none}ul.lst-kix_kobinbwr4qr6-6{list-style-type:none}ul.lst-kix_kobinbwr4qr6-7{list-style-type:none}.lst-kix_ypd5gkkarijk-3>li{counter-increment:lst-ctn-kix_ypd5gkkarijk-3}.lst-kix_ok1n37qarjzb-2>li{counter-increment:lst-ctn-kix_ok1n37qarjzb-2}.lst-kix_iupg79bv69ia-5>li:before{content:"-  "}ul.lst-kix_9hby2lis2y9u-8{list-style-type:none}.lst-kix_incqcf2p39ls-7>li:before{content:"" counter(lst-ctn-kix_incqcf2p39ls-7,lower-latin) ". "}ul.lst-kix_9hby2lis2y9u-4{list-style-type:none}ul.lst-kix_9hby2lis2y9u-5{list-style-type:none}.lst-kix_267f3xfv5ddr-8>li{counter-increment:lst-ctn-kix_267f3xfv5ddr-8}.lst-kix_kobinbwr4qr6-2>li:before{content:"-  "}ul.lst-kix_9hby2lis2y9u-6{list-style-type:none}.lst-kix_tjrvr4c0ezjq-7>li:before{content:"-  "}ul.lst-kix_9hby2lis2y9u-7{list-style-type:none}ul.lst-kix_14k5lhtsu41k-3{list-style-type:none}ul.lst-kix_14k5lhtsu41k-2{list-style-type:none}ul.lst-kix_b3ghc04lfx9t-0{list-style-type:none}.lst-kix_tagzs2njqau3-4>li:before{content:"-  "}ul.lst-kix_14k5lhtsu41k-1{list-style-type:none}ul.lst-kix_14k5lhtsu41k-0{list-style-type:none}ul.lst-kix_14k5lhtsu41k-7{list-style-type:none}ul.lst-kix_b3ghc04lfx9t-3{list-style-type:none}.lst-kix_s9h4llxy1yy0-4>li:before{content:"-  "}ul.lst-kix_14k5lhtsu41k-6{list-style-type:none}ul.lst-kix_b3ghc04lfx9t-4{list-style-type:none}ul.lst-kix_14k5lhtsu41k-5{list-style-type:none}ul.lst-kix_b3ghc04lfx9t-1{list-style-type:none}.lst-kix_7vaamq35f1cc-5>li:before{content:"-  "}ul.lst-kix_14k5lhtsu41k-4{list-style-type:none}ul.lst-kix_b3ghc04lfx9t-2{list-style-type:none}ul.lst-kix_ksf6p4xm2w0d-6{list-style-type:none}ul.lst-kix_b3ghc04lfx9t-7{list-style-type:none}ul.lst-kix_ksf6p4xm2w0d-5{list-style-type:none}.lst-kix_l60gvbdij7aj-1>li:before{content:"-  "}ul.lst-kix_b3ghc04lfx9t-8{list-style-type:none}ul.lst-kix_ksf6p4xm2w0d-4{list-style-type:none}ul.lst-kix_b3ghc04lfx9t-5{list-style-type:none}ul.lst-kix_ksf6p4xm2w0d-3{list-style-type:none}.lst-kix_xhhdon4tpeu0-5>li:before{content:"-  "}ul.lst-kix_14k5lhtsu41k-8{list-style-type:none}ul.lst-kix_b3ghc04lfx9t-6{list-style-type:none}ul.lst-kix_ksf6p4xm2w0d-2{list-style-type:none}ul.lst-kix_ksf6p4xm2w0d-1{list-style-type:none}ul.lst-kix_ksf6p4xm2w0d-0{list-style-type:none}.lst-kix_69k4orytle42-6>li:before{content:"\0025cf   "}ul.lst-kix_kobinbwr4qr6-4{list-style-type:none}ul.lst-kix_kobinbwr4qr6-5{list-style-type:none}ul.lst-kix_kobinbwr4qr6-2{list-style-type:none}ul.lst-kix_kobinbwr4qr6-3{list-style-type:none}ul.lst-kix_kobinbwr4qr6-0{list-style-type:none}ul.lst-kix_kobinbwr4qr6-1{list-style-type:none}ul.lst-kix_ksf6p4xm2w0d-8{list-style-type:none}.lst-kix_ivmzvkm69gsd-5>li:before{content:"-  "}.lst-kix_n9qabngdxy64-8>li:before{content:"-  "}ul.lst-kix_ksf6p4xm2w0d-7{list-style-type:none}.lst-kix_xdqzm25ye8fb-3>li:before{content:"-  "}.lst-kix_tpw8rt3jm7dt-8>li:before{content:"-  "}ol.lst-kix_23ct987xwu67-1.start{counter-reset:lst-ctn-kix_23ct987xwu67-1 0}.lst-kix_x6hb6vgwujyx-7>li:before{content:"-  "}.lst-kix_267f3xfv5ddr-4>li:before{content:"" counter(lst-ctn-kix_267f3xfv5ddr-4,lower-latin) ". "}.lst-kix_epyrmry7301m-8>li:before{content:"-  "}.lst-kix_66ns622ckygr-6>li:before{content:"-  "}.lst-kix_p2dhxl6hicde-3>li:before{content:"-  "}.lst-kix_5ze5xofgghz2-6>li:before{content:"-  "}.lst-kix_7dqsuv1cdvcc-3>li:before{content:"-  "}.lst-kix_5argtotmwusw-3>li:before{content:"-  "}.lst-kix_4voxeic75vm5-4>li:before{content:"-  "}.lst-kix_vayf18aqt55o-7>li{counter-increment:lst-ctn-kix_vayf18aqt55o-7}.lst-kix_r9s6df60is49-2>li:before{content:"-  "}.lst-kix_upq3ni6ul8eb-6>li:before{content:"-  "}.lst-kix_xs6xjhigrbe2-5>li:before{content:"-  "}.lst-kix_wsu1hpz6hqq4-4>li:before{content:"-  "}.lst-kix_vkdxjlf0kb6j-0>li{counter-increment:lst-ctn-kix_vkdxjlf0kb6j-0}.lst-kix_a42anijqpp8a-8>li:before{content:"-  "}.lst-kix_vgg0538grxk3-2>li{counter-increment:lst-ctn-kix_vgg0538grxk3-2}.lst-kix_3bnqwg68tpm3-1>li:before{content:"-  "}.lst-kix_3bnqwg68tpm3-4>li:before{content:"-  "}.lst-kix_hyuyjld7ihkv-7>li:before{content:"-  "}ul.lst-kix_y32h08wggx1t-0{list-style-type:none}.lst-kix_4ii5776egvw8-4>li:before{content:"-  "}ul.lst-kix_y32h08wggx1t-4{list-style-type:none}.lst-kix_mtm8lwd6vxjl-1>li:before{content:"-  "}ul.lst-kix_y32h08wggx1t-3{list-style-type:none}ul.lst-kix_y32h08wggx1t-2{list-style-type:none}ul.lst-kix_y32h08wggx1t-1{list-style-type:none}.lst-kix_mtm8lwd6vxjl-4>li:before{content:"-  "}.lst-kix_l5iaj94ondn3-0>li:before{content:"-  "}.lst-kix_onvme58enb43-7>li:before{content:"-  "}.lst-kix_g47hwi8ilj0t-2>li:before{content:"-  "}.lst-kix_yvohqcnu3146-6>li{counter-increment:lst-ctn-kix_yvohqcnu3146-6}ul.lst-kix_y32h08wggx1t-8{list-style-type:none}ul.lst-kix_y32h08wggx1t-7{list-style-type:none}ul.lst-kix_y32h08wggx1t-6{list-style-type:none}ul.lst-kix_y32h08wggx1t-5{list-style-type:none}.lst-kix_onvme58enb43-4>li:before{content:"-  "}.lst-kix_4ii5776egvw8-1>li:before{content:"-  "}.lst-kix_1x319pprarxc-6>li:before{content:"-  "}.lst-kix_p1rtf0e14360-7>li:before{content:"-  "}.lst-kix_5djgwp8c9ig2-2>li{counter-increment:lst-ctn-kix_5djgwp8c9ig2-2}.lst-kix_1x319pprarxc-3>li:before{content:"-  "}.lst-kix_waivoqs1cu5x-3>li:before{content:"-  "}.lst-kix_kzw7lb63578w-3>li:before{content:"-  "}.lst-kix_66ns622ckygr-3>li:before{content:"-  "}.lst-kix_8w03xjt2k9bc-7>li:before{content:"-  "}.lst-kix_gerk886qza0c-3>li:before{content:"-  "}.lst-kix_c7r1s55bmbei-8>li:before{content:"-  "}.lst-kix_7cboi17aj4i3-1>li:before{content:"-  "}.lst-kix_qbfnanuzy3l5-1>li:before{content:"-  "}.lst-kix_w32pgwk3f0lb-5>li:before{content:"-  "}.lst-kix_7cboi17aj4i3-4>li:before{content:"-  "}.lst-kix_4ypcpsaj0q6h-0>li:before{content:"-  "}.lst-kix_mjig28how5ag-2>li:before{content:"-  "}.lst-kix_14k5lhtsu41k-3>li:before{content:"-  "}.lst-kix_cg6jep1fmawj-5>li:before{content:"-  "}.lst-kix_90bg3luq5inv-7>li{counter-increment:lst-ctn-kix_90bg3luq5inv-7}ul.lst-kix_mh5zhf27i4rj-3{list-style-type:none}.lst-kix_8pn77unkg8hg-3>li:before{content:"-  "}ul.lst-kix_mh5zhf27i4rj-4{list-style-type:none}ul.lst-kix_mh5zhf27i4rj-5{list-style-type:none}.lst-kix_hyuyjld7ihkv-4>li:before{content:"-  "}ul.lst-kix_mh5zhf27i4rj-6{list-style-type:none}ul.lst-kix_mh5zhf27i4rj-7{list-style-type:none}ul.lst-kix_mh5zhf27i4rj-8{list-style-type:none}.lst-kix_8pn77unkg8hg-0>li:before{content:"-  "}.lst-kix_4ypcpsaj0q6h-3>li:before{content:"-  "}ul.lst-kix_mh5zhf27i4rj-0{list-style-type:none}ul.lst-kix_mh5zhf27i4rj-1{list-style-type:none}ul.lst-kix_mh5zhf27i4rj-2{list-style-type:none}.lst-kix_d94n7or3b41v-7>li:before{content:"-  "}.lst-kix_o7acnutkhp1w-8>li:before{content:"-  "}.lst-kix_ssze0kg2kz13-8>li:before{content:"-  "}.lst-kix_ekasiajyrrvz-7>li:before{content:"-  "}.lst-kix_7vvt5hs6rdl-2>li:before{content:"-  "}.lst-kix_v9cryi9ybo1n-4>li:before{content:"\0025cb   "}ul.lst-kix_o328viitwjyp-6{list-style-type:none}ul.lst-kix_o328viitwjyp-5{list-style-type:none}ul.lst-kix_o328viitwjyp-4{list-style-type:none}ul.lst-kix_o328viitwjyp-3{list-style-type:none}ul.lst-kix_o328viitwjyp-2{list-style-type:none}.lst-kix_69k4orytle42-3>li:before{content:"\0025cf   "}ul.lst-kix_o328viitwjyp-1{list-style-type:none}.lst-kix_l60gvbdij7aj-4>li:before{content:"-  "}ul.lst-kix_o328viitwjyp-0{list-style-type:none}.lst-kix_x95t913s41kt-0>li:before{content:"-  "}.lst-kix_i8kfgvsh0fwy-8>li:before{content:"-  "}.lst-kix_6217r3mhjywx-7>li:before{content:"-  "}.lst-kix_mjig28how5ag-5>li:before{content:"-  "}.lst-kix_npanryo7f1m7-0>li:before{content:"-  "}.lst-kix_ugixx4nd67zw-2>li:before{content:"-  "}.lst-kix_tagzs2njqau3-1>li:before{content:"-  "}ul.lst-kix_o328viitwjyp-8{list-style-type:none}.lst-kix_py2swxy3gr0i-8>li:before{content:"-  "}ul.lst-kix_o328viitwjyp-7{list-style-type:none}.lst-kix_2agzfikyhf8k-1>li:before{content:"-  "}ol.lst-kix_ypd5gkkarijk-3{list-style-type:none}ol.lst-kix_ypd5gkkarijk-4{list-style-type:none}ol.lst-kix_ypd5gkkarijk-1{list-style-type:none}ol.lst-kix_ypd5gkkarijk-2{list-style-type:none}ol.lst-kix_ypd5gkkarijk-0{list-style-type:none}.lst-kix_ukx3y28hag8h-7>li:before{content:"-  "}.lst-kix_co74fk70kphx-1>li:before{content:"-  "}.lst-kix_8hvuzyuchy3p-6>li:before{content:"-  "}ol.lst-kix_267f3xfv5ddr-4.start{counter-reset:lst-ctn-kix_267f3xfv5ddr-4 0}.lst-kix_n9qabngdxy64-5>li:before{content:"-  "}ol.lst-kix_ypd5gkkarijk-7{list-style-type:none}ol.lst-kix_ypd5gkkarijk-8{list-style-type:none}ol.lst-kix_ypd5gkkarijk-5{list-style-type:none}ol.lst-kix_t3rn73qejgkj-5.start{counter-reset:lst-ctn-kix_t3rn73qejgkj-5 0}ol.lst-kix_ypd5gkkarijk-6{list-style-type:none}.lst-kix_xhhdon4tpeu0-2>li:before{content:"-  "}ul.lst-kix_v0hsa7m5lywt-6{list-style-type:none}.lst-kix_267f3xfv5ddr-1>li:before{content:"" counter(lst-ctn-kix_267f3xfv5ddr-1,lower-latin) ". "}ul.lst-kix_v0hsa7m5lywt-7{list-style-type:none}ul.lst-kix_v0hsa7m5lywt-4{list-style-type:none}ul.lst-kix_v0hsa7m5lywt-5{list-style-type:none}ul.lst-kix_v0hsa7m5lywt-8{list-style-type:none}.lst-kix_ypd5gkkarijk-0>li{counter-increment:lst-ctn-kix_ypd5gkkarijk-0}.lst-kix_p2dhxl6hicde-0>li:before{content:"-  "}.lst-kix_upq3ni6ul8eb-3>li:before{content:"-  "}.lst-kix_alhag51wggig-1>li:before{content:"-  "}.lst-kix_hytfj9icha07-6>li:before{content:"-  "}ul.lst-kix_v0hsa7m5lywt-2{list-style-type:none}ul.lst-kix_v0hsa7m5lywt-3{list-style-type:none}ul.lst-kix_v0hsa7m5lywt-0{list-style-type:none}.lst-kix_vgg0538grxk3-5>li{counter-increment:lst-ctn-kix_vgg0538grxk3-5}ul.lst-kix_v0hsa7m5lywt-1{list-style-type:none}.lst-kix_5jp9wppv00ra-8>li:before{content:"-  "}.lst-kix_4voxeic75vm5-7>li:before{content:"-  "}.lst-kix_awlaex77cpwh-7>li:before{content:"-  "}.lst-kix_a42anijqpp8a-5>li:before{content:"-  "}.lst-kix_aikphwux0ki0-8>li:before{content:"-  "}.lst-kix_v0hsa7m5lywt-7>li:before{content:"-  "}.lst-kix_rcfi5jnwnxji-5>li:before{content:"-  "}.lst-kix_bnte1i3g4kjh-6>li:before{content:"-  "}.lst-kix_cwjen7nun640-0>li:before{content:"-  "}.lst-kix_2r20t3tmnrwb-8>li:before{content:"-  "}.lst-kix_1v1216yy0n25-0>li:before{content:"-  "}.lst-kix_cwjen7nun640-2>li:before{content:"-  "}.lst-kix_2r20t3tmnrwb-6>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-5.start{counter-reset:lst-ctn-kix_d1gy3hy5r3qj-5 0}.lst-kix_4i10vbfgn91y-1>li:before{content:"-  "}.lst-kix_ofib0hkczw41-2>li:before{content:"-  "}.lst-kix_4i10vbfgn91y-7>li:before{content:"-  "}.lst-kix_w97kncqyzxj3-8>li:before{content:"\0025a0   "}.lst-kix_7vr84ges94ry-4>li:before{content:"-  "}ol.lst-kix_52jgzw489fhs-3.start{counter-reset:lst-ctn-kix_52jgzw489fhs-3 0}.lst-kix_g8jgbze430sv-6>li:before{content:"" counter(lst-ctn-kix_g8jgbze430sv-6,decimal) ". "}.lst-kix_6o2cphkh2n8b-8>li:before{content:"-  "}.lst-kix_hmvj5t8yy8bx-1>li:before{content:"+  "}.lst-kix_2r20t3tmnrwb-0>li:before{content:"-  "}.lst-kix_ug10x97qcpi8-7>li:before{content:"-  "}.lst-kix_ul22dko4fd2j-5>li:before{content:"-  "}ul.lst-kix_11d94ps4c7wj-5{list-style-type:none}ul.lst-kix_11d94ps4c7wj-4{list-style-type:none}ul.lst-kix_11d94ps4c7wj-7{list-style-type:none}ul.lst-kix_11d94ps4c7wj-6{list-style-type:none}.lst-kix_4xiv877yc8jl-5>li:before{content:"-  "}ul.lst-kix_11d94ps4c7wj-1{list-style-type:none}ul.lst-kix_11d94ps4c7wj-0{list-style-type:none}ul.lst-kix_11d94ps4c7wj-3{list-style-type:none}.lst-kix_n9q8wqas57a-5>li:before{content:"-  "}ul.lst-kix_11d94ps4c7wj-2{list-style-type:none}.lst-kix_4xiv877yc8jl-3>li:before{content:"-  "}.lst-kix_6o2cphkh2n8b-2>li:before{content:"-  "}.lst-kix_ug10x97qcpi8-1>li:before{content:"-  "}.lst-kix_dvvzixfw64a1-2>li:before{content:"-  "}.lst-kix_g8jgbze430sv-8>li:before{content:"" counter(lst-ctn-kix_g8jgbze430sv-8,lower-roman) ". "}.lst-kix_svg8hnl23b1r-4>li:before{content:"-  "}.lst-kix_8ujam3zhcr3q-1>li:before{content:"-  "}.lst-kix_3nq914pozpi7-5>li:before{content:"-  "}.lst-kix_3nq914pozpi7-3>li:before{content:"-  "}.lst-kix_x8ffawrvrcyq-6>li:before{content:"\0025cf   "}.lst-kix_gaq1zvh4dcgb-0>li:before{content:"-  "}ul.lst-kix_wzt7symqmcfu-1{list-style-type:none}ul.lst-kix_wzt7symqmcfu-0{list-style-type:none}ul.lst-kix_wzt7symqmcfu-3{list-style-type:none}ul.lst-kix_wzt7symqmcfu-2{list-style-type:none}.lst-kix_tt1bo8z9re67-1>li:before{content:"-  "}.lst-kix_x8ffawrvrcyq-4>li:before{content:"\0025cb   "}ul.lst-kix_wzt7symqmcfu-8{list-style-type:none}ul.lst-kix_wzt7symqmcfu-5{list-style-type:none}ul.lst-kix_wzt7symqmcfu-4{list-style-type:none}ul.lst-kix_wzt7symqmcfu-7{list-style-type:none}.lst-kix_co74fk70kphx-7>li:before{content:"-  "}ul.lst-kix_wzt7symqmcfu-6{list-style-type:none}.lst-kix_2foc6u9lzfq4-0>li:before{content:"" counter(lst-ctn-kix_2foc6u9lzfq4-0,decimal) ". "}ol.lst-kix_2foc6u9lzfq4-3.start{counter-reset:lst-ctn-kix_2foc6u9lzfq4-3 0}.lst-kix_tdrf79x9zyr7-4>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-8>li{counter-increment:lst-ctn-kix_ypd5gkkarijk-8}.lst-kix_hmvj5t8yy8bx-7>li:before{content:"+  "}.lst-kix_4qbfcta6cclt-1>li:before{content:"-  "}.lst-kix_mv77cg19299c-8>li:before{content:"-  "}ol.lst-kix_azgj6sn0lxuj-0.start{counter-reset:lst-ctn-kix_azgj6sn0lxuj-0 0}.lst-kix_lwlxuymndfyq-6>li:before{content:"-  "}.lst-kix_tt1bo8z9re67-7>li:before{content:"-  "}.lst-kix_gaq1zvh4dcgb-6>li:before{content:"-  "}.lst-kix_8w7txqc6xq66-1>li:before{content:"-  "}.lst-kix_a2xq56ushw0p-0>li:before{content:"-  "}.lst-kix_o1voy78o4juz-1>li:before{content:"-  "}.lst-kix_xx6ude5yqnkl-7>li:before{content:"\0025cb   "}ul.lst-kix_yob9gooqotb-5{list-style-type:none}.lst-kix_np9h4y3kt4yk-6>li:before{content:"-  "}ul.lst-kix_yob9gooqotb-6{list-style-type:none}ul.lst-kix_yob9gooqotb-3{list-style-type:none}ul.lst-kix_yob9gooqotb-4{list-style-type:none}.lst-kix_rrloltks13s-7>li:before{content:"-  "}.lst-kix_6pgojrjbxqei-1>li:before{content:"\0025cb   "}.lst-kix_jfoqdfq6uhww-5>li:before{content:"-  "}.lst-kix_35hvjwgc3k2f-8>li:before{content:"-  "}ul.lst-kix_yob9gooqotb-7{list-style-type:none}ul.lst-kix_yob9gooqotb-8{list-style-type:none}.lst-kix_v0hsa7m5lywt-2>li:before{content:"-  "}.lst-kix_a2xq56ushw0p-6>li:before{content:"-  "}ul.lst-kix_yob9gooqotb-1{list-style-type:none}ul.lst-kix_yob9gooqotb-2{list-style-type:none}.lst-kix_35hvjwgc3k2f-2>li:before{content:"-  "}ul.lst-kix_yob9gooqotb-0{list-style-type:none}.lst-kix_py2swxy3gr0i-5>li:before{content:"-  "}.lst-kix_8euewcidoez8-5>li:before{content:"-  "}.lst-kix_xx6ude5yqnkl-1>li:before{content:"\0025cb   "}.lst-kix_arcio13zm8ud-3>li:before{content:"-  "}.lst-kix_bswxvn1l22fp-0>li:before{content:"-  "}ol.lst-kix_sxixw4iqsgzx-3{list-style-type:none}ol.lst-kix_sxixw4iqsgzx-2{list-style-type:none}ol.lst-kix_sxixw4iqsgzx-1{list-style-type:none}.lst-kix_6u6or33vx86s-1>li:before{content:"-  "}.lst-kix_tc7vpn5ce0ra-3>li:before{content:"-  "}ol.lst-kix_sxixw4iqsgzx-0{list-style-type:none}ol.lst-kix_sxixw4iqsgzx-7{list-style-type:none}ol.lst-kix_sxixw4iqsgzx-6{list-style-type:none}ol.lst-kix_sxixw4iqsgzx-5{list-style-type:none}ol.lst-kix_sxixw4iqsgzx-4{list-style-type:none}.lst-kix_tc7vpn5ce0ra-5>li:before{content:"-  "}ol.lst-kix_sxixw4iqsgzx-8{list-style-type:none}ul.lst-kix_co74fk70kphx-4{list-style-type:none}.lst-kix_vayf18aqt55o-1>li:before{content:"" counter(lst-ctn-kix_vayf18aqt55o-1,lower-roman) ") "}.lst-kix_wnr3c516ni7j-6>li:before{content:"-  "}ul.lst-kix_co74fk70kphx-3{list-style-type:none}ul.lst-kix_co74fk70kphx-2{list-style-type:none}.lst-kix_tw1wz6pba43e-3>li:before{content:"-  "}ul.lst-kix_co74fk70kphx-1{list-style-type:none}ul.lst-kix_co74fk70kphx-0{list-style-type:none}.lst-kix_rrloltks13s-1>li:before{content:"-  "}.lst-kix_rt3ua1vpzay9-5>li:before{content:"-  "}.lst-kix_6m4qu83yomn7-4>li:before{content:"-  "}.lst-kix_yhq927c05ak0-6>li:before{content:"-  "}.lst-kix_6ltb10qoez57-6>li:before{content:"\0025cf   "}ul.lst-kix_m5azvtuvtpt1-3{list-style-type:none}ul.lst-kix_m5azvtuvtpt1-2{list-style-type:none}ul.lst-kix_m5azvtuvtpt1-1{list-style-type:none}ul.lst-kix_m5azvtuvtpt1-0{list-style-type:none}ul.lst-kix_m5azvtuvtpt1-7{list-style-type:none}ul.lst-kix_co74fk70kphx-8{list-style-type:none}ul.lst-kix_m5azvtuvtpt1-6{list-style-type:none}ul.lst-kix_11d94ps4c7wj-8{list-style-type:none}ul.lst-kix_co74fk70kphx-7{list-style-type:none}ul.lst-kix_m5azvtuvtpt1-5{list-style-type:none}ul.lst-kix_co74fk70kphx-6{list-style-type:none}ul.lst-kix_m5azvtuvtpt1-4{list-style-type:none}ul.lst-kix_co74fk70kphx-5{list-style-type:none}.lst-kix_g8jgbze430sv-0>li:before{content:"" counter(lst-ctn-kix_g8jgbze430sv-0,decimal) ") "}ol.lst-kix_sxixw4iqsgzx-1.start{counter-reset:lst-ctn-kix_sxixw4iqsgzx-1 0}.lst-kix_j60wooaeanf9-2>li:before{content:"-  "}.lst-kix_vayf18aqt55o-1>li{counter-increment:lst-ctn-kix_vayf18aqt55o-1}.lst-kix_l5iaj94ondn3-5>li:before{content:"-  "}.lst-kix_w97kncqyzxj3-0>li:before{content:"\0025cf   "}ul.lst-kix_dynlpr2uwt2p-6{list-style-type:none}ul.lst-kix_dynlpr2uwt2p-7{list-style-type:none}ul.lst-kix_dynlpr2uwt2p-8{list-style-type:none}ul.lst-kix_dynlpr2uwt2p-2{list-style-type:none}.lst-kix_vkdxjlf0kb6j-6>li{counter-increment:lst-ctn-kix_vkdxjlf0kb6j-6}ul.lst-kix_dynlpr2uwt2p-3{list-style-type:none}.lst-kix_qmryaqe19okh-3>li:before{content:"-  "}ul.lst-kix_dynlpr2uwt2p-4{list-style-type:none}ul.lst-kix_dynlpr2uwt2p-5{list-style-type:none}.lst-kix_cwjen7nun640-8>li:before{content:"-  "}.lst-kix_bswxvn1l22fp-6>li:before{content:"-  "}ul.lst-kix_dynlpr2uwt2p-0{list-style-type:none}.lst-kix_w97kncqyzxj3-6>li:before{content:"\0025cf   "}ul.lst-kix_dynlpr2uwt2p-1{list-style-type:none}ul.lst-kix_awt45k7p90je-2{list-style-type:none}.lst-kix_hsahb38tz2f5-5>li:before{content:"-  "}ul.lst-kix_awt45k7p90je-3{list-style-type:none}ul.lst-kix_awt45k7p90je-4{list-style-type:none}ul.lst-kix_m5azvtuvtpt1-8{list-style-type:none}ul.lst-kix_awt45k7p90je-5{list-style-type:none}.lst-kix_a2xq56ushw0p-8>li:before{content:"-  "}.lst-kix_bswxvn1l22fp-8>li:before{content:"-  "}ul.lst-kix_awt45k7p90je-6{list-style-type:none}ul.lst-kix_awt45k7p90je-7{list-style-type:none}ul.lst-kix_awt45k7p90je-8{list-style-type:none}.lst-kix_3fc7x0lm2mmz-0>li{counter-increment:lst-ctn-kix_3fc7x0lm2mmz-0}.lst-kix_hsahb38tz2f5-3>li:before{content:"-  "}ul.lst-kix_awt45k7p90je-0{list-style-type:none}ul.lst-kix_awt45k7p90je-1{list-style-type:none}ol.lst-kix_hppu19i8fr2p-0.start{counter-reset:lst-ctn-kix_hppu19i8fr2p-0 0}.lst-kix_vie3q5oyli2z-3>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-3>li{counter-increment:lst-ctn-kix_3mj3tp7kj9db-3}.lst-kix_5syfdd8x3l8s-0>li:before{content:"-  "}.lst-kix_3i5qlhg977l0-3>li:before{content:"-  "}ol.lst-kix_5stj9b6acoxv-8.start{counter-reset:lst-ctn-kix_5stj9b6acoxv-8 0}.lst-kix_dynlpr2uwt2p-6>li:before{content:"-  "}.lst-kix_4ii5776egvw8-7>li:before{content:"-  "}ol.lst-kix_vgg0538grxk3-7.start{counter-reset:lst-ctn-kix_vgg0538grxk3-7 0}.lst-kix_qzg09ck6gr7w-5>li:before{content:"-  "}.lst-kix_ozrjmre97pex-2>li:before{content:"-  "}.lst-kix_x74x9xa8n5a0-1>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-2>li:before{content:"" counter(lst-ctn-kix_ok1n37qarjzb-2,decimal) ") "}.lst-kix_932mko8sjg0u-4>li:before{content:"-  "}.lst-kix_fmkfhvl8yhfs-4>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-8>li{counter-increment:lst-ctn-kix_2foc6u9lzfq4-8}.lst-kix_8hf94791m5p0-7>li:before{content:"-  "}.lst-kix_oxgbebk5l98i-6>li:before{content:"-  "}ul.lst-kix_kxjfd2xlpmu-2{list-style-type:none}ul.lst-kix_kxjfd2xlpmu-3{list-style-type:none}ul.lst-kix_kxjfd2xlpmu-0{list-style-type:none}ul.lst-kix_kxjfd2xlpmu-1{list-style-type:none}ul.lst-kix_kxjfd2xlpmu-6{list-style-type:none}ul.lst-kix_kxjfd2xlpmu-7{list-style-type:none}ul.lst-kix_kxjfd2xlpmu-4{list-style-type:none}.lst-kix_ykhrv7u6blcs-6>li:before{content:"-  "}ul.lst-kix_kxjfd2xlpmu-5{list-style-type:none}.lst-kix_ykhoydml7pv3-5>li:before{content:"(" counter(lst-ctn-kix_ykhoydml7pv3-5,lower-roman) ") "}ul.lst-kix_kxjfd2xlpmu-8{list-style-type:none}.lst-kix_y32h08wggx1t-4>li:before{content:"-  "}ul.lst-kix_wnr3c516ni7j-8{list-style-type:none}ul.lst-kix_q7gxc7al9t7n-2{list-style-type:none}ul.lst-kix_8hf94791m5p0-0{list-style-type:none}ul.lst-kix_q7gxc7al9t7n-1{list-style-type:none}ul.lst-kix_8hf94791m5p0-1{list-style-type:none}ul.lst-kix_5jp9wppv00ra-0{list-style-type:none}ul.lst-kix_q7gxc7al9t7n-4{list-style-type:none}ul.lst-kix_8hf94791m5p0-2{list-style-type:none}ul.lst-kix_q7gxc7al9t7n-3{list-style-type:none}ul.lst-kix_5jp9wppv00ra-2{list-style-type:none}ul.lst-kix_wnr3c516ni7j-4{list-style-type:none}ul.lst-kix_q7gxc7al9t7n-6{list-style-type:none}.lst-kix_df6s37r8voak-6>li:before{content:"-  "}ul.lst-kix_5jp9wppv00ra-1{list-style-type:none}ul.lst-kix_wnr3c516ni7j-5{list-style-type:none}ul.lst-kix_q7gxc7al9t7n-5{list-style-type:none}ul.lst-kix_5jp9wppv00ra-4{list-style-type:none}ul.lst-kix_wnr3c516ni7j-6{list-style-type:none}.lst-kix_b3ghc04lfx9t-8>li:before{content:"-  "}ul.lst-kix_q7gxc7al9t7n-8{list-style-type:none}.lst-kix_8w03xjt2k9bc-4>li:before{content:"-  "}ul.lst-kix_5jp9wppv00ra-3{list-style-type:none}ul.lst-kix_wnr3c516ni7j-7{list-style-type:none}ul.lst-kix_q7gxc7al9t7n-7{list-style-type:none}ul.lst-kix_8hf94791m5p0-7{list-style-type:none}ul.lst-kix_8hf94791m5p0-8{list-style-type:none}.lst-kix_c7r1s55bmbei-2>li:before{content:"-  "}ul.lst-kix_8hf94791m5p0-3{list-style-type:none}ul.lst-kix_8hf94791m5p0-4{list-style-type:none}.lst-kix_wnr3c516ni7j-4>li:before{content:"-  "}ul.lst-kix_8hf94791m5p0-5{list-style-type:none}ul.lst-kix_q7gxc7al9t7n-0{list-style-type:none}ul.lst-kix_8hf94791m5p0-6{list-style-type:none}ul.lst-kix_skgpgvhmuoc4-8{list-style-type:none}.lst-kix_6vg5692ogph-6>li:before{content:"-  "}ul.lst-kix_skgpgvhmuoc4-7{list-style-type:none}ul.lst-kix_skgpgvhmuoc4-6{list-style-type:none}ul.lst-kix_skgpgvhmuoc4-5{list-style-type:none}.lst-kix_eiskzjj27gc6-0>li:before{content:"-  "}.lst-kix_tw1wz6pba43e-5>li:before{content:"-  "}ul.lst-kix_skgpgvhmuoc4-4{list-style-type:none}ul.lst-kix_skgpgvhmuoc4-3{list-style-type:none}ul.lst-kix_skgpgvhmuoc4-2{list-style-type:none}ul.lst-kix_skgpgvhmuoc4-1{list-style-type:none}ul.lst-kix_5jp9wppv00ra-6{list-style-type:none}ul.lst-kix_5jp9wppv00ra-5{list-style-type:none}ul.lst-kix_5jp9wppv00ra-8{list-style-type:none}ul.lst-kix_5jp9wppv00ra-7{list-style-type:none}.lst-kix_22zpsclbl6ju-2>li:before{content:"-  "}.lst-kix_zag3ymt8mk2y-1>li:before{content:"-  "}ul.lst-kix_b7rulpv7obgl-8{list-style-type:none}ul.lst-kix_b7rulpv7obgl-4{list-style-type:none}ul.lst-kix_b7rulpv7obgl-5{list-style-type:none}ul.lst-kix_b7rulpv7obgl-6{list-style-type:none}ul.lst-kix_b7rulpv7obgl-7{list-style-type:none}ul.lst-kix_skgpgvhmuoc4-0{list-style-type:none}.lst-kix_tagzs2njqau3-7>li:before{content:"-  "}ul.lst-kix_b7rulpv7obgl-0{list-style-type:none}.lst-kix_mtm8lwd6vxjl-6>li:before{content:"-  "}ul.lst-kix_b7rulpv7obgl-1{list-style-type:none}ul.lst-kix_b7rulpv7obgl-2{list-style-type:none}ul.lst-kix_b7rulpv7obgl-3{list-style-type:none}.lst-kix_cg6jep1fmawj-8>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-2>li:before{content:"" counter(lst-ctn-kix_d1gy3hy5r3qj-2,lower-roman) ") "}.lst-kix_t9t3ckq2i2hz-6>li:before{content:"-  "}.lst-kix_cg6jep1fmawj-0>li:before{content:"-  "}.lst-kix_6nc1nfac2wub-7>li:before{content:"-  "}ul.lst-kix_wnr3c516ni7j-0{list-style-type:none}ul.lst-kix_wnr3c516ni7j-1{list-style-type:none}ul.lst-kix_wnr3c516ni7j-2{list-style-type:none}ul.lst-kix_wnr3c516ni7j-3{list-style-type:none}.lst-kix_j32gjnxzdkip-2>li:before{content:"-  "}.lst-kix_ro388iryhhf5-7>li:before{content:"-  "}ul.lst-kix_30wqf3y6rydr-7{list-style-type:none}ul.lst-kix_30wqf3y6rydr-8{list-style-type:none}ul.lst-kix_30wqf3y6rydr-3{list-style-type:none}ul.lst-kix_30wqf3y6rydr-4{list-style-type:none}ul.lst-kix_30wqf3y6rydr-5{list-style-type:none}ul.lst-kix_30wqf3y6rydr-6{list-style-type:none}ul.lst-kix_30wqf3y6rydr-0{list-style-type:none}ul.lst-kix_30wqf3y6rydr-1{list-style-type:none}ul.lst-kix_30wqf3y6rydr-2{list-style-type:none}.lst-kix_xs6xjhigrbe2-0>li:before{content:"-  "}.lst-kix_ekasiajyrrvz-5>li:before{content:"-  "}.lst-kix_vgg0538grxk3-2>li:before{content:"" counter(lst-ctn-kix_vgg0538grxk3-2,lower-roman) ") "}.lst-kix_ivmzvkm69gsd-0>li:before{content:"-  "}.lst-kix_84zf7o74c8s9-1>li{counter-increment:lst-ctn-kix_84zf7o74c8s9-1}.lst-kix_hngwf7orguk6-8>li:before{content:"-  "}.lst-kix_ukx3y28hag8h-5>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-8>li{counter-increment:lst-ctn-kix_3mj3tp7kj9db-8}ol.lst-kix_vkdxjlf0kb6j-2.start{counter-reset:lst-ctn-kix_vkdxjlf0kb6j-2 0}.lst-kix_n0rv3zxivae3-4>li:before{content:"-  "}ol.lst-kix_u8nobwiguyj1-2.start{counter-reset:lst-ctn-kix_u8nobwiguyj1-2 0}ol.lst-kix_xyra4e5ffsud-6.start{counter-reset:lst-ctn-kix_xyra4e5ffsud-6 0}ol.lst-kix_ysfu1bl0kymd-0.start{counter-reset:lst-ctn-kix_ysfu1bl0kymd-0 0}ul.lst-kix_ms4jfr9nudpc-6{list-style-type:none}.lst-kix_hytfj9icha07-8>li:before{content:"-  "}ul.lst-kix_ms4jfr9nudpc-7{list-style-type:none}ul.lst-kix_ms4jfr9nudpc-8{list-style-type:none}ul.lst-kix_ms4jfr9nudpc-2{list-style-type:none}ul.lst-kix_ms4jfr9nudpc-3{list-style-type:none}ul.lst-kix_ms4jfr9nudpc-4{list-style-type:none}.lst-kix_njs8ubf1qesf-1>li:before{content:"-  "}ul.lst-kix_ms4jfr9nudpc-5{list-style-type:none}ul.lst-kix_ms4jfr9nudpc-0{list-style-type:none}.lst-kix_a42anijqpp8a-3>li:before{content:"-  "}ul.lst-kix_ms4jfr9nudpc-1{list-style-type:none}ul.lst-kix_waivoqs1cu5x-2{list-style-type:none}ul.lst-kix_waivoqs1cu5x-1{list-style-type:none}ul.lst-kix_waivoqs1cu5x-4{list-style-type:none}ul.lst-kix_waivoqs1cu5x-3{list-style-type:none}ul.lst-kix_waivoqs1cu5x-0{list-style-type:none}ul.lst-kix_waivoqs1cu5x-6{list-style-type:none}ul.lst-kix_waivoqs1cu5x-5{list-style-type:none}.lst-kix_qmx92jmkghx8-7>li:before{content:"-  "}ul.lst-kix_waivoqs1cu5x-8{list-style-type:none}ul.lst-kix_waivoqs1cu5x-7{list-style-type:none}.lst-kix_hytfj9icha07-0>li:before{content:"-  "}.lst-kix_rop4yg7lbfg8-7>li:before{content:"-  "}.lst-kix_xs6xjhigrbe2-8>li:before{content:"-  "}.lst-kix_oqibhsqlyfou-3>li:before{content:"-  "}ul.lst-kix_o4efc4ukggt5-6{list-style-type:none}ul.lst-kix_2r20t3tmnrwb-6{list-style-type:none}ul.lst-kix_o4efc4ukggt5-5{list-style-type:none}ul.lst-kix_2r20t3tmnrwb-7{list-style-type:none}ul.lst-kix_o4efc4ukggt5-4{list-style-type:none}ul.lst-kix_2r20t3tmnrwb-4{list-style-type:none}.lst-kix_b7rulpv7obgl-2>li:before{content:"-  "}ul.lst-kix_o4efc4ukggt5-3{list-style-type:none}ul.lst-kix_2r20t3tmnrwb-5{list-style-type:none}ul.lst-kix_o4efc4ukggt5-8{list-style-type:none}.lst-kix_qsto019ofcm1-4>li:before{content:"-  "}ul.lst-kix_2r20t3tmnrwb-8{list-style-type:none}ul.lst-kix_o4efc4ukggt5-7{list-style-type:none}.lst-kix_spt2hfceke6p-7>li:before{content:"-  "}.lst-kix_194f2a56ajxk-5>li:before{content:"-  "}ul.lst-kix_2r20t3tmnrwb-2{list-style-type:none}ul.lst-kix_2r20t3tmnrwb-3{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-0.start{counter-reset:lst-ctn-kix_vkdxjlf0kb6j-0 0}ul.lst-kix_2r20t3tmnrwb-0{list-style-type:none}.lst-kix_kxjfd2xlpmu-4>li:before{content:"-  "}ul.lst-kix_2r20t3tmnrwb-1{list-style-type:none}.lst-kix_hrm7p8w30y7p-1>li:before{content:"-  "}.lst-kix_194f2a56ajxk-3>li:before{content:"-  "}.lst-kix_90bg3luq5inv-1>li:before{content:"" counter(lst-ctn-kix_90bg3luq5inv-1,lower-latin) ") "}.lst-kix_m31se2npgu2r-3>li:before{content:"-  "}ul.lst-kix_o4efc4ukggt5-2{list-style-type:none}ul.lst-kix_o4efc4ukggt5-1{list-style-type:none}ul.lst-kix_o4efc4ukggt5-0{list-style-type:none}ul.lst-kix_eh3u7tkoktop-0{list-style-type:none}.lst-kix_luixtz7s7e5x-2>li:before{content:"-  "}.lst-kix_s0nbf6s2np44-1>li:before{content:"-  "}.lst-kix_wz5gdx83jdla-0>li:before{content:"-  "}.lst-kix_qvomcnyqz8ao-4>li:before{content:"-  "}.lst-kix_wz5gdx83jdla-2>li:before{content:"-  "}ol.lst-kix_hppu19i8fr2p-8.start{counter-reset:lst-ctn-kix_hppu19i8fr2p-8 0}.lst-kix_90bg3luq5inv-3>li:before{content:"(" counter(lst-ctn-kix_90bg3luq5inv-3,decimal) ") "}ul.lst-kix_zjjx8lb18sy-7{list-style-type:none}ul.lst-kix_zjjx8lb18sy-6{list-style-type:none}ul.lst-kix_194f2a56ajxk-7{list-style-type:none}ul.lst-kix_zjjx8lb18sy-5{list-style-type:none}ul.lst-kix_194f2a56ajxk-8{list-style-type:none}ul.lst-kix_zjjx8lb18sy-4{list-style-type:none}ul.lst-kix_194f2a56ajxk-5{list-style-type:none}.lst-kix_wz5gdx83jdla-8>li:before{content:"-  "}ul.lst-kix_194f2a56ajxk-6{list-style-type:none}ul.lst-kix_194f2a56ajxk-3{list-style-type:none}ul.lst-kix_194f2a56ajxk-4{list-style-type:none}ul.lst-kix_zjjx8lb18sy-8{list-style-type:none}ul.lst-kix_eh3u7tkoktop-6{list-style-type:none}ul.lst-kix_194f2a56ajxk-1{list-style-type:none}ul.lst-kix_eh3u7tkoktop-5{list-style-type:none}ul.lst-kix_194f2a56ajxk-2{list-style-type:none}ul.lst-kix_eh3u7tkoktop-8{list-style-type:none}ul.lst-kix_eh3u7tkoktop-7{list-style-type:none}ul.lst-kix_194f2a56ajxk-0{list-style-type:none}ul.lst-kix_eh3u7tkoktop-2{list-style-type:none}.lst-kix_cmm6cscyrjti-1>li:before{content:"-  "}ul.lst-kix_zjjx8lb18sy-3{list-style-type:none}ul.lst-kix_eh3u7tkoktop-1{list-style-type:none}ul.lst-kix_zjjx8lb18sy-2{list-style-type:none}ul.lst-kix_eh3u7tkoktop-4{list-style-type:none}ul.lst-kix_zjjx8lb18sy-1{list-style-type:none}ul.lst-kix_eh3u7tkoktop-3{list-style-type:none}ul.lst-kix_zjjx8lb18sy-0{list-style-type:none}.lst-kix_rp6rf03vbelo-4>li:before{content:"-  "}.lst-kix_8drpzle0jo7q-1>li:before{content:"\0025cb   "}.lst-kix_rxevvtxfoovc-7>li:before{content:"-  "}.lst-kix_8f3g26d9wonp-0>li:before{content:"-  "}.lst-kix_x1n4jlo0gf1q-0>li:before{content:"-  "}.lst-kix_s9h4llxy1yy0-2>li:before{content:"-  "}ol.lst-kix_3mj3tp7kj9db-0.start{counter-reset:lst-ctn-kix_3mj3tp7kj9db-0 0}.lst-kix_a9h81iclzrpy-4>li:before{content:"-  "}.lst-kix_tl77ogq6q7u-1>li:before{content:"-  "}.lst-kix_3koi1cw13a0-2>li:before{content:"-  "}.lst-kix_8a5plp401pog-6>li:before{content:"-  "}.lst-kix_i7kvy3cw4vsq-3>li:before{content:"-  "}.lst-kix_incqcf2p39ls-5>li:before{content:"(" counter(lst-ctn-kix_incqcf2p39ls-5,lower-roman) ") "}ol.lst-kix_5djgwp8c9ig2-3.start{counter-reset:lst-ctn-kix_5djgwp8c9ig2-3 0}.lst-kix_h25uruhpfzux-5>li:before{content:"-  "}.lst-kix_nipj94pw11x6-1>li:before{content:"-  "}.lst-kix_fhtxrv3nkyi7-6>li:before{content:"-  "}.lst-kix_fhtxrv3nkyi7-8>li:before{content:"-  "}ul.lst-kix_sr0z5k7b8i6u-1{list-style-type:none}ul.lst-kix_sr0z5k7b8i6u-2{list-style-type:none}ul.lst-kix_sr0z5k7b8i6u-0{list-style-type:none}ul.lst-kix_sr0z5k7b8i6u-5{list-style-type:none}.lst-kix_fhtxrv3nkyi7-0>li:before{content:"-  "}ul.lst-kix_sr0z5k7b8i6u-6{list-style-type:none}.lst-kix_4gff7g6tktju-0>li:before{content:"-  "}ul.lst-kix_sr0z5k7b8i6u-3{list-style-type:none}ul.lst-kix_sr0z5k7b8i6u-4{list-style-type:none}ul.lst-kix_bnte1i3g4kjh-8{list-style-type:none}ul.lst-kix_bnte1i3g4kjh-7{list-style-type:none}ul.lst-kix_bnte1i3g4kjh-4{list-style-type:none}ul.lst-kix_bnte1i3g4kjh-3{list-style-type:none}.lst-kix_ny5e869gaylo-8>li:before{content:"-  "}ul.lst-kix_bnte1i3g4kjh-6{list-style-type:none}ul.lst-kix_bnte1i3g4kjh-5{list-style-type:none}ul.lst-kix_dvvzixfw64a1-4{list-style-type:none}ul.lst-kix_dvvzixfw64a1-3{list-style-type:none}.lst-kix_8f3g26d9wonp-8>li:before{content:"-  "}ul.lst-kix_dvvzixfw64a1-2{list-style-type:none}ul.lst-kix_dvvzixfw64a1-1{list-style-type:none}ul.lst-kix_dvvzixfw64a1-0{list-style-type:none}ul.lst-kix_sr0z5k7b8i6u-7{list-style-type:none}ul.lst-kix_sr0z5k7b8i6u-8{list-style-type:none}.lst-kix_awt45k7p90je-0>li:before{content:"-  "}ul.lst-kix_dvvzixfw64a1-8{list-style-type:none}ul.lst-kix_dvvzixfw64a1-7{list-style-type:none}ul.lst-kix_dvvzixfw64a1-6{list-style-type:none}ul.lst-kix_dvvzixfw64a1-5{list-style-type:none}.lst-kix_awt45k7p90je-6>li:before{content:"-  "}.lst-kix_i4nwb7g7qe41-5>li:before{content:"-  "}.lst-kix_qij6192l4p0g-1>li:before{content:"-  "}ul.lst-kix_vvjhovkzyen7-5{list-style-type:none}ul.lst-kix_vvjhovkzyen7-4{list-style-type:none}.lst-kix_yjf6dvvoob64-6>li:before{content:"" counter(lst-ctn-kix_yjf6dvvoob64-6,decimal) ". "}ul.lst-kix_vvjhovkzyen7-7{list-style-type:none}ul.lst-kix_vvjhovkzyen7-6{list-style-type:none}ul.lst-kix_vvjhovkzyen7-1{list-style-type:none}.lst-kix_43bwriak8ne4-7>li:before{content:"-  "}ul.lst-kix_vvjhovkzyen7-0{list-style-type:none}ul.lst-kix_vvjhovkzyen7-3{list-style-type:none}ul.lst-kix_vvjhovkzyen7-2{list-style-type:none}.lst-kix_xdqzm25ye8fb-5>li:before{content:"-  "}.lst-kix_43bwriak8ne4-1>li:before{content:"-  "}.lst-kix_df6s37r8voak-0>li:before{content:"-  "}.lst-kix_khixc8f7o03u-1>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-3>li{counter-increment:lst-ctn-kix_ykhoydml7pv3-3}ul.lst-kix_8nwtyhgsvjlm-1{list-style-type:none}ul.lst-kix_8nwtyhgsvjlm-0{list-style-type:none}ul.lst-kix_8nwtyhgsvjlm-5{list-style-type:none}ul.lst-kix_8nwtyhgsvjlm-4{list-style-type:none}ul.lst-kix_8nwtyhgsvjlm-3{list-style-type:none}.lst-kix_wzt7symqmcfu-3>li:before{content:"-  "}ul.lst-kix_8nwtyhgsvjlm-2{list-style-type:none}.lst-kix_izios9u5ks4s-0>li:before{content:"-  "}ul.lst-kix_8nwtyhgsvjlm-8{list-style-type:none}.lst-kix_q8ex99of35ig-3>li:before{content:"-  "}ul.lst-kix_8nwtyhgsvjlm-7{list-style-type:none}ul.lst-kix_8nwtyhgsvjlm-6{list-style-type:none}ul.lst-kix_vvjhovkzyen7-8{list-style-type:none}.lst-kix_x6hb6vgwujyx-5>li:before{content:"-  "}ul.lst-kix_bnte1i3g4kjh-0{list-style-type:none}ul.lst-kix_ms6rbzn59hmq-0{list-style-type:none}ul.lst-kix_bnte1i3g4kjh-2{list-style-type:none}.lst-kix_1xkx8gh1e8n7-5>li:before{content:"-  "}ul.lst-kix_bnte1i3g4kjh-1{list-style-type:none}ul.lst-kix_ms6rbzn59hmq-3{list-style-type:none}ul.lst-kix_ms6rbzn59hmq-4{list-style-type:none}.lst-kix_q8ex99of35ig-5>li:before{content:"-  "}.lst-kix_bnvwt1y8k7b-0>li:before{content:"-  "}ul.lst-kix_ms6rbzn59hmq-1{list-style-type:none}ul.lst-kix_ms6rbzn59hmq-2{list-style-type:none}ul.lst-kix_ms6rbzn59hmq-7{list-style-type:none}ul.lst-kix_ms6rbzn59hmq-8{list-style-type:none}ul.lst-kix_ms6rbzn59hmq-5{list-style-type:none}ul.lst-kix_ms6rbzn59hmq-6{list-style-type:none}.lst-kix_r8i1fgeyliey-2>li:before{content:"-  "}.lst-kix_t3rn73qejgkj-1>li:before{content:"" counter(lst-ctn-kix_t3rn73qejgkj-1,lower-latin) ") "}.lst-kix_5djgwp8c9ig2-3>li:before{content:"" counter(lst-ctn-kix_5djgwp8c9ig2-3,decimal) ". "}.lst-kix_ob04lr2u335p-4>li:before{content:"-  "}.lst-kix_t3rn73qejgkj-3>li:before{content:"(" counter(lst-ctn-kix_t3rn73qejgkj-3,decimal) ") "}.lst-kix_o45gwpewsvxw-3>li:before{content:"-  "}.lst-kix_tpw8rt3jm7dt-2>li:before{content:"-  "}ul.lst-kix_mkfigeky21iv-8{list-style-type:none}.lst-kix_2ccdqvrbclt-4>li:before{content:"-  "}.lst-kix_hrm7p8w30y7p-7>li:before{content:"-  "}.lst-kix_ny5e869gaylo-0>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-8>li{counter-increment:lst-ctn-kix_yjf6dvvoob64-8}ul.lst-kix_mkfigeky21iv-2{list-style-type:none}ul.lst-kix_mkfigeky21iv-3{list-style-type:none}.lst-kix_5syfdd8x3l8s-6>li:before{content:"-  "}ul.lst-kix_mkfigeky21iv-0{list-style-type:none}ul.lst-kix_mkfigeky21iv-1{list-style-type:none}ul.lst-kix_mkfigeky21iv-6{list-style-type:none}ol.lst-kix_incqcf2p39ls-7{list-style-type:none}ul.lst-kix_mkfigeky21iv-7{list-style-type:none}ol.lst-kix_incqcf2p39ls-6{list-style-type:none}ul.lst-kix_mkfigeky21iv-4{list-style-type:none}ul.lst-kix_mkfigeky21iv-5{list-style-type:none}ol.lst-kix_incqcf2p39ls-8{list-style-type:none}.lst-kix_pxpm44v9ngyu-7>li:before{content:"-  "}.lst-kix_nj8yy6k748x0-4>li:before{content:"-  "}ul.lst-kix_sq25f4cnauod-7{list-style-type:none}ul.lst-kix_sq25f4cnauod-6{list-style-type:none}.lst-kix_q2mi4y6rc42i-6>li:before{content:"-  "}ul.lst-kix_sq25f4cnauod-8{list-style-type:none}.lst-kix_yvohqcnu3146-6>li:before{content:"" counter(lst-ctn-kix_yvohqcnu3146-6,decimal) ". "}.lst-kix_i2q40uf7647f-5>li:before{content:"-  "}ul.lst-kix_sq25f4cnauod-1{list-style-type:none}ul.lst-kix_sq25f4cnauod-0{list-style-type:none}ul.lst-kix_sq25f4cnauod-3{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-7{list-style-type:none}.lst-kix_xyra4e5ffsud-0>li:before{content:"" counter(lst-ctn-kix_xyra4e5ffsud-0,decimal) ". "}ul.lst-kix_sq25f4cnauod-2{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-8{list-style-type:none}ul.lst-kix_sq25f4cnauod-5{list-style-type:none}ul.lst-kix_sq25f4cnauod-4{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-3{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-4{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-5{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-6{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-0{list-style-type:none}.lst-kix_267f3xfv5ddr-2>li{counter-increment:lst-ctn-kix_267f3xfv5ddr-2}ol.lst-kix_3mj3tp7kj9db-1{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-2{list-style-type:none}.lst-kix_oc7itsrfkmqv-7>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-6>li:before{content:"" counter(lst-ctn-kix_ypd5gkkarijk-6,lower-latin) ". "}.lst-kix_ykhrv7u6blcs-0>li:before{content:"-  "}.lst-kix_x74x9xa8n5a0-7>li:before{content:"-  "}.lst-kix_5stj9b6acoxv-4>li{counter-increment:lst-ctn-kix_5stj9b6acoxv-4}.lst-kix_pejjsijavmae-7>li:before{content:"-  "}.lst-kix_r8azi25kh461-1>li:before{content:"\0025cf   "}.lst-kix_11d94ps4c7wj-1>li:before{content:"-  "}.lst-kix_4uak8dkv6vr8-3>li:before{content:"-  "}ul.lst-kix_rtczm6eelr4h-3{list-style-type:none}.lst-kix_j32gjnxzdkip-8>li:before{content:"-  "}ul.lst-kix_rtczm6eelr4h-4{list-style-type:none}ul.lst-kix_rtczm6eelr4h-1{list-style-type:none}ul.lst-kix_rtczm6eelr4h-2{list-style-type:none}.lst-kix_mkfigeky21iv-6>li:before{content:"-  "}ul.lst-kix_rtczm6eelr4h-0{list-style-type:none}.lst-kix_nlsa7flowwa1-6>li:before{content:"+  "}.lst-kix_owvy3cstzf0s-3>li:before{content:"-  "}.lst-kix_1kbilie4yf3o-7>li:before{content:"-  "}.lst-kix_w3rscytwttbz-5>li:before{content:"-  "}.lst-kix_3wxxpxfz40sk-0>li:before{content:"-  "}.lst-kix_22zpsclbl6ju-0>li:before{content:"-  "}.lst-kix_rf1gg3liws68-0>li:before{content:"-  "}.lst-kix_vhhvekoaa9d4-6>li:before{content:"\0025cf   "}ul.lst-kix_bswxvn1l22fp-0{list-style-type:none}ul.lst-kix_bswxvn1l22fp-1{list-style-type:none}.lst-kix_22zpsclbl6ju-8>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-4>li:before{content:"(" counter(lst-ctn-kix_d1gy3hy5r3qj-4,lower-latin) ") "}.lst-kix_3ez3vzcedsa0-2>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-6>li{counter-increment:lst-ctn-kix_ysfu1bl0kymd-6}ol.lst-kix_52jgzw489fhs-5.start{counter-reset:lst-ctn-kix_52jgzw489fhs-5 0}.lst-kix_q8c17lyf7k0c-7>li:before{content:"-  "}.lst-kix_73pnq2b8bo4n-4>li:before{content:"-  "}.lst-kix_35hvjwgc3k2f-0>li:before{content:"-  "}ul.lst-kix_o45gwpewsvxw-5{list-style-type:none}.lst-kix_j32gjnxzdkip-0>li:before{content:"-  "}.lst-kix_6pgojrjbxqei-3>li:before{content:"\0025cf   "}ul.lst-kix_o45gwpewsvxw-6{list-style-type:none}ul.lst-kix_o45gwpewsvxw-7{list-style-type:none}ul.lst-kix_o45gwpewsvxw-8{list-style-type:none}.lst-kix_5rn2qrejqs3r-4>li:before{content:"-  "}.lst-kix_ozrjmre97pex-8>li:before{content:"-  "}ul.lst-kix_bswxvn1l22fp-4{list-style-type:none}ul.lst-kix_bswxvn1l22fp-5{list-style-type:none}ul.lst-kix_bswxvn1l22fp-2{list-style-type:none}ul.lst-kix_o45gwpewsvxw-0{list-style-type:none}ul.lst-kix_bswxvn1l22fp-3{list-style-type:none}ul.lst-kix_o45gwpewsvxw-1{list-style-type:none}ul.lst-kix_rtczm6eelr4h-7{list-style-type:none}ul.lst-kix_bswxvn1l22fp-8{list-style-type:none}ul.lst-kix_o45gwpewsvxw-2{list-style-type:none}ul.lst-kix_rtczm6eelr4h-8{list-style-type:none}.lst-kix_7o1va6u13ska-1>li:before{content:"-  "}ul.lst-kix_o45gwpewsvxw-3{list-style-type:none}ul.lst-kix_rtczm6eelr4h-5{list-style-type:none}ul.lst-kix_bswxvn1l22fp-6{list-style-type:none}ul.lst-kix_o45gwpewsvxw-4{list-style-type:none}ul.lst-kix_rtczm6eelr4h-6{list-style-type:none}ul.lst-kix_bswxvn1l22fp-7{list-style-type:none}ul.lst-kix_17yxihawuh4r-1{list-style-type:none}.lst-kix_f4168mxvziu2-3>li:before{content:"-  "}.lst-kix_d626gkjp4fou-4>li:before{content:"\0025cb   "}ul.lst-kix_17yxihawuh4r-0{list-style-type:none}ul.lst-kix_17yxihawuh4r-5{list-style-type:none}ul.lst-kix_17yxihawuh4r-4{list-style-type:none}.lst-kix_sq25f4cnauod-5>li:before{content:"-  "}ul.lst-kix_17yxihawuh4r-3{list-style-type:none}ul.lst-kix_17yxihawuh4r-2{list-style-type:none}.lst-kix_rf3bfhvmysmh-8>li:before{content:"-  "}ul.lst-kix_17yxihawuh4r-8{list-style-type:none}ul.lst-kix_17yxihawuh4r-7{list-style-type:none}.lst-kix_xyra4e5ffsud-4>li{counter-increment:lst-ctn-kix_xyra4e5ffsud-4}ul.lst-kix_17yxihawuh4r-6{list-style-type:none}.lst-kix_o1voy78o4juz-7>li:before{content:"-  "}.lst-kix_28q7sqckfj19-5>li:before{content:"-  "}.lst-kix_ikdz4hpyto9o-6>li:before{content:"-  "}.lst-kix_m3u7mfewl2ow-0>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-2>li:before{content:"" counter(lst-ctn-kix_ysfu1bl0kymd-2,lower-roman) ". "}.lst-kix_vgg0538grxk3-0>li:before{content:"" counter(lst-ctn-kix_vgg0538grxk3-0,decimal) ") "}.lst-kix_r6uhbskcwxv5-7>li:before{content:"-  "}.lst-kix_bttl6bm2dx1a-3>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-8>li{counter-increment:lst-ctn-kix_d1gy3hy5r3qj-8}.lst-kix_pv4jsz2h74wk-0>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-3>li{counter-increment:lst-ctn-kix_hppu19i8fr2p-3}.lst-kix_vgg0538grxk3-8>li:before{content:"" counter(lst-ctn-kix_vgg0538grxk3-8,lower-roman) ". "}.lst-kix_unv0ib1v43rp-2>li:before{content:"-  "}.lst-kix_9ys95s420x24-5>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-7.start{counter-reset:lst-ctn-kix_d1gy3hy5r3qj-7 0}.lst-kix_njs8ubf1qesf-3>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-2.start{counter-reset:lst-ctn-kix_incqcf2p39ls-2 0}.lst-kix_o17eseb5cr8e-8>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-2>li:before{content:"" counter(lst-ctn-kix_azgj6sn0lxuj-2,lower-roman) ". "}.lst-kix_axwe0nze7yft-2>li:before{content:"-  "}.lst-kix_bb3pt2xtt0a5-5>li:before{content:"-  "}.lst-kix_rop4yg7lbfg8-1>li:before{content:"-  "}.lst-kix_q95o92il1jwg-2>li:before{content:"-  "}.lst-kix_rxgry66ibim8-5>li:before{content:"-  "}.lst-kix_v6dv769q7bq3-2>li:before{content:"-  "}.lst-kix_o17eseb5cr8e-0>li:before{content:"-  "}.lst-kix_eahcvjpxxqs-2>li:before{content:"-  "}.lst-kix_qmx92jmkghx8-1>li:before{content:"-  "}.lst-kix_dojezsyc3ti3-2>li:before{content:"-  "}.lst-kix_wn0yiryrov3h-6>li:before{content:"-  "}.lst-kix_1tib71bbsugw-4>li:before{content:"-  "}.lst-kix_oqibhsqlyfou-1>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-6.start{counter-reset:lst-ctn-kix_ok1n37qarjzb-6 0}ol.lst-kix_sxixw4iqsgzx-3.start{counter-reset:lst-ctn-kix_sxixw4iqsgzx-3 0}ul.lst-kix_c73c2x77meqo-1{list-style-type:none}ul.lst-kix_c73c2x77meqo-2{list-style-type:none}.lst-kix_q7gxc7al9t7n-6>li:before{content:"-  "}ul.lst-kix_c73c2x77meqo-3{list-style-type:none}ul.lst-kix_c73c2x77meqo-4{list-style-type:none}ul.lst-kix_c73c2x77meqo-5{list-style-type:none}ul.lst-kix_c73c2x77meqo-6{list-style-type:none}ul.lst-kix_c73c2x77meqo-7{list-style-type:none}ul.lst-kix_c73c2x77meqo-8{list-style-type:none}.lst-kix_vdnr7e70vask-0>li:before{content:"\0025cf   "}.lst-kix_zew29xx7bzz-4>li:before{content:"-  "}.lst-kix_vdnr7e70vask-6>li:before{content:"\0025cf   "}.lst-kix_lojd6plssn1-4>li:before{content:"-  "}ul.lst-kix_g0lr2dxtnslc-6{list-style-type:none}ul.lst-kix_g0lr2dxtnslc-7{list-style-type:none}.lst-kix_vdnr7e70vask-3>li:before{content:"\0025cf   "}ul.lst-kix_g0lr2dxtnslc-4{list-style-type:none}ul.lst-kix_g0lr2dxtnslc-5{list-style-type:none}ul.lst-kix_g0lr2dxtnslc-2{list-style-type:none}ul.lst-kix_g0lr2dxtnslc-3{list-style-type:none}.lst-kix_zew29xx7bzz-7>li:before{content:"-  "}ul.lst-kix_g0lr2dxtnslc-0{list-style-type:none}ul.lst-kix_g0lr2dxtnslc-1{list-style-type:none}.lst-kix_tekivzgenz72-0>li:before{content:"-  "}.lst-kix_e3u4u2bj7x9w-7>li:before{content:"-  "}.lst-kix_85vz7a3ggeai-0>li:before{content:"-  "}.lst-kix_52jgzw489fhs-7>li{counter-increment:lst-ctn-kix_52jgzw489fhs-7}.lst-kix_30wqf3y6rydr-5>li:before{content:"-  "}.lst-kix_tfqdu2hgmdym-1>li:before{content:"-  "}.lst-kix_6217r3mhjywx-2>li:before{content:"-  "}.lst-kix_sgiyubx3nkay-6>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-3>li{counter-increment:lst-ctn-kix_sxixw4iqsgzx-3}.lst-kix_sxixw4iqsgzx-2>li:before{content:"" counter(lst-ctn-kix_sxixw4iqsgzx-2,lower-roman) ". "}.lst-kix_xktbtduo53bq-7>li:before{content:"" counter(lst-ctn-kix_xktbtduo53bq-7,lower-latin) ". "}.lst-kix_30wqf3y6rydr-2>li:before{content:"-  "}.lst-kix_e3u4u2bj7x9w-1>li:before{content:"-  "}.lst-kix_fy701w8ywepa-0>li:before{content:"-  "}ul.lst-kix_c73c2x77meqo-0{list-style-type:none}.lst-kix_85vz7a3ggeai-3>li:before{content:"-  "}.lst-kix_xktbtduo53bq-4>li:before{content:"" counter(lst-ctn-kix_xktbtduo53bq-4,lower-latin) ". "}.lst-kix_e3u4u2bj7x9w-4>li:before{content:"-  "}ol.lst-kix_84zf7o74c8s9-7{list-style-type:none}ol.lst-kix_84zf7o74c8s9-8{list-style-type:none}.lst-kix_9ys95s420x24-8>li:before{content:"-  "}.lst-kix_f4168mxvziu2-0>li:before{content:"-  "}ol.lst-kix_84zf7o74c8s9-1{list-style-type:none}ol.lst-kix_84zf7o74c8s9-2{list-style-type:none}ol.lst-kix_84zf7o74c8s9-0{list-style-type:none}ol.lst-kix_84zf7o74c8s9-5{list-style-type:none}ol.lst-kix_84zf7o74c8s9-6{list-style-type:none}ol.lst-kix_84zf7o74c8s9-3{list-style-type:none}ol.lst-kix_84zf7o74c8s9-4{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-8.start{counter-reset:lst-ctn-kix_3mj3tp7kj9db-8 0}.lst-kix_sq25f4cnauod-2>li:before{content:"-  "}.lst-kix_hc732m8hksyq-5>li:before{content:"-  "}.lst-kix_eahcvjpxxqs-5>li:before{content:"-  "}ul.lst-kix_4gff7g6tktju-5{list-style-type:none}ul.lst-kix_st0egafmkg0z-1{list-style-type:none}ol.lst-kix_xktbtduo53bq-0{list-style-type:none}ul.lst-kix_4gff7g6tktju-4{list-style-type:none}ul.lst-kix_st0egafmkg0z-0{list-style-type:none}ul.lst-kix_4gff7g6tktju-7{list-style-type:none}ul.lst-kix_st0egafmkg0z-3{list-style-type:none}ol.lst-kix_xktbtduo53bq-2{list-style-type:none}ul.lst-kix_4gff7g6tktju-6{list-style-type:none}ul.lst-kix_st0egafmkg0z-2{list-style-type:none}ol.lst-kix_xktbtduo53bq-1{list-style-type:none}.lst-kix_sxixw4iqsgzx-5>li:before{content:"" counter(lst-ctn-kix_sxixw4iqsgzx-5,lower-roman) ". "}ol.lst-kix_xktbtduo53bq-4{list-style-type:none}ul.lst-kix_4gff7g6tktju-8{list-style-type:none}ol.lst-kix_xktbtduo53bq-3{list-style-type:none}ol.lst-kix_xktbtduo53bq-6{list-style-type:none}.lst-kix_tlnfkrylyq1a-0>li:before{content:"-  "}ol.lst-kix_xktbtduo53bq-5{list-style-type:none}ol.lst-kix_xktbtduo53bq-8{list-style-type:none}ol.lst-kix_xktbtduo53bq-7{list-style-type:none}.lst-kix_rog9deufml3h-1>li:before{content:"-  "}ul.lst-kix_4gff7g6tktju-1{list-style-type:none}ul.lst-kix_4gff7g6tktju-0{list-style-type:none}ul.lst-kix_4gff7g6tktju-3{list-style-type:none}ul.lst-kix_4gff7g6tktju-2{list-style-type:none}.lst-kix_npanryo7f1m7-5>li:before{content:"-  "}.lst-kix_i8kfgvsh0fwy-3>li:before{content:"-  "}.lst-kix_7gk9ayd44tft-4>li:before{content:"-  "}ul.lst-kix_hsahb38tz2f5-0{list-style-type:none}ul.lst-kix_hsahb38tz2f5-2{list-style-type:none}ul.lst-kix_g0lr2dxtnslc-8{list-style-type:none}ul.lst-kix_hsahb38tz2f5-1{list-style-type:none}ul.lst-kix_hsahb38tz2f5-4{list-style-type:none}ul.lst-kix_hsahb38tz2f5-3{list-style-type:none}ul.lst-kix_hsahb38tz2f5-6{list-style-type:none}ul.lst-kix_hsahb38tz2f5-5{list-style-type:none}ul.lst-kix_hsahb38tz2f5-8{list-style-type:none}.lst-kix_g02ta87c1sqh-2>li:before{content:"\0025a0   "}ul.lst-kix_hsahb38tz2f5-7{list-style-type:none}.lst-kix_tvu7bmfefz32-0>li:before{content:"-  "}ul.lst-kix_st0egafmkg0z-8{list-style-type:none}.lst-kix_lojd6plssn1-1>li:before{content:"-  "}ul.lst-kix_st0egafmkg0z-5{list-style-type:none}ul.lst-kix_st0egafmkg0z-4{list-style-type:none}ul.lst-kix_st0egafmkg0z-7{list-style-type:none}ul.lst-kix_st0egafmkg0z-6{list-style-type:none}ul.lst-kix_p1rtf0e14360-8{list-style-type:none}ul.lst-kix_p1rtf0e14360-7{list-style-type:none}ul.lst-kix_p1rtf0e14360-4{list-style-type:none}ul.lst-kix_p1rtf0e14360-3{list-style-type:none}ul.lst-kix_p1rtf0e14360-6{list-style-type:none}.lst-kix_awlaex77cpwh-2>li:before{content:"-  "}ul.lst-kix_p1rtf0e14360-5{list-style-type:none}ul.lst-kix_p1rtf0e14360-0{list-style-type:none}.lst-kix_28q7sqckfj19-2>li:before{content:"-  "}ul.lst-kix_p1rtf0e14360-2{list-style-type:none}ul.lst-kix_p1rtf0e14360-1{list-style-type:none}.lst-kix_dojezsyc3ti3-5>li:before{content:"-  "}.lst-kix_g1rm1ujfok3h-3>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-3{list-style-type:none}.lst-kix_g02ta87c1sqh-8>li:before{content:"\0025a0   "}.lst-kix_tvu7bmfefz32-6>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-2{list-style-type:none}ol.lst-kix_incqcf2p39ls-5{list-style-type:none}ol.lst-kix_incqcf2p39ls-4{list-style-type:none}.lst-kix_1tib71bbsugw-1>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-1{list-style-type:none}ol.lst-kix_incqcf2p39ls-0{list-style-type:none}ol.lst-kix_ypd5gkkarijk-6.start{counter-reset:lst-ctn-kix_ypd5gkkarijk-6 0}.lst-kix_yvohqcnu3146-3>li:before{content:"(" counter(lst-ctn-kix_yvohqcnu3146-3,decimal) ") "}.lst-kix_dyq7vlcdkqm5-1>li:before{content:"-  "}.lst-kix_38p7uzj3qds3-2>li:before{content:"-  "}.lst-kix_8wvqr5f1zg2m-5>li:before{content:"-  "}.lst-kix_67mv29rpwb23-8>li:before{content:"-  "}.lst-kix_bnvwt1y8k7b-6>li:before{content:"-  "}ul.lst-kix_h25uruhpfzux-0{list-style-type:none}.lst-kix_oc7itsrfkmqv-4>li:before{content:"-  "}.lst-kix_2nm562bzmwr-4>li:before{content:"-  "}ol.lst-kix_5djgwp8c9ig2-5.start{counter-reset:lst-ctn-kix_5djgwp8c9ig2-5 0}ul.lst-kix_h25uruhpfzux-3{list-style-type:none}ul.lst-kix_h25uruhpfzux-4{list-style-type:none}ul.lst-kix_h25uruhpfzux-1{list-style-type:none}ul.lst-kix_h25uruhpfzux-2{list-style-type:none}.lst-kix_2nm562bzmwr-1>li:before{content:"-  "}.lst-kix_onvme58enb43-2>li:before{content:"-  "}.lst-kix_brqn5pq4e7i7-5>li:before{content:"-  "}ul.lst-kix_eahcvjpxxqs-1{list-style-type:none}ul.lst-kix_eahcvjpxxqs-0{list-style-type:none}.lst-kix_67mv29rpwb23-5>li:before{content:"-  "}ul.lst-kix_eahcvjpxxqs-3{list-style-type:none}.lst-kix_qbfnanuzy3l5-3>li:before{content:"-  "}ul.lst-kix_eahcvjpxxqs-2{list-style-type:none}ul.lst-kix_eahcvjpxxqs-5{list-style-type:none}.lst-kix_hssoi9jbujv-6>li:before{content:"-  "}ul.lst-kix_eahcvjpxxqs-4{list-style-type:none}ul.lst-kix_eahcvjpxxqs-7{list-style-type:none}ul.lst-kix_eahcvjpxxqs-6{list-style-type:none}.lst-kix_brqn5pq4e7i7-8>li:before{content:"-  "}ul.lst-kix_eahcvjpxxqs-8{list-style-type:none}.lst-kix_kzw7lb63578w-1>li:before{content:"-  "}ul.lst-kix_h25uruhpfzux-7{list-style-type:none}ul.lst-kix_pxpm44v9ngyu-0{list-style-type:none}ul.lst-kix_h25uruhpfzux-8{list-style-type:none}ul.lst-kix_pxpm44v9ngyu-1{list-style-type:none}.lst-kix_5u0542f2h2jt-7>li:before{content:"+  "}ul.lst-kix_h25uruhpfzux-5{list-style-type:none}ul.lst-kix_pxpm44v9ngyu-2{list-style-type:none}ul.lst-kix_h25uruhpfzux-6{list-style-type:none}ul.lst-kix_pxpm44v9ngyu-3{list-style-type:none}.lst-kix_oc7itsrfkmqv-1>li:before{content:"-  "}.lst-kix_urqiwn6svi1d-3>li:before{content:"-  "}ol.lst-kix_azgj6sn0lxuj-8.start{counter-reset:lst-ctn-kix_azgj6sn0lxuj-8 0}.lst-kix_qbfnanuzy3l5-6>li:before{content:"-  "}.lst-kix_yvohqcnu3146-0>li:before{content:"" counter(lst-ctn-kix_yvohqcnu3146-0,decimal) ") "}ul.lst-kix_pxpm44v9ngyu-8{list-style-type:none}.lst-kix_ltm9vv1op5tt-1>li:before{content:"-  "}.lst-kix_wfyz8rmi0iq4-7>li:before{content:"-  "}ul.lst-kix_pxpm44v9ngyu-4{list-style-type:none}ul.lst-kix_pxpm44v9ngyu-5{list-style-type:none}ul.lst-kix_pxpm44v9ngyu-6{list-style-type:none}ul.lst-kix_pxpm44v9ngyu-7{list-style-type:none}.lst-kix_wfyz8rmi0iq4-4>li:before{content:"-  "}.lst-kix_w3rscytwttbz-2>li:before{content:"-  "}.lst-kix_wlyv8o88ksmk-8>li:before{content:"-  "}.lst-kix_voj7evacrpie-7>li:before{content:"-  "}.lst-kix_of5ud22cn0qg-3>li:before{content:"-  "}.lst-kix_of5ud22cn0qg-6>li:before{content:"-  "}.lst-kix_x2lkon80l30j-1>li:before{content:"-  "}.lst-kix_23ct987xwu67-5>li{counter-increment:lst-ctn-kix_23ct987xwu67-5}.lst-kix_x2lkon80l30j-4>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-4>li{counter-increment:lst-ctn-kix_hppu19i8fr2p-4}.lst-kix_rf1gg3liws68-3>li:before{content:"-  "}.lst-kix_52jgzw489fhs-1>li{counter-increment:lst-ctn-kix_52jgzw489fhs-1}.lst-kix_aeppt4sbsnmp-2>li:before{content:"-  "}ul.lst-kix_6nc1nfac2wub-1{list-style-type:none}ul.lst-kix_6nc1nfac2wub-2{list-style-type:none}ul.lst-kix_6nc1nfac2wub-0{list-style-type:none}ul.lst-kix_6nc1nfac2wub-5{list-style-type:none}ul.lst-kix_6nc1nfac2wub-6{list-style-type:none}ul.lst-kix_6nc1nfac2wub-3{list-style-type:none}ul.lst-kix_6nc1nfac2wub-4{list-style-type:none}ul.lst-kix_wlyv8o88ksmk-5{list-style-type:none}ul.lst-kix_wlyv8o88ksmk-4{list-style-type:none}.lst-kix_aeppt4sbsnmp-5>li:before{content:"-  "}ul.lst-kix_6nc1nfac2wub-7{list-style-type:none}ul.lst-kix_wlyv8o88ksmk-3{list-style-type:none}ul.lst-kix_6nc1nfac2wub-8{list-style-type:none}ul.lst-kix_wlyv8o88ksmk-2{list-style-type:none}.lst-kix_84zf7o74c8s9-6>li{counter-increment:lst-ctn-kix_84zf7o74c8s9-6}ul.lst-kix_wlyv8o88ksmk-8{list-style-type:none}ul.lst-kix_wlyv8o88ksmk-7{list-style-type:none}.lst-kix_rf1gg3liws68-6>li:before{content:"-  "}ul.lst-kix_wlyv8o88ksmk-6{list-style-type:none}.lst-kix_xyra4e5ffsud-6>li:before{content:"" counter(lst-ctn-kix_xyra4e5ffsud-6,decimal) ". "}ul.lst-kix_wlyv8o88ksmk-1{list-style-type:none}ul.lst-kix_wlyv8o88ksmk-0{list-style-type:none}.lst-kix_4ypcpsaj0q6h-5>li:before{content:"-  "}ol.lst-kix_g8jgbze430sv-4.start{counter-reset:lst-ctn-kix_g8jgbze430sv-4 0}.lst-kix_7vvt5hs6rdl-4>li:before{content:"-  "}.lst-kix_mq980hprr5hl-7>li:before{content:"-  "}.lst-kix_dojezsyc3ti3-8>li:before{content:"-  "}.lst-kix_eahcvjpxxqs-8>li:before{content:"-  "}ol.lst-kix_yvohqcnu3146-2.start{counter-reset:lst-ctn-kix_yvohqcnu3146-2 0}.lst-kix_hc732m8hksyq-8>li:before{content:"-  "}.lst-kix_dmxresnhzo8y-5>li:before{content:"-  "}ul.lst-kix_nipj94pw11x6-2{list-style-type:none}ul.lst-kix_nipj94pw11x6-3{list-style-type:none}ul.lst-kix_nipj94pw11x6-0{list-style-type:none}ul.lst-kix_nipj94pw11x6-1{list-style-type:none}ol.lst-kix_2foc6u9lzfq4-5.start{counter-reset:lst-ctn-kix_2foc6u9lzfq4-5 0}ul.lst-kix_nipj94pw11x6-8{list-style-type:none}.lst-kix_p02ob1bzv6e4-6>li:before{content:"-  "}ul.lst-kix_nipj94pw11x6-6{list-style-type:none}ul.lst-kix_f83agu4s4fw5-1{list-style-type:none}ul.lst-kix_nipj94pw11x6-7{list-style-type:none}ul.lst-kix_f83agu4s4fw5-0{list-style-type:none}.lst-kix_5jp9wppv00ra-6>li:before{content:"-  "}ul.lst-kix_nipj94pw11x6-4{list-style-type:none}ul.lst-kix_f83agu4s4fw5-3{list-style-type:none}ul.lst-kix_nipj94pw11x6-5{list-style-type:none}ul.lst-kix_f83agu4s4fw5-2{list-style-type:none}.lst-kix_ssze0kg2kz13-6>li:before{content:"-  "}.lst-kix_ugixx4nd67zw-4>li:before{content:"-  "}.lst-kix_mjig28how5ag-7>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-8>li:before{content:"" counter(lst-ctn-kix_sxixw4iqsgzx-8,lower-roman) ". "}.lst-kix_i8kfgvsh0fwy-6>li:before{content:"-  "}ul.lst-kix_r8i1fgeyliey-4{list-style-type:none}.lst-kix_6n4varno3bjs-0>li:before{content:"-  "}ul.lst-kix_r8i1fgeyliey-3{list-style-type:none}ul.lst-kix_r8i1fgeyliey-2{list-style-type:none}ul.lst-kix_r8i1fgeyliey-1{list-style-type:none}.lst-kix_npanryo7f1m7-2>li:before{content:"-  "}ul.lst-kix_r8i1fgeyliey-0{list-style-type:none}.lst-kix_f9iqanr8ite6-4>li:before{content:"-  "}.lst-kix_iffqre5r12zx-7>li:before{content:"-  "}ol.lst-kix_ysfu1bl0kymd-2.start{counter-reset:lst-ctn-kix_ysfu1bl0kymd-2 0}.lst-kix_69k4orytle42-1>li:before{content:"\0025cb   "}ol.lst-kix_u8nobwiguyj1-4.start{counter-reset:lst-ctn-kix_u8nobwiguyj1-4 0}ul.lst-kix_r8i1fgeyliey-8{list-style-type:none}.lst-kix_2ei6b6e4ow80-1>li:before{content:"-  "}.lst-kix_8hvuzyuchy3p-8>li:before{content:"-  "}ul.lst-kix_r8i1fgeyliey-7{list-style-type:none}ul.lst-kix_r8i1fgeyliey-6{list-style-type:none}.lst-kix_rog9deufml3h-4>li:before{content:"-  "}ul.lst-kix_r8i1fgeyliey-5{list-style-type:none}ol.lst-kix_vgg0538grxk3-5.start{counter-reset:lst-ctn-kix_vgg0538grxk3-5 0}.lst-kix_g02ta87c1sqh-5>li:before{content:"\0025a0   "}.lst-kix_7gk9ayd44tft-1>li:before{content:"-  "}.lst-kix_urqiwn6svi1d-0>li:before{content:"-  "}.lst-kix_5u0542f2h2jt-4>li:before{content:"+  "}ol.lst-kix_yvohqcnu3146-0.start{counter-reset:lst-ctn-kix_yvohqcnu3146-0 0}.lst-kix_ysfu1bl0kymd-5>li{counter-increment:lst-ctn-kix_ysfu1bl0kymd-5}.lst-kix_wn0yiryrov3h-0>li:before{content:"-  "}ul.lst-kix_f83agu4s4fw5-5{list-style-type:none}.lst-kix_bnvwt1y8k7b-3>li:before{content:"-  "}ul.lst-kix_f83agu4s4fw5-4{list-style-type:none}.lst-kix_2ccdqvrbclt-7>li:before{content:"-  "}ul.lst-kix_f83agu4s4fw5-7{list-style-type:none}ul.lst-kix_f83agu4s4fw5-6{list-style-type:none}ol.lst-kix_84zf7o74c8s9-2.start{counter-reset:lst-ctn-kix_84zf7o74c8s9-2 0}.lst-kix_r9s6df60is49-7>li:before{content:"-  "}ul.lst-kix_f83agu4s4fw5-8{list-style-type:none}ol.lst-kix_g8jgbze430sv-0.start{counter-reset:lst-ctn-kix_g8jgbze430sv-0 0}.lst-kix_8wvqr5f1zg2m-8>li:before{content:"-  "}.lst-kix_tvu7bmfefz32-3>li:before{content:"-  "}.lst-kix_wf1o55flzq55-2>li:before{content:"-  "}.lst-kix_dln561wj05xo-0>li:before{content:"-  "}.lst-kix_awlaex77cpwh-5>li:before{content:"-  "}.lst-kix_qsto019ofcm1-1>li:before{content:"-  "}ul.lst-kix_7gk9ayd44tft-7{list-style-type:none}ul.lst-kix_7gk9ayd44tft-8{list-style-type:none}ul.lst-kix_7gk9ayd44tft-5{list-style-type:none}ul.lst-kix_7gk9ayd44tft-6{list-style-type:none}ul.lst-kix_7gk9ayd44tft-3{list-style-type:none}ul.lst-kix_7gk9ayd44tft-4{list-style-type:none}ul.lst-kix_7gk9ayd44tft-1{list-style-type:none}ul.lst-kix_7gk9ayd44tft-2{list-style-type:none}ul.lst-kix_7gk9ayd44tft-0{list-style-type:none}.lst-kix_f9iu0trsjas1-7>li:before{content:"-  "}.lst-kix_g9hblcm1l6tk-7>li:before{content:"-  "}.lst-kix_e73zm9q3mvin-2>li:before{content:"-  "}ul.lst-kix_eme1x4epzdye-4{list-style-type:none}.lst-kix_qvomcnyqz8ao-7>li:before{content:"-  "}ul.lst-kix_eme1x4epzdye-5{list-style-type:none}ul.lst-kix_eme1x4epzdye-6{list-style-type:none}.lst-kix_g9hblcm1l6tk-4>li:before{content:"-  "}ul.lst-kix_eme1x4epzdye-7{list-style-type:none}ul.lst-kix_eme1x4epzdye-0{list-style-type:none}ul.lst-kix_eme1x4epzdye-1{list-style-type:none}ul.lst-kix_eme1x4epzdye-2{list-style-type:none}.lst-kix_ozbrn4vmjez8-0>li:before{content:"-  "}ul.lst-kix_eme1x4epzdye-3{list-style-type:none}ul.lst-kix_eme1x4epzdye-8{list-style-type:none}.lst-kix_s0nbf6s2np44-4>li:before{content:"-  "}ol.lst-kix_3fc7x0lm2mmz-5.start{counter-reset:lst-ctn-kix_3fc7x0lm2mmz-5 0}.lst-kix_7e64bsb5krip-3>li:before{content:"-  "}.lst-kix_ozbrn4vmjez8-3>li:before{content:"-  "}.lst-kix_ozbrn4vmjez8-6>li:before{content:"-  "}.lst-kix_dmn3lqzfmokk-7>li:before{content:"-  "}ul.lst-kix_kp4gb6sd08f1-0{list-style-type:none}.lst-kix_w21i9d12ynhg-5>li:before{content:"-  "}.lst-kix_nipj94pw11x6-7>li:before{content:"-  "}.lst-kix_2xixyk6jteti-6>li:before{content:"-  "}.lst-kix_zjjx8lb18sy-5>li:before{content:"-  "}.lst-kix_kt8k33f35qi5-1>li:before{content:"-  "}.lst-kix_zjjx8lb18sy-2>li:before{content:"-  "}.lst-kix_kt8k33f35qi5-4>li:before{content:"-  "}.lst-kix_nqtgcebhe8ii-3>li:before{content:"-  "}.lst-kix_4pjeuglo4z6v-3>li:before{content:"-  "}ul.lst-kix_kp4gb6sd08f1-8{list-style-type:none}ul.lst-kix_kp4gb6sd08f1-7{list-style-type:none}ul.lst-kix_kp4gb6sd08f1-6{list-style-type:none}.lst-kix_w21i9d12ynhg-8>li:before{content:"-  "}ul.lst-kix_kp4gb6sd08f1-5{list-style-type:none}ul.lst-kix_kp4gb6sd08f1-4{list-style-type:none}.lst-kix_zjjx8lb18sy-8>li:before{content:"-  "}ul.lst-kix_kp4gb6sd08f1-3{list-style-type:none}ul.lst-kix_kp4gb6sd08f1-2{list-style-type:none}.lst-kix_kt8k33f35qi5-7>li:before{content:"-  "}ul.lst-kix_kp4gb6sd08f1-1{list-style-type:none}.lst-kix_ms6rbzn59hmq-4>li:before{content:"-  "}.lst-kix_zb3jq278pptw-1>li:before{content:"-  "}.lst-kix_bsvmcpoa86br-3>li:before{content:"-  "}.lst-kix_e73zm9q3mvin-5>li:before{content:"-  "}.lst-kix_8a5plp401pog-0>li:before{content:"-  "}ul.lst-kix_ukx3y28hag8h-0{list-style-type:none}ul.lst-kix_ukx3y28hag8h-1{list-style-type:none}ul.lst-kix_ukx3y28hag8h-2{list-style-type:none}ul.lst-kix_ukx3y28hag8h-3{list-style-type:none}ul.lst-kix_ukx3y28hag8h-4{list-style-type:none}.lst-kix_luixtz7s7e5x-8>li:before{content:"-  "}ul.lst-kix_ukx3y28hag8h-5{list-style-type:none}.lst-kix_f9iu0trsjas1-4>li:before{content:"-  "}ul.lst-kix_ukx3y28hag8h-6{list-style-type:none}ul.lst-kix_ukx3y28hag8h-7{list-style-type:none}ul.lst-kix_ukx3y28hag8h-8{list-style-type:none}.lst-kix_bsvmcpoa86br-6>li:before{content:"-  "}.lst-kix_w21i9d12ynhg-2>li:before{content:"-  "}.lst-kix_ms6rbzn59hmq-7>li:before{content:"-  "}.lst-kix_8a5plp401pog-3>li:before{content:"-  "}.lst-kix_nqtgcebhe8ii-0>li:before{content:"-  "}.lst-kix_t6x6ie377r4u-4>li:before{content:"-  "}.lst-kix_7vvt5hs6rdl-7>li:before{content:"-  "}.lst-kix_dln561wj05xo-3>li:before{content:"-  "}.lst-kix_oswsfzrgbvyb-2>li:before{content:"-  "}.lst-kix_p02ob1bzv6e4-3>li:before{content:"-  "}.lst-kix_qij6192l4p0g-7>li:before{content:"-  "}.lst-kix_jvmsa1jxmzig-4>li:before{content:"\0025cb   "}.lst-kix_mq980hprr5hl-4>li:before{content:"-  "}.lst-kix_a62ncfcuapzo-2>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-5>li{counter-increment:lst-ctn-kix_3fc7x0lm2mmz-5}.lst-kix_dmxresnhzo8y-2>li:before{content:"-  "}.lst-kix_9hby2lis2y9u-7>li:before{content:"-  "}.lst-kix_a42anijqpp8a-0>li:before{content:"-  "}.lst-kix_2ei6b6e4ow80-4>li:before{content:"-  "}.lst-kix_iffqre5r12zx-4>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-1>li:before{content:"" counter(lst-ctn-kix_3mj3tp7kj9db-1,lower-latin) ") "}.lst-kix_5jp9wppv00ra-3>li:before{content:"-  "}.lst-kix_ssze0kg2kz13-3>li:before{content:"-  "}.lst-kix_alhag51wggig-6>li:before{content:"-  "}.lst-kix_7vaamq35f1cc-7>li:before{content:"-  "}.lst-kix_ugixx4nd67zw-7>li:before{content:"-  "}ul.lst-kix_8w7txqc6xq66-6{list-style-type:none}ul.lst-kix_8w7txqc6xq66-7{list-style-type:none}ul.lst-kix_8w7txqc6xq66-4{list-style-type:none}ul.lst-kix_8w7txqc6xq66-5{list-style-type:none}ul.lst-kix_8w7txqc6xq66-2{list-style-type:none}ul.lst-kix_8w7txqc6xq66-3{list-style-type:none}.lst-kix_9hby2lis2y9u-1>li:before{content:"-  "}ul.lst-kix_8w7txqc6xq66-0{list-style-type:none}ul.lst-kix_8w7txqc6xq66-1{list-style-type:none}.lst-kix_6n4varno3bjs-3>li:before{content:"-  "}.lst-kix_52jgzw489fhs-7>li:before{content:"" counter(lst-ctn-kix_52jgzw489fhs-7,lower-latin) ". "}.lst-kix_f9iqanr8ite6-1>li:before{content:"-  "}ul.lst-kix_8w7txqc6xq66-8{list-style-type:none}.lst-kix_rtczm6eelr4h-6>li:before{content:"-  "}ol.lst-kix_84zf7o74c8s9-8.start{counter-reset:lst-ctn-kix_84zf7o74c8s9-8 0}.lst-kix_5u0542f2h2jt-1>li:before{content:"+  "}.lst-kix_om0x63wgf9wd-1>li:before{content:"-  "}.lst-kix_upq3ni6ul8eb-8>li:before{content:"-  "}ul.lst-kix_a62ncfcuapzo-5{list-style-type:none}.lst-kix_aikphwux0ki0-3>li:before{content:"-  "}ul.lst-kix_a62ncfcuapzo-6{list-style-type:none}.lst-kix_8hf94791m5p0-1>li:before{content:"-  "}ol.lst-kix_ypd5gkkarijk-4.start{counter-reset:lst-ctn-kix_ypd5gkkarijk-4 0}ul.lst-kix_a62ncfcuapzo-3{list-style-type:none}ul.lst-kix_a62ncfcuapzo-4{list-style-type:none}.lst-kix_n0rv3zxivae3-1>li:before{content:"-  "}ul.lst-kix_a62ncfcuapzo-1{list-style-type:none}.lst-kix_66ns622ckygr-8>li:before{content:"-  "}ul.lst-kix_a62ncfcuapzo-2{list-style-type:none}ul.lst-kix_a62ncfcuapzo-0{list-style-type:none}.lst-kix_xhhdon4tpeu0-7>li:before{content:"-  "}ul.lst-kix_a62ncfcuapzo-7{list-style-type:none}ul.lst-kix_a62ncfcuapzo-8{list-style-type:none}.lst-kix_7e64bsb5krip-0>li:before{content:"-  "}.lst-kix_hssoi9jbujv-3>li:before{content:"-  "}.lst-kix_52jgzw489fhs-1>li:before{content:"" counter(lst-ctn-kix_52jgzw489fhs-1,lower-latin) ". "}.lst-kix_epyrmry7301m-6>li:before{content:"-  "}ul.lst-kix_zag3ymt8mk2y-5{list-style-type:none}.lst-kix_epyrmry7301m-0>li:before{content:"-  "}ul.lst-kix_zag3ymt8mk2y-6{list-style-type:none}ol.lst-kix_3fc7x0lm2mmz-7.start{counter-reset:lst-ctn-kix_3fc7x0lm2mmz-7 0}ul.lst-kix_zag3ymt8mk2y-7{list-style-type:none}ul.lst-kix_zag3ymt8mk2y-8{list-style-type:none}ul.lst-kix_zag3ymt8mk2y-1{list-style-type:none}ul.lst-kix_zag3ymt8mk2y-2{list-style-type:none}ul.lst-kix_zag3ymt8mk2y-3{list-style-type:none}ul.lst-kix_zag3ymt8mk2y-4{list-style-type:none}ul.lst-kix_qb494lue4ahb-8{list-style-type:none}ul.lst-kix_5argtotmwusw-4{list-style-type:none}ul.lst-kix_5argtotmwusw-5{list-style-type:none}ul.lst-kix_5argtotmwusw-2{list-style-type:none}ul.lst-kix_zag3ymt8mk2y-0{list-style-type:none}ul.lst-kix_5argtotmwusw-3{list-style-type:none}ul.lst-kix_qb494lue4ahb-4{list-style-type:none}ul.lst-kix_5argtotmwusw-8{list-style-type:none}ul.lst-kix_qb494lue4ahb-5{list-style-type:none}ul.lst-kix_qb494lue4ahb-6{list-style-type:none}ul.lst-kix_5argtotmwusw-6{list-style-type:none}ul.lst-kix_qb494lue4ahb-7{list-style-type:none}ul.lst-kix_5argtotmwusw-7{list-style-type:none}ul.lst-kix_qb494lue4ahb-0{list-style-type:none}ul.lst-kix_qb494lue4ahb-1{list-style-type:none}ul.lst-kix_qb494lue4ahb-2{list-style-type:none}ul.lst-kix_qb494lue4ahb-3{list-style-type:none}ul.lst-kix_5argtotmwusw-0{list-style-type:none}ul.lst-kix_5argtotmwusw-1{list-style-type:none}.lst-kix_vuz55xpe5xjl-3>li:before{content:"-  "}.lst-kix_8wvqr5f1zg2m-2>li:before{content:"-  "}.lst-kix_incqcf2p39ls-7>li{counter-increment:lst-ctn-kix_incqcf2p39ls-7}.lst-kix_p1rtf0e14360-2>li:before{content:"-  "}.lst-kix_67mv29rpwb23-2>li:before{content:"-  "}.lst-kix_oxgbebk5l98i-3>li:before{content:"-  "}ul.lst-kix_9a7xq1ie41tp-2{list-style-type:none}.lst-kix_w32pgwk3f0lb-0>li:before{content:"-  "}.lst-kix_jnfn9mx5o33t-6>li:before{content:"-  "}ul.lst-kix_9a7xq1ie41tp-1{list-style-type:none}ul.lst-kix_9a7xq1ie41tp-0{list-style-type:none}.lst-kix_gerk886qza0c-8>li:before{content:"-  "}.lst-kix_oxgbebk5l98i-0>li:before{content:"-  "}.lst-kix_ro388iryhhf5-4>li:before{content:"-  "}ul.lst-kix_xx6ude5yqnkl-3{list-style-type:none}.lst-kix_ro388iryhhf5-1>li:before{content:"-  "}ul.lst-kix_xx6ude5yqnkl-4{list-style-type:none}ul.lst-kix_xx6ude5yqnkl-5{list-style-type:none}ul.lst-kix_xx6ude5yqnkl-6{list-style-type:none}ul.lst-kix_xx6ude5yqnkl-0{list-style-type:none}.lst-kix_ltm9vv1op5tt-7>li:before{content:"-  "}ul.lst-kix_xx6ude5yqnkl-1{list-style-type:none}ul.lst-kix_xx6ude5yqnkl-2{list-style-type:none}.lst-kix_eiskzjj27gc6-3>li:before{content:"-  "}.lst-kix_ltm9vv1op5tt-4>li:before{content:"-  "}.lst-kix_xktbtduo53bq-6>li{counter-increment:lst-ctn-kix_xktbtduo53bq-6}ul.lst-kix_xx6ude5yqnkl-7{list-style-type:none}.lst-kix_fs1lzw38maxl-6>li:before{content:"-  "}ul.lst-kix_xx6ude5yqnkl-8{list-style-type:none}ol.lst-kix_yvohqcnu3146-8.start{counter-reset:lst-ctn-kix_yvohqcnu3146-8 0}.lst-kix_fm53cr9wmch0-1>li:before{content:"-  "}.lst-kix_2nm562bzmwr-7>li:before{content:"-  "}.lst-kix_cd2o0cncsajm-7>li:before{content:"-  "}.lst-kix_vuz55xpe5xjl-6>li:before{content:"-  "}.lst-kix_m5azvtuvtpt1-4>li:before{content:"-  "}.lst-kix_4ypcpsaj0q6h-8>li:before{content:"-  "}ul.lst-kix_dmxresnhzo8y-1{list-style-type:none}ul.lst-kix_dmxresnhzo8y-0{list-style-type:none}ul.lst-kix_dmxresnhzo8y-3{list-style-type:none}.lst-kix_81v91kbrmywy-2>li:before{content:"-  "}ul.lst-kix_dmxresnhzo8y-2{list-style-type:none}.lst-kix_9z31rmzc855z-2>li:before{content:"-  "}ul.lst-kix_dmxresnhzo8y-5{list-style-type:none}.lst-kix_voj7evacrpie-1>li:before{content:"-  "}ul.lst-kix_dmxresnhzo8y-4{list-style-type:none}.lst-kix_jvmsa1jxmzig-7>li:before{content:"\0025cb   "}ul.lst-kix_dmxresnhzo8y-7{list-style-type:none}.lst-kix_81v91kbrmywy-5>li:before{content:"-  "}ul.lst-kix_dmxresnhzo8y-6{list-style-type:none}.lst-kix_84zf7o74c8s9-0>li{counter-increment:lst-ctn-kix_84zf7o74c8s9-0}ul.lst-kix_dmxresnhzo8y-8{list-style-type:none}.lst-kix_azgj6sn0lxuj-2>li{counter-increment:lst-ctn-kix_azgj6sn0lxuj-2}.lst-kix_m5azvtuvtpt1-7>li:before{content:"-  "}.lst-kix_voj7evacrpie-4>li:before{content:"-  "}.lst-kix_hkt83gwcgrvq-1>li:before{content:"-  "}ul.lst-kix_2ccdqvrbclt-1{list-style-type:none}ul.lst-kix_2ccdqvrbclt-2{list-style-type:none}.lst-kix_t6x6ie377r4u-1>li:before{content:"-  "}ul.lst-kix_2ccdqvrbclt-3{list-style-type:none}.lst-kix_p02ob1bzv6e4-0>li:before{content:"-  "}ul.lst-kix_2ccdqvrbclt-4{list-style-type:none}.lst-kix_q24qpifeknc3-2>li:before{content:"-  "}ol.lst-kix_3fc7x0lm2mmz-3.start{counter-reset:lst-ctn-kix_3fc7x0lm2mmz-3 0}.lst-kix_8euewcidoez8-2>li:before{content:"-  "}ul.lst-kix_2ccdqvrbclt-0{list-style-type:none}.lst-kix_5nilpkhthb5t-1>li:before{content:"-  "}.lst-kix_9hby2lis2y9u-4>li:before{content:"-  "}.lst-kix_hc732m8hksyq-2>li:before{content:"-  "}ol.lst-kix_vayf18aqt55o-8.start{counter-reset:lst-ctn-kix_vayf18aqt55o-8 0}.lst-kix_wwm574aidb8n-2>li:before{content:"-  "}.lst-kix_x95t913s41kt-8>li:before{content:"-  "}ul.lst-kix_2ccdqvrbclt-5{list-style-type:none}ul.lst-kix_2ccdqvrbclt-6{list-style-type:none}ul.lst-kix_2ccdqvrbclt-7{list-style-type:none}ul.lst-kix_2ccdqvrbclt-8{list-style-type:none}.lst-kix_dln561wj05xo-6>li:before{content:"-  "}.lst-kix_52jgzw489fhs-4>li:before{content:"" counter(lst-ctn-kix_52jgzw489fhs-4,lower-latin) ". "}.lst-kix_d7eif1vat32g-6>li:before{content:"-  "}.lst-kix_9j3np3ow732h-8>li:before{content:"\0025a0   "}.lst-kix_2ei6b6e4ow80-7>li:before{content:"-  "}.lst-kix_ssze0kg2kz13-0>li:before{content:"-  "}.lst-kix_eiskzjj27gc6-6>li:before{content:"-  "}.lst-kix_iffqre5r12zx-1>li:before{content:"-  "}.lst-kix_5jp9wppv00ra-0>li:before{content:"-  "}ul.lst-kix_r8adx85jg0iz-0{list-style-type:none}.lst-kix_hngwf7orguk6-2>li:before{content:"-  "}.lst-kix_i8kfgvsh0fwy-0>li:before{content:"-  "}ul.lst-kix_r8adx85jg0iz-5{list-style-type:none}ul.lst-kix_r8adx85jg0iz-6{list-style-type:none}ul.lst-kix_r8adx85jg0iz-7{list-style-type:none}ul.lst-kix_9a7xq1ie41tp-8{list-style-type:none}ul.lst-kix_r8adx85jg0iz-8{list-style-type:none}.lst-kix_6u6or33vx86s-4>li:before{content:"-  "}ul.lst-kix_9a7xq1ie41tp-7{list-style-type:none}ul.lst-kix_r8adx85jg0iz-1{list-style-type:none}ul.lst-kix_9a7xq1ie41tp-6{list-style-type:none}ul.lst-kix_r8adx85jg0iz-2{list-style-type:none}ul.lst-kix_9a7xq1ie41tp-5{list-style-type:none}ul.lst-kix_r8adx85jg0iz-3{list-style-type:none}ul.lst-kix_9a7xq1ie41tp-4{list-style-type:none}ul.lst-kix_r8adx85jg0iz-4{list-style-type:none}ul.lst-kix_9a7xq1ie41tp-3{list-style-type:none}.lst-kix_1pt1eqcq4ieh-0>li:before{content:"-  "}.lst-kix_yhq927c05ak0-3>li:before{content:"-  "}ul.lst-kix_hytfj9icha07-6{list-style-type:none}.lst-kix_aikphwux0ki0-0>li:before{content:"-  "}ul.lst-kix_hytfj9icha07-5{list-style-type:none}ul.lst-kix_pgnpvlxhai6o-0{list-style-type:none}ul.lst-kix_hytfj9icha07-8{list-style-type:none}ul.lst-kix_hytfj9icha07-7{list-style-type:none}.lst-kix_npanryo7f1m7-8>li:before{content:"-  "}.lst-kix_l5iaj94ondn3-8>li:before{content:"-  "}.lst-kix_epyrmry7301m-3>li:before{content:"-  "}ul.lst-kix_hytfj9icha07-2{list-style-type:none}ul.lst-kix_hytfj9icha07-1{list-style-type:none}ul.lst-kix_hytfj9icha07-4{list-style-type:none}ul.lst-kix_hytfj9icha07-3{list-style-type:none}ol.lst-kix_vayf18aqt55o-6.start{counter-reset:lst-ctn-kix_vayf18aqt55o-6 0}ul.lst-kix_hytfj9icha07-0{list-style-type:none}.lst-kix_7gk9ayd44tft-7>li:before{content:"-  "}.lst-kix_g8jgbze430sv-3>li{counter-increment:lst-ctn-kix_g8jgbze430sv-3}.lst-kix_tjrvr4c0ezjq-2>li:before{content:"-  "}.lst-kix_6ltb10qoez57-3>li:before{content:"\0025cf   "}ul.lst-kix_pgnpvlxhai6o-2{list-style-type:none}ul.lst-kix_pgnpvlxhai6o-1{list-style-type:none}ul.lst-kix_pgnpvlxhai6o-4{list-style-type:none}ul.lst-kix_pgnpvlxhai6o-3{list-style-type:none}ul.lst-kix_pgnpvlxhai6o-6{list-style-type:none}ul.lst-kix_pgnpvlxhai6o-5{list-style-type:none}ul.lst-kix_pgnpvlxhai6o-8{list-style-type:none}ul.lst-kix_pgnpvlxhai6o-7{list-style-type:none}.lst-kix_bnte1i3g4kjh-5>li:before{content:"-  "}.lst-kix_4i10vbfgn91y-2>li:before{content:"-  "}.lst-kix_gfc2v9r4qc22-6>li:before{content:"-  "}ol.lst-kix_ypd5gkkarijk-3.start{counter-reset:lst-ctn-kix_ypd5gkkarijk-3 0}.lst-kix_gvlgpawofwi7-1>li:before{content:"-  "}.lst-kix_2r20t3tmnrwb-1>li:before{content:"-  "}.lst-kix_7vr84ges94ry-5>li:before{content:"-  "}.lst-kix_gvlgpawofwi7-5>li:before{content:"-  "}.lst-kix_yrg2qlcqvak1-8>li:before{content:"-  "}.lst-kix_gfc2v9r4qc22-2>li:before{content:"-  "}ul.lst-kix_ce3ho29dhteb-8{list-style-type:none}ul.lst-kix_ce3ho29dhteb-7{list-style-type:none}ul.lst-kix_ce3ho29dhteb-4{list-style-type:none}ul.lst-kix_ce3ho29dhteb-3{list-style-type:none}ul.lst-kix_ce3ho29dhteb-6{list-style-type:none}ul.lst-kix_ce3ho29dhteb-5{list-style-type:none}.lst-kix_6o2cphkh2n8b-3>li:before{content:"-  "}ol.lst-kix_3mj3tp7kj9db-6.start{counter-reset:lst-ctn-kix_3mj3tp7kj9db-6 0}.lst-kix_n9q8wqas57a-4>li:before{content:"-  "}.lst-kix_g8jgbze430sv-5>li:before{content:"(" counter(lst-ctn-kix_g8jgbze430sv-5,lower-roman) ") "}.lst-kix_dvvzixfw64a1-5>li:before{content:"-  "}.lst-kix_4xiv877yc8jl-6>li:before{content:"-  "}.lst-kix_svg8hnl23b1r-3>li:before{content:"-  "}ul.lst-kix_ce3ho29dhteb-0{list-style-type:none}.lst-kix_4xiv877yc8jl-2>li:before{content:"-  "}ul.lst-kix_ce3ho29dhteb-2{list-style-type:none}ul.lst-kix_ce3ho29dhteb-1{list-style-type:none}.lst-kix_ul22dko4fd2j-8>li:before{content:"-  "}.lst-kix_ug10x97qcpi8-2>li:before{content:"-  "}.lst-kix_dvvzixfw64a1-1>li:before{content:"-  "}.lst-kix_x8ffawrvrcyq-7>li:before{content:"\0025cb   "}ol.lst-kix_xyra4e5ffsud-2.start{counter-reset:lst-ctn-kix_xyra4e5ffsud-2 0}ul.lst-kix_pg2i9lis4p1v-8{list-style-type:none}ul.lst-kix_pg2i9lis4p1v-7{list-style-type:none}.lst-kix_mv77cg19299c-1>li:before{content:"-  "}ul.lst-kix_pg2i9lis4p1v-6{list-style-type:none}ul.lst-kix_pg2i9lis4p1v-5{list-style-type:none}ul.lst-kix_pg2i9lis4p1v-4{list-style-type:none}.lst-kix_8ujam3zhcr3q-8>li:before{content:"-  "}ul.lst-kix_pg2i9lis4p1v-3{list-style-type:none}ol.lst-kix_5djgwp8c9ig2-2.start{counter-reset:lst-ctn-kix_5djgwp8c9ig2-2 0}ul.lst-kix_pg2i9lis4p1v-2{list-style-type:none}.lst-kix_aor1182clqbr-0>li:before{content:"-  "}ul.lst-kix_pg2i9lis4p1v-1{list-style-type:none}.lst-kix_mh5zhf27i4rj-6>li:before{content:"-  "}ul.lst-kix_pg2i9lis4p1v-0{list-style-type:none}ol.lst-kix_ypd5gkkarijk-8.start{counter-reset:lst-ctn-kix_ypd5gkkarijk-8 0}.lst-kix_co74fk70kphx-6>li:before{content:"-  "}.lst-kix_eme1x4epzdye-5>li:before{content:"-  "}.lst-kix_8ujam3zhcr3q-4>li:before{content:"-  "}.lst-kix_x8ffawrvrcyq-3>li:before{content:"\0025cf   "}.lst-kix_mh5zhf27i4rj-2>li:before{content:"-  "}.lst-kix_ul22dko4fd2j-0>li:before{content:"-  "}.lst-kix_hmvj5t8yy8bx-6>li:before{content:"+  "}.lst-kix_ofib0hkczw41-5>li:before{content:"-  "}.lst-kix_267f3xfv5ddr-3>li{counter-increment:lst-ctn-kix_267f3xfv5ddr-3}.lst-kix_lwlxuymndfyq-3>li:before{content:"-  "}.lst-kix_tt1bo8z9re67-6>li:before{content:"-  "}.lst-kix_gaq1zvh4dcgb-5>li:before{content:"-  "}.lst-kix_mv77cg19299c-5>li:before{content:"-  "}.lst-kix_o1voy78o4juz-2>li:before{content:"-  "}.lst-kix_axy5kxvo2nx7-8>li:before{content:"-  "}.lst-kix_jhofo94iol1-2>li:before{content:"-  "}.lst-kix_x12ed5cs6o9z-0>li:before{content:"-  "}.lst-kix_m5azvtuvtpt1-1>li:before{content:"-  "}ol.lst-kix_t3rn73qejgkj-8{list-style-type:none}.lst-kix_4qbfcta6cclt-0>li:before{content:"-  "}ol.lst-kix_t3rn73qejgkj-3{list-style-type:none}ol.lst-kix_t3rn73qejgkj-2{list-style-type:none}ol.lst-kix_t3rn73qejgkj-1{list-style-type:none}ol.lst-kix_t3rn73qejgkj-0{list-style-type:none}.lst-kix_jhofo94iol1-6>li:before{content:"-  "}ol.lst-kix_t3rn73qejgkj-7{list-style-type:none}ol.lst-kix_t3rn73qejgkj-6{list-style-type:none}ol.lst-kix_t3rn73qejgkj-5{list-style-type:none}.lst-kix_wwm574aidb8n-5>li:before{content:"-  "}ol.lst-kix_t3rn73qejgkj-4{list-style-type:none}.lst-kix_ekasiajyrrvz-8>li:before{content:"-  "}.lst-kix_d7eif1vat32g-7>li:before{content:"-  "}.lst-kix_x95t913s41kt-1>li:before{content:"-  "}.lst-kix_5nilpkhthb5t-8>li:before{content:"-  "}.lst-kix_hngwf7orguk6-7>li:before{content:"-  "}.lst-kix_wwm574aidb8n-1>li:before{content:"-  "}.lst-kix_ekasiajyrrvz-4>li:before{content:"-  "}.lst-kix_axy5kxvo2nx7-4>li:before{content:"-  "}.lst-kix_d7eif1vat32g-3>li:before{content:"-  "}.lst-kix_9a7xq1ie41tp-2>li:before{content:"-  "}ul.lst-kix_ctweb0b3a38f-8{list-style-type:none}ul.lst-kix_ctweb0b3a38f-7{list-style-type:none}.lst-kix_x1xhkkpc69w2-2>li:before{content:"-  "}ul.lst-kix_ctweb0b3a38f-4{list-style-type:none}ul.lst-kix_ctweb0b3a38f-3{list-style-type:none}ul.lst-kix_ctweb0b3a38f-6{list-style-type:none}ul.lst-kix_ctweb0b3a38f-5{list-style-type:none}ol.lst-kix_vayf18aqt55o-0.start{counter-reset:lst-ctn-kix_vayf18aqt55o-0 0}ul.lst-kix_e3u4u2bj7x9w-7{list-style-type:none}ul.lst-kix_e3u4u2bj7x9w-6{list-style-type:none}ul.lst-kix_e3u4u2bj7x9w-5{list-style-type:none}.lst-kix_hytfj9icha07-5>li:before{content:"-  "}ul.lst-kix_e3u4u2bj7x9w-4{list-style-type:none}ul.lst-kix_5rn2qrejqs3r-0{list-style-type:none}ul.lst-kix_e3u4u2bj7x9w-3{list-style-type:none}ul.lst-kix_e3u4u2bj7x9w-2{list-style-type:none}ul.lst-kix_e3u4u2bj7x9w-1{list-style-type:none}ul.lst-kix_e3u4u2bj7x9w-0{list-style-type:none}ul.lst-kix_5rn2qrejqs3r-5{list-style-type:none}ul.lst-kix_5rn2qrejqs3r-6{list-style-type:none}ul.lst-kix_5rn2qrejqs3r-7{list-style-type:none}.lst-kix_ukx3y28hag8h-0>li:before{content:"-  "}ul.lst-kix_5rn2qrejqs3r-8{list-style-type:none}ul.lst-kix_5rn2qrejqs3r-1{list-style-type:none}ul.lst-kix_5rn2qrejqs3r-2{list-style-type:none}ul.lst-kix_5rn2qrejqs3r-3{list-style-type:none}ul.lst-kix_e3u4u2bj7x9w-8{list-style-type:none}ul.lst-kix_5rn2qrejqs3r-4{list-style-type:none}ul.lst-kix_wf1o55flzq55-7{list-style-type:none}ul.lst-kix_wf1o55flzq55-8{list-style-type:none}.lst-kix_rcfi5jnwnxji-4>li:before{content:"-  "}.lst-kix_7vr84ges94ry-1>li:before{content:"-  "}.lst-kix_qmx92jmkghx8-2>li:before{content:"-  "}.lst-kix_5stj9b6acoxv-4>li:before{content:"" counter(lst-ctn-kix_5stj9b6acoxv-4,lower-latin) ". "}.lst-kix_ellvdfsu2z7q-8>li:before{content:"-  "}ul.lst-kix_ctweb0b3a38f-0{list-style-type:none}ul.lst-kix_wf1o55flzq55-0{list-style-type:none}ul.lst-kix_ctweb0b3a38f-2{list-style-type:none}ul.lst-kix_wf1o55flzq55-1{list-style-type:none}ul.lst-kix_ctweb0b3a38f-1{list-style-type:none}ul.lst-kix_wf1o55flzq55-2{list-style-type:none}ul.lst-kix_wf1o55flzq55-3{list-style-type:none}.lst-kix_njs8ubf1qesf-8>li:before{content:"-  "}.lst-kix_x12ed5cs6o9z-4>li:before{content:"-  "}ul.lst-kix_wf1o55flzq55-4{list-style-type:none}ol.lst-kix_5stj9b6acoxv-4.start{counter-reset:lst-ctn-kix_5stj9b6acoxv-4 0}ul.lst-kix_wf1o55flzq55-5{list-style-type:none}ul.lst-kix_wf1o55flzq55-6{list-style-type:none}ul.lst-kix_puc0azh4kjfq-8{list-style-type:none}ul.lst-kix_puc0azh4kjfq-2{list-style-type:none}ul.lst-kix_puc0azh4kjfq-3{list-style-type:none}ul.lst-kix_puc0azh4kjfq-0{list-style-type:none}ul.lst-kix_puc0azh4kjfq-1{list-style-type:none}ul.lst-kix_puc0azh4kjfq-6{list-style-type:none}.lst-kix_ozrjmre97pex-7>li:before{content:"-  "}ul.lst-kix_puc0azh4kjfq-7{list-style-type:none}ul.lst-kix_puc0azh4kjfq-4{list-style-type:none}ul.lst-kix_puc0azh4kjfq-5{list-style-type:none}.lst-kix_mtm8lwd6vxjl-3>li:before{content:"-  "}.lst-kix_5syfdd8x3l8s-1>li:before{content:"-  "}.lst-kix_1x319pprarxc-8>li:before{content:"-  "}.lst-kix_1x319pprarxc-0>li:before{content:"-  "}.lst-kix_1xkx8gh1e8n7-8>li:before{content:"-  "}.lst-kix_x74x9xa8n5a0-2>li:before{content:"-  "}.lst-kix_4ii5776egvw8-2>li:before{content:"-  "}ol.lst-kix_ykhoydml7pv3-5.start{counter-reset:lst-ctn-kix_ykhoydml7pv3-5 0}.lst-kix_oxgbebk5l98i-5>li:before{content:"-  "}.lst-kix_8w03xjt2k9bc-5>li:before{content:"-  "}.lst-kix_ro388iryhhf5-6>li:before{content:"-  "}.lst-kix_b3ghc04lfx9t-5>li:before{content:"-  "}.lst-kix_n9qabngdxy64-3>li:before{content:"-  "}.lst-kix_tnd0p97rqwub-2>li:before{content:"-  "}.lst-kix_b3ghc04lfx9t-1>li:before{content:"-  "}.lst-kix_6vg5692ogph-7>li:before{content:"-  "}.lst-kix_tw1wz6pba43e-6>li:before{content:"-  "}.lst-kix_3wxxpxfz40sk-3>li:before{content:"-  "}.lst-kix_23ct987xwu67-0>li:before{content:"" counter(lst-ctn-kix_23ct987xwu67-0,decimal) ") "}.lst-kix_zag3ymt8mk2y-0>li:before{content:"-  "}ol.lst-kix_ysfu1bl0kymd-4.start{counter-reset:lst-ctn-kix_ysfu1bl0kymd-4 0}ol.lst-kix_yvohqcnu3146-3.start{counter-reset:lst-ctn-kix_yvohqcnu3146-3 0}.lst-kix_i2q40uf7647f-6>li:before{content:"-  "}.lst-kix_mtm8lwd6vxjl-7>li:before{content:"-  "}.lst-kix_81v91kbrmywy-0>li:before{content:"-  "}.lst-kix_m5azvtuvtpt1-5>li:before{content:"-  "}.lst-kix_3wxxpxfz40sk-7>li:before{content:"-  "}.lst-kix_23ct987xwu67-4>li:before{content:"(" counter(lst-ctn-kix_23ct987xwu67-4,lower-latin) ") "}.lst-kix_cg6jep1fmawj-7>li:before{content:"-  "}ol.lst-kix_vgg0538grxk3-8.start{counter-reset:lst-ctn-kix_vgg0538grxk3-8 0}.lst-kix_7o1va6u13ska-0>li:before{content:"-  "}.lst-kix_np9h4y3kt4yk-7>li:before{content:"-  "}.lst-kix_8pn77unkg8hg-1>li:before{content:"-  "}.lst-kix_5rn2qrejqs3r-5>li:before{content:"-  "}.lst-kix_k5hm652wcnm2-8>li:before{content:"-  "}.lst-kix_a2xq56ushw0p-1>li:before{content:"-  "}.lst-kix_rrloltks13s-6>li:before{content:"-  "}.lst-kix_innl5fto9oyf-4>li:before{content:"-  "}.lst-kix_innl5fto9oyf-8>li:before{content:"-  "}ol.lst-kix_u8nobwiguyj1-1.start{counter-reset:lst-ctn-kix_u8nobwiguyj1-1 0}.lst-kix_l60gvbdij7aj-2>li:before{content:"-  "}.lst-kix_arcio13zm8ud-0>li:before{content:"-  "}.lst-kix_arcio13zm8ud-8>li:before{content:"-  "}.lst-kix_upq3ni6ul8eb-1>li:before{content:"-  "}ul.lst-kix_hmvj5t8yy8bx-0{list-style-type:none}ul.lst-kix_hmvj5t8yy8bx-1{list-style-type:none}ul.lst-kix_hmvj5t8yy8bx-2{list-style-type:none}ul.lst-kix_hmvj5t8yy8bx-3{list-style-type:none}ul.lst-kix_hmvj5t8yy8bx-4{list-style-type:none}ul.lst-kix_hmvj5t8yy8bx-5{list-style-type:none}ul.lst-kix_hmvj5t8yy8bx-6{list-style-type:none}.lst-kix_9hby2lis2y9u-2>li:before{content:"-  "}ul.lst-kix_hmvj5t8yy8bx-7{list-style-type:none}.lst-kix_o7acnutkhp1w-6>li:before{content:"-  "}ul.lst-kix_hmvj5t8yy8bx-8{list-style-type:none}.lst-kix_tw1wz6pba43e-2>li:before{content:"-  "}ol.lst-kix_sxixw4iqsgzx-5.start{counter-reset:lst-ctn-kix_sxixw4iqsgzx-5 0}.lst-kix_4z9ptm6a4lke-3>li:before{content:"-  "}ul.lst-kix_bsvmcpoa86br-2{list-style-type:none}.lst-kix_7rlftcume51v-0>li:before{content:"-  "}ul.lst-kix_bsvmcpoa86br-3{list-style-type:none}ol.lst-kix_2foc6u9lzfq4-7.start{counter-reset:lst-ctn-kix_2foc6u9lzfq4-7 0}ul.lst-kix_bsvmcpoa86br-0{list-style-type:none}.lst-kix_ms4jfr9nudpc-0>li:before{content:"-  "}.lst-kix_ms4jfr9nudpc-4>li:before{content:"-  "}ul.lst-kix_bsvmcpoa86br-1{list-style-type:none}ul.lst-kix_bsvmcpoa86br-6{list-style-type:none}ul.lst-kix_bsvmcpoa86br-7{list-style-type:none}ul.lst-kix_bsvmcpoa86br-4{list-style-type:none}ul.lst-kix_i2q40uf7647f-1{list-style-type:none}ul.lst-kix_bsvmcpoa86br-5{list-style-type:none}ul.lst-kix_i2q40uf7647f-0{list-style-type:none}.lst-kix_4z9ptm6a4lke-7>li:before{content:"-  "}ul.lst-kix_bsvmcpoa86br-8{list-style-type:none}.lst-kix_khixc8f7o03u-0>li:before{content:"-  "}ul.lst-kix_i2q40uf7647f-7{list-style-type:none}ul.lst-kix_i2q40uf7647f-6{list-style-type:none}ul.lst-kix_i2q40uf7647f-8{list-style-type:none}.lst-kix_p2dhxl6hicde-2>li:before{content:"-  "}ul.lst-kix_i2q40uf7647f-3{list-style-type:none}ul.lst-kix_i2q40uf7647f-2{list-style-type:none}ul.lst-kix_i2q40uf7647f-5{list-style-type:none}ul.lst-kix_i2q40uf7647f-4{list-style-type:none}.lst-kix_4voxeic75vm5-5>li:before{content:"-  "}.lst-kix_bswxvn1l22fp-1>li:before{content:"-  "}.lst-kix_py2swxy3gr0i-2>li:before{content:"-  "}.lst-kix_1xkx8gh1e8n7-0>li:before{content:"-  "}.lst-kix_r8i1fgeyliey-1>li:before{content:"-  "}.lst-kix_hrm7p8w30y7p-6>li:before{content:"-  "}.lst-kix_b7rulpv7obgl-5>li:before{content:"-  "}.lst-kix_spt2hfceke6p-4>li:before{content:"-  "}.lst-kix_194f2a56ajxk-6>li:before{content:"-  "}.lst-kix_m31se2npgu2r-8>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-7>li{counter-increment:lst-ctn-kix_hppu19i8fr2p-7}.lst-kix_a9h81iclzrpy-7>li:before{content:"-  "}ol.lst-kix_yvohqcnu3146-8{list-style-type:none}.lst-kix_ozbrn4vmjez8-1>li:before{content:"-  "}.lst-kix_g9hblcm1l6tk-0>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-3.start{counter-reset:lst-ctn-kix_incqcf2p39ls-3 0}.lst-kix_cmm6cscyrjti-4>li:before{content:"-  "}.lst-kix_rgd2g4si1ihs-3>li:before{content:"-  "}.lst-kix_ce3ho29dhteb-1>li:before{content:"-  "}.lst-kix_90bg3luq5inv-8>li:before{content:"" counter(lst-ctn-kix_90bg3luq5inv-8,lower-roman) ". "}ol.lst-kix_yvohqcnu3146-5{list-style-type:none}.lst-kix_vgg0538grxk3-3>li{counter-increment:lst-ctn-kix_vgg0538grxk3-3}.lst-kix_7e64bsb5krip-7>li:before{content:"-  "}ol.lst-kix_yvohqcnu3146-4{list-style-type:none}ol.lst-kix_yvohqcnu3146-7{list-style-type:none}.lst-kix_bo9wrgz88es4-5>li:before{content:"-  "}ol.lst-kix_yvohqcnu3146-6{list-style-type:none}ol.lst-kix_yvohqcnu3146-1{list-style-type:none}ol.lst-kix_yvohqcnu3146-0{list-style-type:none}ol.lst-kix_yvohqcnu3146-3{list-style-type:none}.lst-kix_s0nbf6s2np44-0>li:before{content:"-  "}ol.lst-kix_yvohqcnu3146-2{list-style-type:none}.lst-kix_w21i9d12ynhg-6>li:before{content:"-  "}.lst-kix_vvjhovkzyen7-3>li:before{content:"-  "}ul.lst-kix_khixc8f7o03u-3{list-style-type:none}.lst-kix_rp6rf03vbelo-1>li:before{content:"-  "}ul.lst-kix_khixc8f7o03u-2{list-style-type:none}ul.lst-kix_khixc8f7o03u-1{list-style-type:none}.lst-kix_h25uruhpfzux-8>li:before{content:"-  "}ul.lst-kix_khixc8f7o03u-0{list-style-type:none}ul.lst-kix_khixc8f7o03u-7{list-style-type:none}ul.lst-kix_khixc8f7o03u-6{list-style-type:none}ul.lst-kix_khixc8f7o03u-5{list-style-type:none}ul.lst-kix_khixc8f7o03u-4{list-style-type:none}.lst-kix_kt8k33f35qi5-3>li:before{content:"-  "}ul.lst-kix_khixc8f7o03u-8{list-style-type:none}.lst-kix_2xixyk6jteti-2>li:before{content:"-  "}.lst-kix_5djgwp8c9ig2-7>li{counter-increment:lst-ctn-kix_5djgwp8c9ig2-7}.lst-kix_x1n4jlo0gf1q-3>li:before{content:"-  "}.lst-kix_dmn3lqzfmokk-4>li:before{content:"-  "}.lst-kix_nqtgcebhe8ii-7>li:before{content:"-  "}.lst-kix_bsvmcpoa86br-2>li:before{content:"-  "}.lst-kix_e73zm9q3mvin-8>li:before{content:"-  "}.lst-kix_f9iu0trsjas1-1>li:before{content:"-  "}.lst-kix_8a5plp401pog-1>li:before{content:"-  "}ul.lst-kix_38p7uzj3qds3-1{list-style-type:none}ul.lst-kix_38p7uzj3qds3-0{list-style-type:none}ul.lst-kix_38p7uzj3qds3-3{list-style-type:none}ul.lst-kix_38p7uzj3qds3-2{list-style-type:none}.lst-kix_3koi1cw13a0-5>li:before{content:"-  "}.lst-kix_m31se2npgu2r-0>li:before{content:"-  "}.lst-kix_yxvs6rw7mq1w-6>li:before{content:"-  "}.lst-kix_luixtz7s7e5x-7>li:before{content:"-  "}.lst-kix_fld6w0ks1f0p-7>li:before{content:"-  "}ul.lst-kix_38p7uzj3qds3-8{list-style-type:none}ol.lst-kix_d1gy3hy5r3qj-4.start{counter-reset:lst-ctn-kix_d1gy3hy5r3qj-4 0}.lst-kix_17yxihawuh4r-7>li:before{content:"-  "}ul.lst-kix_38p7uzj3qds3-5{list-style-type:none}ul.lst-kix_38p7uzj3qds3-4{list-style-type:none}ul.lst-kix_38p7uzj3qds3-7{list-style-type:none}.lst-kix_r8adx85jg0iz-4>li:before{content:"-  "}.lst-kix_x424ckbm5jp1-1>li:before{content:"-  "}ul.lst-kix_38p7uzj3qds3-6{list-style-type:none}.lst-kix_rxevvtxfoovc-2>li:before{content:"-  "}.lst-kix_ms6rbzn59hmq-8>li:before{content:"-  "}.lst-kix_tl77ogq6q7u-4>li:before{content:"-  "}.lst-kix_lcru2cdgc87j-6>li:before{content:"-  "}.lst-kix_incqcf2p39ls-0>li:before{content:"" counter(lst-ctn-kix_incqcf2p39ls-0,decimal) ") "}.lst-kix_8drpzle0jo7q-4>li:before{content:"\0025cb   "}ul.lst-kix_1x319pprarxc-7{list-style-type:none}ul.lst-kix_1x319pprarxc-8{list-style-type:none}.lst-kix_qqbjjwnrc3l8-8>li:before{content:"-  "}.lst-kix_dmxresnhzo8y-6>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-5>li:before{content:"" counter(lst-ctn-kix_ysfu1bl0kymd-5,lower-roman) ". "}ul.lst-kix_x96zthrcdy1e-0{list-style-type:none}ul.lst-kix_ekasiajyrrvz-0{list-style-type:none}ul.lst-kix_x96zthrcdy1e-1{list-style-type:none}ul.lst-kix_ekasiajyrrvz-1{list-style-type:none}ul.lst-kix_x96zthrcdy1e-4{list-style-type:none}ul.lst-kix_ekasiajyrrvz-4{list-style-type:none}ul.lst-kix_x96zthrcdy1e-5{list-style-type:none}ul.lst-kix_ekasiajyrrvz-5{list-style-type:none}.lst-kix_rf3bfhvmysmh-5>li:before{content:"-  "}ul.lst-kix_x96zthrcdy1e-2{list-style-type:none}ul.lst-kix_ekasiajyrrvz-2{list-style-type:none}.lst-kix_3mj3tp7kj9db-5>li:before{content:"(" counter(lst-ctn-kix_3mj3tp7kj9db-5,lower-roman) ") "}ul.lst-kix_x96zthrcdy1e-3{list-style-type:none}ul.lst-kix_ekasiajyrrvz-3{list-style-type:none}ul.lst-kix_x96zthrcdy1e-8{list-style-type:none}ul.lst-kix_ekasiajyrrvz-8{list-style-type:none}ul.lst-kix_x96zthrcdy1e-6{list-style-type:none}ul.lst-kix_ekasiajyrrvz-6{list-style-type:none}ul.lst-kix_x96zthrcdy1e-7{list-style-type:none}ul.lst-kix_ekasiajyrrvz-7{list-style-type:none}.lst-kix_2ei6b6e4ow80-6>li:before{content:"-  "}.lst-kix_tagzs2njqau3-2>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-0>li{counter-increment:lst-ctn-kix_hppu19i8fr2p-0}.lst-kix_eiskzjj27gc6-5>li:before{content:"-  "}.lst-kix_a62ncfcuapzo-6>li:before{content:"-  "}.lst-kix_vgg0538grxk3-3>li:before{content:"(" counter(lst-ctn-kix_vgg0538grxk3-3,decimal) ") "}ul.lst-kix_1x319pprarxc-1{list-style-type:none}ul.lst-kix_1x319pprarxc-2{list-style-type:none}ul.lst-kix_1x319pprarxc-0{list-style-type:none}ul.lst-kix_1x319pprarxc-5{list-style-type:none}.lst-kix_66ns622ckygr-4>li:before{content:"-  "}ul.lst-kix_1x319pprarxc-6{list-style-type:none}ul.lst-kix_1x319pprarxc-3{list-style-type:none}.lst-kix_ivmzvkm69gsd-3>li:before{content:"-  "}.lst-kix_unv0ib1v43rp-5>li:before{content:"-  "}ul.lst-kix_1x319pprarxc-4{list-style-type:none}.lst-kix_waivoqs1cu5x-1>li:before{content:"-  "}.lst-kix_gboi4t2flod9-2>li:before{content:"-  "}.lst-kix_q95o92il1jwg-7>li:before{content:"-  "}.lst-kix_rtczm6eelr4h-2>li:before{content:"-  "}.lst-kix_267f3xfv5ddr-2>li:before{content:"" counter(lst-ctn-kix_267f3xfv5ddr-2,lower-roman) ". "}.lst-kix_f9iqanr8ite6-7>li:before{content:"-  "}.lst-kix_n0rv3zxivae3-7>li:before{content:"-  "}.lst-kix_qvomcnyqz8ao-3>li:before{content:"-  "}.lst-kix_pg2i9lis4p1v-0>li:before{content:"-  "}ol.lst-kix_hppu19i8fr2p-1.start{counter-reset:lst-ctn-kix_hppu19i8fr2p-1 0}.lst-kix_bdjoj2nf5hw9-6>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-8.start{counter-reset:lst-ctn-kix_incqcf2p39ls-8 0}.lst-kix_a42anijqpp8a-6>li:before{content:"-  "}.lst-kix_bb3pt2xtt0a5-0>li:before{content:"-  "}.lst-kix_dynlpr2uwt2p-7>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-5>li{counter-increment:lst-ctn-kix_u8nobwiguyj1-5}.lst-kix_epyrmry7301m-2>li:before{content:"-  "}.lst-kix_o17eseb5cr8e-3>li:before{content:"-  "}.lst-kix_d626gkjp4fou-1>li:before{content:"\0025cb   "}.lst-kix_mvektlca5c5q-8>li:before{content:"-  "}.lst-kix_pgnpvlxhai6o-6>li:before{content:"-  "}.lst-kix_axwe0nze7yft-7>li:before{content:"-  "}.lst-kix_yvohqcnu3146-1>li:before{content:"" counter(lst-ctn-kix_yvohqcnu3146-1,lower-latin) ") "}.lst-kix_6nc1nfac2wub-8>li:before{content:"-  "}.lst-kix_bv8sxewi94yp-7>li:before{content:"-  "}.lst-kix_67mv29rpwb23-6>li:before{content:"-  "}.lst-kix_8wvqr5f1zg2m-3>li:before{content:"-  "}.lst-kix_aeppt4sbsnmp-0>li:before{content:"-  "}.lst-kix_bnvwt1y8k7b-5>li:before{content:"-  "}.lst-kix_6xh4bfg7mbxi-7>li:before{content:"-  "}.lst-kix_oc7itsrfkmqv-2>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-3>li:before{content:"(" counter(lst-ctn-kix_ypd5gkkarijk-3,lower-latin) ") "}.lst-kix_fmkfhvl8yhfs-7>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-5.start{counter-reset:lst-ctn-kix_ok1n37qarjzb-5 0}.lst-kix_5argtotmwusw-5>li:before{content:"-  "}.lst-kix_hssoi9jbujv-7>li:before{content:"-  "}.lst-kix_cpgerodpupjz-7>li:before{content:"-  "}.lst-kix_7o5enrj2ko1w-7>li:before{content:"-  "}.lst-kix_mkfigeky21iv-1>li:before{content:"-  "}.lst-kix_8hf94791m5p0-2>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-6>li:before{content:"" counter(lst-ctn-kix_ykhoydml7pv3-6,decimal) ". "}.lst-kix_vgg0538grxk3-0>li{counter-increment:lst-ctn-kix_vgg0538grxk3-0}.lst-kix_c7r1s55bmbei-7>li:before{content:"-  "}.lst-kix_jnfn9mx5o33t-7>li:before{content:"-  "}ol.lst-kix_ykhoydml7pv3-0.start{counter-reset:lst-ctn-kix_ykhoydml7pv3-0 0}.lst-kix_fs1lzw38maxl-7>li:before{content:"-  "}.lst-kix_4uak8dkv6vr8-8>li:before{content:"-  "}.lst-kix_qbfnanuzy3l5-0>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-4>li:before{content:"(" counter(lst-ctn-kix_u8nobwiguyj1-4,lower-latin) ") "}.lst-kix_1kbilie4yf3o-4>li:before{content:"-  "}.lst-kix_22zpsclbl6ju-3>li:before{content:"-  "}.lst-kix_iyje40sgs3ri-4>li:before{content:"-  "}.lst-kix_vuz55xpe5xjl-7>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-5>li{counter-increment:lst-ctn-kix_ypd5gkkarijk-5}.lst-kix_t9t3ckq2i2hz-7>li:before{content:"-  "}.lst-kix_q8c17lyf7k0c-4>li:before{content:"-  "}.lst-kix_fm53cr9wmch0-8>li:before{content:"-  "}.lst-kix_t6x6ie377r4u-5>li:before{content:"-  "}.lst-kix_mq980hprr5hl-5>li:before{content:"-  "}.lst-kix_p02ob1bzv6e4-4>li:before{content:"-  "}.lst-kix_qij6192l4p0g-6>li:before{content:"-  "}.lst-kix_4gff7g6tktju-3>li:before{content:"-  "}.lst-kix_iupg79bv69ia-6>li:before{content:"-  "}.lst-kix_6pgojrjbxqei-0>li:before{content:"\0025cf   "}.lst-kix_8euewcidoez8-6>li:before{content:"-  "}.lst-kix_tdrf79x9zyr7-5>li:before{content:"-  "}.lst-kix_tjrvr4c0ezjq-6>li:before{content:"-  "}.lst-kix_kobinbwr4qr6-1>li:before{content:"-  "}.lst-kix_qb494lue4ahb-2>li:before{content:"-  "}ul.lst-kix_lojd6plssn1-0{list-style-type:none}.lst-kix_8w7txqc6xq66-0>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-3>li:before{content:"" counter(lst-ctn-kix_2foc6u9lzfq4-3,decimal) ". "}ul.lst-kix_lojd6plssn1-3{list-style-type:none}.lst-kix_s9h4llxy1yy0-5>li:before{content:"-  "}ul.lst-kix_lojd6plssn1-4{list-style-type:none}ul.lst-kix_lojd6plssn1-1{list-style-type:none}.lst-kix_6u6or33vx86s-0>li:before{content:"-  "}ul.lst-kix_lojd6plssn1-2{list-style-type:none}.lst-kix_tc7vpn5ce0ra-6>li:before{content:"-  "}ul.lst-kix_lojd6plssn1-7{list-style-type:none}ul.lst-kix_lojd6plssn1-8{list-style-type:none}ul.lst-kix_lojd6plssn1-5{list-style-type:none}ul.lst-kix_lojd6plssn1-6{list-style-type:none}.lst-kix_8f3g26d9wonp-5>li:before{content:"-  "}.lst-kix_tfqdu2hgmdym-4>li:before{content:"-  "}.lst-kix_l4d8unsm10a0-2>li:before{content:"-  "}.lst-kix_vayf18aqt55o-0>li:before{content:"" counter(lst-ctn-kix_vayf18aqt55o-0,lower-latin) ") "}.lst-kix_xdqzm25ye8fb-2>li:before{content:"-  "}.lst-kix_6ltb10qoez57-7>li:before{content:"\0025cb   "}.lst-kix_4uak8dkv6vr8-0>li:before{content:"-  "}.lst-kix_puc0azh4kjfq-6>li:before{content:"-  "}.lst-kix_ksf6p4xm2w0d-1>li:before{content:"-  "}ul.lst-kix_q8c17lyf7k0c-7{list-style-type:none}ul.lst-kix_q8c17lyf7k0c-8{list-style-type:none}ul.lst-kix_q8c17lyf7k0c-5{list-style-type:none}.lst-kix_x6hb6vgwujyx-8>li:before{content:"-  "}ul.lst-kix_q8c17lyf7k0c-6{list-style-type:none}.lst-kix_tpw8rt3jm7dt-7>li:before{content:"-  "}ul.lst-kix_q8c17lyf7k0c-3{list-style-type:none}.lst-kix_fexdtgozkcsr-6>li:before{content:"-  "}ul.lst-kix_q8c17lyf7k0c-4{list-style-type:none}ul.lst-kix_k5hm652wcnm2-6{list-style-type:none}ul.lst-kix_k5hm652wcnm2-7{list-style-type:none}ul.lst-kix_k5hm652wcnm2-8{list-style-type:none}ul.lst-kix_wiijpxq0m5a-0{list-style-type:none}ul.lst-kix_wiijpxq0m5a-1{list-style-type:none}.lst-kix_om0x63wgf9wd-8>li:before{content:"-  "}ul.lst-kix_wiijpxq0m5a-6{list-style-type:none}ul.lst-kix_wiijpxq0m5a-7{list-style-type:none}.lst-kix_yjf6dvvoob64-3>li:before{content:"" counter(lst-ctn-kix_yjf6dvvoob64-3,decimal) ". "}ul.lst-kix_k5hm652wcnm2-0{list-style-type:none}ul.lst-kix_wiijpxq0m5a-8{list-style-type:none}.lst-kix_c73c2x77meqo-3>li:before{content:"-  "}ul.lst-kix_k5hm652wcnm2-1{list-style-type:none}ul.lst-kix_k5hm652wcnm2-2{list-style-type:none}ul.lst-kix_wiijpxq0m5a-2{list-style-type:none}ul.lst-kix_k5hm652wcnm2-3{list-style-type:none}ul.lst-kix_wiijpxq0m5a-3{list-style-type:none}ul.lst-kix_k5hm652wcnm2-4{list-style-type:none}ul.lst-kix_wiijpxq0m5a-4{list-style-type:none}ul.lst-kix_k5hm652wcnm2-5{list-style-type:none}ul.lst-kix_wiijpxq0m5a-5{list-style-type:none}ol.lst-kix_hppu19i8fr2p-6.start{counter-reset:lst-ctn-kix_hppu19i8fr2p-6 0}.lst-kix_j60wooaeanf9-5>li:before{content:"-  "}.lst-kix_qmryaqe19okh-4>li:before{content:"-  "}.lst-kix_st0egafmkg0z-0>li:before{content:"-  "}ul.lst-kix_q8c17lyf7k0c-1{list-style-type:none}ul.lst-kix_q8c17lyf7k0c-2{list-style-type:none}ul.lst-kix_q8c17lyf7k0c-0{list-style-type:none}.lst-kix_1epl36nedj4y-4>li:before{content:"-  "}.lst-kix_nj8yy6k748x0-7>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-4>li{counter-increment:lst-ctn-kix_2foc6u9lzfq4-4}ul.lst-kix_eh8nesljbkpv-7{list-style-type:none}ul.lst-kix_eh8nesljbkpv-8{list-style-type:none}.lst-kix_vayf18aqt55o-5>li{counter-increment:lst-ctn-kix_vayf18aqt55o-5}.lst-kix_fy701w8ywepa-5>li:before{content:"-  "}ul.lst-kix_eh8nesljbkpv-5{list-style-type:none}ul.lst-kix_eh8nesljbkpv-6{list-style-type:none}.lst-kix_q7gxc7al9t7n-7>li:before{content:"-  "}ul.lst-kix_eh8nesljbkpv-0{list-style-type:none}ul.lst-kix_eh8nesljbkpv-3{list-style-type:none}ul.lst-kix_eh8nesljbkpv-4{list-style-type:none}ul.lst-kix_eh8nesljbkpv-1{list-style-type:none}ul.lst-kix_eh8nesljbkpv-2{list-style-type:none}.lst-kix_azgj6sn0lxuj-1>li{counter-increment:lst-ctn-kix_azgj6sn0lxuj-1}ul.lst-kix_7e64bsb5krip-0{list-style-type:none}.lst-kix_q7gxc7al9t7n-2>li:before{content:"-  "}ul.lst-kix_7e64bsb5krip-1{list-style-type:none}ul.lst-kix_7e64bsb5krip-2{list-style-type:none}.lst-kix_awlaex77cpwh-0>li:before{content:"-  "}.lst-kix_o4efc4ukggt5-2>li:before{content:"-  "}.lst-kix_kp4gb6sd08f1-2>li:before{content:"-  "}.lst-kix_f2t507a7xjue-5>li:before{content:"-  "}.lst-kix_f2t507a7xjue-6>li:before{content:"-  "}.lst-kix_eh8nesljbkpv-3>li:before{content:"-  "}.lst-kix_zew29xx7bzz-5>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-2>li:before{content:"" counter(lst-ctn-kix_3fc7x0lm2mmz-2,lower-roman) ") "}.lst-kix_vdnr7e70vask-4>li:before{content:"\0025cb   "}ul.lst-kix_7e64bsb5krip-7{list-style-type:none}ul.lst-kix_7e64bsb5krip-8{list-style-type:none}.lst-kix_p9ucdfdvxyzl-0>li:before{content:"-  "}.lst-kix_p9ucdfdvxyzl-7>li:before{content:"-  "}.lst-kix_vdnr7e70vask-5>li:before{content:"\0025a0   "}ul.lst-kix_7e64bsb5krip-3{list-style-type:none}ul.lst-kix_7e64bsb5krip-4{list-style-type:none}ul.lst-kix_7e64bsb5krip-5{list-style-type:none}.lst-kix_sr0z5k7b8i6u-6>li:before{content:"-  "}.lst-kix_xktbtduo53bq-7>li{counter-increment:lst-ctn-kix_xktbtduo53bq-7}ul.lst-kix_7e64bsb5krip-6{list-style-type:none}.lst-kix_sxznwwyc44x6-2>li:before{content:"-  "}.lst-kix_sxznwwyc44x6-1>li:before{content:"-  "}.lst-kix_sr0z5k7b8i6u-2>li:before{content:"-  "}ul.lst-kix_2agzfikyhf8k-0{list-style-type:none}.lst-kix_e3u4u2bj7x9w-6>li:before{content:"-  "}ul.lst-kix_2agzfikyhf8k-3{list-style-type:none}ul.lst-kix_2agzfikyhf8k-4{list-style-type:none}.lst-kix_30wqf3y6rydr-7>li:before{content:"-  "}ul.lst-kix_2agzfikyhf8k-1{list-style-type:none}ul.lst-kix_2agzfikyhf8k-2{list-style-type:none}ul.lst-kix_2agzfikyhf8k-7{list-style-type:none}.lst-kix_85vz7a3ggeai-2>li:before{content:"-  "}.lst-kix_o328viitwjyp-8>li:before{content:"-  "}ul.lst-kix_2agzfikyhf8k-8{list-style-type:none}ul.lst-kix_2agzfikyhf8k-5{list-style-type:none}ul.lst-kix_2agzfikyhf8k-6{list-style-type:none}.lst-kix_uwhnriglec8q-2>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-0>li:before{content:"" counter(lst-ctn-kix_hppu19i8fr2p-0,decimal) ") "}.lst-kix_fnlxcectz7fi-5>li:before{content:"-  "}.lst-kix_zew29xx7bzz-0>li:before{content:"-  "}.lst-kix_tfqdu2hgmdym-0>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-3>li:before{content:"(" counter(lst-ctn-kix_3fc7x0lm2mmz-3,decimal) ") "}.lst-kix_fnlxcectz7fi-4>li:before{content:"-  "}.lst-kix_qw4x1ydun1ls-3>li:before{content:"\0025cf   "}.lst-kix_sgiyubx3nkay-7>li:before{content:"-  "}.lst-kix_o4efc4ukggt5-6>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-0>li:before{content:"" counter(lst-ctn-kix_sxixw4iqsgzx-0,decimal) ". "}.lst-kix_d94n7or3b41v-1>li:before{content:"-  "}.lst-kix_xktbtduo53bq-5>li:before{content:"" counter(lst-ctn-kix_xktbtduo53bq-5,lower-roman) ". "}.lst-kix_hppu19i8fr2p-4>li:before{content:"(" counter(lst-ctn-kix_hppu19i8fr2p-4,lower-latin) ") "}.lst-kix_sq25f4cnauod-4>li:before{content:"-  "}.lst-kix_sq25f4cnauod-8>li:before{content:"-  "}ul.lst-kix_6217r3mhjywx-0{list-style-type:none}.lst-kix_hc732m8hksyq-7>li:before{content:"-  "}ul.lst-kix_6217r3mhjywx-1{list-style-type:none}ul.lst-kix_6217r3mhjywx-2{list-style-type:none}ol.lst-kix_incqcf2p39ls-7.start{counter-reset:lst-ctn-kix_incqcf2p39ls-7 0}ul.lst-kix_6217r3mhjywx-7{list-style-type:none}ul.lst-kix_6217r3mhjywx-8{list-style-type:none}ul.lst-kix_6217r3mhjywx-3{list-style-type:none}.lst-kix_9ys95s420x24-0>li:before{content:"-  "}ul.lst-kix_6217r3mhjywx-4{list-style-type:none}.lst-kix_eh3u7tkoktop-1>li:before{content:"-  "}ul.lst-kix_epyrmry7301m-0{list-style-type:none}.lst-kix_eahcvjpxxqs-3>li:before{content:"-  "}ul.lst-kix_6217r3mhjywx-5{list-style-type:none}ul.lst-kix_6217r3mhjywx-6{list-style-type:none}.lst-kix_eh3u7tkoktop-5>li:before{content:"-  "}ul.lst-kix_epyrmry7301m-2{list-style-type:none}.lst-kix_sxixw4iqsgzx-7>li:before{content:"" counter(lst-ctn-kix_sxixw4iqsgzx-7,lower-latin) ". "}ul.lst-kix_epyrmry7301m-1{list-style-type:none}ul.lst-kix_epyrmry7301m-4{list-style-type:none}ol.lst-kix_23ct987xwu67-0.start{counter-reset:lst-ctn-kix_23ct987xwu67-0 0}ul.lst-kix_epyrmry7301m-3{list-style-type:none}.lst-kix_i8kfgvsh0fwy-5>li:before{content:"-  "}ul.lst-kix_epyrmry7301m-6{list-style-type:none}ul.lst-kix_epyrmry7301m-5{list-style-type:none}ul.lst-kix_epyrmry7301m-8{list-style-type:none}ul.lst-kix_epyrmry7301m-7{list-style-type:none}ul.lst-kix_8w03xjt2k9bc-5{list-style-type:none}ul.lst-kix_8w03xjt2k9bc-4{list-style-type:none}.lst-kix_yob9gooqotb-7>li:before{content:"-  "}ul.lst-kix_8w03xjt2k9bc-7{list-style-type:none}ul.lst-kix_8w03xjt2k9bc-6{list-style-type:none}ul.lst-kix_8w03xjt2k9bc-1{list-style-type:none}.lst-kix_mjig28how5ag-8>li:before{content:"-  "}ul.lst-kix_8w03xjt2k9bc-0{list-style-type:none}ul.lst-kix_8w03xjt2k9bc-3{list-style-type:none}ul.lst-kix_8w03xjt2k9bc-2{list-style-type:none}.lst-kix_tlnfkrylyq1a-4>li:before{content:"-  "}ul.lst-kix_8w03xjt2k9bc-8{list-style-type:none}.lst-kix_7gk9ayd44tft-2>li:before{content:"-  "}.lst-kix_g1rm1ujfok3h-7>li:before{content:"-  "}.lst-kix_npanryo7f1m7-7>li:before{content:"-  "}ul.lst-kix_8drpzle0jo7q-0{list-style-type:none}.lst-kix_x96zthrcdy1e-5>li:before{content:"-  "}ul.lst-kix_8drpzle0jo7q-2{list-style-type:none}ul.lst-kix_8drpzle0jo7q-1{list-style-type:none}.lst-kix_52jgzw489fhs-8>li{counter-increment:lst-ctn-kix_52jgzw489fhs-8}ul.lst-kix_8drpzle0jo7q-8{list-style-type:none}ul.lst-kix_8drpzle0jo7q-7{list-style-type:none}ul.lst-kix_8drpzle0jo7q-4{list-style-type:none}ul.lst-kix_8drpzle0jo7q-3{list-style-type:none}ul.lst-kix_8drpzle0jo7q-6{list-style-type:none}ul.lst-kix_8drpzle0jo7q-5{list-style-type:none}ol.lst-kix_90bg3luq5inv-5.start{counter-reset:lst-ctn-kix_90bg3luq5inv-5 0}.lst-kix_f83agu4s4fw5-4>li:before{content:"-  "}.lst-kix_1tib71bbsugw-7>li:before{content:"-  "}ol.lst-kix_vkdxjlf0kb6j-8.start{counter-reset:lst-ctn-kix_vkdxjlf0kb6j-8 0}.lst-kix_p11gr83hik0e-2>li:before{content:"-  "}.lst-kix_1tib71bbsugw-3>li:before{content:"-  "}.lst-kix_3bnqwg68tpm3-7>li:before{content:"-  "}.lst-kix_pxpm44v9ngyu-0>li:before{content:"-  "}.lst-kix_ctweb0b3a38f-5>li:before{content:"-  "}ul.lst-kix_r8azi25kh461-8{list-style-type:none}.lst-kix_g47hwi8ilj0t-8>li:before{content:"-  "}ul.lst-kix_r8azi25kh461-6{list-style-type:none}ul.lst-kix_r8azi25kh461-7{list-style-type:none}ul.lst-kix_r8azi25kh461-4{list-style-type:none}ul.lst-kix_r8azi25kh461-5{list-style-type:none}ul.lst-kix_r8azi25kh461-2{list-style-type:none}ul.lst-kix_r8azi25kh461-3{list-style-type:none}.lst-kix_xyra4e5ffsud-1>li:before{content:"" counter(lst-ctn-kix_xyra4e5ffsud-1,lower-latin) ". "}ul.lst-kix_r8azi25kh461-0{list-style-type:none}ul.lst-kix_r8azi25kh461-1{list-style-type:none}.lst-kix_ctweb0b3a38f-1>li:before{content:"-  "}.lst-kix_8wvqr5f1zg2m-4>li:before{content:"-  "}.lst-kix_yk26x5gkc3g4-4>li:before{content:"-  "}ol.lst-kix_90bg3luq5inv-0.start{counter-reset:lst-ctn-kix_90bg3luq5inv-0 0}.lst-kix_r8azi25kh461-7>li:before{content:"\0025cf   "}ol.lst-kix_vkdxjlf0kb6j-3.start{counter-reset:lst-ctn-kix_vkdxjlf0kb6j-3 0}ul.lst-kix_tjrvr4c0ezjq-3{list-style-type:none}ul.lst-kix_tjrvr4c0ezjq-2{list-style-type:none}ul.lst-kix_tjrvr4c0ezjq-1{list-style-type:none}ul.lst-kix_tjrvr4c0ezjq-0{list-style-type:none}ul.lst-kix_tjrvr4c0ezjq-7{list-style-type:none}ul.lst-kix_tjrvr4c0ezjq-6{list-style-type:none}ul.lst-kix_tjrvr4c0ezjq-5{list-style-type:none}ul.lst-kix_tjrvr4c0ezjq-4{list-style-type:none}.lst-kix_r8azi25kh461-3>li:before{content:"\0025cf   "}ul.lst-kix_tjrvr4c0ezjq-8{list-style-type:none}.lst-kix_yk26x5gkc3g4-8>li:before{content:"-  "}.lst-kix_onvme58enb43-1>li:before{content:"-  "}.lst-kix_7cboi17aj4i3-7>li:before{content:"-  "}.lst-kix_ltm9vv1op5tt-2>li:before{content:"-  "}.lst-kix_r9gci84l54f7-5>li:before{content:"-  "}.lst-kix_uvjyeruqqfgv-7>li:before{content:"-  "}.lst-kix_wlyv8o88ksmk-0>li:before{content:"-  "}.lst-kix_5l84eporjaw3-8>li:before{content:"-  "}ul.lst-kix_ob04lr2u335p-5{list-style-type:none}ul.lst-kix_ob04lr2u335p-4{list-style-type:none}ul.lst-kix_ob04lr2u335p-3{list-style-type:none}.lst-kix_w3rscytwttbz-7>li:before{content:"-  "}ul.lst-kix_ob04lr2u335p-2{list-style-type:none}ul.lst-kix_ob04lr2u335p-1{list-style-type:none}ul.lst-kix_ob04lr2u335p-0{list-style-type:none}.lst-kix_uvjyeruqqfgv-3>li:before{content:"-  "}.lst-kix_wfyz8rmi0iq4-0>li:before{content:"-  "}.lst-kix_vuz55xpe5xjl-8>li:before{content:"-  "}.lst-kix_vhhvekoaa9d4-1>li:before{content:"\0025cb   "}.lst-kix_voj7evacrpie-2>li:before{content:"-  "}.lst-kix_r9gci84l54f7-1>li:before{content:"-  "}.lst-kix_wlyv8o88ksmk-1>li:before{content:"-  "}ol.lst-kix_90bg3luq5inv-1.start{counter-reset:lst-ctn-kix_90bg3luq5inv-1 0}.lst-kix_5l84eporjaw3-4>li:before{content:"-  "}.lst-kix_voj7evacrpie-3>li:before{content:"-  "}.lst-kix_267f3xfv5ddr-0>li{counter-increment:lst-ctn-kix_267f3xfv5ddr-0}ol.lst-kix_yjf6dvvoob64-0.start{counter-reset:lst-ctn-kix_yjf6dvvoob64-0 0}.lst-kix_dln561wj05xo-8>li:before{content:"-  "}ol.lst-kix_vkdxjlf0kb6j-4.start{counter-reset:lst-ctn-kix_vkdxjlf0kb6j-4 0}.lst-kix_r6uhbskcwxv5-1>li:before{content:"-  "}.lst-kix_rog9deufml3h-8>li:before{content:"-  "}.lst-kix_f4168mxvziu2-5>li:before{content:"-  "}ul.lst-kix_4ii5776egvw8-0{list-style-type:none}.lst-kix_8hvuzyuchy3p-0>li:before{content:"-  "}.lst-kix_7vaamq35f1cc-8>li:before{content:"-  "}.lst-kix_52jgzw489fhs-2>li:before{content:"" counter(lst-ctn-kix_52jgzw489fhs-2,lower-roman) ". "}.lst-kix_awt45k7p90je-1>li:before{content:"-  "}ul.lst-kix_4ii5776egvw8-2{list-style-type:none}ul.lst-kix_4ii5776egvw8-1{list-style-type:none}ul.lst-kix_4ii5776egvw8-4{list-style-type:none}ul.lst-kix_4ii5776egvw8-3{list-style-type:none}.lst-kix_2agzfikyhf8k-7>li:before{content:"-  "}ul.lst-kix_4ii5776egvw8-6{list-style-type:none}.lst-kix_2ei6b6e4ow80-5>li:before{content:"-  "}ul.lst-kix_ob04lr2u335p-8{list-style-type:none}ul.lst-kix_4ii5776egvw8-5{list-style-type:none}ul.lst-kix_ob04lr2u335p-7{list-style-type:none}ul.lst-kix_4ii5776egvw8-8{list-style-type:none}ul.lst-kix_ob04lr2u335p-6{list-style-type:none}.lst-kix_ssze0kg2kz13-2>li:before{content:"-  "}ul.lst-kix_4ii5776egvw8-7{list-style-type:none}.lst-kix_ugixx4nd67zw-8>li:before{content:"-  "}.lst-kix_npanryo7f1m7-6>li:before{content:"-  "}.lst-kix_r6uhbskcwxv5-5>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-8>li:before{content:"" counter(lst-ctn-kix_azgj6sn0lxuj-8,lower-roman) ". "}.lst-kix_43bwriak8ne4-6>li:before{content:"-  "}ul.lst-kix_jhofo94iol1-0{list-style-type:none}ul.lst-kix_jhofo94iol1-1{list-style-type:none}ul.lst-kix_jhofo94iol1-2{list-style-type:none}ul.lst-kix_jhofo94iol1-3{list-style-type:none}.lst-kix_bb3pt2xtt0a5-7>li:before{content:"-  "}ul.lst-kix_jhofo94iol1-4{list-style-type:none}ul.lst-kix_jhofo94iol1-5{list-style-type:none}ul.lst-kix_jhofo94iol1-6{list-style-type:none}ul.lst-kix_jhofo94iol1-7{list-style-type:none}ul.lst-kix_jhofo94iol1-8{list-style-type:none}.lst-kix_5quy3fbj2mfg-7>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-4>li:before{content:"" counter(lst-ctn-kix_azgj6sn0lxuj-4,lower-latin) ". "}.lst-kix_wf1o55flzq55-6>li:before{content:"-  "}.lst-kix_q8ex99of35ig-2>li:before{content:"-  "}.lst-kix_lojd6plssn1-0>li:before{content:"-  "}.lst-kix_q8ex99of35ig-6>li:before{content:"-  "}.lst-kix_f83agu4s4fw5-3>li:before{content:"-  "}.lst-kix_epyrmry7301m-1>li:before{content:"-  "}.lst-kix_awlaex77cpwh-1>li:before{content:"-  "}.lst-kix_v6dv769q7bq3-8>li:before{content:"-  "}.lst-kix_dojezsyc3ti3-0>li:before{content:"-  "}.lst-kix_z6rr709h3fky-2>li:before{content:"-  "}.lst-kix_z6rr709h3fky-6>li:before{content:"-  "}.lst-kix_iefjrs8t42tr-7>li:before{content:"-  "}.lst-kix_7vvt5hs6rdl-8>li:before{content:"-  "}.lst-kix_v6dv769q7bq3-4>li:before{content:"-  "}.lst-kix_bdjoj2nf5hw9-5>li:before{content:"-  "}.lst-kix_ozbrn4vmjez8-8>li:before{content:"-  "}ul.lst-kix_8pn77unkg8hg-0{list-style-type:none}ul.lst-kix_8pn77unkg8hg-2{list-style-type:none}ul.lst-kix_8pn77unkg8hg-1{list-style-type:none}ul.lst-kix_8pn77unkg8hg-4{list-style-type:none}ul.lst-kix_8pn77unkg8hg-3{list-style-type:none}ul.lst-kix_4i10vbfgn91y-0{list-style-type:none}ul.lst-kix_6vg5692ogph-3{list-style-type:none}ul.lst-kix_8pn77unkg8hg-6{list-style-type:none}ul.lst-kix_6vg5692ogph-2{list-style-type:none}ul.lst-kix_8pn77unkg8hg-5{list-style-type:none}.lst-kix_194f2a56ajxk-2>li:before{content:"-  "}ul.lst-kix_6vg5692ogph-1{list-style-type:none}ul.lst-kix_8pn77unkg8hg-8{list-style-type:none}ul.lst-kix_6vg5692ogph-0{list-style-type:none}ul.lst-kix_8pn77unkg8hg-7{list-style-type:none}ul.lst-kix_4i10vbfgn91y-4{list-style-type:none}ul.lst-kix_6vg5692ogph-7{list-style-type:none}ul.lst-kix_4i10vbfgn91y-3{list-style-type:none}ul.lst-kix_6vg5692ogph-6{list-style-type:none}ul.lst-kix_4i10vbfgn91y-2{list-style-type:none}ul.lst-kix_6vg5692ogph-5{list-style-type:none}.lst-kix_spt2hfceke6p-8>li:before{content:"-  "}ul.lst-kix_4i10vbfgn91y-1{list-style-type:none}ul.lst-kix_6vg5692ogph-4{list-style-type:none}ul.lst-kix_4i10vbfgn91y-8{list-style-type:none}ul.lst-kix_4i10vbfgn91y-7{list-style-type:none}ul.lst-kix_4i10vbfgn91y-6{list-style-type:none}ol.lst-kix_5stj9b6acoxv-0.start{counter-reset:lst-ctn-kix_5stj9b6acoxv-0 0}ul.lst-kix_4i10vbfgn91y-5{list-style-type:none}ol.lst-kix_5stj9b6acoxv-5.start{counter-reset:lst-ctn-kix_5stj9b6acoxv-5 0}.lst-kix_yjf6dvvoob64-7>li{counter-increment:lst-ctn-kix_yjf6dvvoob64-7}.lst-kix_luixtz7s7e5x-0>li:before{content:"-  "}ul.lst-kix_6vg5692ogph-8{list-style-type:none}.lst-kix_wz5gdx83jdla-6>li:before{content:"-  "}.lst-kix_3wddikkjnk2k-6>li:before{content:"-  "}.lst-kix_g2uanok8rp1g-3>li:before{content:"-  "}.lst-kix_90bg3luq5inv-7>li:before{content:"" counter(lst-ctn-kix_90bg3luq5inv-7,lower-latin) ". "}.lst-kix_rgd2g4si1ihs-2>li:before{content:"-  "}.lst-kix_x1n4jlo0gf1q-7>li:before{content:"-  "}.lst-kix_dmn3lqzfmokk-8>li:before{content:"-  "}.lst-kix_w21i9d12ynhg-7>li:before{content:"-  "}ul.lst-kix_unv0ib1v43rp-3{list-style-type:none}ul.lst-kix_unv0ib1v43rp-4{list-style-type:none}ul.lst-kix_unv0ib1v43rp-5{list-style-type:none}ul.lst-kix_unv0ib1v43rp-6{list-style-type:none}ul.lst-kix_unv0ib1v43rp-7{list-style-type:none}.lst-kix_wiijpxq0m5a-2>li:before{content:"-  "}.lst-kix_bp67ajcb7c38-8>li:before{content:"-  "}ul.lst-kix_unv0ib1v43rp-8{list-style-type:none}.lst-kix_8drpzle0jo7q-0>li:before{content:"\0025cf   "}.lst-kix_zjjx8lb18sy-3>li:before{content:"-  "}.lst-kix_y62sddnu24wd-8>li:before{content:"-  "}ul.lst-kix_unv0ib1v43rp-0{list-style-type:none}.lst-kix_ce3ho29dhteb-5>li:before{content:"-  "}ul.lst-kix_unv0ib1v43rp-1{list-style-type:none}ul.lst-kix_unv0ib1v43rp-2{list-style-type:none}.lst-kix_s9h4llxy1yy0-1>li:before{content:"-  "}.lst-kix_tl77ogq6q7u-0>li:before{content:"-  "}.lst-kix_skgpgvhmuoc4-3>li:before{content:"-  "}.lst-kix_incqcf2p39ls-1>li:before{content:"" counter(lst-ctn-kix_incqcf2p39ls-1,lower-latin) ") "}.lst-kix_bsvmcpoa86br-1>li:before{content:"-  "}.lst-kix_e73zm9q3mvin-4>li:before{content:"-  "}.lst-kix_4pjeuglo4z6v-8>li:before{content:"-  "}.lst-kix_8a5plp401pog-8>li:before{content:"-  "}.lst-kix_9j3np3ow732h-0>li:before{content:"\0025cf   "}.lst-kix_r8adx85jg0iz-3>li:before{content:"-  "}.lst-kix_f9iu0trsjas1-5>li:before{content:"-  "}.lst-kix_kobinbwr4qr6-8>li:before{content:"-  "}.lst-kix_h25uruhpfzux-4>li:before{content:"-  "}.lst-kix_nipj94pw11x6-2>li:before{content:"-  "}.lst-kix_yxvs6rw7mq1w-2>li:before{content:"-  "}.lst-kix_rf3bfhvmysmh-1>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-1>li{counter-increment:lst-ctn-kix_ysfu1bl0kymd-1}.lst-kix_p02ob1bzv6e4-5>li:before{content:"-  "}ol.lst-kix_xktbtduo53bq-6.start{counter-reset:lst-ctn-kix_xktbtduo53bq-6 0}.lst-kix_t6x6ie377r4u-6>li:before{content:"-  "}ul.lst-kix_fexdtgozkcsr-0{list-style-type:none}.lst-kix_g8jgbze430sv-7>li{counter-increment:lst-ctn-kix_g8jgbze430sv-7}.lst-kix_dln561wj05xo-1>li:before{content:"-  "}ul.lst-kix_c7r1s55bmbei-6{list-style-type:none}ul.lst-kix_c7r1s55bmbei-7{list-style-type:none}.lst-kix_pgnpvlxhai6o-2>li:before{content:"-  "}ul.lst-kix_c7r1s55bmbei-8{list-style-type:none}.lst-kix_jvmsa1jxmzig-2>li:before{content:"\0025a0   "}.lst-kix_ny5e869gaylo-6>li:before{content:"-  "}.lst-kix_5jp9wppv00ra-5>li:before{content:"-  "}.lst-kix_qb494lue4ahb-1>li:before{content:"-  "}.lst-kix_a42anijqpp8a-2>li:before{content:"-  "}.lst-kix_upq3ni6ul8eb-0>li:before{content:"-  "}.lst-kix_5ze5xofgghz2-0>li:before{content:"-  "}ul.lst-kix_fexdtgozkcsr-6{list-style-type:none}.lst-kix_qqbjjwnrc3l8-4>li:before{content:"-  "}ul.lst-kix_fexdtgozkcsr-5{list-style-type:none}.lst-kix_sxixw4iqsgzx-8>li{counter-increment:lst-ctn-kix_sxixw4iqsgzx-8}ul.lst-kix_fexdtgozkcsr-8{list-style-type:none}ul.lst-kix_fexdtgozkcsr-7{list-style-type:none}ul.lst-kix_fexdtgozkcsr-2{list-style-type:none}ul.lst-kix_fexdtgozkcsr-1{list-style-type:none}.lst-kix_gboi4t2flod9-6>li:before{content:"-  "}ul.lst-kix_fexdtgozkcsr-4{list-style-type:none}.lst-kix_69k4orytle42-0>li:before{content:"\0025cf   "}ul.lst-kix_fexdtgozkcsr-3{list-style-type:none}.lst-kix_f9iqanr8ite6-3>li:before{content:"-  "}.lst-kix_o7acnutkhp1w-5>li:before{content:"-  "}.lst-kix_iffqre5r12zx-6>li:before{content:"-  "}.lst-kix_n0rv3zxivae3-3>li:before{content:"-  "}.lst-kix_549l9aqx2sdy-5>li:before{content:"-  "}.lst-kix_rop4yg7lbfg8-2>li:before{content:"-  "}.lst-kix_alhag51wggig-4>li:before{content:"-  "}.lst-kix_c73c2x77meqo-4>li:before{content:"-  "}.lst-kix_iefjrs8t42tr-0>li:before{content:"-  "}.lst-kix_cmm6cscyrjti-8>li:before{content:"-  "}ul.lst-kix_gvlgpawofwi7-1{list-style-type:none}ul.lst-kix_gvlgpawofwi7-2{list-style-type:none}ul.lst-kix_gvlgpawofwi7-0{list-style-type:none}ul.lst-kix_gvlgpawofwi7-5{list-style-type:none}ul.lst-kix_gvlgpawofwi7-6{list-style-type:none}.lst-kix_t3rn73qejgkj-7>li:before{content:"" counter(lst-ctn-kix_t3rn73qejgkj-7,lower-latin) ". "}.lst-kix_wzt7symqmcfu-7>li:before{content:"-  "}ul.lst-kix_gvlgpawofwi7-3{list-style-type:none}.lst-kix_bnvwt1y8k7b-4>li:before{content:"-  "}ul.lst-kix_gvlgpawofwi7-4{list-style-type:none}.lst-kix_mvektlca5c5q-4>li:before{content:"-  "}ul.lst-kix_gvlgpawofwi7-7{list-style-type:none}ul.lst-kix_gvlgpawofwi7-8{list-style-type:none}ul.lst-kix_c7r1s55bmbei-2{list-style-type:none}ul.lst-kix_c7r1s55bmbei-3{list-style-type:none}ul.lst-kix_c7r1s55bmbei-4{list-style-type:none}ul.lst-kix_c7r1s55bmbei-5{list-style-type:none}.lst-kix_aikphwux0ki0-5>li:before{content:"-  "}ul.lst-kix_c7r1s55bmbei-0{list-style-type:none}.lst-kix_wn0yiryrov3h-5>li:before{content:"-  "}ul.lst-kix_c7r1s55bmbei-1{list-style-type:none}ul.lst-kix_njs8ubf1qesf-0{list-style-type:none}.lst-kix_ksf6p4xm2w0d-2>li:before{content:"-  "}.lst-kix_r8i1fgeyliey-6>li:before{content:"-  "}.lst-kix_yvohqcnu3146-2>li:before{content:"" counter(lst-ctn-kix_yvohqcnu3146-2,lower-roman) ") "}.lst-kix_67mv29rpwb23-7>li:before{content:"-  "}.lst-kix_q2mi4y6rc42i-2>li:before{content:"-  "}.lst-kix_bv8sxewi94yp-3>li:before{content:"-  "}ol.lst-kix_267f3xfv5ddr-8.start{counter-reset:lst-ctn-kix_267f3xfv5ddr-8 0}ul.lst-kix_qccibyu36y2t-5{list-style-type:none}ul.lst-kix_qccibyu36y2t-6{list-style-type:none}ul.lst-kix_qccibyu36y2t-3{list-style-type:none}ul.lst-kix_qccibyu36y2t-4{list-style-type:none}ul.lst-kix_qccibyu36y2t-1{list-style-type:none}ul.lst-kix_qccibyu36y2t-2{list-style-type:none}ul.lst-kix_qccibyu36y2t-0{list-style-type:none}.lst-kix_5argtotmwusw-6>li:before{content:"-  "}.lst-kix_2nm562bzmwr-2>li:before{content:"-  "}.lst-kix_ykhrv7u6blcs-1>li:before{content:"-  "}.lst-kix_6xh4bfg7mbxi-3>li:before{content:"-  "}ul.lst-kix_3ez3vzcedsa0-0{list-style-type:none}ul.lst-kix_qccibyu36y2t-7{list-style-type:none}ul.lst-kix_3ez3vzcedsa0-1{list-style-type:none}ul.lst-kix_qccibyu36y2t-8{list-style-type:none}ul.lst-kix_3ez3vzcedsa0-2{list-style-type:none}ul.lst-kix_3ez3vzcedsa0-3{list-style-type:none}.lst-kix_hssoi9jbujv-8>li:before{content:"-  "}ul.lst-kix_3ez3vzcedsa0-4{list-style-type:none}ul.lst-kix_3ez3vzcedsa0-5{list-style-type:none}ul.lst-kix_3ez3vzcedsa0-6{list-style-type:none}.lst-kix_pg2i9lis4p1v-7>li:before{content:"-  "}ul.lst-kix_3ez3vzcedsa0-7{list-style-type:none}ul.lst-kix_3ez3vzcedsa0-8{list-style-type:none}.lst-kix_qbfnanuzy3l5-4>li:before{content:"-  "}.lst-kix_5u0542f2h2jt-6>li:before{content:"+  "}.lst-kix_vkdxjlf0kb6j-2>li:before{content:"" counter(lst-ctn-kix_vkdxjlf0kb6j-2,lower-roman) ". "}ul.lst-kix_o17eseb5cr8e-0{list-style-type:none}ul.lst-kix_o17eseb5cr8e-1{list-style-type:none}ul.lst-kix_o17eseb5cr8e-2{list-style-type:none}ul.lst-kix_o17eseb5cr8e-3{list-style-type:none}ul.lst-kix_o17eseb5cr8e-4{list-style-type:none}ul.lst-kix_o17eseb5cr8e-5{list-style-type:none}.lst-kix_7o5enrj2ko1w-3>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-5>li:before{content:"(" counter(lst-ctn-kix_u8nobwiguyj1-5,lower-roman) ") "}ul.lst-kix_o17eseb5cr8e-6{list-style-type:none}ul.lst-kix_o17eseb5cr8e-7{list-style-type:none}ul.lst-kix_o17eseb5cr8e-8{list-style-type:none}.lst-kix_1kbilie4yf3o-0>li:before{content:"-  "}.lst-kix_n9qabngdxy64-2>li:before{content:"-  "}.lst-kix_rxmcp67o7upe-3>li:before{content:"-  "}.lst-kix_gerk886qza0c-0>li:before{content:"-  "}.lst-kix_1pt1eqcq4ieh-8>li:before{content:"-  "}.lst-kix_iyje40sgs3ri-0>li:before{content:"-  "}ul.lst-kix_d626gkjp4fou-0{list-style-type:none}ol.lst-kix_t3rn73qejgkj-6.start{counter-reset:lst-ctn-kix_t3rn73qejgkj-6 0}ul.lst-kix_d626gkjp4fou-2{list-style-type:none}ul.lst-kix_d626gkjp4fou-1{list-style-type:none}ul.lst-kix_d626gkjp4fou-4{list-style-type:none}.lst-kix_of5ud22cn0qg-8>li:before{content:"-  "}ul.lst-kix_d626gkjp4fou-3{list-style-type:none}.lst-kix_rf1gg3liws68-1>li:before{content:"-  "}ul.lst-kix_d626gkjp4fou-6{list-style-type:none}ul.lst-kix_d626gkjp4fou-5{list-style-type:none}.lst-kix_73pnq2b8bo4n-0>li:before{content:"-  "}ul.lst-kix_d626gkjp4fou-8{list-style-type:none}ul.lst-kix_d626gkjp4fou-7{list-style-type:none}.lst-kix_t3rn73qejgkj-7>li{counter-increment:lst-ctn-kix_t3rn73qejgkj-7}ol.lst-kix_t3rn73qejgkj-7.start{counter-reset:lst-ctn-kix_t3rn73qejgkj-7 0}.lst-kix_14k5lhtsu41k-6>li:before{content:"-  "}.lst-kix_4gff7g6tktju-7>li:before{content:"-  "}.lst-kix_q8c17lyf7k0c-0>li:before{content:"-  "}ol.lst-kix_23ct987xwu67-4.start{counter-reset:lst-ctn-kix_23ct987xwu67-4 0}.lst-kix_6pgojrjbxqei-4>li:before{content:"\0025cb   "}.lst-kix_ld6rwbdri49-8>li:before{content:"-  "}.lst-kix_cg6jep1fmawj-2>li:before{content:"-  "}.lst-kix_aeppt4sbsnmp-7>li:before{content:"-  "}.lst-kix_m3u7mfewl2ow-4>li:before{content:"-  "}.lst-kix_3ug9en49p7ih-0>li:before{content:"-  "}.lst-kix_dmxresnhzo8y-7>li:before{content:"-  "}.lst-kix_52jgzw489fhs-5>li{counter-increment:lst-ctn-kix_52jgzw489fhs-5}.lst-kix_xs6xjhigrbe2-2>li:before{content:"-  "}.lst-kix_xx6ude5yqnkl-2>li:before{content:"\0025a0   "}.lst-kix_pv4jsz2h74wk-4>li:before{content:"-  "}.lst-kix_ikdz4hpyto9o-2>li:before{content:"-  "}.lst-kix_9a7xq1ie41tp-3>li:before{content:"-  "}ol.lst-kix_t3rn73qejgkj-2.start{counter-reset:lst-ctn-kix_t3rn73qejgkj-2 0}.lst-kix_ht80gp8jxjfs-1>li:before{content:"-  "}.lst-kix_84zf7o74c8s9-3>li:before{content:"(" counter(lst-ctn-kix_84zf7o74c8s9-3,decimal) ") "}.lst-kix_2foc6u9lzfq4-7>li:before{content:"" counter(lst-ctn-kix_2foc6u9lzfq4-7,lower-latin) ". "}.lst-kix_yjf6dvvoob64-7>li:before{content:"" counter(lst-ctn-kix_yjf6dvvoob64-7,lower-latin) ". "}.lst-kix_3novkjnl93sa-3>li:before{content:"-  "}.lst-kix_1epl36nedj4y-8>li:before{content:"-  "}.lst-kix_7dqsuv1cdvcc-0>li:before{content:"-  "}.lst-kix_df6s37r8voak-1>li:before{content:"-  "}ol.lst-kix_t3rn73qejgkj-3.start{counter-reset:lst-ctn-kix_t3rn73qejgkj-3 0}.lst-kix_xdqzm25ye8fb-6>li:before{content:"-  "}.lst-kix_puc0azh4kjfq-2>li:before{content:"-  "}.lst-kix_tc7vpn5ce0ra-2>li:before{content:"-  "}.lst-kix_x6hb6vgwujyx-4>li:before{content:"-  "}.lst-kix_fexdtgozkcsr-2>li:before{content:"-  "}.lst-kix_qvomcnyqz8ao-2>li:before{content:"-  "}ul.lst-kix_rxmcp67o7upe-0{list-style-type:none}.lst-kix_rxgry66ibim8-1>li:before{content:"-  "}ul.lst-kix_rxmcp67o7upe-1{list-style-type:none}.lst-kix_23ct987xwu67-1>li{counter-increment:lst-ctn-kix_23ct987xwu67-1}ul.lst-kix_rxmcp67o7upe-2{list-style-type:none}ul.lst-kix_rxmcp67o7upe-3{list-style-type:none}.lst-kix_r9s6df60is49-5>li:before{content:"-  "}.lst-kix_5stj9b6acoxv-5>li:before{content:"" counter(lst-ctn-kix_5stj9b6acoxv-5,lower-roman) ". "}ul.lst-kix_om0x63wgf9wd-8{list-style-type:none}ul.lst-kix_om0x63wgf9wd-6{list-style-type:none}.lst-kix_njs8ubf1qesf-7>li:before{content:"-  "}.lst-kix_ellvdfsu2z7q-7>li:before{content:"-  "}ul.lst-kix_om0x63wgf9wd-7{list-style-type:none}ul.lst-kix_rxmcp67o7upe-4{list-style-type:none}ul.lst-kix_om0x63wgf9wd-4{list-style-type:none}ul.lst-kix_rxmcp67o7upe-5{list-style-type:none}ul.lst-kix_om0x63wgf9wd-5{list-style-type:none}ul.lst-kix_rxmcp67o7upe-6{list-style-type:none}.lst-kix_g02ta87c1sqh-7>li:before{content:"\0025cb   "}ul.lst-kix_om0x63wgf9wd-2{list-style-type:none}ul.lst-kix_rxmcp67o7upe-7{list-style-type:none}ul.lst-kix_om0x63wgf9wd-3{list-style-type:none}ul.lst-kix_rxmcp67o7upe-8{list-style-type:none}ul.lst-kix_om0x63wgf9wd-0{list-style-type:none}.lst-kix_tvu7bmfefz32-5>li:before{content:"-  "}ul.lst-kix_om0x63wgf9wd-1{list-style-type:none}.lst-kix_kxjfd2xlpmu-8>li:before{content:"-  "}.lst-kix_gfc2v9r4qc22-7>li:before{content:"-  "}.lst-kix_1v1216yy0n25-4>li:before{content:"-  "}.lst-kix_gvlgpawofwi7-0>li:before{content:"-  "}.lst-kix_bnte1i3g4kjh-0>li:before{content:"-  "}.lst-kix_ofib0hkczw41-4>li:before{content:"-  "}.lst-kix_gfc2v9r4qc22-1>li:before{content:"-  "}.lst-kix_7vr84ges94ry-6>li:before{content:"-  "}.lst-kix_yrg2qlcqvak1-7>li:before{content:"-  "}.lst-kix_dvvzixfw64a1-6>li:before{content:"-  "}.lst-kix_qw2h6jd8xi17-8>li:before{content:"-  "}.lst-kix_yvohqcnu3146-3>li{counter-increment:lst-ctn-kix_yvohqcnu3146-3}.lst-kix_g8jgbze430sv-4>li:before{content:"(" counter(lst-ctn-kix_g8jgbze430sv-4,lower-latin) ") "}.lst-kix_ug10x97qcpi8-3>li:before{content:"-  "}.lst-kix_dvvzixfw64a1-0>li:before{content:"-  "}.lst-kix_ul22dko4fd2j-7>li:before{content:"-  "}.lst-kix_x8ffawrvrcyq-8>li:before{content:"\0025a0   "}ul.lst-kix_a9h81iclzrpy-0{list-style-type:none}.lst-kix_mv77cg19299c-0>li:before{content:"-  "}ul.lst-kix_a9h81iclzrpy-1{list-style-type:none}ul.lst-kix_a9h81iclzrpy-2{list-style-type:none}ul.lst-kix_a9h81iclzrpy-3{list-style-type:none}ul.lst-kix_a9h81iclzrpy-4{list-style-type:none}.lst-kix_8ujam3zhcr3q-3>li:before{content:"-  "}ul.lst-kix_a9h81iclzrpy-5{list-style-type:none}ul.lst-kix_a9h81iclzrpy-6{list-style-type:none}ul.lst-kix_ofib0hkczw41-5{list-style-type:none}ul.lst-kix_ofib0hkczw41-6{list-style-type:none}ul.lst-kix_ofib0hkczw41-3{list-style-type:none}ul.lst-kix_ofib0hkczw41-4{list-style-type:none}ul.lst-kix_1pt1eqcq4ieh-1{list-style-type:none}ul.lst-kix_ofib0hkczw41-1{list-style-type:none}ul.lst-kix_g2uanok8rp1g-8{list-style-type:none}ul.lst-kix_1pt1eqcq4ieh-2{list-style-type:none}ul.lst-kix_ofib0hkczw41-2{list-style-type:none}ul.lst-kix_1pt1eqcq4ieh-0{list-style-type:none}ul.lst-kix_ofib0hkczw41-0{list-style-type:none}.lst-kix_mh5zhf27i4rj-7>li:before{content:"-  "}ul.lst-kix_1pt1eqcq4ieh-5{list-style-type:none}.lst-kix_4xiv877yc8jl-7>li:before{content:"-  "}.lst-kix_aor1182clqbr-1>li:before{content:"-  "}ul.lst-kix_1pt1eqcq4ieh-6{list-style-type:none}ul.lst-kix_1pt1eqcq4ieh-3{list-style-type:none}.lst-kix_g8jgbze430sv-5>li{counter-increment:lst-ctn-kix_g8jgbze430sv-5}ul.lst-kix_1pt1eqcq4ieh-4{list-style-type:none}.lst-kix_qw2h6jd8xi17-2>li:before{content:"-  "}ul.lst-kix_1pt1eqcq4ieh-7{list-style-type:none}ul.lst-kix_1pt1eqcq4ieh-8{list-style-type:none}.lst-kix_mh5zhf27i4rj-1>li:before{content:"-  "}ul.lst-kix_a9h81iclzrpy-7{list-style-type:none}.lst-kix_eme1x4epzdye-4>li:before{content:"-  "}ul.lst-kix_a9h81iclzrpy-8{list-style-type:none}ol.lst-kix_3fc7x0lm2mmz-4.start{counter-reset:lst-ctn-kix_3fc7x0lm2mmz-4 0}.lst-kix_x8ffawrvrcyq-2>li:before{content:"\0025a0   "}.lst-kix_ul22dko4fd2j-1>li:before{content:"-  "}.lst-kix_hmvj5t8yy8bx-5>li:before{content:"+  "}.lst-kix_gvlgpawofwi7-6>li:before{content:"-  "}ul.lst-kix_g2uanok8rp1g-4{list-style-type:none}ul.lst-kix_g2uanok8rp1g-5{list-style-type:none}ul.lst-kix_g2uanok8rp1g-6{list-style-type:none}.lst-kix_tdrf79x9zyr7-0>li:before{content:"-  "}ul.lst-kix_g2uanok8rp1g-7{list-style-type:none}ul.lst-kix_g2uanok8rp1g-0{list-style-type:none}.lst-kix_tt1bo8z9re67-5>li:before{content:"-  "}ul.lst-kix_g2uanok8rp1g-1{list-style-type:none}ul.lst-kix_ofib0hkczw41-7{list-style-type:none}ul.lst-kix_g2uanok8rp1g-2{list-style-type:none}.lst-kix_mv77cg19299c-6>li:before{content:"-  "}ul.lst-kix_ofib0hkczw41-8{list-style-type:none}.lst-kix_yrg2qlcqvak1-1>li:before{content:"-  "}ul.lst-kix_g2uanok8rp1g-3{list-style-type:none}.lst-kix_lwlxuymndfyq-4>li:before{content:"-  "}.lst-kix_aor1182clqbr-7>li:before{content:"-  "}.lst-kix_4qbfcta6cclt-5>li:before{content:"-  "}ul.lst-kix_kt8k33f35qi5-8{list-style-type:none}.lst-kix_8euewcidoez8-1>li:before{content:"-  "}ul.lst-kix_3koi1cw13a0-0{list-style-type:none}ul.lst-kix_3koi1cw13a0-2{list-style-type:none}ul.lst-kix_3koi1cw13a0-1{list-style-type:none}ul.lst-kix_3koi1cw13a0-4{list-style-type:none}.lst-kix_xx6ude5yqnkl-3>li:before{content:"\0025cf   "}ul.lst-kix_3koi1cw13a0-3{list-style-type:none}ul.lst-kix_kt8k33f35qi5-0{list-style-type:none}ol.lst-kix_ysfu1bl0kymd-5.start{counter-reset:lst-ctn-kix_ysfu1bl0kymd-5 0}.lst-kix_8w7txqc6xq66-5>li:before{content:"-  "}ul.lst-kix_kt8k33f35qi5-1{list-style-type:none}ul.lst-kix_kt8k33f35qi5-2{list-style-type:none}ul.lst-kix_kt8k33f35qi5-3{list-style-type:none}ul.lst-kix_kt8k33f35qi5-4{list-style-type:none}.lst-kix_k5hm652wcnm2-7>li:before{content:"-  "}ul.lst-kix_kt8k33f35qi5-5{list-style-type:none}ul.lst-kix_kt8k33f35qi5-6{list-style-type:none}ul.lst-kix_kt8k33f35qi5-7{list-style-type:none}.lst-kix_k5hm652wcnm2-1>li:before{content:"-  "}ul.lst-kix_ht80gp8jxjfs-8{list-style-type:none}ul.lst-kix_q2mi4y6rc42i-7{list-style-type:none}ul.lst-kix_ht80gp8jxjfs-7{list-style-type:none}ul.lst-kix_q2mi4y6rc42i-8{list-style-type:none}ul.lst-kix_ht80gp8jxjfs-4{list-style-type:none}ul.lst-kix_q2mi4y6rc42i-3{list-style-type:none}.lst-kix_8euewcidoez8-7>li:before{content:"-  "}ul.lst-kix_ht80gp8jxjfs-3{list-style-type:none}ul.lst-kix_q2mi4y6rc42i-4{list-style-type:none}ul.lst-kix_ht80gp8jxjfs-6{list-style-type:none}ul.lst-kix_q2mi4y6rc42i-5{list-style-type:none}ul.lst-kix_ht80gp8jxjfs-5{list-style-type:none}ul.lst-kix_q2mi4y6rc42i-6{list-style-type:none}ul.lst-kix_3koi1cw13a0-6{list-style-type:none}ul.lst-kix_3koi1cw13a0-5{list-style-type:none}ul.lst-kix_q2mi4y6rc42i-0{list-style-type:none}ul.lst-kix_3koi1cw13a0-8{list-style-type:none}ul.lst-kix_q2mi4y6rc42i-1{list-style-type:none}ul.lst-kix_3koi1cw13a0-7{list-style-type:none}.lst-kix_tdrf79x9zyr7-6>li:before{content:"-  "}ul.lst-kix_q2mi4y6rc42i-2{list-style-type:none}.lst-kix_2foc6u9lzfq4-2>li:before{content:"" counter(lst-ctn-kix_2foc6u9lzfq4-2,lower-roman) ". "}.lst-kix_py2swxy3gr0i-3>li:before{content:"-  "}.lst-kix_hkt83gwcgrvq-8>li:before{content:"-  "}.lst-kix_tc7vpn5ce0ra-7>li:before{content:"-  "}.lst-kix_vayf18aqt55o-5>li:before{content:"(" counter(lst-ctn-kix_vayf18aqt55o-5,decimal) ") "}.lst-kix_arcio13zm8ud-7>li:before{content:"-  "}.lst-kix_arcio13zm8ud-1>li:before{content:"-  "}.lst-kix_rrloltks13s-5>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-7>li{counter-increment:lst-ctn-kix_3fc7x0lm2mmz-7}ul.lst-kix_dmn3lqzfmokk-8{list-style-type:none}.lst-kix_2foc6u9lzfq4-8>li:before{content:"" counter(lst-ctn-kix_2foc6u9lzfq4-8,lower-roman) ". "}.lst-kix_6u6or33vx86s-5>li:before{content:"-  "}ul.lst-kix_dmn3lqzfmokk-3{list-style-type:none}ul.lst-kix_dmn3lqzfmokk-2{list-style-type:none}ul.lst-kix_dmn3lqzfmokk-1{list-style-type:none}ul.lst-kix_dmn3lqzfmokk-0{list-style-type:none}.lst-kix_tw1wz6pba43e-1>li:before{content:"-  "}ul.lst-kix_dmn3lqzfmokk-7{list-style-type:none}ul.lst-kix_dmn3lqzfmokk-6{list-style-type:none}ul.lst-kix_dmn3lqzfmokk-5{list-style-type:none}ul.lst-kix_dmn3lqzfmokk-4{list-style-type:none}.lst-kix_vayf18aqt55o-8>li{counter-increment:lst-ctn-kix_vayf18aqt55o-8}.lst-kix_yhq927c05ak0-4>li:before{content:"-  "}.lst-kix_4xiv877yc8jl-1>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-0.start{counter-reset:lst-ctn-kix_d1gy3hy5r3qj-0 0}.lst-kix_7rlftcume51v-1>li:before{content:"-  "}.lst-kix_puc0azh4kjfq-7>li:before{content:"-  "}.lst-kix_ms4jfr9nudpc-5>li:before{content:"-  "}.lst-kix_puc0azh4kjfq-1>li:before{content:"-  "}ul.lst-kix_zb3jq278pptw-3{list-style-type:none}ul.lst-kix_zb3jq278pptw-4{list-style-type:none}.lst-kix_7rlftcume51v-7>li:before{content:"-  "}ul.lst-kix_zb3jq278pptw-1{list-style-type:none}ul.lst-kix_zb3jq278pptw-2{list-style-type:none}ul.lst-kix_zb3jq278pptw-0{list-style-type:none}ul.lst-kix_zb3jq278pptw-7{list-style-type:none}ul.lst-kix_zb3jq278pptw-8{list-style-type:none}.lst-kix_6ltb10qoez57-8>li:before{content:"\0025a0   "}ul.lst-kix_zb3jq278pptw-5{list-style-type:none}.lst-kix_tc7vpn5ce0ra-1>li:before{content:"-  "}ul.lst-kix_zb3jq278pptw-6{list-style-type:none}.lst-kix_st0egafmkg0z-1>li:before{content:"-  "}.lst-kix_j60wooaeanf9-4>li:before{content:"-  "}.lst-kix_v0hsa7m5lywt-4>li:before{content:"-  "}.lst-kix_qmryaqe19okh-5>li:before{content:"-  "}.lst-kix_6ltb10qoez57-2>li:before{content:"\0025a0   "}.lst-kix_nj8yy6k748x0-6>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-1>li{counter-increment:lst-ctn-kix_2foc6u9lzfq4-1}ul.lst-kix_njs8ubf1qesf-8{list-style-type:none}ul.lst-kix_njs8ubf1qesf-7{list-style-type:none}ul.lst-kix_njs8ubf1qesf-6{list-style-type:none}ul.lst-kix_njs8ubf1qesf-5{list-style-type:none}ul.lst-kix_njs8ubf1qesf-4{list-style-type:none}ul.lst-kix_njs8ubf1qesf-3{list-style-type:none}ul.lst-kix_njs8ubf1qesf-2{list-style-type:none}ul.lst-kix_njs8ubf1qesf-1{list-style-type:none}.lst-kix_5djgwp8c9ig2-4>li{counter-increment:lst-ctn-kix_5djgwp8c9ig2-4}.lst-kix_5syfdd8x3l8s-8>li:before{content:"-  "}.lst-kix_ozrjmre97pex-6>li:before{content:"-  "}.lst-kix_mtm8lwd6vxjl-2>li:before{content:"-  "}.lst-kix_4ii5776egvw8-3>li:before{content:"-  "}ol.lst-kix_sxixw4iqsgzx-6.start{counter-reset:lst-ctn-kix_sxixw4iqsgzx-6 0}.lst-kix_dynlpr2uwt2p-2>li:before{content:"-  "}.lst-kix_bv8sxewi94yp-2>li:before{content:"-  "}.lst-kix_fmkfhvl8yhfs-0>li:before{content:"-  "}.lst-kix_ykhrv7u6blcs-2>li:before{content:"-  "}.lst-kix_l5iaj94ondn3-3>li:before{content:"-  "}ul.lst-kix_x1xhkkpc69w2-1{list-style-type:none}ol.lst-kix_yjf6dvvoob64-4.start{counter-reset:lst-ctn-kix_yjf6dvvoob64-4 0}ul.lst-kix_x1xhkkpc69w2-2{list-style-type:none}ul.lst-kix_x1xhkkpc69w2-0{list-style-type:none}ul.lst-kix_x1xhkkpc69w2-5{list-style-type:none}.lst-kix_ykhoydml7pv3-1>li:before{content:"" counter(lst-ctn-kix_ykhoydml7pv3-1,lower-latin) ") "}ul.lst-kix_x1xhkkpc69w2-6{list-style-type:none}ul.lst-kix_x1xhkkpc69w2-3{list-style-type:none}ul.lst-kix_x1xhkkpc69w2-4{list-style-type:none}.lst-kix_cpgerodpupjz-6>li:before{content:"-  "}.lst-kix_8hf94791m5p0-3>li:before{content:"-  "}.lst-kix_1x319pprarxc-1>li:before{content:"-  "}.lst-kix_xdqzm25ye8fb-1>li:before{content:"-  "}.lst-kix_7o5enrj2ko1w-2>li:before{content:"-  "}.lst-kix_c7r1s55bmbei-6>li:before{content:"-  "}.lst-kix_jnfn9mx5o33t-8>li:before{content:"-  "}.lst-kix_81v91kbrmywy-7>li:before{content:"-  "}.lst-kix_fs1lzw38maxl-8>li:before{content:"-  "}ul.lst-kix_x1xhkkpc69w2-7{list-style-type:none}ul.lst-kix_x1xhkkpc69w2-8{list-style-type:none}.lst-kix_b3ghc04lfx9t-0>li:before{content:"-  "}.lst-kix_3wxxpxfz40sk-2>li:before{content:"-  "}ul.lst-kix_1v1216yy0n25-6{list-style-type:none}ul.lst-kix_1v1216yy0n25-5{list-style-type:none}ul.lst-kix_1v1216yy0n25-8{list-style-type:none}ul.lst-kix_1v1216yy0n25-7{list-style-type:none}.lst-kix_fm53cr9wmch0-3>li:before{content:"-  "}.lst-kix_m5azvtuvtpt1-6>li:before{content:"-  "}.lst-kix_zag3ymt8mk2y-5>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-1>li{counter-increment:lst-ctn-kix_3mj3tp7kj9db-1}.lst-kix_cd2o0cncsajm-6>li:before{content:"-  "}.lst-kix_23ct987xwu67-5>li:before{content:"(" counter(lst-ctn-kix_23ct987xwu67-5,lower-roman) ") "}.lst-kix_9z31rmzc855z-4>li:before{content:"-  "}.lst-kix_tnd0p97rqwub-3>li:before{content:"-  "}.lst-kix_jvmsa1jxmzig-8>li:before{content:"\0025a0   "}.lst-kix_8pn77unkg8hg-2>li:before{content:"-  "}.lst-kix_6nc1nfac2wub-3>li:before{content:"-  "}ul.lst-kix_1v1216yy0n25-0{list-style-type:none}ol.lst-kix_ypd5gkkarijk-7.start{counter-reset:lst-ctn-kix_ypd5gkkarijk-7 0}ul.lst-kix_1v1216yy0n25-2{list-style-type:none}.lst-kix_6pgojrjbxqei-5>li:before{content:"\0025a0   "}.lst-kix_t9t3ckq2i2hz-2>li:before{content:"-  "}ul.lst-kix_1v1216yy0n25-1{list-style-type:none}ul.lst-kix_1v1216yy0n25-4{list-style-type:none}ul.lst-kix_1v1216yy0n25-3{list-style-type:none}ol.lst-kix_g8jgbze430sv-1.start{counter-reset:lst-ctn-kix_g8jgbze430sv-1 0}ul.lst-kix_3bnqwg68tpm3-2{list-style-type:none}.lst-kix_3mj3tp7kj9db-6>li:before{content:"" counter(lst-ctn-kix_3mj3tp7kj9db-6,decimal) ". "}ul.lst-kix_3bnqwg68tpm3-1{list-style-type:none}ul.lst-kix_3bnqwg68tpm3-0{list-style-type:none}.lst-kix_rf3bfhvmysmh-6>li:before{content:"-  "}ul.lst-kix_3bnqwg68tpm3-8{list-style-type:none}ul.lst-kix_3bnqwg68tpm3-7{list-style-type:none}ul.lst-kix_3bnqwg68tpm3-6{list-style-type:none}ul.lst-kix_3bnqwg68tpm3-5{list-style-type:none}ul.lst-kix_3bnqwg68tpm3-4{list-style-type:none}ul.lst-kix_3bnqwg68tpm3-3{list-style-type:none}.lst-kix_tagzs2njqau3-3>li:before{content:"-  "}.lst-kix_d7eif1vat32g-8>li:before{content:"-  "}.lst-kix_wwm574aidb8n-0>li:before{content:"-  "}.lst-kix_eiskzjj27gc6-4>li:before{content:"-  "}.lst-kix_5nilpkhthb5t-3>li:before{content:"-  "}.lst-kix_x95t913s41kt-6>li:before{content:"-  "}ul.lst-kix_73pnq2b8bo4n-0{list-style-type:none}.lst-kix_3q7au8a3gwav-0>li:before{content:"-  "}.lst-kix_ivmzvkm69gsd-4>li:before{content:"-  "}.lst-kix_a62ncfcuapzo-7>li:before{content:"-  "}.lst-kix_jhofo94iol1-1>li:before{content:"-  "}ul.lst-kix_73pnq2b8bo4n-8{list-style-type:none}.lst-kix_q24qpifeknc3-4>li:before{content:"-  "}ul.lst-kix_73pnq2b8bo4n-7{list-style-type:none}ul.lst-kix_73pnq2b8bo4n-6{list-style-type:none}.lst-kix_unv0ib1v43rp-4>li:before{content:"-  "}ul.lst-kix_73pnq2b8bo4n-5{list-style-type:none}ul.lst-kix_73pnq2b8bo4n-4{list-style-type:none}ul.lst-kix_73pnq2b8bo4n-3{list-style-type:none}ul.lst-kix_73pnq2b8bo4n-2{list-style-type:none}ul.lst-kix_73pnq2b8bo4n-1{list-style-type:none}.lst-kix_84zf7o74c8s9-8>li{counter-increment:lst-ctn-kix_84zf7o74c8s9-8}.lst-kix_rtczm6eelr4h-1>li:before{content:"-  "}.lst-kix_hngwf7orguk6-0>li:before{content:"-  "}.lst-kix_hytfj9icha07-4>li:before{content:"-  "}.lst-kix_rop4yg7lbfg8-3>li:before{content:"-  "}.lst-kix_n0rv3zxivae3-8>li:before{content:"-  "}.lst-kix_5argtotmwusw-0>li:before{content:"-  "}.lst-kix_pg2i9lis4p1v-1>li:before{content:"-  "}.lst-kix_chbthqdwx7gj-5>li:before{content:"-  "}.lst-kix_ukx3y28hag8h-1>li:before{content:"-  "}ol.lst-kix_2foc6u9lzfq4-3{list-style-type:none}ol.lst-kix_2foc6u9lzfq4-2{list-style-type:none}ol.lst-kix_2foc6u9lzfq4-5{list-style-type:none}ol.lst-kix_2foc6u9lzfq4-4{list-style-type:none}ol.lst-kix_2foc6u9lzfq4-1{list-style-type:none}ol.lst-kix_2foc6u9lzfq4-0{list-style-type:none}.lst-kix_a42anijqpp8a-7>li:before{content:"-  "}ol.lst-kix_2foc6u9lzfq4-7{list-style-type:none}ol.lst-kix_2foc6u9lzfq4-6{list-style-type:none}.lst-kix_8nwtyhgsvjlm-6>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-2>li{counter-increment:lst-ctn-kix_u8nobwiguyj1-2}ol.lst-kix_2foc6u9lzfq4-8{list-style-type:none}.lst-kix_qmx92jmkghx8-3>li:before{content:"-  "}ol.lst-kix_5djgwp8c9ig2-6.start{counter-reset:lst-ctn-kix_5djgwp8c9ig2-6 0}ul.lst-kix_p9ucdfdvxyzl-8{list-style-type:none}.lst-kix_b7rulpv7obgl-4>li:before{content:"-  "}ul.lst-kix_p9ucdfdvxyzl-7{list-style-type:none}ul.lst-kix_p9ucdfdvxyzl-6{list-style-type:none}ul.lst-kix_p9ucdfdvxyzl-5{list-style-type:none}ul.lst-kix_p9ucdfdvxyzl-4{list-style-type:none}ul.lst-kix_p9ucdfdvxyzl-3{list-style-type:none}.lst-kix_qsto019ofcm1-2>li:before{content:"-  "}ul.lst-kix_bnvwt1y8k7b-0{list-style-type:none}.lst-kix_e73zm9q3mvin-3>li:before{content:"-  "}ul.lst-kix_bnvwt1y8k7b-1{list-style-type:none}ul.lst-kix_bnvwt1y8k7b-2{list-style-type:none}ul.lst-kix_bnvwt1y8k7b-3{list-style-type:none}ul.lst-kix_bnvwt1y8k7b-4{list-style-type:none}.lst-kix_rgd2g4si1ihs-8>li:before{content:"-  "}ul.lst-kix_bnvwt1y8k7b-5{list-style-type:none}ul.lst-kix_bnvwt1y8k7b-6{list-style-type:none}ul.lst-kix_bnvwt1y8k7b-7{list-style-type:none}.lst-kix_g9hblcm1l6tk-5>li:before{content:"-  "}ul.lst-kix_bnvwt1y8k7b-8{list-style-type:none}.lst-kix_17yxihawuh4r-0>li:before{content:"-  "}.lst-kix_ozbrn4vmjez8-2>li:before{content:"-  "}ol.lst-kix_xyra4e5ffsud-1.start{counter-reset:lst-ctn-kix_xyra4e5ffsud-1 0}.lst-kix_3wddikkjnk2k-5>li:before{content:"-  "}.lst-kix_g2uanok8rp1g-4>li:before{content:"-  "}.lst-kix_bo9wrgz88es4-4>li:before{content:"-  "}.lst-kix_ce3ho29dhteb-0>li:before{content:"-  "}.lst-kix_rp6rf03vbelo-2>li:before{content:"-  "}.lst-kix_x1n4jlo0gf1q-8>li:before{content:"-  "}.lst-kix_wiijpxq0m5a-3>li:before{content:"-  "}.lst-kix_nqtgcebhe8ii-2>li:before{content:"-  "}.lst-kix_4pjeuglo4z6v-1>li:before{content:"-  "}.lst-kix_nipj94pw11x6-3>li:before{content:"-  "}.lst-kix_h25uruhpfzux-3>li:before{content:"-  "}.lst-kix_kt8k33f35qi5-2>li:before{content:"-  "}.lst-kix_2xixyk6jteti-7>li:before{content:"-  "}.lst-kix_kt8k33f35qi5-8>li:before{content:"-  "}.lst-kix_4pjeuglo4z6v-7>li:before{content:"-  "}.lst-kix_s9h4llxy1yy0-0>li:before{content:"-  "}ul.lst-kix_x424ckbm5jp1-0{list-style-type:none}.lst-kix_zb3jq278pptw-8>li:before{content:"-  "}ul.lst-kix_x424ckbm5jp1-1{list-style-type:none}.lst-kix_dmn3lqzfmokk-3>li:before{content:"-  "}ul.lst-kix_x424ckbm5jp1-2{list-style-type:none}.lst-kix_g0lr2dxtnslc-3>li:before{content:"-  "}ul.lst-kix_x424ckbm5jp1-3{list-style-type:none}.lst-kix_x1n4jlo0gf1q-2>li:before{content:"-  "}ul.lst-kix_x424ckbm5jp1-4{list-style-type:none}ul.lst-kix_x424ckbm5jp1-5{list-style-type:none}ul.lst-kix_x424ckbm5jp1-6{list-style-type:none}ul.lst-kix_x424ckbm5jp1-7{list-style-type:none}.lst-kix_ce3ho29dhteb-6>li:before{content:"-  "}ul.lst-kix_x424ckbm5jp1-8{list-style-type:none}.lst-kix_yvohqcnu3146-1>li{counter-increment:lst-ctn-kix_yvohqcnu3146-1}.lst-kix_9j3np3ow732h-7>li:before{content:"\0025cb   "}.lst-kix_7vaamq35f1cc-3>li:before{content:"-  "}.lst-kix_skgpgvhmuoc4-4>li:before{content:"-  "}.lst-kix_ms6rbzn59hmq-3>li:before{content:"-  "}.lst-kix_f9iu0trsjas1-0>li:before{content:"-  "}ul.lst-kix_pv4jsz2h74wk-0{list-style-type:none}ul.lst-kix_pv4jsz2h74wk-2{list-style-type:none}.lst-kix_x424ckbm5jp1-2>li:before{content:"-  "}ul.lst-kix_pv4jsz2h74wk-1{list-style-type:none}ul.lst-kix_pv4jsz2h74wk-4{list-style-type:none}.lst-kix_m31se2npgu2r-1>li:before{content:"-  "}ul.lst-kix_pv4jsz2h74wk-3{list-style-type:none}.lst-kix_3koi1cw13a0-4>li:before{content:"-  "}ul.lst-kix_pv4jsz2h74wk-6{list-style-type:none}.lst-kix_zb3jq278pptw-2>li:before{content:"-  "}ul.lst-kix_pv4jsz2h74wk-5{list-style-type:none}.lst-kix_f9iu0trsjas1-6>li:before{content:"-  "}ul.lst-kix_pv4jsz2h74wk-8{list-style-type:none}ul.lst-kix_pv4jsz2h74wk-7{list-style-type:none}ul.lst-kix_5ze5xofgghz2-2{list-style-type:none}ul.lst-kix_5ze5xofgghz2-1{list-style-type:none}.lst-kix_fld6w0ks1f0p-6>li:before{content:"-  "}ul.lst-kix_5ze5xofgghz2-0{list-style-type:none}.lst-kix_9j3np3ow732h-1>li:before{content:"\0025cb   "}ul.lst-kix_5ze5xofgghz2-6{list-style-type:none}.lst-kix_w21i9d12ynhg-1>li:before{content:"-  "}.lst-kix_bsvmcpoa86br-7>li:before{content:"-  "}ul.lst-kix_5ze5xofgghz2-5{list-style-type:none}ul.lst-kix_5ze5xofgghz2-4{list-style-type:none}ul.lst-kix_5ze5xofgghz2-3{list-style-type:none}ul.lst-kix_5ze5xofgghz2-8{list-style-type:none}.lst-kix_lcru2cdgc87j-5>li:before{content:"-  "}ul.lst-kix_5ze5xofgghz2-7{list-style-type:none}ul.lst-kix_ellvdfsu2z7q-6{list-style-type:none}.lst-kix_oswsfzrgbvyb-4>li:before{content:"-  "}ul.lst-kix_ellvdfsu2z7q-7{list-style-type:none}ul.lst-kix_ellvdfsu2z7q-8{list-style-type:none}.lst-kix_ld6rwbdri49-1>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-1.start{counter-reset:lst-ctn-kix_ok1n37qarjzb-1 0}.lst-kix_t6x6ie377r4u-0>li:before{content:"-  "}ul.lst-kix_ellvdfsu2z7q-2{list-style-type:none}ul.lst-kix_ellvdfsu2z7q-3{list-style-type:none}.lst-kix_qb494lue4ahb-7>li:before{content:"-  "}ul.lst-kix_ellvdfsu2z7q-4{list-style-type:none}.lst-kix_3ug9en49p7ih-1>li:before{content:"-  "}ul.lst-kix_ellvdfsu2z7q-5{list-style-type:none}ul.lst-kix_ellvdfsu2z7q-0{list-style-type:none}ul.lst-kix_ellvdfsu2z7q-1{list-style-type:none}.lst-kix_awt45k7p90je-8>li:before{content:"-  "}.lst-kix_9hby2lis2y9u-3>li:before{content:"-  "}.lst-kix_ssze0kg2kz13-7>li:before{content:"-  "}.lst-kix_mq980hprr5hl-0>li:before{content:"-  "}.lst-kix_innl5fto9oyf-3>li:before{content:"-  "}.lst-kix_52jgzw489fhs-3>li:before{content:"" counter(lst-ctn-kix_52jgzw489fhs-3,decimal) ". "}.lst-kix_ssze0kg2kz13-1>li:before{content:"-  "}.lst-kix_l60gvbdij7aj-3>li:before{content:"-  "}.lst-kix_6n4varno3bjs-5>li:before{content:"-  "}.lst-kix_3ug9en49p7ih-7>li:before{content:"-  "}.lst-kix_4z9ptm6a4lke-2>li:before{content:"-  "}.lst-kix_4z9ptm6a4lke-8>li:before{content:"-  "}.lst-kix_df6s37r8voak-2>li:before{content:"-  "}.lst-kix_5u0542f2h2jt-5>li:before{content:"+  "}.lst-kix_x6hb6vgwujyx-3>li:before{content:"-  "}.lst-kix_7e64bsb5krip-2>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-8>li:before{content:"" counter(lst-ctn-kix_yjf6dvvoob64-8,lower-roman) ". "}.lst-kix_om0x63wgf9wd-3>li:before{content:"-  "}ol.lst-kix_ykhoydml7pv3-4.start{counter-reset:lst-ctn-kix_ykhoydml7pv3-4 0}.lst-kix_xdqzm25ye8fb-7>li:before{content:"-  "}.lst-kix_fexdtgozkcsr-1>li:before{content:"-  "}.lst-kix_1xkx8gh1e8n7-7>li:before{content:"-  "}.lst-kix_5quy3fbj2mfg-6>li:before{content:"-  "}.lst-kix_2ccdqvrbclt-6>li:before{content:"-  "}.lst-kix_tjrvr4c0ezjq-1>li:before{content:"-  "}.lst-kix_t3rn73qejgkj-2>li{counter-increment:lst-ctn-kix_t3rn73qejgkj-2}.lst-kix_3bnqwg68tpm3-0>li:before{content:"-  "}.lst-kix_vuz55xpe5xjl-2>li:before{content:"-  "}.lst-kix_1x319pprarxc-7>li:before{content:"-  "}.lst-kix_vie3q5oyli2z-5>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-8.start{counter-reset:lst-ctn-kix_d1gy3hy5r3qj-8 0}.lst-kix_2nm562bzmwr-3>li:before{content:"-  "}.lst-kix_ozrjmre97pex-0>li:before{content:"-  "}.lst-kix_6xh4bfg7mbxi-2>li:before{content:"-  "}.lst-kix_ykhrv7u6blcs-8>li:before{content:"-  "}.lst-kix_dyq7vlcdkqm5-8>li:before{content:"-  "}.lst-kix_qbfnanuzy3l5-5>li:before{content:"-  "}.lst-kix_dn04c4yafie0-3>li:before{content:"-  "}.lst-kix_p1rtf0e14360-3>li:before{content:"-  "}ol.lst-kix_hppu19i8fr2p-5.start{counter-reset:lst-ctn-kix_hppu19i8fr2p-5 0}.lst-kix_oxgbebk5l98i-4>li:before{content:"-  "}.lst-kix_onvme58enb43-0>li:before{content:"-  "}.lst-kix_wlyv8o88ksmk-6>li:before{content:"-  "}.lst-kix_wfyz8rmi0iq4-5>li:before{content:"-  "}.lst-kix_ltm9vv1op5tt-3>li:before{content:"-  "}.lst-kix_ro388iryhhf5-5>li:before{content:"-  "}.lst-kix_df6s37r8voak-8>li:before{content:"-  "}.lst-kix_w32pgwk3f0lb-4>li:before{content:"-  "}.lst-kix_voj7evacrpie-8>li:before{content:"-  "}.lst-kix_fs1lzw38maxl-2>li:before{content:"-  "}.lst-kix_b3ghc04lfx9t-6>li:before{content:"-  "}.lst-kix_cd2o0cncsajm-0>li:before{content:"-  "}.lst-kix_fifu4bguh6qm-6>li:before{content:"-  "}.lst-kix_1pt1eqcq4ieh-7>li:before{content:"-  "}.lst-kix_jnfn9mx5o33t-2>li:before{content:"-  "}.lst-kix_xyra4e5ffsud-1>li{counter-increment:lst-ctn-kix_xyra4e5ffsud-1}.lst-kix_3wxxpxfz40sk-8>li:before{content:"-  "}.lst-kix_rf1gg3liws68-8>li:before{content:"-  "}ul.lst-kix_ht80gp8jxjfs-0{list-style-type:none}ul.lst-kix_ht80gp8jxjfs-2{list-style-type:none}ul.lst-kix_ht80gp8jxjfs-1{list-style-type:none}ul.lst-kix_hkt83gwcgrvq-3{list-style-type:none}.lst-kix_mtm8lwd6vxjl-8>li:before{content:"-  "}ul.lst-kix_hkt83gwcgrvq-2{list-style-type:none}ul.lst-kix_hkt83gwcgrvq-1{list-style-type:none}ul.lst-kix_hkt83gwcgrvq-0{list-style-type:none}ul.lst-kix_hkt83gwcgrvq-7{list-style-type:none}ul.lst-kix_hkt83gwcgrvq-6{list-style-type:none}.lst-kix_7cboi17aj4i3-0>li:before{content:"-  "}ul.lst-kix_hkt83gwcgrvq-5{list-style-type:none}.lst-kix_ld6rwbdri49-7>li:before{content:"-  "}ul.lst-kix_hkt83gwcgrvq-4{list-style-type:none}.lst-kix_81v91kbrmywy-1>li:before{content:"-  "}ul.lst-kix_hkt83gwcgrvq-8{list-style-type:none}.lst-kix_hkt83gwcgrvq-2>li:before{content:"-  "}.lst-kix_xyra4e5ffsud-8>li:before{content:"" counter(lst-ctn-kix_xyra4e5ffsud-8,lower-roman) ". "}.lst-kix_rf3bfhvmysmh-0>li:before{content:"-  "}.lst-kix_hc732m8hksyq-6>li:before{content:"-  "}ul.lst-kix_4qbfcta6cclt-0{list-style-type:none}ul.lst-kix_4qbfcta6cclt-1{list-style-type:none}.lst-kix_pgnpvlxhai6o-1>li:before{content:"-  "}.lst-kix_dln561wj05xo-2>li:before{content:"-  "}ul.lst-kix_4qbfcta6cclt-6{list-style-type:none}ul.lst-kix_4qbfcta6cclt-7{list-style-type:none}ul.lst-kix_4qbfcta6cclt-8{list-style-type:none}ul.lst-kix_4qbfcta6cclt-2{list-style-type:none}ul.lst-kix_4qbfcta6cclt-3{list-style-type:none}ul.lst-kix_4qbfcta6cclt-4{list-style-type:none}ul.lst-kix_4qbfcta6cclt-5{list-style-type:none}.lst-kix_a62ncfcuapzo-1>li:before{content:"-  "}.lst-kix_wwm574aidb8n-6>li:before{content:"-  "}.lst-kix_jhofo94iol1-7>li:before{content:"-  "}.lst-kix_m5azvtuvtpt1-0>li:before{content:"-  "}.lst-kix_a42anijqpp8a-1>li:before{content:"-  "}.lst-kix_ekasiajyrrvz-3>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-0>li:before{content:"" counter(lst-ctn-kix_3mj3tp7kj9db-0,decimal) ") "}.lst-kix_sxixw4iqsgzx-6>li:before{content:"" counter(lst-ctn-kix_sxixw4iqsgzx-6,decimal) ". "}.lst-kix_xktbtduo53bq-4>li{counter-increment:lst-ctn-kix_xktbtduo53bq-4}.lst-kix_xhhdon4tpeu0-6>li:before{content:"-  "}.lst-kix_axy5kxvo2nx7-3>li:before{content:"-  "}.lst-kix_hngwf7orguk6-6>li:before{content:"-  "}.lst-kix_5stj9b6acoxv-1>li{counter-increment:lst-ctn-kix_5stj9b6acoxv-1}.lst-kix_d7eif1vat32g-2>li:before{content:"-  "}.lst-kix_iffqre5r12zx-5>li:before{content:"-  "}.lst-kix_qqbjjwnrc3l8-3>li:before{content:"-  "}.lst-kix_f9iqanr8ite6-2>li:before{content:"-  "}ul.lst-kix_py2swxy3gr0i-1{list-style-type:none}ul.lst-kix_py2swxy3gr0i-0{list-style-type:none}ul.lst-kix_py2swxy3gr0i-3{list-style-type:none}ul.lst-kix_py2swxy3gr0i-2{list-style-type:none}ul.lst-kix_py2swxy3gr0i-5{list-style-type:none}ul.lst-kix_lwlxuymndfyq-0{list-style-type:none}ul.lst-kix_py2swxy3gr0i-4{list-style-type:none}.lst-kix_x1xhkkpc69w2-3>li:before{content:"-  "}ul.lst-kix_lwlxuymndfyq-1{list-style-type:none}ul.lst-kix_py2swxy3gr0i-7{list-style-type:none}.lst-kix_rtczm6eelr4h-7>li:before{content:"-  "}ul.lst-kix_lwlxuymndfyq-2{list-style-type:none}ul.lst-kix_py2swxy3gr0i-6{list-style-type:none}ul.lst-kix_lwlxuymndfyq-3{list-style-type:none}.lst-kix_5ze5xofgghz2-7>li:before{content:"-  "}ul.lst-kix_lwlxuymndfyq-4{list-style-type:none}ul.lst-kix_lwlxuymndfyq-5{list-style-type:none}ul.lst-kix_lwlxuymndfyq-6{list-style-type:none}.lst-kix_yvohqcnu3146-8>li{counter-increment:lst-ctn-kix_yvohqcnu3146-8}ul.lst-kix_lwlxuymndfyq-7{list-style-type:none}ul.lst-kix_lwlxuymndfyq-8{list-style-type:none}.lst-kix_n0rv3zxivae3-2>li:before{content:"-  "}.lst-kix_7gk9ayd44tft-3>li:before{content:"-  "}.lst-kix_90bg3luq5inv-2>li{counter-increment:lst-ctn-kix_90bg3luq5inv-2}.lst-kix_azgj6sn0lxuj-4>li{counter-increment:lst-ctn-kix_azgj6sn0lxuj-4}ul.lst-kix_py2swxy3gr0i-8{list-style-type:none}.lst-kix_epyrmry7301m-7>li:before{content:"-  "}.lst-kix_brqn5pq4e7i7-3>li:before{content:"-  "}.lst-kix_iefjrs8t42tr-1>li:before{content:"-  "}ul.lst-kix_rf1gg3liws68-7{list-style-type:none}ul.lst-kix_of5ud22cn0qg-0{list-style-type:none}ul.lst-kix_rf1gg3liws68-6{list-style-type:none}ul.lst-kix_of5ud22cn0qg-1{list-style-type:none}ul.lst-kix_rf1gg3liws68-5{list-style-type:none}.lst-kix_7vr84ges94ry-0>li:before{content:"-  "}ul.lst-kix_of5ud22cn0qg-2{list-style-type:none}ul.lst-kix_rf1gg3liws68-4{list-style-type:none}.lst-kix_mvektlca5c5q-3>li:before{content:"-  "}ul.lst-kix_rf1gg3liws68-3{list-style-type:none}ul.lst-kix_rf1gg3liws68-2{list-style-type:none}ul.lst-kix_rf1gg3liws68-1{list-style-type:none}ul.lst-kix_rf1gg3liws68-0{list-style-type:none}ol.lst-kix_52jgzw489fhs-8.start{counter-reset:lst-ctn-kix_52jgzw489fhs-8 0}.lst-kix_wsu1hpz6hqq4-3>li:before{content:"-  "}ul.lst-kix_rf1gg3liws68-8{list-style-type:none}.lst-kix_x12ed5cs6o9z-5>li:before{content:"-  "}.lst-kix_8nwtyhgsvjlm-0>li:before{content:"-  "}ul.lst-kix_of5ud22cn0qg-7{list-style-type:none}ul.lst-kix_p9ucdfdvxyzl-2{list-style-type:none}ul.lst-kix_of5ud22cn0qg-8{list-style-type:none}ul.lst-kix_p9ucdfdvxyzl-1{list-style-type:none}ul.lst-kix_p9ucdfdvxyzl-0{list-style-type:none}ul.lst-kix_of5ud22cn0qg-3{list-style-type:none}ul.lst-kix_of5ud22cn0qg-4{list-style-type:none}ul.lst-kix_of5ud22cn0qg-5{list-style-type:none}ul.lst-kix_of5ud22cn0qg-6{list-style-type:none}ol.lst-kix_vayf18aqt55o-2{list-style-type:none}ol.lst-kix_vayf18aqt55o-1{list-style-type:none}ol.lst-kix_vayf18aqt55o-4{list-style-type:none}ol.lst-kix_vayf18aqt55o-3{list-style-type:none}.lst-kix_fy701w8ywepa-4>li:before{content:"-  "}ol.lst-kix_vayf18aqt55o-0{list-style-type:none}ol.lst-kix_vayf18aqt55o-6{list-style-type:none}ol.lst-kix_vayf18aqt55o-5{list-style-type:none}ol.lst-kix_vayf18aqt55o-8{list-style-type:none}ol.lst-kix_vayf18aqt55o-7{list-style-type:none}.lst-kix_sr0z5k7b8i6u-7>li:before{content:"-  "}ul.lst-kix_rxgry66ibim8-6{list-style-type:none}ul.lst-kix_rxgry66ibim8-7{list-style-type:none}ul.lst-kix_rxgry66ibim8-8{list-style-type:none}.lst-kix_kp4gb6sd08f1-3>li:before{content:"-  "}ul.lst-kix_rxgry66ibim8-0{list-style-type:none}ul.lst-kix_rxgry66ibim8-1{list-style-type:none}ul.lst-kix_rxgry66ibim8-2{list-style-type:none}ul.lst-kix_rxgry66ibim8-3{list-style-type:none}ul.lst-kix_rxgry66ibim8-4{list-style-type:none}ul.lst-kix_rxgry66ibim8-5{list-style-type:none}.lst-kix_sr0z5k7b8i6u-1>li:before{content:"-  "}.lst-kix_p9ucdfdvxyzl-1>li:before{content:"-  "}.lst-kix_eh8nesljbkpv-2>li:before{content:"-  "}.lst-kix_lojd6plssn1-5>li:before{content:"-  "}.lst-kix_o4efc4ukggt5-1>li:before{content:"-  "}.lst-kix_eh8nesljbkpv-8>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-5>li:before{content:"(" counter(lst-ctn-kix_hppu19i8fr2p-5,lower-roman) ") "}.lst-kix_30wqf3y6rydr-6>li:before{content:"-  "}.lst-kix_e3u4u2bj7x9w-5>li:before{content:"-  "}.lst-kix_uwhnriglec8q-3>li:before{content:"-  "}.lst-kix_85vz7a3ggeai-1>li:before{content:"-  "}ul.lst-kix_wn0yiryrov3h-7{list-style-type:none}ul.lst-kix_wn0yiryrov3h-8{list-style-type:none}.lst-kix_l4d8unsm10a0-8>li:before{content:"-  "}ul.lst-kix_wn0yiryrov3h-3{list-style-type:none}ul.lst-kix_wn0yiryrov3h-4{list-style-type:none}ul.lst-kix_wn0yiryrov3h-5{list-style-type:none}ul.lst-kix_wn0yiryrov3h-6{list-style-type:none}.lst-kix_o4efc4ukggt5-7>li:before{content:"-  "}.lst-kix_xktbtduo53bq-0>li:before{content:"" counter(lst-ctn-kix_xktbtduo53bq-0,decimal) ". "}.lst-kix_sgiyubx3nkay-8>li:before{content:"-  "}.lst-kix_v9cryi9ybo1n-3>li:before{content:"\0025cf   "}.lst-kix_qw4x1ydun1ls-4>li:before{content:"\0025cb   "}.lst-kix_ysfu1bl0kymd-3>li{counter-increment:lst-ctn-kix_ysfu1bl0kymd-3}.lst-kix_3fc7x0lm2mmz-8>li:before{content:"" counter(lst-ctn-kix_3fc7x0lm2mmz-8,lower-roman) ". "}.lst-kix_ok1n37qarjzb-1>li{counter-increment:lst-ctn-kix_ok1n37qarjzb-1}.lst-kix_30wqf3y6rydr-0>li:before{content:"-  "}.lst-kix_85vz7a3ggeai-7>li:before{content:"-  "}.lst-kix_o328viitwjyp-3>li:before{content:"-  "}.lst-kix_sgiyubx3nkay-2>li:before{content:"-  "}ol.lst-kix_5djgwp8c9ig2-0{list-style-type:none}ul.lst-kix_hssoi9jbujv-3{list-style-type:none}ol.lst-kix_5djgwp8c9ig2-1{list-style-type:none}ul.lst-kix_hssoi9jbujv-4{list-style-type:none}ol.lst-kix_5djgwp8c9ig2-2{list-style-type:none}ul.lst-kix_hssoi9jbujv-5{list-style-type:none}.lst-kix_d94n7or3b41v-8>li:before{content:"-  "}ol.lst-kix_5djgwp8c9ig2-3{list-style-type:none}ul.lst-kix_hssoi9jbujv-6{list-style-type:none}ul.lst-kix_hssoi9jbujv-0{list-style-type:none}ul.lst-kix_hssoi9jbujv-1{list-style-type:none}ul.lst-kix_hssoi9jbujv-2{list-style-type:none}ol.lst-kix_5djgwp8c9ig2-8{list-style-type:none}ol.lst-kix_vgg0538grxk3-0.start{counter-reset:lst-ctn-kix_vgg0538grxk3-0 0}ol.lst-kix_5djgwp8c9ig2-4{list-style-type:none}ol.lst-kix_5djgwp8c9ig2-5{list-style-type:none}.lst-kix_dojezsyc3ti3-7>li:before{content:"-  "}ol.lst-kix_5djgwp8c9ig2-6{list-style-type:none}.lst-kix_m3u7mfewl2ow-5>li:before{content:"-  "}ol.lst-kix_5djgwp8c9ig2-7{list-style-type:none}.lst-kix_8hvuzyuchy3p-1>li:before{content:"-  "}ul.lst-kix_4ypcpsaj0q6h-1{list-style-type:none}.lst-kix_d94n7or3b41v-2>li:before{content:"-  "}ul.lst-kix_4ypcpsaj0q6h-0{list-style-type:none}ul.lst-kix_8f3g26d9wonp-1{list-style-type:none}ul.lst-kix_8f3g26d9wonp-0{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-7.start{counter-reset:lst-ctn-kix_azgj6sn0lxuj-7 0}.lst-kix_f4168mxvziu2-4>li:before{content:"-  "}ul.lst-kix_8f3g26d9wonp-3{list-style-type:none}ul.lst-kix_8f3g26d9wonp-2{list-style-type:none}ul.lst-kix_4ypcpsaj0q6h-7{list-style-type:none}ul.lst-kix_8f3g26d9wonp-5{list-style-type:none}ul.lst-kix_4ypcpsaj0q6h-6{list-style-type:none}ul.lst-kix_8f3g26d9wonp-4{list-style-type:none}.lst-kix_pv4jsz2h74wk-5>li:before{content:"-  "}ul.lst-kix_8f3g26d9wonp-7{list-style-type:none}ul.lst-kix_4ypcpsaj0q6h-8{list-style-type:none}ul.lst-kix_8f3g26d9wonp-6{list-style-type:none}ul.lst-kix_4ypcpsaj0q6h-3{list-style-type:none}ul.lst-kix_4ypcpsaj0q6h-2{list-style-type:none}ul.lst-kix_8f3g26d9wonp-8{list-style-type:none}ul.lst-kix_4ypcpsaj0q6h-5{list-style-type:none}ul.lst-kix_4ypcpsaj0q6h-4{list-style-type:none}ul.lst-kix_wn0yiryrov3h-0{list-style-type:none}ul.lst-kix_wn0yiryrov3h-1{list-style-type:none}ul.lst-kix_wn0yiryrov3h-2{list-style-type:none}ul.lst-kix_fy701w8ywepa-8{list-style-type:none}ul.lst-kix_fy701w8ywepa-7{list-style-type:none}ul.lst-kix_fy701w8ywepa-6{list-style-type:none}ul.lst-kix_fy701w8ywepa-5{list-style-type:none}.lst-kix_npanryo7f1m7-1>li:before{content:"-  "}ul.lst-kix_fy701w8ywepa-4{list-style-type:none}.lst-kix_84zf7o74c8s9-4>li:before{content:"(" counter(lst-ctn-kix_84zf7o74c8s9-4,lower-latin) ") "}ul.lst-kix_fy701w8ywepa-3{list-style-type:none}ul.lst-kix_fy701w8ywepa-2{list-style-type:none}ul.lst-kix_fy701w8ywepa-1{list-style-type:none}ol.lst-kix_84zf7o74c8s9-7.start{counter-reset:lst-ctn-kix_84zf7o74c8s9-7 0}ul.lst-kix_fy701w8ywepa-0{list-style-type:none}.lst-kix_2agzfikyhf8k-6>li:before{content:"-  "}.lst-kix_tfqdu2hgmdym-5>li:before{content:"-  "}ul.lst-kix_s0nbf6s2np44-8{list-style-type:none}ul.lst-kix_s0nbf6s2np44-7{list-style-type:none}.lst-kix_2agzfikyhf8k-0>li:before{content:"-  "}.lst-kix_ht80gp8jxjfs-2>li:before{content:"-  "}ul.lst-kix_s0nbf6s2np44-4{list-style-type:none}ul.lst-kix_s0nbf6s2np44-3{list-style-type:none}ul.lst-kix_s0nbf6s2np44-6{list-style-type:none}.lst-kix_rog9deufml3h-3>li:before{content:"-  "}ul.lst-kix_s0nbf6s2np44-5{list-style-type:none}ul.lst-kix_s0nbf6s2np44-0{list-style-type:none}.lst-kix_8hvuzyuchy3p-7>li:before{content:"-  "}ul.lst-kix_s0nbf6s2np44-2{list-style-type:none}ul.lst-kix_s0nbf6s2np44-1{list-style-type:none}.lst-kix_4uak8dkv6vr8-1>li:before{content:"-  "}.lst-kix_z6rr709h3fky-1>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-6>li{counter-increment:lst-ctn-kix_3mj3tp7kj9db-6}.lst-kix_awlaex77cpwh-6>li:before{content:"-  "}ul.lst-kix_6u6or33vx86s-3{list-style-type:none}ul.lst-kix_6u6or33vx86s-2{list-style-type:none}ul.lst-kix_6u6or33vx86s-1{list-style-type:none}ul.lst-kix_6u6or33vx86s-0{list-style-type:none}ul.lst-kix_6u6or33vx86s-7{list-style-type:none}ul.lst-kix_6u6or33vx86s-6{list-style-type:none}.lst-kix_z6rr709h3fky-7>li:before{content:"-  "}ul.lst-kix_6u6or33vx86s-5{list-style-type:none}ul.lst-kix_6u6or33vx86s-4{list-style-type:none}.lst-kix_wf1o55flzq55-1>li:before{content:"-  "}.lst-kix_38p7uzj3qds3-4>li:before{content:"-  "}.lst-kix_1epl36nedj4y-3>li:before{content:"-  "}.lst-kix_dojezsyc3ti3-1>li:before{content:"-  "}.lst-kix_v6dv769q7bq3-3>li:before{content:"-  "}.lst-kix_g02ta87c1sqh-6>li:before{content:"\0025cf   "}ul.lst-kix_hssoi9jbujv-7{list-style-type:none}.lst-kix_tvu7bmfefz32-4>li:before{content:"-  "}ul.lst-kix_hssoi9jbujv-8{list-style-type:none}.lst-kix_ctweb0b3a38f-0>li:before{content:"-  "}ol.lst-kix_84zf7o74c8s9-3.start{counter-reset:lst-ctn-kix_84zf7o74c8s9-3 0}.lst-kix_pxpm44v9ngyu-5>li:before{content:"-  "}ul.lst-kix_arcio13zm8ud-3{list-style-type:none}ul.lst-kix_arcio13zm8ud-4{list-style-type:none}ul.lst-kix_xdqzm25ye8fb-8{list-style-type:none}ul.lst-kix_arcio13zm8ud-5{list-style-type:none}ul.lst-kix_arcio13zm8ud-6{list-style-type:none}ul.lst-kix_xdqzm25ye8fb-6{list-style-type:none}ul.lst-kix_xdqzm25ye8fb-7{list-style-type:none}ul.lst-kix_arcio13zm8ud-0{list-style-type:none}ul.lst-kix_xdqzm25ye8fb-4{list-style-type:none}ul.lst-kix_arcio13zm8ud-1{list-style-type:none}ul.lst-kix_xdqzm25ye8fb-5{list-style-type:none}ul.lst-kix_arcio13zm8ud-2{list-style-type:none}ul.lst-kix_8ujam3zhcr3q-6{list-style-type:none}ul.lst-kix_xdqzm25ye8fb-2{list-style-type:none}.lst-kix_pejjsijavmae-2>li:before{content:"-  "}ul.lst-kix_8ujam3zhcr3q-7{list-style-type:none}ul.lst-kix_xdqzm25ye8fb-3{list-style-type:none}ul.lst-kix_8ujam3zhcr3q-4{list-style-type:none}ul.lst-kix_xdqzm25ye8fb-0{list-style-type:none}ul.lst-kix_8ujam3zhcr3q-5{list-style-type:none}ul.lst-kix_6u6or33vx86s-8{list-style-type:none}.lst-kix_yvohqcnu3146-7>li:before{content:"" counter(lst-ctn-kix_yvohqcnu3146-7,lower-latin) ". "}ul.lst-kix_xdqzm25ye8fb-1{list-style-type:none}ul.lst-kix_8ujam3zhcr3q-8{list-style-type:none}ul.lst-kix_8ujam3zhcr3q-2{list-style-type:none}ul.lst-kix_8ujam3zhcr3q-3{list-style-type:none}ul.lst-kix_8ujam3zhcr3q-0{list-style-type:none}ul.lst-kix_8ujam3zhcr3q-1{list-style-type:none}ul.lst-kix_tagzs2njqau3-5{list-style-type:none}.lst-kix_onvme58enb43-6>li:before{content:"-  "}ul.lst-kix_tagzs2njqau3-4{list-style-type:none}.lst-kix_vkdxjlf0kb6j-3>li:before{content:"" counter(lst-ctn-kix_vkdxjlf0kb6j-3,decimal) ". "}ul.lst-kix_tagzs2njqau3-7{list-style-type:none}.lst-kix_yk26x5gkc3g4-3>li:before{content:"-  "}ul.lst-kix_tagzs2njqau3-6{list-style-type:none}ul.lst-kix_tagzs2njqau3-1{list-style-type:none}ol.lst-kix_g8jgbze430sv-5.start{counter-reset:lst-ctn-kix_g8jgbze430sv-5 0}ul.lst-kix_tagzs2njqau3-0{list-style-type:none}ul.lst-kix_tagzs2njqau3-3{list-style-type:none}.lst-kix_r8azi25kh461-2>li:before{content:"\0025cf   "}ul.lst-kix_tagzs2njqau3-2{list-style-type:none}.lst-kix_g47hwi8ilj0t-1>li:before{content:"-  "}ol.lst-kix_52jgzw489fhs-0.start{counter-reset:lst-ctn-kix_52jgzw489fhs-0 0}.lst-kix_kzw7lb63578w-2>li:before{content:"-  "}.lst-kix_3novkjnl93sa-4>li:before{content:"-  "}.lst-kix_11d94ps4c7wj-2>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-4>li:before{content:"(" counter(lst-ctn-kix_ypd5gkkarijk-4,lower-roman) ") "}ul.lst-kix_tagzs2njqau3-8{list-style-type:none}.lst-kix_waivoqs1cu5x-2>li:before{content:"-  "}.lst-kix_mkfigeky21iv-8>li:before{content:"-  "}ul.lst-kix_fifu4bguh6qm-8{list-style-type:none}.lst-kix_fifu4bguh6qm-0>li:before{content:"-  "}ul.lst-kix_fifu4bguh6qm-7{list-style-type:none}ul.lst-kix_fifu4bguh6qm-6{list-style-type:none}ul.lst-kix_fifu4bguh6qm-5{list-style-type:none}ul.lst-kix_fifu4bguh6qm-4{list-style-type:none}.lst-kix_7cboi17aj4i3-6>li:before{content:"-  "}ul.lst-kix_fifu4bguh6qm-3{list-style-type:none}ul.lst-kix_fifu4bguh6qm-2{list-style-type:none}ul.lst-kix_fifu4bguh6qm-1{list-style-type:none}ul.lst-kix_fifu4bguh6qm-0{list-style-type:none}.lst-kix_vhhvekoaa9d4-8>li:before{content:"\0025a0   "}.lst-kix_uvjyeruqqfgv-2>li:before{content:"-  "}.lst-kix_gerk886qza0c-1>li:before{content:"-  "}.lst-kix_w3rscytwttbz-6>li:before{content:"-  "}.lst-kix_x2lkon80l30j-0>li:before{content:"-  "}.lst-kix_1kbilie4yf3o-5>li:before{content:"-  "}.lst-kix_mjig28how5ag-3>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-2>li{counter-increment:lst-ctn-kix_3fc7x0lm2mmz-2}.lst-kix_of5ud22cn0qg-7>li:before{content:"-  "}.lst-kix_rf1gg3liws68-2>li:before{content:"-  "}.lst-kix_q8c17lyf7k0c-5>li:before{content:"-  "}.lst-kix_4gff7g6tktju-8>li:before{content:"-  "}.lst-kix_aeppt4sbsnmp-6>li:before{content:"-  "}.lst-kix_xyra4e5ffsud-2>li:before{content:"" counter(lst-ctn-kix_xyra4e5ffsud-2,lower-roman) ". "}.lst-kix_73pnq2b8bo4n-5>li:before{content:"-  "}.lst-kix_3ez3vzcedsa0-3>li:before{content:"-  "}.lst-kix_14k5lhtsu41k-5>li:before{content:"-  "}ul.lst-kix_5u0542f2h2jt-5{list-style-type:none}ul.lst-kix_innl5fto9oyf-1{list-style-type:none}ul.lst-kix_5u0542f2h2jt-4{list-style-type:none}.lst-kix_r9gci84l54f7-0>li:before{content:"-  "}ul.lst-kix_innl5fto9oyf-2{list-style-type:none}ul.lst-kix_5u0542f2h2jt-3{list-style-type:none}ul.lst-kix_5u0542f2h2jt-2{list-style-type:none}ul.lst-kix_innl5fto9oyf-0{list-style-type:none}ul.lst-kix_5u0542f2h2jt-1{list-style-type:none}ul.lst-kix_innl5fto9oyf-5{list-style-type:none}ul.lst-kix_arcio13zm8ud-7{list-style-type:none}ul.lst-kix_5u0542f2h2jt-0{list-style-type:none}.lst-kix_5l84eporjaw3-3>li:before{content:"-  "}ul.lst-kix_innl5fto9oyf-6{list-style-type:none}ul.lst-kix_arcio13zm8ud-8{list-style-type:none}ul.lst-kix_innl5fto9oyf-3{list-style-type:none}.lst-kix_hyuyjld7ihkv-5>li:before{content:"-  "}ul.lst-kix_innl5fto9oyf-4{list-style-type:none}ul.lst-kix_innl5fto9oyf-7{list-style-type:none}ul.lst-kix_innl5fto9oyf-8{list-style-type:none}ul.lst-kix_5u0542f2h2jt-8{list-style-type:none}ul.lst-kix_5u0542f2h2jt-7{list-style-type:none}ul.lst-kix_5u0542f2h2jt-6{list-style-type:none}.lst-kix_ysfu1bl0kymd-4>li:before{content:"" counter(lst-ctn-kix_ysfu1bl0kymd-4,lower-latin) ". "}.lst-kix_28q7sqckfj19-3>li:before{content:"-  "}.lst-kix_eahcvjpxxqs-4>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-7>li{counter-increment:lst-ctn-kix_u8nobwiguyj1-7}.lst-kix_ykhoydml7pv3-1>li{counter-increment:lst-ctn-kix_ykhoydml7pv3-1}.lst-kix_sq25f4cnauod-3>li:before{content:"-  "}.lst-kix_fhtxrv3nkyi7-1>li:before{content:"-  "}.lst-kix_5djgwp8c9ig2-8>li:before{content:"" counter(lst-ctn-kix_5djgwp8c9ig2-8,lower-roman) ". "}.lst-kix_ny5e869gaylo-7>li:before{content:"-  "}.lst-kix_eh3u7tkoktop-6>li:before{content:"-  "}.lst-kix_69k4orytle42-5>li:before{content:"\0025a0   "}.lst-kix_xhhdon4tpeu0-0>li:before{content:"-  "}.lst-kix_9ys95s420x24-7>li:before{content:"-  "}.lst-kix_gboi4t2flod9-7>li:before{content:"-  "}.lst-kix_yob9gooqotb-0>li:before{content:"-  "}.lst-kix_267f3xfv5ddr-3>li:before{content:"" counter(lst-ctn-kix_267f3xfv5ddr-3,decimal) ". "}.lst-kix_549l9aqx2sdy-4>li:before{content:"-  "}.lst-kix_izios9u5ks4s-5>li:before{content:"-  "}.lst-kix_tekivzgenz72-4>li:before{content:"-  "}.lst-kix_x96zthrcdy1e-4>li:before{content:"-  "}.lst-kix_5ze5xofgghz2-1>li:before{content:"-  "}.lst-kix_q95o92il1jwg-0>li:before{content:"-  "}ol.lst-kix_3mj3tp7kj9db-3.start{counter-reset:lst-ctn-kix_3mj3tp7kj9db-3 0}.lst-kix_f9iqanr8ite6-8>li:before{content:"-  "}.lst-kix_axwe0nze7yft-0>li:before{content:"-  "}.lst-kix_oc7itsrfkmqv-8>li:before{content:"-  "}.lst-kix_wzt7symqmcfu-2>li:before{content:"-  "}ol.lst-kix_azgj6sn0lxuj-3.start{counter-reset:lst-ctn-kix_azgj6sn0lxuj-3 0}.lst-kix_t3rn73qejgkj-8>li:before{content:"" counter(lst-ctn-kix_t3rn73qejgkj-8,lower-roman) ". "}.lst-kix_6xh4bfg7mbxi-8>li:before{content:"-  "}ol.lst-kix_vgg0538grxk3-4.start{counter-reset:lst-ctn-kix_vgg0538grxk3-4 0}.lst-kix_q2mi4y6rc42i-1>li:before{content:"-  "}ol.lst-kix_2foc6u9lzfq4-6.start{counter-reset:lst-ctn-kix_2foc6u9lzfq4-6 0}.lst-kix_1tib71bbsugw-2>li:before{content:"-  "}.lst-kix_wn0yiryrov3h-4>li:before{content:"-  "}.lst-kix_g1rm1ujfok3h-2>li:before{content:"-  "}.lst-kix_d626gkjp4fou-2>li:before{content:"\0025a0   "}.lst-kix_pgnpvlxhai6o-7>li:before{content:"-  "}.lst-kix_3bnqwg68tpm3-6>li:before{content:"-  "}ul.lst-kix_iyje40sgs3ri-8{list-style-type:none}.lst-kix_spt2hfceke6p-3>li:before{content:"-  "}ul.lst-kix_iyje40sgs3ri-7{list-style-type:none}.lst-kix_194f2a56ajxk-7>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-1>li{counter-increment:lst-ctn-kix_sxixw4iqsgzx-1}ul.lst-kix_iyje40sgs3ri-0{list-style-type:none}ul.lst-kix_iyje40sgs3ri-2{list-style-type:none}.lst-kix_kxjfd2xlpmu-3>li:before{content:"-  "}.lst-kix_oqibhsqlyfou-8>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-6>li{counter-increment:lst-ctn-kix_ykhoydml7pv3-6}ul.lst-kix_iyje40sgs3ri-1{list-style-type:none}ul.lst-kix_iyje40sgs3ri-4{list-style-type:none}ul.lst-kix_iyje40sgs3ri-3{list-style-type:none}ul.lst-kix_iyje40sgs3ri-6{list-style-type:none}ul.lst-kix_iyje40sgs3ri-5{list-style-type:none}.lst-kix_m31se2npgu2r-7>li:before{content:"-  "}.lst-kix_194f2a56ajxk-1>li:before{content:"-  "}.lst-kix_90bg3luq5inv-2>li:before{content:"" counter(lst-ctn-kix_90bg3luq5inv-2,lower-roman) ") "}ol.lst-kix_ysfu1bl0kymd-1.start{counter-reset:lst-ctn-kix_ysfu1bl0kymd-1 0}.lst-kix_qsto019ofcm1-8>li:before{content:"-  "}ul.lst-kix_uvjyeruqqfgv-3{list-style-type:none}ul.lst-kix_uvjyeruqqfgv-2{list-style-type:none}ul.lst-kix_uvjyeruqqfgv-1{list-style-type:none}ul.lst-kix_uvjyeruqqfgv-0{list-style-type:none}.lst-kix_a9h81iclzrpy-6>li:before{content:"-  "}ul.lst-kix_uvjyeruqqfgv-8{list-style-type:none}ul.lst-kix_uvjyeruqqfgv-7{list-style-type:none}ul.lst-kix_uvjyeruqqfgv-6{list-style-type:none}ul.lst-kix_uvjyeruqqfgv-5{list-style-type:none}.lst-kix_luixtz7s7e5x-1>li:before{content:"-  "}ul.lst-kix_uvjyeruqqfgv-4{list-style-type:none}.lst-kix_cmm6cscyrjti-3>li:before{content:"-  "}.lst-kix_wz5gdx83jdla-1>li:before{content:"-  "}.lst-kix_wz5gdx83jdla-7>li:before{content:"-  "}.lst-kix_incqcf2p39ls-4>li{counter-increment:lst-ctn-kix_incqcf2p39ls-4}ul.lst-kix_67mv29rpwb23-4{list-style-type:none}ul.lst-kix_67mv29rpwb23-5{list-style-type:none}ul.lst-kix_67mv29rpwb23-2{list-style-type:none}ol.lst-kix_xyra4e5ffsud-0{list-style-type:none}ul.lst-kix_67mv29rpwb23-3{list-style-type:none}ul.lst-kix_67mv29rpwb23-0{list-style-type:none}ul.lst-kix_67mv29rpwb23-1{list-style-type:none}ol.lst-kix_xyra4e5ffsud-5{list-style-type:none}ol.lst-kix_xyra4e5ffsud-6{list-style-type:none}.lst-kix_y62sddnu24wd-3>li:before{content:"-  "}ol.lst-kix_xyra4e5ffsud-7{list-style-type:none}.lst-kix_rp6rf03vbelo-8>li:before{content:"-  "}ol.lst-kix_xyra4e5ffsud-8{list-style-type:none}ol.lst-kix_3mj3tp7kj9db-7.start{counter-reset:lst-ctn-kix_3mj3tp7kj9db-7 0}ol.lst-kix_xyra4e5ffsud-1{list-style-type:none}.lst-kix_i4nwb7g7qe41-6>li:before{content:"-  "}ol.lst-kix_xyra4e5ffsud-2{list-style-type:none}ol.lst-kix_xyra4e5ffsud-3{list-style-type:none}ol.lst-kix_xyra4e5ffsud-4{list-style-type:none}ul.lst-kix_4z9ptm6a4lke-0{list-style-type:none}ul.lst-kix_4z9ptm6a4lke-1{list-style-type:none}ul.lst-kix_4z9ptm6a4lke-2{list-style-type:none}ul.lst-kix_4z9ptm6a4lke-3{list-style-type:none}ul.lst-kix_4z9ptm6a4lke-4{list-style-type:none}ul.lst-kix_4z9ptm6a4lke-5{list-style-type:none}ul.lst-kix_4z9ptm6a4lke-6{list-style-type:none}ul.lst-kix_4z9ptm6a4lke-7{list-style-type:none}.lst-kix_yjf6dvvoob64-0>li{counter-increment:lst-ctn-kix_yjf6dvvoob64-0}.lst-kix_x424ckbm5jp1-8>li:before{content:"-  "}ul.lst-kix_4z9ptm6a4lke-8{list-style-type:none}ol.lst-kix_u8nobwiguyj1-5.start{counter-reset:lst-ctn-kix_u8nobwiguyj1-5 0}.lst-kix_fld6w0ks1f0p-0>li:before{content:"-  "}.lst-kix_yxvs6rw7mq1w-7>li:before{content:"-  "}.lst-kix_incqcf2p39ls-6>li:before{content:"" counter(lst-ctn-kix_incqcf2p39ls-6,decimal) ". "}.lst-kix_84zf7o74c8s9-3>li{counter-increment:lst-ctn-kix_84zf7o74c8s9-3}.lst-kix_a9h81iclzrpy-0>li:before{content:"-  "}.lst-kix_17yxihawuh4r-6>li:before{content:"-  "}.lst-kix_i7kvy3cw4vsq-4>li:before{content:"-  "}.lst-kix_vayf18aqt55o-3>li{counter-increment:lst-ctn-kix_vayf18aqt55o-3}.lst-kix_yxvs6rw7mq1w-1>li:before{content:"-  "}.lst-kix_tl77ogq6q7u-5>li:before{content:"-  "}.lst-kix_8drpzle0jo7q-5>li:before{content:"\0025a0   "}ul.lst-kix_67mv29rpwb23-8{list-style-type:none}.lst-kix_rxevvtxfoovc-3>li:before{content:"-  "}ul.lst-kix_67mv29rpwb23-6{list-style-type:none}ul.lst-kix_67mv29rpwb23-7{list-style-type:none}.lst-kix_3qppsihuuk4z-3>li:before{content:"-  "}ol.lst-kix_2foc6u9lzfq4-2.start{counter-reset:lst-ctn-kix_2foc6u9lzfq4-2 0}.lst-kix_r6uhbskcwxv5-0>li:before{content:"-  "}.lst-kix_4gff7g6tktju-2>li:before{content:"-  "}.lst-kix_8pn77unkg8hg-8>li:before{content:"-  "}.lst-kix_ikdz4hpyto9o-7>li:before{content:"-  "}.lst-kix_s9h4llxy1yy0-6>li:before{content:"-  "}.lst-kix_8f3g26d9wonp-4>li:before{content:"-  "}.lst-kix_bttl6bm2dx1a-4>li:before{content:"-  "}ul.lst-kix_zew29xx7bzz-1{list-style-type:none}ul.lst-kix_zew29xx7bzz-2{list-style-type:none}ul.lst-kix_zew29xx7bzz-0{list-style-type:none}.lst-kix_wrdk3q33keus-4>li:before{content:"-  "}ol.lst-kix_yvohqcnu3146-7.start{counter-reset:lst-ctn-kix_yvohqcnu3146-7 0}.lst-kix_awt45k7p90je-2>li:before{content:"-  "}ul.lst-kix_zew29xx7bzz-7{list-style-type:none}.lst-kix_r6uhbskcwxv5-6>li:before{content:"-  "}ul.lst-kix_zew29xx7bzz-8{list-style-type:none}ul.lst-kix_zew29xx7bzz-5{list-style-type:none}ul.lst-kix_zew29xx7bzz-6{list-style-type:none}ul.lst-kix_zew29xx7bzz-3{list-style-type:none}ul.lst-kix_zew29xx7bzz-4{list-style-type:none}.lst-kix_43bwriak8ne4-5>li:before{content:"-  "}ol.lst-kix_3fc7x0lm2mmz-8.start{counter-reset:lst-ctn-kix_3fc7x0lm2mmz-8 0}.lst-kix_tpw8rt3jm7dt-6>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-2>li:before{content:"" counter(lst-ctn-kix_yjf6dvvoob64-2,lower-roman) ". "}.lst-kix_azgj6sn0lxuj-3>li:before{content:"" counter(lst-ctn-kix_azgj6sn0lxuj-3,decimal) ". "}.lst-kix_fexdtgozkcsr-7>li:before{content:"-  "}.lst-kix_bb3pt2xtt0a5-6>li:before{content:"-  "}.lst-kix_bpsiys7g173w-4>li:before{content:"-  "}.lst-kix_7dqsuv1cdvcc-5>li:before{content:"-  "}.lst-kix_q8ex99of35ig-1>li:before{content:"-  "}.lst-kix_r9s6df60is49-0>li:before{content:"-  "}.lst-kix_g8jgbze430sv-0>li{counter-increment:lst-ctn-kix_g8jgbze430sv-0}.lst-kix_q8ex99of35ig-7>li:before{content:"-  "}.lst-kix_xs6xjhigrbe2-7>li:before{content:"-  "}.lst-kix_rxgry66ibim8-6>li:before{content:"-  "}.lst-kix_hrm7p8w30y7p-5>li:before{content:"-  "}.lst-kix_1xkx8gh1e8n7-1>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-8>li{counter-increment:lst-ctn-kix_ysfu1bl0kymd-8}.lst-kix_2ccdqvrbclt-0>li:before{content:"-  "}.lst-kix_oqibhsqlyfou-2>li:before{content:"-  "}.lst-kix_tpw8rt3jm7dt-0>li:before{content:"-  "}.lst-kix_3i5qlhg977l0-4>li:before{content:"-  "}.lst-kix_bv8sxewi94yp-8>li:before{content:"-  "}ul.lst-kix_fld6w0ks1f0p-7{list-style-type:none}ul.lst-kix_fld6w0ks1f0p-8{list-style-type:none}.lst-kix_q2mi4y6rc42i-7>li:before{content:"-  "}ul.lst-kix_fld6w0ks1f0p-3{list-style-type:none}ul.lst-kix_fld6w0ks1f0p-4{list-style-type:none}ul.lst-kix_fld6w0ks1f0p-5{list-style-type:none}ul.lst-kix_fld6w0ks1f0p-6{list-style-type:none}ul.lst-kix_fld6w0ks1f0p-0{list-style-type:none}.lst-kix_qzg09ck6gr7w-4>li:before{content:"-  "}ul.lst-kix_fld6w0ks1f0p-1{list-style-type:none}ul.lst-kix_fld6w0ks1f0p-2{list-style-type:none}.lst-kix_2foc6u9lzfq4-6>li{counter-increment:lst-ctn-kix_2foc6u9lzfq4-6}ol.lst-kix_vayf18aqt55o-1.start{counter-reset:lst-ctn-kix_vayf18aqt55o-1 0}.lst-kix_5stj9b6acoxv-6>li{counter-increment:lst-ctn-kix_5stj9b6acoxv-6}.lst-kix_5syfdd8x3l8s-2>li:before{content:"-  "}.lst-kix_nj8yy6k748x0-0>li:before{content:"-  "}.lst-kix_r8azi25kh461-8>li:before{content:"\0025cf   "}.lst-kix_mb1zrov3n6kx-4>li:before{content:"-  "}.lst-kix_g47hwi8ilj0t-7>li:before{content:"-  "}ul.lst-kix_onvme58enb43-3{list-style-type:none}ul.lst-kix_onvme58enb43-4{list-style-type:none}ul.lst-kix_onvme58enb43-5{list-style-type:none}.lst-kix_y32h08wggx1t-5>li:before{content:"-  "}ul.lst-kix_onvme58enb43-6{list-style-type:none}.lst-kix_kzw7lb63578w-8>li:before{content:"-  "}ul.lst-kix_onvme58enb43-7{list-style-type:none}.lst-kix_pejjsijavmae-8>li:before{content:"-  "}ul.lst-kix_onvme58enb43-8{list-style-type:none}.lst-kix_ok1n37qarjzb-1>li:before{content:"" counter(lst-ctn-kix_ok1n37qarjzb-1,lower-roman) ") "}.lst-kix_fmkfhvl8yhfs-6>li:before{content:"-  "}.lst-kix_x74x9xa8n5a0-3>li:before{content:"-  "}ul.lst-kix_onvme58enb43-0{list-style-type:none}.lst-kix_932mko8sjg0u-5>li:before{content:"-  "}.lst-kix_4uak8dkv6vr8-7>li:before{content:"-  "}ul.lst-kix_onvme58enb43-1{list-style-type:none}ul.lst-kix_onvme58enb43-2{list-style-type:none}.lst-kix_7o5enrj2ko1w-8>li:before{content:"-  "}.lst-kix_mkfigeky21iv-2>li:before{content:"-  "}.lst-kix_uvjyeruqqfgv-8>li:before{content:"-  "}ul.lst-kix_rt3ua1vpzay9-8{list-style-type:none}ul.lst-kix_rt3ua1vpzay9-4{list-style-type:none}.lst-kix_vkdxjlf0kb6j-4>li{counter-increment:lst-ctn-kix_vkdxjlf0kb6j-4}ul.lst-kix_rt3ua1vpzay9-5{list-style-type:none}ul.lst-kix_rt3ua1vpzay9-6{list-style-type:none}ul.lst-kix_rt3ua1vpzay9-7{list-style-type:none}ul.lst-kix_rt3ua1vpzay9-0{list-style-type:none}.lst-kix_nlsa7flowwa1-5>li:before{content:"+  "}ul.lst-kix_rt3ua1vpzay9-1{list-style-type:none}ul.lst-kix_rt3ua1vpzay9-2{list-style-type:none}.lst-kix_c7r1s55bmbei-0>li:before{content:"-  "}ul.lst-kix_rt3ua1vpzay9-3{list-style-type:none}.lst-kix_wnr3c516ni7j-5>li:before{content:"-  "}.lst-kix_j32gjnxzdkip-7>li:before{content:"-  "}.lst-kix_owvy3cstzf0s-2>li:before{content:"-  "}.lst-kix_waivoqs1cu5x-8>li:before{content:"-  "}.lst-kix_11d94ps4c7wj-8>li:before{content:"-  "}.lst-kix_tw1wz6pba43e-7>li:before{content:"-  "}.lst-kix_r9gci84l54f7-6>li:before{content:"-  "}.lst-kix_iyje40sgs3ri-5>li:before{content:"-  "}.lst-kix_22zpsclbl6ju-4>li:before{content:"-  "}.lst-kix_vhhvekoaa9d4-2>li:before{content:"\0025a0   "}.lst-kix_d1gy3hy5r3qj-3>li:before{content:"(" counter(lst-ctn-kix_d1gy3hy5r3qj-3,decimal) ") "}.lst-kix_ctweb0b3a38f-6>li:before{content:"-  "}.lst-kix_6vg5692ogph-1>li:before{content:"-  "}.lst-kix_d626gkjp4fou-8>li:before{content:"\0025a0   "}.lst-kix_np9h4y3kt4yk-1>li:before{content:"-  "}.lst-kix_fhtxrv3nkyi7-7>li:before{content:"-  "}ol.lst-kix_vayf18aqt55o-5.start{counter-reset:lst-ctn-kix_vayf18aqt55o-5 0}.lst-kix_jfoqdfq6uhww-4>li:before{content:"-  "}.lst-kix_35hvjwgc3k2f-7>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-6>li{counter-increment:lst-ctn-kix_d1gy3hy5r3qj-6}ul.lst-kix_4pjeuglo4z6v-1{list-style-type:none}ul.lst-kix_4pjeuglo4z6v-2{list-style-type:none}.lst-kix_9ys95s420x24-1>li:before{content:"-  "}ul.lst-kix_4pjeuglo4z6v-0{list-style-type:none}ul.lst-kix_4pjeuglo4z6v-5{list-style-type:none}.lst-kix_eh3u7tkoktop-0>li:before{content:"-  "}.lst-kix_23ct987xwu67-8>li{counter-increment:lst-ctn-kix_23ct987xwu67-8}ul.lst-kix_4pjeuglo4z6v-6{list-style-type:none}ul.lst-kix_4pjeuglo4z6v-3{list-style-type:none}ul.lst-kix_4pjeuglo4z6v-4{list-style-type:none}ul.lst-kix_4pjeuglo4z6v-7{list-style-type:none}ul.lst-kix_4pjeuglo4z6v-8{list-style-type:none}.lst-kix_o7acnutkhp1w-0>li:before{content:"-  "}.lst-kix_rt3ua1vpzay9-6>li:before{content:"-  "}.lst-kix_6m4qu83yomn7-5>li:before{content:"-  "}.lst-kix_yob9gooqotb-6>li:before{content:"-  "}.lst-kix_vgg0538grxk3-4>li:before{content:"(" counter(lst-ctn-kix_vgg0538grxk3-4,lower-latin) ") "}.lst-kix_xyra4e5ffsud-6>li{counter-increment:lst-ctn-kix_xyra4e5ffsud-6}.lst-kix_p2dhxl6hicde-8>li:before{content:"-  "}.lst-kix_gboi4t2flod9-1>li:before{content:"-  "}ul.lst-kix_1kbilie4yf3o-7{list-style-type:none}ul.lst-kix_1kbilie4yf3o-8{list-style-type:none}ul.lst-kix_1kbilie4yf3o-5{list-style-type:none}ul.lst-kix_1kbilie4yf3o-6{list-style-type:none}ul.lst-kix_1kbilie4yf3o-3{list-style-type:none}ul.lst-kix_1kbilie4yf3o-4{list-style-type:none}ul.lst-kix_1kbilie4yf3o-1{list-style-type:none}ul.lst-kix_1kbilie4yf3o-2{list-style-type:none}.lst-kix_ok1n37qarjzb-6>li{counter-increment:lst-ctn-kix_ok1n37qarjzb-6}ul.lst-kix_1kbilie4yf3o-0{list-style-type:none}.lst-kix_q95o92il1jwg-6>li:before{content:"-  "}ul.lst-kix_urqiwn6svi1d-0{list-style-type:none}ul.lst-kix_urqiwn6svi1d-1{list-style-type:none}ul.lst-kix_urqiwn6svi1d-2{list-style-type:none}ul.lst-kix_urqiwn6svi1d-3{list-style-type:none}ul.lst-kix_urqiwn6svi1d-4{list-style-type:none}ul.lst-kix_urqiwn6svi1d-5{list-style-type:none}ul.lst-kix_urqiwn6svi1d-6{list-style-type:none}ul.lst-kix_urqiwn6svi1d-7{list-style-type:none}ul.lst-kix_urqiwn6svi1d-8{list-style-type:none}.lst-kix_1tib71bbsugw-8>li:before{content:"-  "}.lst-kix_ny5e869gaylo-1>li:before{content:"-  "}.lst-kix_w97kncqyzxj3-1>li:before{content:"\0025cb   "}.lst-kix_o45gwpewsvxw-4>li:before{content:"-  "}.lst-kix_a2xq56ushw0p-7>li:before{content:"-  "}ul.lst-kix_lcru2cdgc87j-0{list-style-type:none}.lst-kix_5djgwp8c9ig2-2>li:before{content:"" counter(lst-ctn-kix_5djgwp8c9ig2-2,lower-roman) ". "}ul.lst-kix_lcru2cdgc87j-1{list-style-type:none}.lst-kix_t3rn73qejgkj-2>li:before{content:"" counter(lst-ctn-kix_t3rn73qejgkj-2,lower-roman) ") "}ul.lst-kix_lcru2cdgc87j-2{list-style-type:none}.lst-kix_ob04lr2u335p-3>li:before{content:"-  "}.lst-kix_cwjen7nun640-7>li:before{content:"-  "}.lst-kix_bswxvn1l22fp-7>li:before{content:"-  "}ul.lst-kix_lcru2cdgc87j-7{list-style-type:none}ul.lst-kix_lcru2cdgc87j-8{list-style-type:none}ul.lst-kix_lcru2cdgc87j-3{list-style-type:none}.lst-kix_o17eseb5cr8e-4>li:before{content:"-  "}.lst-kix_axwe0nze7yft-6>li:before{content:"-  "}ul.lst-kix_lcru2cdgc87j-4{list-style-type:none}ul.lst-kix_lcru2cdgc87j-5{list-style-type:none}ul.lst-kix_lcru2cdgc87j-6{list-style-type:none}ol.lst-kix_3fc7x0lm2mmz-0.start{counter-reset:lst-ctn-kix_3fc7x0lm2mmz-0 0}.lst-kix_gfc2v9r4qc22-8>li:before{content:"-  "}.lst-kix_bnte1i3g4kjh-7>li:before{content:"-  "}.lst-kix_1v1216yy0n25-1>li:before{content:"-  "}.lst-kix_ug10x97qcpi8-0>li:before{content:"-  "}.lst-kix_2r20t3tmnrwb-7>li:before{content:"-  "}.lst-kix_4i10vbfgn91y-0>li:before{content:"-  "}ul.lst-kix_d94n7or3b41v-0{list-style-type:none}.lst-kix_cwjen7nun640-1>li:before{content:"-  "}ul.lst-kix_d94n7or3b41v-1{list-style-type:none}ol.lst-kix_90bg3luq5inv-8.start{counter-reset:lst-ctn-kix_90bg3luq5inv-8 0}.lst-kix_w97kncqyzxj3-7>li:before{content:"\0025cb   "}.lst-kix_ofib0hkczw41-3>li:before{content:"-  "}.lst-kix_gfc2v9r4qc22-0>li:before{content:"-  "}.lst-kix_yrg2qlcqvak1-6>li:before{content:"-  "}.lst-kix_ug10x97qcpi8-8>li:before{content:"-  "}.lst-kix_7vr84ges94ry-3>li:before{content:"-  "}.lst-kix_g8jgbze430sv-7>li:before{content:"" counter(lst-ctn-kix_g8jgbze430sv-7,lower-latin) ". "}.lst-kix_dvvzixfw64a1-3>li:before{content:"-  "}ul.lst-kix_mjig28how5ag-5{list-style-type:none}ul.lst-kix_mjig28how5ag-6{list-style-type:none}.lst-kix_ul22dko4fd2j-6>li:before{content:"-  "}ul.lst-kix_mjig28how5ag-7{list-style-type:none}.lst-kix_hmvj5t8yy8bx-0>li:before{content:"+  "}ul.lst-kix_mjig28how5ag-8{list-style-type:none}.lst-kix_puc0azh4kjfq-0>li:before{content:"-  "}ul.lst-kix_mjig28how5ag-0{list-style-type:none}ul.lst-kix_mjig28how5ag-1{list-style-type:none}ul.lst-kix_mjig28how5ag-2{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-6.start{counter-reset:lst-ctn-kix_vkdxjlf0kb6j-6 0}ul.lst-kix_mjig28how5ag-3{list-style-type:none}ul.lst-kix_mjig28how5ag-4{list-style-type:none}.lst-kix_svg8hnl23b1r-5>li:before{content:"-  "}.lst-kix_n9q8wqas57a-6>li:before{content:"-  "}.lst-kix_4xiv877yc8jl-4>li:before{content:"-  "}.lst-kix_6o2cphkh2n8b-1>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-7>li{counter-increment:lst-ctn-kix_ysfu1bl0kymd-7}.lst-kix_qw2h6jd8xi17-7>li:before{content:"-  "}ul.lst-kix_mvektlca5c5q-7{list-style-type:none}ul.lst-kix_mvektlca5c5q-6{list-style-type:none}ul.lst-kix_mvektlca5c5q-8{list-style-type:none}.lst-kix_3nq914pozpi7-4>li:before{content:"-  "}ul.lst-kix_mvektlca5c5q-3{list-style-type:none}.lst-kix_co74fk70kphx-8>li:before{content:"-  "}ul.lst-kix_mvektlca5c5q-2{list-style-type:none}.lst-kix_tt1bo8z9re67-8>li:before{content:"-  "}ul.lst-kix_mvektlca5c5q-5{list-style-type:none}ul.lst-kix_mvektlca5c5q-4{list-style-type:none}.lst-kix_x8ffawrvrcyq-5>li:before{content:"\0025a0   "}.lst-kix_mh5zhf27i4rj-8>li:before{content:"-  "}.lst-kix_8ujam3zhcr3q-2>li:before{content:"-  "}ul.lst-kix_vdnr7e70vask-6{list-style-type:none}ol.lst-kix_d1gy3hy5r3qj-7{list-style-type:none}ul.lst-kix_vdnr7e70vask-5{list-style-type:none}ol.lst-kix_d1gy3hy5r3qj-8{list-style-type:none}ul.lst-kix_vdnr7e70vask-8{list-style-type:none}.lst-kix_aor1182clqbr-2>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-5{list-style-type:none}ul.lst-kix_vdnr7e70vask-7{list-style-type:none}ol.lst-kix_d1gy3hy5r3qj-6{list-style-type:none}.lst-kix_tt1bo8z9re67-0>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-0{list-style-type:none}ul.lst-kix_mvektlca5c5q-1{list-style-type:none}ul.lst-kix_mvektlca5c5q-0{list-style-type:none}ol.lst-kix_84zf7o74c8s9-5.start{counter-reset:lst-ctn-kix_84zf7o74c8s9-5 0}ol.lst-kix_d1gy3hy5r3qj-3{list-style-type:none}.lst-kix_eme1x4epzdye-3>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-4{list-style-type:none}ol.lst-kix_d1gy3hy5r3qj-1{list-style-type:none}ol.lst-kix_d1gy3hy5r3qj-2{list-style-type:none}.lst-kix_gaq1zvh4dcgb-7>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-1>li:before{content:"" counter(lst-ctn-kix_2foc6u9lzfq4-1,lower-latin) ". "}.lst-kix_gvlgpawofwi7-7>li:before{content:"-  "}ol.lst-kix_hppu19i8fr2p-4.start{counter-reset:lst-ctn-kix_hppu19i8fr2p-4 0}.lst-kix_hmvj5t8yy8bx-8>li:before{content:"+  "}.lst-kix_4i10vbfgn91y-8>li:before{content:"-  "}ul.lst-kix_upq3ni6ul8eb-0{list-style-type:none}.lst-kix_tdrf79x9zyr7-3>li:before{content:"-  "}.lst-kix_mv77cg19299c-7>li:before{content:"-  "}.lst-kix_4qbfcta6cclt-2>li:before{content:"-  "}.lst-kix_lwlxuymndfyq-5>li:before{content:"-  "}.lst-kix_jhofo94iol1-8>li:before{content:"-  "}ul.lst-kix_yrg2qlcqvak1-0{list-style-type:none}ul.lst-kix_yrg2qlcqvak1-1{list-style-type:none}ul.lst-kix_yrg2qlcqvak1-2{list-style-type:none}.lst-kix_qmx92jmkghx8-8>li:before{content:"-  "}.lst-kix_t3rn73qejgkj-8>li{counter-increment:lst-ctn-kix_t3rn73qejgkj-8}ul.lst-kix_upq3ni6ul8eb-3{list-style-type:none}ul.lst-kix_upq3ni6ul8eb-4{list-style-type:none}ul.lst-kix_upq3ni6ul8eb-1{list-style-type:none}.lst-kix_m5azvtuvtpt1-3>li:before{content:"-  "}ul.lst-kix_upq3ni6ul8eb-2{list-style-type:none}ul.lst-kix_upq3ni6ul8eb-7{list-style-type:none}ul.lst-kix_upq3ni6ul8eb-8{list-style-type:none}.lst-kix_o1voy78o4juz-8>li:before{content:"-  "}ul.lst-kix_upq3ni6ul8eb-5{list-style-type:none}.lst-kix_wwm574aidb8n-3>li:before{content:"-  "}ul.lst-kix_upq3ni6ul8eb-6{list-style-type:none}.lst-kix_52jgzw489fhs-3>li{counter-increment:lst-ctn-kix_52jgzw489fhs-3}.lst-kix_d7eif1vat32g-5>li:before{content:"-  "}.lst-kix_9a7xq1ie41tp-4>li:before{content:"-  "}.lst-kix_ekasiajyrrvz-6>li:before{content:"-  "}.lst-kix_x95t913s41kt-7>li:before{content:"-  "}.lst-kix_ukx3y28hag8h-6>li:before{content:"-  "}.lst-kix_mh5zhf27i4rj-0>li:before{content:"-  "}ol.lst-kix_yjf6dvvoob64-8.start{counter-reset:lst-ctn-kix_yjf6dvvoob64-8 0}.lst-kix_5nilpkhthb5t-2>li:before{content:"-  "}.lst-kix_jhofo94iol1-0>li:before{content:"-  "}.lst-kix_axy5kxvo2nx7-2>li:before{content:"-  "}.lst-kix_co74fk70kphx-0>li:before{content:"-  "}.lst-kix_q24qpifeknc3-3>li:before{content:"-  "}.lst-kix_x1xhkkpc69w2-4>li:before{content:"-  "}.lst-kix_njs8ubf1qesf-2>li:before{content:"-  "}.lst-kix_hngwf7orguk6-1>li:before{content:"-  "}ol.lst-kix_azgj6sn0lxuj-4{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-3{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-6{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-5{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-8{list-style-type:none}ul.lst-kix_g1rm1ujfok3h-0{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-7{list-style-type:none}ul.lst-kix_g1rm1ujfok3h-1{list-style-type:none}ul.lst-kix_g1rm1ujfok3h-2{list-style-type:none}ul.lst-kix_g1rm1ujfok3h-3{list-style-type:none}ul.lst-kix_g1rm1ujfok3h-4{list-style-type:none}ul.lst-kix_g1rm1ujfok3h-5{list-style-type:none}.lst-kix_hytfj9icha07-7>li:before{content:"-  "}ul.lst-kix_g1rm1ujfok3h-6{list-style-type:none}.lst-kix_ykhoydml7pv3-4>li{counter-increment:lst-ctn-kix_ykhoydml7pv3-4}ul.lst-kix_g1rm1ujfok3h-7{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-0{list-style-type:none}ul.lst-kix_g1rm1ujfok3h-8{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-2{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-1{list-style-type:none}ul.lst-kix_mtm8lwd6vxjl-0{list-style-type:none}.lst-kix_rcfi5jnwnxji-6>li:before{content:"-  "}ul.lst-kix_mtm8lwd6vxjl-1{list-style-type:none}ul.lst-kix_mtm8lwd6vxjl-4{list-style-type:none}ul.lst-kix_mtm8lwd6vxjl-5{list-style-type:none}ul.lst-kix_mtm8lwd6vxjl-2{list-style-type:none}ul.lst-kix_mtm8lwd6vxjl-3{list-style-type:none}ul.lst-kix_mtm8lwd6vxjl-8{list-style-type:none}ul.lst-kix_mtm8lwd6vxjl-6{list-style-type:none}ul.lst-kix_mtm8lwd6vxjl-7{list-style-type:none}.lst-kix_qmx92jmkghx8-0>li:before{content:"-  "}ul.lst-kix_d94n7or3b41v-2{list-style-type:none}ul.lst-kix_yrg2qlcqvak1-7{list-style-type:none}ul.lst-kix_d94n7or3b41v-3{list-style-type:none}.lst-kix_x12ed5cs6o9z-6>li:before{content:"-  "}ul.lst-kix_yrg2qlcqvak1-8{list-style-type:none}ul.lst-kix_d94n7or3b41v-4{list-style-type:none}.lst-kix_5stj9b6acoxv-6>li:before{content:"" counter(lst-ctn-kix_5stj9b6acoxv-6,decimal) ". "}ul.lst-kix_d94n7or3b41v-5{list-style-type:none}ul.lst-kix_d94n7or3b41v-6{list-style-type:none}ul.lst-kix_yrg2qlcqvak1-3{list-style-type:none}ul.lst-kix_d94n7or3b41v-7{list-style-type:none}ul.lst-kix_yrg2qlcqvak1-4{list-style-type:none}ul.lst-kix_d94n7or3b41v-8{list-style-type:none}ul.lst-kix_yrg2qlcqvak1-5{list-style-type:none}ul.lst-kix_yrg2qlcqvak1-6{list-style-type:none}ol.lst-kix_g8jgbze430sv-7.start{counter-reset:lst-ctn-kix_g8jgbze430sv-7 0}.lst-kix_ellvdfsu2z7q-6>li:before{content:"-  "}ul.lst-kix_l60gvbdij7aj-7{list-style-type:none}ul.lst-kix_l60gvbdij7aj-8{list-style-type:none}.lst-kix_dn04c4yafie0-8>li:before{content:"-  "}ul.lst-kix_l60gvbdij7aj-5{list-style-type:none}.lst-kix_3i5qlhg977l0-2>li:before{content:"-  "}ul.lst-kix_l60gvbdij7aj-6{list-style-type:none}ul.lst-kix_l60gvbdij7aj-3{list-style-type:none}ul.lst-kix_l60gvbdij7aj-4{list-style-type:none}ul.lst-kix_l60gvbdij7aj-1{list-style-type:none}ul.lst-kix_l60gvbdij7aj-2{list-style-type:none}ul.lst-kix_luixtz7s7e5x-7{list-style-type:none}.lst-kix_qccibyu36y2t-0>li:before{content:"-  "}ul.lst-kix_luixtz7s7e5x-6{list-style-type:none}ul.lst-kix_l60gvbdij7aj-0{list-style-type:none}.lst-kix_nj8yy6k748x0-5>li:before{content:"-  "}ul.lst-kix_luixtz7s7e5x-8{list-style-type:none}ul.lst-kix_8a5plp401pog-5{list-style-type:none}ul.lst-kix_8a5plp401pog-4{list-style-type:none}ul.lst-kix_luixtz7s7e5x-1{list-style-type:none}ul.lst-kix_8a5plp401pog-3{list-style-type:none}ul.lst-kix_luixtz7s7e5x-0{list-style-type:none}ul.lst-kix_8a5plp401pog-2{list-style-type:none}ul.lst-kix_luixtz7s7e5x-3{list-style-type:none}ul.lst-kix_8a5plp401pog-1{list-style-type:none}ul.lst-kix_luixtz7s7e5x-2{list-style-type:none}ul.lst-kix_8a5plp401pog-0{list-style-type:none}.lst-kix_qzg09ck6gr7w-6>li:before{content:"-  "}ul.lst-kix_luixtz7s7e5x-5{list-style-type:none}ul.lst-kix_luixtz7s7e5x-4{list-style-type:none}.lst-kix_bv8sxewi94yp-1>li:before{content:"-  "}.lst-kix_vie3q5oyli2z-4>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-4>li:before{content:"(" counter(lst-ctn-kix_ykhoydml7pv3-4,lower-latin) ") "}.lst-kix_y32h08wggx1t-3>li:before{content:"-  "}.lst-kix_fmkfhvl8yhfs-5>li:before{content:"-  "}.lst-kix_5argtotmwusw-7>li:before{content:"-  "}.lst-kix_8hf94791m5p0-8>li:before{content:"-  "}ul.lst-kix_8a5plp401pog-8{list-style-type:none}ul.lst-kix_8a5plp401pog-7{list-style-type:none}ul.lst-kix_8a5plp401pog-6{list-style-type:none}.lst-kix_dn04c4yafie0-0>li:before{content:"-  "}.lst-kix_cpgerodpupjz-5>li:before{content:"-  "}.lst-kix_ykhrv7u6blcs-7>li:before{content:"-  "}ul.lst-kix_rrloltks13s-7{list-style-type:none}ul.lst-kix_rrloltks13s-8{list-style-type:none}.lst-kix_7o5enrj2ko1w-1>li:before{content:"-  "}.lst-kix_jnfn9mx5o33t-5>li:before{content:"-  "}ul.lst-kix_rrloltks13s-3{list-style-type:none}ul.lst-kix_rrloltks13s-4{list-style-type:none}ul.lst-kix_rrloltks13s-5{list-style-type:none}ul.lst-kix_rrloltks13s-6{list-style-type:none}.lst-kix_c7r1s55bmbei-1>li:before{content:"-  "}ul.lst-kix_rrloltks13s-0{list-style-type:none}ul.lst-kix_rrloltks13s-1{list-style-type:none}.lst-kix_df6s37r8voak-7>li:before{content:"-  "}ul.lst-kix_rrloltks13s-2{list-style-type:none}.lst-kix_owvy3cstzf0s-4>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-6>li:before{content:"" counter(lst-ctn-kix_u8nobwiguyj1-6,decimal) ". "}.lst-kix_cd2o0cncsajm-1>li:before{content:"-  "}.lst-kix_fs1lzw38maxl-5>li:before{content:"-  "}.lst-kix_932mko8sjg0u-3>li:before{content:"-  "}.lst-kix_22zpsclbl6ju-1>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-3>li:before{content:"(" counter(lst-ctn-kix_ok1n37qarjzb-3,lower-latin) ") "}.lst-kix_fm53cr9wmch0-2>li:before{content:"-  "}.lst-kix_35hvjwgc3k2f-1>li:before{content:"-  "}.lst-kix_qccibyu36y2t-8>li:before{content:"-  "}.lst-kix_t9t3ckq2i2hz-5>li:before{content:"-  "}ul.lst-kix_rop4yg7lbfg8-1{list-style-type:none}ul.lst-kix_rop4yg7lbfg8-0{list-style-type:none}ul.lst-kix_rop4yg7lbfg8-3{list-style-type:none}ul.lst-kix_rop4yg7lbfg8-2{list-style-type:none}ul.lst-kix_rop4yg7lbfg8-5{list-style-type:none}.lst-kix_6nc1nfac2wub-6>li:before{content:"-  "}ul.lst-kix_rop4yg7lbfg8-4{list-style-type:none}.lst-kix_j32gjnxzdkip-1>li:before{content:"-  "}ul.lst-kix_rop4yg7lbfg8-7{list-style-type:none}ul.lst-kix_rop4yg7lbfg8-6{list-style-type:none}.lst-kix_9z31rmzc855z-3>li:before{content:"-  "}.lst-kix_qb494lue4ahb-8>li:before{content:"-  "}ul.lst-kix_ld6rwbdri49-8{list-style-type:none}.lst-kix_8w7txqc6xq66-2>li:before{content:"-  "}.lst-kix_jfoqdfq6uhww-6>li:before{content:"-  "}ul.lst-kix_rop4yg7lbfg8-8{list-style-type:none}.lst-kix_6pgojrjbxqei-2>li:before{content:"\0025a0   "}.lst-kix_oswsfzrgbvyb-3>li:before{content:"-  "}.lst-kix_ld6rwbdri49-6>li:before{content:"-  "}.lst-kix_qb494lue4ahb-0>li:before{content:"-  "}.lst-kix_iupg79bv69ia-4>li:before{content:"-  "}.lst-kix_hkt83gwcgrvq-7>li:before{content:"-  "}.lst-kix_qij6192l4p0g-8>li:before{content:"-  "}.lst-kix_kobinbwr4qr6-3>li:before{content:"-  "}ul.lst-kix_ld6rwbdri49-1{list-style-type:none}ul.lst-kix_ld6rwbdri49-0{list-style-type:none}ul.lst-kix_ld6rwbdri49-3{list-style-type:none}.lst-kix_tjrvr4c0ezjq-8>li:before{content:"-  "}ul.lst-kix_ld6rwbdri49-2{list-style-type:none}.lst-kix_xx6ude5yqnkl-0>li:before{content:"  "}.lst-kix_5stj9b6acoxv-0>li{counter-increment:lst-ctn-kix_5stj9b6acoxv-0}ul.lst-kix_ld6rwbdri49-5{list-style-type:none}ul.lst-kix_ld6rwbdri49-4{list-style-type:none}.lst-kix_t6x6ie377r4u-3>li:before{content:"-  "}ul.lst-kix_ld6rwbdri49-7{list-style-type:none}ol.lst-kix_azgj6sn0lxuj-4.start{counter-reset:lst-ctn-kix_azgj6sn0lxuj-4 0}.lst-kix_8euewcidoez8-4>li:before{content:"-  "}ul.lst-kix_ld6rwbdri49-6{list-style-type:none}.lst-kix_8f3g26d9wonp-7>li:before{content:"-  "}.lst-kix_s9h4llxy1yy0-3>li:before{content:"-  "}.lst-kix_qij6192l4p0g-0>li:before{content:"-  "}.lst-kix_tc7vpn5ce0ra-4>li:before{content:"-  "}.lst-kix_vayf18aqt55o-2>li:before{content:"" counter(lst-ctn-kix_vayf18aqt55o-2,decimal) ") "}.lst-kix_6m4qu83yomn7-3>li:before{content:"-  "}.lst-kix_xx6ude5yqnkl-8>li:before{content:"\0025a0   "}.lst-kix_i4nwb7g7qe41-4>li:before{content:"-  "}.lst-kix_rt3ua1vpzay9-4>li:before{content:"-  "}.lst-kix_6u6or33vx86s-2>li:before{content:"-  "}.lst-kix_yhq927c05ak0-5>li:before{content:"-  "}.lst-kix_x6hb6vgwujyx-6>li:before{content:"-  "}.lst-kix_om0x63wgf9wd-2>li:before{content:"-  "}.lst-kix_yvohqcnu3146-2>li{counter-increment:lst-ctn-kix_yvohqcnu3146-2}.lst-kix_fexdtgozkcsr-8>li:before{content:"-  "}.lst-kix_xdqzm25ye8fb-4>li:before{content:"-  "}.lst-kix_6ltb10qoez57-5>li:before{content:"\0025a0   "}.lst-kix_8hf94791m5p0-0>li:before{content:"-  "}.lst-kix_puc0azh4kjfq-8>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-3>li{counter-increment:lst-ctn-kix_azgj6sn0lxuj-3}.lst-kix_7e64bsb5krip-1>li:before{content:"-  "}.lst-kix_fexdtgozkcsr-0>li:before{content:"-  "}.lst-kix_c73c2x77meqo-5>li:before{content:"-  "}ul.lst-kix_x8ffawrvrcyq-2{list-style-type:none}ul.lst-kix_izios9u5ks4s-0{list-style-type:none}ul.lst-kix_x8ffawrvrcyq-3{list-style-type:none}ul.lst-kix_x8ffawrvrcyq-4{list-style-type:none}ul.lst-kix_x8ffawrvrcyq-5{list-style-type:none}ul.lst-kix_izios9u5ks4s-3{list-style-type:none}ul.lst-kix_qmx92jmkghx8-7{list-style-type:none}ul.lst-kix_izios9u5ks4s-4{list-style-type:none}ul.lst-kix_qmx92jmkghx8-8{list-style-type:none}ul.lst-kix_izios9u5ks4s-1{list-style-type:none}ul.lst-kix_qmx92jmkghx8-5{list-style-type:none}.lst-kix_st0egafmkg0z-2>li:before{content:"-  "}ul.lst-kix_x8ffawrvrcyq-0{list-style-type:none}ul.lst-kix_izios9u5ks4s-2{list-style-type:none}ul.lst-kix_qmx92jmkghx8-6{list-style-type:none}ul.lst-kix_x8ffawrvrcyq-1{list-style-type:none}ul.lst-kix_izios9u5ks4s-7{list-style-type:none}.lst-kix_j60wooaeanf9-3>li:before{content:"-  "}ul.lst-kix_qmx92jmkghx8-3{list-style-type:none}ul.lst-kix_izios9u5ks4s-8{list-style-type:none}ul.lst-kix_qmx92jmkghx8-4{list-style-type:none}ul.lst-kix_izios9u5ks4s-5{list-style-type:none}ul.lst-kix_qmx92jmkghx8-1{list-style-type:none}ul.lst-kix_izios9u5ks4s-6{list-style-type:none}ul.lst-kix_qmx92jmkghx8-2{list-style-type:none}ul.lst-kix_x8ffawrvrcyq-6{list-style-type:none}ul.lst-kix_qmx92jmkghx8-0{list-style-type:none}.lst-kix_qmryaqe19okh-2>li:before{content:"-  "}ul.lst-kix_x8ffawrvrcyq-7{list-style-type:none}ul.lst-kix_x8ffawrvrcyq-8{list-style-type:none}.lst-kix_xktbtduo53bq-5>li{counter-increment:lst-ctn-kix_xktbtduo53bq-5}.lst-kix_tjrvr4c0ezjq-0>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-2>li{counter-increment:lst-ctn-kix_hppu19i8fr2p-2}.lst-kix_hsahb38tz2f5-4>li:before{content:"-  "}.lst-kix_ksf6p4xm2w0d-3>li:before{content:"-  "}ol.lst-kix_ykhoydml7pv3-2.start{counter-reset:lst-ctn-kix_ykhoydml7pv3-2 0}ul.lst-kix_f2t507a7xjue-0{list-style-type:none}ul.lst-kix_f2t507a7xjue-2{list-style-type:none}ul.lst-kix_f2t507a7xjue-1{list-style-type:none}.lst-kix_spt2hfceke6p-6>li:before{content:"-  "}ul.lst-kix_f2t507a7xjue-4{list-style-type:none}ul.lst-kix_f2t507a7xjue-3{list-style-type:none}ul.lst-kix_cwjen7nun640-7{list-style-type:none}ul.lst-kix_f2t507a7xjue-6{list-style-type:none}ul.lst-kix_cwjen7nun640-6{list-style-type:none}ul.lst-kix_f2t507a7xjue-5{list-style-type:none}ul.lst-kix_f2t507a7xjue-8{list-style-type:none}ul.lst-kix_cwjen7nun640-8{list-style-type:none}ul.lst-kix_f2t507a7xjue-7{list-style-type:none}ul.lst-kix_cwjen7nun640-1{list-style-type:none}.lst-kix_3mj3tp7kj9db-4>li{counter-increment:lst-ctn-kix_3mj3tp7kj9db-4}ul.lst-kix_cwjen7nun640-0{list-style-type:none}ul.lst-kix_cwjen7nun640-3{list-style-type:none}ul.lst-kix_cwjen7nun640-2{list-style-type:none}ul.lst-kix_cwjen7nun640-5{list-style-type:none}ul.lst-kix_cwjen7nun640-4{list-style-type:none}.lst-kix_xyra4e5ffsud-0>li{counter-increment:lst-ctn-kix_xyra4e5ffsud-0}.lst-kix_ozbrn4vmjez8-7>li:before{content:"-  "}.lst-kix_cmm6cscyrjti-2>li:before{content:"-  "}ul.lst-kix_rog9deufml3h-5{list-style-type:none}ul.lst-kix_rog9deufml3h-4{list-style-type:none}.lst-kix_dmn3lqzfmokk-6>li:before{content:"-  "}ul.lst-kix_rog9deufml3h-7{list-style-type:none}.lst-kix_w21i9d12ynhg-4>li:before{content:"-  "}ul.lst-kix_rog9deufml3h-6{list-style-type:none}.lst-kix_rxevvtxfoovc-8>li:before{content:"-  "}ul.lst-kix_rog9deufml3h-8{list-style-type:none}.lst-kix_23ct987xwu67-6>li{counter-increment:lst-ctn-kix_23ct987xwu67-6}ul.lst-kix_rog9deufml3h-1{list-style-type:none}.lst-kix_zjjx8lb18sy-4>li:before{content:"-  "}ul.lst-kix_rog9deufml3h-0{list-style-type:none}ul.lst-kix_rog9deufml3h-3{list-style-type:none}ul.lst-kix_rog9deufml3h-2{list-style-type:none}.lst-kix_y62sddnu24wd-7>li:before{content:"-  "}.lst-kix_kt8k33f35qi5-5>li:before{content:"-  "}.lst-kix_x424ckbm5jp1-7>li:before{content:"-  "}.lst-kix_fld6w0ks1f0p-1>li:before{content:"-  "}.lst-kix_a9h81iclzrpy-5>li:before{content:"-  "}.lst-kix_lcru2cdgc87j-0>li:before{content:"-  "}.lst-kix_yxvs6rw7mq1w-8>li:before{content:"-  "}.lst-kix_i7kvy3cw4vsq-2>li:before{content:"-  "}.lst-kix_17yxihawuh4r-5>li:before{content:"-  "}.lst-kix_skgpgvhmuoc4-5>li:before{content:"-  "}.lst-kix_e73zm9q3mvin-6>li:before{content:"-  "}.lst-kix_8a5plp401pog-7>li:before{content:"-  "}ul.lst-kix_85vz7a3ggeai-3{list-style-type:none}ul.lst-kix_7dqsuv1cdvcc-8{list-style-type:none}ul.lst-kix_85vz7a3ggeai-2{list-style-type:none}ul.lst-kix_7dqsuv1cdvcc-7{list-style-type:none}ul.lst-kix_85vz7a3ggeai-1{list-style-type:none}ul.lst-kix_7dqsuv1cdvcc-6{list-style-type:none}.lst-kix_lcru2cdgc87j-8>li:before{content:"-  "}ul.lst-kix_85vz7a3ggeai-0{list-style-type:none}ul.lst-kix_7dqsuv1cdvcc-5{list-style-type:none}.lst-kix_rxevvtxfoovc-0>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-3.start{counter-reset:lst-ctn-kix_ok1n37qarjzb-3 0}.lst-kix_yxvs6rw7mq1w-0>li:before{content:"-  "}ul.lst-kix_7dqsuv1cdvcc-0{list-style-type:none}.lst-kix_f9iu0trsjas1-3>li:before{content:"-  "}.lst-kix_vvjhovkzyen7-5>li:before{content:"-  "}ul.lst-kix_85vz7a3ggeai-8{list-style-type:none}ul.lst-kix_85vz7a3ggeai-7{list-style-type:none}ul.lst-kix_7dqsuv1cdvcc-4{list-style-type:none}ul.lst-kix_85vz7a3ggeai-6{list-style-type:none}ul.lst-kix_7dqsuv1cdvcc-3{list-style-type:none}ul.lst-kix_85vz7a3ggeai-5{list-style-type:none}ul.lst-kix_7dqsuv1cdvcc-2{list-style-type:none}.lst-kix_r8adx85jg0iz-2>li:before{content:"-  "}ul.lst-kix_85vz7a3ggeai-4{list-style-type:none}ul.lst-kix_7dqsuv1cdvcc-1{list-style-type:none}.lst-kix_dln561wj05xo-7>li:before{content:"-  "}.lst-kix_3qppsihuuk4z-5>li:before{content:"-  "}.lst-kix_7vvt5hs6rdl-3>li:before{content:"-  "}ul.lst-kix_svg8hnl23b1r-8{list-style-type:none}ul.lst-kix_svg8hnl23b1r-7{list-style-type:none}ul.lst-kix_svg8hnl23b1r-6{list-style-type:none}ul.lst-kix_svg8hnl23b1r-5{list-style-type:none}ul.lst-kix_svg8hnl23b1r-4{list-style-type:none}ul.lst-kix_svg8hnl23b1r-3{list-style-type:none}ul.lst-kix_svg8hnl23b1r-2{list-style-type:none}ul.lst-kix_svg8hnl23b1r-1{list-style-type:none}ul.lst-kix_svg8hnl23b1r-0{list-style-type:none}.lst-kix_xs6xjhigrbe2-1>li:before{content:"-  "}.lst-kix_xhhdon4tpeu0-1>li:before{content:"-  "}.lst-kix_2ei6b6e4ow80-8>li:before{content:"-  "}.lst-kix_wrdk3q33keus-0>li:before{content:"-  "}.lst-kix_wsu1hpz6hqq4-8>li:before{content:"-  "}.lst-kix_iffqre5r12zx-0>li:before{content:"-  "}.lst-kix_ivmzvkm69gsd-1>li:before{content:"-  "}.lst-kix_eiskzjj27gc6-7>li:before{content:"-  "}.lst-kix_ugixx4nd67zw-3>li:before{content:"-  "}.lst-kix_tagzs2njqau3-0>li:before{content:"-  "}.lst-kix_gboi4t2flod9-8>li:before{content:"-  "}.lst-kix_f9iqanr8ite6-5>li:before{content:"-  "}.lst-kix_2ei6b6e4ow80-0>li:before{content:"-  "}.lst-kix_iffqre5r12zx-8>li:before{content:"-  "}.lst-kix_gboi4t2flod9-0>li:before{content:"-  "}ul.lst-kix_f9iqanr8ite6-8{list-style-type:none}.lst-kix_267f3xfv5ddr-0>li:before{content:"" counter(lst-ctn-kix_267f3xfv5ddr-0,decimal) ". "}ul.lst-kix_f9iqanr8ite6-7{list-style-type:none}ul.lst-kix_2nm562bzmwr-7{list-style-type:none}.lst-kix_epyrmry7301m-4>li:before{content:"-  "}ul.lst-kix_2nm562bzmwr-8{list-style-type:none}ul.lst-kix_2nm562bzmwr-5{list-style-type:none}ul.lst-kix_2nm562bzmwr-6{list-style-type:none}ul.lst-kix_2nm562bzmwr-3{list-style-type:none}ul.lst-kix_2nm562bzmwr-4{list-style-type:none}.lst-kix_wrdk3q33keus-8>li:before{content:"-  "}ul.lst-kix_2nm562bzmwr-1{list-style-type:none}ul.lst-kix_2nm562bzmwr-2{list-style-type:none}ul.lst-kix_f9iqanr8ite6-6{list-style-type:none}ul.lst-kix_2nm562bzmwr-0{list-style-type:none}ul.lst-kix_f9iqanr8ite6-5{list-style-type:none}.lst-kix_bpsiys7g173w-0>li:before{content:"-  "}ul.lst-kix_f9iqanr8ite6-4{list-style-type:none}ul.lst-kix_f9iqanr8ite6-3{list-style-type:none}.lst-kix_n0rv3zxivae3-5>li:before{content:"-  "}ul.lst-kix_f9iqanr8ite6-2{list-style-type:none}.lst-kix_5ze5xofgghz2-2>li:before{content:"-  "}ul.lst-kix_f9iqanr8ite6-1{list-style-type:none}ul.lst-kix_f9iqanr8ite6-0{list-style-type:none}.lst-kix_a42anijqpp8a-4>li:before{content:"-  "}.lst-kix_7dqsuv1cdvcc-7>li:before{content:"-  "}.lst-kix_r9s6df60is49-6>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-1.start{counter-reset:lst-ctn-kix_d1gy3hy5r3qj-1 0}.lst-kix_wsu1hpz6hqq4-0>li:before{content:"-  "}.lst-kix_267f3xfv5ddr-8>li:before{content:"" counter(lst-ctn-kix_267f3xfv5ddr-8,lower-roman) ". "}.lst-kix_bpsiys7g173w-8>li:before{content:"-  "}.lst-kix_ctweb0b3a38f-2>li:before{content:"-  "}.lst-kix_4ii5776egvw8-8>li:before{content:"-  "}.lst-kix_23ct987xwu67-3>li{counter-increment:lst-ctn-kix_23ct987xwu67-3}.lst-kix_mtm8lwd6vxjl-5>li:before{content:"-  "}.lst-kix_g47hwi8ilj0t-6>li:before{content:"-  "}.lst-kix_4ii5776egvw8-0>li:before{content:"-  "}.lst-kix_onvme58enb43-3>li:before{content:"-  "}.lst-kix_4voxeic75vm5-3>li:before{content:"-  "}.lst-kix_mb1zrov3n6kx-0>li:before{content:"-  "}ul.lst-kix_ozbrn4vmjez8-5{list-style-type:none}ul.lst-kix_ozbrn4vmjez8-4{list-style-type:none}ul.lst-kix_ozbrn4vmjez8-7{list-style-type:none}ul.lst-kix_ozbrn4vmjez8-6{list-style-type:none}ul.lst-kix_ozbrn4vmjez8-1{list-style-type:none}ul.lst-kix_ozbrn4vmjez8-0{list-style-type:none}ul.lst-kix_ozbrn4vmjez8-3{list-style-type:none}ul.lst-kix_ozbrn4vmjez8-2{list-style-type:none}ul.lst-kix_ozbrn4vmjez8-8{list-style-type:none}.lst-kix_1x319pprarxc-2>li:before{content:"-  "}.lst-kix_gerk886qza0c-7>li:before{content:"-  "}.lst-kix_ltm9vv1op5tt-0>li:before{content:"-  "}.lst-kix_r9gci84l54f7-7>li:before{content:"-  "}.lst-kix_n9qabngdxy64-1>li:before{content:"-  "}.lst-kix_w32pgwk3f0lb-1>li:before{content:"-  "}.lst-kix_81v91kbrmywy-6>li:before{content:"-  "}.lst-kix_waivoqs1cu5x-7>li:before{content:"-  "}.lst-kix_uvjyeruqqfgv-1>li:before{content:"-  "}.lst-kix_6vg5692ogph-5>li:before{content:"-  "}.lst-kix_ltm9vv1op5tt-8>li:before{content:"-  "}.lst-kix_7cboi17aj4i3-5>li:before{content:"-  "}.lst-kix_8w03xjt2k9bc-3>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-7>li{counter-increment:lst-ctn-kix_3mj3tp7kj9db-7}.lst-kix_ro388iryhhf5-0>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-5.start{counter-reset:lst-ctn-kix_incqcf2p39ls-5 0}.lst-kix_mjig28how5ag-1>li:before{content:"-  "}.lst-kix_23ct987xwu67-6>li:before{content:"" counter(lst-ctn-kix_23ct987xwu67-6,decimal) ". "}.lst-kix_tagzs2njqau3-8>li:before{content:"-  "}.lst-kix_cg6jep1fmawj-1>li:before{content:"-  "}.lst-kix_voj7evacrpie-5>li:before{content:"-  "}.lst-kix_4ypcpsaj0q6h-4>li:before{content:"-  "}.lst-kix_ro388iryhhf5-8>li:before{content:"-  "}.lst-kix_hyuyjld7ihkv-3>li:before{content:"-  "}.lst-kix_np9h4y3kt4yk-5>li:before{content:"-  "}ul.lst-kix_np9h4y3kt4yk-8{list-style-type:none}ul.lst-kix_np9h4y3kt4yk-7{list-style-type:none}ul.lst-kix_np9h4y3kt4yk-6{list-style-type:none}ul.lst-kix_np9h4y3kt4yk-5{list-style-type:none}ul.lst-kix_np9h4y3kt4yk-4{list-style-type:none}ul.lst-kix_np9h4y3kt4yk-3{list-style-type:none}ul.lst-kix_np9h4y3kt4yk-2{list-style-type:none}.lst-kix_jvmsa1jxmzig-3>li:before{content:"\0025cf   "}.lst-kix_d94n7or3b41v-3>li:before{content:"-  "}ul.lst-kix_np9h4y3kt4yk-1{list-style-type:none}.lst-kix_ssze0kg2kz13-4>li:before{content:"-  "}.lst-kix_9hby2lis2y9u-8>li:before{content:"-  "}.lst-kix_8pn77unkg8hg-7>li:before{content:"-  "}.lst-kix_5jp9wppv00ra-4>li:before{content:"-  "}ul.lst-kix_iefjrs8t42tr-8{list-style-type:none}.lst-kix_py2swxy3gr0i-4>li:before{content:"-  "}.lst-kix_6217r3mhjywx-3>li:before{content:"-  "}.lst-kix_7vaamq35f1cc-6>li:before{content:"-  "}ul.lst-kix_q95o92il1jwg-0{list-style-type:none}.lst-kix_69k4orytle42-7>li:before{content:"\0025cb   "}ul.lst-kix_q95o92il1jwg-1{list-style-type:none}ul.lst-kix_q95o92il1jwg-4{list-style-type:none}ul.lst-kix_np9h4y3kt4yk-0{list-style-type:none}ul.lst-kix_q95o92il1jwg-5{list-style-type:none}ul.lst-kix_vdnr7e70vask-0{list-style-type:none}ul.lst-kix_q95o92il1jwg-2{list-style-type:none}ul.lst-kix_q95o92il1jwg-3{list-style-type:none}ul.lst-kix_vdnr7e70vask-2{list-style-type:none}ul.lst-kix_q95o92il1jwg-8{list-style-type:none}ul.lst-kix_vdnr7e70vask-1{list-style-type:none}ul.lst-kix_vdnr7e70vask-4{list-style-type:none}ul.lst-kix_q95o92il1jwg-6{list-style-type:none}ul.lst-kix_vdnr7e70vask-3{list-style-type:none}ul.lst-kix_q95o92il1jwg-7{list-style-type:none}.lst-kix_l60gvbdij7aj-0>li:before{content:"-  "}.lst-kix_i8kfgvsh0fwy-4>li:before{content:"-  "}.lst-kix_9hby2lis2y9u-0>li:before{content:"-  "}.lst-kix_52jgzw489fhs-8>li:before{content:"" counter(lst-ctn-kix_52jgzw489fhs-8,lower-roman) ". "}.lst-kix_o7acnutkhp1w-4>li:before{content:"-  "}ul.lst-kix_q24qpifeknc3-8{list-style-type:none}.lst-kix_p2dhxl6hicde-4>li:before{content:"-  "}.lst-kix_oxgbebk5l98i-7>li:before{content:"-  "}ul.lst-kix_q24qpifeknc3-0{list-style-type:none}ul.lst-kix_q24qpifeknc3-1{list-style-type:none}ul.lst-kix_q24qpifeknc3-2{list-style-type:none}ul.lst-kix_q24qpifeknc3-3{list-style-type:none}ul.lst-kix_q24qpifeknc3-4{list-style-type:none}.lst-kix_alhag51wggig-5>li:before{content:"-  "}ul.lst-kix_q24qpifeknc3-5{list-style-type:none}ul.lst-kix_q24qpifeknc3-6{list-style-type:none}ul.lst-kix_q24qpifeknc3-7{list-style-type:none}.lst-kix_l5iaj94ondn3-4>li:before{content:"-  "}.lst-kix_52jgzw489fhs-0>li:before{content:"" counter(lst-ctn-kix_52jgzw489fhs-0,decimal) ". "}.lst-kix_upq3ni6ul8eb-7>li:before{content:"-  "}.lst-kix_84zf7o74c8s9-2>li{counter-increment:lst-ctn-kix_84zf7o74c8s9-2}ul.lst-kix_iefjrs8t42tr-5{list-style-type:none}ul.lst-kix_iefjrs8t42tr-4{list-style-type:none}ul.lst-kix_iefjrs8t42tr-7{list-style-type:none}ul.lst-kix_iefjrs8t42tr-6{list-style-type:none}ul.lst-kix_iefjrs8t42tr-1{list-style-type:none}ul.lst-kix_iefjrs8t42tr-0{list-style-type:none}.lst-kix_l60gvbdij7aj-8>li:before{content:"-  "}ul.lst-kix_iefjrs8t42tr-3{list-style-type:none}ul.lst-kix_iefjrs8t42tr-2{list-style-type:none}.lst-kix_mb1zrov3n6kx-8>li:before{content:"-  "}.lst-kix_v0hsa7m5lywt-3>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-1>li{counter-increment:lst-ctn-kix_d1gy3hy5r3qj-1}.lst-kix_aikphwux0ki0-4>li:before{content:"-  "}.lst-kix_q7gxc7al9t7n-5>li:before{content:"-  "}.lst-kix_o4efc4ukggt5-5>li:before{content:"-  "}ul.lst-kix_7cboi17aj4i3-1{list-style-type:none}.lst-kix_incqcf2p39ls-6>li{counter-increment:lst-ctn-kix_incqcf2p39ls-6}ul.lst-kix_7cboi17aj4i3-0{list-style-type:none}ul.lst-kix_7cboi17aj4i3-3{list-style-type:none}.lst-kix_zew29xx7bzz-6>li:before{content:"-  "}.lst-kix_sxznwwyc44x6-8>li:before{content:"-  "}ul.lst-kix_7cboi17aj4i3-2{list-style-type:none}ul.lst-kix_7cboi17aj4i3-5{list-style-type:none}ul.lst-kix_7cboi17aj4i3-4{list-style-type:none}ul.lst-kix_7cboi17aj4i3-7{list-style-type:none}ul.lst-kix_7cboi17aj4i3-6{list-style-type:none}.lst-kix_52jgzw489fhs-0>li{counter-increment:lst-ctn-kix_52jgzw489fhs-0}.lst-kix_sr0z5k7b8i6u-0>li:before{content:"-  "}.lst-kix_lojd6plssn1-2>li:before{content:"-  "}ul.lst-kix_7cboi17aj4i3-8{list-style-type:none}.lst-kix_zew29xx7bzz-3>li:before{content:"-  "}.lst-kix_o4efc4ukggt5-0>li:before{content:"-  "}.lst-kix_vdnr7e70vask-2>li:before{content:"\0025a0   "}.lst-kix_q7gxc7al9t7n-8>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-1>li:before{content:"" counter(lst-ctn-kix_hppu19i8fr2p-1,lower-latin) ") "}.lst-kix_uwhnriglec8q-8>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-1>li:before{content:"" counter(lst-ctn-kix_sxixw4iqsgzx-1,lower-latin) ". "}.lst-kix_qw4x1ydun1ls-5>li:before{content:"\0025a0   "}.lst-kix_6217r3mhjywx-0>li:before{content:"-  "}.lst-kix_e3u4u2bj7x9w-0>li:before{content:"-  "}.lst-kix_d94n7or3b41v-0>li:before{content:"-  "}.lst-kix_sgiyubx3nkay-0>li:before{content:"-  "}.lst-kix_o328viitwjyp-2>li:before{content:"-  "}.lst-kix_xktbtduo53bq-6>li:before{content:"" counter(lst-ctn-kix_xktbtduo53bq-6,decimal) ". "}.lst-kix_qw4x1ydun1ls-8>li:before{content:"\0025a0   "}.lst-kix_fy701w8ywepa-2>li:before{content:"-  "}.lst-kix_xktbtduo53bq-3>li:before{content:"" counter(lst-ctn-kix_xktbtduo53bq-3,decimal) ". "}.lst-kix_30wqf3y6rydr-1>li:before{content:"-  "}ol.lst-kix_5stj9b6acoxv-1.start{counter-reset:lst-ctn-kix_5stj9b6acoxv-1 0}.lst-kix_hc732m8hksyq-1>li:before{content:"-  "}ol.lst-kix_xyra4e5ffsud-0.start{counter-reset:lst-ctn-kix_xyra4e5ffsud-0 0}.lst-kix_28q7sqckfj19-4>li:before{content:"-  "}.lst-kix_m3u7mfewl2ow-1>li:before{content:"-  "}ul.lst-kix_w32pgwk3f0lb-0{list-style-type:none}.lst-kix_pv4jsz2h74wk-1>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-1>li{counter-increment:lst-ctn-kix_yjf6dvvoob64-1}ul.lst-kix_w32pgwk3f0lb-1{list-style-type:none}ul.lst-kix_w32pgwk3f0lb-2{list-style-type:none}ul.lst-kix_w32pgwk3f0lb-3{list-style-type:none}ul.lst-kix_w32pgwk3f0lb-4{list-style-type:none}ul.lst-kix_w32pgwk3f0lb-5{list-style-type:none}.lst-kix_2agzfikyhf8k-8>li:before{content:"-  "}ul.lst-kix_w32pgwk3f0lb-6{list-style-type:none}ul.lst-kix_w32pgwk3f0lb-7{list-style-type:none}ul.lst-kix_w32pgwk3f0lb-8{list-style-type:none}.lst-kix_ht80gp8jxjfs-8>li:before{content:"-  "}.lst-kix_rog9deufml3h-5>li:before{content:"-  "}.lst-kix_yob9gooqotb-5>li:before{content:"-  "}.lst-kix_9ys95s420x24-6>li:before{content:"-  "}.lst-kix_g02ta87c1sqh-4>li:before{content:"\0025cb   "}.lst-kix_1pt1eqcq4ieh-1>li:before{content:"-  "}.lst-kix_3novkjnl93sa-0>li:before{content:"-  "}.lst-kix_brqn5pq4e7i7-4>li:before{content:"-  "}.lst-kix_7gk9ayd44tft-8>li:before{content:"-  "}ul.lst-kix_vuz55xpe5xjl-8{list-style-type:none}ul.lst-kix_vuz55xpe5xjl-6{list-style-type:none}ul.lst-kix_vuz55xpe5xjl-7{list-style-type:none}ul.lst-kix_vuz55xpe5xjl-4{list-style-type:none}ul.lst-kix_i4nwb7g7qe41-8{list-style-type:none}ul.lst-kix_vuz55xpe5xjl-5{list-style-type:none}ul.lst-kix_i4nwb7g7qe41-7{list-style-type:none}ul.lst-kix_vuz55xpe5xjl-2{list-style-type:none}ul.lst-kix_vuz55xpe5xjl-3{list-style-type:none}ul.lst-kix_vuz55xpe5xjl-0{list-style-type:none}ul.lst-kix_vuz55xpe5xjl-1{list-style-type:none}.lst-kix_v6dv769q7bq3-1>li:before{content:"-  "}.lst-kix_wf1o55flzq55-3>li:before{content:"-  "}.lst-kix_xktbtduo53bq-8>li{counter-increment:lst-ctn-kix_xktbtduo53bq-8}.lst-kix_hppu19i8fr2p-5>li{counter-increment:lst-ctn-kix_hppu19i8fr2p-5}ul.lst-kix_i4nwb7g7qe41-4{list-style-type:none}ul.lst-kix_i4nwb7g7qe41-3{list-style-type:none}ul.lst-kix_i4nwb7g7qe41-6{list-style-type:none}ol.lst-kix_ykhoydml7pv3-3.start{counter-reset:lst-ctn-kix_ykhoydml7pv3-3 0}ul.lst-kix_i4nwb7g7qe41-5{list-style-type:none}ul.lst-kix_i4nwb7g7qe41-0{list-style-type:none}.lst-kix_g1rm1ujfok3h-1>li:before{content:"-  "}ul.lst-kix_i4nwb7g7qe41-2{list-style-type:none}ul.lst-kix_i4nwb7g7qe41-1{list-style-type:none}.lst-kix_q2mi4y6rc42i-8>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-0>li{counter-increment:lst-ctn-kix_azgj6sn0lxuj-0}.lst-kix_g8jgbze430sv-2>li{counter-increment:lst-ctn-kix_g8jgbze430sv-2}.lst-kix_q2mi4y6rc42i-5>li:before{content:"-  "}ul.lst-kix_t9t3ckq2i2hz-0{list-style-type:none}.lst-kix_8wvqr5f1zg2m-1>li:before{content:"-  "}.lst-kix_ob04lr2u335p-8>li:before{content:"-  "}ul.lst-kix_t9t3ckq2i2hz-7{list-style-type:none}.lst-kix_bnvwt1y8k7b-7>li:before{content:"-  "}ul.lst-kix_t9t3ckq2i2hz-8{list-style-type:none}ul.lst-kix_t9t3ckq2i2hz-5{list-style-type:none}ul.lst-kix_t9t3ckq2i2hz-6{list-style-type:none}ul.lst-kix_t9t3ckq2i2hz-3{list-style-type:none}ul.lst-kix_t9t3ckq2i2hz-4{list-style-type:none}ul.lst-kix_t9t3ckq2i2hz-1{list-style-type:none}ul.lst-kix_t9t3ckq2i2hz-2{list-style-type:none}.lst-kix_2nm562bzmwr-5>li:before{content:"-  "}.lst-kix_p1rtf0e14360-0>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-8>li:before{content:"" counter(lst-ctn-kix_ypd5gkkarijk-8,decimal) ". "}.lst-kix_hssoi9jbujv-5>li:before{content:"-  "}ul.lst-kix_ikdz4hpyto9o-0{list-style-type:none}ul.lst-kix_ikdz4hpyto9o-2{list-style-type:none}ul.lst-kix_ikdz4hpyto9o-1{list-style-type:none}.lst-kix_dyq7vlcdkqm5-2>li:before{content:"-  "}.lst-kix_67mv29rpwb23-4>li:before{content:"-  "}.lst-kix_11d94ps4c7wj-3>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-2>li{counter-increment:lst-ctn-kix_sxixw4iqsgzx-2}ul.lst-kix_ikdz4hpyto9o-8{list-style-type:none}.lst-kix_4uak8dkv6vr8-2>li:before{content:"-  "}.lst-kix_pejjsijavmae-6>li:before{content:"-  "}ul.lst-kix_ikdz4hpyto9o-7{list-style-type:none}.lst-kix_oc7itsrfkmqv-0>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-5>li:before{content:"(" counter(lst-ctn-kix_ypd5gkkarijk-5,decimal) ") "}.lst-kix_yk26x5gkc3g4-7>li:before{content:"-  "}ul.lst-kix_ikdz4hpyto9o-4{list-style-type:none}ul.lst-kix_ikdz4hpyto9o-3{list-style-type:none}ul.lst-kix_ikdz4hpyto9o-6{list-style-type:none}ul.lst-kix_ikdz4hpyto9o-5{list-style-type:none}.lst-kix_67mv29rpwb23-1>li:before{content:"-  "}.lst-kix_urqiwn6svi1d-4>li:before{content:"-  "}.lst-kix_nlsa7flowwa1-0>li:before{content:"+  "}.lst-kix_of5ud22cn0qg-2>li:before{content:"-  "}.lst-kix_1kbilie4yf3o-6>li:before{content:"-  "}.lst-kix_wfyz8rmi0iq4-3>li:before{content:"-  "}.lst-kix_uvjyeruqqfgv-6>li:before{content:"-  "}.lst-kix_mkfigeky21iv-7>li:before{content:"-  "}.lst-kix_q8c17lyf7k0c-6>li:before{content:"-  "}.lst-kix_iyje40sgs3ri-6>li:before{content:"-  "}.lst-kix_aeppt4sbsnmp-1>li:before{content:"-  "}.lst-kix_rf1gg3liws68-7>li:before{content:"-  "}.lst-kix_x2lkon80l30j-5>li:before{content:"-  "}.lst-kix_iyje40sgs3ri-3>li:before{content:"-  "}.lst-kix_73pnq2b8bo4n-6>li:before{content:"-  "}.lst-kix_2nm562bzmwr-8>li:before{content:"-  "}.lst-kix_vuz55xpe5xjl-5>li:before{content:"-  "}.lst-kix_5l84eporjaw3-7>li:before{content:"-  "}.lst-kix_3ez3vzcedsa0-8>li:before{content:"-  "}ol.lst-kix_ykhoydml7pv3-7{list-style-type:none}ol.lst-kix_ykhoydml7pv3-6{list-style-type:none}.lst-kix_p02ob1bzv6e4-2>li:before{content:"-  "}ol.lst-kix_ykhoydml7pv3-8{list-style-type:none}ol.lst-kix_ykhoydml7pv3-1{list-style-type:none}ol.lst-kix_ykhoydml7pv3-0{list-style-type:none}ol.lst-kix_ykhoydml7pv3-3{list-style-type:none}ol.lst-kix_ykhoydml7pv3-2{list-style-type:none}ol.lst-kix_ykhoydml7pv3-5{list-style-type:none}ol.lst-kix_ykhoydml7pv3-4{list-style-type:none}ul.lst-kix_tekivzgenz72-3{list-style-type:none}ul.lst-kix_tekivzgenz72-4{list-style-type:none}ul.lst-kix_tekivzgenz72-1{list-style-type:none}ul.lst-kix_tekivzgenz72-2{list-style-type:none}.lst-kix_ikdz4hpyto9o-8>li:before{content:"-  "}ul.lst-kix_tekivzgenz72-7{list-style-type:none}.lst-kix_ysfu1bl0kymd-0>li:before{content:"" counter(lst-ctn-kix_ysfu1bl0kymd-0,decimal) ". "}.lst-kix_4gff7g6tktju-1>li:before{content:"-  "}ul.lst-kix_tekivzgenz72-8{list-style-type:none}ul.lst-kix_tekivzgenz72-5{list-style-type:none}ul.lst-kix_tekivzgenz72-6{list-style-type:none}.lst-kix_eh3u7tkoktop-2>li:before{content:"-  "}ul.lst-kix_bv8sxewi94yp-0{list-style-type:none}.lst-kix_mq980hprr5hl-3>li:before{content:"-  "}.lst-kix_hc732m8hksyq-4>li:before{content:"-  "}ul.lst-kix_tekivzgenz72-0{list-style-type:none}.lst-kix_dmxresnhzo8y-1>li:before{content:"-  "}ul.lst-kix_bv8sxewi94yp-6{list-style-type:none}ul.lst-kix_bv8sxewi94yp-5{list-style-type:none}ul.lst-kix_bv8sxewi94yp-8{list-style-type:none}ul.lst-kix_bv8sxewi94yp-7{list-style-type:none}ul.lst-kix_bv8sxewi94yp-2{list-style-type:none}ul.lst-kix_bv8sxewi94yp-1{list-style-type:none}ul.lst-kix_bv8sxewi94yp-4{list-style-type:none}ul.lst-kix_bv8sxewi94yp-3{list-style-type:none}.lst-kix_6n4varno3bjs-4>li:before{content:"-  "}.lst-kix_tlnfkrylyq1a-1>li:before{content:"-  "}.lst-kix_yob9gooqotb-8>li:before{content:"-  "}.lst-kix_wrdk3q33keus-5>li:before{content:"-  "}.lst-kix_3qppsihuuk4z-8>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-4>li{counter-increment:lst-ctn-kix_3fc7x0lm2mmz-4}ul.lst-kix_x2lkon80l30j-4{list-style-type:none}.lst-kix_549l9aqx2sdy-8>li:before{content:"-  "}ul.lst-kix_x2lkon80l30j-5{list-style-type:none}ul.lst-kix_x2lkon80l30j-6{list-style-type:none}ul.lst-kix_x2lkon80l30j-7{list-style-type:none}ul.lst-kix_x2lkon80l30j-0{list-style-type:none}ul.lst-kix_x2lkon80l30j-1{list-style-type:none}ul.lst-kix_x2lkon80l30j-2{list-style-type:none}.lst-kix_7gk9ayd44tft-5>li:before{content:"-  "}ul.lst-kix_x2lkon80l30j-3{list-style-type:none}.lst-kix_g02ta87c1sqh-1>li:before{content:"\0025cb   "}ul.lst-kix_x2lkon80l30j-8{list-style-type:none}.lst-kix_gboi4t2flod9-3>li:before{content:"-  "}.lst-kix_izios9u5ks4s-1>li:before{content:"-  "}ol.lst-kix_ysfu1bl0kymd-6{list-style-type:none}ol.lst-kix_ysfu1bl0kymd-7{list-style-type:none}ol.lst-kix_ysfu1bl0kymd-4{list-style-type:none}.lst-kix_hssoi9jbujv-2>li:before{content:"-  "}ol.lst-kix_ysfu1bl0kymd-5{list-style-type:none}.lst-kix_5u0542f2h2jt-0>li:before{content:"+  "}ol.lst-kix_ysfu1bl0kymd-8{list-style-type:none}ul.lst-kix_yxvs6rw7mq1w-7{list-style-type:none}ul.lst-kix_yxvs6rw7mq1w-8{list-style-type:none}ol.lst-kix_ysfu1bl0kymd-2{list-style-type:none}ol.lst-kix_ysfu1bl0kymd-3{list-style-type:none}ol.lst-kix_ysfu1bl0kymd-0{list-style-type:none}ol.lst-kix_ysfu1bl0kymd-1{list-style-type:none}ul.lst-kix_yxvs6rw7mq1w-0{list-style-type:none}.lst-kix_x96zthrcdy1e-8>li:before{content:"-  "}ul.lst-kix_yxvs6rw7mq1w-1{list-style-type:none}ul.lst-kix_yxvs6rw7mq1w-2{list-style-type:none}ul.lst-kix_yxvs6rw7mq1w-3{list-style-type:none}.lst-kix_5djgwp8c9ig2-4>li:before{content:"" counter(lst-ctn-kix_5djgwp8c9ig2-4,lower-latin) ". "}ul.lst-kix_yxvs6rw7mq1w-4{list-style-type:none}.lst-kix_ob04lr2u335p-5>li:before{content:"-  "}ul.lst-kix_yxvs6rw7mq1w-5{list-style-type:none}ul.lst-kix_yxvs6rw7mq1w-6{list-style-type:none}.lst-kix_axwe0nze7yft-4>li:before{content:"-  "}.lst-kix_tpw8rt3jm7dt-1>li:before{content:"-  "}.lst-kix_o45gwpewsvxw-2>li:before{content:"-  "}.lst-kix_1epl36nedj4y-2>li:before{content:"-  "}.lst-kix_b7rulpv7obgl-3>li:before{content:"-  "}.lst-kix_qsto019ofcm1-3>li:before{content:"-  "}.lst-kix_qsto019ofcm1-0>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-1>li{counter-increment:lst-ctn-kix_3fc7x0lm2mmz-1}.lst-kix_hrm7p8w30y7p-0>li:before{content:"-  "}.lst-kix_g9hblcm1l6tk-6>li:before{content:"-  "}.lst-kix_qvomcnyqz8ao-5>li:before{content:"-  "}.lst-kix_qvomcnyqz8ao-8>li:before{content:"-  "}.lst-kix_s0nbf6s2np44-2>li:before{content:"-  "}.lst-kix_a9h81iclzrpy-8>li:before{content:"-  "}ul.lst-kix_p11gr83hik0e-8{list-style-type:none}.lst-kix_s0nbf6s2np44-5>li:before{content:"-  "}ul.lst-kix_p11gr83hik0e-2{list-style-type:none}ul.lst-kix_p11gr83hik0e-3{list-style-type:none}ul.lst-kix_p11gr83hik0e-0{list-style-type:none}ul.lst-kix_p11gr83hik0e-1{list-style-type:none}ul.lst-kix_p11gr83hik0e-6{list-style-type:none}ul.lst-kix_p11gr83hik0e-7{list-style-type:none}ul.lst-kix_p11gr83hik0e-4{list-style-type:none}ul.lst-kix_p11gr83hik0e-5{list-style-type:none}.lst-kix_2xixyk6jteti-8>li:before{content:"-  "}.lst-kix_nqtgcebhe8ii-1>li:before{content:"-  "}.lst-kix_rp6rf03vbelo-3>li:before{content:"-  "}ul.lst-kix_fnlxcectz7fi-0{list-style-type:none}.lst-kix_g0lr2dxtnslc-0>li:before{content:"-  "}ul.lst-kix_fnlxcectz7fi-1{list-style-type:none}.lst-kix_x1n4jlo0gf1q-4>li:before{content:"-  "}.lst-kix_f9iqanr8ite6-0>li:before{content:"-  "}ul.lst-kix_fnlxcectz7fi-6{list-style-type:none}ul.lst-kix_fnlxcectz7fi-7{list-style-type:none}.lst-kix_4pjeuglo4z6v-2>li:before{content:"-  "}ul.lst-kix_fnlxcectz7fi-8{list-style-type:none}.lst-kix_rp6rf03vbelo-6>li:before{content:"-  "}ul.lst-kix_fnlxcectz7fi-2{list-style-type:none}.lst-kix_nipj94pw11x6-5>li:before{content:"-  "}ul.lst-kix_fnlxcectz7fi-3{list-style-type:none}.lst-kix_ce3ho29dhteb-2>li:before{content:"-  "}ul.lst-kix_fnlxcectz7fi-4{list-style-type:none}ul.lst-kix_fnlxcectz7fi-5{list-style-type:none}.lst-kix_4pjeuglo4z6v-5>li:before{content:"-  "}.lst-kix_h25uruhpfzux-1>li:before{content:"-  "}.lst-kix_x1n4jlo0gf1q-1>li:before{content:"-  "}.lst-kix_3koi1cw13a0-6>li:before{content:"-  "}.lst-kix_nipj94pw11x6-8>li:before{content:"-  "}.lst-kix_8a5plp401pog-2>li:before{content:"-  "}.lst-kix_ms6rbzn59hmq-6>li:before{content:"-  "}.lst-kix_bsvmcpoa86br-4>li:before{content:"-  "}ol.lst-kix_90bg3luq5inv-7.start{counter-reset:lst-ctn-kix_90bg3luq5inv-7 0}.lst-kix_3koi1cw13a0-3>li:before{content:"-  "}ol.lst-kix_5stj9b6acoxv-0{list-style-type:none}.lst-kix_m31se2npgu2r-2>li:before{content:"-  "}.lst-kix_luixtz7s7e5x-6>li:before{content:"-  "}ol.lst-kix_5stj9b6acoxv-4{list-style-type:none}ol.lst-kix_vkdxjlf0kb6j-5.start{counter-reset:lst-ctn-kix_vkdxjlf0kb6j-5 0}ol.lst-kix_5stj9b6acoxv-3{list-style-type:none}ol.lst-kix_5stj9b6acoxv-2{list-style-type:none}ol.lst-kix_5stj9b6acoxv-1{list-style-type:none}ul.lst-kix_wwm574aidb8n-0{list-style-type:none}ol.lst-kix_5stj9b6acoxv-8{list-style-type:none}ul.lst-kix_wwm574aidb8n-1{list-style-type:none}ol.lst-kix_5stj9b6acoxv-7{list-style-type:none}ul.lst-kix_wwm574aidb8n-2{list-style-type:none}ol.lst-kix_5stj9b6acoxv-6{list-style-type:none}ul.lst-kix_wwm574aidb8n-3{list-style-type:none}ol.lst-kix_5stj9b6acoxv-5{list-style-type:none}ul.lst-kix_wwm574aidb8n-4{list-style-type:none}ul.lst-kix_wwm574aidb8n-5{list-style-type:none}ul.lst-kix_wwm574aidb8n-6{list-style-type:none}ul.lst-kix_wwm574aidb8n-7{list-style-type:none}ul.lst-kix_wwm574aidb8n-8{list-style-type:none}.lst-kix_skgpgvhmuoc4-0>li:before{content:"-  "}.lst-kix_b7rulpv7obgl-0>li:before{content:"-  "}ul.lst-kix_vie3q5oyli2z-1{list-style-type:none}.lst-kix_dmxresnhzo8y-4>li:before{content:"-  "}ul.lst-kix_vie3q5oyli2z-2{list-style-type:none}ul.lst-kix_vie3q5oyli2z-3{list-style-type:none}ul.lst-kix_vie3q5oyli2z-4{list-style-type:none}.lst-kix_azgj6sn0lxuj-6>li{counter-increment:lst-ctn-kix_azgj6sn0lxuj-6}ul.lst-kix_vie3q5oyli2z-0{list-style-type:none}.lst-kix_d626gkjp4fou-3>li:before{content:"\0025cf   "}ul.lst-kix_vie3q5oyli2z-5{list-style-type:none}ul.lst-kix_vie3q5oyli2z-6{list-style-type:none}ul.lst-kix_vie3q5oyli2z-7{list-style-type:none}.lst-kix_mq980hprr5hl-6>li:before{content:"-  "}ul.lst-kix_vie3q5oyli2z-8{list-style-type:none}.lst-kix_4gff7g6tktju-4>li:before{content:"-  "}.lst-kix_fhtxrv3nkyi7-2>li:before{content:"-  "}ol.lst-kix_vkdxjlf0kb6j-7.start{counter-reset:lst-ctn-kix_vkdxjlf0kb6j-7 0}.lst-kix_oswsfzrgbvyb-0>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-3>li:before{content:"" counter(lst-ctn-kix_ysfu1bl0kymd-3,decimal) ". "}.lst-kix_5djgwp8c9ig2-7>li:before{content:"" counter(lst-ctn-kix_5djgwp8c9ig2-7,lower-latin) ". "}.lst-kix_ikdz4hpyto9o-5>li:before{content:"-  "}.lst-kix_a62ncfcuapzo-0>li:before{content:"-  "}ul.lst-kix_uwhnriglec8q-7{list-style-type:none}ul.lst-kix_uwhnriglec8q-6{list-style-type:none}.lst-kix_rf3bfhvmysmh-7>li:before{content:"-  "}ul.lst-kix_uwhnriglec8q-8{list-style-type:none}.lst-kix_chbthqdwx7gj-8>li:before{content:"-  "}.lst-kix_qij6192l4p0g-5>li:before{content:"-  "}.lst-kix_unv0ib1v43rp-3>li:before{content:"-  "}ul.lst-kix_28q7sqckfj19-0{list-style-type:none}ul.lst-kix_28q7sqckfj19-1{list-style-type:none}ul.lst-kix_28q7sqckfj19-2{list-style-type:none}.lst-kix_6n4varno3bjs-1>li:before{content:"-  "}ul.lst-kix_28q7sqckfj19-7{list-style-type:none}ul.lst-kix_28q7sqckfj19-8{list-style-type:none}.lst-kix_5u0542f2h2jt-3>li:before{content:"+  "}ol.lst-kix_267f3xfv5ddr-0.start{counter-reset:lst-ctn-kix_267f3xfv5ddr-0 0}.lst-kix_rtczm6eelr4h-8>li:before{content:"-  "}ul.lst-kix_28q7sqckfj19-3{list-style-type:none}.lst-kix_5quy3fbj2mfg-0>li:before{content:"-  "}.lst-kix_43bwriak8ne4-3>li:before{content:"-  "}ul.lst-kix_28q7sqckfj19-4{list-style-type:none}ul.lst-kix_28q7sqckfj19-5{list-style-type:none}.lst-kix_i4nwb7g7qe41-1>li:before{content:"-  "}ul.lst-kix_28q7sqckfj19-6{list-style-type:none}.lst-kix_ksf6p4xm2w0d-8>li:before{content:"-  "}.lst-kix_khixc8f7o03u-5>li:before{content:"-  "}.lst-kix_axwe0nze7yft-1>li:before{content:"-  "}.lst-kix_izios9u5ks4s-4>li:before{content:"-  "}.lst-kix_q95o92il1jwg-1>li:before{content:"-  "}.lst-kix_wzt7symqmcfu-1>li:before{content:"-  "}ul.lst-kix_p02ob1bzv6e4-8{list-style-type:none}.lst-kix_r8i1fgeyliey-0>li:before{content:"-  "}ul.lst-kix_p02ob1bzv6e4-7{list-style-type:none}ul.lst-kix_p02ob1bzv6e4-6{list-style-type:none}ul.lst-kix_p02ob1bzv6e4-1{list-style-type:none}ul.lst-kix_p02ob1bzv6e4-0{list-style-type:none}.lst-kix_pgnpvlxhai6o-8>li:before{content:"-  "}ul.lst-kix_p02ob1bzv6e4-5{list-style-type:none}.lst-kix_2ccdqvrbclt-8>li:before{content:"-  "}ul.lst-kix_p02ob1bzv6e4-4{list-style-type:none}ul.lst-kix_p02ob1bzv6e4-3{list-style-type:none}.lst-kix_rxgry66ibim8-4>li:before{content:"-  "}ul.lst-kix_p02ob1bzv6e4-2{list-style-type:none}.lst-kix_xktbtduo53bq-2>li{counter-increment:lst-ctn-kix_xktbtduo53bq-2}.lst-kix_rop4yg7lbfg8-8>li:before{content:"-  "}ul.lst-kix_rxevvtxfoovc-3{list-style-type:none}ul.lst-kix_rxevvtxfoovc-4{list-style-type:none}.lst-kix_5syfdd8x3l8s-7>li:before{content:"-  "}.lst-kix_vie3q5oyli2z-1>li:before{content:"-  "}ul.lst-kix_rxevvtxfoovc-1{list-style-type:none}ul.lst-kix_rxevvtxfoovc-2{list-style-type:none}ul.lst-kix_rxevvtxfoovc-7{list-style-type:none}ul.lst-kix_rxevvtxfoovc-8{list-style-type:none}ul.lst-kix_rxevvtxfoovc-5{list-style-type:none}ul.lst-kix_rxevvtxfoovc-6{list-style-type:none}.lst-kix_pxpm44v9ngyu-6>li:before{content:"-  "}.lst-kix_i2q40uf7647f-1>li:before{content:"-  "}ul.lst-kix_axy5kxvo2nx7-0{list-style-type:none}.lst-kix_dynlpr2uwt2p-5>li:before{content:"-  "}ul.lst-kix_axy5kxvo2nx7-2{list-style-type:none}ul.lst-kix_axy5kxvo2nx7-1{list-style-type:none}.lst-kix_ozrjmre97pex-4>li:before{content:"-  "}ul.lst-kix_axy5kxvo2nx7-4{list-style-type:none}ul.lst-kix_axy5kxvo2nx7-3{list-style-type:none}.lst-kix_ozrjmre97pex-1>li:before{content:"-  "}ul.lst-kix_axy5kxvo2nx7-6{list-style-type:none}.lst-kix_t9t3ckq2i2hz-8>li:before{content:"-  "}.lst-kix_i2q40uf7647f-4>li:before{content:"-  "}ul.lst-kix_axy5kxvo2nx7-5{list-style-type:none}.lst-kix_38p7uzj3qds3-0>li:before{content:"-  "}ul.lst-kix_axy5kxvo2nx7-8{list-style-type:none}ul.lst-kix_axy5kxvo2nx7-7{list-style-type:none}ul.lst-kix_rxevvtxfoovc-0{list-style-type:none}.lst-kix_oc7itsrfkmqv-3>li:before{content:"-  "}.lst-kix_ykhrv7u6blcs-4>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-7>li:before{content:"" counter(lst-ctn-kix_ykhoydml7pv3-7,lower-latin) ". "}.lst-kix_brqn5pq4e7i7-7>li:before{content:"-  "}ol.lst-kix_5stj9b6acoxv-2.start{counter-reset:lst-ctn-kix_5stj9b6acoxv-2 0}.lst-kix_pejjsijavmae-3>li:before{content:"-  "}ol.lst-kix_xktbtduo53bq-2.start{counter-reset:lst-ctn-kix_xktbtduo53bq-2 0}.lst-kix_11d94ps4c7wj-0>li:before{content:"-  "}.lst-kix_urqiwn6svi1d-1>li:before{content:"-  "}.lst-kix_x74x9xa8n5a0-8>li:before{content:"-  "}.lst-kix_owvy3cstzf0s-7>li:before{content:"-  "}.lst-kix_5rn2qrejqs3r-0>li:before{content:"-  "}.lst-kix_b3ghc04lfx9t-7>li:before{content:"-  "}.lst-kix_w3rscytwttbz-4>li:before{content:"-  "}.lst-kix_wlyv8o88ksmk-7>li:before{content:"-  "}.lst-kix_wfyz8rmi0iq4-6>li:before{content:"-  "}.lst-kix_3wxxpxfz40sk-1>li:before{content:"-  "}ul.lst-kix_xs6xjhigrbe2-7{list-style-type:none}ul.lst-kix_xs6xjhigrbe2-8{list-style-type:none}ul.lst-kix_xs6xjhigrbe2-5{list-style-type:none}ul.lst-kix_xs6xjhigrbe2-6{list-style-type:none}.lst-kix_73pnq2b8bo4n-3>li:before{content:"-  "}.lst-kix_3wxxpxfz40sk-4>li:before{content:"-  "}ul.lst-kix_xs6xjhigrbe2-3{list-style-type:none}.lst-kix_of5ud22cn0qg-5>li:before{content:"-  "}ul.lst-kix_xs6xjhigrbe2-4{list-style-type:none}ul.lst-kix_xs6xjhigrbe2-1{list-style-type:none}ul.lst-kix_xs6xjhigrbe2-2{list-style-type:none}.lst-kix_vhhvekoaa9d4-7>li:before{content:"\0025cb   "}.lst-kix_x2lkon80l30j-2>li:before{content:"-  "}ul.lst-kix_xs6xjhigrbe2-0{list-style-type:none}.lst-kix_cpgerodpupjz-0>li:before{content:"-  "}ul.lst-kix_uwhnriglec8q-3{list-style-type:none}ul.lst-kix_uwhnriglec8q-2{list-style-type:none}ul.lst-kix_uwhnriglec8q-5{list-style-type:none}ul.lst-kix_uwhnriglec8q-4{list-style-type:none}.lst-kix_zag3ymt8mk2y-2>li:before{content:"-  "}ul.lst-kix_uwhnriglec8q-1{list-style-type:none}ul.lst-kix_uwhnriglec8q-0{list-style-type:none}.lst-kix_7o1va6u13ska-5>li:before{content:"-  "}.lst-kix_xyra4e5ffsud-4>li:before{content:"" counter(lst-ctn-kix_xyra4e5ffsud-4,lower-latin) ". "}ol.lst-kix_t3rn73qejgkj-0.start{counter-reset:lst-ctn-kix_t3rn73qejgkj-0 0}.lst-kix_w3rscytwttbz-1>li:before{content:"-  "}.lst-kix_q8c17lyf7k0c-3>li:before{content:"-  "}.lst-kix_7o1va6u13ska-2>li:before{content:"-  "}.lst-kix_xyra4e5ffsud-7>li:before{content:"" counter(lst-ctn-kix_xyra4e5ffsud-7,lower-latin) ". "}.lst-kix_5rn2qrejqs3r-3>li:before{content:"-  "}.lst-kix_o1voy78o4juz-0>li:before{content:"-  "}.lst-kix_dojezsyc3ti3-6>li:before{content:"-  "}.lst-kix_rf3bfhvmysmh-4>li:before{content:"-  "}.lst-kix_awt45k7p90je-7>li:before{content:"-  "}ol.lst-kix_xktbtduo53bq-3.start{counter-reset:lst-ctn-kix_xktbtduo53bq-3 0}.lst-kix_eahcvjpxxqs-6>li:before{content:"-  "}.lst-kix_sq25f4cnauod-1>li:before{content:"-  "}.lst-kix_arcio13zm8ud-2>li:before{content:"-  "}.lst-kix_rrloltks13s-0>li:before{content:"-  "}.lst-kix_3q7au8a3gwav-6>li:before{content:"-  "}.lst-kix_rog9deufml3h-2>li:before{content:"-  "}.lst-kix_rxmcp67o7upe-0>li:before{content:"-  "}ol.lst-kix_23ct987xwu67-6.start{counter-reset:lst-ctn-kix_23ct987xwu67-6 0}.lst-kix_bp67ajcb7c38-2>li:before{content:"-  "}ol.lst-kix_23ct987xwu67-8.start{counter-reset:lst-ctn-kix_23ct987xwu67-8 0}.lst-kix_ysfu1bl0kymd-4>li{counter-increment:lst-ctn-kix_ysfu1bl0kymd-4}.lst-kix_g1rm1ujfok3h-4>li:before{content:"-  "}.lst-kix_43bwriak8ne4-0>li:before{content:"-  "}.lst-kix_wn0yiryrov3h-2>li:before{content:"-  "}.lst-kix_khixc8f7o03u-2>li:before{content:"-  "}.lst-kix_bb3pt2xtt0a5-1>li:before{content:"-  "}.lst-kix_1xkx8gh1e8n7-6>li:before{content:"-  "}ul.lst-kix_x74x9xa8n5a0-2{list-style-type:none}ul.lst-kix_x74x9xa8n5a0-3{list-style-type:none}.lst-kix_2ccdqvrbclt-5>li:before{content:"-  "}ul.lst-kix_x74x9xa8n5a0-4{list-style-type:none}ul.lst-kix_x74x9xa8n5a0-5{list-style-type:none}ul.lst-kix_x74x9xa8n5a0-6{list-style-type:none}ul.lst-kix_x74x9xa8n5a0-7{list-style-type:none}ol.lst-kix_23ct987xwu67-7.start{counter-reset:lst-ctn-kix_23ct987xwu67-7 0}ul.lst-kix_x74x9xa8n5a0-8{list-style-type:none}.lst-kix_wzt7symqmcfu-4>li:before{content:"-  "}.lst-kix_r8i1fgeyliey-3>li:before{content:"-  "}.lst-kix_rop4yg7lbfg8-5>li:before{content:"-  "}.lst-kix_38p7uzj3qds3-3>li:before{content:"-  "}.lst-kix_dynlpr2uwt2p-8>li:before{content:"-  "}.lst-kix_28q7sqckfj19-1>li:before{content:"-  "}.lst-kix_1tib71bbsugw-0>li:before{content:"-  "}.lst-kix_wf1o55flzq55-0>li:before{content:"-  "}ul.lst-kix_x74x9xa8n5a0-0{list-style-type:none}.lst-kix_d626gkjp4fou-0>li:before{content:"\0025cf   "}ul.lst-kix_x74x9xa8n5a0-1{list-style-type:none}ul.lst-kix_1epl36nedj4y-0{list-style-type:none}ul.lst-kix_1epl36nedj4y-1{list-style-type:none}ul.lst-kix_1epl36nedj4y-2{list-style-type:none}ul.lst-kix_1epl36nedj4y-3{list-style-type:none}ul.lst-kix_6xh4bfg7mbxi-0{list-style-type:none}ul.lst-kix_1epl36nedj4y-8{list-style-type:none}ul.lst-kix_6xh4bfg7mbxi-3{list-style-type:none}.lst-kix_gfc2v9r4qc22-5>li:before{content:"-  "}ul.lst-kix_6xh4bfg7mbxi-4{list-style-type:none}ul.lst-kix_6xh4bfg7mbxi-1{list-style-type:none}ul.lst-kix_6xh4bfg7mbxi-2{list-style-type:none}ul.lst-kix_1epl36nedj4y-4{list-style-type:none}ul.lst-kix_6xh4bfg7mbxi-7{list-style-type:none}ul.lst-kix_1epl36nedj4y-5{list-style-type:none}ul.lst-kix_6xh4bfg7mbxi-8{list-style-type:none}ul.lst-kix_1epl36nedj4y-6{list-style-type:none}ul.lst-kix_6xh4bfg7mbxi-5{list-style-type:none}ul.lst-kix_1epl36nedj4y-7{list-style-type:none}.lst-kix_1v1216yy0n25-6>li:before{content:"-  "}ul.lst-kix_6xh4bfg7mbxi-6{list-style-type:none}.lst-kix_2r20t3tmnrwb-2>li:before{content:"-  "}ul.lst-kix_wz5gdx83jdla-8{list-style-type:none}.lst-kix_gfc2v9r4qc22-3>li:before{content:"-  "}.lst-kix_4i10vbfgn91y-3>li:before{content:"-  "}ul.lst-kix_wz5gdx83jdla-6{list-style-type:none}ul.lst-kix_ugixx4nd67zw-8{list-style-type:none}ul.lst-kix_wz5gdx83jdla-7{list-style-type:none}ul.lst-kix_ugixx4nd67zw-7{list-style-type:none}ul.lst-kix_wz5gdx83jdla-4{list-style-type:none}.lst-kix_ofib0hkczw41-0>li:before{content:"-  "}ul.lst-kix_ugixx4nd67zw-6{list-style-type:none}ul.lst-kix_wz5gdx83jdla-5{list-style-type:none}ul.lst-kix_ugixx4nd67zw-5{list-style-type:none}ul.lst-kix_wz5gdx83jdla-2{list-style-type:none}ul.lst-kix_ugixx4nd67zw-4{list-style-type:none}ul.lst-kix_wz5gdx83jdla-3{list-style-type:none}.lst-kix_bnte1i3g4kjh-4>li:before{content:"-  "}.lst-kix_gvlgpawofwi7-4>li:before{content:"-  "}ul.lst-kix_ugixx4nd67zw-3{list-style-type:none}ul.lst-kix_wz5gdx83jdla-0{list-style-type:none}ul.lst-kix_ugixx4nd67zw-2{list-style-type:none}ul.lst-kix_wz5gdx83jdla-1{list-style-type:none}ul.lst-kix_ugixx4nd67zw-1{list-style-type:none}ul.lst-kix_ugixx4nd67zw-0{list-style-type:none}.lst-kix_dvvzixfw64a1-8>li:before{content:"-  "}.lst-kix_eme1x4epzdye-6>li:before{content:"-  "}.lst-kix_6o2cphkh2n8b-4>li:before{content:"-  "}.lst-kix_qw2h6jd8xi17-4>li:before{content:"-  "}.lst-kix_n9q8wqas57a-3>li:before{content:"-  "}.lst-kix_svg8hnl23b1r-2>li:before{content:"-  "}.lst-kix_mv77cg19299c-2>li:before{content:"-  "}.lst-kix_23ct987xwu67-0>li{counter-increment:lst-ctn-kix_23ct987xwu67-0}ul.lst-kix_3q7au8a3gwav-7{list-style-type:none}ul.lst-kix_3q7au8a3gwav-8{list-style-type:none}ul.lst-kix_3q7au8a3gwav-5{list-style-type:none}ul.lst-kix_3q7au8a3gwav-6{list-style-type:none}ul.lst-kix_3q7au8a3gwav-3{list-style-type:none}ul.lst-kix_3q7au8a3gwav-4{list-style-type:none}ul.lst-kix_3q7au8a3gwav-1{list-style-type:none}ul.lst-kix_3q7au8a3gwav-2{list-style-type:none}.lst-kix_t3rn73qejgkj-0>li{counter-increment:lst-ctn-kix_t3rn73qejgkj-0}ul.lst-kix_3q7au8a3gwav-0{list-style-type:none}.lst-kix_x8ffawrvrcyq-0>li:before{content:"\0025cf   "}.lst-kix_eme1x4epzdye-0>li:before{content:"-  "}.lst-kix_ul22dko4fd2j-3>li:before{content:"-  "}.lst-kix_8ujam3zhcr3q-7>li:before{content:"-  "}.lst-kix_co74fk70kphx-5>li:before{content:"-  "}.lst-kix_mh5zhf27i4rj-5>li:before{content:"-  "}.lst-kix_8ujam3zhcr3q-5>li:before{content:"-  "}.lst-kix_mh5zhf27i4rj-3>li:before{content:"-  "}.lst-kix_lwlxuymndfyq-0>li:before{content:"-  "}.lst-kix_lwlxuymndfyq-2>li:before{content:"-  "}.lst-kix_aor1182clqbr-5>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-4>li{counter-increment:lst-ctn-kix_ok1n37qarjzb-4}.lst-kix_yrg2qlcqvak1-3>li:before{content:"-  "}.lst-kix_lwlxuymndfyq-8>li:before{content:"-  "}.lst-kix_ofib0hkczw41-6>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-4.start{counter-reset:lst-ctn-kix_incqcf2p39ls-4 0}.lst-kix_gaq1zvh4dcgb-4>li:before{content:"-  "}.lst-kix_ofib0hkczw41-8>li:before{content:"-  "}.lst-kix_4qbfcta6cclt-7>li:before{content:"-  "}.lst-kix_o1voy78o4juz-3>li:before{content:"-  "}.lst-kix_mv77cg19299c-4>li:before{content:"-  "}.lst-kix_np9h4y3kt4yk-2>li:before{content:"-  "}.lst-kix_v0hsa7m5lywt-8>li:before{content:"-  "}.lst-kix_hkt83gwcgrvq-4>li:before{content:"-  "}.lst-kix_6m4qu83yomn7-0>li:before{content:"-  "}ul.lst-kix_qvomcnyqz8ao-0{list-style-type:none}ul.lst-kix_qvomcnyqz8ao-2{list-style-type:none}ul.lst-kix_qvomcnyqz8ao-1{list-style-type:none}.lst-kix_2foc6u9lzfq4-6>li:before{content:"" counter(lst-ctn-kix_2foc6u9lzfq4-6,decimal) ". "}ul.lst-kix_qvomcnyqz8ao-4{list-style-type:none}ul.lst-kix_qvomcnyqz8ao-3{list-style-type:none}.lst-kix_35hvjwgc3k2f-6>li:before{content:"-  "}ul.lst-kix_qvomcnyqz8ao-6{list-style-type:none}ul.lst-kix_qvomcnyqz8ao-5{list-style-type:none}ul.lst-kix_qvomcnyqz8ao-8{list-style-type:none}ul.lst-kix_qvomcnyqz8ao-7{list-style-type:none}.lst-kix_a2xq56ushw0p-2>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-4>li:before{content:"" counter(lst-ctn-kix_2foc6u9lzfq4-4,lower-latin) ". "}.lst-kix_vayf18aqt55o-7>li:before{content:"" counter(lst-ctn-kix_vayf18aqt55o-7,lower-roman) ". "}.lst-kix_k5hm652wcnm2-3>li:before{content:"-  "}.lst-kix_np9h4y3kt4yk-0>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-8>li:before{content:"" counter(lst-ctn-kix_d1gy3hy5r3qj-8,lower-roman) ". "}ol.lst-kix_ykhoydml7pv3-1.start{counter-reset:lst-ctn-kix_ykhoydml7pv3-1 0}ol.lst-kix_267f3xfv5ddr-1.start{counter-reset:lst-ctn-kix_267f3xfv5ddr-1 0}.lst-kix_rt3ua1vpzay9-1>li:before{content:"-  "}.lst-kix_py2swxy3gr0i-7>li:before{content:"-  "}.lst-kix_6u6or33vx86s-7>li:before{content:"-  "}.lst-kix_rt3ua1vpzay9-7>li:before{content:"-  "}.lst-kix_jfoqdfq6uhww-3>li:before{content:"-  "}.lst-kix_6m4qu83yomn7-6>li:before{content:"-  "}.lst-kix_rrloltks13s-3>li:before{content:"-  "}.lst-kix_arcio13zm8ud-5>li:before{content:"-  "}.lst-kix_ms4jfr9nudpc-3>li:before{content:"-  "}ol.lst-kix_yvohqcnu3146-4.start{counter-reset:lst-ctn-kix_yvohqcnu3146-4 0}.lst-kix_yhq927c05ak0-0>li:before{content:"-  "}.lst-kix_svg8hnl23b1r-8>li:before{content:"-  "}.lst-kix_7rlftcume51v-5>li:before{content:"-  "}.lst-kix_puc0azh4kjfq-5>li:before{content:"-  "}.lst-kix_g8jgbze430sv-2>li:before{content:"" counter(lst-ctn-kix_g8jgbze430sv-2,lower-roman) ") "}.lst-kix_puc0azh4kjfq-3>li:before{content:"-  "}.lst-kix_j60wooaeanf9-0>li:before{content:"-  "}.lst-kix_st0egafmkg0z-5>li:before{content:"-  "}.lst-kix_py2swxy3gr0i-1>li:before{content:"-  "}.lst-kix_mb1zrov3n6kx-5>li:before{content:"-  "}.lst-kix_bswxvn1l22fp-2>li:before{content:"-  "}.lst-kix_j60wooaeanf9-6>li:before{content:"-  "}.lst-kix_st0egafmkg0z-7>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-4>li{counter-increment:lst-ctn-kix_d1gy3hy5r3qj-4}.lst-kix_cwjen7nun640-6>li:before{content:"-  "}.lst-kix_8w7txqc6xq66-7>li:before{content:"-  "}.lst-kix_w97kncqyzxj3-2>li:before{content:"\0025a0   "}.lst-kix_nj8yy6k748x0-8>li:before{content:"-  "}.lst-kix_6ltb10qoez57-0>li:before{content:"\0025cf   "}.lst-kix_j60wooaeanf9-8>li:before{content:"-  "}.lst-kix_bv8sxewi94yp-6>li:before{content:"-  "}ul.lst-kix_ul22dko4fd2j-2{list-style-type:none}.lst-kix_nj8yy6k748x0-2>li:before{content:"-  "}ul.lst-kix_ul22dko4fd2j-3{list-style-type:none}ul.lst-kix_ul22dko4fd2j-0{list-style-type:none}ul.lst-kix_ul22dko4fd2j-1{list-style-type:none}ul.lst-kix_ul22dko4fd2j-6{list-style-type:none}ul.lst-kix_ul22dko4fd2j-7{list-style-type:none}ul.lst-kix_ul22dko4fd2j-4{list-style-type:none}ul.lst-kix_ul22dko4fd2j-5{list-style-type:none}.lst-kix_dn04c4yafie0-5>li:before{content:"-  "}ul.lst-kix_l5iaj94ondn3-0{list-style-type:none}ul.lst-kix_l5iaj94ondn3-2{list-style-type:none}ul.lst-kix_l5iaj94ondn3-1{list-style-type:none}.lst-kix_qccibyu36y2t-3>li:before{content:"-  "}ul.lst-kix_l5iaj94ondn3-8{list-style-type:none}ul.lst-kix_l5iaj94ondn3-7{list-style-type:none}.lst-kix_mb1zrov3n6kx-3>li:before{content:"-  "}ul.lst-kix_l5iaj94ondn3-4{list-style-type:none}ul.lst-kix_l5iaj94ondn3-3{list-style-type:none}.lst-kix_90bg3luq5inv-5>li{counter-increment:lst-ctn-kix_90bg3luq5inv-5}.lst-kix_5syfdd8x3l8s-4>li:before{content:"-  "}ul.lst-kix_l5iaj94ondn3-6{list-style-type:none}ul.lst-kix_l5iaj94ondn3-5{list-style-type:none}ul.lst-kix_sgiyubx3nkay-3{list-style-type:none}ul.lst-kix_sgiyubx3nkay-2{list-style-type:none}ul.lst-kix_sgiyubx3nkay-1{list-style-type:none}ul.lst-kix_sgiyubx3nkay-0{list-style-type:none}ul.lst-kix_sgiyubx3nkay-7{list-style-type:none}ul.lst-kix_sgiyubx3nkay-6{list-style-type:none}ul.lst-kix_sgiyubx3nkay-5{list-style-type:none}ul.lst-kix_sgiyubx3nkay-4{list-style-type:none}ul.lst-kix_sgiyubx3nkay-8{list-style-type:none}.lst-kix_y32h08wggx1t-0>li:before{content:"-  "}.lst-kix_pg2i9lis4p1v-5>li:before{content:"-  "}.lst-kix_1x319pprarxc-5>li:before{content:"-  "}ul.lst-kix_oqibhsqlyfou-8{list-style-type:none}.lst-kix_x74x9xa8n5a0-5>li:before{content:"-  "}ul.lst-kix_oqibhsqlyfou-7{list-style-type:none}ul.lst-kix_oqibhsqlyfou-6{list-style-type:none}ul.lst-kix_oqibhsqlyfou-5{list-style-type:none}ul.lst-kix_oqibhsqlyfou-4{list-style-type:none}ul.lst-kix_oqibhsqlyfou-3{list-style-type:none}ul.lst-kix_oqibhsqlyfou-2{list-style-type:none}ul.lst-kix_ul22dko4fd2j-8{list-style-type:none}ul.lst-kix_oqibhsqlyfou-1{list-style-type:none}ul.lst-kix_oqibhsqlyfou-0{list-style-type:none}.lst-kix_fmkfhvl8yhfs-8>li:before{content:"-  "}.lst-kix_fs1lzw38maxl-0>li:before{content:"-  "}.lst-kix_wnr3c516ni7j-0>li:before{content:"-  "}.lst-kix_cpgerodpupjz-2>li:before{content:"-  "}.lst-kix_7o5enrj2ko1w-6>li:before{content:"-  "}.lst-kix_j32gjnxzdkip-6>li:before{content:"-  "}.lst-kix_unv0ib1v43rp-0>li:before{content:"-  "}.lst-kix_932mko8sjg0u-0>li:before{content:"-  "}.lst-kix_rxmcp67o7upe-5>li:before{content:"-  "}.lst-kix_jnfn9mx5o33t-0>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-4>li{counter-increment:lst-ctn-kix_u8nobwiguyj1-4}.lst-kix_owvy3cstzf0s-1>li:before{content:"-  "}.lst-kix_8w03xjt2k9bc-0>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-3>li:before{content:"(" counter(lst-ctn-kix_u8nobwiguyj1-3,decimal) ") "}.lst-kix_7o1va6u13ska-7>li:before{content:"-  "}.lst-kix_23ct987xwu67-1>li:before{content:"" counter(lst-ctn-kix_23ct987xwu67-1,lower-latin) ") "}.lst-kix_i2q40uf7647f-7>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-6>li:before{content:"" counter(lst-ctn-kix_ok1n37qarjzb-6,lower-latin) ". "}.lst-kix_9z31rmzc855z-8>li:before{content:"-  "}.lst-kix_iupg79bv69ia-7>li:before{content:"-  "}.lst-kix_3wxxpxfz40sk-6>li:before{content:"-  "}.lst-kix_22zpsclbl6ju-6>li:before{content:"-  "}.lst-kix_5rn2qrejqs3r-6>li:before{content:"-  "}.lst-kix_fm53cr9wmch0-7>li:before{content:"-  "}.lst-kix_6vg5692ogph-2>li:before{content:"-  "}.lst-kix_tnd0p97rqwub-7>li:before{content:"-  "}.lst-kix_rf3bfhvmysmh-2>li:before{content:"-  "}.lst-kix_jhofo94iol1-5>li:before{content:"-  "}.lst-kix_wwm574aidb8n-8>li:before{content:"-  "}.lst-kix_q24qpifeknc3-8>li:before{content:"-  "}ol.lst-kix_xyra4e5ffsud-8.start{counter-reset:lst-ctn-kix_xyra4e5ffsud-8 0}.lst-kix_yjf6dvvoob64-4>li{counter-increment:lst-ctn-kix_yjf6dvvoob64-4}.lst-kix_9a7xq1ie41tp-1>li:before{content:"-  "}ol.lst-kix_84zf7o74c8s9-4.start{counter-reset:lst-ctn-kix_84zf7o74c8s9-4 0}.lst-kix_vgg0538grxk3-6>li{counter-increment:lst-ctn-kix_vgg0538grxk3-6}ol.lst-kix_3mj3tp7kj9db-2.start{counter-reset:lst-ctn-kix_3mj3tp7kj9db-2 0}.lst-kix_vgg0538grxk3-6>li:before{content:"" counter(lst-ctn-kix_vgg0538grxk3-6,decimal) ". "}.lst-kix_axy5kxvo2nx7-5>li:before{content:"-  "}.lst-kix_d7eif1vat32g-0>li:before{content:"-  "}ul.lst-kix_npanryo7f1m7-7{list-style-type:none}ul.lst-kix_npanryo7f1m7-6{list-style-type:none}ul.lst-kix_npanryo7f1m7-8{list-style-type:none}ul.lst-kix_npanryo7f1m7-3{list-style-type:none}.lst-kix_3q7au8a3gwav-4>li:before{content:"-  "}ul.lst-kix_npanryo7f1m7-2{list-style-type:none}ul.lst-kix_npanryo7f1m7-5{list-style-type:none}ul.lst-kix_npanryo7f1m7-4{list-style-type:none}.lst-kix_5nilpkhthb5t-7>li:before{content:"-  "}.lst-kix_x95t913s41kt-2>li:before{content:"-  "}ul.lst-kix_npanryo7f1m7-1{list-style-type:none}ul.lst-kix_npanryo7f1m7-0{list-style-type:none}.lst-kix_unv0ib1v43rp-8>li:before{content:"-  "}.lst-kix_x1xhkkpc69w2-1>li:before{content:"-  "}.lst-kix_bpsiys7g173w-3>li:before{content:"-  "}ul.lst-kix_tl77ogq6q7u-1{list-style-type:none}ul.lst-kix_hrm7p8w30y7p-0{list-style-type:none}ul.lst-kix_tl77ogq6q7u-2{list-style-type:none}ul.lst-kix_hrm7p8w30y7p-1{list-style-type:none}ul.lst-kix_hrm7p8w30y7p-2{list-style-type:none}ul.lst-kix_tl77ogq6q7u-0{list-style-type:none}ul.lst-kix_hrm7p8w30y7p-3{list-style-type:none}ul.lst-kix_tl77ogq6q7u-5{list-style-type:none}.lst-kix_5argtotmwusw-4>li:before{content:"-  "}ul.lst-kix_hrm7p8w30y7p-4{list-style-type:none}ul.lst-kix_tl77ogq6q7u-6{list-style-type:none}ul.lst-kix_hrm7p8w30y7p-5{list-style-type:none}ul.lst-kix_tl77ogq6q7u-3{list-style-type:none}.lst-kix_ypd5gkkarijk-1>li{counter-increment:lst-ctn-kix_ypd5gkkarijk-1}ul.lst-kix_hrm7p8w30y7p-6{list-style-type:none}ul.lst-kix_tl77ogq6q7u-4{list-style-type:none}ul.lst-kix_tl77ogq6q7u-7{list-style-type:none}ul.lst-kix_tl77ogq6q7u-8{list-style-type:none}.lst-kix_5djgwp8c9ig2-6>li{counter-increment:lst-ctn-kix_5djgwp8c9ig2-6}.lst-kix_mvektlca5c5q-5>li:before{content:"-  "}.lst-kix_rcfi5jnwnxji-3>li:before{content:"-  "}ul.lst-kix_hrm7p8w30y7p-7{list-style-type:none}ul.lst-kix_hrm7p8w30y7p-8{list-style-type:none}.lst-kix_ellvdfsu2z7q-1>li:before{content:"-  "}ul.lst-kix_nqtgcebhe8ii-7{list-style-type:none}ul.lst-kix_nqtgcebhe8ii-6{list-style-type:none}ul.lst-kix_nqtgcebhe8ii-5{list-style-type:none}ul.lst-kix_nqtgcebhe8ii-4{list-style-type:none}.lst-kix_5stj9b6acoxv-3>li:before{content:"" counter(lst-ctn-kix_5stj9b6acoxv-3,decimal) ". "}ul.lst-kix_nqtgcebhe8ii-3{list-style-type:none}ul.lst-kix_nqtgcebhe8ii-2{list-style-type:none}ul.lst-kix_nqtgcebhe8ii-1{list-style-type:none}ul.lst-kix_nqtgcebhe8ii-0{list-style-type:none}.lst-kix_rxgry66ibim8-7>li:before{content:"-  "}.lst-kix_x12ed5cs6o9z-3>li:before{content:"-  "}ul.lst-kix_nqtgcebhe8ii-8{list-style-type:none}ol.lst-kix_yjf6dvvoob64-7.start{counter-reset:lst-ctn-kix_yjf6dvvoob64-7 0}.lst-kix_yvohqcnu3146-5>li{counter-increment:lst-ctn-kix_yvohqcnu3146-5}.lst-kix_oqibhsqlyfou-7>li:before{content:"-  "}ol.lst-kix_u8nobwiguyj1-0.start{counter-reset:lst-ctn-kix_u8nobwiguyj1-0 0}.lst-kix_cmm6cscyrjti-7>li:before{content:"-  "}.lst-kix_g2uanok8rp1g-2>li:before{content:"-  "}.lst-kix_3wddikkjnk2k-7>li:before{content:"-  "}.lst-kix_bp67ajcb7c38-4>li:before{content:"-  "}ul.lst-kix_w97kncqyzxj3-7{list-style-type:none}ul.lst-kix_w97kncqyzxj3-8{list-style-type:none}ul.lst-kix_35hvjwgc3k2f-3{list-style-type:none}ul.lst-kix_35hvjwgc3k2f-2{list-style-type:none}.lst-kix_rxevvtxfoovc-5>li:before{content:"-  "}ul.lst-kix_35hvjwgc3k2f-1{list-style-type:none}ul.lst-kix_35hvjwgc3k2f-0{list-style-type:none}ul.lst-kix_x95t913s41kt-3{list-style-type:none}ul.lst-kix_35hvjwgc3k2f-7{list-style-type:none}ul.lst-kix_x95t913s41kt-4{list-style-type:none}ul.lst-kix_35hvjwgc3k2f-6{list-style-type:none}ul.lst-kix_x95t913s41kt-5{list-style-type:none}ul.lst-kix_35hvjwgc3k2f-5{list-style-type:none}ul.lst-kix_x95t913s41kt-6{list-style-type:none}ul.lst-kix_35hvjwgc3k2f-4{list-style-type:none}.lst-kix_y62sddnu24wd-2>li:before{content:"-  "}ul.lst-kix_x95t913s41kt-7{list-style-type:none}ul.lst-kix_x95t913s41kt-8{list-style-type:none}.lst-kix_wiijpxq0m5a-1>li:before{content:"-  "}.lst-kix_i4nwb7g7qe41-7>li:before{content:"-  "}.lst-kix_vvjhovkzyen7-8>li:before{content:"-  "}ul.lst-kix_35hvjwgc3k2f-8{list-style-type:none}.lst-kix_dmn3lqzfmokk-1>li:before{content:"-  "}.lst-kix_7vaamq35f1cc-1>li:before{content:"-  "}.lst-kix_y62sddnu24wd-4>li:before{content:"-  "}.lst-kix_8f3g26d9wonp-2>li:before{content:"-  "}.lst-kix_17yxihawuh4r-2>li:before{content:"-  "}.lst-kix_x424ckbm5jp1-4>li:before{content:"-  "}.lst-kix_yxvs6rw7mq1w-5>li:before{content:"-  "}.lst-kix_i7kvy3cw4vsq-5>li:before{content:"-  "}.lst-kix_lcru2cdgc87j-3>li:before{content:"-  "}.lst-kix_a9h81iclzrpy-2>li:before{content:"-  "}.lst-kix_fld6w0ks1f0p-4>li:before{content:"-  "}.lst-kix_8drpzle0jo7q-7>li:before{content:"\0025cb   "}.lst-kix_17yxihawuh4r-8>li:before{content:"-  "}.lst-kix_tl77ogq6q7u-7>li:before{content:"-  "}ul.lst-kix_x95t913s41kt-0{list-style-type:none}ul.lst-kix_x95t913s41kt-1{list-style-type:none}ul.lst-kix_x95t913s41kt-2{list-style-type:none}.lst-kix_yxvs6rw7mq1w-3>li:before{content:"-  "}.lst-kix_spt2hfceke6p-1>li:before{content:"-  "}.lst-kix_skgpgvhmuoc4-2>li:before{content:"-  "}.lst-kix_kobinbwr4qr6-6>li:before{content:"-  "}.lst-kix_8pn77unkg8hg-4>li:before{content:"-  "}.lst-kix_iupg79bv69ia-1>li:before{content:"-  "}.lst-kix_l60gvbdij7aj-5>li:before{content:"-  "}.lst-kix_s9h4llxy1yy0-8>li:before{content:"-  "}.lst-kix_69k4orytle42-4>li:before{content:"\0025cb   "}.lst-kix_o7acnutkhp1w-1>li:before{content:"-  "}.lst-kix_upq3ni6ul8eb-2>li:before{content:"-  "}.lst-kix_o7acnutkhp1w-7>li:before{content:"-  "}.lst-kix_n9qabngdxy64-4>li:before{content:"-  "}ol.lst-kix_5djgwp8c9ig2-1.start{counter-reset:lst-ctn-kix_5djgwp8c9ig2-1 0}ul.lst-kix_5quy3fbj2mfg-3{list-style-type:none}ul.lst-kix_w97kncqyzxj3-5{list-style-type:none}.lst-kix_c73c2x77meqo-8>li:before{content:"-  "}ul.lst-kix_5quy3fbj2mfg-2{list-style-type:none}ul.lst-kix_w97kncqyzxj3-6{list-style-type:none}.lst-kix_p2dhxl6hicde-7>li:before{content:"-  "}ul.lst-kix_5quy3fbj2mfg-5{list-style-type:none}ul.lst-kix_w97kncqyzxj3-3{list-style-type:none}ul.lst-kix_5quy3fbj2mfg-4{list-style-type:none}ul.lst-kix_w97kncqyzxj3-4{list-style-type:none}ul.lst-kix_5quy3fbj2mfg-7{list-style-type:none}ul.lst-kix_w97kncqyzxj3-1{list-style-type:none}.lst-kix_tpw8rt3jm7dt-4>li:before{content:"-  "}ul.lst-kix_5quy3fbj2mfg-6{list-style-type:none}ul.lst-kix_w97kncqyzxj3-2{list-style-type:none}ul.lst-kix_5quy3fbj2mfg-8{list-style-type:none}ul.lst-kix_w97kncqyzxj3-0{list-style-type:none}.lst-kix_xyra4e5ffsud-8>li{counter-increment:lst-ctn-kix_xyra4e5ffsud-8}.lst-kix_ksf6p4xm2w0d-6>li:before{content:"-  "}ul.lst-kix_spt2hfceke6p-0{list-style-type:none}ul.lst-kix_spt2hfceke6p-1{list-style-type:none}.lst-kix_yjf6dvvoob64-0>li:before{content:"" counter(lst-ctn-kix_yjf6dvvoob64-0,decimal) ". "}ul.lst-kix_5quy3fbj2mfg-1{list-style-type:none}.lst-kix_izios9u5ks4s-6>li:before{content:"-  "}ul.lst-kix_5quy3fbj2mfg-0{list-style-type:none}ul.lst-kix_spt2hfceke6p-4{list-style-type:none}ul.lst-kix_spt2hfceke6p-5{list-style-type:none}.lst-kix_p2dhxl6hicde-1>li:before{content:"-  "}ul.lst-kix_spt2hfceke6p-2{list-style-type:none}ul.lst-kix_spt2hfceke6p-3{list-style-type:none}ul.lst-kix_spt2hfceke6p-8{list-style-type:none}.lst-kix_alhag51wggig-0>li:before{content:"-  "}ul.lst-kix_spt2hfceke6p-6{list-style-type:none}ul.lst-kix_spt2hfceke6p-7{list-style-type:none}.lst-kix_fexdtgozkcsr-3>li:before{content:"-  "}.lst-kix_4voxeic75vm5-6>li:before{content:"-  "}.lst-kix_ny5e869gaylo-2>li:before{content:"-  "}.lst-kix_q2mi4y6rc42i-0>li:before{content:"-  "}.lst-kix_o45gwpewsvxw-5>li:before{content:"-  "}.lst-kix_549l9aqx2sdy-3>li:before{content:"-  "}.lst-kix_5djgwp8c9ig2-1>li:before{content:"" counter(lst-ctn-kix_5djgwp8c9ig2-1,lower-latin) ". "}.lst-kix_ob04lr2u335p-2>li:before{content:"-  "}.lst-kix_3i5qlhg977l0-5>li:before{content:"-  "}.lst-kix_mtm8lwd6vxjl-0>li:before{content:"-  "}ul.lst-kix_gboi4t2flod9-2{list-style-type:none}.lst-kix_fmkfhvl8yhfs-2>li:before{content:"-  "}ul.lst-kix_gboi4t2flod9-3{list-style-type:none}.lst-kix_qzg09ck6gr7w-3>li:before{content:"-  "}ul.lst-kix_gboi4t2flod9-0{list-style-type:none}ul.lst-kix_gboi4t2flod9-1{list-style-type:none}ul.lst-kix_gboi4t2flod9-6{list-style-type:none}ul.lst-kix_gboi4t2flod9-7{list-style-type:none}ul.lst-kix_gboi4t2flod9-4{list-style-type:none}ul.lst-kix_gboi4t2flod9-5{list-style-type:none}ul.lst-kix_gboi4t2flod9-8{list-style-type:none}.lst-kix_bv8sxewi94yp-4>li:before{content:"-  "}.lst-kix_4ii5776egvw8-5>li:before{content:"-  "}.lst-kix_qccibyu36y2t-5>li:before{content:"-  "}ul.lst-kix_2xixyk6jteti-8{list-style-type:none}.lst-kix_932mko8sjg0u-6>li:before{content:"-  "}.lst-kix_yk26x5gkc3g4-2>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-6.start{counter-reset:lst-ctn-kix_incqcf2p39ls-6 0}.lst-kix_y32h08wggx1t-6>li:before{content:"-  "}ul.lst-kix_2xixyk6jteti-1{list-style-type:none}ul.lst-kix_2xixyk6jteti-0{list-style-type:none}ul.lst-kix_2xixyk6jteti-3{list-style-type:none}ul.lst-kix_2xixyk6jteti-2{list-style-type:none}ul.lst-kix_2xixyk6jteti-5{list-style-type:none}ul.lst-kix_2xixyk6jteti-4{list-style-type:none}ul.lst-kix_2xixyk6jteti-7{list-style-type:none}.lst-kix_ok1n37qarjzb-0>li:before{content:"" counter(lst-ctn-kix_ok1n37qarjzb-0,lower-latin) ") "}ul.lst-kix_2xixyk6jteti-6{list-style-type:none}.lst-kix_g47hwi8ilj0t-3>li:before{content:"-  "}.lst-kix_kzw7lb63578w-7>li:before{content:"-  "}.lst-kix_4voxeic75vm5-0>li:before{content:"-  "}.lst-kix_vkdxjlf0kb6j-1>li:before{content:"" counter(lst-ctn-kix_vkdxjlf0kb6j-1,lower-latin) ". "}.lst-kix_7cboi17aj4i3-8>li:before{content:"-  "}.lst-kix_c7r1s55bmbei-4>li:before{content:"-  "}.lst-kix_6vg5692ogph-0>li:before{content:"-  "}.lst-kix_7o5enrj2ko1w-4>li:before{content:"-  "}.lst-kix_waivoqs1cu5x-4>li:before{content:"-  "}.lst-kix_267f3xfv5ddr-6>li{counter-increment:lst-ctn-kix_267f3xfv5ddr-6}.lst-kix_r9gci84l54f7-2>li:before{content:"-  "}.lst-kix_8w03xjt2k9bc-6>li:before{content:"-  "}.lst-kix_6vg5692ogph-8>li:before{content:"-  "}.lst-kix_uvjyeruqqfgv-4>li:before{content:"-  "}.lst-kix_iyje40sgs3ri-1>li:before{content:"-  "}.lst-kix_14k5lhtsu41k-7>li:before{content:"-  "}.lst-kix_tagzs2njqau3-5>li:before{content:"-  "}.lst-kix_onvme58enb43-8>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-3.start{counter-reset:lst-ctn-kix_d1gy3hy5r3qj-3 0}.lst-kix_cg6jep1fmawj-6>li:before{content:"-  "}.lst-kix_23ct987xwu67-3>li:before{content:"(" counter(lst-ctn-kix_23ct987xwu67-3,decimal) ") "}.lst-kix_4gff7g6tktju-6>li:before{content:"-  "}.lst-kix_5l84eporjaw3-2>li:before{content:"-  "}.lst-kix_hyuyjld7ihkv-0>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-8>li:before{content:"" counter(lst-ctn-kix_ok1n37qarjzb-8,decimal) ". "}ul.lst-kix_tc7vpn5ce0ra-0{list-style-type:none}ul.lst-kix_tc7vpn5ce0ra-4{list-style-type:none}ul.lst-kix_tc7vpn5ce0ra-3{list-style-type:none}.lst-kix_ctweb0b3a38f-7>li:before{content:"-  "}ul.lst-kix_tc7vpn5ce0ra-2{list-style-type:none}ul.lst-kix_tc7vpn5ce0ra-1{list-style-type:none}ul.lst-kix_tc7vpn5ce0ra-8{list-style-type:none}ul.lst-kix_tc7vpn5ce0ra-7{list-style-type:none}ul.lst-kix_tc7vpn5ce0ra-6{list-style-type:none}ul.lst-kix_tc7vpn5ce0ra-5{list-style-type:none}.lst-kix_5stj9b6acoxv-8>li{counter-increment:lst-ctn-kix_5stj9b6acoxv-8}.lst-kix_np9h4y3kt4yk-8>li:before{content:"-  "}.lst-kix_3qppsihuuk4z-2>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-4.start{counter-reset:lst-ctn-kix_ok1n37qarjzb-4 0}.lst-kix_8hvuzyuchy3p-2>li:before{content:"-  "}.lst-kix_vkdxjlf0kb6j-2>li{counter-increment:lst-ctn-kix_vkdxjlf0kb6j-2}.lst-kix_eh3u7tkoktop-4>li:before{content:"-  "}.lst-kix_qw4x1ydun1ls-0>li:before{content:"\0025cf   "}.lst-kix_2agzfikyhf8k-5>li:before{content:"-  "}.lst-kix_9a7xq1ie41tp-7>li:before{content:"-  "}.lst-kix_v9cryi9ybo1n-8>li:before{content:"\0025a0   "}.lst-kix_ivmzvkm69gsd-6>li:before{content:"-  "}.lst-kix_wrdk3q33keus-3>li:before{content:"-  "}ul.lst-kix_4xiv877yc8jl-5{list-style-type:none}ul.lst-kix_4xiv877yc8jl-4{list-style-type:none}ul.lst-kix_4xiv877yc8jl-7{list-style-type:none}ul.lst-kix_4xiv877yc8jl-6{list-style-type:none}ul.lst-kix_4xiv877yc8jl-1{list-style-type:none}ul.lst-kix_4xiv877yc8jl-0{list-style-type:none}.lst-kix_yob9gooqotb-2>li:before{content:"-  "}ul.lst-kix_4xiv877yc8jl-3{list-style-type:none}ul.lst-kix_4xiv877yc8jl-2{list-style-type:none}.lst-kix_tekivzgenz72-6>li:before{content:"-  "}.lst-kix_gboi4t2flod9-5>li:before{content:"-  "}.lst-kix_t3rn73qejgkj-5>li{counter-increment:lst-ctn-kix_t3rn73qejgkj-5}.lst-kix_r9s6df60is49-1>li:before{content:"-  "}.lst-kix_7dqsuv1cdvcc-4>li:before{content:"-  "}ul.lst-kix_4xiv877yc8jl-8{list-style-type:none}.lst-kix_xs6xjhigrbe2-6>li:before{content:"-  "}.lst-kix_ellvdfsu2z7q-3>li:before{content:"-  "}ul.lst-kix_9j3np3ow732h-8{list-style-type:none}.lst-kix_bpsiys7g173w-5>li:before{content:"-  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_9j3np3ow732h-0{list-style-type:none}ul.lst-kix_9j3np3ow732h-1{list-style-type:none}ul.lst-kix_9j3np3ow732h-2{list-style-type:none}ul.lst-kix_9j3np3ow732h-3{list-style-type:none}.lst-kix_hytfj9icha07-2>li:before{content:"-  "}ul.lst-kix_9j3np3ow732h-4{list-style-type:none}ul.lst-kix_9j3np3ow732h-5{list-style-type:none}ul.lst-kix_9j3np3ow732h-6{list-style-type:none}.lst-kix_3bnqwg68tpm3-8>li:before{content:"-  "}ul.lst-kix_9j3np3ow732h-7{list-style-type:none}.lst-kix_267f3xfv5ddr-5>li:before{content:"" counter(lst-ctn-kix_267f3xfv5ddr-5,lower-roman) ". "}ol.lst-kix_yvohqcnu3146-6.start{counter-reset:lst-ctn-kix_yvohqcnu3146-6 0}.lst-kix_kp4gb6sd08f1-1>li:before{content:"-  "}ul.lst-kix_f9iu0trsjas1-8{list-style-type:none}.lst-kix_q7gxc7al9t7n-3>li:before{content:"-  "}.lst-kix_sr0z5k7b8i6u-8>li:before{content:"-  "}.lst-kix_eh8nesljbkpv-1>li:before{content:"-  "}.lst-kix_f2t507a7xjue-4>li:before{content:"-  "}.lst-kix_kp4gb6sd08f1-4>li:before{content:"-  "}.lst-kix_84zf7o74c8s9-5>li{counter-increment:lst-ctn-kix_84zf7o74c8s9-5}.lst-kix_q7gxc7al9t7n-0>li:before{content:"-  "}.lst-kix_p11gr83hik0e-7>li:before{content:"-  "}.lst-kix_kp4gb6sd08f1-7>li:before{content:"-  "}.lst-kix_f2t507a7xjue-7>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-1>li:before{content:"" counter(lst-ctn-kix_3fc7x0lm2mmz-1,lower-latin) ") "}.lst-kix_eh8nesljbkpv-7>li:before{content:"-  "}.lst-kix_sxznwwyc44x6-6>li:before{content:"-  "}.lst-kix_p9ucdfdvxyzl-5>li:before{content:"-  "}.lst-kix_p9ucdfdvxyzl-8>li:before{content:"-  "}.lst-kix_eh8nesljbkpv-4>li:before{content:"-  "}.lst-kix_sxznwwyc44x6-0>li:before{content:"-  "}.lst-kix_sr0z5k7b8i6u-5>li:before{content:"-  "}.lst-kix_lojd6plssn1-7>li:before{content:"-  "}.lst-kix_p9ucdfdvxyzl-2>li:before{content:"-  "}.lst-kix_sxznwwyc44x6-3>li:before{content:"-  "}.lst-kix_xktbtduo53bq-0>li{counter-increment:lst-ctn-kix_xktbtduo53bq-0}.lst-kix_hppu19i8fr2p-6>li:before{content:"" counter(lst-ctn-kix_hppu19i8fr2p-6,decimal) ". "}.lst-kix_o328viitwjyp-7>li:before{content:"-  "}.lst-kix_5djgwp8c9ig2-1>li{counter-increment:lst-ctn-kix_5djgwp8c9ig2-1}.lst-kix_l4d8unsm10a0-4>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-7>li:before{content:"" counter(lst-ctn-kix_3fc7x0lm2mmz-7,lower-latin) ". "}.lst-kix_fnlxcectz7fi-6>li:before{content:"-  "}.lst-kix_zew29xx7bzz-1>li:before{content:"-  "}.lst-kix_fnlxcectz7fi-3>li:before{content:"-  "}.lst-kix_l4d8unsm10a0-7>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-2.start{counter-reset:lst-ctn-kix_ok1n37qarjzb-2 0}.lst-kix_3fc7x0lm2mmz-4>li:before{content:"(" counter(lst-ctn-kix_3fc7x0lm2mmz-4,lower-latin) ") "}.lst-kix_o4efc4ukggt5-8>li:before{content:"-  "}.lst-kix_xktbtduo53bq-1>li:before{content:"" counter(lst-ctn-kix_xktbtduo53bq-1,lower-latin) ". "}ul.lst-kix_f9iu0trsjas1-5{list-style-type:none}.lst-kix_azgj6sn0lxuj-8>li{counter-increment:lst-ctn-kix_azgj6sn0lxuj-8}ul.lst-kix_f9iu0trsjas1-4{list-style-type:none}.lst-kix_v9cryi9ybo1n-2>li:before{content:"\0025a0   "}ul.lst-kix_f9iu0trsjas1-7{list-style-type:none}ul.lst-kix_f9iu0trsjas1-6{list-style-type:none}ul.lst-kix_f9iu0trsjas1-1{list-style-type:none}ul.lst-kix_f9iu0trsjas1-0{list-style-type:none}.lst-kix_vgg0538grxk3-1>li{counter-increment:lst-ctn-kix_vgg0538grxk3-1}ul.lst-kix_f9iu0trsjas1-3{list-style-type:none}ul.lst-kix_f9iu0trsjas1-2{list-style-type:none}.lst-kix_85vz7a3ggeai-6>li:before{content:"-  "}.lst-kix_o328viitwjyp-4>li:before{content:"-  "}.lst-kix_sgiyubx3nkay-3>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-3>li:before{content:"(" counter(lst-ctn-kix_hppu19i8fr2p-3,decimal) ") "}.lst-kix_m3u7mfewl2ow-3>li:before{content:"-  "}.lst-kix_8hvuzyuchy3p-5>li:before{content:"-  "}.lst-kix_vkdxjlf0kb6j-1>li{counter-increment:lst-ctn-kix_vkdxjlf0kb6j-1}.lst-kix_f83agu4s4fw5-8>li:before{content:"-  "}.lst-kix_d94n7or3b41v-6>li:before{content:"-  "}.lst-kix_pv4jsz2h74wk-3>li:before{content:"-  "}ul.lst-kix_tdrf79x9zyr7-0{list-style-type:none}.lst-kix_ht80gp8jxjfs-6>li:before{content:"-  "}.lst-kix_v9cryi9ybo1n-5>li:before{content:"\0025a0   "}ul.lst-kix_tdrf79x9zyr7-1{list-style-type:none}.lst-kix_84zf7o74c8s9-8>li:before{content:"" counter(lst-ctn-kix_84zf7o74c8s9-8,lower-roman) ". "}ul.lst-kix_tdrf79x9zyr7-4{list-style-type:none}.lst-kix_mjig28how5ag-4>li:before{content:"-  "}ul.lst-kix_tdrf79x9zyr7-5{list-style-type:none}ul.lst-kix_tdrf79x9zyr7-2{list-style-type:none}ul.lst-kix_tdrf79x9zyr7-3{list-style-type:none}.lst-kix_84zf7o74c8s9-2>li:before{content:"" counter(lst-ctn-kix_84zf7o74c8s9-2,lower-roman) ".) "}.lst-kix_ht80gp8jxjfs-0>li:before{content:"-  "}.lst-kix_eh3u7tkoktop-7>li:before{content:"-  "}.lst-kix_267f3xfv5ddr-7>li{counter-increment:lst-ctn-kix_267f3xfv5ddr-7}.lst-kix_rog9deufml3h-7>li:before{content:"-  "}ol.lst-kix_hppu19i8fr2p-2.start{counter-reset:lst-ctn-kix_hppu19i8fr2p-2 0}.lst-kix_l4d8unsm10a0-1>li:before{content:"-  "}.lst-kix_6217r3mhjywx-8>li:before{content:"-  "}ul.lst-kix_tdrf79x9zyr7-8{list-style-type:none}ul.lst-kix_tdrf79x9zyr7-6{list-style-type:none}ul.lst-kix_tdrf79x9zyr7-7{list-style-type:none}.lst-kix_2agzfikyhf8k-2>li:before{content:"-  "}.lst-kix_tlnfkrylyq1a-6>li:before{content:"-  "}.lst-kix_1epl36nedj4y-7>li:before{content:"-  "}.lst-kix_3novkjnl93sa-2>li:before{content:"-  "}.lst-kix_tekivzgenz72-3>li:before{content:"-  "}ul.lst-kix_a42anijqpp8a-1{list-style-type:none}ul.lst-kix_a42anijqpp8a-0{list-style-type:none}ul.lst-kix_a42anijqpp8a-3{list-style-type:none}ul.lst-kix_a42anijqpp8a-2{list-style-type:none}ul.lst-kix_a42anijqpp8a-5{list-style-type:none}ul.lst-kix_a42anijqpp8a-4{list-style-type:none}ul.lst-kix_a42anijqpp8a-7{list-style-type:none}ul.lst-kix_a42anijqpp8a-6{list-style-type:none}ol.lst-kix_52jgzw489fhs-1.start{counter-reset:lst-ctn-kix_52jgzw489fhs-1 0}.lst-kix_x96zthrcdy1e-3>li:before{content:"-  "}ul.lst-kix_22zpsclbl6ju-8{list-style-type:none}ol.lst-kix_u8nobwiguyj1-8.start{counter-reset:lst-ctn-kix_u8nobwiguyj1-8 0}ul.lst-kix_a42anijqpp8a-8{list-style-type:none}ul.lst-kix_22zpsclbl6ju-4{list-style-type:none}ul.lst-kix_22zpsclbl6ju-5{list-style-type:none}ul.lst-kix_22zpsclbl6ju-6{list-style-type:none}ul.lst-kix_22zpsclbl6ju-7{list-style-type:none}ul.lst-kix_22zpsclbl6ju-0{list-style-type:none}ul.lst-kix_22zpsclbl6ju-1{list-style-type:none}ul.lst-kix_22zpsclbl6ju-2{list-style-type:none}.lst-kix_brqn5pq4e7i7-2>li:before{content:"-  "}ul.lst-kix_22zpsclbl6ju-3{list-style-type:none}.lst-kix_5stj9b6acoxv-3>li{counter-increment:lst-ctn-kix_5stj9b6acoxv-3}ul.lst-kix_n9q8wqas57a-3{list-style-type:none}ul.lst-kix_n9q8wqas57a-2{list-style-type:none}ul.lst-kix_n9q8wqas57a-1{list-style-type:none}ul.lst-kix_n9q8wqas57a-0{list-style-type:none}ul.lst-kix_n9q8wqas57a-7{list-style-type:none}ul.lst-kix_n9q8wqas57a-6{list-style-type:none}ul.lst-kix_n9q8wqas57a-5{list-style-type:none}ul.lst-kix_n9q8wqas57a-4{list-style-type:none}.lst-kix_wf1o55flzq55-5>li:before{content:"-  "}.lst-kix_p11gr83hik0e-4>li:before{content:"-  "}.lst-kix_awlaex77cpwh-8>li:before{content:"-  "}.lst-kix_38p7uzj3qds3-8>li:before{content:"-  "}ul.lst-kix_n9q8wqas57a-8{list-style-type:none}.lst-kix_3bnqwg68tpm3-5>li:before{content:"-  "}.lst-kix_f83agu4s4fw5-2>li:before{content:"-  "}ul.lst-kix_hc732m8hksyq-7{list-style-type:none}ul.lst-kix_hc732m8hksyq-8{list-style-type:none}.lst-kix_pxpm44v9ngyu-1>li:before{content:"-  "}.lst-kix_pxpm44v9ngyu-4>li:before{content:"-  "}.lst-kix_p1rtf0e14360-8>li:before{content:"-  "}ul.lst-kix_hc732m8hksyq-0{list-style-type:none}ul.lst-kix_hc732m8hksyq-1{list-style-type:none}.lst-kix_hyuyjld7ihkv-6>li:before{content:"-  "}ul.lst-kix_hc732m8hksyq-2{list-style-type:none}ul.lst-kix_hc732m8hksyq-3{list-style-type:none}ul.lst-kix_hc732m8hksyq-4{list-style-type:none}ul.lst-kix_hc732m8hksyq-5{list-style-type:none}ul.lst-kix_hc732m8hksyq-6{list-style-type:none}.lst-kix_3bnqwg68tpm3-2>li:before{content:"-  "}.lst-kix_vuz55xpe5xjl-0>li:before{content:"-  "}.lst-kix_pejjsijavmae-1>li:before{content:"-  "}ul.lst-kix_oc7itsrfkmqv-0{list-style-type:none}ul.lst-kix_ug10x97qcpi8-5{list-style-type:none}ul.lst-kix_ug10x97qcpi8-6{list-style-type:none}.lst-kix_vkdxjlf0kb6j-4>li:before{content:"" counter(lst-ctn-kix_vkdxjlf0kb6j-4,lower-latin) ". "}ul.lst-kix_ug10x97qcpi8-7{list-style-type:none}.lst-kix_onvme58enb43-5>li:before{content:"-  "}ul.lst-kix_ug10x97qcpi8-8{list-style-type:none}.lst-kix_g47hwi8ilj0t-0>li:before{content:"-  "}ul.lst-kix_ug10x97qcpi8-1{list-style-type:none}.lst-kix_6xh4bfg7mbxi-4>li:before{content:"-  "}ol.lst-kix_2foc6u9lzfq4-1.start{counter-reset:lst-ctn-kix_2foc6u9lzfq4-1 0}ul.lst-kix_ug10x97qcpi8-2{list-style-type:none}ul.lst-kix_ug10x97qcpi8-3{list-style-type:none}ul.lst-kix_ug10x97qcpi8-4{list-style-type:none}.lst-kix_vkdxjlf0kb6j-7>li:before{content:"" counter(lst-ctn-kix_vkdxjlf0kb6j-7,lower-latin) ". "}ul.lst-kix_ug10x97qcpi8-0{list-style-type:none}.lst-kix_ypd5gkkarijk-0>li:before{content:"" counter(lst-ctn-kix_ypd5gkkarijk-0,lower-latin) ") "}.lst-kix_3novkjnl93sa-8>li:before{content:"-  "}.lst-kix_6xh4bfg7mbxi-1>li:before{content:"-  "}.lst-kix_3novkjnl93sa-5>li:before{content:"-  "}.lst-kix_p1rtf0e14360-5>li:before{content:"-  "}.lst-kix_wlyv8o88ksmk-5>li:before{content:"-  "}.lst-kix_66ns622ckygr-2>li:before{content:"-  "}.lst-kix_fifu4bguh6qm-1>li:before{content:"-  "}.lst-kix_1pt1eqcq4ieh-6>li:before{content:"-  "}.lst-kix_w32pgwk3f0lb-3>li:before{content:"-  "}.lst-kix_gerk886qza0c-2>li:before{content:"-  "}.lst-kix_1kbilie4yf3o-1>li:before{content:"-  "}ol.lst-kix_u8nobwiguyj1-3{list-style-type:none}ol.lst-kix_u8nobwiguyj1-4{list-style-type:none}.lst-kix_73pnq2b8bo4n-1>li:before{content:"-  "}.lst-kix_7cboi17aj4i3-2>li:before{content:"-  "}ol.lst-kix_u8nobwiguyj1-1{list-style-type:none}ol.lst-kix_u8nobwiguyj1-2{list-style-type:none}ul.lst-kix_rf3bfhvmysmh-8{list-style-type:none}ol.lst-kix_u8nobwiguyj1-0{list-style-type:none}ul.lst-kix_rf3bfhvmysmh-5{list-style-type:none}ul.lst-kix_rf3bfhvmysmh-4{list-style-type:none}ul.lst-kix_rf3bfhvmysmh-7{list-style-type:none}.lst-kix_fifu4bguh6qm-4>li:before{content:"-  "}ul.lst-kix_rf3bfhvmysmh-6{list-style-type:none}ul.lst-kix_rf3bfhvmysmh-1{list-style-type:none}.lst-kix_w32pgwk3f0lb-6>li:before{content:"-  "}ul.lst-kix_rf3bfhvmysmh-0{list-style-type:none}ul.lst-kix_rf3bfhvmysmh-3{list-style-type:none}ul.lst-kix_rf3bfhvmysmh-2{list-style-type:none}ul.lst-kix_oc7itsrfkmqv-1{list-style-type:none}ul.lst-kix_oc7itsrfkmqv-2{list-style-type:none}ul.lst-kix_oc7itsrfkmqv-3{list-style-type:none}.lst-kix_14k5lhtsu41k-1>li:before{content:"-  "}ul.lst-kix_oc7itsrfkmqv-4{list-style-type:none}ul.lst-kix_oc7itsrfkmqv-5{list-style-type:none}.lst-kix_4ypcpsaj0q6h-2>li:before{content:"-  "}ul.lst-kix_oc7itsrfkmqv-6{list-style-type:none}ul.lst-kix_oc7itsrfkmqv-7{list-style-type:none}ul.lst-kix_oc7itsrfkmqv-8{list-style-type:none}.lst-kix_q8c17lyf7k0c-1>li:before{content:"-  "}ol.lst-kix_u8nobwiguyj1-7{list-style-type:none}.lst-kix_14k5lhtsu41k-4>li:before{content:"-  "}ol.lst-kix_vgg0538grxk3-1.start{counter-reset:lst-ctn-kix_vgg0538grxk3-1 0}ol.lst-kix_u8nobwiguyj1-8{list-style-type:none}ol.lst-kix_u8nobwiguyj1-5{list-style-type:none}ol.lst-kix_u8nobwiguyj1-6{list-style-type:none}.lst-kix_vayf18aqt55o-6>li{counter-increment:lst-ctn-kix_vayf18aqt55o-6}.lst-kix_gerk886qza0c-5>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-8>li:before{content:"" counter(lst-ctn-kix_ysfu1bl0kymd-8,lower-roman) ". "}.lst-kix_m3u7mfewl2ow-6>li:before{content:"-  "}.lst-kix_52jgzw489fhs-6>li{counter-increment:lst-ctn-kix_52jgzw489fhs-6}.lst-kix_ikdz4hpyto9o-0>li:before{content:"-  "}.lst-kix_6217r3mhjywx-5>li:before{content:"-  "}.lst-kix_84zf7o74c8s9-5>li:before{content:"(" counter(lst-ctn-kix_84zf7o74c8s9-5,lower-roman) ") "}ul.lst-kix_qqbjjwnrc3l8-0{list-style-type:none}ul.lst-kix_qqbjjwnrc3l8-1{list-style-type:none}ul.lst-kix_qqbjjwnrc3l8-2{list-style-type:none}.lst-kix_qqbjjwnrc3l8-5>li:before{content:"-  "}ul.lst-kix_qqbjjwnrc3l8-3{list-style-type:none}.lst-kix_xhhdon4tpeu0-4>li:before{content:"-  "}ul.lst-kix_qqbjjwnrc3l8-4{list-style-type:none}.lst-kix_3ug9en49p7ih-2>li:before{content:"-  "}ul.lst-kix_qqbjjwnrc3l8-5{list-style-type:none}ul.lst-kix_qqbjjwnrc3l8-6{list-style-type:none}.lst-kix_ht80gp8jxjfs-3>li:before{content:"-  "}ul.lst-kix_qqbjjwnrc3l8-7{list-style-type:none}ul.lst-kix_qqbjjwnrc3l8-8{list-style-type:none}.lst-kix_g1rm1ujfok3h-6>li:before{content:"-  "}.lst-kix_66ns622ckygr-5>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-4>li{counter-increment:lst-ctn-kix_sxixw4iqsgzx-4}.lst-kix_x96zthrcdy1e-0>li:before{content:"-  "}ol.lst-kix_azgj6sn0lxuj-2.start{counter-reset:lst-ctn-kix_azgj6sn0lxuj-2 0}.lst-kix_5ze5xofgghz2-5>li:before{content:"-  "}.lst-kix_wsu1hpz6hqq4-5>li:before{content:"-  "}.lst-kix_pv4jsz2h74wk-6>li:before{content:"-  "}.lst-kix_wzt7symqmcfu-6>li:before{content:"-  "}ol.lst-kix_sxixw4iqsgzx-7.start{counter-reset:lst-ctn-kix_sxixw4iqsgzx-7 0}.lst-kix_bdjoj2nf5hw9-1>li:before{content:"-  "}.lst-kix_549l9aqx2sdy-0>li:before{content:"-  "}.lst-kix_pgnpvlxhai6o-3>li:before{content:"-  "}.lst-kix_38p7uzj3qds3-5>li:before{content:"-  "}.lst-kix_p11gr83hik0e-1>li:before{content:"-  "}ol.lst-kix_3mj3tp7kj9db-4.start{counter-reset:lst-ctn-kix_3mj3tp7kj9db-4 0}.lst-kix_vkdxjlf0kb6j-7>li{counter-increment:lst-ctn-kix_vkdxjlf0kb6j-7}.lst-kix_bo9wrgz88es4-3>li:before{content:"-  "}.lst-kix_3wddikkjnk2k-4>li:before{content:"-  "}.lst-kix_rgd2g4si1ihs-7>li:before{content:"-  "}.lst-kix_g2uanok8rp1g-8>li:before{content:"-  "}.lst-kix_r8adx85jg0iz-8>li:before{content:"-  "}.lst-kix_bo9wrgz88es4-0>li:before{content:"-  "}.lst-kix_s0nbf6s2np44-7>li:before{content:"-  "}.lst-kix_ms6rbzn59hmq-1>li:before{content:"-  "}.lst-kix_b7rulpv7obgl-8>li:before{content:"-  "}.lst-kix_3wddikkjnk2k-1>li:before{content:"-  "}ol.lst-kix_g8jgbze430sv-8.start{counter-reset:lst-ctn-kix_g8jgbze430sv-8 0}ol.lst-kix_vayf18aqt55o-4.start{counter-reset:lst-ctn-kix_vayf18aqt55o-4 0}.lst-kix_g9hblcm1l6tk-1>li:before{content:"-  "}.lst-kix_g2uanok8rp1g-5>li:before{content:"-  "}.lst-kix_rgd2g4si1ihs-4>li:before{content:"-  "}.lst-kix_bp67ajcb7c38-7>li:before{content:"-  "}.lst-kix_rgd2g4si1ihs-1>li:before{content:"-  "}.lst-kix_7e64bsb5krip-6>li:before{content:"-  "}.lst-kix_bo9wrgz88es4-6>li:before{content:"-  "}.lst-kix_wiijpxq0m5a-4>li:before{content:"-  "}.lst-kix_x1n4jlo0gf1q-6>li:before{content:"-  "}.lst-kix_wiijpxq0m5a-7>li:before{content:"-  "}.lst-kix_vvjhovkzyen7-2>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-3>li{counter-increment:lst-ctn-kix_d1gy3hy5r3qj-3}.lst-kix_4pjeuglo4z6v-0>li:before{content:"-  "}.lst-kix_2xixyk6jteti-0>li:before{content:"-  "}ol.lst-kix_azgj6sn0lxuj-6.start{counter-reset:lst-ctn-kix_azgj6sn0lxuj-6 0}.lst-kix_ce3ho29dhteb-4>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-3>li{counter-increment:lst-ctn-kix_2foc6u9lzfq4-3}.lst-kix_g0lr2dxtnslc-5>li:before{content:"-  "}.lst-kix_nqtgcebhe8ii-6>li:before{content:"-  "}.lst-kix_skgpgvhmuoc4-8>li:before{content:"-  "}.lst-kix_ce3ho29dhteb-7>li:before{content:"-  "}.lst-kix_g0lr2dxtnslc-2>li:before{content:"-  "}.lst-kix_7vaamq35f1cc-4>li:before{content:"-  "}.lst-kix_zb3jq278pptw-7>li:before{content:"-  "}.lst-kix_3koi1cw13a0-8>li:before{content:"-  "}.lst-kix_2xixyk6jteti-3>li:before{content:"-  "}ul.lst-kix_3ug9en49p7ih-8{list-style-type:none}ul.lst-kix_3ug9en49p7ih-7{list-style-type:none}ul.lst-kix_3ug9en49p7ih-6{list-style-type:none}ul.lst-kix_3ug9en49p7ih-5{list-style-type:none}ul.lst-kix_rp6rf03vbelo-8{list-style-type:none}ul.lst-kix_3ug9en49p7ih-4{list-style-type:none}ul.lst-kix_rp6rf03vbelo-7{list-style-type:none}ul.lst-kix_3ug9en49p7ih-3{list-style-type:none}ul.lst-kix_rp6rf03vbelo-6{list-style-type:none}.lst-kix_zb3jq278pptw-4>li:before{content:"-  "}ul.lst-kix_3ug9en49p7ih-2{list-style-type:none}ul.lst-kix_rp6rf03vbelo-5{list-style-type:none}.lst-kix_9j3np3ow732h-5>li:before{content:"\0025a0   "}ul.lst-kix_3ug9en49p7ih-1{list-style-type:none}ul.lst-kix_rp6rf03vbelo-4{list-style-type:none}ul.lst-kix_3ug9en49p7ih-0{list-style-type:none}.lst-kix_g0lr2dxtnslc-8>li:before{content:"-  "}.lst-kix_r8adx85jg0iz-5>li:before{content:"-  "}.lst-kix_9j3np3ow732h-2>li:before{content:"\0025a0   "}ol.lst-kix_84zf7o74c8s9-6.start{counter-reset:lst-ctn-kix_84zf7o74c8s9-6 0}ul.lst-kix_rp6rf03vbelo-3{list-style-type:none}ul.lst-kix_rp6rf03vbelo-2{list-style-type:none}ul.lst-kix_rp6rf03vbelo-1{list-style-type:none}ul.lst-kix_rp6rf03vbelo-0{list-style-type:none}.lst-kix_kobinbwr4qr6-0>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-3>li{counter-increment:lst-ctn-kix_ok1n37qarjzb-3}ol.lst-kix_ysfu1bl0kymd-8.start{counter-reset:lst-ctn-kix_ysfu1bl0kymd-8 0}.lst-kix_pgnpvlxhai6o-0>li:before{content:"-  "}.lst-kix_qb494lue4ahb-3>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-3>li{counter-increment:lst-ctn-kix_yjf6dvvoob64-3}.lst-kix_ld6rwbdri49-3>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-7>li:before{content:"" counter(lst-ctn-kix_3mj3tp7kj9db-7,lower-latin) ". "}.lst-kix_innl5fto9oyf-5>li:before{content:"-  "}.lst-kix_xyra4e5ffsud-3>li{counter-increment:lst-ctn-kix_xyra4e5ffsud-3}.lst-kix_incqcf2p39ls-1>li{counter-increment:lst-ctn-kix_incqcf2p39ls-1}.lst-kix_qqbjjwnrc3l8-2>li:before{content:"-  "}.lst-kix_3q7au8a3gwav-1>li:before{content:"-  "}.lst-kix_3ug9en49p7ih-5>li:before{content:"-  "}.lst-kix_oswsfzrgbvyb-8>li:before{content:"-  "}.lst-kix_4z9ptm6a4lke-4>li:before{content:"-  "}.lst-kix_a62ncfcuapzo-8>li:before{content:"-  "}ol.lst-kix_ypd5gkkarijk-2.start{counter-reset:lst-ctn-kix_ypd5gkkarijk-2 0}.lst-kix_90bg3luq5inv-0>li{counter-increment:lst-ctn-kix_90bg3luq5inv-0}.lst-kix_ksf6p4xm2w0d-0>li:before{content:"-  "}.lst-kix_5quy3fbj2mfg-2>li:before{content:"-  "}ol.lst-kix_g8jgbze430sv-6.start{counter-reset:lst-ctn-kix_g8jgbze430sv-6 0}ul.lst-kix_cmm6cscyrjti-8{list-style-type:none}ul.lst-kix_cmm6cscyrjti-7{list-style-type:none}ul.lst-kix_cmm6cscyrjti-6{list-style-type:none}ul.lst-kix_cmm6cscyrjti-5{list-style-type:none}ul.lst-kix_cmm6cscyrjti-4{list-style-type:none}.lst-kix_5ze5xofgghz2-8>li:before{content:"-  "}ul.lst-kix_cmm6cscyrjti-3{list-style-type:none}ul.lst-kix_cmm6cscyrjti-2{list-style-type:none}ul.lst-kix_cmm6cscyrjti-1{list-style-type:none}ul.lst-kix_cmm6cscyrjti-0{list-style-type:none}.lst-kix_267f3xfv5ddr-1>li{counter-increment:lst-ctn-kix_267f3xfv5ddr-1}.lst-kix_chbthqdwx7gj-0>li:before{content:"-  "}.lst-kix_chbthqdwx7gj-6>li:before{content:"-  "}.lst-kix_iefjrs8t42tr-2>li:before{content:"-  "}.lst-kix_5quy3fbj2mfg-8>li:before{content:"-  "}.lst-kix_khixc8f7o03u-7>li:before{content:"-  "}.lst-kix_c73c2x77meqo-2>li:before{content:"-  "}ol.lst-kix_ysfu1bl0kymd-6.start{counter-reset:lst-ctn-kix_ysfu1bl0kymd-6 0}.lst-kix_pg2i9lis4p1v-2>li:before{content:"-  "}.lst-kix_5argtotmwusw-1>li:before{content:"-  "}.lst-kix_mvektlca5c5q-2>li:before{content:"-  "}.lst-kix_om0x63wgf9wd-7>li:before{content:"-  "}.lst-kix_8nwtyhgsvjlm-7>li:before{content:"-  "}ul.lst-kix_fhtxrv3nkyi7-5{list-style-type:none}ul.lst-kix_fhtxrv3nkyi7-4{list-style-type:none}ul.lst-kix_fhtxrv3nkyi7-7{list-style-type:none}ul.lst-kix_fhtxrv3nkyi7-6{list-style-type:none}ul.lst-kix_fhtxrv3nkyi7-1{list-style-type:none}ul.lst-kix_fhtxrv3nkyi7-0{list-style-type:none}ul.lst-kix_fhtxrv3nkyi7-3{list-style-type:none}.lst-kix_tjrvr4c0ezjq-5>li:before{content:"-  "}ul.lst-kix_fhtxrv3nkyi7-2{list-style-type:none}.lst-kix_wsu1hpz6hqq4-2>li:before{content:"-  "}ul.lst-kix_fhtxrv3nkyi7-8{list-style-type:none}.lst-kix_r8i1fgeyliey-8>li:before{content:"-  "}.lst-kix_rtczm6eelr4h-0>li:before{content:"-  "}.lst-kix_iefjrs8t42tr-8>li:before{content:"-  "}.lst-kix_bdjoj2nf5hw9-4>li:before{content:"-  "}.lst-kix_8nwtyhgsvjlm-1>li:before{content:"-  "}ul.lst-kix_w21i9d12ynhg-8{list-style-type:none}ul.lst-kix_w21i9d12ynhg-6{list-style-type:none}ul.lst-kix_w21i9d12ynhg-7{list-style-type:none}ul.lst-kix_w21i9d12ynhg-4{list-style-type:none}ul.lst-kix_w21i9d12ynhg-5{list-style-type:none}ul.lst-kix_w21i9d12ynhg-2{list-style-type:none}ul.lst-kix_w21i9d12ynhg-3{list-style-type:none}ul.lst-kix_w21i9d12ynhg-0{list-style-type:none}ul.lst-kix_w21i9d12ynhg-1{list-style-type:none}.lst-kix_dynlpr2uwt2p-0>li:before{content:"-  "}.lst-kix_vie3q5oyli2z-6>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-2>li:before{content:"" counter(lst-ctn-kix_ykhoydml7pv3-2,lower-roman) ") "}.lst-kix_dyq7vlcdkqm5-7>li:before{content:"-  "}ul.lst-kix_ivmzvkm69gsd-2{list-style-type:none}ul.lst-kix_ivmzvkm69gsd-3{list-style-type:none}ul.lst-kix_ivmzvkm69gsd-4{list-style-type:none}ul.lst-kix_ivmzvkm69gsd-5{list-style-type:none}.lst-kix_dyq7vlcdkqm5-4>li:before{content:"-  "}ul.lst-kix_ivmzvkm69gsd-6{list-style-type:none}ul.lst-kix_ivmzvkm69gsd-7{list-style-type:none}ul.lst-kix_ivmzvkm69gsd-8{list-style-type:none}.lst-kix_of5ud22cn0qg-0>li:before{content:"-  "}.lst-kix_cpgerodpupjz-8>li:before{content:"-  "}.lst-kix_dn04c4yafie0-2>li:before{content:"-  "}ul.lst-kix_ivmzvkm69gsd-0{list-style-type:none}ul.lst-kix_ivmzvkm69gsd-1{list-style-type:none}ul.lst-kix_tpw8rt3jm7dt-0{list-style-type:none}.lst-kix_1pt1eqcq4ieh-3>li:before{content:"-  "}.lst-kix_jnfn9mx5o33t-3>li:before{content:"-  "}.lst-kix_fs1lzw38maxl-3>li:before{content:"-  "}.lst-kix_urqiwn6svi1d-6>li:before{content:"-  "}.lst-kix_fifu4bguh6qm-7>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-0>li:before{content:"" counter(lst-ctn-kix_u8nobwiguyj1-0,decimal) ") "}.lst-kix_tnd0p97rqwub-1>li:before{content:"-  "}.lst-kix_wfyz8rmi0iq4-1>li:before{content:"-  "}ul.lst-kix_tpw8rt3jm7dt-4{list-style-type:none}ul.lst-kix_tpw8rt3jm7dt-3{list-style-type:none}ul.lst-kix_tpw8rt3jm7dt-2{list-style-type:none}.lst-kix_rxmcp67o7upe-8>li:before{content:"-  "}ul.lst-kix_tpw8rt3jm7dt-1{list-style-type:none}ul.lst-kix_tpw8rt3jm7dt-8{list-style-type:none}ul.lst-kix_tpw8rt3jm7dt-7{list-style-type:none}ul.lst-kix_tpw8rt3jm7dt-6{list-style-type:none}.lst-kix_b3ghc04lfx9t-2>li:before{content:"-  "}ul.lst-kix_tpw8rt3jm7dt-5{list-style-type:none}.lst-kix_x2lkon80l30j-7>li:before{content:"-  "}ul.lst-kix_p2dhxl6hicde-8{list-style-type:none}ul.lst-kix_p2dhxl6hicde-7{list-style-type:none}ul.lst-kix_p2dhxl6hicde-6{list-style-type:none}ul.lst-kix_p2dhxl6hicde-5{list-style-type:none}ul.lst-kix_p2dhxl6hicde-4{list-style-type:none}ul.lst-kix_p2dhxl6hicde-3{list-style-type:none}ul.lst-kix_p2dhxl6hicde-2{list-style-type:none}ul.lst-kix_p2dhxl6hicde-1{list-style-type:none}ul.lst-kix_p2dhxl6hicde-0{list-style-type:none}.lst-kix_cd2o0cncsajm-4>li:before{content:"-  "}.lst-kix_fm53cr9wmch0-4>li:before{content:"-  "}.lst-kix_6nc1nfac2wub-1>li:before{content:"-  "}.lst-kix_vayf18aqt55o-0>li{counter-increment:lst-ctn-kix_vayf18aqt55o-0}ol.lst-kix_ypd5gkkarijk-0.start{counter-reset:lst-ctn-kix_ypd5gkkarijk-0 0}.lst-kix_6nc1nfac2wub-4>li:before{content:"-  "}.lst-kix_t9t3ckq2i2hz-3>li:before{content:"-  "}.lst-kix_tnd0p97rqwub-4>li:before{content:"-  "}.lst-kix_zag3ymt8mk2y-7>li:before{content:"-  "}.lst-kix_9z31rmzc855z-5>li:before{content:"-  "}.lst-kix_t9t3ckq2i2hz-0>li:before{content:"-  "}.lst-kix_wlyv8o88ksmk-2>li:before{content:"-  "}ol.lst-kix_vayf18aqt55o-2.start{counter-reset:lst-ctn-kix_vayf18aqt55o-2 0}.lst-kix_oswsfzrgbvyb-5>li:before{content:"-  "}.lst-kix_ld6rwbdri49-0>li:before{content:"-  "}.lst-kix_k5hm652wcnm2-6>li:before{content:"-  "}.lst-kix_qb494lue4ahb-6>li:before{content:"-  "}.lst-kix_8w7txqc6xq66-4>li:before{content:"-  "}.lst-kix_mq980hprr5hl-1>li:before{content:"-  "}.lst-kix_a62ncfcuapzo-5>li:before{content:"-  "}.lst-kix_innl5fto9oyf-2>li:before{content:"-  "}.lst-kix_3ug9en49p7ih-8>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-4>li:before{content:"(" counter(lst-ctn-kix_3mj3tp7kj9db-4,lower-latin) ") "}ul.lst-kix_549l9aqx2sdy-0{list-style-type:none}ul.lst-kix_549l9aqx2sdy-1{list-style-type:none}ul.lst-kix_549l9aqx2sdy-2{list-style-type:none}ul.lst-kix_549l9aqx2sdy-3{list-style-type:none}ul.lst-kix_549l9aqx2sdy-4{list-style-type:none}ul.lst-kix_549l9aqx2sdy-5{list-style-type:none}ul.lst-kix_549l9aqx2sdy-6{list-style-type:none}ul.lst-kix_549l9aqx2sdy-7{list-style-type:none}ul.lst-kix_549l9aqx2sdy-8{list-style-type:none}ul.lst-kix_ny5e869gaylo-2{list-style-type:none}ul.lst-kix_wrdk3q33keus-3{list-style-type:none}ul.lst-kix_ny5e869gaylo-1{list-style-type:none}ul.lst-kix_wrdk3q33keus-4{list-style-type:none}ul.lst-kix_ny5e869gaylo-0{list-style-type:none}ul.lst-kix_wrdk3q33keus-1{list-style-type:none}ul.lst-kix_wrdk3q33keus-2{list-style-type:none}ul.lst-kix_ny5e869gaylo-6{list-style-type:none}ul.lst-kix_wrdk3q33keus-7{list-style-type:none}ul.lst-kix_ny5e869gaylo-5{list-style-type:none}ul.lst-kix_wrdk3q33keus-8{list-style-type:none}ul.lst-kix_ny5e869gaylo-4{list-style-type:none}ul.lst-kix_wrdk3q33keus-5{list-style-type:none}ul.lst-kix_ny5e869gaylo-3{list-style-type:none}ul.lst-kix_wrdk3q33keus-6{list-style-type:none}.lst-kix_vayf18aqt55o-4>li:before{content:"(" counter(lst-ctn-kix_vayf18aqt55o-4,lower-roman) ") "}ul.lst-kix_ny5e869gaylo-8{list-style-type:none}.lst-kix_tlnfkrylyq1a-3>li:before{content:"-  "}ul.lst-kix_ny5e869gaylo-7{list-style-type:none}.lst-kix_6n4varno3bjs-6>li:before{content:"-  "}ul.lst-kix_wrdk3q33keus-0{list-style-type:none}.lst-kix_fnlxcectz7fi-0>li:before{content:"-  "}.lst-kix_4z9ptm6a4lke-1>li:before{content:"-  "}.lst-kix_x1xhkkpc69w2-7>li:before{content:"-  "}.lst-kix_rtczm6eelr4h-3>li:before{content:"-  "}ol.lst-kix_3fc7x0lm2mmz-1.start{counter-reset:lst-ctn-kix_3fc7x0lm2mmz-1 0}.lst-kix_7rlftcume51v-2>li:before{content:"-  "}.lst-kix_om0x63wgf9wd-4>li:before{content:"-  "}.lst-kix_ms4jfr9nudpc-6>li:before{content:"-  "}.lst-kix_chbthqdwx7gj-3>li:before{content:"-  "}.lst-kix_wf1o55flzq55-8>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-7>li{counter-increment:lst-ctn-kix_ypd5gkkarijk-7}.lst-kix_5quy3fbj2mfg-5>li:before{content:"-  "}.lst-kix_qmryaqe19okh-0>li:before{content:"-  "}.lst-kix_hssoi9jbujv-0>li:before{content:"-  "}.lst-kix_8nwtyhgsvjlm-4>li:before{content:"-  "}.lst-kix_bdjoj2nf5hw9-7>li:before{content:"-  "}.lst-kix_f83agu4s4fw5-5>li:before{content:"-  "}.lst-kix_iefjrs8t42tr-5>li:before{content:"-  "}.lst-kix_f2t507a7xjue-1>li:before{content:"-  "}.lst-kix_90bg3luq5inv-6>li{counter-increment:lst-ctn-kix_90bg3luq5inv-6}.lst-kix_bnte1i3g4kjh-1>li:before{content:"-  "}.lst-kix_4i10vbfgn91y-6>li:before{content:"-  "}ul.lst-kix_f4168mxvziu2-6{list-style-type:none}ul.lst-kix_f4168mxvziu2-5{list-style-type:none}ul.lst-kix_f4168mxvziu2-4{list-style-type:none}ul.lst-kix_f4168mxvziu2-3{list-style-type:none}.lst-kix_yrg2qlcqvak1-4>li:before{content:"-  "}.lst-kix_1v1216yy0n25-7>li:before{content:"-  "}ul.lst-kix_f4168mxvziu2-2{list-style-type:none}.lst-kix_2r20t3tmnrwb-5>li:before{content:"-  "}ul.lst-kix_f4168mxvziu2-1{list-style-type:none}ul.lst-kix_f4168mxvziu2-0{list-style-type:none}.lst-kix_ofib0hkczw41-1>li:before{content:"-  "}ul.lst-kix_f4168mxvziu2-8{list-style-type:none}ul.lst-kix_f4168mxvziu2-7{list-style-type:none}ul.lst-kix_brqn5pq4e7i7-4{list-style-type:none}.lst-kix_6o2cphkh2n8b-7>li:before{content:"-  "}ul.lst-kix_brqn5pq4e7i7-5{list-style-type:none}ul.lst-kix_brqn5pq4e7i7-2{list-style-type:none}ul.lst-kix_brqn5pq4e7i7-3{list-style-type:none}ul.lst-kix_brqn5pq4e7i7-0{list-style-type:none}ul.lst-kix_brqn5pq4e7i7-1{list-style-type:none}ol.lst-kix_xktbtduo53bq-5.start{counter-reset:lst-ctn-kix_xktbtduo53bq-5 0}.lst-kix_ul22dko4fd2j-4>li:before{content:"-  "}.lst-kix_ug10x97qcpi8-6>li:before{content:"-  "}ol.lst-kix_xyra4e5ffsud-7.start{counter-reset:lst-ctn-kix_xyra4e5ffsud-7 0}.lst-kix_3mj3tp7kj9db-2>li{counter-increment:lst-ctn-kix_3mj3tp7kj9db-2}.lst-kix_qw2h6jd8xi17-5>li:before{content:"-  "}ul.lst-kix_brqn5pq4e7i7-8{list-style-type:none}.lst-kix_n9q8wqas57a-8>li:before{content:"-  "}ul.lst-kix_brqn5pq4e7i7-6{list-style-type:none}ul.lst-kix_brqn5pq4e7i7-7{list-style-type:none}.lst-kix_3nq914pozpi7-6>li:before{content:"-  "}.lst-kix_8ujam3zhcr3q-0>li:before{content:"-  "}.lst-kix_3nq914pozpi7-2>li:before{content:"-  "}ul.lst-kix_3qppsihuuk4z-2{list-style-type:none}ul.lst-kix_3qppsihuuk4z-3{list-style-type:none}ul.lst-kix_3qppsihuuk4z-0{list-style-type:none}ul.lst-kix_3qppsihuuk4z-1{list-style-type:none}.lst-kix_eme1x4epzdye-1>li:before{content:"-  "}.lst-kix_tt1bo8z9re67-2>li:before{content:"-  "}.lst-kix_gaq1zvh4dcgb-1>li:before{content:"-  "}.lst-kix_vkdxjlf0kb6j-5>li{counter-increment:lst-ctn-kix_vkdxjlf0kb6j-5}.lst-kix_qw2h6jd8xi17-1>li:before{content:"-  "}.lst-kix_hmvj5t8yy8bx-2>li:before{content:"+  "}.lst-kix_n9q8wqas57a-0>li:before{content:"-  "}ol.lst-kix_u8nobwiguyj1-6.start{counter-reset:lst-ctn-kix_u8nobwiguyj1-6 0}.lst-kix_vayf18aqt55o-8>li:before{content:"" counter(lst-ctn-kix_vayf18aqt55o-8,decimal) ". "}.lst-kix_aor1182clqbr-8>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-5>li{counter-increment:lst-ctn-kix_azgj6sn0lxuj-5}.lst-kix_aor1182clqbr-4>li:before{content:"-  "}.lst-kix_lwlxuymndfyq-7>li:before{content:"-  "}ol.lst-kix_3mj3tp7kj9db-1.start{counter-reset:lst-ctn-kix_3mj3tp7kj9db-1 0}.lst-kix_4qbfcta6cclt-4>li:before{content:"-  "}.lst-kix_tdrf79x9zyr7-1>li:before{content:"-  "}.lst-kix_yrg2qlcqvak1-0>li:before{content:"-  "}.lst-kix_1v1216yy0n25-3>li:before{content:"-  "}.lst-kix_q24qpifeknc3-1>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-6>li{counter-increment:lst-ctn-kix_3fc7x0lm2mmz-6}.lst-kix_o1voy78o4juz-6>li:before{content:"-  "}.lst-kix_5nilpkhthb5t-0>li:before{content:"-  "}.lst-kix_xktbtduo53bq-3>li{counter-increment:lst-ctn-kix_xktbtduo53bq-3}.lst-kix_ukx3y28hag8h-4>li:before{content:"-  "}.lst-kix_x95t913s41kt-5>li:before{content:"-  "}.lst-kix_axy5kxvo2nx7-0>li:before{content:"-  "}.lst-kix_9a7xq1ie41tp-6>li:before{content:"-  "}ul.lst-kix_mq980hprr5hl-7{list-style-type:none}ul.lst-kix_mq980hprr5hl-8{list-style-type:none}ul.lst-kix_mq980hprr5hl-5{list-style-type:none}ul.lst-kix_mq980hprr5hl-6{list-style-type:none}.lst-kix_hngwf7orguk6-3>li:before{content:"-  "}.lst-kix_co74fk70kphx-2>li:before{content:"-  "}.lst-kix_5nilpkhthb5t-4>li:before{content:"-  "}.lst-kix_q24qpifeknc3-5>li:before{content:"-  "}ul.lst-kix_mq980hprr5hl-0{list-style-type:none}.lst-kix_ukx3y28hag8h-8>li:before{content:"-  "}ul.lst-kix_mq980hprr5hl-3{list-style-type:none}ul.lst-kix_mq980hprr5hl-4{list-style-type:none}ul.lst-kix_mq980hprr5hl-1{list-style-type:none}ul.lst-kix_mq980hprr5hl-2{list-style-type:none}.lst-kix_ekasiajyrrvz-0>li:before{content:"-  "}ul.lst-kix_7o1va6u13ska-6{list-style-type:none}.lst-kix_x1xhkkpc69w2-6>li:before{content:"-  "}ul.lst-kix_7o1va6u13ska-5{list-style-type:none}ul.lst-kix_7o1va6u13ska-8{list-style-type:none}.lst-kix_vayf18aqt55o-2>li{counter-increment:lst-ctn-kix_vayf18aqt55o-2}ul.lst-kix_7o1va6u13ska-7{list-style-type:none}ul.lst-kix_7o1va6u13ska-2{list-style-type:none}ul.lst-kix_7o1va6u13ska-1{list-style-type:none}ul.lst-kix_7o1va6u13ska-4{list-style-type:none}.lst-kix_5stj9b6acoxv-8>li:before{content:"" counter(lst-ctn-kix_5stj9b6acoxv-8,lower-roman) ". "}ul.lst-kix_7o1va6u13ska-3{list-style-type:none}.lst-kix_njs8ubf1qesf-4>li:before{content:"-  "}ul.lst-kix_7o1va6u13ska-0{list-style-type:none}.lst-kix_rcfi5jnwnxji-0>li:before{content:"-  "}.lst-kix_njs8ubf1qesf-0>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-0.start{counter-reset:lst-ctn-kix_ok1n37qarjzb-0 0}.lst-kix_ellvdfsu2z7q-0>li:before{content:"-  "}.lst-kix_rcfi5jnwnxji-8>li:before{content:"-  "}.lst-kix_5stj9b6acoxv-0>li:before{content:"" counter(lst-ctn-kix_5stj9b6acoxv-0,decimal) ". "}.lst-kix_x12ed5cs6o9z-8>li:before{content:"-  "}.lst-kix_qmx92jmkghx8-6>li:before{content:"-  "}ul.lst-kix_eiskzjj27gc6-0{list-style-type:none}ul.lst-kix_eiskzjj27gc6-1{list-style-type:none}ul.lst-kix_eiskzjj27gc6-2{list-style-type:none}ul.lst-kix_eiskzjj27gc6-3{list-style-type:none}.lst-kix_hytfj9icha07-1>li:before{content:"-  "}ul.lst-kix_eiskzjj27gc6-4{list-style-type:none}.lst-kix_ellvdfsu2z7q-4>li:before{content:"-  "}ul.lst-kix_eiskzjj27gc6-5{list-style-type:none}ul.lst-kix_eiskzjj27gc6-6{list-style-type:none}ul.lst-kix_eiskzjj27gc6-7{list-style-type:none}ul.lst-kix_eiskzjj27gc6-8{list-style-type:none}ol.lst-kix_sxixw4iqsgzx-0.start{counter-reset:lst-ctn-kix_sxixw4iqsgzx-0 0}ul.lst-kix_i8kfgvsh0fwy-0{list-style-type:none}ul.lst-kix_i8kfgvsh0fwy-2{list-style-type:none}ul.lst-kix_i8kfgvsh0fwy-1{list-style-type:none}.lst-kix_5syfdd8x3l8s-5>li:before{content:"-  "}ul.lst-kix_i8kfgvsh0fwy-8{list-style-type:none}ul.lst-kix_i8kfgvsh0fwy-7{list-style-type:none}ul.lst-kix_i8kfgvsh0fwy-4{list-style-type:none}ul.lst-kix_i8kfgvsh0fwy-3{list-style-type:none}ul.lst-kix_i8kfgvsh0fwy-6{list-style-type:none}ul.lst-kix_i8kfgvsh0fwy-5{list-style-type:none}.lst-kix_yvohqcnu3146-4>li{counter-increment:lst-ctn-kix_yvohqcnu3146-4}.lst-kix_dynlpr2uwt2p-3>li:before{content:"-  "}.lst-kix_i2q40uf7647f-2>li:before{content:"-  "}ul.lst-kix_7o5enrj2ko1w-8{list-style-type:none}ul.lst-kix_7o5enrj2ko1w-7{list-style-type:none}ul.lst-kix_7o5enrj2ko1w-6{list-style-type:none}.lst-kix_ozrjmre97pex-3>li:before{content:"-  "}ul.lst-kix_7o5enrj2ko1w-5{list-style-type:none}.lst-kix_4ii5776egvw8-6>li:before{content:"-  "}ul.lst-kix_7o5enrj2ko1w-4{list-style-type:none}ul.lst-kix_7o5enrj2ko1w-3{list-style-type:none}ul.lst-kix_7o5enrj2ko1w-2{list-style-type:none}ul.lst-kix_m3u7mfewl2ow-2{list-style-type:none}ul.lst-kix_7o5enrj2ko1w-1{list-style-type:none}ul.lst-kix_m3u7mfewl2ow-3{list-style-type:none}ul.lst-kix_7o5enrj2ko1w-0{list-style-type:none}ul.lst-kix_m3u7mfewl2ow-0{list-style-type:none}ul.lst-kix_m3u7mfewl2ow-1{list-style-type:none}.lst-kix_l5iaj94ondn3-2>li:before{content:"-  "}ul.lst-kix_m3u7mfewl2ow-6{list-style-type:none}ul.lst-kix_m3u7mfewl2ow-7{list-style-type:none}ul.lst-kix_m3u7mfewl2ow-4{list-style-type:none}.lst-kix_mb1zrov3n6kx-2>li:before{content:"-  "}ul.lst-kix_m3u7mfewl2ow-5{list-style-type:none}ul.lst-kix_t6x6ie377r4u-0{list-style-type:none}ul.lst-kix_m3u7mfewl2ow-8{list-style-type:none}ul.lst-kix_t6x6ie377r4u-3{list-style-type:none}.lst-kix_pg2i9lis4p1v-4>li:before{content:"-  "}ul.lst-kix_t6x6ie377r4u-4{list-style-type:none}ul.lst-kix_t6x6ie377r4u-1{list-style-type:none}ul.lst-kix_t6x6ie377r4u-2{list-style-type:none}.lst-kix_x74x9xa8n5a0-6>li:before{content:"-  "}.lst-kix_4voxeic75vm5-1>li:before{content:"-  "}.lst-kix_1x319pprarxc-4>li:before{content:"-  "}.lst-kix_pg2i9lis4p1v-8>li:before{content:"-  "}ul.lst-kix_i7kvy3cw4vsq-6{list-style-type:none}ul.lst-kix_i7kvy3cw4vsq-7{list-style-type:none}ul.lst-kix_i7kvy3cw4vsq-8{list-style-type:none}ul.lst-kix_i7kvy3cw4vsq-2{list-style-type:none}ul.lst-kix_i7kvy3cw4vsq-3{list-style-type:none}.lst-kix_5rn2qrejqs3r-1>li:before{content:"-  "}ul.lst-kix_i7kvy3cw4vsq-4{list-style-type:none}.lst-kix_oxgbebk5l98i-1>li:before{content:"-  "}ul.lst-kix_i7kvy3cw4vsq-5{list-style-type:none}.lst-kix_wnr3c516ni7j-3>li:before{content:"-  "}ul.lst-kix_i7kvy3cw4vsq-0{list-style-type:none}.lst-kix_81v91kbrmywy-8>li:before{content:"-  "}ul.lst-kix_i7kvy3cw4vsq-1{list-style-type:none}.lst-kix_unv0ib1v43rp-1>li:before{content:"-  "}.lst-kix_ro388iryhhf5-2>li:before{content:"-  "}.lst-kix_g8jgbze430sv-4>li{counter-increment:lst-ctn-kix_g8jgbze430sv-4}.lst-kix_tagzs2njqau3-6>li:before{content:"-  "}.lst-kix_rxmcp67o7upe-6>li:before{content:"-  "}.lst-kix_8w03xjt2k9bc-1>li:before{content:"-  "}.lst-kix_eiskzjj27gc6-1>li:before{content:"-  "}ul.lst-kix_r6uhbskcwxv5-5{list-style-type:none}ul.lst-kix_8hvuzyuchy3p-2{list-style-type:none}.lst-kix_7o1va6u13ska-8>li:before{content:"-  "}ul.lst-kix_r6uhbskcwxv5-6{list-style-type:none}ul.lst-kix_8hvuzyuchy3p-1{list-style-type:none}ul.lst-kix_r6uhbskcwxv5-7{list-style-type:none}ul.lst-kix_8hvuzyuchy3p-0{list-style-type:none}ul.lst-kix_r6uhbskcwxv5-8{list-style-type:none}ul.lst-kix_r6uhbskcwxv5-1{list-style-type:none}ul.lst-kix_8hvuzyuchy3p-6{list-style-type:none}ul.lst-kix_r6uhbskcwxv5-2{list-style-type:none}ul.lst-kix_8hvuzyuchy3p-5{list-style-type:none}ul.lst-kix_r6uhbskcwxv5-3{list-style-type:none}ul.lst-kix_8hvuzyuchy3p-4{list-style-type:none}.lst-kix_d1gy3hy5r3qj-5>li:before{content:"(" counter(lst-ctn-kix_d1gy3hy5r3qj-5,lower-roman) ") "}ul.lst-kix_r6uhbskcwxv5-4{list-style-type:none}ul.lst-kix_8hvuzyuchy3p-3{list-style-type:none}.lst-kix_7o1va6u13ska-4>li:before{content:"-  "}.lst-kix_zag3ymt8mk2y-4>li:before{content:"-  "}.lst-kix_81v91kbrmywy-4>li:before{content:"-  "}.lst-kix_6vg5692ogph-3>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-1>li:before{content:"" counter(lst-ctn-kix_d1gy3hy5r3qj-1,lower-latin) ") "}.lst-kix_cg6jep1fmawj-3>li:before{content:"-  "}ul.lst-kix_8hvuzyuchy3p-8{list-style-type:none}ul.lst-kix_8hvuzyuchy3p-7{list-style-type:none}.lst-kix_23ct987xwu67-8>li:before{content:"" counter(lst-ctn-kix_23ct987xwu67-8,lower-roman) ". "}.lst-kix_zag3ymt8mk2y-8>li:before{content:"-  "}.lst-kix_tnd0p97rqwub-6>li:before{content:"-  "}.lst-kix_np9h4y3kt4yk-3>li:before{content:"-  "}.lst-kix_4qbfcta6cclt-8>li:before{content:"-  "}.lst-kix_xyra4e5ffsud-5>li{counter-increment:lst-ctn-kix_xyra4e5ffsud-5}.lst-kix_jvmsa1jxmzig-5>li:before{content:"\0025a0   "}.lst-kix_k5hm652wcnm2-0>li:before{content:"-  "}.lst-kix_innl5fto9oyf-0>li:before{content:"-  "}.lst-kix_9hby2lis2y9u-6>li:before{content:"-  "}.lst-kix_v0hsa7m5lywt-1>li:before{content:"-  "}ol.lst-kix_5djgwp8c9ig2-7.start{counter-reset:lst-ctn-kix_5djgwp8c9ig2-7 0}.lst-kix_8pn77unkg8hg-5>li:before{content:"-  "}.lst-kix_py2swxy3gr0i-6>li:before{content:"-  "}.lst-kix_a2xq56ushw0p-5>li:before{content:"-  "}.lst-kix_k5hm652wcnm2-4>li:before{content:"-  "}ul.lst-kix_r6uhbskcwxv5-0{list-style-type:none}.lst-kix_jvmsa1jxmzig-1>li:before{content:"\0025cb   "}.lst-kix_l60gvbdij7aj-6>li:before{content:"-  "}.lst-kix_arcio13zm8ud-4>li:before{content:"-  "}.lst-kix_o7acnutkhp1w-2>li:before{content:"-  "}.lst-kix_alhag51wggig-7>li:before{content:"-  "}ol.lst-kix_azgj6sn0lxuj-1.start{counter-reset:lst-ctn-kix_azgj6sn0lxuj-1 0}ul.lst-kix_3qppsihuuk4z-6{list-style-type:none}.lst-kix_wnr3c516ni7j-7>li:before{content:"-  "}ul.lst-kix_3qppsihuuk4z-7{list-style-type:none}.lst-kix_rxmcp67o7upe-2>li:before{content:"-  "}ul.lst-kix_3qppsihuuk4z-4{list-style-type:none}.lst-kix_n9qabngdxy64-7>li:before{content:"-  "}ul.lst-kix_3qppsihuuk4z-5{list-style-type:none}.lst-kix_t3rn73qejgkj-6>li{counter-increment:lst-ctn-kix_t3rn73qejgkj-6}.lst-kix_ms4jfr9nudpc-8>li:before{content:"-  "}ul.lst-kix_3qppsihuuk4z-8{list-style-type:none}.lst-kix_rrloltks13s-2>li:before{content:"-  "}ol.lst-kix_vgg0538grxk3-3.start{counter-reset:lst-ctn-kix_vgg0538grxk3-3 0}ul.lst-kix_qbfnanuzy3l5-6{list-style-type:none}ul.lst-kix_qbfnanuzy3l5-5{list-style-type:none}ul.lst-kix_qbfnanuzy3l5-4{list-style-type:none}ul.lst-kix_qbfnanuzy3l5-3{list-style-type:none}.lst-kix_p2dhxl6hicde-6>li:before{content:"-  "}.lst-kix_svg8hnl23b1r-7>li:before{content:"-  "}ul.lst-kix_qbfnanuzy3l5-8{list-style-type:none}ul.lst-kix_qbfnanuzy3l5-7{list-style-type:none}.lst-kix_aikphwux0ki0-2>li:before{content:"-  "}.lst-kix_alhag51wggig-3>li:before{content:"-  "}.lst-kix_upq3ni6ul8eb-5>li:before{content:"-  "}.lst-kix_l5iaj94ondn3-6>li:before{content:"-  "}.lst-kix_7rlftcume51v-4>li:before{content:"-  "}.lst-kix_7rlftcume51v-8>li:before{content:"-  "}.lst-kix_g8jgbze430sv-1>li:before{content:"" counter(lst-ctn-kix_g8jgbze430sv-1,lower-latin) ") "}ul.lst-kix_qbfnanuzy3l5-2{list-style-type:none}ul.lst-kix_qbfnanuzy3l5-1{list-style-type:none}ul.lst-kix_qbfnanuzy3l5-0{list-style-type:none}.lst-kix_khixc8f7o03u-4>li:before{content:"-  "}.lst-kix_1xkx8gh1e8n7-4>li:before{content:"-  "}.lst-kix_mb1zrov3n6kx-6>li:before{content:"-  "}.lst-kix_khixc8f7o03u-8>li:before{content:"-  "}.lst-kix_bswxvn1l22fp-5>li:before{content:"-  "}.lst-kix_aikphwux0ki0-6>li:before{content:"-  "}.lst-kix_v0hsa7m5lywt-5>li:before{content:"-  "}.lst-kix_r8i1fgeyliey-5>li:before{content:"-  "}ul.lst-kix_qw4x1ydun1ls-3{list-style-type:none}ul.lst-kix_qw4x1ydun1ls-2{list-style-type:none}ul.lst-kix_qw4x1ydun1ls-1{list-style-type:none}ul.lst-kix_qw4x1ydun1ls-0{list-style-type:none}.lst-kix_u8nobwiguyj1-1>li{counter-increment:lst-ctn-kix_u8nobwiguyj1-1}.lst-kix_g2uanok8rp1g-7>li:before{content:"-  "}.lst-kix_kxjfd2xlpmu-1>li:before{content:"-  "}ul.lst-kix_qw4x1ydun1ls-8{list-style-type:none}ul.lst-kix_qw4x1ydun1ls-7{list-style-type:none}.lst-kix_3wddikkjnk2k-2>li:before{content:"-  "}ul.lst-kix_qw4x1ydun1ls-6{list-style-type:none}ul.lst-kix_qw4x1ydun1ls-5{list-style-type:none}.lst-kix_e73zm9q3mvin-0>li:before{content:"-  "}ul.lst-kix_qw4x1ydun1ls-4{list-style-type:none}.lst-kix_qsto019ofcm1-5>li:before{content:"-  "}.lst-kix_ms6rbzn59hmq-0>li:before{content:"-  "}.lst-kix_90bg3luq5inv-0>li:before{content:"" counter(lst-ctn-kix_90bg3luq5inv-0,decimal) ") "}.lst-kix_s0nbf6s2np44-8>li:before{content:"-  "}.lst-kix_wz5gdx83jdla-3>li:before{content:"-  "}ul.lst-kix_6ltb10qoez57-0{list-style-type:none}ul.lst-kix_6ltb10qoez57-1{list-style-type:none}ul.lst-kix_6ltb10qoez57-2{list-style-type:none}ul.lst-kix_6ltb10qoez57-3{list-style-type:none}ul.lst-kix_6ltb10qoez57-4{list-style-type:none}ul.lst-kix_6ltb10qoez57-5{list-style-type:none}ul.lst-kix_6ltb10qoez57-6{list-style-type:none}ul.lst-kix_6ltb10qoez57-7{list-style-type:none}ul.lst-kix_6ltb10qoez57-8{list-style-type:none}.lst-kix_zjjx8lb18sy-6>li:before{content:"-  "}.lst-kix_nipj94pw11x6-6>li:before{content:"-  "}.lst-kix_y62sddnu24wd-1>li:before{content:"-  "}ul.lst-kix_axwe0nze7yft-3{list-style-type:none}ul.lst-kix_axwe0nze7yft-4{list-style-type:none}ul.lst-kix_axwe0nze7yft-5{list-style-type:none}ul.lst-kix_axwe0nze7yft-6{list-style-type:none}ul.lst-kix_axwe0nze7yft-7{list-style-type:none}ul.lst-kix_axwe0nze7yft-8{list-style-type:none}.lst-kix_4pjeuglo4z6v-4>li:before{content:"-  "}.lst-kix_g0lr2dxtnslc-6>li:before{content:"-  "}.lst-kix_7vaamq35f1cc-0>li:before{content:"-  "}.lst-kix_h25uruhpfzux-0>li:before{content:"-  "}.lst-kix_zb3jq278pptw-5>li:before{content:"-  "}.lst-kix_wiijpxq0m5a-6>li:before{content:"-  "}.lst-kix_i7kvy3cw4vsq-8>li:before{content:"-  "}ul.lst-kix_y62sddnu24wd-0{list-style-type:none}ul.lst-kix_qzg09ck6gr7w-5{list-style-type:none}ul.lst-kix_n0rv3zxivae3-8{list-style-type:none}ul.lst-kix_qzg09ck6gr7w-6{list-style-type:none}ul.lst-kix_n0rv3zxivae3-7{list-style-type:none}ul.lst-kix_qzg09ck6gr7w-3{list-style-type:none}ul.lst-kix_n0rv3zxivae3-6{list-style-type:none}ul.lst-kix_qzg09ck6gr7w-4{list-style-type:none}ul.lst-kix_y62sddnu24wd-4{list-style-type:none}ul.lst-kix_n0rv3zxivae3-5{list-style-type:none}ul.lst-kix_qzg09ck6gr7w-1{list-style-type:none}ul.lst-kix_y62sddnu24wd-3{list-style-type:none}ul.lst-kix_n0rv3zxivae3-4{list-style-type:none}ul.lst-kix_qzg09ck6gr7w-2{list-style-type:none}ul.lst-kix_y62sddnu24wd-2{list-style-type:none}ul.lst-kix_n0rv3zxivae3-3{list-style-type:none}.lst-kix_5stj9b6acoxv-5>li{counter-increment:lst-ctn-kix_5stj9b6acoxv-5}ul.lst-kix_y62sddnu24wd-1{list-style-type:none}ul.lst-kix_n0rv3zxivae3-2{list-style-type:none}ul.lst-kix_qzg09ck6gr7w-0{list-style-type:none}ul.lst-kix_y62sddnu24wd-8{list-style-type:none}ul.lst-kix_n0rv3zxivae3-1{list-style-type:none}.lst-kix_9j3np3ow732h-4>li:before{content:"\0025cb   "}.lst-kix_skgpgvhmuoc4-7>li:before{content:"-  "}ul.lst-kix_y62sddnu24wd-7{list-style-type:none}ul.lst-kix_n0rv3zxivae3-0{list-style-type:none}ul.lst-kix_y62sddnu24wd-6{list-style-type:none}ul.lst-kix_y62sddnu24wd-5{list-style-type:none}ul.lst-kix_qzg09ck6gr7w-7{list-style-type:none}ul.lst-kix_qzg09ck6gr7w-8{list-style-type:none}.lst-kix_vgg0538grxk3-7>li{counter-increment:lst-ctn-kix_vgg0538grxk3-7}.lst-kix_i7kvy3cw4vsq-0>li:before{content:"-  "}ol.lst-kix_90bg3luq5inv-7{list-style-type:none}ol.lst-kix_90bg3luq5inv-6{list-style-type:none}ol.lst-kix_90bg3luq5inv-8{list-style-type:none}.lst-kix_dln561wj05xo-5>li:before{content:"-  "}ol.lst-kix_90bg3luq5inv-3{list-style-type:none}ol.lst-kix_90bg3luq5inv-2{list-style-type:none}ol.lst-kix_90bg3luq5inv-5{list-style-type:none}ol.lst-kix_90bg3luq5inv-4{list-style-type:none}.lst-kix_3qppsihuuk4z-7>li:before{content:"-  "}ol.lst-kix_90bg3luq5inv-1{list-style-type:none}ol.lst-kix_90bg3luq5inv-0{list-style-type:none}ul.lst-kix_3wddikkjnk2k-5{list-style-type:none}ul.lst-kix_3wddikkjnk2k-4{list-style-type:none}ul.lst-kix_3wddikkjnk2k-3{list-style-type:none}ul.lst-kix_3wddikkjnk2k-2{list-style-type:none}ul.lst-kix_3wddikkjnk2k-1{list-style-type:none}ul.lst-kix_3wddikkjnk2k-0{list-style-type:none}.lst-kix_bttl6bm2dx1a-6>li:before{content:"-  "}.lst-kix_ysfu1bl0kymd-2>li{counter-increment:lst-ctn-kix_ysfu1bl0kymd-2}.lst-kix_7vvt5hs6rdl-1>li:before{content:"-  "}ol.lst-kix_52jgzw489fhs-3{list-style-type:none}ol.lst-kix_52jgzw489fhs-2{list-style-type:none}.lst-kix_3q7au8a3gwav-7>li:before{content:"-  "}.lst-kix_ikdz4hpyto9o-3>li:before{content:"-  "}ol.lst-kix_52jgzw489fhs-1{list-style-type:none}ol.lst-kix_52jgzw489fhs-0{list-style-type:none}.lst-kix_ugixx4nd67zw-1>li:before{content:"-  "}.lst-kix_mvektlca5c5q-0>li:before{content:"-  "}.lst-kix_qqbjjwnrc3l8-0>li:before{content:"-  "}.lst-kix_iffqre5r12zx-2>li:before{content:"-  "}.lst-kix_2foc6u9lzfq4-0>li{counter-increment:lst-ctn-kix_2foc6u9lzfq4-0}ol.lst-kix_ok1n37qarjzb-8{list-style-type:none}.lst-kix_wrdk3q33keus-6>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-7{list-style-type:none}.lst-kix_r6uhbskcwxv5-4>li:before{content:"-  "}ol.lst-kix_ok1n37qarjzb-6{list-style-type:none}ol.lst-kix_ok1n37qarjzb-5{list-style-type:none}ol.lst-kix_ok1n37qarjzb-4{list-style-type:none}ul.lst-kix_axwe0nze7yft-0{list-style-type:none}ol.lst-kix_ok1n37qarjzb-3{list-style-type:none}ul.lst-kix_axwe0nze7yft-1{list-style-type:none}ol.lst-kix_ok1n37qarjzb-2{list-style-type:none}ul.lst-kix_axwe0nze7yft-2{list-style-type:none}ol.lst-kix_ok1n37qarjzb-1{list-style-type:none}ol.lst-kix_ok1n37qarjzb-0{list-style-type:none}ol.lst-kix_52jgzw489fhs-8{list-style-type:none}.lst-kix_xhhdon4tpeu0-3>li:before{content:"-  "}ol.lst-kix_52jgzw489fhs-7{list-style-type:none}ol.lst-kix_52jgzw489fhs-6{list-style-type:none}ol.lst-kix_52jgzw489fhs-5{list-style-type:none}ol.lst-kix_52jgzw489fhs-4{list-style-type:none}.lst-kix_bb3pt2xtt0a5-8>li:before{content:"-  "}ul.lst-kix_w3rscytwttbz-6{list-style-type:none}.lst-kix_chbthqdwx7gj-2>li:before{content:"-  "}ul.lst-kix_w3rscytwttbz-5{list-style-type:none}ul.lst-kix_w3rscytwttbz-4{list-style-type:none}ul.lst-kix_w3rscytwttbz-3{list-style-type:none}.lst-kix_bp67ajcb7c38-1>li:before{content:"-  "}ul.lst-kix_w3rscytwttbz-8{list-style-type:none}ul.lst-kix_w3rscytwttbz-7{list-style-type:none}ul.lst-kix_t6x6ie377r4u-7{list-style-type:none}ul.lst-kix_t6x6ie377r4u-8{list-style-type:none}.lst-kix_iefjrs8t42tr-4>li:before{content:"-  "}.lst-kix_bpsiys7g173w-2>li:before{content:"-  "}ul.lst-kix_t6x6ie377r4u-5{list-style-type:none}ul.lst-kix_t6x6ie377r4u-6{list-style-type:none}ul.lst-kix_w3rscytwttbz-2{list-style-type:none}.lst-kix_7dqsuv1cdvcc-1>li:before{content:"-  "}ul.lst-kix_w3rscytwttbz-1{list-style-type:none}.lst-kix_r9s6df60is49-4>li:before{content:"-  "}.lst-kix_5ze5xofgghz2-4>li:before{content:"-  "}ul.lst-kix_w3rscytwttbz-0{list-style-type:none}.lst-kix_wn0yiryrov3h-1>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-5>li:before{content:"" counter(lst-ctn-kix_azgj6sn0lxuj-5,lower-roman) ". "}.lst-kix_5djgwp8c9ig2-3>li{counter-increment:lst-ctn-kix_5djgwp8c9ig2-3}.lst-kix_wsu1hpz6hqq4-6>li:before{content:"-  "}.lst-kix_rxgry66ibim8-2>li:before{content:"-  "}.lst-kix_rop4yg7lbfg8-6>li:before{content:"-  "}.lst-kix_xs6xjhigrbe2-3>li:before{content:"-  "}ul.lst-kix_3wddikkjnk2k-8{list-style-type:none}ul.lst-kix_3wddikkjnk2k-7{list-style-type:none}ul.lst-kix_3wddikkjnk2k-6{list-style-type:none}.lst-kix_oqibhsqlyfou-4>li:before{content:"-  "}ul.lst-kix_fs1lzw38maxl-7{list-style-type:none}ul.lst-kix_fs1lzw38maxl-8{list-style-type:none}.lst-kix_8nwtyhgsvjlm-3>li:before{content:"-  "}ul.lst-kix_fs1lzw38maxl-5{list-style-type:none}.lst-kix_2foc6u9lzfq4-7>li{counter-increment:lst-ctn-kix_2foc6u9lzfq4-7}ul.lst-kix_fs1lzw38maxl-6{list-style-type:none}ul.lst-kix_fs1lzw38maxl-3{list-style-type:none}ul.lst-kix_fs1lzw38maxl-4{list-style-type:none}ul.lst-kix_fs1lzw38maxl-1{list-style-type:none}ul.lst-kix_fs1lzw38maxl-2{list-style-type:none}ol.lst-kix_52jgzw489fhs-2.start{counter-reset:lst-ctn-kix_52jgzw489fhs-2 0}ul.lst-kix_fs1lzw38maxl-0{list-style-type:none}.lst-kix_qzg09ck6gr7w-0>li:before{content:"-  "}.lst-kix_vie3q5oyli2z-2>li:before{content:"-  "}.lst-kix_dn04c4yafie0-6>li:before{content:"-  "}ul.lst-kix_yk26x5gkc3g4-0{list-style-type:none}ul.lst-kix_yk26x5gkc3g4-3{list-style-type:none}.lst-kix_qccibyu36y2t-2>li:before{content:"-  "}ul.lst-kix_yk26x5gkc3g4-4{list-style-type:none}.lst-kix_ob04lr2u335p-7>li:before{content:"-  "}ul.lst-kix_yk26x5gkc3g4-1{list-style-type:none}ul.lst-kix_yk26x5gkc3g4-2{list-style-type:none}ul.lst-kix_yk26x5gkc3g4-7{list-style-type:none}ul.lst-kix_yk26x5gkc3g4-8{list-style-type:none}ul.lst-kix_yk26x5gkc3g4-5{list-style-type:none}.lst-kix_3i5qlhg977l0-0>li:before{content:"-  "}ul.lst-kix_yk26x5gkc3g4-6{list-style-type:none}.lst-kix_q2mi4y6rc42i-3>li:before{content:"-  "}.lst-kix_yk26x5gkc3g4-5>li:before{content:"-  "}ul.lst-kix_hyuyjld7ihkv-7{list-style-type:none}ul.lst-kix_hyuyjld7ihkv-8{list-style-type:none}ul.lst-kix_hyuyjld7ihkv-5{list-style-type:none}ul.lst-kix_hyuyjld7ihkv-6{list-style-type:none}ul.lst-kix_hyuyjld7ihkv-3{list-style-type:none}ul.lst-kix_hyuyjld7ihkv-4{list-style-type:none}ul.lst-kix_hyuyjld7ihkv-1{list-style-type:none}ul.lst-kix_hyuyjld7ihkv-2{list-style-type:none}.lst-kix_y32h08wggx1t-1>li:before{content:"-  "}ul.lst-kix_hyuyjld7ihkv-0{list-style-type:none}.lst-kix_vkdxjlf0kb6j-6>li:before{content:"" counter(lst-ctn-kix_vkdxjlf0kb6j-6,decimal) ". "}.lst-kix_brqn5pq4e7i7-6>li:before{content:"-  "}.lst-kix_qzg09ck6gr7w-8>li:before{content:"-  "}.lst-kix_r8azi25kh461-4>li:before{content:"\0025cf   "}ul.lst-kix_dojezsyc3ti3-8{list-style-type:none}ul.lst-kix_dojezsyc3ti3-7{list-style-type:none}ul.lst-kix_dojezsyc3ti3-6{list-style-type:none}ul.lst-kix_dojezsyc3ti3-5{list-style-type:none}.lst-kix_p1rtf0e14360-6>li:before{content:"-  "}.lst-kix_pejjsijavmae-4>li:before{content:"-  "}ul.lst-kix_dojezsyc3ti3-0{list-style-type:none}.lst-kix_owvy3cstzf0s-6>li:before{content:"-  "}.lst-kix_kzw7lb63578w-4>li:before{content:"-  "}ul.lst-kix_dojezsyc3ti3-4{list-style-type:none}.lst-kix_ykhrv7u6blcs-5>li:before{content:"-  "}ul.lst-kix_dojezsyc3ti3-3{list-style-type:none}ul.lst-kix_dojezsyc3ti3-2{list-style-type:none}ul.lst-kix_dojezsyc3ti3-1{list-style-type:none}.lst-kix_df6s37r8voak-5>li:before{content:"-  "}.lst-kix_1pt1eqcq4ieh-4>li:before{content:"-  "}.lst-kix_cd2o0cncsajm-3>li:before{content:"-  "}.lst-kix_fifu4bguh6qm-3>li:before{content:"-  "}.lst-kix_fm53cr9wmch0-0>li:before{content:"-  "}.lst-kix_932mko8sjg0u-1>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-5>li:before{content:"(" counter(lst-ctn-kix_ok1n37qarjzb-5,decimal) ") "}.lst-kix_14k5lhtsu41k-2>li:before{content:"-  "}.lst-kix_2nm562bzmwr-6>li:before{content:"-  "}.lst-kix_rf1gg3liws68-5>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-2>li{counter-increment:lst-ctn-kix_ypd5gkkarijk-2}.lst-kix_6pgojrjbxqei-8>li:before{content:"\0025a0   "}.lst-kix_6nc1nfac2wub-0>li:before{content:"-  "}.lst-kix_5l84eporjaw3-5>li:before{content:"-  "}.lst-kix_3ez3vzcedsa0-5>li:before{content:"-  "}.lst-kix_9z31rmzc855z-1>li:before{content:"-  "}.lst-kix_3i5qlhg977l0-8>li:before{content:"-  "}.lst-kix_aeppt4sbsnmp-8>li:before{content:"-  "}.lst-kix_j32gjnxzdkip-3>li:before{content:"-  "}.lst-kix_xx6ude5yqnkl-6>li:before{content:"\0025cf   "}.lst-kix_oswsfzrgbvyb-1>li:before{content:"-  "}ol.lst-kix_hppu19i8fr2p-7.start{counter-reset:lst-ctn-kix_hppu19i8fr2p-7 0}.lst-kix_6m4qu83yomn7-1>li:before{content:"-  "}.lst-kix_hkt83gwcgrvq-5>li:before{content:"-  "}ul.lst-kix_sxznwwyc44x6-5{list-style-type:none}ul.lst-kix_sxznwwyc44x6-4{list-style-type:none}ul.lst-kix_sxznwwyc44x6-7{list-style-type:none}ul.lst-kix_sxznwwyc44x6-6{list-style-type:none}ul.lst-kix_sxznwwyc44x6-1{list-style-type:none}ul.lst-kix_sxznwwyc44x6-0{list-style-type:none}ul.lst-kix_sxznwwyc44x6-3{list-style-type:none}.lst-kix_ld6rwbdri49-4>li:before{content:"-  "}.lst-kix_g8jgbze430sv-8>li{counter-increment:lst-ctn-kix_g8jgbze430sv-8}ul.lst-kix_sxznwwyc44x6-2{list-style-type:none}.lst-kix_5djgwp8c9ig2-6>li:before{content:"" counter(lst-ctn-kix_5djgwp8c9ig2-6,decimal) ". "}.lst-kix_jfoqdfq6uhww-8>li:before{content:"-  "}.lst-kix_incqcf2p39ls-8>li:before{content:"" counter(lst-ctn-kix_incqcf2p39ls-8,lower-roman) ". "}.lst-kix_35hvjwgc3k2f-3>li:before{content:"-  "}ul.lst-kix_sxznwwyc44x6-8{list-style-type:none}.lst-kix_ht80gp8jxjfs-5>li:before{content:"-  "}.lst-kix_rt3ua1vpzay9-2>li:before{content:"-  "}ul.lst-kix_tnd0p97rqwub-8{list-style-type:none}ul.lst-kix_tnd0p97rqwub-7{list-style-type:none}ul.lst-kix_tnd0p97rqwub-6{list-style-type:none}ul.lst-kix_tnd0p97rqwub-5{list-style-type:none}ul.lst-kix_tnd0p97rqwub-4{list-style-type:none}.lst-kix_3ug9en49p7ih-4>li:before{content:"-  "}.lst-kix_jfoqdfq6uhww-0>li:before{content:"-  "}ol.lst-kix_52jgzw489fhs-7.start{counter-reset:lst-ctn-kix_52jgzw489fhs-7 0}.lst-kix_i4nwb7g7qe41-2>li:before{content:"-  "}.lst-kix_6n4varno3bjs-2>li:before{content:"-  "}.lst-kix_5u0542f2h2jt-2>li:before{content:"+  "}.lst-kix_om0x63wgf9wd-0>li:before{content:"-  "}.lst-kix_yhq927c05ak0-7>li:before{content:"-  "}.lst-kix_549l9aqx2sdy-6>li:before{content:"-  "}.lst-kix_qbfnanuzy3l5-8>li:before{content:"-  "}.lst-kix_x6hb6vgwujyx-0>li:before{content:"-  "}.lst-kix_tvu7bmfefz32-1>li:before{content:"-  "}ul.lst-kix_7vvt5hs6rdl-1{list-style-type:none}ul.lst-kix_7vvt5hs6rdl-0{list-style-type:none}ul.lst-kix_tnd0p97rqwub-3{list-style-type:none}ul.lst-kix_7vvt5hs6rdl-3{list-style-type:none}ul.lst-kix_tnd0p97rqwub-2{list-style-type:none}ul.lst-kix_7vvt5hs6rdl-2{list-style-type:none}ul.lst-kix_tnd0p97rqwub-1{list-style-type:none}ul.lst-kix_7vvt5hs6rdl-5{list-style-type:none}.lst-kix_x96zthrcdy1e-6>li:before{content:"-  "}ul.lst-kix_tnd0p97rqwub-0{list-style-type:none}ul.lst-kix_7vvt5hs6rdl-4{list-style-type:none}.lst-kix_6u6or33vx86s-8>li:before{content:"-  "}ul.lst-kix_7vvt5hs6rdl-7{list-style-type:none}ul.lst-kix_7vvt5hs6rdl-6{list-style-type:none}ul.lst-kix_7vvt5hs6rdl-8{list-style-type:none}.lst-kix_u8nobwiguyj1-8>li{counter-increment:lst-ctn-kix_u8nobwiguyj1-8}.lst-kix_izios9u5ks4s-3>li:before{content:"-  "}ul.lst-kix_7vaamq35f1cc-3{list-style-type:none}.lst-kix_o45gwpewsvxw-8>li:before{content:"-  "}ul.lst-kix_7vaamq35f1cc-4{list-style-type:none}ul.lst-kix_7vaamq35f1cc-1{list-style-type:none}.lst-kix_5djgwp8c9ig2-0>li{counter-increment:lst-ctn-kix_5djgwp8c9ig2-0}ul.lst-kix_7vaamq35f1cc-2{list-style-type:none}ul.lst-kix_7vaamq35f1cc-7{list-style-type:none}ul.lst-kix_7vaamq35f1cc-8{list-style-type:none}ul.lst-kix_7vaamq35f1cc-5{list-style-type:none}ul.lst-kix_7vaamq35f1cc-6{list-style-type:none}.lst-kix_ny5e869gaylo-5>li:before{content:"-  "}.lst-kix_g9hblcm1l6tk-8>li:before{content:"-  "}.lst-kix_st0egafmkg0z-8>li:before{content:"-  "}.lst-kix_o45gwpewsvxw-0>li:before{content:"-  "}.lst-kix_hsahb38tz2f5-6>li:before{content:"-  "}.lst-kix_w97kncqyzxj3-5>li:before{content:"\0025a0   "}.lst-kix_cwjen7nun640-3>li:before{content:"-  "}ul.lst-kix_7vaamq35f1cc-0{list-style-type:none}.lst-kix_8w7txqc6xq66-8>li:before{content:"-  "}.lst-kix_fy701w8ywepa-8>li:before{content:"-  "}.lst-kix_o4efc4ukggt5-3>li:before{content:"-  "}.lst-kix_g8jgbze430sv-1>li{counter-increment:lst-ctn-kix_g8jgbze430sv-1}.lst-kix_lojd6plssn1-3>li:before{content:"-  "}.lst-kix_p9ucdfdvxyzl-3>li:before{content:"-  "}ul.lst-kix_d7eif1vat32g-8{list-style-type:none}.lst-kix_vdnr7e70vask-1>li:before{content:"\0025cb   "}.lst-kix_kp4gb6sd08f1-5>li:before{content:"-  "}.lst-kix_eh8nesljbkpv-6>li:before{content:"-  "}.lst-kix_sxznwwyc44x6-5>li:before{content:"-  "}ul.lst-kix_d7eif1vat32g-1{list-style-type:none}ul.lst-kix_d7eif1vat32g-0{list-style-type:none}ul.lst-kix_d7eif1vat32g-3{list-style-type:none}ul.lst-kix_d7eif1vat32g-2{list-style-type:none}ul.lst-kix_d7eif1vat32g-5{list-style-type:none}ul.lst-kix_d7eif1vat32g-4{list-style-type:none}ul.lst-kix_d7eif1vat32g-7{list-style-type:none}ul.lst-kix_d7eif1vat32g-6{list-style-type:none}.lst-kix_sr0z5k7b8i6u-3>li:before{content:"-  "}ol.lst-kix_yjf6dvvoob64-1.start{counter-reset:lst-ctn-kix_yjf6dvvoob64-1 0}.lst-kix_30wqf3y6rydr-8>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-7>li:before{content:"" counter(lst-ctn-kix_hppu19i8fr2p-7,lower-latin) ". "}.lst-kix_30wqf3y6rydr-4>li:before{content:"-  "}.lst-kix_fnlxcectz7fi-8>li:before{content:"-  "}.lst-kix_uwhnriglec8q-1>li:before{content:"-  "}.lst-kix_vdnr7e70vask-8>li:before{content:"\0025a0   "}.lst-kix_tfqdu2hgmdym-3>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-6>li:before{content:"" counter(lst-ctn-kix_3fc7x0lm2mmz-6,decimal) ". "}.lst-kix_l4d8unsm10a0-6>li:before{content:"-  "}.lst-kix_uwhnriglec8q-5>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-3>li:before{content:"" counter(lst-ctn-kix_sxixw4iqsgzx-3,decimal) ". "}ol.lst-kix_yjf6dvvoob64-6.start{counter-reset:lst-ctn-kix_yjf6dvvoob64-6 0}.lst-kix_6217r3mhjywx-1>li:before{content:"-  "}ul.lst-kix_gerk886qza0c-3{list-style-type:none}.lst-kix_qw4x1ydun1ls-6>li:before{content:"\0025cf   "}ul.lst-kix_gerk886qza0c-4{list-style-type:none}ul.lst-kix_gerk886qza0c-1{list-style-type:none}ul.lst-kix_gerk886qza0c-2{list-style-type:none}.lst-kix_o328viitwjyp-1>li:before{content:"-  "}ul.lst-kix_gerk886qza0c-0{list-style-type:none}ul.lst-kix_gerk886qza0c-7{list-style-type:none}ul.lst-kix_gerk886qza0c-8{list-style-type:none}ul.lst-kix_gerk886qza0c-5{list-style-type:none}ul.lst-kix_gerk886qza0c-6{list-style-type:none}.lst-kix_e3u4u2bj7x9w-3>li:before{content:"-  "}.lst-kix_o328viitwjyp-5>li:before{content:"-  "}.lst-kix_m3u7mfewl2ow-7>li:before{content:"-  "}.lst-kix_f4168mxvziu2-2>li:before{content:"-  "}.lst-kix_hc732m8hksyq-3>li:before{content:"-  "}.lst-kix_xktbtduo53bq-8>li:before{content:"" counter(lst-ctn-kix_xktbtduo53bq-8,lower-roman) ". "}.lst-kix_f4168mxvziu2-6>li:before{content:"-  "}.lst-kix_fnlxcectz7fi-1>li:before{content:"-  "}.lst-kix_v9cryi9ybo1n-7>li:before{content:"\0025cb   "}.lst-kix_yvohqcnu3146-0>li{counter-increment:lst-ctn-kix_yvohqcnu3146-0}ul.lst-kix_7vr84ges94ry-4{list-style-type:none}ul.lst-kix_7vr84ges94ry-3{list-style-type:none}ul.lst-kix_7vr84ges94ry-2{list-style-type:none}.lst-kix_npanryo7f1m7-3>li:before{content:"-  "}ul.lst-kix_7vr84ges94ry-1{list-style-type:none}.lst-kix_i8kfgvsh0fwy-1>li:before{content:"-  "}ul.lst-kix_7vr84ges94ry-8{list-style-type:none}ul.lst-kix_7vr84ges94ry-7{list-style-type:none}ul.lst-kix_7vr84ges94ry-6{list-style-type:none}ul.lst-kix_7vr84ges94ry-5{list-style-type:none}.lst-kix_tlnfkrylyq1a-8>li:before{content:"-  "}.lst-kix_tfqdu2hgmdym-7>li:before{content:"-  "}ul.lst-kix_7vr84ges94ry-0{list-style-type:none}.lst-kix_xyra4e5ffsud-2>li{counter-increment:lst-ctn-kix_xyra4e5ffsud-2}.lst-kix_1epl36nedj4y-5>li:before{content:"-  "}.lst-kix_7gk9ayd44tft-6>li:before{content:"-  "}.lst-kix_p11gr83hik0e-6>li:before{content:"-  "}.lst-kix_23ct987xwu67-4>li{counter-increment:lst-ctn-kix_23ct987xwu67-4}.lst-kix_f83agu4s4fw5-0>li:before{content:"-  "}.lst-kix_pv4jsz2h74wk-7>li:before{content:"-  "}.lst-kix_f2t507a7xjue-2>li:before{content:"-  "}.lst-kix_1epl36nedj4y-1>li:before{content:"-  "}.lst-kix_v6dv769q7bq3-7>li:before{content:"-  "}.lst-kix_tvu7bmfefz32-2>li:before{content:"-  "}.lst-kix_38p7uzj3qds3-6>li:before{content:"-  "}.lst-kix_awlaex77cpwh-4>li:before{content:"-  "}.lst-kix_z6rr709h3fky-3>li:before{content:"-  "}.lst-kix_dojezsyc3ti3-3>li:before{content:"-  "}ul.lst-kix_qij6192l4p0g-4{list-style-type:none}.lst-kix_ctweb0b3a38f-4>li:before{content:"-  "}ul.lst-kix_qij6192l4p0g-5{list-style-type:none}ul.lst-kix_qij6192l4p0g-6{list-style-type:none}ul.lst-kix_qij6192l4p0g-7{list-style-type:none}ul.lst-kix_qij6192l4p0g-0{list-style-type:none}ul.lst-kix_qij6192l4p0g-1{list-style-type:none}ul.lst-kix_qij6192l4p0g-2{list-style-type:none}ul.lst-kix_qij6192l4p0g-3{list-style-type:none}.lst-kix_8wvqr5f1zg2m-0>li:before{content:"-  "}.lst-kix_vuz55xpe5xjl-4>li:before{content:"-  "}.lst-kix_vkdxjlf0kb6j-8>li{counter-increment:lst-ctn-kix_vkdxjlf0kb6j-8}ul.lst-kix_x12ed5cs6o9z-1{list-style-type:none}ul.lst-kix_x12ed5cs6o9z-0{list-style-type:none}ul.lst-kix_x12ed5cs6o9z-3{list-style-type:none}ul.lst-kix_x12ed5cs6o9z-2{list-style-type:none}ul.lst-kix_x12ed5cs6o9z-5{list-style-type:none}ul.lst-kix_x12ed5cs6o9z-4{list-style-type:none}ul.lst-kix_x12ed5cs6o9z-7{list-style-type:none}ul.lst-kix_x12ed5cs6o9z-6{list-style-type:none}ul.lst-kix_x12ed5cs6o9z-8{list-style-type:none}ul.lst-kix_j32gjnxzdkip-4{list-style-type:none}ul.lst-kix_nj8yy6k748x0-4{list-style-type:none}ul.lst-kix_j32gjnxzdkip-3{list-style-type:none}ul.lst-kix_nj8yy6k748x0-3{list-style-type:none}ul.lst-kix_j32gjnxzdkip-6{list-style-type:none}ul.lst-kix_nj8yy6k748x0-6{list-style-type:none}ul.lst-kix_j32gjnxzdkip-5{list-style-type:none}ul.lst-kix_nj8yy6k748x0-5{list-style-type:none}ul.lst-kix_dyq7vlcdkqm5-0{list-style-type:none}ul.lst-kix_j32gjnxzdkip-0{list-style-type:none}ul.lst-kix_nj8yy6k748x0-0{list-style-type:none}ul.lst-kix_j32gjnxzdkip-2{list-style-type:none}ul.lst-kix_nj8yy6k748x0-2{list-style-type:none}ul.lst-kix_j32gjnxzdkip-1{list-style-type:none}ul.lst-kix_nj8yy6k748x0-1{list-style-type:none}.lst-kix_g47hwi8ilj0t-5>li:before{content:"-  "}ul.lst-kix_j32gjnxzdkip-8{list-style-type:none}ul.lst-kix_nj8yy6k748x0-8{list-style-type:none}ul.lst-kix_j32gjnxzdkip-7{list-style-type:none}ul.lst-kix_nj8yy6k748x0-7{list-style-type:none}.lst-kix_p1rtf0e14360-1>li:before{content:"-  "}.lst-kix_mkfigeky21iv-0>li:before{content:"-  "}ul.lst-kix_bp67ajcb7c38-5{list-style-type:none}.lst-kix_3mj3tp7kj9db-5>li{counter-increment:lst-ctn-kix_3mj3tp7kj9db-5}ul.lst-kix_bp67ajcb7c38-6{list-style-type:none}ul.lst-kix_bp67ajcb7c38-7{list-style-type:none}ul.lst-kix_bp67ajcb7c38-8{list-style-type:none}ul.lst-kix_qij6192l4p0g-8{list-style-type:none}ul.lst-kix_bp67ajcb7c38-1{list-style-type:none}ul.lst-kix_bp67ajcb7c38-2{list-style-type:none}.lst-kix_4uak8dkv6vr8-5>li:before{content:"-  "}ul.lst-kix_bp67ajcb7c38-3{list-style-type:none}ul.lst-kix_bp67ajcb7c38-4{list-style-type:none}.lst-kix_qbfnanuzy3l5-7>li:before{content:"-  "}ul.lst-kix_bp67ajcb7c38-0{list-style-type:none}.lst-kix_dyq7vlcdkqm5-5>li:before{content:"-  "}.lst-kix_r9gci84l54f7-8>li:before{content:"-  "}.lst-kix_wlyv8o88ksmk-4>li:before{content:"-  "}ol.lst-kix_yjf6dvvoob64-5.start{counter-reset:lst-ctn-kix_yjf6dvvoob64-5 0}.lst-kix_nlsa7flowwa1-3>li:before{content:"+  "}.lst-kix_mkfigeky21iv-4>li:before{content:"-  "}.lst-kix_voj7evacrpie-6>li:before{content:"-  "}.lst-kix_r9gci84l54f7-4>li:before{content:"-  "}.lst-kix_11d94ps4c7wj-6>li:before{content:"-  "}.lst-kix_urqiwn6svi1d-7>li:before{content:"-  "}ul.lst-kix_cg6jep1fmawj-8{list-style-type:none}.lst-kix_vhhvekoaa9d4-4>li:before{content:"\0025cb   "}ul.lst-kix_cg6jep1fmawj-6{list-style-type:none}ul.lst-kix_cg6jep1fmawj-7{list-style-type:none}.lst-kix_nlsa7flowwa1-7>li:before{content:"+  "}ul.lst-kix_cg6jep1fmawj-4{list-style-type:none}.lst-kix_ltm9vv1op5tt-6>li:before{content:"-  "}ul.lst-kix_cg6jep1fmawj-5{list-style-type:none}ul.lst-kix_cg6jep1fmawj-2{list-style-type:none}ul.lst-kix_cg6jep1fmawj-3{list-style-type:none}.lst-kix_ltm9vv1op5tt-5>li:before{content:"-  "}ul.lst-kix_g47hwi8ilj0t-8{list-style-type:none}.lst-kix_x2lkon80l30j-8>li:before{content:"-  "}ul.lst-kix_g47hwi8ilj0t-6{list-style-type:none}.lst-kix_5stj9b6acoxv-2>li{counter-increment:lst-ctn-kix_5stj9b6acoxv-2}ul.lst-kix_g47hwi8ilj0t-7{list-style-type:none}.lst-kix_ok1n37qarjzb-7>li{counter-increment:lst-ctn-kix_ok1n37qarjzb-7}ul.lst-kix_cg6jep1fmawj-0{list-style-type:none}ul.lst-kix_g47hwi8ilj0t-0{list-style-type:none}ul.lst-kix_cg6jep1fmawj-1{list-style-type:none}.lst-kix_vhhvekoaa9d4-0>li:before{content:"\0025cf   "}ul.lst-kix_g47hwi8ilj0t-1{list-style-type:none}ul.lst-kix_g47hwi8ilj0t-4{list-style-type:none}ul.lst-kix_g47hwi8ilj0t-5{list-style-type:none}ul.lst-kix_g47hwi8ilj0t-2{list-style-type:none}ul.lst-kix_g47hwi8ilj0t-3{list-style-type:none}.lst-kix_ctweb0b3a38f-8>li:before{content:"-  "}ul.lst-kix_kzw7lb63578w-7{list-style-type:none}ul.lst-kix_kzw7lb63578w-6{list-style-type:none}ul.lst-kix_kzw7lb63578w-8{list-style-type:none}.lst-kix_4ypcpsaj0q6h-6>li:before{content:"-  "}.lst-kix_hyuyjld7ihkv-1>li:before{content:"-  "}ul.lst-kix_kzw7lb63578w-1{list-style-type:none}ul.lst-kix_kzw7lb63578w-0{list-style-type:none}ul.lst-kix_kzw7lb63578w-3{list-style-type:none}ul.lst-kix_kzw7lb63578w-2{list-style-type:none}ul.lst-kix_kzw7lb63578w-5{list-style-type:none}ul.lst-kix_kzw7lb63578w-4{list-style-type:none}.lst-kix_sq25f4cnauod-7>li:before{content:"-  "}.lst-kix_fhtxrv3nkyi7-5>li:before{content:"-  "}.lst-kix_d626gkjp4fou-6>li:before{content:"\0025cf   "}.lst-kix_dln561wj05xo-4>li:before{content:"-  "}.lst-kix_9ys95s420x24-3>li:before{content:"-  "}.lst-kix_f83agu4s4fw5-7>li:before{content:"-  "}ul.lst-kix_rcfi5jnwnxji-8{list-style-type:none}ul.lst-kix_rcfi5jnwnxji-7{list-style-type:none}ul.lst-kix_rcfi5jnwnxji-6{list-style-type:none}.lst-kix_28q7sqckfj19-7>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-4>li:before{content:"" counter(lst-ctn-kix_sxixw4iqsgzx-4,lower-latin) ". "}.lst-kix_iffqre5r12zx-3>li:before{content:"-  "}.lst-kix_qw4x1ydun1ls-2>li:before{content:"\0025a0   "}.lst-kix_52jgzw489fhs-6>li:before{content:"" counter(lst-ctn-kix_52jgzw489fhs-6,decimal) ". "}.lst-kix_5jp9wppv00ra-2>li:before{content:"-  "}.lst-kix_i8kfgvsh0fwy-2>li:before{content:"-  "}.lst-kix_q95o92il1jwg-8>li:before{content:"-  "}.lst-kix_5quy3fbj2mfg-3>li:before{content:"-  "}ol.lst-kix_vgg0538grxk3-5{list-style-type:none}.lst-kix_ypd5gkkarijk-6>li{counter-increment:lst-ctn-kix_ypd5gkkarijk-6}ol.lst-kix_vgg0538grxk3-4{list-style-type:none}ol.lst-kix_vgg0538grxk3-3{list-style-type:none}ol.lst-kix_vgg0538grxk3-2{list-style-type:none}ol.lst-kix_vgg0538grxk3-8{list-style-type:none}ol.lst-kix_vgg0538grxk3-7{list-style-type:none}ol.lst-kix_vgg0538grxk3-6{list-style-type:none}.lst-kix_iefjrs8t42tr-3>li:before{content:"-  "}.lst-kix_epyrmry7301m-5>li:before{content:"-  "}ol.lst-kix_vgg0538grxk3-1{list-style-type:none}ol.lst-kix_vgg0538grxk3-0{list-style-type:none}.lst-kix_q95o92il1jwg-4>li:before{content:"-  "}.lst-kix_xhhdon4tpeu0-8>li:before{content:"-  "}ul.lst-kix_dyq7vlcdkqm5-4{list-style-type:none}ul.lst-kix_dyq7vlcdkqm5-3{list-style-type:none}ul.lst-kix_dyq7vlcdkqm5-2{list-style-type:none}ul.lst-kix_dyq7vlcdkqm5-1{list-style-type:none}ul.lst-kix_dyq7vlcdkqm5-8{list-style-type:none}ul.lst-kix_dyq7vlcdkqm5-7{list-style-type:none}ul.lst-kix_dyq7vlcdkqm5-6{list-style-type:none}ul.lst-kix_dyq7vlcdkqm5-5{list-style-type:none}.lst-kix_tekivzgenz72-8>li:before{content:"-  "}.lst-kix_brqn5pq4e7i7-1>li:before{content:"-  "}.lst-kix_p11gr83hik0e-5>li:before{content:"-  "}.lst-kix_eahcvjpxxqs-0>li:before{content:"-  "}ul.lst-kix_rcfi5jnwnxji-5{list-style-type:none}.lst-kix_t3rn73qejgkj-4>li:before{content:"(" counter(lst-ctn-kix_t3rn73qejgkj-4,lower-latin) ") "}ul.lst-kix_oxgbebk5l98i-8{list-style-type:none}ul.lst-kix_rcfi5jnwnxji-4{list-style-type:none}ul.lst-kix_rcfi5jnwnxji-3{list-style-type:none}.lst-kix_1tib71bbsugw-6>li:before{content:"-  "}ul.lst-kix_rcfi5jnwnxji-2{list-style-type:none}ul.lst-kix_rcfi5jnwnxji-1{list-style-type:none}ul.lst-kix_rcfi5jnwnxji-0{list-style-type:none}.lst-kix_o17eseb5cr8e-2>li:before{content:"-  "}ul.lst-kix_jnfn9mx5o33t-4{list-style-type:none}ul.lst-kix_oxgbebk5l98i-1{list-style-type:none}ul.lst-kix_jnfn9mx5o33t-3{list-style-type:none}ul.lst-kix_oxgbebk5l98i-0{list-style-type:none}.lst-kix_d1gy3hy5r3qj-7>li{counter-increment:lst-ctn-kix_d1gy3hy5r3qj-7}ul.lst-kix_jnfn9mx5o33t-6{list-style-type:none}.lst-kix_t3rn73qejgkj-0>li:before{content:"" counter(lst-ctn-kix_t3rn73qejgkj-0,decimal) ") "}ul.lst-kix_oxgbebk5l98i-3{list-style-type:none}ul.lst-kix_jnfn9mx5o33t-5{list-style-type:none}ul.lst-kix_oxgbebk5l98i-2{list-style-type:none}ul.lst-kix_jnfn9mx5o33t-0{list-style-type:none}ul.lst-kix_oxgbebk5l98i-5{list-style-type:none}.lst-kix_267f3xfv5ddr-7>li:before{content:"" counter(lst-ctn-kix_267f3xfv5ddr-7,lower-latin) ". "}ul.lst-kix_oxgbebk5l98i-4{list-style-type:none}ul.lst-kix_jnfn9mx5o33t-2{list-style-type:none}ul.lst-kix_oxgbebk5l98i-7{list-style-type:none}ul.lst-kix_jnfn9mx5o33t-1{list-style-type:none}ul.lst-kix_oxgbebk5l98i-6{list-style-type:none}.lst-kix_o17eseb5cr8e-6>li:before{content:"-  "}.lst-kix_wn0yiryrov3h-8>li:before{content:"-  "}ul.lst-kix_jnfn9mx5o33t-8{list-style-type:none}ul.lst-kix_jnfn9mx5o33t-7{list-style-type:none}.lst-kix_bo9wrgz88es4-8>li:before{content:"-  "}.lst-kix_kxjfd2xlpmu-5>li:before{content:"-  "}.lst-kix_bo9wrgz88es4-1>li:before{content:"-  "}.lst-kix_b7rulpv7obgl-6>li:before{content:"-  "}.lst-kix_m31se2npgu2r-5>li:before{content:"-  "}.lst-kix_qsto019ofcm1-6>li:before{content:"-  "}.lst-kix_luixtz7s7e5x-3>li:before{content:"-  "}.lst-kix_cmm6cscyrjti-5>li:before{content:"-  "}.lst-kix_g2uanok8rp1g-0>li:before{content:"-  "}.lst-kix_90bg3luq5inv-4>li:before{content:"(" counter(lst-ctn-kix_90bg3luq5inv-4,lower-latin) ") "}.lst-kix_84zf7o74c8s9-7>li{counter-increment:lst-ctn-kix_84zf7o74c8s9-7}.lst-kix_ozbrn4vmjez8-5>li:before{content:"-  "}.lst-kix_bp67ajcb7c38-5>li:before{content:"-  "}ul.lst-kix_r9s6df60is49-0{list-style-type:none}ul.lst-kix_r9s6df60is49-1{list-style-type:none}ul.lst-kix_r9s6df60is49-2{list-style-type:none}.lst-kix_h25uruhpfzux-7>li:before{content:"-  "}ul.lst-kix_r9s6df60is49-3{list-style-type:none}.lst-kix_dmn3lqzfmokk-5>li:before{content:"-  "}.lst-kix_incqcf2p39ls-8>li{counter-increment:lst-ctn-kix_incqcf2p39ls-8}ul.lst-kix_r9s6df60is49-8{list-style-type:none}.lst-kix_rp6rf03vbelo-0>li:before{content:"-  "}.lst-kix_vvjhovkzyen7-7>li:before{content:"-  "}ul.lst-kix_r9s6df60is49-4{list-style-type:none}ul.lst-kix_r9s6df60is49-5{list-style-type:none}ul.lst-kix_r9s6df60is49-6{list-style-type:none}ul.lst-kix_r9s6df60is49-7{list-style-type:none}.lst-kix_kt8k33f35qi5-6>li:before{content:"-  "}.lst-kix_17yxihawuh4r-4>li:before{content:"-  "}.lst-kix_y62sddnu24wd-5>li:before{content:"-  "}.lst-kix_wiijpxq0m5a-5>li:before{content:"-  "}.lst-kix_3koi1cw13a0-0>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-2>li{counter-increment:lst-ctn-kix_ykhoydml7pv3-2}.lst-kix_e73zm9q3mvin-7>li:before{content:"-  "}.lst-kix_8a5plp401pog-5>li:before{content:"-  "}.lst-kix_fld6w0ks1f0p-2>li:before{content:"-  "}.lst-kix_r8adx85jg0iz-0>li:before{content:"-  "}.lst-kix_tl77ogq6q7u-3>li:before{content:"-  "}ul.lst-kix_v9cryi9ybo1n-7{list-style-type:none}.lst-kix_incqcf2p39ls-4>li:before{content:"(" counter(lst-ctn-kix_incqcf2p39ls-4,lower-latin) ") "}.lst-kix_skgpgvhmuoc4-6>li:before{content:"-  "}ul.lst-kix_v9cryi9ybo1n-8{list-style-type:none}ul.lst-kix_v9cryi9ybo1n-5{list-style-type:none}ul.lst-kix_v9cryi9ybo1n-6{list-style-type:none}ul.lst-kix_v9cryi9ybo1n-3{list-style-type:none}.lst-kix_g0lr2dxtnslc-7>li:before{content:"-  "}ul.lst-kix_v9cryi9ybo1n-4{list-style-type:none}ul.lst-kix_v9cryi9ybo1n-1{list-style-type:none}ul.lst-kix_mv77cg19299c-7{list-style-type:none}ul.lst-kix_v9cryi9ybo1n-2{list-style-type:none}ul.lst-kix_mv77cg19299c-8{list-style-type:none}ul.lst-kix_mv77cg19299c-5{list-style-type:none}ul.lst-kix_v9cryi9ybo1n-0{list-style-type:none}ul.lst-kix_mv77cg19299c-6{list-style-type:none}ol.lst-kix_xktbtduo53bq-4.start{counter-reset:lst-ctn-kix_xktbtduo53bq-4 0}ul.lst-kix_mv77cg19299c-3{list-style-type:none}.lst-kix_lcru2cdgc87j-7>li:before{content:"-  "}ul.lst-kix_mv77cg19299c-4{list-style-type:none}ul.lst-kix_mv77cg19299c-1{list-style-type:none}.lst-kix_f9iu0trsjas1-2>li:before{content:"-  "}ul.lst-kix_mv77cg19299c-2{list-style-type:none}.lst-kix_x424ckbm5jp1-0>li:before{content:"-  "}ul.lst-kix_mv77cg19299c-0{list-style-type:none}ul.lst-kix_n9qabngdxy64-0{list-style-type:none}ul.lst-kix_n9qabngdxy64-1{list-style-type:none}ul.lst-kix_n9qabngdxy64-2{list-style-type:none}ul.lst-kix_n9qabngdxy64-3{list-style-type:none}ol.lst-kix_t3rn73qejgkj-8.start{counter-reset:lst-ctn-kix_t3rn73qejgkj-8 0}ul.lst-kix_n9qabngdxy64-4{list-style-type:none}ul.lst-kix_n9qabngdxy64-5{list-style-type:none}ul.lst-kix_n9qabngdxy64-6{list-style-type:none}ul.lst-kix_n9qabngdxy64-7{list-style-type:none}ul.lst-kix_n9qabngdxy64-8{list-style-type:none}.lst-kix_ld6rwbdri49-5>li:before{content:"-  "}.lst-kix_7vvt5hs6rdl-5>li:before{content:"-  "}ul.lst-kix_bdjoj2nf5hw9-7{list-style-type:none}ul.lst-kix_r9gci84l54f7-4{list-style-type:none}ul.lst-kix_bdjoj2nf5hw9-8{list-style-type:none}ul.lst-kix_r9gci84l54f7-3{list-style-type:none}ul.lst-kix_bdjoj2nf5hw9-5{list-style-type:none}ul.lst-kix_r9gci84l54f7-6{list-style-type:none}ul.lst-kix_bdjoj2nf5hw9-6{list-style-type:none}.lst-kix_ssze0kg2kz13-5>li:before{content:"-  "}ul.lst-kix_r9gci84l54f7-5{list-style-type:none}ul.lst-kix_r9gci84l54f7-0{list-style-type:none}.lst-kix_8pn77unkg8hg-6>li:before{content:"-  "}ul.lst-kix_oswsfzrgbvyb-0{list-style-type:none}ul.lst-kix_r9gci84l54f7-2{list-style-type:none}ul.lst-kix_oswsfzrgbvyb-1{list-style-type:none}.lst-kix_incqcf2p39ls-0>li{counter-increment:lst-ctn-kix_incqcf2p39ls-0}ul.lst-kix_r9gci84l54f7-1{list-style-type:none}ul.lst-kix_oswsfzrgbvyb-2{list-style-type:none}ul.lst-kix_oswsfzrgbvyb-3{list-style-type:none}ul.lst-kix_oswsfzrgbvyb-4{list-style-type:none}ul.lst-kix_oswsfzrgbvyb-5{list-style-type:none}ul.lst-kix_oswsfzrgbvyb-6{list-style-type:none}ul.lst-kix_oswsfzrgbvyb-7{list-style-type:none}ul.lst-kix_oswsfzrgbvyb-8{list-style-type:none}.lst-kix_8f3g26d9wonp-6>li:before{content:"-  "}.lst-kix_bttl6bm2dx1a-2>li:before{content:"-  "}ul.lst-kix_bdjoj2nf5hw9-0{list-style-type:none}.lst-kix_r6uhbskcwxv5-8>li:before{content:"-  "}ul.lst-kix_bdjoj2nf5hw9-3{list-style-type:none}ul.lst-kix_r9gci84l54f7-8{list-style-type:none}ul.lst-kix_bdjoj2nf5hw9-4{list-style-type:none}ul.lst-kix_r9gci84l54f7-7{list-style-type:none}ul.lst-kix_bdjoj2nf5hw9-1{list-style-type:none}ul.lst-kix_bdjoj2nf5hw9-2{list-style-type:none}.lst-kix_innl5fto9oyf-7>li:before{content:"-  "}.lst-kix_ugixx4nd67zw-5>li:before{content:"-  "}.lst-kix_2ei6b6e4ow80-2>li:before{content:"-  "}.lst-kix_3q7au8a3gwav-3>li:before{content:"-  "}.lst-kix_wrdk3q33keus-2>li:before{content:"-  "}.lst-kix_awt45k7p90je-4>li:before{content:"-  "}.lst-kix_3ug9en49p7ih-3>li:before{content:"-  "}.lst-kix_fexdtgozkcsr-5>li:before{content:"-  "}.lst-kix_52jgzw489fhs-2>li{counter-increment:lst-ctn-kix_52jgzw489fhs-2}.lst-kix_4z9ptm6a4lke-6>li:before{content:"-  "}.lst-kix_x6hb6vgwujyx-1>li:before{content:"-  "}.lst-kix_bb3pt2xtt0a5-4>li:before{content:"-  "}ol.lst-kix_5stj9b6acoxv-3.start{counter-reset:lst-ctn-kix_5stj9b6acoxv-3 0}.lst-kix_l60gvbdij7aj-7>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-4>li:before{content:"" counter(lst-ctn-kix_yjf6dvvoob64-4,lower-latin) ". "}ul.lst-kix_x1n4jlo0gf1q-2{list-style-type:none}ul.lst-kix_x1n4jlo0gf1q-3{list-style-type:none}.lst-kix_1xkx8gh1e8n7-3>li:before{content:"-  "}ul.lst-kix_x1n4jlo0gf1q-0{list-style-type:none}ul.lst-kix_x1n4jlo0gf1q-1{list-style-type:none}.lst-kix_8wvqr5f1zg2m-7>li:before{content:"-  "}ul.lst-kix_x1n4jlo0gf1q-6{list-style-type:none}ul.lst-kix_x1n4jlo0gf1q-7{list-style-type:none}.lst-kix_r9s6df60is49-8>li:before{content:"-  "}ul.lst-kix_x1n4jlo0gf1q-4{list-style-type:none}ul.lst-kix_x1n4jlo0gf1q-5{list-style-type:none}ul.lst-kix_69k4orytle42-8{list-style-type:none}ul.lst-kix_69k4orytle42-7{list-style-type:none}ul.lst-kix_69k4orytle42-6{list-style-type:none}.lst-kix_bpsiys7g173w-6>li:before{content:"-  "}ul.lst-kix_x1n4jlo0gf1q-8{list-style-type:none}.lst-kix_oqibhsqlyfou-0>li:before{content:"-  "}ul.lst-kix_69k4orytle42-5{list-style-type:none}.lst-kix_bdjoj2nf5hw9-2>li:before{content:"-  "}ul.lst-kix_69k4orytle42-4{list-style-type:none}ul.lst-kix_69k4orytle42-3{list-style-type:none}.lst-kix_hrm7p8w30y7p-3>li:before{content:"-  "}ul.lst-kix_69k4orytle42-2{list-style-type:none}ul.lst-kix_69k4orytle42-1{list-style-type:none}ul.lst-kix_69k4orytle42-0{list-style-type:none}ul.lst-kix_81v91kbrmywy-7{list-style-type:none}ul.lst-kix_6n4varno3bjs-2{list-style-type:none}ul.lst-kix_81v91kbrmywy-8{list-style-type:none}ul.lst-kix_6n4varno3bjs-1{list-style-type:none}ul.lst-kix_81v91kbrmywy-5{list-style-type:none}ul.lst-kix_6n4varno3bjs-4{list-style-type:none}.lst-kix_azgj6sn0lxuj-1>li:before{content:"" counter(lst-ctn-kix_azgj6sn0lxuj-1,lower-latin) ". "}ul.lst-kix_81v91kbrmywy-6{list-style-type:none}ul.lst-kix_6n4varno3bjs-3{list-style-type:none}ul.lst-kix_6n4varno3bjs-0{list-style-type:none}.lst-kix_2ccdqvrbclt-2>li:before{content:"-  "}ul.lst-kix_81v91kbrmywy-0{list-style-type:none}ul.lst-kix_81v91kbrmywy-3{list-style-type:none}ul.lst-kix_6n4varno3bjs-6{list-style-type:none}ul.lst-kix_81v91kbrmywy-4{list-style-type:none}ul.lst-kix_6n4varno3bjs-5{list-style-type:none}ul.lst-kix_81v91kbrmywy-1{list-style-type:none}ul.lst-kix_6n4varno3bjs-8{list-style-type:none}ul.lst-kix_81v91kbrmywy-2{list-style-type:none}ul.lst-kix_6n4varno3bjs-7{list-style-type:none}ul.lst-kix_6o2cphkh2n8b-7{list-style-type:none}.lst-kix_pxpm44v9ngyu-3>li:before{content:"-  "}ul.lst-kix_6o2cphkh2n8b-6{list-style-type:none}ol.lst-kix_g8jgbze430sv-1{list-style-type:none}ul.lst-kix_6o2cphkh2n8b-5{list-style-type:none}ol.lst-kix_g8jgbze430sv-0{list-style-type:none}ul.lst-kix_6o2cphkh2n8b-4{list-style-type:none}.lst-kix_dn04c4yafie0-7>li:before{content:"-  "}ul.lst-kix_6o2cphkh2n8b-8{list-style-type:none}.lst-kix_yvohqcnu3146-5>li:before{content:"(" counter(lst-ctn-kix_yvohqcnu3146-5,lower-roman) ") "}ol.lst-kix_267f3xfv5ddr-2.start{counter-reset:lst-ctn-kix_267f3xfv5ddr-2 0}.lst-kix_hppu19i8fr2p-8>li{counter-increment:lst-ctn-kix_hppu19i8fr2p-8}ul.lst-kix_6o2cphkh2n8b-3{list-style-type:none}ul.lst-kix_6o2cphkh2n8b-2{list-style-type:none}ul.lst-kix_6o2cphkh2n8b-1{list-style-type:none}ul.lst-kix_6o2cphkh2n8b-0{list-style-type:none}.lst-kix_bv8sxewi94yp-0>li:before{content:"-  "}.lst-kix_qccibyu36y2t-6>li:before{content:"-  "}.lst-kix_pejjsijavmae-0>li:before{content:"-  "}ol.lst-kix_t3rn73qejgkj-1.start{counter-reset:lst-ctn-kix_t3rn73qejgkj-1 0}ol.lst-kix_g8jgbze430sv-7{list-style-type:none}ol.lst-kix_g8jgbze430sv-6{list-style-type:none}.lst-kix_yk26x5gkc3g4-1>li:before{content:"-  "}ol.lst-kix_g8jgbze430sv-8{list-style-type:none}ol.lst-kix_g8jgbze430sv-3{list-style-type:none}ol.lst-kix_g8jgbze430sv-2{list-style-type:none}ol.lst-kix_g8jgbze430sv-5{list-style-type:none}ol.lst-kix_g8jgbze430sv-4{list-style-type:none}.lst-kix_ypd5gkkarijk-2>li:before{content:"" counter(lst-ctn-kix_ypd5gkkarijk-2,decimal) ") "}.lst-kix_6xh4bfg7mbxi-6>li:before{content:"-  "}ul.lst-kix_8euewcidoez8-0{list-style-type:none}ul.lst-kix_8euewcidoez8-8{list-style-type:none}ul.lst-kix_8euewcidoez8-7{list-style-type:none}.lst-kix_oc7itsrfkmqv-6>li:before{content:"-  "}ul.lst-kix_8euewcidoez8-6{list-style-type:none}ul.lst-kix_8euewcidoez8-5{list-style-type:none}ul.lst-kix_8euewcidoez8-4{list-style-type:none}.lst-kix_vkdxjlf0kb6j-5>li:before{content:"" counter(lst-ctn-kix_vkdxjlf0kb6j-5,lower-roman) ". "}ul.lst-kix_8euewcidoez8-3{list-style-type:none}ul.lst-kix_8euewcidoez8-2{list-style-type:none}ul.lst-kix_8euewcidoez8-1{list-style-type:none}.lst-kix_8hf94791m5p0-6>li:before{content:"-  "}.lst-kix_84zf7o74c8s9-4>li{counter-increment:lst-ctn-kix_84zf7o74c8s9-4}.lst-kix_kzw7lb63578w-0>li:before{content:"-  "}.lst-kix_3novkjnl93sa-6>li:before{content:"-  "}.lst-kix_r8azi25kh461-0>li:before{content:"\0025cf   "}ol.lst-kix_90bg3luq5inv-6.start{counter-reset:lst-ctn-kix_90bg3luq5inv-6 0}ul.lst-kix_alhag51wggig-4{list-style-type:none}.lst-kix_df6s37r8voak-4>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-8>li:before{content:"" counter(lst-ctn-kix_u8nobwiguyj1-8,lower-roman) ". "}ul.lst-kix_alhag51wggig-3{list-style-type:none}ul.lst-kix_alhag51wggig-6{list-style-type:none}ul.lst-kix_alhag51wggig-5{list-style-type:none}ul.lst-kix_alhag51wggig-8{list-style-type:none}.lst-kix_7o5enrj2ko1w-0>li:before{content:"-  "}ul.lst-kix_alhag51wggig-7{list-style-type:none}.lst-kix_fifu4bguh6qm-2>li:before{content:"-  "}ul.lst-kix_tfqdu2hgmdym-5{list-style-type:none}ul.lst-kix_tfqdu2hgmdym-6{list-style-type:none}.lst-kix_cpgerodpupjz-3>li:before{content:"-  "}ul.lst-kix_tfqdu2hgmdym-7{list-style-type:none}ul.lst-kix_tfqdu2hgmdym-8{list-style-type:none}ul.lst-kix_alhag51wggig-0{list-style-type:none}.lst-kix_66ns622ckygr-0>li:before{content:"-  "}ul.lst-kix_alhag51wggig-2{list-style-type:none}ul.lst-kix_alhag51wggig-1{list-style-type:none}ol.lst-kix_23ct987xwu67-5.start{counter-reset:lst-ctn-kix_23ct987xwu67-5 0}.lst-kix_84zf7o74c8s9-0>li:before{content:"" counter(lst-ctn-kix_84zf7o74c8s9-0,decimal) ".) "}ul.lst-kix_tfqdu2hgmdym-0{list-style-type:none}ol.lst-kix_267f3xfv5ddr-3.start{counter-reset:lst-ctn-kix_267f3xfv5ddr-3 0}ul.lst-kix_tfqdu2hgmdym-1{list-style-type:none}ul.lst-kix_tfqdu2hgmdym-2{list-style-type:none}.lst-kix_w32pgwk3f0lb-8>li:before{content:"-  "}ul.lst-kix_tfqdu2hgmdym-3{list-style-type:none}ul.lst-kix_tfqdu2hgmdym-4{list-style-type:none}.lst-kix_1kbilie4yf3o-3>li:before{content:"-  "}.lst-kix_3ez3vzcedsa0-1>li:before{content:"-  "}.lst-kix_rf1gg3liws68-4>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-5>li{counter-increment:lst-ctn-kix_ykhoydml7pv3-5}.lst-kix_5l84eporjaw3-1>li:before{content:"-  "}.lst-kix_aeppt4sbsnmp-4>li:before{content:"-  "}ul.lst-kix_2ei6b6e4ow80-4{list-style-type:none}.lst-kix_uvjyeruqqfgv-0>li:before{content:"-  "}ul.lst-kix_2ei6b6e4ow80-5{list-style-type:none}ul.lst-kix_2ei6b6e4ow80-2{list-style-type:none}ul.lst-kix_2ei6b6e4ow80-3{list-style-type:none}ul.lst-kix_2ei6b6e4ow80-0{list-style-type:none}ul.lst-kix_2ei6b6e4ow80-1{list-style-type:none}.lst-kix_6pgojrjbxqei-7>li:before{content:"\0025cb   "}.lst-kix_23ct987xwu67-7>li:before{content:"" counter(lst-ctn-kix_23ct987xwu67-7,lower-latin) ". "}ul.lst-kix_2ei6b6e4ow80-8{list-style-type:none}ul.lst-kix_2ei6b6e4ow80-6{list-style-type:none}ul.lst-kix_2ei6b6e4ow80-7{list-style-type:none}ul.lst-kix_q8ex99of35ig-2{list-style-type:none}.lst-kix_ysfu1bl0kymd-6>li:before{content:"" counter(lst-ctn-kix_ysfu1bl0kymd-6,decimal) ". "}ul.lst-kix_q8ex99of35ig-3{list-style-type:none}ul.lst-kix_q8ex99of35ig-0{list-style-type:none}ul.lst-kix_q8ex99of35ig-1{list-style-type:none}ul.lst-kix_q8ex99of35ig-6{list-style-type:none}.lst-kix_x12ed5cs6o9z-1>li:before{content:"-  "}ul.lst-kix_q8ex99of35ig-7{list-style-type:none}ul.lst-kix_q8ex99of35ig-4{list-style-type:none}ul.lst-kix_q8ex99of35ig-5{list-style-type:none}.lst-kix_axy5kxvo2nx7-7>li:before{content:"-  "}ul.lst-kix_q8ex99of35ig-8{list-style-type:none}.lst-kix_kobinbwr4qr6-5>li:before{content:"-  "}.lst-kix_qqbjjwnrc3l8-7>li:before{content:"-  "}.lst-kix_jhofo94iol1-3>li:before{content:"-  "}ul.lst-kix_g9hblcm1l6tk-8{list-style-type:none}ul.lst-kix_g9hblcm1l6tk-7{list-style-type:none}ul.lst-kix_g9hblcm1l6tk-6{list-style-type:none}.lst-kix_p02ob1bzv6e4-8>li:before{content:"-  "}ul.lst-kix_g9hblcm1l6tk-5{list-style-type:none}ul.lst-kix_g9hblcm1l6tk-4{list-style-type:none}ul.lst-kix_g9hblcm1l6tk-3{list-style-type:none}.lst-kix_iupg79bv69ia-2>li:before{content:"-  "}ul.lst-kix_g9hblcm1l6tk-2{list-style-type:none}ul.lst-kix_g9hblcm1l6tk-1{list-style-type:none}ul.lst-kix_g9hblcm1l6tk-0{list-style-type:none}.lst-kix_wsu1hpz6hqq4-7>li:before{content:"-  "}.lst-kix_eh3u7tkoktop-8>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-5>li{counter-increment:lst-ctn-kix_sxixw4iqsgzx-5}.lst-kix_ivmzvkm69gsd-2>li:before{content:"-  "}.lst-kix_unv0ib1v43rp-6>li:before{content:"-  "}.lst-kix_qij6192l4p0g-2>li:before{content:"-  "}.lst-kix_c73c2x77meqo-7>li:before{content:"-  "}.lst-kix_izios9u5ks4s-7>li:before{content:"-  "}.lst-kix_waivoqs1cu5x-0>li:before{content:"-  "}ol.lst-kix_267f3xfv5ddr-7.start{counter-reset:lst-ctn-kix_267f3xfv5ddr-7 0}.lst-kix_x96zthrcdy1e-2>li:before{content:"-  "}ol.lst-kix_xktbtduo53bq-1.start{counter-reset:lst-ctn-kix_xktbtduo53bq-1 0}.lst-kix_f9iqanr8ite6-6>li:before{content:"-  "}.lst-kix_5ze5xofgghz2-3>li:before{content:"-  "}.lst-kix_n0rv3zxivae3-6>li:before{content:"-  "}ul.lst-kix_z6rr709h3fky-3{list-style-type:none}ol.lst-kix_267f3xfv5ddr-6.start{counter-reset:lst-ctn-kix_267f3xfv5ddr-6 0}ul.lst-kix_z6rr709h3fky-2{list-style-type:none}ul.lst-kix_z6rr709h3fky-1{list-style-type:none}ol.lst-kix_xktbtduo53bq-0.start{counter-reset:lst-ctn-kix_xktbtduo53bq-0 0}ul.lst-kix_z6rr709h3fky-0{list-style-type:none}.lst-kix_mvektlca5c5q-7>li:before{content:"-  "}ul.lst-kix_z6rr709h3fky-8{list-style-type:none}.lst-kix_bnvwt1y8k7b-1>li:before{content:"-  "}ul.lst-kix_z6rr709h3fky-7{list-style-type:none}ul.lst-kix_z6rr709h3fky-6{list-style-type:none}ul.lst-kix_z6rr709h3fky-5{list-style-type:none}ul.lst-kix_z6rr709h3fky-4{list-style-type:none}.lst-kix_qmryaqe19okh-8>li:before{content:"-  "}.lst-kix_549l9aqx2sdy-2>li:before{content:"-  "}.lst-kix_ksf6p4xm2w0d-5>li:before{content:"-  "}.lst-kix_hsahb38tz2f5-2>li:before{content:"-  "}.lst-kix_pgnpvlxhai6o-5>li:before{content:"-  "}.lst-kix_qmx92jmkghx8-5>li:before{content:"-  "}.lst-kix_st0egafmkg0z-4>li:before{content:"-  "}ul.lst-kix_4voxeic75vm5-2{list-style-type:none}.lst-kix_hsahb38tz2f5-1>li:before{content:"-  "}ul.lst-kix_4voxeic75vm5-1{list-style-type:none}ul.lst-kix_4voxeic75vm5-4{list-style-type:none}ul.lst-kix_4voxeic75vm5-3{list-style-type:none}.lst-kix_bnte1i3g4kjh-8>li:before{content:"-  "}ul.lst-kix_4voxeic75vm5-0{list-style-type:none}.lst-kix_gvlgpawofwi7-2>li:before{content:"-  "}.lst-kix_2r20t3tmnrwb-4>li:before{content:"-  "}ul.lst-kix_4voxeic75vm5-6{list-style-type:none}ul.lst-kix_4voxeic75vm5-5{list-style-type:none}ul.lst-kix_4voxeic75vm5-8{list-style-type:none}.lst-kix_bnte1i3g4kjh-2>li:before{content:"-  "}.lst-kix_yrg2qlcqvak1-5>li:before{content:"-  "}ul.lst-kix_4voxeic75vm5-7{list-style-type:none}.lst-kix_1v1216yy0n25-8>li:before{content:"-  "}.lst-kix_7vr84ges94ry-2>li:before{content:"-  "}.lst-kix_4i10vbfgn91y-5>li:before{content:"-  "}.lst-kix_eme1x4epzdye-8>li:before{content:"-  "}.lst-kix_6o2cphkh2n8b-6>li:before{content:"-  "}.lst-kix_dvvzixfw64a1-4>li:before{content:"-  "}.lst-kix_svg8hnl23b1r-0>li:before{content:"-  "}.lst-kix_6o2cphkh2n8b-0>li:before{content:"-  "}.lst-kix_7vr84ges94ry-8>li:before{content:"-  "}.lst-kix_ug10x97qcpi8-5>li:before{content:"-  "}ol.lst-kix_azgj6sn0lxuj-5.start{counter-reset:lst-ctn-kix_azgj6sn0lxuj-5 0}.lst-kix_qw2h6jd8xi17-6>li:before{content:"-  "}.lst-kix_n9q8wqas57a-7>li:before{content:"-  "}ul.lst-kix_qsto019ofcm1-3{list-style-type:none}ul.lst-kix_qsto019ofcm1-2{list-style-type:none}ul.lst-kix_qsto019ofcm1-1{list-style-type:none}ul.lst-kix_qsto019ofcm1-0{list-style-type:none}ul.lst-kix_qsto019ofcm1-7{list-style-type:none}ul.lst-kix_qsto019ofcm1-6{list-style-type:none}ul.lst-kix_qsto019ofcm1-5{list-style-type:none}ul.lst-kix_qsto019ofcm1-4{list-style-type:none}ul.lst-kix_qsto019ofcm1-8{list-style-type:none}.lst-kix_co74fk70kphx-3>li:before{content:"-  "}.lst-kix_qw2h6jd8xi17-0>li:before{content:"-  "}.lst-kix_eme1x4epzdye-2>li:before{content:"-  "}.lst-kix_3nq914pozpi7-1>li:before{content:"-  "}.lst-kix_n9q8wqas57a-1>li:before{content:"-  "}.lst-kix_hmvj5t8yy8bx-3>li:before{content:"+  "}.lst-kix_gaq1zvh4dcgb-8>li:before{content:"-  "}ul.lst-kix_tt1bo8z9re67-8{list-style-type:none}.lst-kix_gaq1zvh4dcgb-2>li:before{content:"-  "}.lst-kix_gvlgpawofwi7-8>li:before{content:"-  "}ul.lst-kix_tt1bo8z9re67-7{list-style-type:none}.lst-kix_aor1182clqbr-3>li:before{content:"-  "}ul.lst-kix_tt1bo8z9re67-6{list-style-type:none}ul.lst-kix_tt1bo8z9re67-5{list-style-type:none}ul.lst-kix_tt1bo8z9re67-4{list-style-type:none}ul.lst-kix_tt1bo8z9re67-3{list-style-type:none}ul.lst-kix_tt1bo8z9re67-2{list-style-type:none}.lst-kix_tt1bo8z9re67-3>li:before{content:"-  "}.lst-kix_4qbfcta6cclt-3>li:before{content:"-  "}ul.lst-kix_tt1bo8z9re67-1{list-style-type:none}.lst-kix_tdrf79x9zyr7-2>li:before{content:"-  "}ul.lst-kix_tt1bo8z9re67-0{list-style-type:none}.lst-kix_1v1216yy0n25-2>li:before{content:"-  "}.lst-kix_8euewcidoez8-3>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-7>li{counter-increment:lst-ctn-kix_sxixw4iqsgzx-7}.lst-kix_jfoqdfq6uhww-7>li:before{content:"-  "}.lst-kix_k5hm652wcnm2-5>li:before{content:"-  "}ul.lst-kix_vhhvekoaa9d4-0{list-style-type:none}.lst-kix_8w7txqc6xq66-3>li:before{content:"-  "}.lst-kix_np9h4y3kt4yk-4>li:before{content:"-  "}.lst-kix_xx6ude5yqnkl-5>li:before{content:"\0025a0   "}.lst-kix_hkt83gwcgrvq-6>li:before{content:"-  "}.lst-kix_v0hsa7m5lywt-0>li:before{content:"-  "}.lst-kix_a2xq56ushw0p-4>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-6>li:before{content:"" counter(lst-ctn-kix_d1gy3hy5r3qj-6,decimal) ". "}.lst-kix_35hvjwgc3k2f-4>li:before{content:"-  "}.lst-kix_tdrf79x9zyr7-8>li:before{content:"-  "}.lst-kix_vayf18aqt55o-3>li:before{content:"(" counter(lst-ctn-kix_vayf18aqt55o-3,lower-latin) ") "}.lst-kix_6m4qu83yomn7-8>li:before{content:"-  "}ul.lst-kix_vhhvekoaa9d4-6{list-style-type:none}ul.lst-kix_vhhvekoaa9d4-5{list-style-type:none}ul.lst-kix_vhhvekoaa9d4-8{list-style-type:none}ul.lst-kix_vhhvekoaa9d4-7{list-style-type:none}.lst-kix_rxmcp67o7upe-1>li:before{content:"-  "}ul.lst-kix_vhhvekoaa9d4-2{list-style-type:none}ul.lst-kix_vhhvekoaa9d4-1{list-style-type:none}ul.lst-kix_vhhvekoaa9d4-4{list-style-type:none}.lst-kix_6m4qu83yomn7-2>li:before{content:"-  "}ul.lst-kix_vhhvekoaa9d4-3{list-style-type:none}.lst-kix_rt3ua1vpzay9-3>li:before{content:"-  "}.lst-kix_wnr3c516ni7j-8>li:before{content:"-  "}.lst-kix_jfoqdfq6uhww-1>li:before{content:"-  "}.lst-kix_6u6or33vx86s-3>li:before{content:"-  "}.lst-kix_3nq914pozpi7-7>li:before{content:"-  "}ul.lst-kix_jvmsa1jxmzig-0{list-style-type:none}ul.lst-kix_jvmsa1jxmzig-1{list-style-type:none}ul.lst-kix_jvmsa1jxmzig-2{list-style-type:none}ul.lst-kix_jvmsa1jxmzig-3{list-style-type:none}.lst-kix_svg8hnl23b1r-6>li:before{content:"-  "}ul.lst-kix_jvmsa1jxmzig-4{list-style-type:none}ul.lst-kix_jvmsa1jxmzig-5{list-style-type:none}.lst-kix_ms4jfr9nudpc-7>li:before{content:"-  "}.lst-kix_yhq927c05ak0-2>li:before{content:"-  "}.lst-kix_yhq927c05ak0-8>li:before{content:"-  "}.lst-kix_7rlftcume51v-3>li:before{content:"-  "}.lst-kix_6ltb10qoez57-4>li:before{content:"\0025cb   "}.lst-kix_oxgbebk5l98i-8>li:before{content:"-  "}.lst-kix_l5iaj94ondn3-7>li:before{content:"-  "}.lst-kix_ms4jfr9nudpc-1>li:before{content:"-  "}.lst-kix_mb1zrov3n6kx-7>li:before{content:"-  "}.lst-kix_qmryaqe19okh-1>li:before{content:"-  "}.lst-kix_bswxvn1l22fp-4>li:before{content:"-  "}.lst-kix_hsahb38tz2f5-7>li:before{content:"-  "}.lst-kix_qmryaqe19okh-7>li:before{content:"-  "}.lst-kix_cwjen7nun640-4>li:before{content:"-  "}.lst-kix_w97kncqyzxj3-4>li:before{content:"\0025cb   "}ul.lst-kix_jvmsa1jxmzig-6{list-style-type:none}.lst-kix_v0hsa7m5lywt-6>li:before{content:"-  "}ul.lst-kix_jvmsa1jxmzig-7{list-style-type:none}ul.lst-kix_jvmsa1jxmzig-8{list-style-type:none}.lst-kix_st0egafmkg0z-3>li:before{content:"-  "}.lst-kix_qzg09ck6gr7w-1>li:before{content:"-  "}.lst-kix_vie3q5oyli2z-7>li:before{content:"-  "}.lst-kix_i2q40uf7647f-3>li:before{content:"-  "}.lst-kix_qccibyu36y2t-7>li:before{content:"-  "}ul.lst-kix_awlaex77cpwh-0{list-style-type:none}ul.lst-kix_awlaex77cpwh-2{list-style-type:none}ul.lst-kix_awlaex77cpwh-1{list-style-type:none}ul.lst-kix_awlaex77cpwh-4{list-style-type:none}ul.lst-kix_awlaex77cpwh-3{list-style-type:none}ul.lst-kix_awlaex77cpwh-6{list-style-type:none}.lst-kix_932mko8sjg0u-8>li:before{content:"-  "}ul.lst-kix_awlaex77cpwh-5{list-style-type:none}ul.lst-kix_awlaex77cpwh-8{list-style-type:none}ul.lst-kix_awlaex77cpwh-7{list-style-type:none}.lst-kix_5argtotmwusw-8>li:before{content:"-  "}.lst-kix_4voxeic75vm5-2>li:before{content:"-  "}.lst-kix_y32h08wggx1t-8>li:before{content:"-  "}.lst-kix_dn04c4yafie0-1>li:before{content:"-  "}ul.lst-kix_wsu1hpz6hqq4-0{list-style-type:none}.lst-kix_owvy3cstzf0s-5>li:before{content:"-  "}ul.lst-kix_wsu1hpz6hqq4-7{list-style-type:none}ul.lst-kix_wsu1hpz6hqq4-8{list-style-type:none}ul.lst-kix_wsu1hpz6hqq4-5{list-style-type:none}.lst-kix_oxgbebk5l98i-2>li:before{content:"-  "}ul.lst-kix_wsu1hpz6hqq4-6{list-style-type:none}ul.lst-kix_wsu1hpz6hqq4-3{list-style-type:none}ul.lst-kix_wsu1hpz6hqq4-4{list-style-type:none}ul.lst-kix_wsu1hpz6hqq4-1{list-style-type:none}ul.lst-kix_wsu1hpz6hqq4-2{list-style-type:none}.lst-kix_u8nobwiguyj1-7>li:before{content:"" counter(lst-ctn-kix_u8nobwiguyj1-7,lower-latin) ". "}.lst-kix_jnfn9mx5o33t-4>li:before{content:"-  "}.lst-kix_8w03xjt2k9bc-8>li:before{content:"-  "}.lst-kix_n9qabngdxy64-0>li:before{content:"-  "}.lst-kix_fs1lzw38maxl-4>li:before{content:"-  "}.lst-kix_ro388iryhhf5-3>li:before{content:"-  "}ol.lst-kix_vgg0538grxk3-2.start{counter-reset:lst-ctn-kix_vgg0538grxk3-2 0}.lst-kix_cd2o0cncsajm-2>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-6>li{counter-increment:lst-ctn-kix_yjf6dvvoob64-6}.lst-kix_b3ghc04lfx9t-4>li:before{content:"-  "}ol.lst-kix_xyra4e5ffsud-3.start{counter-reset:lst-ctn-kix_xyra4e5ffsud-3 0}ol.lst-kix_ykhoydml7pv3-6.start{counter-reset:lst-ctn-kix_ykhoydml7pv3-6 0}.lst-kix_vgg0538grxk3-4>li{counter-increment:lst-ctn-kix_vgg0538grxk3-4}.lst-kix_5rn2qrejqs3r-2>li:before{content:"-  "}.lst-kix_7o1va6u13ska-3>li:before{content:"-  "}.lst-kix_cg6jep1fmawj-4>li:before{content:"-  "}.lst-kix_hkt83gwcgrvq-0>li:before{content:"-  "}.lst-kix_81v91kbrmywy-3>li:before{content:"-  "}.lst-kix_3i5qlhg977l0-7>li:before{content:"-  "}.lst-kix_q24qpifeknc3-0>li:before{content:"-  "}ol.lst-kix_3mj3tp7kj9db-5.start{counter-reset:lst-ctn-kix_3mj3tp7kj9db-5 0}.lst-kix_9z31rmzc855z-0>li:before{content:"-  "}.lst-kix_o1voy78o4juz-5>li:before{content:"-  "}.lst-kix_wwm574aidb8n-4>li:before{content:"-  "}.lst-kix_52jgzw489fhs-4>li{counter-increment:lst-ctn-kix_52jgzw489fhs-4}.lst-kix_a62ncfcuapzo-3>li:before{content:"-  "}.lst-kix_m5azvtuvtpt1-2>li:before{content:"-  "}ol.lst-kix_2foc6u9lzfq4-8.start{counter-reset:lst-ctn-kix_2foc6u9lzfq4-8 0}.lst-kix_eiskzjj27gc6-8>li:before{content:"-  "}.lst-kix_9a7xq1ie41tp-5>li:before{content:"-  "}.lst-kix_d7eif1vat32g-4>li:before{content:"-  "}.lst-kix_3q7au8a3gwav-8>li:before{content:"-  "}.lst-kix_axy5kxvo2nx7-1>li:before{content:"-  "}.lst-kix_3mj3tp7kj9db-2>li:before{content:"" counter(lst-ctn-kix_3mj3tp7kj9db-2,lower-roman) ") "}ol.lst-kix_84zf7o74c8s9-1.start{counter-reset:lst-ctn-kix_84zf7o74c8s9-1 0}.lst-kix_ekasiajyrrvz-1>li:before{content:"-  "}.lst-kix_hngwf7orguk6-4>li:before{content:"-  "}.lst-kix_n0rv3zxivae3-0>li:before{content:"-  "}.lst-kix_bp67ajcb7c38-0>li:before{content:"-  "}.lst-kix_chbthqdwx7gj-1>li:before{content:"-  "}.lst-kix_njs8ubf1qesf-5>li:before{content:"-  "}.lst-kix_qvomcnyqz8ao-0>li:before{content:"-  "}.lst-kix_incqcf2p39ls-3>li{counter-increment:lst-ctn-kix_incqcf2p39ls-3}.lst-kix_mvektlca5c5q-1>li:before{content:"-  "}.lst-kix_x1xhkkpc69w2-5>li:before{content:"-  "}.lst-kix_rtczm6eelr4h-5>li:before{content:"-  "}.lst-kix_rxgry66ibim8-3>li:before{content:"-  "}ul.lst-kix_o1voy78o4juz-8{list-style-type:none}ul.lst-kix_o1voy78o4juz-7{list-style-type:none}ul.lst-kix_o1voy78o4juz-6{list-style-type:none}.lst-kix_rcfi5jnwnxji-7>li:before{content:"-  "}.lst-kix_bpsiys7g173w-7>li:before{content:"-  "}.lst-kix_xs6xjhigrbe2-4>li:before{content:"-  "}.lst-kix_x12ed5cs6o9z-7>li:before{content:"-  "}.lst-kix_5stj9b6acoxv-7>li:before{content:"" counter(lst-ctn-kix_5stj9b6acoxv-7,lower-latin) ". "}ul.lst-kix_o1voy78o4juz-1{list-style-type:none}ul.lst-kix_o1voy78o4juz-0{list-style-type:none}ul.lst-kix_o1voy78o4juz-5{list-style-type:none}ul.lst-kix_o1voy78o4juz-4{list-style-type:none}.lst-kix_8nwtyhgsvjlm-2>li:before{content:"-  "}ul.lst-kix_o1voy78o4juz-3{list-style-type:none}.lst-kix_23ct987xwu67-7>li{counter-increment:lst-ctn-kix_23ct987xwu67-7}.lst-kix_ellvdfsu2z7q-5>li:before{content:"-  "}ul.lst-kix_o1voy78o4juz-2{list-style-type:none}ul.lst-kix_v6dv769q7bq3-6{list-style-type:none}ul.lst-kix_v6dv769q7bq3-5{list-style-type:none}ul.lst-kix_v6dv769q7bq3-4{list-style-type:none}ul.lst-kix_v6dv769q7bq3-3{list-style-type:none}ul.lst-kix_v6dv769q7bq3-8{list-style-type:none}.lst-kix_rgd2g4si1ihs-0>li:before{content:"-  "}.lst-kix_kxjfd2xlpmu-6>li:before{content:"-  "}ul.lst-kix_v6dv769q7bq3-7{list-style-type:none}.lst-kix_r8adx85jg0iz-7>li:before{content:"-  "}ul.lst-kix_v6dv769q7bq3-2{list-style-type:none}ul.lst-kix_v6dv769q7bq3-1{list-style-type:none}ul.lst-kix_v6dv769q7bq3-0{list-style-type:none}.lst-kix_bo9wrgz88es4-2>li:before{content:"-  "}.lst-kix_e73zm9q3mvin-1>li:before{content:"-  "}ol.lst-kix_hppu19i8fr2p-3.start{counter-reset:lst-ctn-kix_hppu19i8fr2p-3 0}.lst-kix_23ct987xwu67-2>li{counter-increment:lst-ctn-kix_23ct987xwu67-2}.lst-kix_f9iu0trsjas1-8>li:before{content:"-  "}.lst-kix_luixtz7s7e5x-4>li:before{content:"-  "}.lst-kix_g9hblcm1l6tk-3>li:before{content:"-  "}.lst-kix_s0nbf6s2np44-3>li:before{content:"-  "}.lst-kix_rgd2g4si1ihs-6>li:before{content:"-  "}.lst-kix_qvomcnyqz8ao-6>li:before{content:"-  "}.lst-kix_7e64bsb5krip-4>li:before{content:"-  "}.lst-kix_ozbrn4vmjez8-4>li:before{content:"-  "}.lst-kix_bp67ajcb7c38-6>li:before{content:"-  "}.lst-kix_kt8k33f35qi5-0>li:before{content:"-  "}.lst-kix_g0lr2dxtnslc-1>li:before{content:"-  "}.lst-kix_w21i9d12ynhg-3>li:before{content:"-  "}.lst-kix_2xixyk6jteti-5>li:before{content:"-  "}.lst-kix_nqtgcebhe8ii-4>li:before{content:"-  "}.lst-kix_vvjhovkzyen7-0>li:before{content:"-  "}.lst-kix_ce3ho29dhteb-8>li:before{content:"-  "}ol.lst-kix_sxixw4iqsgzx-4.start{counter-reset:lst-ctn-kix_sxixw4iqsgzx-4 0}.lst-kix_zjjx8lb18sy-7>li:before{content:"-  "}.lst-kix_incqcf2p39ls-3>li:before{content:"(" counter(lst-ctn-kix_incqcf2p39ls-3,decimal) ") "}.lst-kix_ms6rbzn59hmq-5>li:before{content:"-  "}.lst-kix_bsvmcpoa86br-5>li:before{content:"-  "}.lst-kix_zb3jq278pptw-0>li:before{content:"-  "}.lst-kix_zjjx8lb18sy-1>li:before{content:"-  "}.lst-kix_vvjhovkzyen7-6>li:before{content:"-  "}.lst-kix_r8adx85jg0iz-1>li:before{content:"-  "}.lst-kix_8a5plp401pog-4>li:before{content:"-  "}.lst-kix_t6x6ie377r4u-2>li:before{content:"-  "}.lst-kix_jvmsa1jxmzig-0>li:before{content:"\0025cf   "}.lst-kix_mq980hprr5hl-8>li:before{content:"-  "}.lst-kix_p02ob1bzv6e4-1>li:before{content:"-  "}.lst-kix_qb494lue4ahb-5>li:before{content:"-  "}.lst-kix_iupg79bv69ia-3>li:before{content:"-  "}.lst-kix_kobinbwr4qr6-4>li:before{content:"-  "}.lst-kix_9hby2lis2y9u-5>li:before{content:"-  "}.lst-kix_innl5fto9oyf-1>li:before{content:"-  "}.lst-kix_mq980hprr5hl-2>li:before{content:"-  "}.lst-kix_p02ob1bzv6e4-7>li:before{content:"-  "}.lst-kix_6n4varno3bjs-7>li:before{content:"-  "}.lst-kix_52jgzw489fhs-5>li:before{content:"" counter(lst-ctn-kix_52jgzw489fhs-5,lower-roman) ". "}.lst-kix_alhag51wggig-8>li:before{content:"-  "}ul.lst-kix_43bwriak8ne4-5{list-style-type:none}ul.lst-kix_43bwriak8ne4-6{list-style-type:none}ul.lst-kix_43bwriak8ne4-3{list-style-type:none}ul.lst-kix_43bwriak8ne4-4{list-style-type:none}ul.lst-kix_43bwriak8ne4-1{list-style-type:none}.lst-kix_5jp9wppv00ra-1>li:before{content:"-  "}ul.lst-kix_43bwriak8ne4-2{list-style-type:none}ul.lst-kix_43bwriak8ne4-0{list-style-type:none}.lst-kix_4z9ptm6a4lke-0>li:before{content:"-  "}.lst-kix_qij6192l4p0g-3>li:before{content:"-  "}.lst-kix_t6x6ie377r4u-8>li:before{content:"-  "}.lst-kix_oswsfzrgbvyb-6>li:before{content:"-  "}.lst-kix_69k4orytle42-2>li:before{content:"\0025a0   "}.lst-kix_n9qabngdxy64-6>li:before{content:"-  "}.lst-kix_c73c2x77meqo-6>li:before{content:"-  "}.lst-kix_aikphwux0ki0-1>li:before{content:"-  "}.lst-kix_izios9u5ks4s-8>li:before{content:"-  "}.lst-kix_om0x63wgf9wd-5>li:before{content:"-  "}.lst-kix_c73c2x77meqo-0>li:before{content:"-  "}ul.lst-kix_1tib71bbsugw-0{list-style-type:none}ul.lst-kix_43bwriak8ne4-7{list-style-type:none}.lst-kix_upq3ni6ul8eb-4>li:before{content:"-  "}ul.lst-kix_43bwriak8ne4-8{list-style-type:none}ul.lst-kix_1tib71bbsugw-2{list-style-type:none}ul.lst-kix_1tib71bbsugw-1{list-style-type:none}ul.lst-kix_1tib71bbsugw-4{list-style-type:none}.lst-kix_5quy3fbj2mfg-4>li:before{content:"-  "}ul.lst-kix_1tib71bbsugw-3{list-style-type:none}.lst-kix_khixc8f7o03u-3>li:before{content:"-  "}ul.lst-kix_1tib71bbsugw-6{list-style-type:none}ul.lst-kix_1tib71bbsugw-5{list-style-type:none}ul.lst-kix_1tib71bbsugw-8{list-style-type:none}.lst-kix_alhag51wggig-2>li:before{content:"-  "}ul.lst-kix_1tib71bbsugw-7{list-style-type:none}.lst-kix_5jp9wppv00ra-7>li:before{content:"-  "}.lst-kix_4voxeic75vm5-8>li:before{content:"-  "}.lst-kix_wzt7symqmcfu-5>li:before{content:"-  "}.lst-kix_bnvwt1y8k7b-2>li:before{content:"-  "}.lst-kix_tjrvr4c0ezjq-3>li:before{content:"-  "}ul.lst-kix_a2xq56ushw0p-8{list-style-type:none}.lst-kix_549l9aqx2sdy-1>li:before{content:"-  "}.lst-kix_aikphwux0ki0-7>li:before{content:"-  "}ul.lst-kix_a2xq56ushw0p-7{list-style-type:none}ul.lst-kix_a2xq56ushw0p-6{list-style-type:none}ul.lst-kix_a2xq56ushw0p-5{list-style-type:none}ul.lst-kix_a2xq56ushw0p-4{list-style-type:none}ul.lst-kix_a2xq56ushw0p-3{list-style-type:none}ul.lst-kix_a2xq56ushw0p-2{list-style-type:none}ul.lst-kix_a2xq56ushw0p-1{list-style-type:none}.lst-kix_ksf6p4xm2w0d-4>li:before{content:"-  "}ul.lst-kix_a2xq56ushw0p-0{list-style-type:none}.lst-kix_r8i1fgeyliey-4>li:before{content:"-  "}ol.lst-kix_d1gy3hy5r3qj-2.start{counter-reset:lst-ctn-kix_d1gy3hy5r3qj-2 0}.lst-kix_dyq7vlcdkqm5-0>li:before{content:"-  "}.lst-kix_hyuyjld7ihkv-8>li:before{content:"-  "}ol.lst-kix_52jgzw489fhs-6.start{counter-reset:lst-ctn-kix_52jgzw489fhs-6 0}.lst-kix_bnvwt1y8k7b-8>li:before{content:"-  "}.lst-kix_sxixw4iqsgzx-0>li{counter-increment:lst-ctn-kix_sxixw4iqsgzx-0}.lst-kix_dynlpr2uwt2p-4>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-7>li{counter-increment:lst-ctn-kix_ykhoydml7pv3-7}.lst-kix_hppu19i8fr2p-6>li{counter-increment:lst-ctn-kix_hppu19i8fr2p-6}ul.lst-kix_rgd2g4si1ihs-1{list-style-type:none}.lst-kix_ykhoydml7pv3-3>li:before{content:"(" counter(lst-ctn-kix_ykhoydml7pv3-3,decimal) ") "}ul.lst-kix_rgd2g4si1ihs-0{list-style-type:none}ul.lst-kix_rgd2g4si1ihs-3{list-style-type:none}ul.lst-kix_rgd2g4si1ihs-2{list-style-type:none}ul.lst-kix_rgd2g4si1ihs-5{list-style-type:none}ul.lst-kix_rgd2g4si1ihs-4{list-style-type:none}ul.lst-kix_rgd2g4si1ihs-7{list-style-type:none}ul.lst-kix_rgd2g4si1ihs-6{list-style-type:none}ul.lst-kix_mb1zrov3n6kx-8{list-style-type:none}.lst-kix_hssoi9jbujv-4>li:before{content:"-  "}ul.lst-kix_mb1zrov3n6kx-6{list-style-type:none}ul.lst-kix_mb1zrov3n6kx-7{list-style-type:none}.lst-kix_l5iaj94ondn3-1>li:before{content:"-  "}ul.lst-kix_mb1zrov3n6kx-4{list-style-type:none}ul.lst-kix_mb1zrov3n6kx-5{list-style-type:none}ul.lst-kix_mb1zrov3n6kx-2{list-style-type:none}ul.lst-kix_iupg79bv69ia-3{list-style-type:none}ul.lst-kix_mb1zrov3n6kx-3{list-style-type:none}ul.lst-kix_iupg79bv69ia-4{list-style-type:none}ul.lst-kix_mb1zrov3n6kx-0{list-style-type:none}.lst-kix_8hf94791m5p0-5>li:before{content:"-  "}ul.lst-kix_iupg79bv69ia-1{list-style-type:none}ul.lst-kix_mb1zrov3n6kx-1{list-style-type:none}ul.lst-kix_iupg79bv69ia-2{list-style-type:none}ul.lst-kix_iupg79bv69ia-0{list-style-type:none}.lst-kix_3novkjnl93sa-7>li:before{content:"-  "}.lst-kix_67mv29rpwb23-3>li:before{content:"-  "}ul.lst-kix_rgd2g4si1ihs-8{list-style-type:none}ul.lst-kix_iupg79bv69ia-7{list-style-type:none}.lst-kix_urqiwn6svi1d-2>li:before{content:"-  "}ul.lst-kix_iupg79bv69ia-8{list-style-type:none}ul.lst-kix_iupg79bv69ia-5{list-style-type:none}ul.lst-kix_iupg79bv69ia-6{list-style-type:none}ul.lst-kix_3nq914pozpi7-0{list-style-type:none}ul.lst-kix_3nq914pozpi7-1{list-style-type:none}ul.lst-kix_3nq914pozpi7-2{list-style-type:none}ul.lst-kix_3nq914pozpi7-3{list-style-type:none}ul.lst-kix_3nq914pozpi7-4{list-style-type:none}ul.lst-kix_3nq914pozpi7-5{list-style-type:none}ul.lst-kix_3nq914pozpi7-6{list-style-type:none}ul.lst-kix_3nq914pozpi7-7{list-style-type:none}.lst-kix_cpgerodpupjz-4>li:before{content:"-  "}.lst-kix_of5ud22cn0qg-4>li:before{content:"-  "}.lst-kix_eiskzjj27gc6-2>li:before{content:"-  "}.lst-kix_u8nobwiguyj1-1>li:before{content:"" counter(lst-ctn-kix_u8nobwiguyj1-1,lower-latin) ") "}ul.lst-kix_3nq914pozpi7-8{list-style-type:none}.lst-kix_rxmcp67o7upe-7>li:before{content:"-  "}.lst-kix_x2lkon80l30j-3>li:before{content:"-  "}ul.lst-kix_66ns622ckygr-2{list-style-type:none}.lst-kix_cd2o0cncsajm-8>li:before{content:"-  "}ul.lst-kix_66ns622ckygr-3{list-style-type:none}ul.lst-kix_66ns622ckygr-4{list-style-type:none}.lst-kix_aeppt4sbsnmp-3>li:before{content:"-  "}ul.lst-kix_66ns622ckygr-5{list-style-type:none}.lst-kix_zag3ymt8mk2y-3>li:before{content:"-  "}ul.lst-kix_66ns622ckygr-0{list-style-type:none}ul.lst-kix_66ns622ckygr-1{list-style-type:none}.lst-kix_fm53cr9wmch0-5>li:before{content:"-  "}.lst-kix_voj7evacrpie-0>li:before{content:"-  "}ul.lst-kix_qmryaqe19okh-6{list-style-type:none}.lst-kix_jvmsa1jxmzig-6>li:before{content:"\0025cf   "}.lst-kix_t9t3ckq2i2hz-4>li:before{content:"-  "}ul.lst-kix_qmryaqe19okh-5{list-style-type:none}.lst-kix_4ypcpsaj0q6h-7>li:before{content:"-  "}ul.lst-kix_qmryaqe19okh-4{list-style-type:none}ul.lst-kix_qmryaqe19okh-3{list-style-type:none}ul.lst-kix_qmryaqe19okh-2{list-style-type:none}.lst-kix_9z31rmzc855z-6>li:before{content:"-  "}ul.lst-kix_qmryaqe19okh-1{list-style-type:none}ul.lst-kix_qmryaqe19okh-0{list-style-type:none}.lst-kix_tnd0p97rqwub-5>li:before{content:"-  "}.lst-kix_gerk886qza0c-4>li:before{content:"-  "}ul.lst-kix_66ns622ckygr-6{list-style-type:none}ul.lst-kix_66ns622ckygr-7{list-style-type:none}.lst-kix_m5azvtuvtpt1-8>li:before{content:"-  "}ul.lst-kix_66ns622ckygr-8{list-style-type:none}ul.lst-kix_qmryaqe19okh-8{list-style-type:none}.lst-kix_6nc1nfac2wub-5>li:before{content:"-  "}ul.lst-kix_qmryaqe19okh-7{list-style-type:none}ul.lst-kix_bo9wrgz88es4-6{list-style-type:none}ul.lst-kix_bo9wrgz88es4-5{list-style-type:none}ul.lst-kix_bo9wrgz88es4-8{list-style-type:none}ul.lst-kix_bo9wrgz88es4-7{list-style-type:none}.lst-kix_dmxresnhzo8y-3>li:before{content:"-  "}.lst-kix_7vvt5hs6rdl-6>li:before{content:"-  "}.lst-kix_ykhoydml7pv3-0>li{counter-increment:lst-ctn-kix_ykhoydml7pv3-0}.lst-kix_3mj3tp7kj9db-8>li:before{content:"" counter(lst-ctn-kix_3mj3tp7kj9db-8,lower-roman) ". "}ul.lst-kix_bo9wrgz88es4-0{list-style-type:none}ul.lst-kix_bo9wrgz88es4-2{list-style-type:none}ul.lst-kix_bo9wrgz88es4-1{list-style-type:none}ul.lst-kix_bo9wrgz88es4-4{list-style-type:none}ul.lst-kix_bo9wrgz88es4-3{list-style-type:none}ol.lst-kix_ok1n37qarjzb-7.start{counter-reset:lst-ctn-kix_ok1n37qarjzb-7 0}.lst-kix_x95t913s41kt-4>li:before{content:"-  "}.lst-kix_ukx3y28hag8h-3>li:before{content:"-  "}ul.lst-kix_pejjsijavmae-0{list-style-type:none}.lst-kix_npanryo7f1m7-4>li:before{content:"-  "}ul.lst-kix_pejjsijavmae-1{list-style-type:none}ul.lst-kix_pejjsijavmae-2{list-style-type:none}.lst-kix_ugixx4nd67zw-6>li:before{content:"-  "}ul.lst-kix_pejjsijavmae-3{list-style-type:none}.lst-kix_tlnfkrylyq1a-7>li:before{content:"-  "}.lst-kix_q24qpifeknc3-6>li:before{content:"-  "}.lst-kix_5nilpkhthb5t-5>li:before{content:"-  "}.lst-kix_2ei6b6e4ow80-3>li:before{content:"-  "}.lst-kix_3q7au8a3gwav-2>li:before{content:"-  "}.lst-kix_84zf7o74c8s9-7>li:before{content:"" counter(lst-ctn-kix_84zf7o74c8s9-7,lower-latin) ". "}ul.lst-kix_df6s37r8voak-0{list-style-type:none}.lst-kix_g02ta87c1sqh-3>li:before{content:"\0025cf   "}ul.lst-kix_df6s37r8voak-3{list-style-type:none}ul.lst-kix_df6s37r8voak-4{list-style-type:none}ul.lst-kix_df6s37r8voak-1{list-style-type:none}ul.lst-kix_df6s37r8voak-2{list-style-type:none}ul.lst-kix_pejjsijavmae-8{list-style-type:none}.lst-kix_3fc7x0lm2mmz-3>li{counter-increment:lst-ctn-kix_3fc7x0lm2mmz-3}.lst-kix_66ns622ckygr-7>li:before{content:"-  "}ul.lst-kix_pejjsijavmae-4{list-style-type:none}ul.lst-kix_pejjsijavmae-5{list-style-type:none}ul.lst-kix_pejjsijavmae-6{list-style-type:none}ul.lst-kix_pejjsijavmae-7{list-style-type:none}.lst-kix_5argtotmwusw-2>li:before{content:"-  "}.lst-kix_chbthqdwx7gj-7>li:before{content:"-  "}.lst-kix_pg2i9lis4p1v-3>li:before{content:"-  "}ul.lst-kix_df6s37r8voak-7{list-style-type:none}ul.lst-kix_df6s37r8voak-8{list-style-type:none}ul.lst-kix_df6s37r8voak-5{list-style-type:none}ul.lst-kix_df6s37r8voak-6{list-style-type:none}ul.lst-kix_tvu7bmfefz32-2{list-style-type:none}ul.lst-kix_tvu7bmfefz32-3{list-style-type:none}ul.lst-kix_tvu7bmfefz32-0{list-style-type:none}ul.lst-kix_tvu7bmfefz32-1{list-style-type:none}ul.lst-kix_tvu7bmfefz32-6{list-style-type:none}.lst-kix_8nwtyhgsvjlm-8>li:before{content:"-  "}ul.lst-kix_tvu7bmfefz32-7{list-style-type:none}ul.lst-kix_tvu7bmfefz32-4{list-style-type:none}ul.lst-kix_tvu7bmfefz32-5{list-style-type:none}.lst-kix_bdjoj2nf5hw9-3>li:before{content:"-  "}.lst-kix_awlaex77cpwh-3>li:before{content:"-  "}.lst-kix_8wvqr5f1zg2m-6>li:before{content:"-  "}.lst-kix_5stj9b6acoxv-1>li:before{content:"" counter(lst-ctn-kix_5stj9b6acoxv-1,lower-latin) ". "}ul.lst-kix_tvu7bmfefz32-8{list-style-type:none}.lst-kix_pv4jsz2h74wk-8>li:before{content:"-  "}.lst-kix_rcfi5jnwnxji-1>li:before{content:"-  "}.lst-kix_m3u7mfewl2ow-8>li:before{content:"-  "}ol.lst-kix_incqcf2p39ls-1.start{counter-reset:lst-ctn-kix_incqcf2p39ls-1 0}ul.lst-kix_9ys95s420x24-0{list-style-type:none}.lst-kix_fy701w8ywepa-7>li:before{content:"-  "}ul.lst-kix_9ys95s420x24-4{list-style-type:none}ul.lst-kix_9ys95s420x24-3{list-style-type:none}ul.lst-kix_9ys95s420x24-2{list-style-type:none}ul.lst-kix_3novkjnl93sa-0{list-style-type:none}ul.lst-kix_9ys95s420x24-1{list-style-type:none}ul.lst-kix_3novkjnl93sa-1{list-style-type:none}ul.lst-kix_3novkjnl93sa-2{list-style-type:none}ul.lst-kix_3novkjnl93sa-3{list-style-type:none}ul.lst-kix_3novkjnl93sa-4{list-style-type:none}ul.lst-kix_3novkjnl93sa-5{list-style-type:none}ul.lst-kix_3novkjnl93sa-6{list-style-type:none}ul.lst-kix_3novkjnl93sa-7{list-style-type:none}ul.lst-kix_3novkjnl93sa-8{list-style-type:none}.lst-kix_kp4gb6sd08f1-0>li:before{content:"-  "}ul.lst-kix_9ys95s420x24-8{list-style-type:none}.lst-kix_o4efc4ukggt5-4>li:before{content:"-  "}ul.lst-kix_9ys95s420x24-7{list-style-type:none}ul.lst-kix_9ys95s420x24-6{list-style-type:none}ul.lst-kix_9ys95s420x24-5{list-style-type:none}.lst-kix_eh8nesljbkpv-5>li:before{content:"-  "}.lst-kix_p9ucdfdvxyzl-4>li:before{content:"-  "}.lst-kix_f2t507a7xjue-8>li:before{content:"-  "}.lst-kix_kp4gb6sd08f1-6>li:before{content:"-  "}.lst-kix_zew29xx7bzz-8>li:before{content:"-  "}ol.lst-kix_yvohqcnu3146-1.start{counter-reset:lst-ctn-kix_yvohqcnu3146-1 0}.lst-kix_tekivzgenz72-1>li:before{content:"-  "}.lst-kix_sr0z5k7b8i6u-4>li:before{content:"-  "}ol.lst-kix_sxixw4iqsgzx-8.start{counter-reset:lst-ctn-kix_sxixw4iqsgzx-8 0}.lst-kix_7gk9ayd44tft-0>li:before{content:"-  "}.lst-kix_lojd6plssn1-8>li:before{content:"-  "}.lst-kix_e3u4u2bj7x9w-8>li:before{content:"-  "}.lst-kix_uwhnriglec8q-6>li:before{content:"-  "}.lst-kix_uwhnriglec8q-0>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-8>li:before{content:"" counter(lst-ctn-kix_hppu19i8fr2p-8,lower-roman) ". "}ul.lst-kix_hngwf7orguk6-2{list-style-type:none}.lst-kix_fnlxcectz7fi-7>li:before{content:"-  "}ul.lst-kix_hngwf7orguk6-3{list-style-type:none}.lst-kix_vdnr7e70vask-7>li:before{content:"\0025cb   "}ul.lst-kix_hngwf7orguk6-4{list-style-type:none}.lst-kix_tfqdu2hgmdym-2>li:before{content:"-  "}ul.lst-kix_hngwf7orguk6-5{list-style-type:none}.lst-kix_l4d8unsm10a0-5>li:before{content:"-  "}ul.lst-kix_hngwf7orguk6-0{list-style-type:none}ol.lst-kix_vayf18aqt55o-3.start{counter-reset:lst-ctn-kix_vayf18aqt55o-3 0}ul.lst-kix_hngwf7orguk6-1{list-style-type:none}.lst-kix_yvohqcnu3146-7>li{counter-increment:lst-ctn-kix_yvohqcnu3146-7}.lst-kix_3fc7x0lm2mmz-5>li:before{content:"(" counter(lst-ctn-kix_3fc7x0lm2mmz-5,lower-roman) ") "}ul.lst-kix_hngwf7orguk6-6{list-style-type:none}ul.lst-kix_hngwf7orguk6-7{list-style-type:none}ul.lst-kix_hngwf7orguk6-8{list-style-type:none}.lst-kix_sgiyubx3nkay-5>li:before{content:"-  "}.lst-kix_o328viitwjyp-0>li:before{content:"-  "}.lst-kix_qw4x1ydun1ls-7>li:before{content:"\0025cb   "}.lst-kix_v9cryi9ybo1n-0>li:before{content:"\0025cf   "}.lst-kix_o328viitwjyp-6>li:before{content:"-  "}.lst-kix_30wqf3y6rydr-3>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-2>li:before{content:"" counter(lst-ctn-kix_hppu19i8fr2p-2,lower-roman) ") "}.lst-kix_e3u4u2bj7x9w-2>li:before{content:"-  "}.lst-kix_fy701w8ywepa-1>li:before{content:"-  "}.lst-kix_85vz7a3ggeai-4>li:before{content:"-  "}.lst-kix_sq25f4cnauod-6>li:before{content:"-  "}ul.lst-kix_7rlftcume51v-8{list-style-type:none}ul.lst-kix_7rlftcume51v-3{list-style-type:none}ul.lst-kix_7rlftcume51v-2{list-style-type:none}ul.lst-kix_7rlftcume51v-1{list-style-type:none}ol.lst-kix_3fc7x0lm2mmz-6.start{counter-reset:lst-ctn-kix_3fc7x0lm2mmz-6 0}ul.lst-kix_7rlftcume51v-0{list-style-type:none}ul.lst-kix_7rlftcume51v-7{list-style-type:none}ul.lst-kix_7rlftcume51v-6{list-style-type:none}ul.lst-kix_7rlftcume51v-5{list-style-type:none}ul.lst-kix_7rlftcume51v-4{list-style-type:none}.lst-kix_sq25f4cnauod-0>li:before{content:"-  "}.lst-kix_eahcvjpxxqs-7>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-4>li{counter-increment:lst-ctn-kix_ypd5gkkarijk-4}.lst-kix_28q7sqckfj19-6>li:before{content:"-  "}.lst-kix_eh3u7tkoktop-3>li:before{content:"-  "}ol.lst-kix_ypd5gkkarijk-5.start{counter-reset:lst-ctn-kix_ypd5gkkarijk-5 0}.lst-kix_qw4x1ydun1ls-1>li:before{content:"\0025cb   "}.lst-kix_mjig28how5ag-6>li:before{content:"-  "}.lst-kix_i8kfgvsh0fwy-7>li:before{content:"-  "}.lst-kix_1kbilie4yf3o-8>li:before{content:"-  "}.lst-kix_6217r3mhjywx-6>li:before{content:"-  "}.lst-kix_9ys95s420x24-4>li:before{content:"-  "}.lst-kix_tekivzgenz72-7>li:before{content:"-  "}.lst-kix_x96zthrcdy1e-1>li:before{content:"-  "}.lst-kix_yob9gooqotb-3>li:before{content:"-  "}.lst-kix_g1rm1ujfok3h-5>li:before{content:"-  "}ul.lst-kix_qw2h6jd8xi17-8{list-style-type:none}ul.lst-kix_qw2h6jd8xi17-7{list-style-type:none}ul.lst-kix_qw2h6jd8xi17-6{list-style-type:none}.lst-kix_x96zthrcdy1e-7>li:before{content:"-  "}ol.lst-kix_2foc6u9lzfq4-0.start{counter-reset:lst-ctn-kix_2foc6u9lzfq4-0 0}ul.lst-kix_aeppt4sbsnmp-8{list-style-type:none}ul.lst-kix_e73zm9q3mvin-8{list-style-type:none}ul.lst-kix_e73zm9q3mvin-5{list-style-type:none}ul.lst-kix_e73zm9q3mvin-4{list-style-type:none}ul.lst-kix_e73zm9q3mvin-7{list-style-type:none}ol.lst-kix_5djgwp8c9ig2-0.start{counter-reset:lst-ctn-kix_5djgwp8c9ig2-0 0}ul.lst-kix_e73zm9q3mvin-6{list-style-type:none}ul.lst-kix_aeppt4sbsnmp-0{list-style-type:none}ul.lst-kix_qw2h6jd8xi17-1{list-style-type:none}ul.lst-kix_e73zm9q3mvin-1{list-style-type:none}ul.lst-kix_aeppt4sbsnmp-1{list-style-type:none}ul.lst-kix_qw2h6jd8xi17-0{list-style-type:none}ul.lst-kix_e73zm9q3mvin-0{list-style-type:none}ul.lst-kix_aeppt4sbsnmp-2{list-style-type:none}ul.lst-kix_e73zm9q3mvin-3{list-style-type:none}ul.lst-kix_aeppt4sbsnmp-3{list-style-type:none}ul.lst-kix_e73zm9q3mvin-2{list-style-type:none}ul.lst-kix_aeppt4sbsnmp-4{list-style-type:none}ul.lst-kix_qw2h6jd8xi17-5{list-style-type:none}ul.lst-kix_aeppt4sbsnmp-5{list-style-type:none}ul.lst-kix_qw2h6jd8xi17-4{list-style-type:none}ul.lst-kix_aeppt4sbsnmp-6{list-style-type:none}.lst-kix_eahcvjpxxqs-1>li:before{content:"-  "}ul.lst-kix_qw2h6jd8xi17-3{list-style-type:none}ul.lst-kix_aeppt4sbsnmp-7{list-style-type:none}.lst-kix_1tib71bbsugw-5>li:before{content:"-  "}ul.lst-kix_qw2h6jd8xi17-2{list-style-type:none}.lst-kix_p11gr83hik0e-0>li:before{content:"-  "}.lst-kix_28q7sqckfj19-0>li:before{content:"-  "}ol.lst-kix_ysfu1bl0kymd-7.start{counter-reset:lst-ctn-kix_ysfu1bl0kymd-7 0}.lst-kix_3bnqwg68tpm3-3>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-0>li{counter-increment:lst-ctn-kix_d1gy3hy5r3qj-0}ol.lst-kix_267f3xfv5ddr-4{list-style-type:none}ol.lst-kix_267f3xfv5ddr-5{list-style-type:none}ol.lst-kix_267f3xfv5ddr-2{list-style-type:none}ol.lst-kix_267f3xfv5ddr-3{list-style-type:none}ol.lst-kix_267f3xfv5ddr-8{list-style-type:none}ol.lst-kix_267f3xfv5ddr-6{list-style-type:none}.lst-kix_yvohqcnu3146-4>li:before{content:"(" counter(lst-ctn-kix_yvohqcnu3146-4,lower-latin) ") "}ol.lst-kix_267f3xfv5ddr-7{list-style-type:none}ul.lst-kix_l4d8unsm10a0-3{list-style-type:none}ol.lst-kix_u8nobwiguyj1-3.start{counter-reset:lst-ctn-kix_u8nobwiguyj1-3 0}ul.lst-kix_l4d8unsm10a0-2{list-style-type:none}.lst-kix_q2mi4y6rc42i-4>li:before{content:"-  "}ul.lst-kix_l4d8unsm10a0-1{list-style-type:none}ul.lst-kix_l4d8unsm10a0-0{list-style-type:none}.lst-kix_yk26x5gkc3g4-0>li:before{content:"-  "}.lst-kix_38p7uzj3qds3-1>li:before{content:"-  "}ul.lst-kix_ykhrv7u6blcs-7{list-style-type:none}ul.lst-kix_ykhrv7u6blcs-8{list-style-type:none}.lst-kix_ypd5gkkarijk-1>li:before{content:"" counter(lst-ctn-kix_ypd5gkkarijk-1,lower-roman) ") "}ul.lst-kix_ykhrv7u6blcs-5{list-style-type:none}ul.lst-kix_ykhrv7u6blcs-6{list-style-type:none}ul.lst-kix_ykhrv7u6blcs-3{list-style-type:none}ul.lst-kix_9z31rmzc855z-1{list-style-type:none}ul.lst-kix_ykhrv7u6blcs-4{list-style-type:none}ul.lst-kix_9z31rmzc855z-0{list-style-type:none}.lst-kix_6xh4bfg7mbxi-5>li:before{content:"-  "}ul.lst-kix_ykhrv7u6blcs-1{list-style-type:none}ul.lst-kix_9z31rmzc855z-3{list-style-type:none}ul.lst-kix_ykhrv7u6blcs-2{list-style-type:none}ul.lst-kix_9z31rmzc855z-2{list-style-type:none}ul.lst-kix_9z31rmzc855z-5{list-style-type:none}ul.lst-kix_ykhrv7u6blcs-0{list-style-type:none}ul.lst-kix_9z31rmzc855z-4{list-style-type:none}.lst-kix_2nm562bzmwr-0>li:before{content:"-  "}ul.lst-kix_9z31rmzc855z-7{list-style-type:none}ul.lst-kix_9z31rmzc855z-6{list-style-type:none}.lst-kix_g47hwi8ilj0t-4>li:before{content:"-  "}.lst-kix_oc7itsrfkmqv-5>li:before{content:"-  "}ul.lst-kix_9z31rmzc855z-8{list-style-type:none}.lst-kix_qbfnanuzy3l5-2>li:before{content:"-  "}.lst-kix_pejjsijavmae-5>li:before{content:"-  "}.lst-kix_pxpm44v9ngyu-8>li:before{content:"-  "}.lst-kix_kzw7lb63578w-5>li:before{content:"-  "}.lst-kix_90bg3luq5inv-3>li{counter-increment:lst-ctn-kix_90bg3luq5inv-3}.lst-kix_vkdxjlf0kb6j-0>li:before{content:"" counter(lst-ctn-kix_vkdxjlf0kb6j-0,decimal) ". "}.lst-kix_5u0542f2h2jt-8>li:before{content:"+  "}ol.lst-kix_ysfu1bl0kymd-3.start{counter-reset:lst-ctn-kix_ysfu1bl0kymd-3 0}.lst-kix_66ns622ckygr-1>li:before{content:"-  "}.lst-kix_1kbilie4yf3o-2>li:before{content:"-  "}.lst-kix_wfyz8rmi0iq4-8>li:before{content:"-  "}.lst-kix_waivoqs1cu5x-5>li:before{content:"-  "}.lst-kix_w3rscytwttbz-3>li:before{content:"-  "}ul.lst-kix_x6hb6vgwujyx-3{list-style-type:none}.lst-kix_w32pgwk3f0lb-7>li:before{content:"-  "}.lst-kix_73pnq2b8bo4n-2>li:before{content:"-  "}ul.lst-kix_x6hb6vgwujyx-4{list-style-type:none}.lst-kix_nlsa7flowwa1-8>li:before{content:"+  "}ul.lst-kix_x6hb6vgwujyx-1{list-style-type:none}ul.lst-kix_x6hb6vgwujyx-2{list-style-type:none}.lst-kix_7cboi17aj4i3-3>li:before{content:"-  "}ul.lst-kix_x6hb6vgwujyx-0{list-style-type:none}.lst-kix_84zf7o74c8s9-1>li:before{content:"" counter(lst-ctn-kix_84zf7o74c8s9-1,lower-latin) ".) "}.lst-kix_iyje40sgs3ri-2>li:before{content:"-  "}.lst-kix_14k5lhtsu41k-8>li:before{content:"-  "}.lst-kix_vhhvekoaa9d4-5>li:before{content:"\0025a0   "}.lst-kix_3ez3vzcedsa0-0>li:before{content:"-  "}.lst-kix_4ypcpsaj0q6h-1>li:before{content:"-  "}ul.lst-kix_6m4qu83yomn7-7{list-style-type:none}.lst-kix_mjig28how5ag-0>li:before{content:"-  "}ul.lst-kix_6m4qu83yomn7-8{list-style-type:none}ul.lst-kix_6m4qu83yomn7-5{list-style-type:none}ul.lst-kix_6m4qu83yomn7-6{list-style-type:none}ul.lst-kix_6m4qu83yomn7-3{list-style-type:none}ul.lst-kix_6m4qu83yomn7-4{list-style-type:none}ul.lst-kix_6m4qu83yomn7-1{list-style-type:none}ul.lst-kix_6m4qu83yomn7-2{list-style-type:none}ul.lst-kix_l4d8unsm10a0-8{list-style-type:none}ul.lst-kix_l4d8unsm10a0-7{list-style-type:none}ul.lst-kix_6m4qu83yomn7-0{list-style-type:none}ul.lst-kix_l4d8unsm10a0-6{list-style-type:none}.lst-kix_5l84eporjaw3-0>li:before{content:"-  "}ul.lst-kix_l4d8unsm10a0-5{list-style-type:none}ul.lst-kix_l4d8unsm10a0-4{list-style-type:none}.lst-kix_xyra4e5ffsud-5>li:before{content:"" counter(lst-ctn-kix_xyra4e5ffsud-5,lower-roman) ". "}.lst-kix_hyuyjld7ihkv-2>li:before{content:"-  "}ol.lst-kix_267f3xfv5ddr-0{list-style-type:none}ol.lst-kix_267f3xfv5ddr-1{list-style-type:none}.lst-kix_q8c17lyf7k0c-2>li:before{content:"-  "}.lst-kix_f4168mxvziu2-1>li:before{content:"-  "}.lst-kix_3qppsihuuk4z-0>li:before{content:"-  "}ol.lst-kix_5djgwp8c9ig2-4.start{counter-reset:lst-ctn-kix_5djgwp8c9ig2-4 0}.lst-kix_8hvuzyuchy3p-4>li:before{content:"-  "}ul.lst-kix_yhq927c05ak0-0{list-style-type:none}ul.lst-kix_4uak8dkv6vr8-1{list-style-type:none}ul.lst-kix_4uak8dkv6vr8-2{list-style-type:none}ul.lst-kix_yhq927c05ak0-2{list-style-type:none}ul.lst-kix_4uak8dkv6vr8-3{list-style-type:none}ul.lst-kix_yhq927c05ak0-1{list-style-type:none}ul.lst-kix_4uak8dkv6vr8-4{list-style-type:none}ul.lst-kix_yhq927c05ak0-4{list-style-type:none}ul.lst-kix_4uak8dkv6vr8-5{list-style-type:none}ul.lst-kix_yhq927c05ak0-3{list-style-type:none}.lst-kix_4gff7g6tktju-5>li:before{content:"-  "}ul.lst-kix_4uak8dkv6vr8-6{list-style-type:none}ul.lst-kix_yhq927c05ak0-6{list-style-type:none}ul.lst-kix_4uak8dkv6vr8-7{list-style-type:none}ul.lst-kix_yhq927c05ak0-5{list-style-type:none}ul.lst-kix_4uak8dkv6vr8-8{list-style-type:none}.lst-kix_7vvt5hs6rdl-0>li:before{content:"-  "}.lst-kix_m3u7mfewl2ow-2>li:before{content:"-  "}.lst-kix_d94n7or3b41v-5>li:before{content:"-  "}ul.lst-kix_4uak8dkv6vr8-0{list-style-type:none}.lst-kix_v9cryi9ybo1n-6>li:before{content:"\0025cf   "}.lst-kix_pv4jsz2h74wk-2>li:before{content:"-  "}.lst-kix_ugixx4nd67zw-0>li:before{content:"-  "}.lst-kix_ikdz4hpyto9o-4>li:before{content:"-  "}.lst-kix_bttl6bm2dx1a-1>li:before{content:"-  "}ol.lst-kix_vgg0538grxk3-6.start{counter-reset:lst-ctn-kix_vgg0538grxk3-6 0}ul.lst-kix_x6hb6vgwujyx-7{list-style-type:none}ul.lst-kix_x6hb6vgwujyx-8{list-style-type:none}ul.lst-kix_x6hb6vgwujyx-5{list-style-type:none}.lst-kix_rog9deufml3h-0>li:before{content:"-  "}ul.lst-kix_x6hb6vgwujyx-6{list-style-type:none}.lst-kix_awt45k7p90je-5>li:before{content:"-  "}ul.lst-kix_wfyz8rmi0iq4-7{list-style-type:none}ul.lst-kix_wfyz8rmi0iq4-8{list-style-type:none}ul.lst-kix_wfyz8rmi0iq4-5{list-style-type:none}ul.lst-kix_wfyz8rmi0iq4-6{list-style-type:none}.lst-kix_wrdk3q33keus-1>li:before{content:"-  "}ul.lst-kix_wfyz8rmi0iq4-3{list-style-type:none}ul.lst-kix_wfyz8rmi0iq4-4{list-style-type:none}ul.lst-kix_wfyz8rmi0iq4-1{list-style-type:none}.lst-kix_2agzfikyhf8k-3>li:before{content:"-  "}ul.lst-kix_wfyz8rmi0iq4-2{list-style-type:none}ul.lst-kix_wfyz8rmi0iq4-0{list-style-type:none}.lst-kix_3novkjnl93sa-1>li:before{content:"-  "}.lst-kix_ok1n37qarjzb-0>li{counter-increment:lst-ctn-kix_ok1n37qarjzb-0}.lst-kix_43bwriak8ne4-2>li:before{content:"-  "}.lst-kix_1epl36nedj4y-6>li:before{content:"-  "}.lst-kix_r9s6df60is49-3>li:before{content:"-  "}.lst-kix_7dqsuv1cdvcc-2>li:before{content:"-  "}.lst-kix_90bg3luq5inv-8>li{counter-increment:lst-ctn-kix_90bg3luq5inv-8}.lst-kix_bb3pt2xtt0a5-3>li:before{content:"-  "}.lst-kix_yjf6dvvoob64-5>li:before{content:"" counter(lst-ctn-kix_yjf6dvvoob64-5,lower-roman) ". "}.lst-kix_v6dv769q7bq3-0>li:before{content:"-  "}ul.lst-kix_yhq927c05ak0-8{list-style-type:none}.lst-kix_tvu7bmfefz32-7>li:before{content:"-  "}ul.lst-kix_yhq927c05ak0-7{list-style-type:none}.lst-kix_azgj6sn0lxuj-0>li:before{content:"" counter(lst-ctn-kix_azgj6sn0lxuj-0,decimal) ". "}ul.lst-kix_tlnfkrylyq1a-0{list-style-type:none}ul.lst-kix_tlnfkrylyq1a-1{list-style-type:none}ul.lst-kix_tlnfkrylyq1a-2{list-style-type:none}.lst-kix_dojezsyc3ti3-4>li:before{content:"-  "}ul.lst-kix_tlnfkrylyq1a-3{list-style-type:none}ul.lst-kix_tlnfkrylyq1a-4{list-style-type:none}ul.lst-kix_tlnfkrylyq1a-5{list-style-type:none}ul.lst-kix_tlnfkrylyq1a-6{list-style-type:none}ul.lst-kix_tlnfkrylyq1a-7{list-style-type:none}ul.lst-kix_tlnfkrylyq1a-8{list-style-type:none}.lst-kix_2ccdqvrbclt-3>li:before{content:"-  "}ul.lst-kix_cpgerodpupjz-1{list-style-type:none}ul.lst-kix_cpgerodpupjz-0{list-style-type:none}.lst-kix_b7rulpv7obgl-1>li:before{content:"-  "}.lst-kix_spt2hfceke6p-0>li:before{content:"-  "}ul.lst-kix_tw1wz6pba43e-5{list-style-type:none}ul.lst-kix_tw1wz6pba43e-6{list-style-type:none}ul.lst-kix_tw1wz6pba43e-7{list-style-type:none}ul.lst-kix_tw1wz6pba43e-8{list-style-type:none}ol.lst-kix_5djgwp8c9ig2-8.start{counter-reset:lst-ctn-kix_5djgwp8c9ig2-8 0}ul.lst-kix_jfoqdfq6uhww-0{list-style-type:none}.lst-kix_hrm7p8w30y7p-2>li:before{content:"-  "}.lst-kix_194f2a56ajxk-4>li:before{content:"-  "}ul.lst-kix_jfoqdfq6uhww-7{list-style-type:none}ul.lst-kix_jfoqdfq6uhww-8{list-style-type:none}ul.lst-kix_jfoqdfq6uhww-5{list-style-type:none}ul.lst-kix_jfoqdfq6uhww-6{list-style-type:none}ul.lst-kix_jfoqdfq6uhww-3{list-style-type:none}ul.lst-kix_jfoqdfq6uhww-4{list-style-type:none}.lst-kix_m31se2npgu2r-4>li:before{content:"-  "}ul.lst-kix_jfoqdfq6uhww-1{list-style-type:none}.lst-kix_kxjfd2xlpmu-0>li:before{content:"-  "}ul.lst-kix_jfoqdfq6uhww-2{list-style-type:none}ol.lst-kix_yjf6dvvoob64-5{list-style-type:none}ol.lst-kix_yjf6dvvoob64-4{list-style-type:none}ol.lst-kix_yjf6dvvoob64-3{list-style-type:none}ol.lst-kix_yjf6dvvoob64-2{list-style-type:none}ol.lst-kix_yjf6dvvoob64-8{list-style-type:none}ol.lst-kix_yjf6dvvoob64-7{list-style-type:none}.lst-kix_cmm6cscyrjti-6>li:before{content:"-  "}ol.lst-kix_yjf6dvvoob64-6{list-style-type:none}ol.lst-kix_yjf6dvvoob64-1{list-style-type:none}ol.lst-kix_yjf6dvvoob64-0{list-style-type:none}ul.lst-kix_5nilpkhthb5t-4{list-style-type:none}ul.lst-kix_5nilpkhthb5t-3{list-style-type:none}ul.lst-kix_5nilpkhthb5t-2{list-style-type:none}ul.lst-kix_5nilpkhthb5t-1{list-style-type:none}ul.lst-kix_5nilpkhthb5t-0{list-style-type:none}.lst-kix_wz5gdx83jdla-4>li:before{content:"-  "}.lst-kix_90bg3luq5inv-5>li:before{content:"(" counter(lst-ctn-kix_90bg3luq5inv-5,lower-roman) ") "}ul.lst-kix_cpgerodpupjz-8{list-style-type:none}ul.lst-kix_cpgerodpupjz-7{list-style-type:none}ul.lst-kix_cpgerodpupjz-6{list-style-type:none}ul.lst-kix_cpgerodpupjz-5{list-style-type:none}ol.lst-kix_2foc6u9lzfq4-4.start{counter-reset:lst-ctn-kix_2foc6u9lzfq4-4 0}ul.lst-kix_cpgerodpupjz-4{list-style-type:none}.lst-kix_cmm6cscyrjti-0>li:before{content:"-  "}ul.lst-kix_cpgerodpupjz-3{list-style-type:none}ul.lst-kix_cpgerodpupjz-2{list-style-type:none}.lst-kix_y62sddnu24wd-0>li:before{content:"-  "}.lst-kix_rxevvtxfoovc-6>li:before{content:"-  "}.lst-kix_rp6rf03vbelo-5>li:before{content:"-  "}.lst-kix_8drpzle0jo7q-2>li:before{content:"\0025a0   "}ul.lst-kix_5nilpkhthb5t-8{list-style-type:none}ul.lst-kix_5nilpkhthb5t-7{list-style-type:none}ul.lst-kix_5nilpkhthb5t-6{list-style-type:none}ul.lst-kix_5nilpkhthb5t-5{list-style-type:none}.lst-kix_ivmzvkm69gsd-7>li:before{content:"-  "}.lst-kix_dmn3lqzfmokk-0>li:before{content:"-  "}ol.lst-kix_g8jgbze430sv-3.start{counter-reset:lst-ctn-kix_g8jgbze430sv-3 0}.lst-kix_17yxihawuh4r-3>li:before{content:"-  "}.lst-kix_y62sddnu24wd-6>li:before{content:"-  "}.lst-kix_8f3g26d9wonp-1>li:before{content:"-  "}.lst-kix_i7kvy3cw4vsq-7>li:before{content:"-  "}.lst-kix_lcru2cdgc87j-2>li:before{content:"-  "}.lst-kix_a9h81iclzrpy-3>li:before{content:"-  "}.lst-kix_yxvs6rw7mq1w-4>li:before{content:"-  "}.lst-kix_3fc7x0lm2mmz-8>li{counter-increment:lst-ctn-kix_3fc7x0lm2mmz-8}.lst-kix_x424ckbm5jp1-5>li:before{content:"-  "}.lst-kix_fld6w0ks1f0p-3>li:before{content:"-  "}.lst-kix_tl77ogq6q7u-2>li:before{content:"-  "}.lst-kix_8drpzle0jo7q-8>li:before{content:"\0025a0   "}ul.lst-kix_bpsiys7g173w-2{list-style-type:none}ul.lst-kix_chbthqdwx7gj-1{list-style-type:none}.lst-kix_tl77ogq6q7u-8>li:before{content:"-  "}ul.lst-kix_bpsiys7g173w-1{list-style-type:none}ul.lst-kix_chbthqdwx7gj-0{list-style-type:none}ul.lst-kix_bpsiys7g173w-4{list-style-type:none}ul.lst-kix_chbthqdwx7gj-3{list-style-type:none}ul.lst-kix_bpsiys7g173w-3{list-style-type:none}ul.lst-kix_chbthqdwx7gj-2{list-style-type:none}ul.lst-kix_tw1wz6pba43e-0{list-style-type:none}ul.lst-kix_bpsiys7g173w-6{list-style-type:none}ul.lst-kix_tw1wz6pba43e-1{list-style-type:none}ul.lst-kix_bpsiys7g173w-5{list-style-type:none}.lst-kix_i7kvy3cw4vsq-1>li:before{content:"-  "}ul.lst-kix_tw1wz6pba43e-2{list-style-type:none}ul.lst-kix_bpsiys7g173w-8{list-style-type:none}ul.lst-kix_tw1wz6pba43e-3{list-style-type:none}ul.lst-kix_bpsiys7g173w-7{list-style-type:none}ul.lst-kix_tw1wz6pba43e-4{list-style-type:none}ul.lst-kix_chbthqdwx7gj-8{list-style-type:none}ul.lst-kix_chbthqdwx7gj-5{list-style-type:none}.lst-kix_nipj94pw11x6-0>li:before{content:"-  "}.lst-kix_skgpgvhmuoc4-1>li:before{content:"-  "}.lst-kix_3koi1cw13a0-1>li:before{content:"-  "}ul.lst-kix_chbthqdwx7gj-4{list-style-type:none}ul.lst-kix_bpsiys7g173w-0{list-style-type:none}ul.lst-kix_chbthqdwx7gj-7{list-style-type:none}.lst-kix_h25uruhpfzux-6>li:before{content:"-  "}ul.lst-kix_chbthqdwx7gj-6{list-style-type:none}ul.lst-kix_bttl6bm2dx1a-2{list-style-type:none}ul.lst-kix_bttl6bm2dx1a-3{list-style-type:none}ul.lst-kix_bttl6bm2dx1a-4{list-style-type:none}ul.lst-kix_bttl6bm2dx1a-5{list-style-type:none}ul.lst-kix_bttl6bm2dx1a-6{list-style-type:none}.lst-kix_fhtxrv3nkyi7-4>li:before{content:"-  "}ul.lst-kix_bttl6bm2dx1a-7{list-style-type:none}ul.lst-kix_bttl6bm2dx1a-8{list-style-type:none}.lst-kix_d626gkjp4fou-5>li:before{content:"\0025a0   "}ol.lst-kix_u8nobwiguyj1-7.start{counter-reset:lst-ctn-kix_u8nobwiguyj1-7 0}.lst-kix_5djgwp8c9ig2-5>li:before{content:"" counter(lst-ctn-kix_5djgwp8c9ig2-5,lower-roman) ". "}.lst-kix_ysfu1bl0kymd-1>li:before{content:"" counter(lst-ctn-kix_ysfu1bl0kymd-1,lower-latin) ". "}.lst-kix_69k4orytle42-8>li:before{content:"\0025a0   "}.lst-kix_vgg0538grxk3-1>li:before{content:"" counter(lst-ctn-kix_vgg0538grxk3-1,lower-latin) ") "}.lst-kix_vgg0538grxk3-7>li:before{content:"" counter(lst-ctn-kix_vgg0538grxk3-7,lower-latin) ". "}ul.lst-kix_s9h4llxy1yy0-4{list-style-type:none}ul.lst-kix_s9h4llxy1yy0-3{list-style-type:none}ul.lst-kix_s9h4llxy1yy0-6{list-style-type:none}ul.lst-kix_s9h4llxy1yy0-5{list-style-type:none}ul.lst-kix_dn04c4yafie0-8{list-style-type:none}ul.lst-kix_s9h4llxy1yy0-0{list-style-type:none}ul.lst-kix_dn04c4yafie0-7{list-style-type:none}ul.lst-kix_dn04c4yafie0-6{list-style-type:none}ul.lst-kix_s9h4llxy1yy0-2{list-style-type:none}ul.lst-kix_dn04c4yafie0-5{list-style-type:none}ul.lst-kix_s9h4llxy1yy0-1{list-style-type:none}ul.lst-kix_dn04c4yafie0-4{list-style-type:none}ul.lst-kix_dn04c4yafie0-3{list-style-type:none}.lst-kix_o7acnutkhp1w-3>li:before{content:"-  "}ul.lst-kix_dn04c4yafie0-2{list-style-type:none}ul.lst-kix_dn04c4yafie0-1{list-style-type:none}ul.lst-kix_dn04c4yafie0-0{list-style-type:none}ul.lst-kix_s9h4llxy1yy0-8{list-style-type:none}ul.lst-kix_s9h4llxy1yy0-7{list-style-type:none}ul.lst-kix_bttl6bm2dx1a-0{list-style-type:none}.lst-kix_i4nwb7g7qe41-3>li:before{content:"-  "}ul.lst-kix_bttl6bm2dx1a-1{list-style-type:none}.lst-kix_549l9aqx2sdy-7>li:before{content:"-  "}.lst-kix_gboi4t2flod9-4>li:before{content:"-  "}.lst-kix_o17eseb5cr8e-7>li:before{content:"-  "}.lst-kix_p2dhxl6hicde-5>li:before{content:"-  "}.lst-kix_axwe0nze7yft-3>li:before{content:"-  "}.lst-kix_q95o92il1jwg-3>li:before{content:"-  "}ul.lst-kix_ssze0kg2kz13-5{list-style-type:none}ul.lst-kix_ssze0kg2kz13-6{list-style-type:none}ul.lst-kix_ssze0kg2kz13-3{list-style-type:none}ul.lst-kix_ssze0kg2kz13-4{list-style-type:none}ul.lst-kix_ssze0kg2kz13-1{list-style-type:none}ul.lst-kix_ssze0kg2kz13-2{list-style-type:none}ul.lst-kix_ssze0kg2kz13-0{list-style-type:none}.lst-kix_rop4yg7lbfg8-0>li:before{content:"-  "}ul.lst-kix_ssze0kg2kz13-7{list-style-type:none}.lst-kix_izios9u5ks4s-2>li:before{content:"-  "}ul.lst-kix_ssze0kg2kz13-8{list-style-type:none}.lst-kix_o45gwpewsvxw-7>li:before{content:"-  "}.lst-kix_ob04lr2u335p-0>li:before{content:"-  "}ol.lst-kix_yvohqcnu3146-5.start{counter-reset:lst-ctn-kix_yvohqcnu3146-5 0}.lst-kix_t3rn73qejgkj-5>li:before{content:"(" counter(lst-ctn-kix_t3rn73qejgkj-5,lower-roman) ") "}.lst-kix_ny5e869gaylo-4>li:before{content:"-  "}.lst-kix_o17eseb5cr8e-1>li:before{content:"-  "}.lst-kix_o45gwpewsvxw-1>li:before{content:"-  "}.lst-kix_267f3xfv5ddr-6>li:before{content:"" counter(lst-ctn-kix_267f3xfv5ddr-6,decimal) ". "}.lst-kix_wn0yiryrov3h-7>li:before{content:"-  "}.lst-kix_g8jgbze430sv-6>li{counter-increment:lst-ctn-kix_g8jgbze430sv-6}.lst-kix_nj8yy6k748x0-3>li:before{content:"-  "}.lst-kix_ctweb0b3a38f-3>li:before{content:"-  "}.lst-kix_3i5qlhg977l0-1>li:before{content:"-  "}ul.lst-kix_8wvqr5f1zg2m-6{list-style-type:none}ul.lst-kix_8wvqr5f1zg2m-5{list-style-type:none}ul.lst-kix_8wvqr5f1zg2m-8{list-style-type:none}ul.lst-kix_8wvqr5f1zg2m-7{list-style-type:none}ul.lst-kix_8wvqr5f1zg2m-2{list-style-type:none}ul.lst-kix_8wvqr5f1zg2m-1{list-style-type:none}.lst-kix_267f3xfv5ddr-4>li{counter-increment:lst-ctn-kix_267f3xfv5ddr-4}ul.lst-kix_8wvqr5f1zg2m-4{list-style-type:none}.lst-kix_qccibyu36y2t-1>li:before{content:"-  "}ul.lst-kix_8wvqr5f1zg2m-3{list-style-type:none}.lst-kix_ob04lr2u335p-6>li:before{content:"-  "}ul.lst-kix_8wvqr5f1zg2m-0{list-style-type:none}.lst-kix_fmkfhvl8yhfs-3>li:before{content:"-  "}ol.lst-kix_3fc7x0lm2mmz-2.start{counter-reset:lst-ctn-kix_3fc7x0lm2mmz-2 0}.lst-kix_r8azi25kh461-5>li:before{content:"\0025cf   "}.lst-kix_yk26x5gkc3g4-6>li:before{content:"-  "}.lst-kix_y32h08wggx1t-2>li:before{content:"-  "}.lst-kix_qzg09ck6gr7w-7>li:before{content:"-  "}.lst-kix_ypd5gkkarijk-7>li:before{content:"" counter(lst-ctn-kix_ypd5gkkarijk-7,lower-roman) ". "}.lst-kix_mb1zrov3n6kx-1>li:before{content:"-  "}.lst-kix_t3rn73qejgkj-3>li{counter-increment:lst-ctn-kix_t3rn73qejgkj-3}.lst-kix_4uak8dkv6vr8-4>li:before{content:"-  "}ol.lst-kix_vayf18aqt55o-7.start{counter-reset:lst-ctn-kix_vayf18aqt55o-7 0}.lst-kix_nlsa7flowwa1-2>li:before{content:"+  "}ul.lst-kix_fm53cr9wmch0-0{list-style-type:none}.lst-kix_c7r1s55bmbei-3>li:before{content:"-  "}.lst-kix_mkfigeky21iv-5>li:before{content:"-  "}ol.lst-kix_ypd5gkkarijk-1.start{counter-reset:lst-ctn-kix_ypd5gkkarijk-1 0}.lst-kix_r9gci84l54f7-3>li:before{content:"-  "}.lst-kix_11d94ps4c7wj-5>li:before{content:"-  "}.lst-kix_932mko8sjg0u-2>li:before{content:"-  "}.lst-kix_5rn2qrejqs3r-8>li:before{content:"-  "}ul.lst-kix_fm53cr9wmch0-4{list-style-type:none}ul.lst-kix_fm53cr9wmch0-3{list-style-type:none}.lst-kix_wnr3c516ni7j-2>li:before{content:"-  "}ul.lst-kix_fm53cr9wmch0-2{list-style-type:none}ul.lst-kix_fm53cr9wmch0-1{list-style-type:none}ul.lst-kix_fm53cr9wmch0-8{list-style-type:none}ul.lst-kix_fm53cr9wmch0-7{list-style-type:none}.lst-kix_x74x9xa8n5a0-0>li:before{content:"-  "}.lst-kix_uvjyeruqqfgv-5>li:before{content:"-  "}ul.lst-kix_fm53cr9wmch0-6{list-style-type:none}.lst-kix_ok1n37qarjzb-4>li:before{content:"(" counter(lst-ctn-kix_ok1n37qarjzb-4,lower-roman) ") "}.lst-kix_8w03xjt2k9bc-2>li:before{content:"-  "}ul.lst-kix_fm53cr9wmch0-5{list-style-type:none}.lst-kix_23ct987xwu67-2>li:before{content:"" counter(lst-ctn-kix_23ct987xwu67-2,lower-roman) ") "}.lst-kix_22zpsclbl6ju-7>li:before{content:"-  "}.lst-kix_iyje40sgs3ri-8>li:before{content:"-  "}.lst-kix_q8c17lyf7k0c-8>li:before{content:"-  "}.lst-kix_d1gy3hy5r3qj-0>li:before{content:"" counter(lst-ctn-kix_d1gy3hy5r3qj-0,decimal) ") "}.lst-kix_3ez3vzcedsa0-6>li:before{content:"-  "}.lst-kix_5l84eporjaw3-6>li:before{content:"-  "}.lst-kix_6vg5692ogph-4>li:before{content:"-  "}.lst-kix_j32gjnxzdkip-4>li:before{content:"-  "}.lst-kix_73pnq2b8bo4n-8>li:before{content:"-  "}.lst-kix_3qppsihuuk4z-6>li:before{content:"-  "}.lst-kix_bttl6bm2dx1a-7>li:before{content:"-  "}.lst-kix_f4168mxvziu2-7>li:before{content:"-  "}.lst-kix_rrloltks13s-8>li:before{content:"-  "}.lst-kix_hppu19i8fr2p-1>li{counter-increment:lst-ctn-kix_hppu19i8fr2p-1}.lst-kix_tw1wz6pba43e-4>li:before{content:"-  "}.lst-kix_r6uhbskcwxv5-3>li:before{content:"-  "}.lst-kix_tfqdu2hgmdym-8>li:before{content:"-  "}ul.lst-kix_gfc2v9r4qc22-8{list-style-type:none}ul.lst-kix_gfc2v9r4qc22-5{list-style-type:none}ul.lst-kix_gfc2v9r4qc22-4{list-style-type:none}ul.lst-kix_gfc2v9r4qc22-7{list-style-type:none}ul.lst-kix_gfc2v9r4qc22-6{list-style-type:none}ul.lst-kix_gfc2v9r4qc22-1{list-style-type:none}ul.lst-kix_6pgojrjbxqei-7{list-style-type:none}ul.lst-kix_gfc2v9r4qc22-0{list-style-type:none}ul.lst-kix_6pgojrjbxqei-6{list-style-type:none}ul.lst-kix_gfc2v9r4qc22-3{list-style-type:none}.lst-kix_43bwriak8ne4-8>li:before{content:"-  "}ul.lst-kix_gfc2v9r4qc22-2{list-style-type:none}ul.lst-kix_6pgojrjbxqei-8{list-style-type:none}ul.lst-kix_6pgojrjbxqei-3{list-style-type:none}ul.lst-kix_6pgojrjbxqei-2{list-style-type:none}.lst-kix_wrdk3q33keus-7>li:before{content:"-  "}ul.lst-kix_6pgojrjbxqei-5{list-style-type:none}ul.lst-kix_6pgojrjbxqei-4{list-style-type:none}.lst-kix_j60wooaeanf9-1>li:before{content:"-  "}.lst-kix_bpsiys7g173w-1>li:before{content:"-  "}.lst-kix_azgj6sn0lxuj-6>li:before{content:"" counter(lst-ctn-kix_azgj6sn0lxuj-6,decimal) ". "}.lst-kix_hrm7p8w30y7p-8>li:before{content:"-  "}.lst-kix_q8ex99of35ig-4>li:before{content:"-  "}ol.lst-kix_23ct987xwu67-8{list-style-type:none}ol.lst-kix_23ct987xwu67-7{list-style-type:none}ol.lst-kix_23ct987xwu67-6{list-style-type:none}.lst-kix_7dqsuv1cdvcc-8>li:before{content:"-  "}.lst-kix_py2swxy3gr0i-0>li:before{content:"-  "}.lst-kix_z6rr709h3fky-4>li:before{content:"-  "}ul.lst-kix_6pgojrjbxqei-1{list-style-type:none}ul.lst-kix_6pgojrjbxqei-0{list-style-type:none}.lst-kix_v6dv769q7bq3-6>li:before{content:"-  "}.lst-kix_1epl36nedj4y-0>li:before{content:"-  "}.lst-kix_oqibhsqlyfou-5>li:before{content:"-  "}ol.lst-kix_23ct987xwu67-5{list-style-type:none}ol.lst-kix_23ct987xwu67-4{list-style-type:none}ol.lst-kix_23ct987xwu67-3{list-style-type:none}ol.lst-kix_23ct987xwu67-2{list-style-type:none}ol.lst-kix_23ct987xwu67-1{list-style-type:none}.lst-kix_tpw8rt3jm7dt-3>li:before{content:"-  "}ol.lst-kix_23ct987xwu67-0{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c16{border-right-style:solid;border-top-width:0pt;border-right-width:0pt;border-top-style:solid;border-bottom-width:0pt;border-bottom-style:solid;padding-right:0pt}.c21{color:#666666;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c19{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:italic}.c17{padding-top:14pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c5{padding-top:12pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Arial";font-style:normal}.c63{padding-top:-2pt;padding-bottom:-2pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c74{padding-top:3pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c40{-webkit-text-decoration-skip:none;color:#000000;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-family:"Arial"}.c29{padding-top:20pt;padding-bottom:6pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c35{padding-top:16pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c75{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c71{padding-top:20pt;padding-bottom:6pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c84{padding-top:0pt;padding-bottom:6pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c55{padding-top:12pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c14{padding-top:0pt;padding-bottom:0pt;line-height:1.38;orphans:2;widows:2;text-align:left}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c64{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c67{padding-top:16pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c85{padding-top:14pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c57{padding-top:14pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c59{padding-top:12pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c32{color:#434343;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial"}.c18{font-weight:700;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c13{padding-top:3pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c68{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline line-through}.c4{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c23{font-weight:400;vertical-align:baseline;font-size:10pt;font-family:"Arial"}.c34{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:line-through}.c65{color:#6aa94f;vertical-align:baseline;font-family:"Courier New"}.c44{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline}.c69{color:#dcddde;vertical-align:baseline;font-family:"Courier New"}.c73{color:#212121;vertical-align:baseline;font-family:"Courier New"}.c43{color:#1f2328;text-decoration:none}.c42{vertical-align:baseline;font-family:"Arial"}.c72{vertical-align:baseline;font-family:"Comic Sans MS"}.c12{font-weight:700;font-style:italic}.c54{color:#dcddde;font-size:12pt}.c47{text-decoration:none;font-size:14pt}.c49{color:#434343;text-decoration:none}.c15{color:#000000;text-decoration:none}.c3{color:inherit;text-decoration:inherit}.c9{padding:0;margin:0}.c81{max-width:451.4pt;padding:28.3pt 72pt 72pt 72pt}.c27{page-break-after:avoid}.c36{font-weight:400}.c22{font-weight:700}.c20{font-style:italic}.c51{text-decoration:none}.c62{text-indent:36pt}.c58{font-size:12pt}.c52{font-size:9.5pt}.c53{font-size:14pt}.c45{font-size:7pt}.c80{margin-left:35.4pt}.c7{height:11pt}.c25{padding-left:0pt}.c60{font-size:6pt}.c28{vertical-align:super}.c61{margin-left:54pt}.c37{font-size:9pt}.c66{margin-left:96pt}.c41{font-size:10.5pt}.c33{font-size:11pt}.c82{font-size:5pt}.c76{font-family:"Times New Roman"}.c11{font-size:8pt}.c39{margin-left:72pt}.c31{font-size:10pt}.c56{color:#1f2328}.c46{font-size:13pt}.c24{color:#666666}.c83{vertical-align:baseline}.c30{font-style:normal}.c26{margin-left:18pt}.c77{font-family:"Courier New"}.c79{font-size:15pt}.c50{color:#000000}.c48{margin-left:48pt}.c70{height:13pt}.c78{color:#434343}.c8{margin-left:36pt}.c38{background-color:#ffffff}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-weight:700;font-size:13pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:center}h2{padding-top:20pt;color:#000000;font-weight:700;font-size:13pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:center}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:0pt;color:#000000;font-size:11pt;padding-bottom:0pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:center}</style></head><body class="c38 c81 doc-content"><div><h2 class="c29 c27 c70" id="h.16yxt2a6ev96"><span class="c42 c15 c22 c31 c30"></span></h2><h2 class="c1 c70" id="h.8ak0w6w8gqum"><span class="c0"></span></h2><h2 class="c1 c70" id="h.avd17bbh3cf3"><span class="c42 c15 c22 c31 c30"></span></h2><h6 class="c1 c7" id="h.knl0bh88pegg"><span class="c0"></span></h6></div><h2 class="c71 c27" id="h.roiuj54hzww3"><span class="c20 c11">edit. </span><span class="c36 c37">04.12.25</span></h2><p class="c2"><span class="c15 c36 c20 c45 c72">deton24&rsquo;s</span></p><p class="c2"><span class="c22">Instrumental and vocal &amp; stems separation &amp; </span><span class="c12 c78"><a class="c3" href="#h.k34y1vaaneb1">mastering</a></span></p><p class="c2"><span class="c20 c11">(UVR 5 GUI: </span><span class="c44 c11"><a class="c3" href="#h.atxff7m4vp8n">VR</a></span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.7znr3r5gprdy">MDX-Net</a></span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.7znr3r5gprdy">MDX23C</a></span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.m9ndauawzs5f">Demucs</a></span><span class="c11">&nbsp;1-4, and BS/Mel-Roformer in </span><span class="c44 c11"><a class="c3" href="#h.6y2plb943p9v">beta</a></span></p><p class="c2"><span class="c44 c11"><a class="c3" href="#h.jmb1yj7x3kj7">MVSEP-MDX23-Colab</a></span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.7kniy2i3s0qc">KaraFan</a></span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.m55fp5i7rdpm">Drumsep</a></span><span class="c11">/</span><span class="c11 c44"><a class="c3" href="#h.sjf0vefmplt">SCNet</a></span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.i7mm2bj53u07&amp;sa=D&amp;source=editors&amp;ust=1765035741745145&amp;usg=AOvVaw3IhtPfPtX8v7Qh_paz2Pj-">Apollo</a></span></p><p class="c2"><span class="c44 c11"><a class="c3" href="#h.wbc0pja7faof">x-minus</a></span><span class="c11">.pro</span><span class="c11">&nbsp;(uvronline.app)/</span><span class="c44 c11"><a class="c3" href="#h.wbc0pja7faof">mvsep</a></span><span class="c11">.com</span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.wbc0pja7faof">Colabs</a></span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span></p><p class="c2"><span class="c44 c11"><a class="c3" href="#h.yy2jex1n5sq">Gaudio</a></span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.xdux18tet3x9">Dango</a></span><span class="c11">.ai</span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.tc4az79fufkn">Audioshake</a></span><span class="c11">/</span><span class="c44 c11"><a class="c3" href="#h.vyz1ol39n8d2">Music ai</a></span><span class="c42 c15 c36 c11 c30">)</span></p><p class="c2 c7"><span class="c42 c15 c36 c11 c30"></span></p><p class="c1"><span class="c4 c60"><a class="c3" href="#h.jx9um5zd7fnp">General reading advice</a></span><span class="c60">&nbsp;| </span><span class="c4 c60"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/ZPtAU5R6rP&amp;sa=D&amp;source=editors&amp;ust=1765035741746443&amp;usg=AOvVaw2Ofj7E5rxfUtNvN1kaTqBW">Discord</a></span><span class="c60">&nbsp;(ask, or suggest edits there) | Table of </span><span class="c4 c60"><a class="c3" href="#h.sm5m61aib1vx">content</a></span><span class="c60">&nbsp;(newer in Options&gt;Document outline on PC or in the app) | </span><span class="c4 c60"><a class="c3" href="#h.bg6u0y2kn4ui">Training</a></span></p><p class="c1 c7"><span class="c42 c15 c36 c30 c45"></span></p><p class="c1"><span>Straight to currently the best </span><span class="c4"><a class="c3" href="#h.rz0d5zk9ms4w">models list</a></span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c42 c15 c36 c45 c30"></span></p><p class="c1"><span>___</span></p><h5 class="c5" id="h.k3vca4e9ena8"><span class="c42 c36 c20 c51 c33 c24">Last updates and news</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox voc_fv7 beta 3 added to the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741748000&amp;usg=AOvVaw15Q3-YsXUrR6DfD9MSUpll">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;Four new models have been added:</span></p><p class="c1"><span>1) MVSep Percussion (percussion, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251128141738-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741748714&amp;usg=AOvVaw1wQPAXdmyIwf2PdTlx8RoH">https://mvsep.com/result/20251128141738-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>2) MVSep Keys (keys, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251128142835-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741749156&amp;usg=AOvVaw2PD9gflwEcifgqHGf4AATk">https://mvsep.com/result/20251128142835-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>3) MVSep Brass (brass, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251128142905-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741749614&amp;usg=AOvVaw2SsG6JXjKIiQXiXpUaJFbl">https://mvsep.com/result/20251128142905-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>4) MVSep Woodwind (woodwind, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251128143157-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741750097&amp;usg=AOvVaw1F94vAeJieQ1gEHjNy0WQS">https://mvsep.com/result/20251128143157-f0bb276157-mixture.wav</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa BS-Roformer HyperACE inst model has been added to a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1lqHRm_h122qgpxLyx3xfHsrVei6ASx1t?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741750644&amp;usg=AOvVaw2U0UPyIY81019uiOvPI8Bk">separate Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Gabox released two new models (vocal and instrumental):</span></p><p class="c1"><span>Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/vocfv7beta3.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741751211&amp;usg=AOvVaw2M_dhfM9rxFWb_ovW6BW49">vocfv7beta3</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741751439&amp;usg=AOvVaw2jFioSWmeJF12eevSHQUsl">yaml</a></span></p><p class="c1"><span class="c0">Voc. fullness 21.82 | bleedless 30.83 &nbsp;| SDR 10.80</span></p><p class="c1"><span class="c0">&ldquo;beta 1 and 2... eh, pretty close to same instrumental bleed,</span></p><p class="c1"><span class="c0">but beta 3 def a step up from the two songs I compared (...)</span></p><p class="c1"><span class="c0">most songs so far, fv7beta3 is fuller than fv7beta1,</span></p><p class="c1"><span class="c0">def less robotic sounding at times (when a voice gets quiet/hard to capture, and it just fails).</span></p><p class="c1"><span class="c0">Just had another song where fv7beta1 was fuller than fv7beta3, but it was also a lot noisier</span></p><p class="c1"><span class="c0">large majority of the songs I tested, fv7beta3 was fuller... I think fv7beta3 is usually a bit noisier than fv7beta1? But also sounds fuller in those cases, I&#39;d say it&#39;s generally worth it</span></p><p class="c1"><span class="c0">instrumental bleed, usually worse with fv7beta3 versus fv7beta1, but it depends</span></p><p class="c1"><span class="c0">fv7beta2 is always less full/less noise, but only slightly less instrumental bleed than fv7beta1&rdquo; - rainboomdash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/inst_fv7b.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741754309&amp;usg=AOvVaw0-vwrcuGg0ymm9W3Dx6ijP">inst_fv7b</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741754572&amp;usg=AOvVaw0X074MwkErMb784z05fGw2">yaml</a></span></p><p class="c1"><span>Inst. fullness 27.07 | </span><span class="c22">bleedless </span><span class="c0">47.49 | SDR 16.71</span></p><p class="c1"><span class="c0">&ldquo;this may be the last beta before the final model&rdquo; - Gabox</span></p><p class="c1"><span class="c0">The highest bleedless metric out of all instrumental models so far. But fullness is worse than even most vocal Mel-Roformers (including BS-RoFormer SW and Mel Kim OG model).</span></p><p class="c1"><span>&ldquo;On the fuller side, somewhere around inst v1e+, maybe a tiny bit below. The main thing I notice is it captures more instruments than v1e+, but isn&#39;t muddy like [HyperACE] (which also captures more instruments) (...) It can add a lot of crackling noise, though, more than v1e+ (...) can be a little on the noisy side sometimes... but it at least isn&#39;t muddy and sounds natural (...) I&#39;d still ensemble if you want the noise reduced - rainboomdash</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1441680934129631325&amp;sa=D&amp;source=editors&amp;ust=1765035741756113&amp;usg=AOvVaw3_MwUQrZem5Cau2q0X96n7">src</a></span><span>)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-HyperACE/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741756356&amp;usg=AOvVaw1_zYXEVz6m3lDXuqlTeiTJ">BS-Roformer-HyperACE</a></span><span>&nbsp;instrumental model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1lqHRm_h122qgpxLyx3xfHsrVei6ASx1t?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741756548&amp;usg=AOvVaw2almx4-n14UbN4nKWOilze">separate Colab</a></span></p><p class="c1"><span class="c0">Inst. fullness 36.91 | bleedless 38.77 | SDR 17.27</span></p><p class="c1"><span class="c0">(less fullness than v1e+: 37.89, but more bleedless: 36.53, SDR: 16.65)</span></p><p class="c1"><span class="c0">Note: It uses its own inference script. &ldquo;You can use this model by replacing the MSST repository&#39;s models/bs_roformer.py with the repository&#39;s bs_roformer.py.&rdquo;</span></p><p class="c1"><span>To not affect functionality of other BS-Roformer models by it, you can add it as new model_type by editing utils/settings.py and models/bs_roformer/init.py </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/dkGXo2r&amp;sa=D&amp;source=editors&amp;ust=1765035741757492&amp;usg=AOvVaw1cVLJs1TpeeBZpgRpTLr8u">here</a></span><span class="c0">&nbsp;(thx anvuew).</span></p><p class="c1"><span class="c0">&ldquo;Currently, this model holds the highest aura_mrstft score on the instrumental side of the Multisong dataset. (...)</span></p><p class="c1"><span>Some components in the SegmModel module were implemented based on this paper: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2506.17733&amp;sa=D&amp;source=editors&amp;ust=1765035741758031&amp;usg=AOvVaw3t0LfomTW3d95UqV5Fa1hq">https://arxiv.org/abs/2506.17733</a></span></p><p class="c1"><span>Simply put, it&#39;s a module that utilizes hypergraphs to capture global relationships and standard convolutions to capture local relationships, thereby generating the final &ldquo;Correlation-Enhanced&rdquo; feature map.</span></p><p class="c1"><span class="c0">This weight is based on the following weights. Thank you, anvuew!</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/BS-RoFormer&amp;sa=D&amp;source=editors&amp;ust=1765035741758656&amp;usg=AOvVaw3AbWd4oR-OApD4WgLkgbip">https://huggingface.co/anvuew/BS-RoFormer</a></span><span class="c0">&rdquo; - unwa</span></p><p class="c1"><span class="c0">- The inference file got updated to fix error</span></p><p class="c1"><span class="c0">Consider changing overlap from default 4 to 2 in the yaml of the model. The difference won&rsquo;t be really noticeable for most people, but it will be faster.</span></p><p class="c1"><span class="c0">&ldquo;thirty minutes of audio [on 4090]:</span></p><p class="c1"><span class="c0">FNO was 71.38 seconds, HyperACE was 120.37</span></p><p class="c1"><span class="c0">so HyperACE is about 2x longer than FNO (...) Does seem like HyperACE is picking up more instruments than v1e+</span></p><p class="c1"><span class="c0">does seem like slightly worse vocal bleed overall (still need to test this more, though)... haven&#39;t encountered the super tinny vocal bleed like v1e+, at least</span></p><p class="c1"><span class="c0">still fails to pick up that brass instrument on one song... Not really any worse than v1e+, though (...) resurrection inst does sound more muddy, but also a lot less noise... which makes sense... IDK, a little muddy for my tastes.</span></p><p class="c1"><span class="c0">I did find one song/spot and resurrection inst was on par with HyperACE in picking up the wind instrument, v1e+ lost it for a bit.</span></p><p class="c1"><span class="c0">I have found in the past that resurrection inst generally picks up more instruments than v1e+ (...) fullness of HyperACE is much closer to v1e+ than resurrection inst (...) it gets pretty staticy compared to v1e+ [on some drums] (...) v1e+ does this to a lot less extent</span></p><p class="c1"><span class="c0">it&#39;s not super common, though&hellip; (...) I&#39;m very confident in saying HyperACE picks up more stuff than v1e+.</span></p><p class="c1"><span class="c0">Resurrection inst does pick it up much better than v1e+, but I think it&#39;s still too quiet</span></p><p class="c1"><span class="c0">resurrection inst really does just pick up so much more instruments, despite having a lot less fullness&rdquo; - rainboomdash</span></p><p class="c1"><span class="c0">&ldquo;fullness that is comparable to v1e+, but has significant more vocal crossbleeding in instrumental than BS Roformer Resurrection Inst, but still less than v1e+ and v1e&rdquo; - dca100fb8</span></p><p class="c1"><span class="c0">&ldquo;the best instrumental model ive ever heard</span></p><p class="c1"><span class="c0">Unbelievable how realistic it sounds</span></p><p class="c1"><span class="c0">especially with bass and piano - PezZHasACat/pezz23</span></p><p class="c1"><span>Might have problems with flute in specific songs - Hen</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;We have released a new model &#39;MVSep Lead/Rhythm Guitar (lead-guitar, rhythm-guitar) &#39;. It has two variants:</span></p><p class="c1"><span class="c0">1) Two-stage model (SDR: 9.21) - Best guitar model applied, and then 2-stem model is used which can separate lead/rhythm guitar.</span></p><p class="c1"><span class="c0">2) One-stage model (SDR: 9.02) - Single model is applied, which was trained on a 3 stem dataset.</span></p><p class="c1"><span class="c0">They can give pretty different results, so worth trying both.</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251120090832-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741763470&amp;usg=AOvVaw1ZFBftE3Ok3rtnIEQaw62r">https://mvsep.com/result/20251120090832-f0bb276157-mixture.wav</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &nbsp;We have released the &quot;MVSep Plucked Strings (plucked-strings, other)&quot; model.</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251120092757-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741764129&amp;usg=AOvVaw16Io0sre00CLPEPOMm1ucM">https://mvsep.com/result/20251120092757-f0bb276157-mixture.wav</a></span><span>&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- fr4z49 reported that they managed to use MSST with ROCm 7 and 6 on Linux and AMD RX 7600 for fast separations. Officially, it&rsquo;s not </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html&amp;sa=D&amp;source=editors&amp;ust=1765035741764620&amp;usg=AOvVaw1NCo1C0UusVbc49xT6MNHR">supported</a></span><span>&nbsp;</span><span>by AMD, but works, although your mileage might vary from GFX to GFX (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://llvm.org/docs/AMDGPUUsage.html%23processors&amp;sa=D&amp;source=editors&amp;ust=1765035741764859&amp;usg=AOvVaw2291cNhlzkZ9s6T6A9IANI">range</a></span><span>&nbsp;of GPU models inside various generations/archs).<br>- Probably, 5700 XT with some older ROCm versions (e.g. older than 6.33) might work too &nbsp;(e.g. HIP 5.7 and ROCm around 5.2.* - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.reddit.com/r/ROCm/comments/1gcf3x4/comment/ma62qop/&amp;sa=D&amp;source=editors&amp;ust=1765035741765262&amp;usg=AOvVaw2oy_tbaDsAiXwdGK-2273G">src</a></span><span>, although you can try out 6.21 or 6.2.x to ensure, as it could happen that some earlier 6.x wasn&rsquo;t supporting RX 5700 XT correctly, while e.g. for RX 6000 ROCm 6.24 worked in some apps at some point, but more up-to-date information might be found in some ZLUDA guides, as it needs ROCm too - some suggestions </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/875539590373572648/1429855493668732989&amp;sa=D&amp;source=editors&amp;ust=1765035741766143&amp;usg=AOvVaw3j-y1IPodRL0QRlmNtm5N8">here</a></span><span class="c0">).</span></p><p class="c1"><span>- The most performance gains on ROCm 7 might be potentially observed on officially supported GPUs like Instinct MI350 CDNA 4, providing even 3-7x performance gains over 6.0 in some applications (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.techpowerup.com/341074/amd-launches-rocm-7-0-up-to-3-8x-performance-uplift-over-rocm-6-0&amp;sa=D&amp;source=editors&amp;ust=1765035741766711&amp;usg=AOvVaw2YLytYjNysj_e3eetJlHxc">more</a></span><span class="c0">). </span></p><p class="c1"><span>- Official support for RX 400/500 (a.k.a. Polaris/GCN 4/GFX803) GPUs support was dropped, but you can follow </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/robertrosenbusch/gfx803_rocm&amp;sa=D&amp;source=editors&amp;ust=1765035741767002&amp;usg=AOvVaw0gOOM6NS3rRzmo6hGZwdR-">this</a></span><span>&nbsp;</span><span class="c0">repo for unofficial ROCm 6 support.</span></p><p class="c1"><span>Or for ROCm 5, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nikos230/Run-Pytorch-with-AMD-Radeon-GPU&amp;sa=D&amp;source=editors&amp;ust=1765035741767279&amp;usg=AOvVaw2Q3Jj--mN11EWb9Hz8sBAf">this</a></span><span>&nbsp;</span><span class="c0">Ubuntu guide (it might even potentially work from Windows using WSL [if using at least Ubuntu 22.04 LTS] with almost no GPU performance overhead). There seemed to be some issues building Torch (UtilsAVX512.cc/tensorpipe) on Python 3.13, fixed on Python 3.10, and maybe 3.11.9.</span></p><p class="c1"><span>Also, there seems to be some Arch Linux community package to install Pytorch still compatible for these GPUs (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs%23install-on-amd-and-arch-linux&amp;sa=D&amp;source=editors&amp;ust=1765035741768029&amp;usg=AOvVaw0i5AcpM8vtUUNmMgsB2y1T">click</a></span><span class="c0">).<br>Or also might be potentially supported with some other specific versions of ROC, e.g. 5.7.2 and also described above:</span></p><p class="c1"><span class="c20">export ROC_ENABLE_PRE_VEGA=1 </span><span class="c0">(deprecated in ROCm 6; might help for lacking dependencies or wheel building issues). Or check out also this:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/10435%23issuecomment-1555399844&amp;sa=D&amp;source=editors&amp;ust=1765035741769066&amp;usg=AOvVaw1q1JjZg_az-dHmm2BbAj2d">https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/10435#issuecomment-1555399844</a></span><span>, </span><span class="c0">or alternatively follow below instructions:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pytorch.org/get-started/locally/&amp;sa=D&amp;source=editors&amp;ust=1765035741769428&amp;usg=AOvVaw1vRiRqwBSF3tti4wjLrhR_">https://pytorch.org/get-started/locally/</a></span><span>&nbsp;a</span><span class="c0">nd then execute:</span></p><p class="c1"><span class="c20">pip3 install torch torchvision torchaudio --index-url </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://download.pytorch.org/whl/rocm5.4.2&amp;sa=D&amp;source=editors&amp;ust=1765035741769738&amp;usg=AOvVaw2Jxj6d569iKkaYdbZtKdo5">https://download.pytorch.org/whl/rocm5.4.2</a></span></p><p class="c1"><span>- Since then also ROCm 6.4.4 allowing using PyTorch natively on Linux and Windows on RX 7000 and 9000 was released (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.techpowerup.com/341329/amd-enables-pytorch-on-radeon-rx-7000-9000-gpus-with-windows-and-linux-preview&amp;sa=D&amp;source=editors&amp;ust=1765035741770090&amp;usg=AOvVaw1XiHh43275AhQw-CCSLcf9">more</a></span><span>), but it wasn&rsquo;t tested yet (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.amd.com/en/resources/support-articles/release-notes/RN-AMDGPU-WINDOWS-PYTORCH-PREVIEW.html&amp;sa=D&amp;source=editors&amp;ust=1765035741770253&amp;usg=AOvVaw1i7G5APNbuyA-xcchcbibY">DL</a></span><span>). You might get the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708595418400817162/1439447187183505541&amp;sa=D&amp;source=editors&amp;ust=1765035741770421&amp;usg=AOvVaw1TXrR-U6IHyZiyTMukOJzn">error</a></span><span class="c0">&nbsp;using at least WebUI.</span></p><p class="c1"><span>- Also, you might want to experiment with using ZLUDA in UVR (CUDA&gt;ROCm translation layer - some suggestions </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/875539590373572648/1429855493668732989&amp;sa=D&amp;source=editors&amp;ust=1765035741770767&amp;usg=AOvVaw0lvs6y86_zdwtOG1_Q2sIZ">here</a></span><span class="c0">). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt;fr4z49 ROCm report:</span></p><p class="c1"><span>- &ldquo;I managed to make</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/SUC-DriverOld/MSST-WebUI&amp;sa=D&amp;source=editors&amp;ust=1765035741771032&amp;usg=AOvVaw08jmlJdaOglQUUqw2AbcDe">&nbsp;MSST-WebUI</a></span><span class="c0">&nbsp;work [on Linux] with: </span></p><p class="c1"><span class="c6">Torch 2.10.0.dev20251110+rocm7.0 </span></p><p class="c1"><span class="c0">on RX 7600</span></p><p class="c1"><span class="c0">(...) it seems like ROCm 7.0 is about a second faster [than 6.x]&rdquo; <br>(probably by adding just pip install before it)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Turns out that if you do:</span></p><p class="c1"><span class="c6">export TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1</span></p><p class="c1"><span class="c0">it uses waay less VRAM and processes even faster.</span></p><p class="c1"><span class="c0">inst_V1e_plus batch_size=2 overlap=3 chunk_size= 485100, 51.78s/it &nbsp;[3:50 of audio in 61 seconds]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For ROCm 6.x (a tad slower, might work on more GPUs) use:</span></p><p class="c1"><span class="c6">torch 2.9.0+rocm6.3 torchvision0.24.0+rocm6.3 [--index-url https://download.pytorch.org/whl/rocm6.3]</span></p><p class="c1"><span>Or older version suggested above</span><span class="c6">.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Thanks, fr4z49.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- yxlllc&rsquo;s harmonic noise separation VR (6 or 5.x model, unsure) if someone was interested:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/yxlllc/vocal-remover/releases/tag/hnsep_240512&amp;sa=D&amp;source=editors&amp;ust=1765035741772989&amp;usg=AOvVaw2VubElaVN_wIYt6cnZJu9U">https://github.com/yxlllc/vocal-remover/releases/tag/hnsep_240512</a></span><span>&nbsp;(July 2025)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Gabox released beta 2 of vocfv7 Mel-Roformer &ldquo;fullness went down a little bit&rdquo;</span></p><p class="c1"><span class="c0">Voc. bleedless: 31.55, fullness: 20.44, SDR: 10.87</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/vocfv7beta2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741773644&amp;usg=AOvVaw0Q4kgYusJ4M_oSPrp2v17P">https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/vocfv7beta2.ckpt</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741773801&amp;usg=AOvVaw3ytctAeDAn_uL3Wd_kbzTo">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741773985&amp;usg=AOvVaw3vnFTXTQcHVdqHc5w-BRZs">Colab</a></span><span>&nbsp;(TL;DR in the vocals section)</span></p><p class="c1"><span class="c0">&ldquo;still quite a bit fuller than big beta 6x, but has less noise than even fv4 (also a bit less fullness, of course)&rdquo; at least when the instruments are loud, fv7beta2 is usually quite a bit less noisy than fv4, while still maintaining a decent amount of fullness... it is a bit less, but not too much (...) both are pretty noisy with fv4 (...) <br>still gonna have an issue with backing vocals compared to fv7beta1 sometimes... (makes sense, it&#39;s a less full model). (...) Fv7beta2 has still been significantly better with BV than fv4, despite quite a bit less noise&rdquo; but &ldquo;significant issues on one song, while fv6/fv7beta1 didn&#39;t (...) Def an improvement over fv4. I&#39;m really liking the balance of fullness and noise for most songs. fv4 and fv6/fv7beta1 are usually pretty noisy... this is less noisy, but still has a good amount of fullness.&rdquo; &ldquo;Where the noise was undesirable and I ensembled fv4/fv6/fv7beta1 with big beta 6x, now I can just use this instead&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;Fv7beta2 has still been significantly better with BV than fv4, despite quite a bit less noise&rdquo; but &ldquo;significant issues on one song, while fv6/fv7beta1 didn&#39;t&rdquo;<br><br>&ldquo;If the noise isn&#39;t an issue, and you just want fullness, fv6/fv7beta1 are still the best models. I&#39;d say fv6 and fv7beta1 are better models than fv4, fullness/noise aside. It depends with fv7beta1 versus fv7beta2, sometimes the noise can be pretty significant with fv7beta1, and fv7beta2 may have the fullness you desire.<br></span></p><p class="c1"><span class="c0">fv6 is usually more noisy/full than fv7beta1, but it just depends... I&#39;ve had instances where it&#39;s less noisy/full than fv7beta1. But if you really want high fullness, fv6 and fv7beta1 are the choices. Sometimes fv6 can be quite a bit more noisy and the gain in fullness isn&#39;t worth it&rdquo;. <br>- rainboomdash (thx). <br>&ldquo;vocals sound very robotic with those models, however. Compared to fv4&rdquo; - pipedream</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Anvuew released a new BS-Roformer vocal model:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/BS-RoFormer&amp;sa=D&amp;source=editors&amp;ust=1765035741777275&amp;usg=AOvVaw1A6ukJE6BRTK6n8bSd2zHR">https://huggingface.co/anvuew/BS-RoFormer</a></span></p><p class="c1"><span>It also doesn&#39;t work on the UVR&rsquo;s RTX 5000 patch - then use </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span class="c0">&nbsp;instead.</span></p><p class="c1"><span>On an M1 Mac, you will probably need to decrease chunk_size in the yaml a bit.</span></p><p class="c1"><span class="c0">&quot;On one song it was on par with the 2025.07 BSRoformer model on MVSep, at least to my ears (Tentative by System Of A Down) </span></p><p class="c1"><span class="c0">The other song [Linkin Park - Part of Me] has some background vocals that are hard to get for a lot of voc/inst models, 2025.07 manages to get them while this model doesn&#39;t.</span></p><p class="c1"><span class="c0">The instrumentals and vocals seem pretty good other than that&quot; - ryanz48</span></p><p class="c1"><span class="c0">&ldquo;Guessing it&#39;s not high enough fullness</span></p><p class="c1"><span>the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/18mGbHJM8KEqKHpqLzNDpT9mXPbgO_XYM/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741778604&amp;usg=AOvVaw1ysiMUFPQgZL8d1VP8nN-M">l o s t</a></span><span class="c0">&nbsp;is extremely muddied, and the other chanting is just gone.</span></p><p class="c1"><span class="c0">The lower harmony at 0:49-0:53 is mostly gone, making it sound very thin</span></p><p class="c1"><span class="c0">and a lot of the vocals just sound like they are breaking apart.</span></p><p class="c1"><span class="c0">Hmm, big beta 6x is significantly better, it&#39;s def a fullness issue.. probably too high of a bleedless model for my tastes</span></p><p class="c1"><span class="c0">big beta 6x still isn&#39;t super great here, the one I used for the other one I posted was fv7beta1, which is a fullness model.</span></p><p class="c1"><span class="c0">yeah, big beta 6x seems more balanced, it&#39;s a bit fuller but not noisy to my ears, either</span></p><p class="c1"><span class="c0">but I&#39;m not using headphones, so I won&#39;t hear any minor noise easily.</span></p><p class="c1"><span>yoooo, it properly doesn&#39;t capture the instrument </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1KdZEEMTezU4iQhv9-_zLpwPL9A84G8_m/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741779875&amp;usg=AOvVaw1gJRlNeBwJQMjzO8exINaO">here</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">even FT2 bleedless gets tricked by this part, but this does just fine.</span></p><p class="c1"><span>Maybe I&#39;ll try it out for this song.. most I&#39;ll still use higher fullness models</span><span class="c0">&rdquo; - rainboomdash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anvuew&rsquo;s BS-Roformer Karaoke Model added to the inference </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741780566&amp;usg=AOvVaw3GjVD65t_RYYGRcZU06CMA">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;Eleven new models have been added:</span></p><p class="c1"><span>1) MVSep Triangle (triangle, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104082053-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741781003&amp;usg=AOvVaw1ckib9qHEMtA9EwhtzxU7v">https://mvsep.com/result/20251104082053-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>2) MVSep Sitar (sitar, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104082317-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741781280&amp;usg=AOvVaw3wxzw2kkrF4QvjK4w2HWWA">https://mvsep.com/result/20251104082317-f0bb276157-mixture.wav</a></span></p><p class="c1"><span class="c0">3) MVSep Harpsichord (harpsichord, other)</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104082809-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741781609&amp;usg=AOvVaw3WKZ5wY3RCX1azwfV8daJR">https://mvsep.com/result/20251104082809-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>4) MVSep Tuba (tuba, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104082845-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741781881&amp;usg=AOvVaw2deiTynT7xna7u9xA5GWLM">https://mvsep.com/result/20251104082845-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>5) MVSep Bassoon (bassoon, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104083211-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741782155&amp;usg=AOvVaw3fOPwwKnTosAbKmRL3nQi1">https://mvsep.com/result/20251104083211-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>6) MVSep Congas (congas, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104083239-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741782433&amp;usg=AOvVaw0foxF9l6RurTN62lLu__r7">https://mvsep.com/result/20251104083239-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>7) MVSep Bells (bells, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104083305-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741782705&amp;usg=AOvVaw0ImIgtSZbO9AWQnd45GgwX">https://mvsep.com/result/20251104083305-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>8) MVSep Ukulele (ukulele, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104083332-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741782984&amp;usg=AOvVaw1sFs7YnBza8zb7VtX5VS5B">https://mvsep.com/result/20251104083332-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>9) MVSep Dobro (dobro, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104115825-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741783254&amp;usg=AOvVaw28BEzd28MU9l4Aj6yP7BR1">https://mvsep.com/result/20251104115825-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>10) MVSep Wind Chimes (wind-chimes, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104115849-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741783566&amp;usg=AOvVaw0LKr7aAqCVwCWnscxP0aAi">https://mvsep.com/result/20251104115849-f0bb276157-mixture.wav</a></span></p><p class="c1"><span class="c0">11) MVSep Accordion (accordion, other)</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251104115916-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741783891&amp;usg=AOvVaw1hUomlfmMLaRLujHyrtnnc">https://mvsep.com/result/20251104115916-f0bb276157-mixture.wav</a></span><span>&rdquo; - ZFTurbo</span></p><p class="c1"><span class="c0">- &ldquo;Yeah, I just tried [the bells] on a drum loop sample with sleigh bells I wanted to isolate, and I got a rude awakening lol&rdquo;</span></p><p class="c1"><span class="c0">- &ldquo;That&#39;s why that model name is confusing, lol. What they mean is tubular Bells or chimes. There&#39;s currently no sleigh bells model, but the Tambourine model may work&rdquo;</span></p><p class="c1"><span class="c0">- &ldquo;It worked (...) I used drumsep on it before&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;I finally was able to extract the lead guitar in this song using the dobro model, but i noticed how the bass synth is leaking in the dobro stem&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;So I thought, what if I just remove the bass in the source and try again? I did, and now it doesn&#39;t pick the lead guitar anymore&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (uvronline) &ldquo;Added two new models:</span></p><p class="c1"><span class="c0">BS-RoFormer Kar (anvuew)</span></p><p class="c1"><span class="c0">De-reverb Room (anvuew)&rdquo; - Aufr33</span></p><p class="c1"><span>The latter is also added to the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741785553&amp;usg=AOvVaw0ZMLDBu56pkBhFhJo5qcYL">Colab</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;We added MVSep Synth (synth, other) model. Synth is included the following stems: Synth, Synthesizer, Synth Pad, Synth Bass, Synth Vocals, Synth Strings, Synth Percussion, Synth FX, Synth Keys, Synth Brass, Synth Guitar, Synth Flute, Synth Ambiant.</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251031214429-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741786234&amp;usg=AOvVaw3GRqTSm9CHJ24GIAvGjWYU">https://mvsep.com/result/20251031214429-f0bb276157-mixture.wav</a></span><span class="c0">&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;So, my initial thoughts. The model works great for certain kinds of sounds e.g. leads, pads, plucks. But it&#39;s tricky to predict what it&#39;ll do, so might be safer to get rid of the other stems first, and then using synth on what&#39;s left if you need further separation.<br>Some examples:</span></p><p class="c1"><span class="c0">It isn&#39;t picking up synth basses for me, so use BS-Roformer SW for that.</span></p><p class="c1"><span class="c0">It also sort of picks up synth brass, but wind model is catching that better, at least on the stuff I ran. The same could possibly be said for synth guitars.&rdquo; - Musicalman</span></p><p class="c1"><span class="c0">&ldquo;I tested it on a front channel rip from a cue from the TV show CHUCK, and it ripped the synth lead. But it did not isolate the synth &quot;effect&quot; at the end of it&rdquo; - fal_2067</span></p><p class="c1"><span class="c0">&ldquo;is good, but sometimes it can&#39;t detect some bass synths for some reason, still not a big problem since an SW does the work almost every time. And sometimes it picks the strumming of guitars. And also it seems to fail if they are vocals or harmonies.&rdquo; - smilewasfound</span></p><p class="c1"><span class="c0">&ldquo;Most of the time gets more out of the song rather than taking out guitar, keys, bass separately until synths are left over. Sometimes very few misses or stem bleeds through, but overall very impressive!! It also picks up Vibraphone&rdquo; - Tobias51</span></p><p class="c1"><span class="c0">&ldquo;Synth stem seems way too muddy on full songs, (...) But much better than I was expecting, I&#39;ll be honest. It messes up a lot on full songs, it seems. It seems like it&#39;s more like a stem remover than an isolator to me. The no synth stems sounds very clean. Tried it on Dolby stems, same thing, the no synth stem was very clean, synth stem sounded a bit muddy though. That&#39;s fine though. Gets very confused with bass thought.</span></p><p class="c1"><span class="c0">Seems to also have a lot less of the classic MVSep phase issue, where for some reason half the stem is in the synth stem and the other half is in the no synth stem </span></p><p class="c1"><span class="c0">and inverting it cancels it out (literally almost all models have this issue on MVSep it&#39;s very strange). It&#39;s much less than the other models, but yeah, it still happens. (...) Using any other model in UVR or uvronline don&#39;t have this issue. (...) I put a bass guitar stem from Fortnite festival, it worked exceptionally well. Not much muddiness at ALL, really good. Separated the synth bass stem from bass really well. Ok wait, it seems very freaky, extremely freaky.</span></p><p class="c1"><span class="c0">It has the phasing issue. Yeah, WTF. It inverts&rdquo; - Isling</span></p><p class="c1"><span class="c0">&ldquo;I put it the synth model through a really packed song with no synth to see if it would get tripped up, it didn&#39;t other than some bass at the end.</span></p><p class="c1"><span>Which actually didn&#39;t get picked up by the bass model, so even that is a win&rdquo; - dynamic64</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;Several SATB (soprano, alto, tenor, bass) choir models I trained ages ago, currently only a scnet_masked model is available, but I did have Demucs, MDX23C, and standard SCNet models that I will upload to this link when/if I find them, although I&#39;m pretty sure the scnet_masked model was the best in the end:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1BpPgtlDk0yqrlArmrq9vnYErixb8I8zJ?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741791532&amp;usg=AOvVaw2Rp-vgWcb9aP6JtWYgln7M">https://drive.google.com/drive/folders/1BpPgtlDk0yqrlArmrq9vnYErixb8I8zJ?usp=sharing</a></span><span class="c0">&rdquo; - Dry Paint Dealer</span></p><p class="c1"><span>Treat it as proof of concept.</span></p><p class="c1"><span class="c0">&ldquo;I&#39;ve tried the SCNet one, it&#39;s really noisy, and it has a lot of bleed, it kinda works. I can see the potential on this kind of model ngl.&rdquo; - smilewasfound</span></p><p class="c1"><span>&ldquo;You can&rsquo;t install [the VR ones] into UVR since that only supports VR v5 [and 5.1] not </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/tsurumeso/vocal-remover/releases&amp;sa=D&amp;source=editors&amp;ust=1765035741792234&amp;usg=AOvVaw2LemoZgucCRXVp3yA7Oi8F">VR v6</a></span><span class="c0">&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) Seven new models have been added:</span></p><p class="c1"><span>1) MVSep Electric Guitar (electric-guitar, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251031064813-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741792944&amp;usg=AOvVaw3RIdUtQM3_8xsUuE--nA0F">https://mvsep.com/result/20251031064813-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>2) MVSep French Horn (french-horn, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251031072529-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741793434&amp;usg=AOvVaw12jAwGZ7ulArNz6sz598eR">https://mvsep.com/result/20251031072529-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>3) MVSep Banjo (banjo, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251031095934-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741793868&amp;usg=AOvVaw0sHhTu6QcRGg3pznal3wcI">https://mvsep.com/result/20251031095934-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>4) MVSep Marimba (marimba, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251031100024-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741794311&amp;usg=AOvVaw30XOjCwCQ8AJ-5sPeLWB4D">https://mvsep.com/result/20251031100024-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>5) MVSep Glockenspiel (glockenspiel, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251031100134-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741794793&amp;usg=AOvVaw0VKsidpcxVqEDiEByeehez">https://mvsep.com/result/20251031100134-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>6) MVSep Timpani (timpani, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251031100232-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741795102&amp;usg=AOvVaw0UtuEMEw0maLgbZUBv5C7Z">https://mvsep.com/result/20251031100232-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>7) MVSep Harmonica (harmonica, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251031100508-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741795396&amp;usg=AOvVaw0dNHcDGE6zBLYEuIbKPsB2">https://mvsep.com/result/20251031100508-f0bb276157-mixture.wav</a></span><span class="c0">&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The Harmonica model is hit or miss.&rdquo; - musicbybrooks</span></p><p class="c1"><span class="c0">&ldquo;Wow, the electric guitar model is really neat. One thing I noticed is that it seems to be better than other models at picking up midi/synth lead guitars. At least on stuff I tried.</span></p><p class="c1"><span>I think it also gets tripped up a bit more by weird FX and synth sounds being partially flagged as guitar. An interesting model, though, for sure.&rdquo; - Musicalman</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;The karaoke model by anvuew has been added under the algorithm &quot;MVSep Karaoke (lead/back vocals)&quot;. It is available as the option &quot;BS Roformer by anvuew (SDR: 10.22)&quot; - ZFTurbo</span></p><p class="c1"><span class="c0">For some reason it seems to give worse results than the ckpt anvuew shared.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Dear friends at Apple Music. Please stop harassing labels and their sound engineers for making Atmos mixes using our and yours awesome AI models for audio separation. The artificial artifacts you&#39;re solely looking for in spectrograms in separate channels are inaudible in the entire tracks. The tracks are well mixed and accepted by major labels, but rejected by your lazy ass incompetent bullshit. The quality of Atmos mixes got better since the very beginning, and either your employees, or your algorithms, or both, do a lazy job without even hearing the shit on their own, while still rejecting stuff without sensible reason! You&#39;re making things nasty difficult for artists who lost their multitracks for certain legacy songs, rendering re-releasing of their albums in Atmos potentially impossible. Bring it up with the executives. Get your shit together, for fuck sakes!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Full release of mesk&rsquo;s rifforge Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/meskvlla33/rifforge/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741798414&amp;usg=AOvVaw3YDoNBmDvMm_iFglzvGe6V">model</a></span><span>&nbsp;</span><span class="c0">focused on inst/voc separation for metal music</span></p><p class="c1"><span class="c0">&ldquo;The model can have some quirks (just like most models) but it&#39;s all around clean for me to release.&rdquo;</span></p><p class="c1"><span class="c0">Training details:<br>&ldquo;Characteristics:</span></p><p class="c1"><span class="c0">This is a dimension 512 depth 24 model (so fairly large file size at 1.9 GB!), with an SDR of 14.2436.</span></p><p class="c1"><span class="c0">It&#39;s finetuned from an older Melband Roformer checkpoint with an SDR of 13.7.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released experimental BS-Roformer karaoke </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/bsroformers&amp;sa=D&amp;source=editors&amp;ust=1765035741799417&amp;usg=AOvVaw2SN0MuARD6SmkTvfA1A8Ol">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9198&amp;sa=D&amp;source=editors&amp;ust=1765035741799522&amp;usg=AOvVaw1dHyLJoC8BxhxFBrSX1ve9">metrics</a></span></p><p class="c1"><span class="c0">It gives the same error for RTX 5000 UVR patch users as the avuew&rsquo;s model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New ensemble (avg) of anvuew&rsquo;s and becruily &amp; frazer karaoke models was evaluated on the leaderboard (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9190&amp;sa=D&amp;source=editors&amp;ust=1765035741800078&amp;usg=AOvVaw0JJLTPidaZD1sYEbf8zp5k">metrics</a></span><span>&nbsp;lower than BSkarfrazerBecruily+BSkarMVSEP+MBkarGaboxV2 SDR-wise</span><span>). Probably you could make a </span><span class="c4"><a class="c3" href="#h.900rfc8gjynn">fusion model</a></span><span>&nbsp;</span><span class="c0">out of the two to save on inference time in cost of slight SDR decrease (both use the same config so it might work).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- erosunica found out that BS-Roformer SW drums is &ldquo;really good to remove some SFX and foley, way better than DnR v3&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released voc_fv7 beta 1 Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/vocfv7beta1.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741801011&amp;usg=AOvVaw2QZBZ1tjmxZeW9OWyEiZpH">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741801178&amp;usg=AOvVaw3wnVdTTBuf0-SaJVYJZe6R">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741801372&amp;usg=AOvVaw1o4rIVeH2gmfwAf4axe-Dy">Colab</a></span></p><p class="c1"><span class="c0">Voc. fullness: 21.21, bleedless: 30.81, SDR: 10.96</span></p><p class="c1"><span class="c0">&quot;Just a better fv4 it seems, better bleedless&quot; (fullness: 21.33, bleedless: 29.07, SDR 10.58)</span></p><p class="c1"><span class="c0">vs voc_fv4 &quot;It is noisier.. Kinda closer to beta 5e?&rdquo; &ldquo;It&#39;s slightly less noise and fullness than beta 5e but picking up the backing vocals REALLY well, significantly better than beta 5e&rdquo;</span></p><p class="c1"><span class="c0">But it&#39;s pulling the backing vocals out even better than 5e&rdquo; &ldquo;the backing vocals are so good!</span></p><p class="c1"><span class="c0">&ldquo;it does have significant synth bleed, too... &nbsp; it at least wasn&#39;t coming through at full volume</span></p><p class="c1"><span class="c0">when I say fullness, I specifically mean how muddy it sounds&rdquo; - Raiboom Dash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Anvuew released a new Karaoke BS-Roformer model</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/karaoke_bs_roformer&amp;sa=D&amp;source=editors&amp;ust=1765035741802906&amp;usg=AOvVaw1dewhW_KNIcyDUBzRDswbX">https://huggingface.co/anvuew/karaoke_bs_roformer</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9180&amp;sa=D&amp;source=editors&amp;ust=1765035741803090&amp;usg=AOvVaw0MwzQVe1Tn9Nu8xc_gdg4g">https://mvsep.com/quality_checker/entry/9180</a></span></p><p class="c1"><span>UVR users will encounter &ldquo;ModuleNotFoundError: &quot;No module named &#39;torch._dynamo.polyfills.fx&#39;&quot; with this model (consider </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span>&nbsp;instead). </span><span class="c34">Maybe users of RTX 5000 won&rsquo;t encounter that issue due to newer PyTorch in dedicated patch. </span><span class="c0">Sadly not - even with CPU only. Even more, the issue seems to exist only on RTX 5000 patch.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;karaoke anvuew extracts lead vocals a bit better than karaoke becruily frazer, and in some parts, the lead vocals from karaoke anvuew still sound brighter compared to karaoke becruily frazer, which sounds a bit more compressed. oh, and for some reason, the becruily frazer model doesn&rsquo;t detect vocals with radio effects, while anvuew&rsquo;s model handles them just fine&rdquo; - neoculture </span></p><p class="c1"><span class="c0">&ldquo;lead vocals leak into instrumental (...) Mel Becruily and Frazer&rsquo;s BS don&rsquo;t have this problem&rdquo;</span></p><p class="c1"><span class="c0">In that case, maybe &ldquo;isolate the acapella first in almost all cases of using a karaoke model&rdquo;</span></p><p class="c1"><span class="c0">Demo:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pillows.su/f/671f60ffdd615eb2613c78dca70319fe&amp;sa=D&amp;source=editors&amp;ust=1765035741805155&amp;usg=AOvVaw2qaqvfvAnSJNVAN5_55F0f">https://pillows.su/f/671f60ffdd615eb2613c78dca70319fe</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pillows.su/f/391ec7ba8353a086989c9c0934321260&amp;sa=D&amp;source=editors&amp;ust=1765035741805392&amp;usg=AOvVaw2Wkl7gSqL4NvhIpydaiZ2-">https://pillows.su/f/391ec7ba8353a086989c9c0934321260</a></span><span>&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (MVSEP) &ldquo;I added a new DeReverb model </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_room&amp;sa=D&amp;source=editors&amp;ust=1765035741805737&amp;usg=AOvVaw1ZH6NhCT4swwEza08xfptI">https://huggingface.co/anvuew/dereverb_room</a></span></p><p class="c1"><span class="c0">by avuew. It&#39;s available in Reverb Removal (noreverb) [by choosing] DeReverb room by anvuew (BSRoformer). It works only for vocals. Since it is a mono model, it processes 2 stereo channels independently.&rdquo; - ZFTurbo</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251017064532-53be20aa17-10seconds-song.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741806380&amp;usg=AOvVaw1hVe9xyWinDEaRiswVJmkl">https://mvsep.com/result/20251017064532-53be20aa17-10seconds-song.wav</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) Four new models have been added:</span></p><p class="c1"><span>1) MVSep Tambourine (tambourine, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251015221411-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741806872&amp;usg=AOvVaw20N-7PBaP5RLHsXPbnY_D9">https://mvsep.com/result/20251015221411-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>2) MVSep Oboe (oboe, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251015221618-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741807206&amp;usg=AOvVaw2M3ALS0sSWTwxXC7HyJH1O">https://mvsep.com/result/20251015221618-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>3) MVSep Clarinet (clarinet, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251015221718-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741807537&amp;usg=AOvVaw0O8LGuDpC8QU3OBgx20F2v">https://mvsep.com/result/20251015221718-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>4) MVSep Digital Piano (digital-piano, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20251015221944-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741807846&amp;usg=AOvVaw0h98RmbMeqVdlb17jkdZ3Q">https://mvsep.com/result/20251015221944-f0bb276157-mixture.wav</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes it can also work better for normal piano and make even better work then SW if it works.</span></p><p class="c1"><span class="c0">&ldquo;Absolutely fantastic for an epiano. i just put your example song through mvsep with the bs sw piano model as a comparison and bs sw did terribly. Ofc your epiano model picked up all of the epiano in a clean way&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Pretty impressive. Besides it being more full than other piano models (in most cases), it&#39;s also by far the only piano model that doesn&rsquo;t mistakenly pick up other instruments like tubular bells as piano.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;From what i tested is more for midi piano, i tested with some tracks with that kind of midi sound and it worked way better that SW.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (training) Becruily made a modification of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/junyuchen-cjy/DTTNet-Pytorch&amp;sa=D&amp;source=editors&amp;ust=1765035741809211&amp;usg=AOvVaw0_HCo-DM6jbKmy_11Kl1Sf">dTTnet </a></span><span>arch working in MSST (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1e2NmyxxJU1h2wGxomBl7D-NXJBYHMXsU?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741809368&amp;usg=AOvVaw2gmL81aXKCUMEWy019_Ovc">DL</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">&ldquo;They report very good performance on vocals with low parameters&rdquo; - Kim</span></p><p class="c1"><span class="c0">Back in the end of 2023, one indie pop song from multisong dataset (of the two there) received the best SDR - Bas Curtiz</span></p><p class="c1"><span class="c0">&ldquo;Better than SCNet imo, remains to see if it can beat rofos&rdquo; - Becruily</span></p><p class="c1"><span class="c0">&ldquo;Not fast to train. I&#39;m back with vanilla mdx23c. Trying a config to train model with less than 4GB &nbsp;VRAM, (...) with my 1080Ti and batch_size=1, chunk_size is around 1.5sec)&rdquo; - jarreou</span></p><p class="c1"><span class="c0">Installation instruction:</span></p><p class="c1"><span class="c0">&ldquo;In the latest MSST [at least for 13.10.25]</span></p><p class="c1"><span class="c0">add the ddtnet folder to &quot;models&quot; and replace your settings file in utils with this&rdquo;</span></p><p class="c1"><span class="c0">The mod breaks compatibility with the authors&#39; checkpoint. </span></p><p class="c1"><span>&ldquo;The weird thing is, it sounds like a fullness model despite not being one, I barely can find dips in instrumentals. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/12an8wnKC-FKE48gVu9pHvUaLSxzpC6C8?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741811214&amp;usg=AOvVaw28cPR7yRUj_szJH_Mvzvt4">ddtnet vs kim melband</a></span><span class="c0">, if anyone is curious&rdquo; - bcr</span></p><p class="c1"><span class="c0">&ldquo;Also keep in mind authors trained with l1 loss only, default in MSST is masked loss&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;l1 loss when dataset is noisy, mse loss when dataset is clean&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;the loss is defined from msst, but in the original dttnet it was in the code itself</span></p><p class="c1"><span class="c0">you can just --loss l1_loss&rdquo;</span></p><p class="c1"><span class="c0">@jarredou &ldquo;I copied your tfc and tfc_tdf classes to my files (and used that latest stft/istft I sent) - and seems to be better, just like the og dttnet </span></p><p class="c1"><span class="c0">the tfc/tdf fixed the nan issue for me (...)</span></p><p class="c1"><span class="c0">Keep in mind, ddtnet was trained only with musdb and has 10-20x less params while being comparable in quality&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;the authors checkpoints had 16khz cutoff because dim_f was smaller than nfft/2</span></p><p class="c1"><span class="c0">if you want to train model with cutoff it&#39;s fine, if you want fullband then dim_f must be half of nfft + 1&rdquo; - becruily</span></p><p class="c1"><span>Hit our </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1220364005034561628/1414698972752248904&amp;sa=D&amp;source=editors&amp;ust=1765035741814117&amp;usg=AOvVaw2Quwe4UjwvIuIMdawjH85S">#dev-talk</a></span><span class="c0">&nbsp;for more.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New sites added to </span><span class="c4"><a class="c3" href="#h.ataywcoviqx0">Site and rippers</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://deezmate.com/&amp;sa=D&amp;source=editors&amp;ust=1765035741814597&amp;usg=AOvVaw3WcmRIY-stPD4IJYPze2ZF">deezmate.com</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tidal.qqdl.site/&amp;sa=D&amp;source=editors&amp;ust=1765035741814735&amp;usg=AOvVaw2pcgDV87S7yGgBPyBi0te7">tidal.qqdl.site</a></span><span>).<br>Qubuz remains or defunct/problematic for now.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- We have numerous reports about some models like Unwa Resurrection inst having problems on AMD (and probably Intel GPUs) in UVR, returning &ldquo;Invalid parameter&rdquo; error. In that case, uncheck GPU Conversion (but it will be slower). If you find a fix, please let us know on the Discord (link at the top of the doc).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- if you deal with slow separation times on becruily &amp; Frazer karaoke model, decrease chunk_size to 160000 on 8GB GPUs. As long as decreasing chunk_size on CUDA (NVIDIA) doesn&#39;t seem to affect separation times, it&#39;s not the case with DirectML (AMD/Intel), if you&#39;re exceeding your VRAM, but it still doesn&rsquo;t crash.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Added anvuew BS-Roformer Dereverb Room (mono) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_room&amp;sa=D&amp;source=editors&amp;ust=1765035741816912&amp;usg=AOvVaw0Xsc51wOgDseTquSKQLruk">model</a></span><span>&nbsp;to the inference </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741817266&amp;usg=AOvVaw2EOZYCuHhoV1J0pEdQ2fGN">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sir Joseph released a Colab for A2SB: Audio Restoration NVIDIA&rsquo;s upscaler.</span></p><p class="c1"><span class="c0">It&rsquo;s very slow - on 4070 Super it was slow already, and in free Colab we got Tesla T4 with RTX 3050 performance with 12GB of VRAM instead of 8 - memory issues might occasionally occur, Colab Pro recommended. <br>Only inpainting doesn&rsquo;t work (feature for filling silences if exist or missing parts) - &ldquo;I couldn&#39;t fix the error. If anyone solves it, I&#39;d be glad if they let me know so I can update it too.&rdquo;. A2SB should rather surpass AudioSR, Apollo and FlashSR (it does at least metrically).</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1ThenZDCRTJKV1I_ax17XGWmkB1qoKrFs?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741820453&amp;usg=AOvVaw2ih087vQ9UY4G8RY0vUreH">https://colab.research.google.com/drive/1ThenZDCRTJKV1I_ax17XGWmkB1qoKrFs?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Gabox released inst_fv4 model. Don&rsquo;t confuse it with inst_fv4noise - the regular variant was never released before (and with voc_fv4).</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_Fv4.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741821586&amp;usg=AOvVaw07UhfERQ-h3oHooez2lnnz">https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_Fv4.ckpt</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741821844&amp;usg=AOvVaw266uVYiuLMoQFwwdjEP6iA">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741822173&amp;usg=AOvVaw0-Q0jI7ybVQ0QxSJdZGJKw">Colab</a></span></p><p class="c1"><span>&ldquo;Seems to be erasing a xylophone instrument. Does sound not too noisy and not muddy, I like it. (...) A little noisy with piano (I split the song up and process with resurrection inst there). (...) Does have some issues that resurrection inst doesn&#39;t have, but it doesn&#39;t sound muddy! It usually works great. (...) In my opinion, fv4 still has vocal traces, I don&#39;t know if in all of its songs and v1e plus doesn&#39;t have them, but the noise can bother you even though it&#39;s not much. Does have more vocal bleed at times. I think a lot of what I thought was vocal bleed was a synth, it did a pretty good job... There was one segment on a song where it caught vocal residues, though&rdquo; - rainboomdash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- neoculture released a Mel-Roformer instrumental model focused on preserving vocal chops</span></p><p class="c1"><span class="c0">Inst. fullness 39.88, bleedless: 32.56, SDR: 14.35</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/natanworkspace/melband_roformer/blob/main/Neo_InstVFX.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741825038&amp;usg=AOvVaw3i1x0RPNP0erIqssqQL9HO">https://huggingface.co/natanworkspace/melband_roformer/blob/main/Neo_InstVFX.ckpt</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/natanworkspace/melband_roformer/blob/main/config_neo_inst.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741825198&amp;usg=AOvVaw3mokH_U5XKLfw5oWDLlaan">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741825391&amp;usg=AOvVaw0NcP2xC8DsHQSoHPC4ZApm">Colab</a></span></p><p class="c1"><span class="c0">&ldquo;great model (at least for K-pop it achieved the clarity and quality that no other model managed to have) it should be noted that it has a bit of noise even in its latest update, its stability is impressive, how it captures vocal chops, in blank spaces it does not leave a vocal record, sometimes the voice on certain occasions tries to eliminate them confusing them with noise, but in general it was a model that impressed me. It captures the instruments very clearly&rdquo; - billieoconnell.</span></p><p class="c1"><span class="c0">&ldquo;NOISY AF, this is probably the dumbest idea ever had for an instrumental model. Don&rsquo;t use it as your main one, some vocals will leak because I added tracks with vocal chops to the dataset. Just use this model for songs that have vocal chops&rdquo; - neoculture</span></p><p class="c1"><span class="c0">It was trained on only RTX 4060 8GB.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aname Mel trained a Mel-Roformer model called </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/Mel_Band_Roformer_Full_Scratch&amp;sa=D&amp;source=editors&amp;ust=1765035741827130&amp;usg=AOvVaw2eyYOu_iqWNcAZczluJkLm">Full Scratch</a></span></p><p class="c1"><span class="c0">Inst. fullness: 25.10, bleedless: 37.13, SDR: 14.32</span></p><p class="c1"><span class="c0">Voc. fullness: 13.24, bleedless: 30.75, SDR: 8.01</span></p><p class="c1"><span class="c0">(&ldquo;trained from scratch on a custom-built dataset targeting vocals. It can be used as a base model or for direct inference. Estimated Training cost: ~$100&rdquo;)</span></p><p class="c1"><span class="c0">For state_dict error, update MSST to the last repo version:</span></p><p class="c1"><span class="c0">!rm -rf /content/Music-Source-Separation-Training</span></p><p class="c1"><span class="c0">!git clone https://github.com/ZFTurbo/Music-Source-Separation-Training</span></p><p class="c1"><span class="c0">&ldquo;and you must reinstall main branch&#39;s requirement.txt. (before it, edit requirements.txt to remove wxpython)&rdquo; - Essid</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Kim Mel model for reference:</span></p><p class="c1"><span class="c0">Inst. fullness 27.44, bleedless 46.56, SDR: 17.32</span></p><p class="c1"><span class="c0">Voc. bleedless: 36.75, fullness: 16.26, SDR: 11.07</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;1) Model by baicai1145 was added in Apollo Enhancers (by JusperLee, Lew, baicai1145) with name Universal Super Resolution (by baicai1145) (...)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2) New option added for Apollo Enhancers (by JusperLee, Lew, baicai1145) - Cutoff (Hz). Sometimes it can be useful to cut higher frequencies before applying model.&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- baicai1145 released their own Apollo vocal restoration model, which surpassed Lew&rsquo;s vocal V2 model metrically.</span></p><p class="c1"><span class="c0">&ldquo;with a 92-hour high-quality vocal dataset trained for 1 million steps.&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/baicai1145/Apollo-vocal-msst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741829926&amp;usg=AOvVaw2A1vsItl9nyZWXF97E-TJ0">https://huggingface.co/baicai1145/Apollo-vocal-msst/tree/main</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9105&amp;sa=D&amp;source=editors&amp;ust=1765035741830139&amp;usg=AOvVaw0hQD9gyGX0iuCw5OIvqb5G">https://mvsep.com/quality_checker/entry/9105</a></span></p><p class="c1"><span class="c0">21.24 vs 13.09 Aura MR STFT</span></p><p class="c1"><span class="c0">(thx Essid)</span></p><p class="c1"><span>ReminderL Apollo arch support was added to UVR too (acceleration work with NVIDIA GPUs only). Installing the model should be possible also there, although currently UVR seems to be incompatible with the model outputting following error:<br></span><span class="c20">KeyError: &quot;&#39;infos&#39;&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;Two new algorithms have been added:</span></p><p class="c1"><span>1) MVSep Mandolin (mandolin, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250927132339-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741831181&amp;usg=AOvVaw1f6XPoIsz0C2IO5lBeFQWT">https://mvsep.com/result/20250927132339-f0bb276157-mixture.wav</a></span></p><p class="c1"><span>2) MVSep Trombone (trombone, other). Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250927132547-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741831481&amp;usg=AOvVaw2qj6PBjQrOJO3xXBg_OAfD">https://mvsep.com/result/20250927132547-f0bb276157-mixture.wav</a></span><span>&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- ROCm 6.4.4 now allows using PyTorch natively on Linux and Windows on RX 7000 and 9000, so you don&rsquo;t need WSL with them - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.techpowerup.com/341329/amd-enables-pytorch-on-radeon-rx-7000-9000-gpus-with-windows-and-linux-preview&amp;sa=D&amp;source=editors&amp;ust=1765035741831953&amp;usg=AOvVaw2VLmkjn2p9oUQXH1Y47W95">link</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- BS-Roformer 6 stems added on uvronline</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;I added new version of MVSep Organ (organ, other) model: &quot;BS Roformer (SDR organ: 5.08)&quot;. SDR increased from 3.05 to 5.08.</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250924223759-0efd607228-song-organ-000-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741832653&amp;usg=AOvVaw2RSe0q8kTnd5cRKYvqNiqc">https://mvsep.com/result/20250924223759-0efd607228-song-organ-000-mixture.wav</a></span><span>&rdquo; </span><span class="c0">- ZFTurbo</span></p><p class="c1"><span class="c0">&ldquo;I think the model is remarkable improvement&rdquo; - totalmentenormal</span></p><p class="c1"><span class="c0">&ldquo;the result is great, no bleed from what I tested it on&rdquo; - dynamic64</span></p><p class="c1"><span class="c0">&ldquo;much better isolation of the Hammond organs compared to the previous model. In places where the organ sound was not picked up before, it is now separated in the track&rdquo; - lukasz2286</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Google Colab now allows pinning your environment to specific version having the same versions of packages, so maybe your notebook won&#39;t break in the future due to changes in the environment introduced by Google in the Colab with package updates.</span></p><p class="c1"><span class="c0">For now there is only 2025.07 and the latest environment to choose from, and it&#39;s hard to tell if e g. 2025.07 environment will be gradually replaced along the time while new changes to the latest Colab environment will be made: </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://developers.googleblog.com/en/google-colab-adds-more-back-to-school-improvements/&amp;sa=D&amp;source=editors&amp;ust=1765035741834324&amp;usg=AOvVaw3kTUTLNDE72TKRc7NcujPo">https://developers.googleblog.com/en/google-colab-adds-more-back-to-school-improvements/</a></span></p><p class="c1"><span>To use it, go to Environment&gt;Change environment type&gt;Environment type version and choose 2025.07 option</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Essid reevaluated GAudio (a.k.a. </span><span class="c4"><a class="c3" href="#h.yy2jex1n5sq">GSEP</a></span><span class="c0">) for the leaderboard.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9095&amp;sa=D&amp;source=editors&amp;ust=1765035741834965&amp;usg=AOvVaw3tf4QbZXUvkzmjVd0cDXvH">https://mvsep.com/quality_checker/entry/9095</a></span></p><p class="c1"><span>Inst fullness: 28.83, bleedless: 31.18, SDR: 12.59</span></p><p class="c1"><span class="c0">The result would rather cover my observations that instrumentals rather have gotten worse over the years (at least since the last 2023 Bas&#39; evaluation or even earlier, at least for certain songs). But it appears that the vocals might got better.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?algo_name_filter%3DGsep%26sort%3Dinstrum%26ranking_metrics%3D&amp;sa=D&amp;source=editors&amp;ust=1765035741835953&amp;usg=AOvVaw04_mrj4_cy99DAlIN6bGa-">https://mvsep.com/quality_checker/multisong_leaderboard?algo_name_filter=Gsep&amp;sort=instrum&amp;ranking_metrics=</a></span></p><p class="c1"><span class="c0">Despite the fact the metrics are worse than even the least bleedless free community models like even V1e, for specific songs where bleeding doesn&#39;t occur so badly, GSEP might be still interesting too try out to some limited extend, being a different architecture, sounding maybe less filtered. Also, mixdown of multi stem extraction instead, should rather have bigger bleedless metric, but since the appearance of instrumental Roformers, GSEP relevance for separation is rather faded.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;Ensemble of 3 [karaoke] models &quot;Mvsep + gabox + frazer/becruily&quot; gives 10.6 SDR on leaderboard. I didn&#39;t upload it yet, but I had local testing.&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- fabio06844 shared his method for &ldquo;very clean and full&rdquo; instrumental lately.</span></p><p class="c1"><span class="c0">1) Go to MVSep and separate your song with the latest Karaoke BS-Roformer by MVSep Team</span></p><p class="c1"><span class="c0">2) On its instrumental stem use DEBLEED-MelBand-Roformer (by unwa/97chris)</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/bleed_suppressor_melband_rofo_by_unwa_97chris/resolve/main/bleed_suppressor_v1.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741837958&amp;usg=AOvVaw2GdhZhOwqVS3WEkOBmxEzF">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/bleed_suppressor_melband_rofo_by_unwa_97chris/resolve/main/config_bleed_suppressor_v1.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741838129&amp;usg=AOvVaw3PBRgkiAmmvYa3CqScX7Kh">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741838315&amp;usg=AOvVaw3rID60Quhb98O3bfvwvdNB">Colab</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">Despite the fact that &ldquo;the MVSep Team Karaoke uses the MVSep BS model to extract/remove vocals, then applies [the] karaoke model to that&rdquo;, it was told to be not enough to just use BS 2025.07 model instead, leaving a little more residues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aname released Mel-Roformer duality </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/Mel-Band-Roformer_Duality&amp;sa=D&amp;source=editors&amp;ust=1765035741839125&amp;usg=AOvVaw2dQUQy4Y5mHH9IfMZFC24I">model</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">&ldquo;it&#39;s odd why the model is named duality, but it has a single target (and the file size of the ckpt confirms it further)&rdquo; - becruily <br>It&rsquo;s focused more on bleedless than fullness metric contrary to the unwa&rsquo;s duality v2 model, but with bigger SDR. </span></p><p class="c1"><span class="c0">Inst. fullness 24.36, bleedless 46.52, SDR: 17.15</span></p><p class="c1"><span class="c0">&ldquo;instrumental is really muddy&rdquo; - Gabox</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For comparison - </span></p><p class="c1"><span class="c0">Mel Duality v2 by unwa</span></p><p class="c1"><span class="c0">Inst. fullness 28.03, bleedless 44.16, SDR: 16.69</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MelBand Roformer vocals by Kim</span></p><p class="c1"><span class="c0">Inst. fullness 27.44, bleedless 46.56, SDR: 17.39</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instrumental public models with the biggest fullness metric -</span></p><p class="c1"><span class="c0">Gabox Mel Roformer Inst_GaboxFv7z</span></p><p class="c1"><span class="c0">Inst. fullness: 29.96, bleedless: 44.61, SDR: 16.62</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unwa BS-Roformer-Inst-FNO </span></p><p class="c1"><span class="c0">Inst. fullness: 32.03, bleedless: 42.87, SDR: 17.60</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;I added new SCNet vocals model: SCNet XL IHF (high instrum fullness by becruily). It&#39;s high fullness version for instrumental prepared by becruily.&rdquo;</span></p><p class="c1"><span>&nbsp;Inst. </span><span>fullness</span><span class="c0">&nbsp;32.31, inst. bleedless 38.15, SDR 17.20</span></p><p class="c1"><span class="c0">&ldquo;One of my favorite instrumental models, Roformer-like quality.</span></p><p class="c1"><span class="c0">For busy songs it works great, for trap/acoustic etc. Roformer is better due to SCNet bleed&rdquo; - becruily</span></p><p class="c1"><span class="c0">&ldquo;It&#39;s better than BS Roformer (mvsep 2025.07 and inst Resurrection) at low frequencies, but bad at highs due the bleeding. I think it has better phase understanding, because it keeps the harmonics that were masked behind vocals cleaner (but it might not necessary be true to the source, it might just interpret/make up the harmonics instead of actual unmasking)&rdquo; - IntroC</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Dry Paint Dealer Undr released Melband Roformer and Demucs (&ldquo;or at least I think this is the correct model file&rdquo;) Lead and Rhythm guitar </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JH2tjhgDcJgvdi-hrQT82RsaV2XhE8hn?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741843193&amp;usg=AOvVaw2R7vTgAValMPJ4KW1ctVMP">models</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">&ldquo;My own very mediocre model for it that I never shared. It does work but has issues that I imagine any better executed model won&#39;t.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Wait, I think it separated doubles in vocals&rdquo; - isling</span></p><p class="c1"><span>Demucs model doesn&#39;t work in UVR, as it was trained on MSST, and not the OG code (I tried to workaround the bag_num issue </span><span class="c4"><a class="c3" href="#h.3c6n9m7vjxul">before</a></span><span>, and failed)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;Two new instrumental models have been added:</span></p><p class="c1"><span class="c0">MVSep Harp (harp, other)</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250921131108-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741844347&amp;usg=AOvVaw3M4fxEIQMGGBfQk6GsvZsQ">https://mvsep.com/result/20250921131108-f0bb276157-mixture.wav</a></span></p><p class="c1"><span class="c0">MVSep Double Bass (double-bass, other)</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250921131129-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741844790&amp;usg=AOvVaw1dwQLZxZssJTlwkchiMUcA">https://mvsep.com/result/20250921131129-f0bb276157-mixture.wav</a></span><span class="c0">&rdquo; - ZFTurbo</span></p><p class="c1"><span class="c0">&ldquo;The BS-Roformer SW bass model should probably be used first to extract the double bass. Creates a better sound. This does not apply to bowed double bass.</span></p><p class="c1"><span>Bowed double bass doesn&#39;t get picked up by BS-Roformer and therefore needs the double bass model. Good news is that bowed double bass is picked up in the strings stem so if you run the strings model you&#39;re good either way.&rdquo; - dynamic64</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;A new saxophone model based on BSRoformer was added. It has a much better metric compared to the previous [model]. SDR grew from 7.13 up to 9.77.</span></p><p class="c1"><span class="c0">It&#39;s available in &quot;MVSep Saxophone (saxophone, other)&quot; with option &quot;BS Roformer (SDR saxophone: 9.77)</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250920151232-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741846223&amp;usg=AOvVaw1NwTx6Rm8Trrf9Kmz9aXas">https://mvsep.com/result/20250920151232-f0bb276157-mixture.wav</a></span><span>&rdquo;</span><span class="c0">&nbsp;- ZFTurbo</span></p><p class="c1"><span class="c0">&ldquo;after testing this on a song where trumpet and sax play in unison, doing the trumpet model is cleaner than doing the sax model&rdquo; - dynamic64</span></p><p class="c1"><span class="c0">&ldquo;Amazing. Tested it on one song, it got every single Saxophone Part from the song it seems lit. Can hear one small little bitty part of it where it tries to come in off the Sax part, however I can barely hear it&rdquo; - cali_tay98</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- GAudio (a.k.a. GSEP) announced their SFX (DnR) model in their API:<br>&ldquo;DME Separation (Dialogue, Music, Effects)&rdquo; <br>So far it&rsquo;s not available for everyone on their regular site:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://studio.gaudiolab.io/&amp;sa=D&amp;source=editors&amp;ust=1765035741847431&amp;usg=AOvVaw09BWUfAXzcjlPb8OwrQ1ea">https://studio.gaudiolab.io/</a></span></p><p class="c1"><span class="c0">But the link on their Discord redirects to the site with a form to write an inquiry:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.gaudiolab.com/developers&amp;sa=D&amp;source=editors&amp;ust=1765035741847772&amp;usg=AOvVaw2NYJQDCo6csLpXvXFQ1uQi">https://www.gaudiolab.com/developers</a></span></p><p class="c1"><span class="c0">Shortly after entering the one or both of the links and logging on the first, you might get an email that $20 of free credits to access their API have been added to your account, and link to the API documentation:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.gaudiolab.com/docs&amp;sa=D&amp;source=editors&amp;ust=1765035741848251&amp;usg=AOvVaw2budxQSs6dmCysVBK_fHZg">https://www.gaudiolab.com/docs</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New Dango Karaoke model released </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tuanziai.com/en-US/blog/68ca20c87c8c85686c1b4511&amp;sa=D&amp;source=editors&amp;ust=1765035741848590&amp;usg=AOvVaw3YkForWks78Nuh2PBNgCV4">https://tuanziai.com/en-US/blog/68ca20c87c8c85686c1b4511</a></span></p><p class="c1"><span class="c0">A lot of problems when songs don&#39;t have lead vocals in the center.</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.8ewxd0mk3h66"><span>- (MVSEP) &ldquo;I added new Karaoke model: &quot;BS Roformer by MVSep Team (SDR: 10.41)&quot; it&#39;s available under option &quot;MVSep MelBand Karaoke (lead/back vocals)&quot;. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9068&amp;sa=D&amp;source=editors&amp;ust=1765035741849116&amp;usg=AOvVaw2BaF_wEo82qepV60G6MECV">Metrics</a></span><span>.</span></h6><h6 class="c1 c27" id="h.nge6bgppu1y0"><span class="c0">In contrast with other Karaoke models, it returns 3 stems: &quot;lead&quot;, &quot;back&quot; and &quot;instrumental&quot;.</span></h6><h6 class="c1 c27" id="h.ayyeij2sv9al"><span>Example: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250915192251-53be20aa17-10seconds-song.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741849672&amp;usg=AOvVaw0WKchiwJfAllZLESofHZoq">https://mvsep.com/result/20250915192251-53be20aa17-10seconds-song.wav</a></span><span class="c0">&rdquo; - ZFTurbo</span></h6><p class="c1"><span class="c0">&ldquo;If I had to compare it to any of the models, it is similar to the frazer and becruily model. Sometimes it does not detect the lead vocals specially if there&#39;s some heavy hard panning, but when it does, there is almost no bleed, and it works very well with heavy harmonies in mono from what I tested.&rdquo; - smilewasfound</span></p><p class="c1"><span class="c0">&ldquo;becruily &amp; frazer is better a little when the main voice is stereo&rdquo; - daylightgay</span></p><p class="c1"><span class="c0">&ldquo;On tracks I tested, harmony preservation was better in becruily &amp; frazer (...) the new model isn&#39;t worse, I ended up finding examples like Chan Chan by Buena Vista Social Club or The Way I Are by Timbaland where it is better than the previous kar model. The thing is, with the Kar models, it&#39;s just track per track. Difficult to find a model for batch processing as it&#39;s really different from one track to another&rdquo; - dca100fb8</span></p><p class="c1"><span class="c0">&ldquo;I also found the new model to not keep some BGVs, mainly mono/low octave ones, despite higher SDR&rdquo; - becruily</span></p><p class="c1"><span class="c0">&ldquo;I think I&#39;ve found a solution for people who don&#39;t like the new model.</span></p><p class="c1"><span class="c0">If you put an audio file through the karaoke model and then put the lead vocal result through that, it usually picks up doubles. <br>Which you can then put in your BGV stem if you&#39;d like&rdquo; - dynamic64</span></p><p class="c1"><span class="c0">&ldquo;it&#39;s definitely not as good as the one by frazer and becruily. SDR can be misleading sometimes&rdquo; - ryanz48</span></p><p class="c1"><span class="c0">becruily [&ldquo;our model] uses 11.9 SDR vocal model as a base&rdquo;</span></p><p class="c1"><span class="c0">ZFTurbo &ldquo;I started from SW weights&rdquo;</span></p><p class="c1"><span>&ldquo;I&#39;ve had fantastic results with it so far. Much MUCH better at holding the &#39;S&#39; &amp; &#39;T&#39; sounds than the Rofo oke (for backing vox). Generally seems to provide fuller results .. but also the typical &#39;ghost&#39; residue from the main vox can end up in the backing vox sometimes, but it&#39;s usually not enough to be an issue. I won&#39;t go so far as so say that it&#39;s replacing the other backing vox models for me entirely .. but it feels like the best of both worlds that Rofo and UVR2 provide.&rdquo; - CC Karaoke</span></p><h6 class="c1 c27 c7" id="h.yaly31rb6n1g"><span class="c0"></span></h6><h6 class="c1 c27" id="h.q7mmvsvty3k5"><span>- (MVSEP) &ldquo;We&rsquo;ve added a mirror of MVSep (big thanks to okhostok): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mirror.mvsep.com&amp;sa=D&amp;source=editors&amp;ust=1765035741853424&amp;usg=AOvVaw2pG0seckFy0ifE8aLw-68_">https://mirror.mvsep.com</a></span></h6><h6 class="c1 c27" id="h.j4kplwim5i1p"><span class="c0">If you have a problem with upload/download speed or can&#39;t reach the main site then try the mirror.</span></h6><h6 class="c1 c27" id="h.rbip7cu8qym5"><span class="c0">Report please if it helped you to speed things up.&rdquo; - ZFTurbo</span></h6><p class="c1"><span>Some issues with being unable to click separate button for some users were fixed.</span></p><h6 class="c1 c27 c7" id="h.7ywi9r3x2jni"><span class="c0"></span></h6><h6 class="c1 c27" id="h.zgs4nmt4n7oi"><span>- Gabox released BS_ResurrectioN </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/BS_ResurrectioN.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741854336&amp;usg=AOvVaw1aa8FbbC6HGyctpajdBWye">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741854509&amp;usg=AOvVaw0VnV_BkWxHj_59CuUybaV6">yaml</a></span></h6><h6 class="c1 c27" id="h.nxlim75k6p8o"><span class="c0">&ldquo;It is a finetune of BS Roformer Resurrection Inst but with higher fullness (like v1e for example), it needs [MVSEP&rsquo;s] BS 2025.07 (as a source/reference) phase fix [so you &ldquo;should process the instrumental result using BS 2025.07 then put [it] as source in UVR GUI phase fix tool&rdquo;]. I requested it because I found some songs where Resur Inst was producing muddy instrum results (...) I requested it not just for me because I saw other people were looking for something like v1e++&rdquo; - dca </span></h6><h6 class="c1 c27 c7" id="h.hv39hn9217y6"><span class="c0"></span></h6><h6 class="c1 c27" id="h.7d0taha5j2l4"><span>- anvuew released BS-Roformer Dereverb Room </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_room&amp;sa=D&amp;source=editors&amp;ust=1765035741855518&amp;usg=AOvVaw1BrXoJxw-pZyBFftSoqapa">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741855699&amp;usg=AOvVaw3j9ILsNhcPDds-KKzzvFAP">Colab</a></span></h6><h6 class="c1 c27" id="h.7hyw89vmnqto"><span class="c0">&ldquo;specifically for mono vocal room reverb.&rdquo; as most are recorded in mono.</span></h6><p class="c1"><span class="c0">Not that long inference compared to other Roformers.</span></p><p class="c1"><span class="c0">&ldquo;Really liking the fullness in the noreverb stem. Virtually all dereverb roformers I&#39;ve tried sound muddy, but this one is just the opposite. (...) Other noises may interfere, and in my experience, makes the model underestimate the reverb. [The previous anvuew&rsquo;s mono model] is way different [from] this one in every way. So, like I say, worth a shot.&rdquo; - Musicalman. &ldquo;WOAH this is insane. This would go viral if someone implemented in a plugin&rdquo; - heuhew</span></p><p class="c1"><span>We have reports about errors in UVR while using this model. Consider using </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span>&nbsp;</span><span class="c0">instead.<br>If you have stereo errors using MSST on stereo files, update MSST (git clone and git pull commands) or:<br>(it might work in your current version and not only in the linked repo too, but potentially the code will be located in a different line, the change will be pushed there later)</span></p><p class="c1"><span>&ldquo;Edit inference.py from my </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training/tree/colab-inference&amp;sa=D&amp;source=editors&amp;ust=1765035741857746&amp;usg=AOvVaw3THlETdb8S5ayPDIZssiXW">repo</a></span><span>&nbsp;</span><span class="c0">line 59:</span></p><p class="c1"><span class="c0">Replace :</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; # Convert mono to stereo if needed</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; if len(mix.shape) == 1:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mix = np.stack([mix, mix], axis=0)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">by :</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; # If mono audio we must adjust it depending on model</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; if len(mix.shape) == 1:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mix = np.expand_dims(mix, axis=0)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if &#39;num_channels&#39; in config.audio:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if config.audio[&#39;num_channels&#39;] == 2:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(f&#39;Convert mono track to stereo...&#39;)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mix = np.concatenate([mix, mix], axis=0)&rdquo;</span></p><p class="c1 c8"><span>&nbsp; &nbsp; - jarredou</span></p><h6 class="c1 c27 c7" id="h.8fm12z6qk9ea"><span class="c0"></span></h6><h6 class="c1 c27" id="h.snva8th7p3bn"><span>- BS-Roformer Karaoke </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/bs-roformer-karaoke/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741859574&amp;usg=AOvVaw0E9apVNunmQRys3EKbC51b">model</a></span><span>&nbsp;by becruily &amp; frazer released | MVSEP | uvronline<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9013&amp;sa=D&amp;source=editors&amp;ust=1765035741859749&amp;usg=AOvVaw3mREgJW9PBzEJ2nUS_P7h6">Metrics</a></span><span>&nbsp;better than even fused model gabox + aufr33/viperx and SCNet IHF below)</span><span class="c0">.</span></h6><h6 class="c1 c27" id="h.en3r3zxljk3w"><span>Make sure you don&rsquo;t have the option &ldquo;Vocals only&rdquo; checked in UVR.</span></h6><p class="c1"><span class="c0">&ldquo;After dozens of tests I can tell this (...) is the best (better harmony detection, better differentiation between LVs and BVs, sounds fuller, less background roformer bleed, better uncommon panning handling etc)&rdquo; - dca</span></p><p class="c1"><span class="c0">&ldquo;it also can detect the double vocals&rdquo; - black_as_night</span></p><p class="c1"><span class="c0">It works the best for some previously difficult songs. Aufr33 and viperx model seems more consistent, but the new BS is still the best in overall - Musicalman</span></p><p class="c1"><span class="c0">&ldquo;my og Mel also catches some of the FX/drums, I guess quite a difficult one due to how it&rsquo;s mixed&rdquo; - becruily</span></p><p class="c1"><span class="c0">&ldquo;it does do better on mono than previous</span></p><p class="c1"><span class="c0">sometimes confuses which voice should be the lead, but all models do that on mono in the exact use-case I normally test&rdquo; - Dry Paint Dealer Undr</span></p><p class="c1"><span class="c0">&ldquo;In my opinion, this model is in no way inferior to the ViperX (Play da Segunda) &mdash; it&#39;s really very good. (...) I noticed that in the separation, the first voice still appears mixed with the second. The second voice, however, stands out more, but not completely isolated&mdash;in some passages, it still appears alongside the first. In short: the model better separates the second voice, but still presents some mixing between them.&rdquo; - fabio5284 </span></p><p class="c1"><span class="c0">&ldquo;The new karaoke model doesn&#39;t actually differentiate between lvs &amp; bvs and there&#39;s some lead vocal bleeding in the instrumental stem&rdquo; - scdxtherevolution</span></p><p class="c1"><span class="c0">Fixes and expansion to the dataset and retrain of the model possible in the future.</span></p><p class="c1"><span class="c0">&ldquo;The dataset isn&#39;t correctly labelled, so in some training examples it was literally training the model to treat the backing vocal as the lead&rdquo; - frazer</span></p><p class="c1"><span class="c0">VS the newer BS-Roformer MVSEP team model above: &ldquo;sound isn&#39;t as clear, but it does an infinitely better job at telling lead/BGV apart&rdquo;</span></p><p class="c1"><span class="c0">Becruily:</span></p><p class="c1"><span class="c0">&ldquo;I want to remind something regarding my (and the frazer) models</span></p><p class="c1"><span class="c0">they&#39;re made to separate true lead vocals, meaning either all of the main singer&#39;s vocals, or if it&#39;s multiple singers - theirs too</span></p><p class="c1"><span class="c0">this means if the main singer has stuff like adlibs on top of the main vocals, these are considered lead vocals too - they go together</span></p><p class="c1"><span class="c0">if there are multiple singers singing on top of each other, including harmonise each other, and if there are additional background vocals behind those - all the singers will be separated as one main lead vocal, leaving only the true background vocals&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">think of them like concert ready models - the output instrumentals will be ready to play in cases where all main vocalists are going to sing on top of the karaoke instrumental</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">ps: and yes, double/stereo lead vocals are still lead vocals, they&#39;re not bgvs (only in rare cases)</span></p><p class="c1"><span>ps 2: if there are two singers singing the same melody and they don&#39;t harmonise each other - the model will most likely consider both singers as one lead vocal (again in rare cases one singer could be left) &rdquo;</span></p><h6 class="c1 c27 c7" id="h.55nqpnr7r89x"><span class="c0"></span></h6><h6 class="c1 c27" id="h.vn3e7zqkmp3z"><span>- (MVSEP) &ldquo;New Karaoke model based on SCNet XL IHF was added on site in &quot;MVSep MelBand Karaoke (lead/back vocals)&quot;. Name of model &quot;SCNet XL IHF by becruily (SDR: 9.53, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8962&amp;sa=D&amp;source=editors&amp;ust=1765035741866187&amp;usg=AOvVaw1pmPRNBuIPhp9P9trzFdtW">metrics</a></span><span class="c0">)&quot;. It has slightly worse metrics than the top Roformer model, but since it&#39;s different architecture it can give better results in some cases where the Rofo failed.</span></h6><h6 class="c1 c27" id="h.7ln6u4wu5csz"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250908072226-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741866753&amp;usg=AOvVaw3wtfbrmF3xa9MQpbyr4FHF">https://mvsep.com/result/20250908072226-f0bb276157-mixture.wav</a></span><span class="c0">&rdquo; - ZFTurbo</span></h6><p class="c1"><span>Iirc it&#39;s BVE or IHF unpublic ZFTurbo model retrain, and ckpt won&#39;t be public till further notice, as becruily said.</span></p><p class="c1"><span class="c0">&ldquo;SCNet is more bleedy in general despite me trying to reduce the leakage</span></p><p class="c1"><span class="c0">it&#39;s recommended for busy songs, often captures proper lead vocals better than Roformer. Another use case is to ensemble it with Roformer to improve fullness&rdquo; - becruily </span></p><p class="c1"><span class="c0">&ldquo;Oh, might be related to the lead vocals panning, it seems this model doesn&#39;t like when it&#39;s not center (...) I&#39;m indeed noticing this model works really great on some songs that the Mel Rofo Karaoke had trouble with (...) I noticed that, this model, instead of creating crossbleeding between LVs and BVs, make them both quieter. I prefer that compared to previous models Plus, it handle songs which have lead vocals in the sides and BVs also in the sides better&rdquo;</span></p><p class="c1"><span class="c0">To fix bleed in back-instrum stem, use &ldquo;Extract vocals first, but, &ldquo;I noticed a pattern that if you hear the lead vocals in the back-instrum track already (SCNet bleed), dont try to use Extract vocals first because there will be even more lead vocal bleed&rdquo; &nbsp;- dca</span></p><p class="c1"><span class="c0">&ldquo;Separates lead vocals better than Mel-Roformer karaoke becruily. It&#39;s not perfectly clean, sometimes a bit of the backing vocals slips through, but for now, scent karaoke model still the most reliable for lead vocals separation (imo)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pillows.su/f/df8c1791bceba5fe3ef6b16d310ec123&amp;sa=D&amp;source=editors&amp;ust=1765035741869753&amp;usg=AOvVaw1dr9Tc2IBTk_NpnJcZlzGi">https://pillows.su/f/df8c1791bceba5fe3ef6b16d310ec123</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pillows.su/f/e1272a02c56e3d3eb7ba4007bbb0c4bd&amp;sa=D&amp;source=editors&amp;ust=1765035741870053&amp;usg=AOvVaw1e-fXmR1NeDPILHpSdTnY7">https://pillows.su/f/e1272a02c56e3d3eb7ba4007bbb0c4bd</a></span><span class="c0">&rdquo; - neoculture.</span></p><p class="c1"><span class="c0">&ldquo;the model seems to handle mono vocals better than melband but isn&#39;t as clean, lot of bleed&rdquo; (extract vocals first was also used to test this) - Dry Paint Dealer Undr</span></p><p class="c1"><span class="c0">Since the Mel Kar Becruily&#39;s model, the dataset is &ldquo;larger&rdquo; now, but still not &ldquo;great&rdquo;, and it might get eventually fixed, becruily said.</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.g6guxr3z230p"><span class="c0">- (MVSEP) Four &ldquo;new models for independent instruments were added:</span></h6><h6 class="c1 c27" id="h.fkz7b9mum74"><span>1) MVSep Viola (viola, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250907234931-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741871391&amp;usg=AOvVaw2Zvv90HuUuzTZfs4DNTRBm">https://mvsep.com/result/20250907234931-f0bb276157-mixture.wav</a></span></h6><h6 class="c1 c27" id="h.7bp5gbhfkpl7"><span>2) MVSep Cello (cello, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250907235225-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741871765&amp;usg=AOvVaw1Z4mHkIkC-4WQb7FG7bHz5">https://mvsep.com/result/20250907235225-f0bb276157-mixture.wav</a></span></h6><p class="c1"><span>&ldquo;quite impressive&rdquo; - dynamic64</span></p><h6 class="c1 c27" id="h.yn5xp3mcz81o"><span>3) MVSep Trumpet (trumpet, other) Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250907235543-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741872263&amp;usg=AOvVaw3LgioJ9CyXiOykvyK2-xAa">https://mvsep.com/result/20250907235543-f0bb276157-mixture.wav</a></span></h6><p class="c1"><span class="c0">&ldquo;I can&#39;t get over how good the trumpet model is, it&#39;s so cleannn&rdquo; - Shintaro</span></p><p class="c1"><span>&ldquo;trumpet struggles a bit on muted trumpet&rdquo; - dynamic64</span></p><p class="c1"><span class="c0">4) MVSEP Strings BS-Roformer (strings, other)</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250907225920-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741872994&amp;usg=AOvVaw32D2spmXQ6QmFwU_ebeIMI">https://mvsep.com/result/20250907225920-f0bb276157-mixture.wav</a></span></p><h6 class="c1 c27" id="h.lh3u1yjcrg59"><span>T</span><span>he SDR has increased significantly compared to the previous MDX23C model, from 3.84 to 5.41. It is currently the best model on the leaderboard: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard/strings/?sort%3Dstrings&amp;sa=D&amp;source=editors&amp;ust=1765035741873627&amp;usg=AOvVaw12LvcDzuctFh54B2uG4hzW">https://mvsep.com/quality_checker/leaderboard/strings/?sort=strings</a></span><span class="c0">&rdquo; - ZFTurbo</span></h6><p class="c1"><span class="c0">&ldquo;From some quick testing, it does not disappoint. Still playing with it, but atm it&#39;s exactly what I hoped for.&rdquo; - Musicalman</span></p><p class="c1"><span class="c0">&ldquo;Yeah, I&rsquo;m running some tests too with a few tracks that were really hard to separate, mostly ones with cellos or vocals that were too blended with the strings to isolate even with the latest inst/voc models, and it&rsquo;s been working out surprisingly well.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.7r5bkm49kmf3"><span>- anvuew released experimental BS-Roformer vocal model (nfft 4096, stft_hop_length 1024 &ldquo;so not that large&rdquo;) with 12 SDR measured on musdb18hq dataset. Might be worth checking: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/18Va9tQqh_mkUHe_R2syl19bB9q_zzUre?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035741874782&amp;usg=AOvVaw1EhqYABooDcx-s8ClYL8xP">download</a></span><span class="c0">. </span></h6><h6 class="c1 c27" id="h.f7xrg49p6v7a"><span>11.60 SDR on the same test set was previously achieved by one of the first Mel-Roformers trained by Bytedance on musdbhq + 500 songs (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2310.01809&amp;sa=D&amp;source=editors&amp;ust=1765035741875309&amp;usg=AOvVaw0ScHzdT0YvnN2kIO1aZAzC">paper</a></span><span>), although it wasn&#39;t nfft 4096.</span></h6><p class="c1"><span>It uses very high 1024000 chunk_size in the yaml, so consider decreasing it when having memory issues, 500MB ckpt size.</span></p><h6 class="c1 c27 c7" id="h.y631tftnee2i"><span class="c0"></span></h6><h6 class="c1 c27" id="h.mha9xrfqx84j"><span>- introC released a python </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://file.garden/Z3gSJFxsb21HAqp6/scripts/v1ep_resonance_remover.zip&amp;sa=D&amp;source=editors&amp;ust=1765035741875964&amp;usg=AOvVaw2Uo2bjllDjQuhfXvjWowgq">script</a></span><span>&nbsp;</span><span class="c0">to get rid of vocal leakage in v1e+ model</span></h6><h6 class="c1 c27 c7" id="h.36mygh62fovb"><span class="c0"></span></h6><h6 class="c1 c27" id="h.wvbabryt7ky7"><span class="c0">- iZotope released Ozone 12. Separation still has Spleeter-like quality, but &ldquo;it&#39;s unclear what they use&rdquo; - Spleeter references disappeared from their readme (jarredou).</span></h6><p class="c1"><span>&ldquo;the stems sound very bleedy and not at all usable&rdquo; - becruily.</span></p><p class="c1"><span>A notable new feature working competitively is their Delimiter.</span></p><h6 class="c1 c27 c7" id="h.c2qt94qm0jr"><span class="c0"></span></h6><h6 class="c1 c27" id="h.8vzkn99tuifp"><span>- Ableton received its own stem separation feature in Live 12.3. It&rsquo;s made in cooperation with </span><span>Moises.ai</span><span>. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DuSahY-HGKt4&amp;sa=D&amp;source=editors&amp;ust=1765035741877439&amp;usg=AOvVaw1DsNvixMQLhJgWwqE1mlkb">https://www.youtube.com/watch?v=uSahY-HGKt4</a></span></h6><p class="c1"><span class="c0">&ldquo;doesn&rsquo;t even sound good&rdquo; - isling</span></p><p class="c1"><span>It doesn&rsquo;t use GPU, and has a slower High Quality setting too (single model for each stem opposing to default multi stem), but it can take even 20 minutes for 1 minute file on a slower CPU. At least default sounds more similar to Demucs than Roformers or SCNet archs, although files look like BS-Roformer judging by memory dump (model files are encrypted). </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8977&amp;sa=D&amp;source=editors&amp;ust=1765035741878513&amp;usg=AOvVaw2j3-FWRIsmhCpIaxwtTPwn">Here</a></span><span>&nbsp;are the low default model stems metrics - e.g. vocals only 8.71 SDR, but HQ option has bigger SDR than public SCNet weights released by ZFTurbo in MSST repo, but they&#39;re on a bleedless metric side, fullness is lower than in the public undertrained SCNet XL </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">4 stem</a></span><span class="c0">&nbsp;model. Average SDR of the first 12 songs in the multisong dataset vs public SCNet XL: drums: 11.58 vs 11.22, bass: 12.25 vs 11.27 (thx jarredou).</span></p><p class="c1"><span class="c0">&ldquo;The boring thing is that you have to launch separation for each file manually (no batch processing). To nice things is that the separated stems are automatically saved individually in folder (no need to export them individually through Live&#39;s rendering and all issue that this can produce; different length...)&rdquo; - jarredou </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- It seems like we&rsquo;ve received a step-by-step tutorial how to install the new Nvidia&rsquo;s upscaler: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/814405660325969942/1412356906030334003&amp;sa=D&amp;source=editors&amp;ust=1765035741880094&amp;usg=AOvVaw1_u3MCr7kb8RHiEZFskue5">click</a></span><span class="c0">&nbsp;(thanks Pipedream)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;I added BS Roformer flute model. It&#39;s available in &quot;MVSep Flute (flute, other)&quot;. It superior comparing to SCNet version. SDR: 9.45 vs 6.27. More than 3 SDR difference.</span></p><p class="c1"><span>Example: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250830211041-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741880736&amp;usg=AOvVaw28-dQBXiHuWC5fqfOnFsHM">https://mvsep.com/result/20250830211041-f0bb276157-mixture.wav</a></span><span>&rdquo; ZFTurbo </span></p><h6 class="c1 c27 c7" id="h.1e9tfv6df07k"><span class="c0"></span></h6><h6 class="c1 c27" id="h.dge0l0kovtzf"><span>- Thanks to Essid, metrics for following instrumental models were added to the models </span><span class="c4"><a class="c3" href="#h.2vdz5zlpb27h">list</a></span><span>:<br>INSTV7N, inst_fv8 (v2), inst_gabox3, Rifforge model, older mesk&rsquo;s metal model, FVX, Bv1, Bv2 (b - bleedless, v - for version)</span></h6><h6 class="c1 c27 c7" id="h.z96ygx768zsv"><span class="c0"></span></h6><h6 class="c1 c27" id="h.yax2b1y9ffy"><span class="c0">- &ldquo;New Wind model based on BS Roformer has been added in MVSep Wind (wind, other):</span></h6><h6 class="c1 c27" id="h.nujhjtjwtvpb"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250829230056-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741882056&amp;usg=AOvVaw1Dkpp3wDM8voiMZiDEipz9">https://mvsep.com/result/20250829230056-f0bb276157-mixture.wav</a></span></h6><h6 class="c1 c27" id="h.941m71ob400"><span>Results on quality checker: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8933&amp;sa=D&amp;source=editors&amp;ust=1765035741882426&amp;usg=AOvVaw1Fi2nfqPRZvx8CLbBU6XVD">https://mvsep.com/quality_checker/entry/8933</a></span><span class="c0">&nbsp;</span></h6><h6 class="c1 c27" id="h.wxjfq1gfq37b"><span>It increased SDR +2.5 comparing to previous best model.&rdquo; - ZFTurbo</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;this one does not disappoint. At least not with the stuff I&#39;ve tried so far. (...) the improvement is most noticeable with orchestral music. In heavy mixes eg. with lots of strings, the old models trip out. [The] new one is a lot more robust.&rdquo; - Musicalman</span></p><p class="c1"><span class="c0">&ldquo;the model is not only cleaner but also detects some wind instruments that the previous one couldn&#39;t (specially baritone saxophones, I need to test it a bit more)&rdquo; - smilewasfound</span></p><p class="c1"><span>&ldquo;the bs roformer wind model does really well with the other result and the violin model really is quite useful&rdquo; - dio7500, dynamic64</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.l0u3j68jiaa5"><span class="c0">- Suno now has stem separation feature &ldquo;t&#39;s generative, so the separation isn&#39;t exact. Also, you apparently can&#39;t use it on like famous songs because they&#39;ll get flagged.&rdquo; - Musicalman</span></h6><p class="c1"><span>&rdquo;it sounds like shit tbh, tried it out&rdquo; - dynamic64</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.nkgro1p90o7j"><span>- Gabox released experimental inst Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Fullness.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741884855&amp;usg=AOvVaw1C2WRCbL9gBznBKpSL7TeL">model</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741885032&amp;usg=AOvVaw3XuxOUL1-A7aW71ao_yQHb">yaml</a></span><span>) </span><span class="c0">called just &ldquo;fullness&rdquo;.</span></h6><p class="c1"><span class="c0">&ldquo;this isn&#39;t called fullness.ckpt for nothing.&rdquo; - Musicalman</span></p><p class="c1"><span>Inst. fullness: 37.66, bleedless: 35.53, SDR: 15.91 (thx Essid)</span></p><h6 class="c1 c27 c7" id="h.q4dthnouyd3f"><span class="c0"></span></h6><h6 class="c1 c27" id="h.l99gh5y9d8hk"><span class="c0">- (MVSEP) &ldquo;We added 2 new algorithms for Acoustic Guitar (based on BS Roformer) and for Flute (based on SCNet XL)</span></h6><h6 class="c1 c27 c7" id="h.9tzehwrd1jr8"><span class="c0"></span></h6><h6 class="c1 c27" id="h.lujqdbups9tu"><span>1) `MVSep Acoustic Guitar (acoustic-guitar, other)` Example: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250825095613-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741886272&amp;usg=AOvVaw383hblrOTl53D22aVg0xHO">https://mvsep.com/result/20250825095613-f0bb276157-mixture.wav</a></span><span class="c0">&rdquo;</span></h6><p class="c1"><span class="c0">&ldquo;excellent, it&#39;s separating acoustic from electric very well, even in fuzzy, lo-fi recordings&rdquo; &nbsp;- Input Output (A5)</span></p><p class="c1"><span class="c0">&ldquo;outperforms moises&#39; model like crazy&rdquo; - Sausum</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.87yzv33d0mo4"><span>&ldquo;</span><span>2) `MVSep Flute (fulte, other)` Example: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250825095856-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741887162&amp;usg=AOvVaw271ES7J9wGbR12zHDR3CvI">https://mvsep.com/result/20250825095856-f0bb276157-mixture.wav</a></span><span class="c0">&rdquo; - ZFTurbo</span></h6><p class="c1"><span>&ldquo;I tried the fulte model on stairway to heaven and it was so disappointing&rdquo; - santilli_</span></p><h6 class="c1 c27 c7" id="h.jspq2a2fujkl"><span class="c0"></span></h6><h6 class="c1 c27" id="h.tmismilaoyo3"><span class="c0">- We have the first lucky person on the server who succeeded to actually use the new NVIDIA&rsquo;s upscaler, and their messy AF code on Windows using Docker.</span></h6><p class="c1"><span class="c0">The output is mono, so you need to process each channel manually.</span></p><p class="c1"><span>Also, it&#39;s extremely slow, even on 4070 Super, but results are &ldquo;impressive&rdquo;. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/814405660325969942/1409223906828750878&amp;sa=D&amp;source=editors&amp;ust=1765035741888190&amp;usg=AOvVaw0XK7Obx8mgdQyxOm4JFqC9">More</a></span><span>&nbsp;(don&#39;t expect step-by-step tutorial for now because the guy is &ldquo;not tech support&rdquo;).</span></p><h6 class="c1 c27 c7" id="h.sogszr4dsf0a"><span class="c0"></span></h6><h6 class="c1 c27" id="h.hjuoj68tot6v"><span>- Unwa released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Inst-FNO&amp;sa=D&amp;source=editors&amp;ust=1765035741888605&amp;usg=AOvVaw1B9iKc7P84FvTfPmGmDpb5">BS-Roformer-Inst-FNO</a></span><span>&nbsp;model (incompatible with UVR, use </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span>&nbsp;and read special model installation instruction below</span><span class="c0">).</span></h6><p class="c1"><span class="c0">inst. bleedless: 42.87, fullness: 32.03, SDR: 17.60</span></p><p class="c1"><span class="c0">&ldquo;very small amount of noise compared to other fullness inst models, while keeping enough fullness IMO. I don&#39;t even know if phase fix is needed. Maybe it&#39;s still needed a little bit.&rdquo; dca</span></p><p class="c1"><span class="c0">&ldquo;seems less full than reserection, which I would expect given the MVSEP [metric] results. (...) I&#39;d say it&#39;s roughly comparable to gabox inst v7&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;I replaced the MLP of the BS-Roformer mask estimator with FNO1d [Fourier Neural Operator], froze everything except the mask estimator, and trained it, which yielded good results. (...) While MLP is a universal function approximator, FNO learns mappings (operators) on function spaces.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;(The base weight is Resurrection Inst)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Installing the model - instructions</span><span class="c0">:<br>1. &ldquo;I had many errors with torch.load and load_state_dict, but I managed to solve them. <br>PyTorch 2.6 and later have improved security when loading checkpoints, which causes the problem. torch._C_.nn.gelu must be set to exception&rdquo;<br>&gt; &ldquo;Add the following line above torch.load (at utils/model_utils.py line 479; 531/532 in updated MSST):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">with torch.serialization.safe_globals([torch._C._nn.gelu])</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp;- unwa, or:</span></p><p class="c1"><span class="c0">1*. Or use PyTorch older than 2.6.</span></p><p class="c1"><span>2. Read the linked </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Inst-FNO&amp;sa=D&amp;source=editors&amp;ust=1765035741891711&amp;usg=AOvVaw36XBsw8s6qC4zv8nebO7UE">model card</a></span><span class="c0">. &ldquo;You need to replace the entire &quot;MaskEstimator&quot; class in original bs_roformer.py from ZFTurbo (in models/bs_roformer folder) with the code provided by unwa [indention error fixed]. </span></p><p class="c1"><span>3. And probably install this lib </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pypi.org/project/neuraloperator/&amp;sa=D&amp;source=editors&amp;ust=1765035741892273&amp;usg=AOvVaw1JujnZiL8KqdJkv_K4JN5u">https://pypi.org/project/neuraloperator/</a></span><span class="c0">&rdquo; so: </span></p><p class="c1"><span class="c0">&ldquo;pip install neuraloperator&rdquo;.</span></p><p class="c1"><span>*. Use this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1SeCG31kz6yDa2A9gPS0YVfOGM-lAdYt7/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741892574&amp;usg=AOvVaw1GFrr3OslZrs9-QtRUWMlz">models_utils.py</a></span><span class="c0">&nbsp;if still nothing (neoculture)<br></span></p><p class="c1"><span>4*. Seems like </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span class="c0">&nbsp;might have some issues with GPUs other than corresponding archs to RTX 5000, 4000, 3000, H100, H200 or maybe using ROCm, resulting in SageAttention error, forcing slower CPU separation. </span></p><p class="c1"><span class="c0">In that case, ensure you have compatible CUDA/torch/torchvision/torchaudio installed: </span></p><p class="c1"><span class="c0">Compatible CUDA version requirement for GTX 1660 is 10 (e.g. on GTX 1060, Torch 2.5.1+cu121 can be used), but pip doesn&rsquo;t find such package of Torch. To fix it:</span></p><p class="c1"><span class="c0">*a) Check out index-url method described below:</span></p><p class="c1"><span class="c0">pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span class="c0">pip install torch==2.3.0+cu118 torchvision torchaudio &mdash;-extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span class="c0">pip install torch==2.3.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">and</span></p><p class="c1"><span class="c0">pip install torchaudio==2.3.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">Replacing cu118 with newer cu121 or even 129 seems to give proper working URL too. </span></p><p class="c1"><span class="c0">Maybe replacing 2.3.0 with 2.3.1 will work too.</span></p><p class="c1"><span>*a2) Alternatively, you can try to install it from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://download.pytorch.org/whl/torch_stable.html&amp;sa=D&amp;source=editors&amp;ust=1765035741894911&amp;usg=AOvVaw3SfnrmVy8ZmB7OAIl1zeOO">here</a></span><span class="c0">&nbsp;from wheels by the following command:</span></p><p class="c1"><span class="c0">&ldquo;pip install SomePackage-1.0-py2.py3-none-any.whl&rdquo; - providing full path with the file name should do the trick. Just for the location with spaces, you also need &quot; &quot;. </span></p><p class="c1"><span class="c0">On GTX 1660 and Turing GPUs, you might seek for e.g. cu121/torch-2.3.1&quot; and those various CP wheels (there are no newer versions).</span></p><p class="c1"><span>JFYI, the official PyTorch page: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pytorch.org/get-started/previous-versions/&amp;sa=D&amp;source=editors&amp;ust=1765035741895924&amp;usg=AOvVaw384exZEVl1LSeVlJ4LouJG">https://pytorch.org/get-started/previous-versions/</a></span></p><p class="c1"><span class="c0">lacks links for CUDA 10 compatible versions for older GPUs other than v1.12.1 (which is pretty old, and might be a bit slower if even compatible at all), so the only way to install newer versions for CUDA 10 is the --extra-index-url trick, as executing normally &ldquo;pip install torch==2.3.0+cu118&rdquo; will end up with the version not found error.</span></p><p class="c1"><span class="c0">*b) You might still have SageAttention not found error. Perform the following:</span></p><p class="c1"><span class="c0">&ldquo;Had to replace cufft64_10.dll from C:\Users\user\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\lib </span></p><p class="c1"><span class="c0">by the one from C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin&rdquo;</span></p><p class="c1"><span class="c0">It is even compatible with the newest Torch 2.8.0 (if you followed the instruction to fix the dict issue above) if you grab that apparently &ldquo; fixed version of cufft64_10.dll from CUDA v10.0&rdquo; - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I guess it&#39;s possible to use it with the Colab inference custom model one, you run install cell, install the neuralop thing with &quot;!pip&quot; in a cell code (on Colab, system command needs the &quot;!&quot; before them), then edit the existing Roformer code accordingly to unwa&#39;s guidelines on his repo&rdquo; - jarredou</span></p><p class="c1"><span>If you want to train with FNO1d or Conformer, you might check out this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/dillfrescott/mvsep-beta/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741898107&amp;usg=AOvVaw0gSYgWuBBdBEIKckNFWsuk">repo</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Turns out Duality model is very good for pops and clicks of 45 RPM vinyl, moving them to instrumental stem (bratmix)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Google broke installing dependencies in many Colabs.</span></p><p class="c1"><span>For the inference Colab by jarredou, see </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1310358701831487508/1407544876026957966&amp;sa=D&amp;source=editors&amp;ust=1765035741898732&amp;usg=AOvVaw0EPIrTYEEUvWYvzO-OBzMv">here</a></span><span class="c0">&nbsp;for troubleshooting (pushed the changes - not tested, might be useful for other Colabs; fixed).</span></p><p class="c1"><span>In the case of AudioSR, use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/Nick088/Audio-SR&amp;sa=D&amp;source=editors&amp;ust=1765035741899048&amp;usg=AOvVaw1suqjUbDshjk80KXcz8on7">huggingface</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- NVIDIA released their own audio upscaler, with also an ability of inpainting (so it can fill short silences between damaged segments of audio).</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/NVIDIA/diffusion-audio-restoration&amp;sa=D&amp;source=editors&amp;ust=1765035741899518&amp;usg=AOvVaw3CwnHKDH_tb4RyXdHR_TUA">https://github.com/NVIDIA/diffusion-audio-restoration</a></span></p><p class="c1"><span class="c0">But maybe don&rsquo;t try it out the upscaler just yet, as the code is currently so messy and difficult to deploy e.g. on MacOS, that it took 9 hours for two of our users, and they still didn&#39;t succeed even with help of AI chats. And to make it work on Colab, the code needs to be completely rewritten, jarredou says.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- mesk released a beta version of his metal Mel-Roformer fine-tune instrumental model called &ldquo;Rifforge&rdquo; focused more on bleedless.</span></p><p class="c1"><span>&ldquo;training is still in progress, that&#39;s why it&#39;s a beta test of the model; It should work fine for a lot of things, but it HAS quirks on some tracks + to me there&#39;s some vocal stuff still audible on some tracks, I&#39;m mostly trying to get feedback on how I could improve it&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1405719212592464003&amp;sa=D&amp;source=editors&amp;ust=1765035741900902&amp;usg=AOvVaw0effCM0RncuMnEXyM3tAmj">known issues</a></span><span class="c0">.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.proton.me/urls/5XM3PR1M7G%23F3UhCU8RDGhX&amp;sa=D&amp;source=editors&amp;ust=1765035741901120&amp;usg=AOvVaw05CpKTrWLJmiuLpzQzeUUl">https://drive.proton.me/urls/5XM3PR1M7G#F3UhCU8RDGhX</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Custom model import Colab might have currently some issues with the model above. Probably, using that old version will work (at least locally).</span></p><p class="c1"><span class="c0">&quot;My old MSST repo I&#39;m using, but I removed all the training stuff</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.proton.me/urls/P530GFQR4W%23VCAsF0E1TPje&amp;sa=D&amp;source=editors&amp;ust=1765035741901745&amp;usg=AOvVaw3Wln-jnz5yBc0TwUGHNqxt">https://drive.proton.me/urls/P530GFQR4W#VCAsF0E1TPje</a></span></p><p class="c1"><span class="c0">pip install -r requirements.txt (u gotta have Python and PyTorch installed as well) for the script to work.</span></p><p class="c1"><span class="c0">You just gotta put all the tracks you want to test on in the **&quot;tracks&quot;** folder then double-click on **&quot;inference.bat&quot;** to run the inference script</span></p><p class="c1"><span class="c0">it&#39;s like if you were to type in the command in cmd, but it&#39;s simpler, and I&#39;m lazy&quot; - mesk</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Shared bias added during weight conversion was removed from the SW model, making it compatible with UVR and normal MSST repo code (it was just a leftover not doing anything, just zeroes). Also, delete the shared bias line from the yaml.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, it was possible to trim the model size to have only vocals (although it probably can be achievable quicker in the config). mask_estimators.0 is responsible for vocals (each mask estimator is responsible for other stem).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The new violin model on MVSEP sometimes does better than the strings model for strings (dynamic64)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aufr33&rsquo;s Mel-Roformer Denoise average variant (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/vM4mHTYQ%23f_uCxxS_olfTR4iAsOc-XS6sfUecfbF-ZKXrk3IjbnY&amp;sa=D&amp;source=editors&amp;ust=1765035741903644&amp;usg=AOvVaw1QWmu8X6G8J8ZgTyz9dpOh">link</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1uwInhwgjOMIdOMTgj_oNR_dmaq7E-b3g/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741903773&amp;usg=AOvVaw32bf8ZkEyNED3WphiXAxkX">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741903957&amp;usg=AOvVaw3-ISb1NbTQNKw-HKSZ3l5S">Colab</a></span><span>)</span><span class="c0">&nbsp;can be also used for crowd removal (Gabox)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;I released new MVSep Violin (violin, other). It based on BS Roformer model with SDR: 7.29 for violin on my internal validation.</span></p><p class="c1"><span>Link: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/home?sep_type%3D65&amp;sa=D&amp;source=editors&amp;ust=1765035741904491&amp;usg=AOvVaw1xAUn35McZ2idtTuDBhT_Q">https://mvsep.com/home?sep_type=65</a></span></p><p class="c1"><span>Example: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250809120109-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035741904737&amp;usg=AOvVaw3VTJUSsDhyVBfezm7zGpZs">https://mvsep.com/result/20250809120109-f0bb276157-mixture.wav</a></span><span>&rdquo;</span><span class="c0">- ZFTurbo</span></p><p class="c1"><span class="c0">&ldquo;I&#39;ve only played around with it a little bit, but it can even separate violin quartets from cellos, so cool.&rdquo; - smilewasfound</span></p><p class="c1"><span class="c0">&ldquo;Very neat model. (...) Sometimes the model does seem to pick up more than just violins imo, but yeah for separating high strings in particular it is really cool.&rdquo; - Musicalman</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSEP now has also official YouTube channel:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/@MVSEP&amp;sa=D&amp;source=editors&amp;ust=1765035741905575&amp;usg=AOvVaw0DqBH16ug1xT-KDXEjeUkO">https://www.youtube.com/@MVSEP</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Issues with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035741905827&amp;usg=AOvVaw1W14th9NIOTVcGiHYW_Ioo">https://huggingface.co/spaces/TheStinger/UVR5_UI</a></span><span class="c0">&nbsp;have been fixed.</span></p><p class="c1"><span>Mirror is still functional: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035741906104&amp;usg=AOvVaw3s-SN_bUp7vOt0guMimxJh">https://huggingface.co/spaces/qtzmusic/UVR5_UI</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa BS-Roformer Resurrection instrumental model added on MVSEP and on uvronline with these links for </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035741906457&amp;usg=AOvVaw3nZhKIkQubTHlqAOcYqRtx">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035741906539&amp;usg=AOvVaw0ppJkaE10bA9C8negRT81O">premium</a></span><span>&nbsp;accounts.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released experimental voc_fv6 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_fv6.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741906828&amp;usg=AOvVaw0qcBrcCWg7aFbZ7lRw8VtK">model </a></span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741906967&amp;usg=AOvVaw149-gIdsaMIFLklHmgA8Wn">yaml</a></span></p><p class="c1"><span class="c0">&ldquo;Sounds like b5e with vocal enhancer. Needs more training, some instruments are confused as vocals&rdquo; - Gabox. &ldquo;fv6 = fv4 but with better background vocal capture&rdquo; - neoculture</span></p><p class="c1"><span class="c0">bleedless: 26.61 | fullness: 24.93 | SDR: 10.64</span></p><p class="c1"><span class="c0">For comparison:<br>SCNet XL very high fuillness on MVSEP has followin metrics:</span></p><p class="c1"><span>Vocals bleedless: 25.30, fullness: 23.50, SDR: 10.40</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- yt-dlp and their frontenteds like cobalt.tools are currently defunct. It might affect some Colabs YT downloading features, although JDownloader 2 still works.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The below model added on x-minus/uvronline</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035741908326&amp;usg=AOvVaw1SfSJioFq-eCSTwUiSFXq2">https://uvronline.app/ai?discordtest</a></span><span class="c0">&nbsp;- free accounts</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035741908514&amp;usg=AOvVaw2kOrYlUuR8asD3k9ZxMUwM">https://uvronline.app/ai?hp&amp;test</a></span><span class="c0">&nbsp;- premium accounts</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released a new BS-Roformer Resurrection instrumental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741908850&amp;usg=AOvVaw0hoGNi5lSVHKQfKoCuj0_N">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741909018&amp;usg=AOvVaw0eOPtJUBSuDepdy_n4fAR2">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741909205&amp;usg=AOvVaw3v2D73NoprChHhwyIheQD3">Colab</a></span><span>&nbsp;</span></p><p class="c1"><span class="c0">SDR: 17.25, bleedless: 40.14, fullness: 34.93</span></p><p class="c1"><span class="c0">Compatible with UVR (model type v1). &ldquo;Fast model to inference (204 MB only)&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;One of my favorite fullness inst models ATM. Sounds like v1e to me, but cleaner. Especially with guitar/piano where v1e tended to add more phase distortion, I guess that&#39;s what you&#39;d call it lol. This model preserves their purity better IMO&rdquo; - Musicalman</span></p><p class="c1"><span class="c0">&ldquo;the way it sounds, is indeed the best fullness model, it&#39;s like between v1e and v1e+, so not so noisy and full enough, though it creates problems with instruments gone in the instrumental sadly, but apparently it seems Roformer inst models will always have problems with instruments it seems, seems like a rule. (...) Instrument preservation (...) is between v1e and v1e+ (...) Fixes crossbleeding of vocals in instrumental in a lot of songs, compared to previous models (...) No robotic voice bug at silent instrumental moments&rdquo; - dca100fb8</span></p><p class="c1"><span class="c0">&ldquo;Some songs leaves vocal residue. It is heard little but felt&rdquo; - Fabio</span></p><p class="c1"><span class="c0">&ldquo;Almost loses some sounds that v1e+ picks up just fine&rdquo; - neoculture</span></p><p class="c1"><span class="c0">Mushes some synths a bit in e.g. trap/drill tune compared to inst Mel-Roformers like INSTV7/Becruily/FVX/inst3, but the residues/vocal shells are a bit quieter, although the clarity is also decreased a bit. Kind of a trade.</span></p><p class="c1"><span class="c0">So far, none models work for phase fixer/swapper besides 1296/1297 by viperx and unwa BS Large V1 to alleviate the remaining noise. ~ dca. SW model not tested.</span></p><p class="c1"><span class="c0">Less crossbleeding than paid Dango 11.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Gabox released a bunch of new models:</span></p><p class="c1"><span>a) Gabox Inst_ExperimentalV1 model |</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741912313&amp;usg=AOvVaw2fTYnNDIb2PIj8d4Kp8YQU">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741912491&amp;usg=AOvVaw1SC5ZCKW74gBYkQmCxZiSJ">yaml</a></span></p><p class="c1"><span class="c4"><br></span><span>b) </span><span>Gabox Kar v2 Mel-Roformer |</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Karaoke_GaboxV2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741912767&amp;usg=AOvVaw3UC_EUfxWfTf_maeh5cLHC">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Karaoke_GaboxV2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741912891&amp;usg=AOvVaw0Pjap9Rg-ZqvCGMjm15CTp">model</a></span><span>&nbsp;|</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/karaoke/karaokegabox_1750911344.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741913022&amp;usg=AOvVaw2TjmbkIiS81t5t4o5RwzAE">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/karaoke/karaokegabox_1750911344.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741913142&amp;usg=AOvVaw0qJqBK1JZIy10aW-iS4RNY">yaml</a></span></p><p class="c1"><span class="c0">SDR is very similar with the v1 Gabox model: 9.7699 vs 9.7661.</span></p><p class="c1"><span class="c0">Lead:</span></p><p class="c1"><span>bleedless: 27.58 </span><span>vs 28.18, fullness: 15.24 vs 14.79</span><span><br>Back-instrum:<br>bleedless: 50.67 vs 50.74, fullness: 32.46 vs 32.84</span></p><p class="c1"><span class="c0">(but you&rsquo;ll most likely get better results with Gabox denoise/debleed Mel-Roformer model instead ~Gabox, but it can&rsquo;t remove vocal residues</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/denoisedebleed.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741914206&amp;usg=AOvVaw2c3l6WqKG8O1297R8mx4sQ">model</a></span><span>&nbsp;|</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741914365&amp;usg=AOvVaw1bSCZdvEa5GcWVAAR4SDNb">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741914483&amp;usg=AOvVaw2F_mKrQreCjfxtCF_0V16f">yaml</a></span><span>&nbsp;|</span><span><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035741914613&amp;usg=AOvVaw2Tei2e02qEqSL2L0WcI7zO">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035741914754&amp;usg=AOvVaw1-xpnpgVGyuvPBjRB44p-2">Colab</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>c) Gabox Lead Vocal De-Reverb Mel-Roformer |</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Lead_VocalDereverb.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741915145&amp;usg=AOvVaw3SAtTbvORziop161ZHkWM7">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Lead_VocalDereverb.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741915301&amp;usg=AOvVaw1ysYJMcPpba_uYv1-a6vlN">DL</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/karaoke/karaokegabox_1750911344.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741915473&amp;usg=AOvVaw2T1Tv_Zzn-HOY2vDn7S2tz">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741915663&amp;usg=AOvVaw1wKILnMuSqzNBiit2RKWLg">Colab</a></span></p><p class="c1"><span class="c0">&ldquo;just use it on the mixture&rdquo; - Gabox, &ldquo;sounds great&rdquo; - Rage313</span></p><p class="c1"><span class="c0">Sometimes removes back vocals, especially if they&#39;re panned to the sides.</span></p><p class="c1"><span class="c0">&ldquo;(...) also a vocal/inst separator. Dry vocals go in vocal stem, everything else goes to reverb. Don&#39;t think anvuew&#39;s models do that.</span></p><p class="c1"><span class="c0">I might still preprocess with vocal isolation before dereverb. But only really worth it if you&#39;re after high fullness vocals.&rdquo; - Musicalman</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Issues with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035741916737&amp;usg=AOvVaw1XuiELQ6CALcJobtFExAaS">https://huggingface.co/spaces/TheStinger/UVR5_UI</a></span><span class="c0">&nbsp;occur.</span></p><p class="c1"><span class="c0">&ldquo;We have a problem with Zero GPU atm, waiting for a fix from HF staff</span></p><p class="c1"><span class="c0">isn&#39;t related to the code or last commit&rdquo; - Not Eddy</span></p><p class="c1"><span>Meanwhile, you can use: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035741917249&amp;usg=AOvVaw3DwAYf9_Fj3h_3HJ5Jyr6h">https://huggingface.co/spaces/qtzmusic/UVR5_UI</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) Now 32-bit float for WAV will be used only if gain level falls outside 1.0 range to prevent clipping, otherwise 16 bit PCM will be used, when it won&#39;t occur. If you really need it anyway, 32-bit float output for all files unconditionally is available for paid users.</span></p><p class="c1"><span class="c0">If you have troubles with nulling due to the new changes in free version, consider decreasing volume of your mixtures by e.g. 3-5dB, and you won&rsquo;t be affected, although it might slightly affect separation results.</span></p><p class="c1"><span class="c0">Also, FLAC now uses 16-bit instead of 24-bit.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;Sometimes we have complaints on speed from different parts of the world. The best way is to use VPN to solve them.&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox&rsquo; voc_Fv5, Inst_GaboxFv7z, Unwa&rsquo;s voc Resurrection, voc_gabox2 and the new jarredou&rsquo;s drumsep 5 stem added to the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741919206&amp;usg=AOvVaw0wnam817gmAkye6Tjv4y9b">inference Colab</a></span><span>&nbsp;<br>(Resurrection [now with the config] and Fv7z fixed). Also, previously released anvuew&rsquo;s mono dereverb added.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you feel overwhelmed by this GDoc&rsquo;s list, isling released their own, shorter version with recommended models for audio separation - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/19A9Z32LgqTUdI7z0LUAoGXjm07BO-IkRNS_QNnUxaYA/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741920043&amp;usg=AOvVaw1XlxqPrm6zS4PrN_yKdIEX">click</a></span><span class="c0">.</span></p><p class="c1"><span><br>- Also, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1tSOkau6iZ8DxenKs8ZD-7gmgEc5GaXuOSfl9ULioCcs/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741920248&amp;usg=AOvVaw1_cJcQanVWoVTnyXDfxS1g">here</a></span><span>&nbsp;you&rsquo;ll find an excerpt of the current document with only models and their links, if you find it hard to navigate through the whole document (edit. 24.07.25)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) BS-Roformer 2025.06 described previously below received two updates (11.81 -&gt; 11.86 and 11.86&gt;11.89) and it has been changed to: </span></p><p class="c1"><span>BS-Roformer 2025.07. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8693&amp;sa=D&amp;source=editors&amp;ust=1765035741921042&amp;usg=AOvVaw2imtH7dVoeS-W6YFNpitSW">Full metrics</a></span><span class="c0">.<br>&ldquo;All Ensembles and models where this model is involved improved a little bit too.&rdquo; - ZFTurbo</span></p><p class="c1"><span class="c0">MVSEP Multichannel BS feature started using 11.81 model at some point, now sure if now uses 11.89.</span></p><p class="c1"><span>If you tried achieving results any similar to BS-Roformer 2025.07, you could potentially try out </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/undef13/splifft/releases&amp;sa=D&amp;source=editors&amp;ust=1765035741921858&amp;usg=AOvVaw0M3UYhveMdlh-6Qn0oCP3I">splifft</a></span><span>&nbsp;or its </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Colab_Inference_BSRofo_SW_fp16.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741922051&amp;usg=AOvVaw1zf-UZk99LG8ZK-VneNn75">Colab</a></span><span>. If you fail to use Spliff check the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1ee9HBdwygactWLi_7hdZiFgFNv45Y22m&amp;sa=D&amp;source=editors&amp;ust=1765035741922266&amp;usg=AOvVaw2WBK_IiyJ1suaSFBhvc8GG">model</a></span><span>&nbsp;before conversion on MSST repo (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1mHbBZGcjXHwVfV5hxfyLY2d6ZhaZofkB/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741922585&amp;usg=AOvVaw0VeyIcNFK0GmjrcVKMEMGj">more</a></span><span>)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) Gabox INSTV7 instrumental model added </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) MelBand Karaoke (lead/back vocals) Gabox model added (SDR: 9.67)</span></p><p class="c1"><span class="c0">- Fused model of Gabox and Aufr33/viperx weights 0.5 + 0.5 added (SDR: 9.85)<br>It gives maybe only slightly worse results than normal ensembling, but with separation time of just one model &ldquo;it doesn&#39;t have the same quality and definition as Gabox Karaoke, fused doesn&#39;t separate well.&rdquo; - Billie O&rsquo;Connell.</span></p><p class="c1"><span>You can perform fusion of models using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/18E5uTSVJV6rn8gTsOc0RC1m12lJFJGmP/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741923822&amp;usg=AOvVaw0VJRDONjSh4xcFuxebq9Mf">ZFTurbo script</a></span><span class="c28">(</span><span class="c4 c28"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1220364005034561628/1386610707042271243&amp;sa=D&amp;source=editors&amp;ust=1765035741923971&amp;usg=AOvVaw0HLvL21ghdk0ueWeetAAby">src</a></span><span class="c28">)</span><span>&nbsp;or by </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer/blob/main/scripts/model_fusion.py&amp;sa=D&amp;source=editors&amp;ust=1765035741924157&amp;usg=AOvVaw34TcB65oaRHKmhXIiAwS8l">Sucial script</a></span><span class="c0">&nbsp;(they&rsquo;re similar if not the same). &ldquo;I think the models need to have at least the same dim and depth but I&#39;m not sure about that&rdquo; - mesk.</span></p><p class="c1"><span>Despite the higher SDR, the fusion model seems to confuse lead/back vocals more.<br>- The same goes to public Karaoke fusion models released by Gonzaluigi </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-3094728853&amp;sa=D&amp;source=editors&amp;ust=1765035741924763&amp;usg=AOvVaw1D0zaLFhKk6Sp2cUVjHypB">here</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_gabox2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741925059&amp;usg=AOvVaw2OiZXi7VttD9LOl7KYZLwb">voc_gabox2</a></span><span>&nbsp;vocal model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741925222&amp;usg=AOvVaw3_wMIh_MENCaOJvea3iIkf">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741925420&amp;usg=AOvVaw0cv39WfzH4E5mJw0ih96Cl">Colab</a></span></p><p class="c1"><span>Vocal bleedless: 33.13, fullness: 18.98, SDR: 10.98</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released a BS-Roformer vocal model called &quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/resolve/main/BS-Roformer-Resurrection.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741925864&amp;usg=AOvVaw0V5r-JL-ThHuyemsjheBb3">Resurrection</a></span><span>&quot; | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/resolve/main/BS-Roformer-Resurrection-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741926078&amp;usg=AOvVaw26DNJqLzVOBAzJaNQuPyIt">yaml</a></span><span class="c0">&nbsp;which shares some similarities with the SW model (might be a retrain). The default chunk_size is pretty big, so if you run out of memory, decrease it to e.g. 523776.</span></p><p class="c1"><span class="c0">Vocal bleedless: 39.99, fullness: 15.14, SDR: 11.34.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Omg, this model is doing a really good job at capturing backing vocals (...)</span></p><p class="c1"><span class="c0">Honestly, it sounds a bit muddy, and there&#39;s some instrumental bleeding into the vocal stems&quot; neoculture</span></p><p class="c1"><span class="c0">Not so good for speech denoising unlike some other models (Musicalman).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- mesk&rsquo;s training guide updated and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1jUcwiPfrJ8CpHqXIRHuOu70cFDMv_n-UzW53iaFuM9w/edit&amp;sa=D&amp;source=editors&amp;ust=1765035741927425&amp;usg=AOvVaw0oou2tQp4dYTB86_F6VDzD">link</a></span><span>&nbsp;</span><span class="c0">changed</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) New All-in and 5 stem ensembles have been added for paid users </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- AudioSR WebUI </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9CjxMDyYnggKKQBPpGLufuVzt_yJJrL&amp;sa=D&amp;source=editors&amp;ust=1765035741927939&amp;usg=AOvVaw1FvsVsBIRRX0A1PUfaO88Z">Colab</a></span><span>&nbsp;</span><span class="c0">by Sir Joseph got fixed</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Ensemble 11.93 (vocals, instrum) (2025.06.28) added.<br>Eventually surpassed sami-bytedance-v.1.1 on the multisong dataset SDR-wise.</span></p><p class="c1"><span class="c0">Instrumental bleedless: 47.65, fullness: 28.76, SDR: 18.24</span></p><p class="c1"><span class="c0">Vocal bleedless: 36.30, fullness: 17.73, SDR: 11.93</span></p><p class="c1"><span class="c0">- corrected typos in the metrics (thx yakomotoo)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) MultiChannel now uses 11.81 BS Roformer model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) New BS Roformer model is now available on site - it&rsquo;s called 2025.06 (don&rsquo;t confuse it with SW).</span></p><p class="c1"><span class="c0">Vocals bleedless: 48.59, fullness: 27.85, SDR: 11.82</span></p><p class="c1"><span class="c0">Instrumental bleedless: 37.83, fullness: 17.30, SDR: 18.12</span></p><p class="c1"><span class="c0">&ldquo;It has +0.5 SDR to the previous best [24.08] model. We reached ByteDance&#39;s best model quality [only 0.1 SDR difference). It is also TOP1 on the Synth dataset. It&#39;s balanced between both [instrumental and vocals]. I used metal dataset during training as well&quot; </span></p><p class="c1"><span class="c0">Compared to previous models, picks up backing vocals and vocal chops greatly where 6X struggles, and fixes crossbleeding and reverbs where in some songs previous models struggled before. Sometimes you might still get better results with Beta 6X or voc_fv4 (depending on a song). &ldquo;Very similar to SCNet very high fullness without the crazy noise&rdquo; - dynamic64, &ldquo;handles speech very well. Most models get confused by stuff like birds churping (they put it in the vocal stem), but this model keeps them out of the vocal stem way more than most. I love it!&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;not a fan of the inst result. I feel like unwa and gabox sound better despite being less accurate&rdquo; - dynamic64. Might be better than Fv7n &ldquo;I think gabox tends to sound better but the new BS-Roformer is more accurate&rdquo; dynamic64, &ldquo;instrumentals are muddy&rdquo; - santilli_,</span></p><p class="c1"><span class="c0">&ldquo;I think the Gabox [fv7n] model sounded more crispier than BS&rdquo; - REYYY. &ldquo;[voc_]fv4 sounds better&rdquo; - neoculture, &ldquo;instrumentals sound very good&rdquo; - GameAgainPL.</span></p><p class="c1"><span class="c0">&ldquo;it did things i never thought it could before&rdquo; &ldquo;this model is insane wtf (...) never seen a model accurately do the ayahuasca experience before&rdquo; - mesk. </span></p><p class="c1"><span class="c0">&nbsp;&ldquo;the first model to not produce vocal bleed in instrumental for &quot;Supersonic&quot; by Jamiroquai (not even Dango does it). It is also the case with &quot;Samsam (Chanson du g&eacute;n&eacute;rique)&quot; and &quot;Porcelain&quot; by Moby.&rdquo; and &quot;In the Air Tonight&quot; by Phil Collins, also &ldquo;removes very most of Daft Punk vocoder vocals&quot; - dca. &ldquo;my new favorite for vocals. It sounds fantastic&rdquo; - dynamics64. &ldquo;for the first time ever it managed to remove the reverb from one specific song. it is not perfect, but still much better than previous attempts&rdquo; - santilli_</span></p><p class="c1"><span class="c0">&ldquo;It even seems to handle speech very well. Most models get confused by stuff like birds churping (they put it in the vocal stem), but this model keeps them out of the vocal stem way more than most. I love it!&rdquo;. &ldquo;sometimes 6x is better sometimes bs is better&rdquo; - isling &ldquo;for me it&#39;s picked up a lot that 6x hadn&#39;t for backing vocals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Using this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/RyanMetcalfeInt8/Music-Source-Separation-Training/tree/openvino_conversion/openvino_conversion&amp;sa=D&amp;source=editors&amp;ust=1765035741933943&amp;usg=AOvVaw0aySsFLRR4b73q1dLb3fKR">repo</a></span><span class="c0">, you can convert Mel-Roformers, HTDemucs and Apollo models to OpenVINO (so to onnx)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Lew, if you read it, some guy wants to add your Apollo uni model into a plugin for OpenVINO and Intel&rsquo;s HF, but the model lacks an open source licence. If you could re-release it with the proper licence, it would be appreciated. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/intel/openvino-plugins-ai-audacity/discussions/356%23discussioncomment-13600033&amp;sa=D&amp;source=editors&amp;ust=1765035741934771&amp;usg=AOvVaw2xE0geTgRYyZZZhcnWJ0pC">More</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus/uvronline) &ldquo;I added two new models to remove vocals and hid a few old ones.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So there are now only three main models in the menu for different purposes:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Mel-RoFormer by Gabox Fv7z - best bleedless, good fullness, almost noiseless</span></p><p class="c1"><span class="c0">Mel-RoFormer by unwa v1e+ - best fullness, average bleedless</span></p><p class="c1"><span class="c0">Mel-RoFormer unwa big beta6x - best vocals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older models are still available at the link: </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035741936215&amp;usg=AOvVaw38CaQhN72K4eiDYkwGS9HC">https://uvronline.app/ai?hp&amp;test</a></span><span>&nbsp;</span><span class="c0">(premium)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?test&amp;sa=D&amp;source=editors&amp;ust=1765035741936469&amp;usg=AOvVaw33C04cmVCVaP4F1iNMu-Dx">https://uvronline.app/ai?test</a></span><span>&nbsp;</span><span class="c0">(free)&rdquo; - Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Oh! Lead vocal panning has been added for Mel Kar Old! (...)</span></p><p class="c1"><span class="c0">Along with MDX Kar old and UVR Kar old to the test page!!&rdquo; - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released a new experimental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/karaoke&amp;sa=D&amp;source=editors&amp;ust=1765035741937384&amp;usg=AOvVaw1CsLMgXARR3fkeD-IqCNYU">Karaoke model</a></span><span>.</span><span class="c0">&nbsp;It&rsquo;s one stem target so keep extract_instrumental enabled for the rest stem.</span></p><p class="c1"><span class="c0">&ldquo;really hard to tell the difference between this and becruily&#39;s karaoke model&rdquo; minus the latter has more target stems.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- jarredou released his new MDX23C drumsep 5 stem model, which is public for everyone to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/models/releases/tag/DrumSep&amp;sa=D&amp;source=editors&amp;ust=1765035741938089&amp;usg=AOvVaw35qzSqNFTg9rlEd7fDq2PH">download</a></span><span class="c0">. All SDR metrics are better than the previous model (&ldquo;on kick/snare/toms it&#39;s around +2 SDR better than previous version&rdquo;):</span></p><p class="c1"><span>SDR: kick: 16.66, snare: 11.54, toms 12.34, hihat: 4.04, cymbals: 6.36 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8460&amp;sa=D&amp;source=editors&amp;ust=1765035741938618&amp;usg=AOvVaw38q_viPiKQDqPSyXMD6Ukz">all metrics</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">Metric fullness for snare: 25.0361, bleedless for hh: 12.3470, log_wmse for snare: 13.8959</span></p><p class="c1"><span class="c0">&ldquo;Quite cleaner than the previous one&rdquo;, &ldquo;it&#39;s more on the fullness side than bleedless&rdquo;, </span></p><p class="c1"><span class="c0">From all the metrics, only bleedless for snare is worse than in the previous model: <br>26.8420 vs 30.4149 and indeed &ldquo;snare has a bit of bleed sometimes&rdquo; - isling, &ldquo;as well as cymbals bleed in hi hat track, but the stems sound clean&rdquo; - dca.</span></p><p class="c1"><span class="c0">&ldquo;a lot noisier than other drumpsep models, but that&#39;s not necessarily a bad thing.&rdquo;</span></p><p class="c1"><span>&ldquo;Surprisingly, it&#39;s the 2nd best model for hi hat and 2nd best model for cymbals on mvsep leaderboard. It&#39;s a bit biased because ZF&#39;s top mel model is 4 stem only.&rdquo;</span><span><br>For comparison, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8195&amp;sa=D&amp;source=editors&amp;ust=1765035741940216&amp;usg=AOvVaw15xA1_Px6ccyXcYcV7Aed6">metrics</a></span><span>&nbsp;of</span><span class="c0">&nbsp;the old 6 stem jarredou/Aufr33 MDX23C model </span></p><p class="c1"><span class="c0">(which has cymbals divided into ride and crash which are not evaluated):</span></p><p class="c1"><span class="c0">SDR: kick: 14.55, snare: 9.79, toms: 10.64, hihat: 3.20, cymbals: 6.08</span></p><p class="c1"><span class="c0">Metric fullness for snare: 25.0361, bleedless for hh: 10.2765, log_wmse for snare: 12.4258</span></p><p class="c1"><span class="c0">The model was trained with a lightweight config to train on a subpar T4 GPU on free Colabs and 10 accounts (&ldquo;CRAAZY fast&rdquo; for inferencing). The metrics do not surpass exclusive drumsep Mel-Roformer and SCNet models on MVSEP, but at least you can use this one locally.</span></p><p class="c1"><span class="c0">&ldquo;Most of the issues with my model are already known issues with mdx23c arch, it&#39;s bleedy and has band splitting artifacts. Like I said a few days ago, if I would have to redo it now, it would have probably gone with SCNet Masked. It&#39;s using 4x times lower n_fft resolution than InstVocHQ while using 2 times longer chunk_size (and with MDX23C, whatever number of stems, it&#39;s the same inference speed). A bit like the fruit&rsquo;s model is doing&rdquo;.<br>Trained on 511 tracks, MVSEP models were trained on almost the same dataset.</span></p><p class="c1"><span class="c0">Maybe if we separate just snare with the old MDX23C model from an already separated drums stem, and mix/invert to get the rest, then pass it through the new model, the bleed would be gone.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Remember that you need already separated </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">drums</a></span><span class="c0">&nbsp;in one track to use this model effectively.</span></p><p class="c1"><span class="c0">About used dataset: &ldquo;It was around 2/3 acoustic drums and 1/3 electro drums dataset at start of training, I&#39;ve added more electro drums at end of training to balance it a bit more.&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- septcoco released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/septcoco/macvsep/&amp;sa=D&amp;source=editors&amp;ust=1765035741943949&amp;usg=AOvVaw3kE_Aa2S_V-zdwNxo64Y2X">macvsep</a></span><span>&nbsp;which is &ldquo;macOS client for the Mvsep music separation API&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Added Clear Voice in </span><span class="c4"><a class="c3" href="#h.o6au7k9vcmk6">speech separation</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv7z.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741944702&amp;usg=AOvVaw20TXeVzRTnbLmVyX-KPlZI">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv7z.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741944862&amp;usg=AOvVaw35jGxKfDvLpUaRSIbE9JmT">Inst_GaboxFv7z</a></span><span>&nbsp;Mel Roformer |</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741945021&amp;usg=AOvVaw2DeEdFKs7PqnCp9P7BkE4H">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741945144&amp;usg=AOvVaw0FkGHoi5X25bBJ4BuJgLkP">yaml</a></span></p><p class="c1"><span>Inst. f</span><span class="c0">ullness: 29.38, bleedless: 44.95</span></p><p class="c1"><span class="c0">&ldquo;Focusing on the less amount of noise keeping fullness&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;The results were similar to INSTV7 but with less noise&rdquo; - neoculture</span></p><p class="c1"><span class="c0">Metrically better bleedless than Unwa v2 (although it&rsquo;s even more muddy), for comparison:</span></p><p class="c1"><span class="c0">Fullness: 31.85, bleedless: 41.73</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (MVSEP) &ldquo;I added a new SCNet vocal model. It&#39;s called SCNet XL IHF. It has a better SDR than previous versions. Very close to Roformers now&quot;.<br>Vocal bleedless is the best among all SCNet variants on MVSEP. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/2E9rI5G&amp;sa=D&amp;source=editors&amp;ust=1765035741946299&amp;usg=AOvVaw1BZtxspje6f2JVwQEl3eeB">Metrics</a></span><span class="c0">. <br>IHF stands for &ldquo;Improved high frequencies&rdquo;.</span></p><p class="c1"><span class="c0">Vocal bleedless 28.31, fullness 17.98</span></p><p class="c1"><span>&ldquo;certainly sounds better than classic SCNet XL (...) less crossbleeding of vocals in instrumental so far, and handle complex vocals better (...) problems with instruments, compared to high fullness one. XL high fullness remain the one without too many instruments cut&rdquo;, but some difficult songs used with previous models can yield better results - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Great news! MVSEP now allows sorting scores on the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?sort%3Dinstrum%26ranking_metrics%3Dfullness&amp;sa=D&amp;source=editors&amp;ust=1765035741947393&amp;usg=AOvVaw3OPal_MNsPB13yvgSYBRvC">Multisong Leaderboard</a></span><span>&nbsp;by SDR, fullness, bleedless, aura_stft, aura_mrstft, log_wmse, l1_freq, si_sdr.<br>Be aware that Gabox (and probably sometimes becruily) used to give funny names to their evaluations, so finding proper model names on the leaderboard is sometimes impossible. But I&rsquo;ve tracked down all possible models with their metrics and proper names in the </span><span class="c4"><a class="c3" href="#h.2vdz5zlpb27h">instrumentals</a></span><span>&nbsp;</span><span>and </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">vocal</a></span><span>&nbsp;models </span><span class="c0">section, so no worries.</span></p><p class="c1"><span>Also, metrics beside SDR are not available for old evaluations where they weren&rsquo;t listed in the model details yet. You can find more info about bleedless/fullness metrics </span><span class="c4"><a class="c3" href="#h.le80353knnv5">here</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">Log WMSE metric is good &ldquo;at least for drums or anything rich in low frequency content&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Our server members send their warm regards to A5 whose account disappeared for the ~5th time :) And later reappeared weirdly mutated. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;Dango launched their new instrumental model</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tuanziai.com/en-US/blog/684841907c8c85686c1b3da6&amp;sa=D&amp;source=editors&amp;ust=1765035741949584&amp;usg=AOvVaw10Im0EWz3z8a0vtHg7S38P">https://tuanziai.com/en-US/blog/684841907c8c85686c1b3da6</a></span><span class="c0">&rdquo; It&rsquo;s version 11.</span></p><p class="c1"><span class="c0">&ldquo;there is no opportunity to try at least 3 complete tracks for free.&rdquo;</span></p><p class="c1"><span class="c0">Some crossbleeding issues from v10 are still present, plus some songs are even getting worse results than in v10. You might want to use v1e (with phase fix) + Becruily vocal model (Max Spec) instead, although some people might still like Dango anyway. </span></p><p class="c1"><span class="c0">&ldquo;Some tracks are fuller than Gabox v8&rdquo;. Conservative mode is less full than V1e.</span></p><p class="c1"><span class="c0">&ldquo;They have a tool called &quot;edit &amp; improve&quot; [or &ldquo;Advanced Repair tool&rdquo;] that lets you use &#39;Conservative mode&#39; for some of more complex parts of a song and &#39;Smart mode&#39; for other parts. I find that way more convenient than processing the entire track in &#39;Conservative&#39; mode.&rdquo;</span></p><p class="c1"><span>They plan to release a karaoke model in two months.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released a &ldquo;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/small_inst.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741951902&amp;usg=AOvVaw2iki0dCTyAX36UnfGYgPyN">small</a></span><span>&rdquo; version of Mel instrumental model for faster inference | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-small/resolve/main/config_melbandroformer_small.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741952175&amp;usg=AOvVaw0DiLEwyFr1J6LeytuvILSJ">yaml</a></span><span class="c0"><br>Be aware that it can have some audible faint constant residues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- ZFTurbo: &ldquo;I added BS Roformer SW to &quot;MVSep Piano&quot;, &nbsp;&quot;MVSep Guitar&quot;, &nbsp;&quot;MVSep Bass&quot;, &nbsp;&quot;MVSep Drums&quot; algorithms. For Bass and Drums available new Ensembles.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;drum SDR jumped by .6 on the ensemble! Atho fullness took a hit&rdquo; - heuhew</span></p><p class="c1"><span class="c0">&ldquo;Same with bass, sdr leaped but fullness shot down 4 points&rdquo; - dynamic64</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- BS-Roformer SW 6 stem model replaced the old one.<br>Iirc, the model didn&rsquo;t change, just the inference code. SW stands for &ldquo;shared weights&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;I got better drums/bass separation with that model than with any others when input is some live/rehearsal recordings with shitty sound&rdquo;</span></p><p class="c1"><span class="c0">Also, there&rsquo;s better SDR and fullness for instrumentals when you invert vocals against mixture instead of mixing down drums/bass/other stems.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- undef13 released these &ldquo;bs-roformer weights stored in fp16 precision, half the size of frazer&#39;s initial version. quality is the exact same as the fp32 version&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- First vocal retrain was published shortly after a day &ldquo;May not perform very well&rdquo; (at least for now)</span></p><p class="c1"><span class="c0">If you were to fine-tune it &ldquo;this model generalizes like crazy (...) hasn&#39;t failed yet to confuse instruments and just chews through whatever you put through it (i ignore the overall mudiness)&rdquo; you can retrain it to just being inst/voc model &ldquo;I&rsquo;m currently training it to my 2 stem (...) dataset (...) I was pleasantly surprised)&rdquo; iirc on even laptop RTX 3070...</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Added on MVSEP as BS-Roformer 6 stem (no clicking issues)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The new Logic Pro model has been reversed/cracked and shared as a standalone model for inference. Full metrics for all stems added later below. It has the best SDR on multisong dataset for all stems besides vocals (but still not bad).<br>It uses a BS-Reformer arch. .MIL (CoreML) model file was converted to .PT. </span></p><p class="c1"><span class="c0">&ldquo;The only change they made was a global parameter for bias which I&#39;ve never seen before so I guess it&#39;s apple secret sauce&rdquo;. No quantization was used &ldquo;they had a shared bias across QKV and the out_proj&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;It is wonderful to achieve such results with dim 256. It seems that what was still needed was depth.&rdquo;</span></p><p class="c1"><span class="c0">A bit scared to share it, but seek and ye shall find.</span></p><p class="c1"><span class="c0">Usage:</span></p><p class="c1"><span class="c0">python inference.py --audio_path=&quot;./sample.flac&quot;</span></p><p class="c1"><span class="c0">For: ModuleNotFoundError: No module named &#39;hyper_connections&#39;</span></p><p class="c1"><span class="c0">Run: pip install hyper_connections</span></p><p class="c1"><span class="c0">&ldquo;looks like chunks aren&#39;t overlapping? Getting clicks in output.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;A very small edit, line 13:</span></p><p class="c1"><span class="c0">parser.add_argument(&#39;--chunk_size&#39;, type=int, default=588800) </span></p><p class="c1"><span class="c0">- this produces 99% identical results with the DAW.</span></p><p class="c1"><span class="c0">Previous 117760 chunk size was adding clicks and was lower quality in general.&rdquo;</span></p><p class="c1"><span class="c0">Still, the code doesn&rsquo;t use overlap, and it will result in click, just less than before.<br>Also, you can run out of memory with 588800 with 5GB VRAM free.<br>882000 was tested to have the biggest SDR in that model (not lower or higher).</span></p><p class="c1"><span class="c0">On a CPU without an Nvidia GPU it will probably be long.</span></p><p class="c1"><span>The inference script and model probably still needs the validation to ensure the metrics are the same with the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8340&amp;sa=D&amp;source=editors&amp;ust=1765035741958742&amp;usg=AOvVaw285F4QomOKlBuyitLAL7S-">validation</a></span><span>&nbsp;</span><span class="c0">made from DAW lately, but it&rsquo;s rather the same (at least other inference code got 0.03 SDR difference or same results based on the same converted weights).</span></p><p class="c1"><span class="c0">To use it with ZFTurbo MSST repo:<br>&ldquo;You need to replace bs_roformer.py in the repo with file from the archive (...) and change line 8 to:</span></p><p class="c1"><span class="c0">from models.bs_roformer.attend import Attend&rdquo; and then use separately shared config for the MSST repo and the model. Using MSST repo for inferencing fixes the clicking issue.</span></p><p class="c1"><span class="c0">For &ldquo;unrecognized arguments&rdquo; issue, &ldquo;you must put your path inside quotation marks or apostrophes&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;If you&#39;re using the script GUI, be aware that the browser popup window when choosing checkpoint has some predefined extension and .pt is not part of it&rdquo;</span></p><p class="c1"><span class="c0">Since then, weight compatible with UVR with deleted shared bias was shared (there were actually only zeroes). Also, with mask estimator method, just one stem file can be extracted out of the full weight. Vocals only were shared, but config for UVR will rather require some tweaks.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Becruily guitar model added to inference </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741960904&amp;usg=AOvVaw111LRYKR5bhtqkM_y8G6zE">Colab</a></span><span>, bleed suppressor by unwa/97chris model fixed, denoise-debleed by Gabox added, Revive 3e fixed, Revive 2 added</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&nbsp;- Gabox released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/instv7plus.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741961359&amp;usg=AOvVaw0zzsxz-nFRNkq4-wlxdfcU">instv7plus</a></span><span class="c0">&nbsp;bleedless model (experimental)</span></p><p class="c1"><span class="c0">fullness: 29.83, bleedless: 39.36, SDR 16.51</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- And </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Inst_FV8b.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741961759&amp;usg=AOvVaw14ZisBk085vmJdpgDiRpTN">Inst_FV8b</a></span></p><p class="c1"><span class="c0">fullness: 35.05, bleedless: 36.90, SDR 16.59</span></p><p class="c1"><span class="c0">&ldquo;Very clean&rdquo; although muddier than V1E+.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- wesleyr36/Dry Paint Dealer Undr HTDemucs Phantom Center model was added to the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741962423&amp;usg=AOvVaw3ibzX12Uw24EzVydpAgK7r">inference Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (Unwa) &ldquo;After a long time, I&#39;m uploading a vocal model specialized in fullness.</span></p><p class="c1"><span class="c0">Revive 3e is the opposite of version 2 &mdash; it pushes fullness to the extreme.</span></p><p class="c1"><span class="c0">Also, the training dataset was provided by Aufr33. Many thanks for that.&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/blob/main/bs_roformer_revive3e.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741963163&amp;usg=AOvVaw2mPjhpdOUbE2myWv3A-4wx">bs_roformer_revive3e</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/resolve/main/config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741963288&amp;usg=AOvVaw2asdbFx_y9bWWtCeGdlJqT">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741963490&amp;usg=AOvVaw3rzBLev6lyNeu19GqzpR1L">Colab</a></span><span>&nbsp;(should be fixed now)<br>Voc. SDR: 10.98, fullness: 21.43, bleedless: 30.51</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Logic Pro updated their stem separation feature, which now incorporates guitar</span></p><p class="c1"><span>Overall, it&rsquo;s &ldquo;surprisingly good&rdquo; - dynamic64. And a piano separator was also added to it. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://9to5mac.com/2025/05/28/logic-pro-update-adds-guitar-and-piano-stems-new-sound-packs-and-can-even-recover-tracks-you-didnt-save/&amp;sa=D&amp;source=editors&amp;ust=1765035741964190&amp;usg=AOvVaw0VIiO1gjNU_YTKWPWRurNw">More</a></span></p><p class="c1"><span class="c0">&ldquo;Guitar &amp; Piano separation seems to be really on point. So far it separated super well, also didn&rsquo;t confuse organs for guitars and certain piano sounds as well.&rdquo; - Tobias51</span></p><p class="c1"><span class="c0">&ldquo;guitar model sounds better than demucs, mvsep, and moises&rdquo; - Sausum</span></p><p class="c1"><span class="c0">&ldquo;it&#39;s not a fullness emphasis or anything, but it&#39;s shockingly good at understanding different types of instruments and keeping them consistent sounding&rdquo; - becruily<br>You don&rsquo;t need to process L and R for bleeding across channels like in other models, there isn&rsquo;t any in this one - A5</span></p><p class="c1"><span>Full </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8355&amp;sa=D&amp;source=editors&amp;ust=1765035741965290&amp;usg=AOvVaw0OBwlCR8eViWKbHqJBRluB">evaluation</a></span><span>&nbsp;</span><span class="c0">on multisong dataset (besides instrumental):</span></p><p class="c1"><span class="c0">SDR piano 7.79, bleedless 31.96, fullness 14.42</span></p><p class="c1"><span class="c0">SDR other 19.90, bleedless 58.68, fullness 49.85</span></p><p class="c1"><span class="c0">SDR guitar 9.00, bleedless 31.54, fullness 15.95</span></p><p class="c1"><span class="c0">SDR other 15.94, bleedless 49.36, fullness 31.57</span></p><p class="c1"><span class="c0">SDR drums 14.05 (although lower fullness than MVSep SCNet XL drums 14.26 vs 21.21), <br>SDR bass 14.57 (-||-), other 8.66, vocals 11.27 (only that is not SOTA)</span></p><p class="c1"><span>MVSep Piano Ensemble (SCNet + Mel) has only other fullness higher: 56.96 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7396&amp;sa=D&amp;source=editors&amp;ust=1765035741966409&amp;usg=AOvVaw0T1uj8068_x0bxSvO9WHw-">click</a></span><span class="c0">)<br></span></p><p class="c1"><span>- Since 23.05.25 jarredou (Discord: rigo2) and dca100fb8 (Discord) also have writing privileges to this document. You can find it mirrored to this date </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1_ShCnI3Qvp2Q7l_0R55jJuXzzKRtc_Ye?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741966845&amp;usg=AOvVaw1IpOUVEOkzwYTxnkZ-Tjor">here</a></span><span>&nbsp;in docx, pdf and html</span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Becruily released Melband guitar </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-guitar/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741967199&amp;usg=AOvVaw1pmq86HYgNk4V5MfmzxnX4">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741967439&amp;usg=AOvVaw0309xrcsUOEHRd3kvGuDJU">Colab</a></span></p><p class="c1"><span class="c0">&ldquo;Not SOTA, but much more efficient and comparable to existing guitar models, and for some songs it might work better because it picks up more guitars (though it can also pick some other instruments).</span></p><p class="c1"><span class="c0">For better results you might try first removing vocals.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;We added a new GUI example to work with the MVSep API. Now it allows to use multiple files and multiple algorithms at once.</span></p><p class="c1"><span class="c0">It exists as standalone .exe file, so it doesn&#39;t require python installation</span></p><p class="c1"><span>Repository: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/MVSep-API-Examples&amp;sa=D&amp;source=editors&amp;ust=1765035741968586&amp;usg=AOvVaw1f5bkY1GXOhPxzpKYvFB8H">https://github.com/ZFTurbo/MVSep-API-Examples</a></span></p><p class="c1"><span>Exe for Windows: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/MVSep-API-Examples/raw/refs/heads/main/python_example5_gui/mvsep_client_gui_win.exe&amp;sa=D&amp;source=editors&amp;ust=1765035741968961&amp;usg=AOvVaw24tyjCxuTDUVQEWG-UsA6C">https://github.com/ZFTurbo/MVSep-API-Examples/raw/refs/heads/main/python_example5_gui/mvsep_client_gui_win.exe</a></span><span class="c0">&rdquo; - ZFTurbo</span></p><p class="c1"><span>TL;DR &ldquo;You can process a song with multiple models, and process multiple songs&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sucial released v1/2 de-breath VR models:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/De-Breathe-Models/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741969593&amp;usg=AOvVaw3Vc-t6Dr825BXbg4bK_vvN">https://huggingface.co/Sucial/De-Breathe-Models/tree/main</a></span></p><p class="c1"><span>Alternatively, for this purpose you can also try out free/abandonware:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://archive.org/details/accusonus-era-bundle-v-6.2.00&amp;sa=D&amp;source=editors&amp;ust=1765035741970098&amp;usg=AOvVaw1ASy9Vp6nq4v27HYGSKJFZ">https://archive.org/details/accusonus-era-bundle-v-6.2.00</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus/uvronline) Aufr33 added new Lead and Backing vocal separator.</span></p><p class="c1"><span class="c34">It uses big beta 5e model as preprocessor for becruily Mel Karaoke model </span><span class="c0">&nbsp;&ldquo;In fact, the big beta 5e model is run after becruily Mel Karaoke&rdquo; Aufr33 (so you don&rsquo;t need the additional step to use this separator), plus it also allows controlling option for lead vocal panning like for BVE v2 (it&rsquo;s to &ldquo;to &quot;tell&quot; the AI &#8203;&#8203;where the main vocals are located (how they are mixed).&rdquo;. Becruily&rsquo;s model &ldquo;doesn&#39;t even need Lead vocal panning a lot of the time, [the] ability to recognize what is LV and what is BV [is] impressive&rdquo; - dca).</span></p><p class="c1"><span class="c0">The difference from using single becruily Kar model (without preprocessor) is that, here, &ldquo;you get the third track, backing vocals.&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The new separator is available in the free version, however, due to its resource intensity, only the first minute of the song will be processed.&rdquo; if you don&rsquo;t have premium.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Becruily:</span></p><p class="c1"><span class="c0">&ldquo;Probably too resource-intensive, but you could try adding demudders to each step</span></p><p class="c1"><span class="c0">1) karaoke model + demudding</span></p><p class="c1"><span class="c0">2) separate vocals of bgv + demudidng </span></p><p class="c1"><span class="c0">But not sure how much noise this will bring</span></p><p class="c1"><span class="c0">(Or even a 50:50 ensemble with BVE OG)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741973686&amp;usg=AOvVaw0d9NLrQbFVUdcbjdAsIG_j">Revive 2</a></span><span class="c0">&nbsp;variant of his BS-Roformer fine-tune of viperx 1297 model</span></p><p class="c1"><span class="c0">Voc. bleedless: 40.07, fullness: 15.13, SDR: 10.97</span></p><p class="c1"><span class="c0">&ldquo;has a Bleedless score that surpasses the FT2 Bleedless&rdquo; and fullness lower by 0.64.</span></p><p class="c1"><span class="c0">&ldquo;can keep the string well&rdquo; better than viperx 1297 (...) in my country they have some song with Ethnic instruments. Only 1297 and Revive2 can keep them in Instrumental while other model notice them as Vocal&rdquo; ~daylight</span></p><p class="c1"><span class="c0">&ldquo;it does capture more than viperx&#39;s&rdquo; - mesk</span></p><p class="c1"><span class="c0">It&rsquo;s depth 12 and dim 512, so the inference is much slower than with some newer Mel-Roformers like voc_fv4 (even two times), with the exception of Mel 1143 which is as slow as BS 1297 (thx dca, neoculture).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- BS-Roformer Revive unwa&rsquo;s vocal </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741975437&amp;usg=AOvVaw2fC-spruMblMsiwwWmCuyt">model</a></span><span class="c0">&nbsp;(viperx 1297 model fine-tuned) was released.</span></p><p class="c1"><span class="c0">Voc. bleedless: 38.80, fullness: 15.48, SDR: 11.03</span></p><p class="c1"><span>&ldquo;Less instrument bleed in vocal track compared to BS 1296/1297&rdquo; but it still has many </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1226334240250269797/1371215438352224307&amp;sa=D&amp;source=editors&amp;ust=1765035741975966&amp;usg=AOvVaw1o0xewlMlmpIE9MjbcfbRM">issues</a></span><span class="c0">, &ldquo;has fewer problems with instruments bleeding it seems compared to Mel. (...) 1297 had very few instrument bleeding in vocal, and that Revive model is even better at this</span></p><p class="c1"><span class="c0">(...). Works great as a phase fixer reference to remove Mel Roformer inst models noise&rdquo; it doesn&rsquo;t seem to remove instruments like FT3 Preview for phase fixing (thx dca100fb8)</span></p><p class="c1"><span>Added to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1uDXiZAHYk7dQajOLtaq8QmYXL1VtybM2&amp;sa=D&amp;source=editors&amp;ust=1765035741976834&amp;usg=AOvVaw112YyhX39uNDKf4uErdj6C">phase fixer Colab</a></span><span>.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- &nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv8.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741977183&amp;usg=AOvVaw0USYU35cEKvb4UdKiZVq-t">Inst_GaboxFv8</a></span><span>&nbsp;model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741977337&amp;usg=AOvVaw34tPQL8pfZZSAtwRVdVKBa">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741977542&amp;usg=AOvVaw1b4tfrbK5Hdbp_efJ7UXgg">Colab</a></span><span class="c0">&nbsp;checkpoint has been updated, metrics could have changed, but most of the model qualities might remain similar</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;I added new Drumsep MelBand Roformer (4 stems) model on MVSep (old one was removed). It gives the best metrics with big gap for kick, snare and cymbals.&rdquo; - ZFTurbo</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/h924uBF&amp;sa=D&amp;source=editors&amp;ust=1765035741978187&amp;usg=AOvVaw3sI75i0kdDfjeQFm4yVnc8">metrics</a></span><span>; only toms are worse SDR-wise vs previous SCNet Drumsep models</span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_fv5.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035741978566&amp;usg=AOvVaw3XYA9eAK0yyNOS-DzAX8Ww">voc_fv5</a></span><span>&nbsp;vocal model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035741978722&amp;usg=AOvVaw3LgfdC5k6zRxxWc1knVMeC">yaml</a></span></p><p class="c1"><span class="c0">voc bleedless: 29.50, fullness: 20.67, SDR: 10.56</span></p><p class="c1"><span>&ldquo;fv5 sounds a bit fuller than fv4, but the vocal chops end up in the vocal stem. In my opinion, fv4 is better for removing vocal chops from the vocal stem&rdquo; - neoculture. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1369232029291511881&amp;sa=D&amp;source=editors&amp;ust=1765035741979245&amp;usg=AOvVaw3cUJ8Ahud11Q1jgXpgcpq0">Examples</a></span></p><p class="c1"><span class="c0">&ldquo;v5 is slightly fuller, v4 is less full but also slightly more careful about what it considers as vocals. I think b5e is the fullest overall, but it&#39;s a bit much sometimes. Pretty sure the gabox models are a little more accurate with vocal/instrument detection.&rdquo; Musicalman</span></p><p class="c1"><span>Passes the Gregory Brothers - Dudes a Beast test (before - trumpets in vocal stem at 0:51; unwa&rsquo;s beta4 and inst v1e tested) - maxi74x1</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c20">Some of our less active users have been accidentally kicked out of our Discord server during some administrative tasks. You&rsquo;re free to rejoin using </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/ZPtAU5R6rP&amp;sa=D&amp;source=editors&amp;ust=1765035741980358&amp;usg=AOvVaw0raAhw0eEx2Xtcoau6fGms">this</a></span><span class="c20">&nbsp;</span><span class="c6">invite link (unless you were banned before in some other unrelated event).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Dry Paint Dealer Undr (a.k.a. wesley36) released new Phantom Centre Models:</span></p><p class="c1"><span class="c0">HTDemucs Similarity/Phantom Centre Extraction model:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/10PRuNxAc_VOcdZLHxawAfEdPCO6bYli3?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741981064&amp;usg=AOvVaw15Vzcp8AYa5eNr8mJrPP8g">https://drive.google.com/drive/folders/10PRuNxAc_VOcdZLHxawAfEdPCO6bYli3?usp=sharing</a></span><span class="c0">&nbsp;(it tends to be more &ldquo;correct&rdquo; in center extraction than the last MDX23C model)</span></p><p class="c1"><span class="c0">The Demucs model won&rsquo;t work with UVR giving bag_num error even with the yaml prepared in the same way as for Imagoy Drumsep and after renaming ckpt to th (it&rsquo;s probably because it needs ZFTurbo inference code).</span></p><p class="c1"><span class="c0">SCNet Similarity/Phantom Centre Extraction model:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1CM0uKDf60vhYyYOCg2G1Ft4aAiK1sLwZ?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741981944&amp;usg=AOvVaw06Bh4ThJzADYdMhcAUTChw">https://drive.google.com/drive/folders/1CM0uKDf60vhYyYOCg2G1Ft4aAiK1sLwZ?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">And also, difference/Side Extraction model based on SCNet arch was released:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1ZSUw6ZuhJusv7HE5eMa-MORKA0XbSEht?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741982421&amp;usg=AOvVaw2aRolHlSOLm-61flTgssP9">https://drive.google.com/drive/folders/1ZSUw6ZuhJusv7HE5eMa-MORKA0XbSEht?usp=sharing</a></span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span>- Aufr33 released his UVR Backing Vocals Extractor v2 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/XZpXyJAD%23if8wRRDxHZ0T-HiH8ZRLhXUloNIm87kpGKrBRMlHoq8&amp;sa=D&amp;source=editors&amp;ust=1765035741982731&amp;usg=AOvVaw3mmC96bB-HpVECVB8xwtll">model</a></span><span class="c0">, previously available only on x-minus/uvronline (VR arch).</span></p><p class="c1"><span class="c0">&ldquo;Note that this model should be used with a rebalanced mix. </span></p><p class="c1"><span class="c0">The recommended music level is no more than 25% or -12 dB.</span></p><p class="c1"><span class="c0">If you use this model in your project, please credit me.&rdquo;</span></p><p class="c1"><span>Should work in UVR. Just place the model file in Ultimate Vocal Remover\models\VR_Models and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1aGjDkPhqPLLlOKXeIfWDw09LElHMJfos/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741983499&amp;usg=AOvVaw2R7Ke1Jb_HS8egBI_ZP5IT">config</a></span><span>&nbsp;file in lib_v5\vr_network\modelparams. Then pick &ldquo;4band_v4_ms_fullband.json&rdquo; when asked to recognize the model</span><span>&nbsp;(it has the same checksum as in lib_v5\vr_network\modelparams folder if it&rsquo;s there already)</span><span class="c0">. Also, I think it&#39;s not VR 5.1 model. And it was used with vocal model as preprocessor.</span></p><p class="c1"><span>More about its usage in </span><span class="c4"><a class="c3" href="#h.vg1wnx1dc4g0">Karaoke</a></span><span>&nbsp;</span><span class="c0">section (scroll down a bit).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- squid.wtf doesn&#39;t work anymore &ldquo;it just downloads 30 seconds of a song, just a random 30 second snippet&rdquo; lucida works. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.4svuy3bzvi1t">USS-Bytedance</a></span><span class="c0">&nbsp;Colab has been fixed (Python &ldquo;No such file or directory&rdquo; fix) - thx epiphery.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1rfl0YJt7cwxdT_pQlgobJNuX3fANyYmx?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741984939&amp;usg=AOvVaw1FEvGuxi7ePsU4MDYjoeZg">https://colab.research.google.com/drive/1rfl0YJt7cwxdT_pQlgobJNuX3fANyYmx?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;I added a new MVSep Saxophone (saxophone, other) model. It has 3 versions: </span></p><p class="c1"><span class="c0">SCNet XL (SDR saxophone: 6.15, other: 18.87)</span></p><p class="c1"><span class="c0">MelBand Roformer (SDR saxophone: 6.97, other 19.70)</span></p><p class="c1"><span>Ensemble Mel + SCNet (SDR saxophone: 7.13, other 19.77)</span><span>&rdquo; ZFTurbo</span></p><p class="c1"><span class="c0">&ldquo;SCNet XL take[s] wurlitzer as sax tho. Mel Rofo one (...) didn&#39;t&rdquo; - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus) Server code updated [might fix the issue with bleeding at first seconds in e.g. Mel Decrowd; edit. it didn&rsquo;t]</span></p><p class="c1"><span class="c0">Added Lead vocal panning setting for Mel-RoFormer Kar by becruily model.</span></p><p class="c1"><span class="c0">[It&rsquo;s] &ldquo;to &quot;tell&quot; the AI &#8203;&#8203;where the main vocals are located (how they are mixed).</span></p><p class="c1"><span class="c0">Added Demudder for the Mel-RoFormer Kar by becruily model.&rdquo; - Aufr33</span></p><p class="c1"><span class="c0">&ldquo;doesn&#39;t even need Lead vocal panning a lot of the time, [the] ability to recognize what is LV and what is BV [is] impressive&rdquo; - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anjok released a new UVR Roformer patch #15 fixing CUDA for RTX 5000 Series GPUs and Windows users (it&rsquo;s based on CUDA 12.6 and newer PyTorch). It might not be backward compatible with older GPUs, so be aware (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/CarlGao4/Demucs-Gui/issues/115%23issuecomment-2819652160&amp;sa=D&amp;source=editors&amp;ust=1765035741987080&amp;usg=AOvVaw1q9M-EkG2IQ9nhbEFiw69K">src</a></span><span>).<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mediafire.com/file_premium/4jg10r9wa3tujav/UVR_Patch_4_24_25_20_11_BETA_full_cuda_12.8.zip/file&amp;sa=D&amp;source=editors&amp;ust=1765035741987235&amp;usg=AOvVaw1KbFLwy6GuiZPluVAS8Ium">Download</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;I added becruily Karaoke model. It&#39;s available as option in MelBand Karaoke (lead/back vocals) algorithm.&rdquo; ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) Since at least February there&#39;s a normalization for all input unless WAV is chosen as output format.</span></p><p class="c1"><span class="c0">Sometimesi it can be &quot;annoying when you have to combine the outputs later&quot;.</span></p><p class="c1"><span class="c0">&ldquo;No, if you turn off normalization, FLAC will cut all above 1.0</span></p><p class="c1"><span class="c0">And if it was normalized, it means you had these values.&rdquo;</span></p><p class="c1"><span class="c0">FLAC doesn&rsquo;t support 32-bit float, it&rsquo;s 32 int, so normalization is still needed.&rdquo;</span></p><p class="c1"><span class="c0">So if your stems don&rsquo;t invert correctly, just use WAV output format - it&#39;s 32-bit float.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Audioshake now have strings model</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1u9oUj3T0Z5F-Jl3J6Nm0dtAGsEESx80F?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741988956&amp;usg=AOvVaw2_iCTSP2UzyxZEzc18Tutm">Fast Separation</a></span><span class="c0">&nbsp;Colab by Sir Joseph has been updated with the following models:</span></p><p class="c1"><span>MelBand Roformers: FT 3 by unwa, Karaoke by becruily, FVX by Gabox, INSTV8N by Gabox, INSTV8 by Gabox, INSTV7N by Gabox, Instrumental Bleedless V3 by Gabox, Inst V1 (E) Plus by Unwa, Inst V1 Plus by Unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (stephanie/UVR) &ldquo;Those of you on Linux running the current </span><span class="c20">roformer_add+directml</span><span class="c0">&nbsp;branch that cant get becruily&#39;s karaoke model working due to the same error: </span></p><p class="c1"><span class="c0">it seems editing line 790 in separate.py setting the keyword argument strict to False when calling load_state_dict seems to make the karaoke model load and infer properly, so i think it will work</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">model.load_state_dict(checkpoint, strict=False)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I don&#39;t know if this is a robust workaround, but I haven&#39;t observed anything behaving differently than it should yet, so if you want to give it a shot I think it will work</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">TL;DR change line 790 in separate.py to the codeblock and then run again and karaoke model should work&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aname&rsquo;s Mel-Roformer 4 stems Large added to inference </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741991129&amp;usg=AOvVaw2P2oma9858jcZTp3vZkoD2">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Apollo Lew Uni model can be also used as denoiser.</span></p><p class="c1"><span>It tends to smooth out some noise in higher frequencies, making the spectrum more even there, smoothing out the sound in general (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1HuDRh5dkkNbMbIhcybDTTusnWwZOgp4V?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035741991654&amp;usg=AOvVaw3qvE7aw0cx3mXH3g8i7ZYp">example</a></span><span class="c0">). </span></p><p class="c1"><span>More about the model and its usage - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.7nivwczgciev&amp;sa=D&amp;source=editors&amp;ust=1765035741991973&amp;usg=AOvVaw1KtefGyYzmLco6_-ZegxyV">click</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Becruily&rsquo;s Mel-Roformer Karaoke model added on x-minus/uvronline under &ldquo;Keep backing vocals&rdquo; option and in the inference </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035741992519&amp;usg=AOvVaw1oK_L8tXXKl6qBmKDuw-sy">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Most likely, you&rsquo;ll have &ldquo;&rdquo;&rsquo;norm&rsquo;&rdquo;&rdquo; AttributeError when trying out that model in UVR. Read </span><span class="c4"><a class="c3" href="#h.vrtjkbqu3t9r">here</a></span><span class="c0">&nbsp;for troubleshooting. Use melband-roformer model type, not v2.</span></p><p class="c1"><span>Make sure you use the latest UVR Roformer </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">patch</a></span><span>&nbsp;</span><span class="c0">- older patches like #2 will show RuntimeError about layers.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (becruily) &ldquo;I&#39;m releasing my first karaoke </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-karaoke/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741993474&amp;usg=AOvVaw0ksKIE_q_--Nn4gXD3LUuI">model</a></span><span class="c0">. </span></p><p class="c1"><span class="c0">It&#39;s a dual model trained for both vocals and instrumental. It sounds fuller + understands better what is lead and background vocal, and to me, it is better than any other karaoke model.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;Compared to Aufr33&rsquo;s Melband model, it can achieve e.g. cleaner pronunciation in some songs (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1361694470403260556&amp;sa=D&amp;source=editors&amp;ust=1765035741994165&amp;usg=AOvVaw3UJAQvEBjUPNzENxhKBbPX">examples</a></span><span class="c0">) - neoculture &ldquo;It is the best available, better than Mel Kar, UVR BVE v2, lalal.ai, Dango...&rdquo; - dca &ldquo;This sounds amazing&rdquo; - Rege 313 &ldquo;It performs very well with male/female duets, nice work&rdquo; - Gabox</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Important note: This is not a duet or male/female model. If 2 singers are singing simultaneously + background vocals, it will count both singers as lead vocals. The model strictly keeps only actual background vocals. The same goes for &quot;adlibs&quot; such as high notes or other overlapping lead vocals.</span></p><p class="c1"><span class="c0">The model is not foolproof. Some songs might not sound that much improved compared to others. It&#39;s very hard to find a dataset for this kind of task.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Tip: For even better results, first extract the vocals with a fullness model (like mine) and combine the results with a fullness instrumental model.&rdquo; becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The model outputs 2 stems like duality models, so you might end up with three outputs if you check the option to invert stem - don&rsquo;t use it, it will rather have worse quality than what the model outputs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;I added 2 more models for DrumSep based on MelBand Roformer architecture.&rdquo; </span></p><p class="c1"><span>a) 4 stems (kick, snare, toms, cymbals) - average </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/n9WMkSY&amp;sa=D&amp;source=editors&amp;ust=1765035741996504&amp;usg=AOvVaw0Ygl0WI50do8NYOTY2RMs0">SDR</a></span><span>&nbsp;</span><span class="c0">of hihat ride, crash is 11,52 (but in one stem) and so far it&rsquo;s the best SDR out of all models (even vs the previous ensemble consisting of three MDX23C and SCNet models). </span></p><p class="c1"><span class="c0">b) 6 stems (kick, snare, toms, hihat, ride, crash) - average SDR of hihat ride, crash is 8.18 (but from separated stems), while </span></p><p class="c1"><span class="c0">The snare in a) has the best SDR out of all available models.<br>Kick and toms are still the best SDR-wise in the previous 3x MDX23C and SCNet ensemble (new ensemble with these new Mel-Roformers so far)</span></p><p class="c1"><span class="c0">- The new models &ldquo;are very great for ride/crash/hh. And overall they have the best metrics almost for all stems.&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Aname released two 4 stems Mel-Roformer models:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/melbandroformer4stems/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035741997943&amp;usg=AOvVaw1fynJt-UthoWQyS0cjns5Y">https://huggingface.co/Aname-Tommy/melbandroformer4stems/tree/main</a></span></p><p class="c1"><span class="c0">a) Large (4GB) SDR drums: 9.72, bass: 9.40, other: 5.11, vocals 8.65 (multisong dataset)</span></p><p class="c1"><span class="c0">b) XL (7GB) SDR drums: 9.83, bass: 9.37, other: 5.31, vocals 8.57 (multisong dataset)</span></p><p class="c1"><span class="c0">The latter doesn&rsquo;t work in the custom model import Colab with at least the default chunk_size, and works slow on e.g. 3060 (?12GB). Both models were trained with chunks set to 15 seconds (chunk_size = 661500).</span></p><p class="c1"><span class="c0">&ldquo;I tried a song on 4070 Super it took like 6 mins on XL 4 stems compared to 30 seconds on Large 4 stems&rdquo; On 3060 XL is very slow.</span></p><p class="c1"><span>Despite lower AVG SDR on musdb18 dataset vs demucs_ft (8.54 vs 9), it seems to outperform that model (SDR is only better in other stem), public SCNet, SCNetXL, BS-Roformer have better </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/1pGC8En&amp;sa=D&amp;source=editors&amp;ust=1765035741999436&amp;usg=AOvVaw0yzwk2qNiHPaE4tfX1324s">metrics</a></span><span>&nbsp;</span><span class="c0">(still musdb18 dataset, not multisong on MVSEP)</span></p><p class="c1"><span class="c0">&ldquo;Drums are sounding really good in particular, tested a couple songs with the large model after using unwa&#39;s v1e+ for instrumental&rdquo; &ldquo;drums are absolutely the standout&ldquo;</span></p><p class="c1"><span class="c0">&ldquo;Large works in like 99% use case&rdquo; &ldquo;Large split sounds amazing so far tho&rdquo;</span></p><p class="c1"><span class="c0">XL &ldquo;result would take so much longer, but the large results sounded better imo&rdquo; 5B</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The Colab is forcing a different value than the one from the config. You can try to edit the inference cell code and add 661500 as possible value and see if it goes better.</span></p><p class="c1"><span class="c0">The Colab only changes chunk_size (value from GUI), batch_size (forcing =1) and overlap (value from GUI), it doesn&#39;t touch other settings from config.&rdquo; - jarredou</span></p><p class="c1"><span class="c0">&ldquo;It may change audio setting, chunk_size=485100, n_fft=2048 will work, but it will go lower SDR maybe&rdquo; while the lowest reasonable value will be rather 112455 (2,5 s).</span></p><p class="c1"><span class="c0">Large model uses 7GB VRAM on Nvidia GPU in UVR with default config settings.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Sir Joseph released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1u9oUj3T0Z5F-Jl3J6Nm0dtAGsEESx80F?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742002606&amp;usg=AOvVaw3gT6uAr3Tm6Kn_tcXp8TKw">SESA Fast Separation</a></span><span>&nbsp;Colab based on UVR. It&rsquo;s faster than the regular </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742002956&amp;usg=AOvVaw0_dAWFxEpqWRT4a3V8rXo2">SESA</a></span><span>&nbsp;</span><span class="c0">Colab (whiuch now has &ldquo;added Apollo to Auto Ensemble and fixed a few technical glitches. It&rsquo;s running smoother now!&rdquo;)<br>More changes in the fast Colab:</span></p><p class="c1"><span class="c0">V1e+ and Gabox inst fv8 are missing because the model list cannot be updated in the Fast Colab yet.<br>&ldquo;auto-ensemble feature is included here too.</span></p><p class="c1"><span class="c0">Background noise suppression is a bit more polished.</span></p><p class="c1"><span class="c0">You can specify unwanted stems to filter out.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus/uvronline) &ldquo;1. A new Mel-RoFormer by unwa v1e+ model has been added. It removes vocals very gently while preserving instruments. It is recommended to use it with correct_phase post-processing.</span></p><p class="c1"><span>2. Mel-RoFormer by Kim &amp; unwa ft3 and some other models are hidden. As before, you can find them here: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742005554&amp;usg=AOvVaw24rprjkePqtjtPsUYd4DdD">https://uvronline.app/ai?hp&amp;test</a></span><span class="c0">&rdquo; - Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The only problem is the phase correction, it still uses FT2 as a reference [for phase fixer], and FT2 cuts instruments still, so I&#39;m waiting for FT3 release by unwa so it can be added as phase fixer reference and preserve instruments well&rdquo; dca</span></p><p class="c1"><span class="c0">&ldquo;Results are still better with phase fixer though, right&rdquo;</span></p><p class="c1"><span class="c0">Make sure you&rsquo;re &ldquo;clicking on &quot;Ensemble&quot;? It should &quot;reveal&quot; that option&rdquo; since the last website layout changes.</span></p><p class="c1"><span class="c0">&ldquo;phase fixer [on the site] swaps the v1e+ vocals with the ft2 vocals&rdquo;</span></p><p class="c1"><span>Iirc phase fixer feature requires premium.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- SESA Colab by Sir Joseph is back! The Colab link has changed - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742007924&amp;usg=AOvVaw2a_P9x8tb7ttvwtNcgpOB7">click</a></span></p><p class="c1"><span class="c0">Apollo Integration: Added Apollo audio enhancement feature. Supports Normal and Mid/Side methods.</span></p><p class="c1"><span class="c0">UI Updates: Added new Apollo settings components under the Settings tab.</span></p><p class="c1"><span class="c0">Bug Fixes:</span></p><p class="c1"><span class="c0">Fixed Apollo output not showing in the terminal.</span></p><p class="c1"><span class="c0">Corrected &quot;Phase Remix&quot; and &quot;Overlap Info&quot; display in the UI.</span></p><p class="c1"><span class="c0">Translation Updates: Added new translation keys for Apollo, removed unused keys.</span></p><p class="c1"><span class="c0">Colab Support: Added 10 new languages: EN_US (English), TR_TR (Turkish), AR_SA (Arabic), RU_RU (Russian), ES_ES (Spanish), DE_DE (German), ZN_CN (Chinese), HI_IN (Hindi), JA_JP (Japanese), IT_IT (Italian).</span></p><p class="c1"><span class="c0">and new models added</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Note: Enhanced UI and processing stability.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv8.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742010725&amp;usg=AOvVaw2y7GS7-BGa1ijcXbDRjQim">Inst_GaboxFv8</a></span><span>&nbsp;model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742011016&amp;usg=AOvVaw3EF_Ohwnd2wP3g4ip-Ba__">yaml</a></span><span class="c0">) [weight has been replaced by v2]</span></p><p class="c1"><span class="c0">Inst. bleedless: 38.06, fullness: 35.57, SDR: 16.51 [outdated]</span></p><p class="c1"><span class="c0">Might have some &ldquo;ugly vocal residues&rdquo; at times (Phil Collins - In The Air Tonight) - 00:46, 02:56 - dca.</span></p><p class="c1"><span class="c0">VS v1e &rdquo;it seems to pick up some instruments better&rdquo; Gabox</span></p><p class="c1"><span class="c0">&ldquo;a bit cleaner-sounding and has less filtering/watery artifacts. </span></p><p class="c1"><span class="c0">Both models are prone to very strange vocal leakage [&ldquo;especially in the chorus.&rdquo;]. </span></p><p class="c1"><span class="c0">And because Fv8 can be so clean at times, the leakage can be fairly obvious. For now, my vote is for Fv8, but I&#39;ll still probably be switching back and forth a lot&rdquo; - Musicalman</span></p><p class="c1"><span>&ldquo;sometimes v1e+ have vocal residues which sound like you were speaking through a fan/low quality mp3&rdquo; - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Added Mesk Metal Model Preview, Unwa v1+ Preview, and Unwa v1e+ Mel instrumental models and Beta6X and FT3 Preview by Unwa vocal models, and Bandit v2 multilingual model to inference </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742014106&amp;usg=AOvVaw1VWZWQlupfowpcELZPH0wE">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released a new V1e+ Mel-Roformer instrumental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/blob/main/inst_v1e_plus.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742014605&amp;usg=AOvVaw28os5tXzpm2lMOKkeFwFug">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/blob/main/config_melbandroformer_inst.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742014821&amp;usg=AOvVaw2l3csDliveRnx9YvDplfzT">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742015133&amp;usg=AOvVaw3gdKKF_UZQEAZU-1RXEg5u">Colab</a></span></p><p class="c1"><span class="c0">Inst bleedless: 36.53, fullness: 37.89, SDR: 16.65</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Less noise than v1e (esp. in the lower frequencies), but it&rsquo;s also less full - &ldquo;somewhere between v1 and v1e.&rdquo;. It has fewer problems with quiet vocals in instrumentals than the V1+, &ldquo;issues with harmonica, saxophone, elec guitar and synth seem to have been fixed. Theremin and kazoo are still problematic [like] for models from MDX-Net or SCNet [archs]). Only dango seems to correctly detect kazoo as an instrument it seems&rdquo; - dca, &ldquo;The loss function was changed to be more fullness-oriented, and trained a further 50k steps from the v1+ test.&rdquo; Unwa</span></p><p class="c1"><span class="c0">&ldquo;v1e keeps better instruments like trumps than v1e+</span></p><p class="c1"><span class="c0">With v1e+ there is less noise, but some instruments are hidden&rdquo; koseidon72</span></p><p class="c1"><span class="c0">&ldquo;v1e+ has a strange problem of almost vocoding the vocals and keeping them in quietly&rdquo; even with phase fixer</span></p><p class="c1"><span class="c0">&ldquo;has some problems with cymbals bleed in vocals (not the case with other instrumental roformer models)&rdquo; dca</span></p><p class="c1"><span class="c0">&ldquo;trained with additional phase loss which helps remove some of that metallic fullness noise, and also has higher sdr I believe&rdquo; - becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released V1+ Mel-Roformer instrumental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742018846&amp;usg=AOvVaw0BaYz-gCv9scTx79B6PJZz">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/blob/main/config_melbandroformer_inst.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742019086&amp;usg=AOvVaw3E_6sU467EY2sHuqX2ZHeG">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742019403&amp;usg=AOvVaw1vpFHnPB8EOiKCBGs2nI0Y">Colab</a></span></p><p class="c1"><span class="c0">Inst. bleedless: 38.26, fullness: 35.31, SDR: 16.72</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It is based on v1e, but the Fullness is not as high as v1e, so it is positioned as an improved version of v1.&quot; Unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;very nice model, the multistft noise is gone&quot;</span></p><p class="c1"><span class="c0">It&#39;s probably due to:</span></p><p class="c1"><span class="c0">&quot;Unwrapped phase loss function added&quot; Unwa</span></p><p class="c1"><span class="c0">BTW. It was already proven before, that adding artificial noise to separations was increasing fullness metric.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Seems to have significantly less sax and harmonica bleed in vocal, which is an awesome thing (...) It still struggles with other things like FX and Kazoo.&quot; dca</span></p><p class="c1"><span class="c0">&quot;It sounds clean. The only thing [is] that some instruments are deleted, and in some tracks leaves remnants of voice in the instrumental.&quot; Fabio</span></p><p class="c1"><span class="c0">&quot;Screams are not removed from the track&quot; Halif</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Training details </span></p><p class="c1"><span class="c0">&quot;I made a small improvement to the dataset and trained about 50k steps with a batch size of 2.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">8192 was added to multi_stft_resolutions_window_sizes.</span></p><p class="c1"><span class="c0">As it was, the memory usage increased too much, so it was rewritten to use hop_length = 147 when window_size is 4096 or less and 441 when window_size is greater than that.&quot; Unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mesk released a preview of his instrumental model retrained from Mel Kim on metal dataset consisting of a few thousands of songs.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/meskvlla33/metal_roformer_preview/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742023599&amp;usg=AOvVaw0-TZQOKnDqifyQUOiEwDOi">https://huggingface.co/meskvlla33/metal_roformer_preview/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742023823&amp;usg=AOvVaw0nKFkTaR7ft1UZvXQLSv0F">Colab</a></span></p><p class="c1"><span class="c0">These are not multisong metrics, but made with private dataset!</span></p><p class="c1"><span class="c0">Instr bleedless: 48.81, fullness: 42.85, SDR: 13.7621</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;currently restarting from scratch because I think I know what all the problematic vocal tracks were, and I removed them, we&#39;ll see if it&#39;s gonna be better&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;vocals could follow if requested.</span></p><p class="c1"><span class="c0">Should work fine for all genres of metal, but doesn&#39;t work on:</span></p><p class="c1"><span class="c0">- hard compressed screams</span></p><p class="c1"><span class="c0">- some background vocals</span></p><p class="c1"><span class="c0">- weird tracks (think Meshuggah&#39;s &quot;The Ayahuasca Experience&quot;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>P.S: Use the training repo </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">(MSST)</a></span><span>&nbsp;if you want to [separate] with it. UVR will be abysmally slow (because of chunk_size [introduced since </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR Roformer beta</a></span><span class="c0">&nbsp;#3])&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Yusuf fixed </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1lHnu9-rVvNp5VtU7MFjWx92501Qwfdyf&amp;sa=D&amp;source=editors&amp;ust=1765035742025459&amp;usg=AOvVaw1zCaUUXSIXQAJX8gKfNkLd">Apollo</a></span><span>&nbsp;</span><span>and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9CjxMDyYnggKKQBPpGLufuVzt_yJJrL&amp;sa=D&amp;source=editors&amp;ust=1765035742025599&amp;usg=AOvVaw0RAqrfBgOJ83MTQNkfTsqM">AudioSR</a></span><span>&nbsp;</span><span class="c0">WebUI Colabs and mid/side method of upscaling was added to Apollo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released Big Beta 6X vocal </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/resolve/main/big_beta6x.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742025959&amp;usg=AOvVaw0t_V0y7rCELrxfszKibKPz">model</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/resolve/main/big_beta6x.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742026076&amp;usg=AOvVaw2i4wFCFXWYVCFpOvVzfzoz">yaml</a></span><span class="c0">)<br>Vocal bleedless: 35.16, fullness: 17.77, SDR: 11.12</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;it is probably the highest SDR or log wmse score in my model to date.&rdquo;<br>Some leaks into vocal might occur.</span></p><p class="c1"><span class="c0">&ldquo;dim 512, depth 12.</span></p><p class="c1"><span class="c0">It is the largest Mel-Band Roformer model I have ever uploaded.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;I&#39;ve added dozens of samples and songs that use a lot of them to the dataset&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;I added new Apollo model with Aura MR STFT: 22.42</span></p><p class="c1"><span class="c0">It&#39;s available under &quot;Apollo Enhancers (by JusperLee and Lew)&quot; with option: <br>&quot;Universal Super Resolution (by MVSep Team)&quot;.</span></p><p class="c1"><span class="c0">It requires a hard cutoff on frequency for best experience.&rdquo; - ZFTurbo</span></p><p class="c1"><span class="c0">Iirc, it was trained by his student.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;It&#39;s doing well on more transient stuff like snare hits, but it seems to really struggle to actually add harmonics. Has this really weird quality of sounding high quality and low quality at the same time&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;It doesn&#39;t seem to like 8 kHz cutoff, it has generated almost nothing&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;I tried with a 10 kHz cutoff and just got quitet-ish transients&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Lew told me the same while training his, the model would learn transients/drums but struggle with harmonics. Maybe it&rsquo;s an Apollo limitation. I don&rsquo;t recall if the OG model by jusper lee has this issue too, since it rarely works&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Advice</span></p><p class="c1"><span class="c0">You might want to process your song even 4 times to potentially get better results.</span></p><p class="c1"><span>Also, you can split mids and sides, and upscale them separately to get better results, although it&rsquo;s not always better solution (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/9hGtihd&amp;sa=D&amp;source=editors&amp;ust=1765035742029132&amp;usg=AOvVaw267PYRWpoeCXzoqKjFPXwm">spectrograms</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1G7EXEQh9oEWtBXId_OSiCy-qXC6X2xve4BTRnyQlvJQ/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742029279&amp;usg=AOvVaw2RyxDgZ0HWrEyrIoOC6m9F">tutorial</a></span><span class="c0">), thx AG89.</span></p><p class="c1"><span>Using e.g. MDX23C Similarity/Phantom Centre extraction model instead with 2x slowdown (to reduce smearing artefacts) gives less high-end recovery, but less noise resulting in more proper cancelling of both channels (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/uVbNGJ7&amp;sa=D&amp;source=editors&amp;ust=1765035742029732&amp;usg=AOvVaw2gDB2x5XgL4g6SZGSzdAOl">spectrograms</a></span><span>&nbsp;by AG89).<br>Avg ensemble will be rather diminishing returns, so consider manual weighted ensemble in DAW.<br>Getting rid of noise or dithering above real frequencies by making cutoff can make a night and day difference for the result (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/roAJR2G&amp;sa=D&amp;source=editors&amp;ust=1765035742030148&amp;usg=AOvVaw0xp8I-O-4n6puy5wn_1P7y">example</a></span><span class="c0">)</span></p><p class="c1"><span>Sometimes cutting off some more existing frequencies might be beneficial too (the model was trained with hard cutoff)<br>For noise artefacts after upscaling you can use some </span><span class="c4"><a class="c3" href="#h.hyzts95m298o">denoisers</a></span><span class="c0"><br></span></p><p class="c1"><span>- Gabox released new </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/INSTV8N.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742030691&amp;usg=AOvVaw0VZYd0kQDXo8Q3-ntK5BZo">INSTV8N</a></span><span>&nbsp;instrumental model in experimental folder (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742030905&amp;usg=AOvVaw3IeOi7_h3ilvqQo-onU8Pi">yaml</a></span><span>)<br>&ldquo;noticed too many vocal residues. (...) there is no noise&rdquo; although N stands for noise in its name.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Some upscaling Colabs are also affected by the last runtime changes in Colab made by Google. Maybe downgrading !pip install torch==2.5 would help.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- We&#39;re aware of the issues in some Colabs like </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742032121&amp;usg=AOvVaw0A1n3_KSWe5gsTDDzGi39W">MDX by HV</a></span><span class="c0">&nbsp;(numpy errors related to its wrong version). Any fixing will be announced. Stay tuned.</span></p><p class="c1"><span class="c0">- Fixed, but initialization is slow till further notice, and you need to click initialization cell second time when you&rsquo;re prompted to restart environment.<br>- Fixed, but now you need to click the initialization cell again after Numpy has been installed (happens briefly after launching the initialization cell).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Unwa&#39;s FT3 test vocal model added on x-minus/uvronline</span></p><p class="c1"><span class="c0">&ldquo;make vocals sound a bit lower at chorus compared to other parts of songs&rdquo;, doesn&rsquo;t happen with big beta 5e - oak</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;ZFTurbo: &ldquo;I added 2 new super resolution algorithms on MVSep in Experimental section:</span></p><p class="c1"><span>1) AudioSR. Metrics: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8067&amp;sa=D&amp;source=editors&amp;ust=1765035742034277&amp;usg=AOvVaw2_IFMT84PWhXRxxI-1ge_c">https://mvsep.com/quality_checker/entry/8067</a></span></p><p class="c1"><span>2) FlashSR. Metrics: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8071&amp;sa=D&amp;source=editors&amp;ust=1765035742034538&amp;usg=AOvVaw1CNMrIe5BYInS30dx6lVsY">https://mvsep.com/quality_checker/entry/8071</a></span><span>&rdquo;</span></p><p class="c1"><span class="c0">Be aware that both can give some errors occasionally. Some problems with mono audio were fixed already.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released FT3 preview vocal </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/blob/main/kimmel_unwa_ft3_prev.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742034995&amp;usg=AOvVaw219QNNFcYJWysaptDlbZOy">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/resolve/main/config_kimmel_unwa_ft.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742035127&amp;usg=AOvVaw17JV-yFi-dcuXbXAxT2Gyy">yaml</a></span></p><p class="c1"><span class="c0">Vocal bleedless: 36.11, fullness: 16.80, SDR: 11.05</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;primarily aimed at reducing leakage of wind instruments to vocals.</span></p><p class="c1"><span class="c0">I will upload a further fine-tuned version as FT3 in the near future.&rdquo;</span></p><p class="c1"><span class="c0">For now, FT2 has less leakage for some songs (maybe till the next FT will be released).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox added some new experimental instrumental models in a separate repo </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/experimental&amp;sa=D&amp;source=editors&amp;ust=1765035742036479&amp;usg=AOvVaw1uddYGw4K3qg-AxxHSwOO-">folder</a></span><span>.</span></p><p class="c1"><span class="c0">They are called V8, V9, V10, don&rsquo;t consider them as newer/better, but forgotten to upload in the meantime.<br>They&rsquo;re less full than V7, but have less vocal residues. Also, the results from V8 and V10 are the same (&ldquo;inverted polarity between 2 results, and it&#39;s just silence&rdquo;), and also for V9.<br>&ldquo;Both remove some instruments from the music, like V7.</span></p><p class="c1"><span class="c0">As for noise, however, they are less noisy&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gaboxBv3.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742037445&amp;usg=AOvVaw1wTmvHoDBqID2yKG79EnTD">inst_gaboxBv3</a></span><span class="c0">&nbsp;instrumental model (B for bleedless)</span></p><p class="c1"><span class="c0">Inst. bleedless: 41.69, fullness: 32.13</span></p><p class="c1"><span class="c0">&ldquo;can be muddy sometimes&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/15CDkDugqBKGMFe98ltQ6XGZEh8pdDOCTMT4ue89GQIM/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742037926&amp;usg=AOvVaw0Rgss33_cs8mxJzehDhxLe">mesk&rsquo;s training model guide</a></span><span class="c0">&nbsp;link has been changed (the previous one has been deleted)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Apart from new drumsep models on MVSEP, also moises.ai has their own drumsep model (paid).<br>Probably their base drums model used for drumsep is not better than other solutions, so check </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">this</a></span><span class="c0">&nbsp;section of the doc to get better drums to separate first to test it out, although one user reported that moises&rsquo; drums model (free), probably vs Mel-Roformer on MVSEP or x-minus (not sure) can give &ldquo;better results (...) if the input material is for example cassette-tape sourced or post-FM).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Joseph made the SESA Colab private till some stuff will be fixed in the future.<br>Consider using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742039214&amp;usg=AOvVaw3TxRHadg1z0yZzIanMCqdF">this</a></span><span>&nbsp;Colab with newer models added at this time.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus) Inst V7 model by Gabox replaced v1e model by Unwa.</span></p><p class="c1"><span class="c0">It can be still accessed by these links:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742039754&amp;usg=AOvVaw18TubG0Fx-aaoGXFFbQMgn">https://uvronline.app/ai?hp&amp;test</a></span><span>&nbsp;</span><span class="c0">(premium)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?test&amp;sa=D&amp;source=editors&amp;ust=1765035742039957&amp;usg=AOvVaw1NSG0hvfq1v6c_OOctO3Kn">https://uvronline.app/ai?test</a></span><span>&nbsp;</span><span class="c0">(free) </span></p><p class="c1"><span class="c0">(v1e might be still fuller, and impair fewer instruments in cost of more noise, also be aware that separation on x-minus might differ from Colabs, MSST or UVR, possibly due to different inference parameters)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Training (and inferencing) locally on Radeon using </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span class="c0">, specifically RX 7900 XTX, was confirmed to work by Unwa on Ubuntu 24.04 LTS using Pytorch 2.6 for ROCm 6.3.3.</span></p><p class="c1"><span>Currently, officially </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html&amp;sa=D&amp;source=editors&amp;ust=1765035742040985&amp;usg=AOvVaw0Nj1XeKpVMa9pwYoYEnQNU">supported</a></span><span>&nbsp;</span><span class="c0">consumer GPUs with ROCm are: </span></p><p class="c1"><span class="c0">RX 7900 XTX, RX 7900 XT, RX 7900 GRE and AMD Radeon VII. But in fact, there are more consumer Radeons confirmed to work already too.</span></p><p class="c1"><span>&ldquo;No special editing of the code was necessary. All we had to do was install a ROCm-compatible version of the OS, install the AMD driver, create a venv, and install ROCm-compatible PyTorch, Torchaudio, and other dependencies on it.&rdquo; </span><span class="c4"><a class="c3" href="#h.bg6u0y2kn4ui">More</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;So far I have not had any problems. Running the same thing appears to use a little more VRAM than when running on the NVIDIA GPU, but this is not a problem since my budget is not that large and if I choose NVIDIA I end up with 16GB of VRAM (4070 Ti S/4080 S).</span></p><p class="c1"><span>Processing speeds are also noticeably faster, but I did not record the results on the previous GPU, so I can&#39;t compare them exactly.&ldquo; </span><span class="c4"><a class="c3" href="#h.bg6u0y2kn4ui">More</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/Inst_GaboxFVX.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742042761&amp;usg=AOvVaw2KN025VEGuxNKH28RxQKst">Inst_GaboxFVX</a></span><span>&nbsp;model was released</span><span class="c0">&nbsp;(which is &ldquo;instv7+3&rdquo; - so probably fuller than instv3) and </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/INSTV7N.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742043139&amp;usg=AOvVaw32rKKHIPPE9BKZOQDXOZ1e">INSTV7N</a></span><span>&nbsp;(so more noisy than INSTV7; &ldquo;it&#39;s [even] closer to fv7 than inst3&rdquo;) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742043438&amp;usg=AOvVaw2hfhq2ZFyZyeH2NHn2W8RE">yaml</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Gabox Karaoke model got updated (links have been replaced, and the old deleted from the repo), </span></p><p class="c1"><span>- and also final </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/Inst_GaboxV7.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742043861&amp;usg=AOvVaw39NoQlw3RrEe1rx6ezPRCZ">INSTV7</a></span><span>&nbsp;</span><span class="c0">was released (&ldquo;I hear less noise compared to v1e, but it has worse bleedless metric&rdquo;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released instv7 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://gofile.io/d/aiZiEl&amp;sa=D&amp;source=editors&amp;ust=1765035742044181&amp;usg=AOvVaw09HvfdMmLJ5JylCV1gRKWb">beta 2</a></span><span class="c0"><br>Inst. bleedless: 34.66, fullness: 38.96</span></p><p class="c1"><span>and instv7 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/instv7beta3.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742044440&amp;usg=AOvVaw0JCQbxKXmvbVWopkqKm1Rk">beta 3</a></span><span class="c0"><br>&ldquo;Both are noisy with small vocal residuals in places where music is low and deletions of some musical instruments.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New 4 stem drumsep SCNet model (kick, snare, toms, cymbals) has been added on MVSEP (best SDR for kick and similar for toms to previous 6s modelm -0.01 SDR difference), and also 8 stems ensemble of all other drumsep models (besides the older Demucs model by Imagoy) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/aXxSgV7&amp;sa=D&amp;source=editors&amp;ust=1765035742045139&amp;usg=AOvVaw1E1h-IabrICJerfEa6fWKx">metrics</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/instv7beta.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742045407&amp;usg=AOvVaw0iPKp0m4zVA-Grauve1fja">instv7beta</a></span><span>&nbsp;model </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742045557&amp;usg=AOvVaw0ctecuqqbhP05-PJM0qfkV">yaml</a></span></p><p class="c1"><span>Inst. bleedless: 35.01, fullness: 38.39<br>&ldquo;sound is good, but sometimes some instruments are lowered or deleted&rdquo;<br>&ldquo;while the annoying buzzing/noise is still present, it seems to be more contained.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/kar_gabox.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742046147&amp;usg=AOvVaw2ekqOSDquV6dvk37SGEvcN">KaraokeGabox</a></span><span>&nbsp;model (uses Aufr&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/config_mel_band_roformer_karaoke.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742046324&amp;usg=AOvVaw061-l3he3NZ9pippI46v28">config</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742046470&amp;usg=AOvVaw3ZZPTzEKrzvukUbgo__eGV">Colab</a></span></p><p class="c1"><span class="c0">&ldquo;the lead vocals are good and clean! <br>While the backing tracks are lossy for this model, [it still] provide[s] great convenient for those who need LdV&rdquo;</span></p><p class="c1"><span>&ldquo;The model doesn&#39;t keep the backing vocals below the main vocals, sometimes the backing vocals will be lost even though there are backing vocals there.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/MelBandRoformers/blob/main/FullnessVocalModel.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742047324&amp;usg=AOvVaw0sY1M4Z2F_6NoPuUN5fmKR">FullnessVocalModel</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/MelBandRoformers/blob/main/config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742047495&amp;usg=AOvVaw33w6sPmkEsZD57kmYVZiBy">yaml</a></span><span>) vocal model was released by Aname | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742047679&amp;usg=AOvVaw30DwovBsOh33-WnRcKVZNd">Colab</a></span></p><p class="c1"><span class="c0">Voc. bleedless: 32.98 (less than beta 4), fullness: 18.83 (less than big beta 5e/voc_fv4/becruily, more than beta 4)</span></p><p class="c1"><span class="c0">&ldquo;While it emphasizes fullness, the noise is well-balanced and does not interfere much. (...)</span></p><p class="c1"><span>in sections without vocals, faint, rustling vocals can be heard.&rdquo;</span></p><p class="c1"><span class="c0">We have some report of very long separation of this model in UVR on Macs.</span></p><p class="c1"><span class="c0">&gt; Try to change chunk_size: 529200 to 112455 for that model/yaml (but it&rsquo;s dim_t 256 equivalent, so something higher to test might be a better idea too)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (SESA) No audio file found bug fixed</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;In my testing, I&#39;ve found that SCNet very high fullness (on mvsep) put through Mel-Roformer denoise (average) and UVR denoise (minimum) has the best acapella result</span></p><p class="c1"><span class="c0">would love to see people&#39;s thoughts&rdquo; dynamic</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_fv4.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742049672&amp;usg=AOvVaw1mCs6KUHUMQsglE-cczQql">voc_fv4</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742049822&amp;usg=AOvVaw3140GW_SxlAR198xjnr9g_">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742050053&amp;usg=AOvVaw2nOCAWBdXStQrsDZhrQ7gU">Colab</a></span></p><p class="c1"><span class="c0">Voc. bleedless 29.07, fullness 21.33</span></p><p class="c1"><span class="c0">&ldquo;Very clean, non-muddy vocals. Loving this model so far&rdquo; (mrmason347)</span></p><p class="c1"><span class="c0">&ldquo;lost some of the trumpet sound &nbsp;while on Becruily model can keep it, but some also was lost&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Joseph fixed some bugs and errors in SESA Colab, and also added new interface</span></p><p class="c1"><span class="c0">There are still some issues with auto ensemble till further notice.</span></p><p class="c1"><span>- Fixed</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- unwa released Big Beta 6 vocal </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/resolve/main/big_beta6.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742051213&amp;usg=AOvVaw2XIjQNfklK1JVJU_TK4DLX">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/blob/main/big_beta6.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742051332&amp;usg=AOvVaw1J5dxYvFUS9LGIPCFJ1ari">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742051534&amp;usg=AOvVaw3-RP3PDaj_qKkxe6UZuiQB">Colab</a></span><span class="c0"><br>&ldquo;Although it belongs to the Big series, the characteristics of the model are similar to those of the FT series. (...) this model is based on FT2 bleedless with the dim increased to 512&rdquo;</span></p><p class="c1"><span class="c0">Muddier than Big Beta 5, might be better than FT2 at times.<br>&ldquo;If you liked the output of the Big Beta 5e model, you may not like 6 as much; it does not have the output noise problem of 5e, but instead sacrifices Fullness. (...) Simply put, it is a more conservative model&rdquo; unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- To get rid of noise in INSTV6N, use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/denoisedebleed.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742052544&amp;usg=AOvVaw0h3TFgUACEWTUMOZQDG8Ar">denoisedebleed.ckpt</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742052689&amp;usg=AOvVaw0lDtW59meDA8T8zqkIuK9X">yaml</a></span><span>) on mixture first, then use INSTV6N - &ldquo;for some reason it gives cleaner results&rdquo; (Gabox)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New Gabox model released: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/INSTV6N.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742053112&amp;usg=AOvVaw0uaT0AF9OMbGzycgTaG5dj">INSTV6N</a></span><span>&nbsp;(noisy) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742053264&amp;usg=AOvVaw0_6pd0XwdP4Y2p7krdAEWq">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742053478&amp;usg=AOvVaw1KWm-sXX_MFk4MXdqAvnaj">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742053644&amp;usg=AOvVaw2zhwSh6HAGzlKs3WSe8AgA">SESA</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7915&amp;sa=D&amp;source=editors&amp;ust=1765035742053793&amp;usg=AOvVaw0n-TDxUJqrxv9a3ZTmHBT6">metrics</a></span><span class="c0">: <br>inst bleedless: 32.63, fullness: 41.68 (more than v1e)<br>Interestingly, some people find it having less noise vs v1e, and more fullness.<br>Also, it has more fullness vs INSTV6, and more noise.<br>&ldquo;v1e sounds like an &quot;overall&quot; noise on the song, while v6n kind of mixes into it.</span></p><p class="c1"><span class="c0">v6n also sounds like two layers, one of noise that&#39;s just there. And the other one mixes into the song somehow.</span></p><p class="c1"><span>Using the phase swap barely makes it any better than phase swapping with v1e though&rdquo; - vernight<br>Also Kim model for phase swap seems to give less noise than unwa ft2 bleedless<br><br>- Demudder in UVR using at least DirectML (Intel/AMD) works only if &quot;Match freq cut-off&quot; is enabled in MDX settings. Otherwise, you&rsquo;ll get &ldquo;Format not recognised&rdquo; error.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- SESA Colab might undergo some issues with hyper_connections at the moment.<br>It might be fixed tomorrow.<br>- Done</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742056133&amp;usg=AOvVaw26QKFkXzqCmOgo9oEhdxUF">SESA </a></span><span class="c0">Colab update:<br>Voc_Fv3 (by Gabox)</span></p><p class="c1"><span class="c0">dereverb_mel_band_roformer_mono (by anvuew) </span></p><p class="c1"><span class="c0">MelBandRoformer4StemFTLarge</span></p><p class="c1"><span class="c0">INSTV5N (by Gabox) </span></p><p class="c1"><span class="c0">denoisedebleed (by Gabox)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/denoisedebleed.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742057044&amp;usg=AOvVaw1hIUt6-5F2xiflTjziv0jS">denoisedebleed.ckpt</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742057234&amp;usg=AOvVaw1soQH0MxeNuyuCo_7tYIwA">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742057380&amp;usg=AOvVaw3Kw96LqLJTzG5ateV7JNbu">Colab</a></span><span>&nbsp;for noise from fullness models (tested on v5n) - it can&#39;t remove vocal residues</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aname released small inst/voc 200MB Mel-Roformer with null target stem (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/Mel_Band_Roformer_small/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742057851&amp;usg=AOvVaw0LLkLNu9I_rLpGVH5EWOA2">link</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/INSTV5N.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742058104&amp;usg=AOvVaw0UCDEzfLYeiQfNxJs0Ijhl">v5_noise</a></span><span>&nbsp;inst model released | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742058269&amp;usg=AOvVaw0TPRouT59z4sFuivlczdsm">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7884&amp;sa=D&amp;source=editors&amp;ust=1765035742058361&amp;usg=AOvVaw1mLf-M8LPWuOXtwSfKZcMk">metrics</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742058488&amp;usg=AOvVaw1m9UiY0VuYwrnd8uUOW8bE">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New Gabox vocal model released: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_Fv3.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742058756&amp;usg=AOvVaw3GyazRhIlTpuiM14IN9c0n">voc_Fv3.ckpt</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742058894&amp;usg=AOvVaw1Ug5-D95kKSyDU30RHy0b3">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742059078&amp;usg=AOvVaw3H1SmHr_4X5SJTEfUpuDGX">Colab</a></span></p><p class="c1"><span class="c0">Enthusiastic opinions so far</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/instrumental&amp;sa=D&amp;source=editors&amp;ust=1765035742059365&amp;usg=AOvVaw0GnwUFIAuX7EjpUpXpQiWU">INSTV6</a></span><span>&nbsp;by Gabox and De-reverb (Mono) by anvuew models added on x-minus | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742059659&amp;usg=AOvVaw1VQlA9ACTqsYi1l6Zf2Wrb">Colab</a></span><span><br>V6 &ldquo;is slightly better than v5&rdquo; (although not for everyone), but &ldquo;v1e still gives better fullness, but noise [in v1e] is a problem&rdquo; old viperx 12xx models have less problems with sax.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (added on MVSEP as SDR 13.72) ZFTurbo trained new SCNet XL model for drums.</span></p><p class="c1"><span class="c0">&ldquo;I have 2 versions: one is slightly higher SDR and avg Bleedless. </span></p><p class="c1"><span>Second is better for fullness and L1Freq.<br>Previous best SDR model had 13.01 (it&#39;s SCNet Large).&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1338528118973005855&amp;sa=D&amp;source=editors&amp;ust=1765035742060578&amp;usg=AOvVaw2VD9yA-alSh00cU9CZa1r1">Metrics</a></span></p><p class="c1"><span class="c0">15.7180 (13.72) one has much better fullness metric.</span></p><p class="c1"><span class="c0">&ldquo;It&#39;s far superior to the other one, but I still hear some weird parts.</span></p><p class="c1"><span class="c0">It still messes up on some percussion.</span></p><p class="c1"><span class="c0">The drums stem sounds really weird.</span></p><p class="c1"><span>The no drums is alright except for some bleeding but yeah the drums is quite muddy&rdquo; - insling</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released new fine-tunes of his inst Mel-Roformer models (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/instrumental&amp;sa=D&amp;source=editors&amp;ust=1765035742061536&amp;usg=AOvVaw1K3H12642LPp6dkgXkxzli">click</a></span><span class="c0">):<br>inst_gabox2.ckpt, inst_gabox3.ckpt. INSTV5.ckpt. INSTV6.ckpt<br>with one opinion that the last one is his best inst model so far. <br>&ldquo;seems like a mix between brecuily and unwa&#39;s models&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;confuses way less instruments for vocals than v1e, but it&#39;s still not as full as v1e (...) But it&#39;s a very good model&rdquo;</span></p><p class="c1"><span class="c0">Rarely it can give &ldquo;Run out of input error&rdquo; in UVR when installing using the new Model install option (moved model has 0 bytes), while V5 worked correctly, then move the ckpt to Ultimate Vocal Remover\models\MDX_Net_Models manually.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- We&rsquo;re aware that the x86-64 version of the latest UVR patch for Mac went offline.<br>Anjok was pinged about it.<br></span></p><p class="c1"><span>- anvuew released new </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/blob/main/dereverb_mel_band_roformer_mono_anvuew_sdr_20.4029.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742062924&amp;usg=AOvVaw1Kv1f5-XNQvFPUDgFU5184">dereverb_mel_band_roformer_mono_anvuew_sdr_20.4029</a></span><span class="c0">&nbsp;model.<br>&ldquo;supports mono, but ability to remove bleed and BV is decreased<br>should not matter whether it&#39;s singing or speech, because my dataset contains speech.&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742063318&amp;usg=AOvVaw3M1JaKNJSWeIhwX4dNiYqD">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MedleyVox Colab is currently broken (you can use MVSEP instead)</span></p><p class="c1"><span class="c0">&gt; fixed:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/10x8mkZmpqiu-oKAd8oBv_GSnZNKfa8r2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742063813&amp;usg=AOvVaw07zNAAgxIDVDShXExIDHKI">https://colab.research.google.com/drive/10x8mkZmpqiu-oKAd8oBv_GSnZNKfa8r2?usp=sharing</a></span><span>&nbsp;(although initialization now takes 7 minutes, GDrive integration added)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Phase remix functionality was added to SESA model inference Colab</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035742064350&amp;usg=AOvVaw1R6yDKfGebHYhXmWsTB0ka">https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (MVSEP) ZFTurbo added new SCNet XL &ldquo;high fullness&rdquo; and &ldquo;very high fullness&rdquo; models on the site (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/ahLe1Cz&amp;sa=D&amp;source=editors&amp;ust=1765035742064649&amp;usg=AOvVaw2e_LSE9eG5SqB28jbhaOfC">metrics</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">They&rsquo;re good for both vocals and instrumentals, and sometimes are fuller than v1e, although with more noise, which can be too strong for some people, but not all.</span></p><p class="c1"><span class="c0">&ldquo;very high fullness&rdquo; variant have both vocals and instrumental fullness and bleedless metric better than the &ldquo;high fullness&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;they also correctly detect &quot;complex&quot; (for the AI) instruments as part of the instrumental track rather than in vocals (like flute or sax for example), which isn&#39;t the case for v1e and Fv5. Example: sax solo of Shine On You Crazy Diamond detected the sax solo as part of acapella using v1e or Fv5 or becruily inst.&rdquo; dca100fb8</span></p><p class="c1"><span class="c0">The noise &quot;gonna go nuts with distortion, compression and other vct plugins&quot; John. </span></p><p class="c1"><span class="c0">Both variants &quot;have the same amount of buzzing noise&quot; </span></p><p class="c1"><span class="c0">&quot;Instrumentals are very good. It&#39;s holy shit level. Unwa v1e/Gabox Fv5 are still amazing, it&#39;s just nice to have such a decent model like these new ones on a different arch&quot; dca</span></p><p class="c1"><span class="c0">From the songs I&rsquo;ve tested, SCNet is incredible. Very full sounding&quot; mrmason347 </span></p><p class="c1"><span class="c0">&quot;Regular high fullness though has a less full instrumental but quite good acapella&quot; theamogusguy</span></p><p class="c1"><span class="c0">VHF leaves some vocal residues in metal, but seems to do well for e.g. alt-pop.</span></p><p class="c1"><span class="c0">&quot;scnet doesn&#39;t pick up the drone backing vocals, but 10.2024 has mad violin bleed in the vocals&quot; dynamic64</span></p><p class="c1"><span class="c0">For &quot;mainly orchestral tracks with choir&quot; &quot;it gave me noticeably fuller results than v1e&quot; Shintaro5034.</span></p><p class="c1"><span class="c0">&quot;For noisy/dense mixes though, Roformers are probably better, especially for inst.</span></p><p class="c1"><span class="c0">scnet seems better at preserving treble in some vocals. These high fullness models especially so. So maybe teaming SCNet up with Roformer might give a nice middle ground&quot;</span></p><p class="c1"><span class="c0">&ldquo;Rofos are really bad for some kinds of EDM that are very aggressive (Dubstep, Trance, Breakcore, etc...), also it has a very hard time with Experimental (IDM)&rdquo;</span></p><p class="c1"><span class="c0">VHF seems to have more crossbleed in some songs, along with also basic XL model. Some songs which sound full enough even with basic SCNet XL. While others sound muddy (dca)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (X-Minus) Mel Kim model has been replaced for phase correction by Unwa&rsquo;s Kim FT2 model for premium users</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New </span><span class="c4"><a class="c3" href="#h.ataywcoviqx0">sites and rippers</a></span><span class="c0">&nbsp;added:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://yams.tf/&amp;sa=D&amp;source=editors&amp;ust=1765035742068679&amp;usg=AOvVaw2LF5Uoj_xP1vkwrwjBvuew">https://yams.tf/</a></span><span>&nbsp;</span><span class="c0">(Qobuz, Tidal, Spotify, Apple Music [currently 320kbps], Deezer) - for URLs</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://us.deezer.squid.wtf/&amp;sa=D&amp;source=editors&amp;ust=1765035742068966&amp;usg=AOvVaw27gUcpK_2pTQYggG_5PvSO">https://us.deezer.squid.wtf/</a></span><span>&nbsp;</span><span class="c0">(Deezer only) - for queries</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ImAiiR/QobuzDownloaderX&amp;sa=D&amp;source=editors&amp;ust=1765035742069196&amp;usg=AOvVaw033mnGhR1kKJ9v8i63W1WT">https://github.com/ImAiiR/QobuzDownloaderX</a></span><span>&nbsp;</span><span class="c0">(local ripper for premium accounts or provided ARLs)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jakeoneijk/FlashSR_Inference&amp;sa=D&amp;source=editors&amp;ust=1765035742069508&amp;usg=AOvVaw14RNC2mpbBX0oZZo5tMffJ">FlashSR</a></span><span>&nbsp;has been released (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/FlashSR-Colab-Inference/blob/main/FlashSR_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742069706&amp;usg=AOvVaw10bC05VFk9t4w7Sv1NvvSQ">Colab</a></span><span class="c0">&nbsp;with chunking and overlap by jarredou). </span></p><p class="c1"><span>It&rsquo;s a diffusion distillation of AudioSR, and has lower Aura MR STFT </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard/super_res_music/?sort%3Drestored&amp;sa=D&amp;source=editors&amp;ust=1765035742070017&amp;usg=AOvVaw0OexsUhHm0DRlAmANo1HjT">metric</a></span><span>, </span><span class="c0">and usually lower quality as well, but it might give better results for music for some people</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;We trained new DrumSep models (5 stem and 6 stem) based on SCNet XL.</span></p><p class="c1"><span class="c0">* 5 stems: cymbals, hh, kick, snare, toms</span></p><p class="c1"><span class="c0">* 6 stems: ride, crash, hh, kick, snare, toms&rdquo;</span></p><p class="c1"><span class="c0">Both have better SDR than the previous MDX23C model by jarredou and Aufr33.</span></p><p class="c1"><span>The 5 stems variant has e.g. better snare SDR than the 6 stems variant. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1334429689527402567&amp;sa=D&amp;source=editors&amp;ust=1765035742070954&amp;usg=AOvVaw3F7UQUmatrk7Z8tzNHNMrd">Full metrics</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">It doesn&#39;t work correctly on the site yet, it will be announced in the link above by ZFTurbo when it will be fixed.</span></p><p class="c1"><span class="c0">- They work already</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released ft2 bleedless vocal model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742071463&amp;usg=AOvVaw24rrDwgxt0w3-a7-M7tjvN">Colab</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742071690&amp;usg=AOvVaw2ncgl94_5haE6XnPGAUDdf">https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main</a></span></p><p class="c1"><span class="c0">voc bleedless 39.30 | fullness 15.77 | SDR 11.05</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- instv5 model released by Gabox (39.40 inst fullness | inst. bleedless 33.49) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/instrumental&amp;sa=D&amp;source=editors&amp;ust=1765035742072103&amp;usg=AOvVaw3INpiwZLAMsgc-sDDACMT-">link</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-instrumental/resolve/main/config_instrumental_becruily.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742072243&amp;usg=AOvVaw2ZgP4tt_MHqtHOgJeL2yDe">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742072364&amp;usg=AOvVaw0i3Kxd3-1ydpa6qYBL1HPE">Colab</a></span><span class="c0">&nbsp;| x-minus</span></p><p class="c1"><span class="c0">&ldquo;it seems that most vocal leakage is gone, and the noise did significantly decrease, although there&#39;s still a bit more noise presence than v1e.</span></p><p class="c1"><span class="c0">In terms of fullness though, for some reason it sounds as if it&#39;s actually less full than v1e, despite the higher instrumental fullness SDR.</span></p><p class="c1"><span class="c0">Despite v4&#39;s significant amount of noise, it seems to be the only model that gave me a fuller sounding result compared to v1e that&#39;s actually perceivable by my ears.&rdquo; Shintaro</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New inst/voc SYH99999 models released</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/SYH99999/MelBandRoformerSYHFTB1/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742073533&amp;usg=AOvVaw13m9MrqIiCnSvA0sFVWako">https://huggingface.co/SYH99999/MelBandRoformerSYHFTB1/tree/main</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus) Phase fixer added for Gabox fv3 and becruily models for premium users</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For vocals, you can alleviate some of the noise/residues in unwa&rsquo;s 5e model by using phase fixer/swapper and using becruily vocals model as a reference (imogen).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For instrumentals, you can try unwa&#39;s v1e with phase swap at 500/500 with original mel band of kim. It consistently gives less noise - midol</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;500 / 500 means you use original phase below 500 Hz and hard cutoff/swap to transferred phase above 500hz. (this can potentially create phase artifacts at 500Hz because of hard swap)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">500 / 20000 means you use original phase below 500hz and progressively crossfade to transferred phase until 20000hz and transferred phase is used above 20000hz. So it&#39;s softer phase swap below 20kHz&quot; - jarredou<br><br>&ldquo;using 500 on both parameters really does make me have the illusion that I have produced the official instrumental. Even tho it&#39;s unofficial haha&rdquo; - midol</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Deezer on Lucida doesn&rsquo;t work. Doubledouble.top came back (probably temporarily), but returns mp3 128kbps from Deezer now. Also, it supported Apple Music unlike Lucida, but now it doesn&rsquo;t work, (check current services </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://doubledouble.top/stats/&amp;sa=D&amp;source=editors&amp;ust=1765035742075823&amp;usg=AOvVaw0V4kBbeJJ1H2OKdwP6zSOw">status</a></span><span class="c0">). Besides, occasionally it can happen that rips from Amazon only on doubledouble have quality higher than 44/16. Plus, downloading full albums frequently fails, swhile single songs downloading works.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Lots of new Gabox models added since then, including: </span></p><p class="c1"><span>a) BS-Roformer instrumental variant, which doesn&rsquo;t struggle so much with choirs like most Mel-Roformers, although may not help in all cases (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/BSRoformerVocTest/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742076617&amp;usg=AOvVaw3s4KPoQIlPxLioy6AkuHbx">link</a></span><span class="c0">) </span></p><p class="c1"><span>b) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gaboxFv3.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742076840&amp;usg=AOvVaw20OFHu4uEwhdo8DDaM7Rsq">inst_gaboxFv3.ckpt</a></span><span class="c0">&nbsp;- like v1e when it comes to fullness (added on x-minus)</span></p><p class="c1"><span>Inst SDR 16.43 | inst. fullness 38.71 | inst. bleedless 35.62<br>It might pick up entire sax in vocal stem.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox models have been added to SESA </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742077408&amp;usg=AOvVaw0i1tTvfRoeazvyaXJVQmzd">Colab</a></span><span>&nbsp;(you&rsquo;ll find more info about them later below). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Along with UVR Roformer beta patch #14, Anjok released the long anticipated </span><span class="c22">demudder</span><span class="c0">.<br>It&#39;s in Settings &gt; Advanced MDX options (so works only for Roformers and MDX models).<br>It consists of three methods to choose from (each separates your twice): </span></p><p class="c1 c8"><span class="c0">- Phase Rotate</span></p><p class="c1 c8"><span class="c0">- Phase Remix (Similar to X-Minus) - &ldquo;the fullest sounding, but can leave a lot of artifacts with certain models. I only recommend that method for the muddiest models. Otherwise, Combined Methods is the best&rdquo; &ldquo;I don&#39;t recommend using phase remix on the Instrumental v1e model. I recommend combined methods or phase rotate for models produce fuller instrumentals.&rdquo; Anjok<br>It might leave some choruses when using V1E (Fabio)</span></p><p class="c1 c8"><span>- Combine Methods (weighted mix of the final instrumentals generated by the above). More in the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1331189771078471721&amp;sa=D&amp;source=editors&amp;ust=1765035742079032&amp;usg=AOvVaw2ma_hZo6gfhpaoAOyz1MdD">full changelog</a></span><span class="c0">. You cannot use demudder on 4GB AMD GPUs with 800MB Roformers with even 2 seconds chunk size set (memory allocation error).</span></p><p class="c1"><span class="c0">&ldquo;It&#39;s meant to solely target instrumentals. The vocals should stay exactly as before.<br>For Roformer models, it must detect a stem called &quot;Instrumental&rdquo; so for some models like Mel-Kim, you need to open model&rsquo;s corresponding yaml, and change &ldquo;other&rdquo; to &ldquo;instrumental&rdquo;.</span></p><p class="c1"><span class="c0"><br>&ldquo;I&#39;ve noticed with the few amounts of tracks I&#39;ve tried, demudding can sometimes accentuate instances of bleeding or otherwise entirely missed vocal-like sounds&rdquo;</span></p><p class="c1"><span class="c0"><br>In case of file not found error on attempt of using demudder, reinstall UVR.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I put the demudded instrumental in the bleed suppressor, and it sounds really good, almost noise free. I either do a bleed suppressor or a V1/bleed suppressor ensemble&rdquo; gilliaan</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;With the new config editor feature you could probably edit the configs of models to have the vocal stem labelled as the Instrumental stem so the demudder demuds the vocal stem, it definitely still makes a difference.</span></p><p class="c1"><span class="c0">I accidentally did this when installing another model, but it seems to actually have an effect on vocal stems too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You just change the target instrument from vocals to instrumental I think (don&#39;t move the stems around) </span></p><p class="c1"><span class="c0">You can verify it works if the stems are the other way around when processing (vocals are in the file labelled as Instrumental). Then you can use the demudder on the vocals that way</span></p><p class="c1"><span class="c0">I think. If you want to use the demudder with other models that aren&#39;t labeled with instrumental, you&#39;ll have to select the stem you want to demud and replace it with Instrumental.</span></p><p class="c1"><span>Though demudding the vocal stem will definitely make it quite noisy depending on what model you use, though there </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1331633822088954010&amp;sa=D&amp;source=editors&amp;ust=1765035742082198&amp;usg=AOvVaw2i4Kw0GTzglGC-q0297C0A">appears</a></span><span class="c0">&nbsp;to be instances where demudding the vocal stem can mildly help with certain effects but i did not test this enough&rdquo; stephanie</span></p><p class="c1"><span class="c0"><br>Anjok: &ldquo;Just a few quick notes on the Demudder:</span></p><p class="c1"><span class="c0">It works best on tracks that are spectrally dense (ex. Metal, Rock, Alternative, EDM, etc.)</span></p><p class="c1"><span class="c0">I don&#39;t recommend it for acoustic or light tracks.</span></p><p class="c1"><span class="c0">I don&#39;t recommend using it with models that emphasize fuller instrumentals (like Unwa&#39;s v1e model).</span></p><p class="c1"><span class="c0">I do plan on adding options to tweak the phase rotation.</span></p><p class="c1"><span>I also plan on adding another combination method that may work better on certain tracks.&rdquo;<br></span></p><p class="c1"><span>UVR_Patch_1_21_25_2_28_BETA:<br>Small patch (you must have a </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">Roformer Patch</a></span><span>&nbsp;[e.g. #13]</span><span>&nbsp;previously installed for this to work): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_21_25_2_28_BETA_small_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742083762&amp;usg=AOvVaw2m0F_pD59UY_fKMPX_GRqy">Link</a></span><span><br>Also, minor bugs fixed, calculate compensation for MDX-Net v1 models added.<br>The MacOS version will be released later (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1331189771078471721&amp;sa=D&amp;source=editors&amp;ust=1765035742084058&amp;usg=AOvVaw3_lG2VI-sMsoXjROADimml">observe</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">Be aware that at least Phase Rotate doesn&rsquo;t work on AMD and 4GB VRAM GPUs on even 88200 chunk size (prev. dim_t 201 - 2 seconds) and 800MB Roformers like Becruily&rsquo;s, while 112455 (2,55s, prev. dim_t = 256) works just fine for normal separation.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- BS-RoFormer 4 stems model by yukunelatyh / SYH99999 added on x-minus</span></p><p class="c1"><span class="c0">Since then, a new version was added (later epoch, but it has lower SDR for all stems).</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742084921&amp;usg=AOvVaw2_r6_8G_r_yjazdyu1VTW4">https://uvronline.app/ai?discordtest</a></span><span class="c0"><br>Some people liked the v1 more than Demucs, but &ldquo;it&#39;s like demucs v4 but worse i think</span></p><p class="c1"><span class="c0">the vocals have a ton of bleed, the bass is disappointing tbh</span></p><p class="c1"><span>the other stem has a ton of bgv and adlib bleed in it&rdquo; Isling<br>It has </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/O2qDgTQ&amp;sa=D&amp;source=editors&amp;ust=1765035742085380&amp;usg=AOvVaw3yHyy8bXDF4NSwd6k6_t8U">SDR metrics</a></span><span class="c0">&nbsp;for all stems worse than 4 stem BS-Roformer by ZFTurbo and demuics_ft.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aname also released 4 stem BS-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/GwY1TQoB%23UmeMGO2BBtgrUXkmXXQQVXqwR_hwxaAmkycDr-fitWg&amp;sa=D&amp;source=editors&amp;ust=1765035742085709&amp;usg=AOvVaw129kwA4c5lBixHyz0fdxO8">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/Pwp32DrY%23Kyl5sK3j6l5kXCe7Br52gN2CXn9c8N6lzOYT1g0FOS0&amp;sa=D&amp;source=editors&amp;ust=1765035742085830&amp;usg=AOvVaw0_xPlugQkkb3aW5SCCHpvc">yaml</a></span></p><p class="c1"><span class="c0">It has better SDR than the above (as in the SDR metrics link above), but worse than the other two mentioned</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox released Mel-Roformer instrumental model (Kim/Unwa/Becruily FT): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers&amp;sa=D&amp;source=editors&amp;ust=1765035742086466&amp;usg=AOvVaw2-vBV6yzC3wvp-bG4bbAe8">https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers</a></span></p><p class="c1"><span class="c0">inst bleedless: 37.40 (better than v1e by 1.8), fullness 37.07 (better than unwa inst v1 and v2)<br>&ldquo;It&rsquo;s like the v1 model with phase fixer, but it gets more instruments,</span></p><p class="c1"><span class="c0">like, it prevents some instruments getting into the vocals&rdquo;, &ldquo;sometimes both models don&#39;t get choirs&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- instrumental variant called fullness v1 (&ldquo;noisier but fuller&rdquo;)</span></p><p class="c1"><span class="c0">inst bleedless: 37.19, fullness 37.26</span></p><p class="c1"><span>(thanks for evaluation to Bas Curtiz and his </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1pPEJpu4tZjTkjPh_F5YjtIyHq8v0SxLnBydfUBUNlbI/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742087467&amp;usg=AOvVaw2qlzxa-CgwRH6BU7GM3plM">GSheet</a></span><span class="c0">&nbsp;with all models.)</span></p><p class="c1"><span class="c0">- fullness v2 released</span></p><p class="c1"><span class="c0">- fullness v3 released</span></p><p class="c1"><span class="c0">- B (bleedless) v1/v2 variants released</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- voc_gabox.ckpt:</span></p><p class="c1"><span class="c0">voc bleedless: 34.66 (better than 5e), fullness 18.10 (on pair with beta 4)</span></p><p class="c1"><span class="c0">- Vocal model F v1</span></p><p class="c1"><span class="c0">- Vocal model F v2 </span></p><p class="c1"><span class="c0">voc bleedless: 33.4013, fullness: 19.3064</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Issues with dataset 4 in MSST repo were fixed <br>&ldquo;I think that issue could also explain why training de-reverb models with pregenerated reverb audio files was not working that well, as reverb was not aligned with clean dry audio as it should have been.&rdquo; jarredou (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1330983209885896757&amp;sa=D&amp;source=editors&amp;ust=1765035742088776&amp;usg=AOvVaw0Et8fvpgiWGe1lIO5OZCw8">more</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aufr33 BS-Roformer Male/Female beta (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/XZwV2QwB%235nvWpmvtoBMTJkpor-lMUZCbBZWDH-3i52ELJS_JmcU&amp;sa=D&amp;source=editors&amp;ust=1765035742089011&amp;usg=AOvVaw0Sw-wBBrmvIQXYnBRGvxrf">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Chorus_Male_Female_BS_Roformer/blob/main/config_chorus_male_female_bs_roformer.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742089161&amp;usg=AOvVaw2oHMe_Tg3l244B2omwvfXC">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/15dxMvEanC8h_djEuHoQXHKMk0ERN02_y/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742089282&amp;usg=AOvVaw0fQz3r6kX3-93R09Y8bBV7">config</a></span><span>&nbsp;for UVR</span><span class="c56">&nbsp;| tensor match error </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nomadkaraoke/python-audio-separator/releases/download/model-configs/deverb_bs_roformer_8_384dim_10depth_config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742089501&amp;usg=AOvVaw3BqSe8sj6Z8iEFgkzv6HGo">fix</a></span><span>)</span><span>&nbsp;added on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742089719&amp;usg=AOvVaw0Mfg_c2y7EUzifu0UbLYhP">Colab</a></span><span class="c0">&nbsp;(based on BS-RoFormer Chorus Male Female by Sucial) along with Unwa&rsquo;s Kim FT2</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Anjok released the MacOS versions of UVR Roformer beta patch #13.1 applying hotfix to address a few graphics issues:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mac M1 (arm64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_arm64_hf.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742090333&amp;usg=AOvVaw3aatJ18i7HxCUlJ8_yBdl2">Link</a></span></p><p class="c1"><span>- Mac Intel (x86_64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_x86_64_hf.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742090577&amp;usg=AOvVaw3y6pu5J-TFovt4yVMkOEOM">Link</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Anjok released UVR beta Roformer patch #13 for Mac (Windows further below):<br></span></p><p class="c1"><span>U</span><span class="c0">VR_Patch_1_15_25_22_30_BETA:</span></p><p class="c16 c1"><span>- Mac M1 (arm64) users -</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742091103&amp;usg=AOvVaw2EBbXMdl1MM5BDKs_A1ExL">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742091242&amp;usg=AOvVaw1ScbrzGno_2XjRCtD-DMs_">Link</a></span></p><p class="c16 c1"><span>- Mac Intel (x86_64) users -</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742091509&amp;usg=AOvVaw2sbhLNVVDUtz6o7c55_UX3">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742091706&amp;usg=AOvVaw0az3HvEPcNgJR8SRbwbctS">Link</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- mesk wrote a good comprehensive </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/12KzNIojKSWLA7uvHhhxydXvBLZgussewc1aRzWxqGwY/edit&amp;sa=D&amp;source=editors&amp;ust=1765035742092014&amp;usg=AOvVaw3d5pwaQGt5DVnlb7O7sMJB">training guide</a></span><span>&nbsp;for beginning model trainers. Later you can proceed to read further </span><span class="c4"><a class="c3" href="#h.bg6u0y2kn4ui">section</a></span><span>&nbsp;</span><span class="c0">of this doc for more details and arch explanations</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Apple Music bot link added in </span><span class="c4"><a class="c3" href="#h.ataywcoviqx0">this</a></span><span>&nbsp;</span><span class="c0">section (thx mesk)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- mrmason347 and Havoc shared an interesting method to get cleaner vocals. The last point of tips to enhance separation </span><span class="c4"><a class="c3" href="#h.929g1wjjaxz7">here</a></span><span>:<br>Separate with becruily Mel Vocal model and its instrumental model variant, then get vocals from the vocal model, and instrumental from instrumental model, import both stems for the DAW of your choice (can be Audacity) so you&rsquo;ll get a file sounding like original file, then export - perform a mixdown of both stems, then separate it with vocal model <br><br>- If you somehow still struggle with &ldquo;norn&rdquo; issues in UVR, see at the bottom of the section </span><span class="c4"><a class="c3" href="#h.c4nrb8x886ob">here</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Dango released &ldquo;Reverb Remover&rdquo; - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tuanziai.com/en-US/de-reverb&amp;sa=D&amp;source=editors&amp;ust=1765035742093760&amp;usg=AOvVaw3W-hudJaxQOwqqzRoUFWTC">click</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">&ldquo;it&#39;s very similar to RX11 Dialogue Isolate, good/real-time set to 5</span></p><p class="c1"><span class="c0">it&#39;s like listening to the same inference files&rdquo; John; probably also works in mono, you can get 30 seconds for free)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://filegarden.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742094334&amp;usg=AOvVaw3rioEm2CxMGTcHRg41b1nc">filegarden</a></span><span>&nbsp;added to the </span><span class="c4"><a class="c3" href="#h.5haztbxg91rt">list of cloud services</a></span><span>&nbsp;(seems to be unlimited, registration required, link shortener with custom name available) <br>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1325284373087391845&amp;sa=D&amp;source=editors&amp;ust=1765035742094720&amp;usg=AOvVaw3DLRkswAay3aOl_ejQUfte">your-good-results</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1325284456382075041&amp;sa=D&amp;source=editors&amp;ust=1765035742094847&amp;usg=AOvVaw0wlbu2K6NIDGMB-EbDI7eS">your-bad-results</a></span><span class="c0">&nbsp;channels have been reopened on the server, but you need to paste links to uploads instead of uploading audio files directly on Discord due to copyright issues the server was undergoing</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you want to use Phase fixer Colab with cut-offs suggested by CC Karaoke, check </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/14HIQRhOcMmC8RCKUzo_t-ogIfjORbs2K&amp;sa=D&amp;source=editors&amp;ust=1765035742095450&amp;usg=AOvVaw3jy3s0Ivu2OeRdVTPXnL3w">here</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa&rsquo;s Kim FT2 model added to the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742095780&amp;usg=AOvVaw3XJA7jRglqkCLUbCadGTxu">inference Colab </a></span><span class="c0">(both inst and voc becruily models are added too)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- jarredou released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference)_CustomModel.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742096229&amp;usg=AOvVaw15DJmmVf-6dNdoNlO8ZlPv">Custom Model Import</a></span><span class="c0">&nbsp;Version of the inference Colab. You can use it if we don&rsquo;t add any new model to the main Colab on time, or you test your own models.<br><br>Just make sure that pasted link haven&rsquo;t &ldquo;downloaded the webpage presenting the model instead of the model itself.&rdquo;</span></p><p class="c1"><span class="c0">So, e.g. for yamls pasted from GH, use:<br>https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/main/configs/config_vocals_mdx23c.yaml&#39;</span></p><p class="c1"><span class="c0">Instead of:<br>https://github.com/ZFTurbo/Music-Source-Separation-Training/main/configs/config_vocals_mdx23c.yaml&#39;<br>And for HF, follow the pattern presented in the Colab example (so with the resolve in the file address)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer/blob/main/scripts/model_fusion.py&amp;sa=D&amp;source=editors&amp;ust=1765035742097432&amp;usg=AOvVaw3wGx1g0IV0iYMiZ_IFYZO4">model_fusion.py</a></span><span class="c0">&nbsp;by Sucial</span></p><p class="c1"><span class="c0">This script seems to save the weighted ensemble of three models into a checkpoint called &quot;fused&quot;. The result is not bigger than a single model.</span></p><p class="c1"><span class="c0">Probably you could basically create one checkpoint getting the same or similar results of manually weighted models, and not inference every of them one by one.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Becruily models added on MVSEP and instrumental on variant on x-minus</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- ZFTurbo &ldquo;added new organ model: MVSep Organ (organ, other).</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250116160630-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035742098532&amp;usg=AOvVaw0_xpV3sL3MYCXTHx2NVJ44">https://mvsep.com/result/20250116160630-f0bb276157-mixture.wav</a></span><span>&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Anjok released a patch #13 fixing following issue with no sound on some Roformer models (like avvuew&rsquo;s and sucial&rsquo;s de-reverb) on GTX 10XX or older (Windows):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR_Patch_1_15_25_22_30_BETA:</span></p><p class="c16 c1"><span>&ldquo;- Full Install:</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_1_15_25_22_30_BETA_full.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742099215&amp;usg=AOvVaw1zdCTN3_xhYhsIqlDtMwlZ">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_1_15_25_22_30_BETA_full.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742099339&amp;usg=AOvVaw3CJM2xxZbIkU5FUcH5IneA">Link</a></span></p><p class="c16 c1"><span>- </span><span>Patch Install (use if you still have non-beta UVR installed):</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_Patch_1_15_25_22_30_BETA_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742099625&amp;usg=AOvVaw2aBjdmFha80ygL6jQVNb2T">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_Patch_1_15_25_22_30_BETA_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742099743&amp;usg=AOvVaw11lfTRRvADP4LE3UdfUKzK">Link</a></span></p><p class="c16 c1"><span>- </span><span>Small Patch Install (have a Roformer patch previously installed for this to work):</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_15_25_22_30_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742100083&amp;usg=AOvVaw3cKWgbWoIvs-nEnmOEFNOH">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_15_25_22_30_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742100240&amp;usg=AOvVaw1punmv9AqTSzbCa19pdNmo">Link</a></span></p><p class="c16 c1"><span class="c0">The issue was some older GPU&#39;s are not compatible with Torches &quot;Inference Mode,&quot; (which is apparently faster) so it&#39;s now using &quot;No Grad&quot; mode instead. Users can switch back to using &quot;Inference Mode&quot; via the advanced multi-network options.</span></p><p class="c16 c1"><span>The MacOS version will be released in a few days. I just need to finish testing out all the models and networks and ensure all the kinks are worked out.&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1329312294521405493&amp;sa=D&amp;source=editors&amp;ust=1765035742101111&amp;usg=AOvVaw3s-OSINAeaKVyKObMrDON5">More</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Users undergo some issues (no sound) with Mel-Roformer de-reverb by anvuew (a.k.a. v2/19.1729 SDR) since the latest UVR beta #11/12 updates (the issue seems to occur only on GTX 10XX series, and maybe older). Anjok&rsquo;s working on the issue.</span></p><p class="c1"><span class="c0">You should be able to use more than one UVR installation at the same time when one&rsquo;s been copied before updating (patch #10 still works) or use MSST repo and/or its GUIs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anjok released patch #12 which is a hotfix for the </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">4 stem</a></span><span class="c0">&nbsp;BS-Roformer model by ZFTurbo (trained on MUSDB)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_13_0_23_46_BETA_rofo_fixed.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742102394&amp;usg=AOvVaw2aF9MQoUxIBV9ZlyDqHG_T">UVR_Patch_1_13_0_23_46_BETA_rofo_fixed.exe</a></span><span>&nbsp;(Windows only)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Anjok released a new UVR beta Roformer patch #11 (Windows only for now):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR_Patch_1_13_0_23_46_BETA_rofo</span></p><p class="c1"><span class="c0">It fixes 4 bugs: with VR post-processing threshold, Segment default in multi-arch menu, CMD will no longer pop-in during operations, and error in phase swapper.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1328267582871961620&amp;sa=D&amp;source=editors&amp;ust=1765035742103262&amp;usg=AOvVaw1Rd3tVaPjW0VGsdZR4XQqm">More</a></span><span>&nbsp;</span><span class="c0">details/potential updates.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Standalone (for non-existent UVR installation)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_1_13_0_23_46_BETA_full.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742103728&amp;usg=AOvVaw1drUCQa2RAMO-NIOuC3Uad">UVR_1_13_0_23_46_BETA_full.exe</a></span></p><p class="c1"><span class="c0">For 5.6 stable (so for non-beta Roformer installation)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_Patch_1_13_0_23_46_BETA_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742104118&amp;usg=AOvVaw3ulyaE0ET6vgKSiudwmjM7">UVR_Patch_1_13_0_23_46_BETA_rofo.exe</a></span></p><p class="c1"><span class="c0">Small (for already existing Roformer beta patch installation)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_13_25_0_23_46_rofo_small_patch.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742104516&amp;usg=AOvVaw3obxqja5YxjWuKeTQ5Ydmn">UVR_Patch_1_13_25_0_23_46_rofo_small_patch.exe</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New beta UVR Roformer patch #10 released by Anjok (for now, only small patch for already existing </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta Roformer</a></span><span>&nbsp;installation is available, and only for Windows, check </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1327237549114261524&amp;sa=D&amp;source=editors&amp;ust=1765035742104983&amp;usg=AOvVaw1IeHVk4eWPYb7v6iJfPpRs">here</a></span><span class="c0">&nbsp;for Mac later)</span></p><p class="c1"><span><br>UVR_Patch_1_9_25_23_46_BETA_rofo_small_patch - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_9_25_23_46_BETA_rofo_small_patch.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742105270&amp;usg=AOvVaw1OWv6zsN3FcPHCGnc_gPnT">Link</a></span></p><p class="c1"><span class="c0">Added SCNet and Bandit archs with models in Download Center (SCNet models using ZFTurbo&rsquo;s unofficial code update will not work since they appear to require a library &quot;mamba_ssm&quot; that is only available in Linux), fixed compatibility with some newer Roformer models (wesley&rsquo;s MDX23C and Roformer Phantom center models, and 400MB inst small by Unwa), new Model Installer option added, model configuration menu enhanced, allowing aliases to selected models, added compatibility for Roformer/MDX23C Karaoke models with the vocal splitter, VIP code issue is gone, issues with secondary models options and minor bugs and interface annoyances are addressed, &ldquo;improved the &quot;Change Model Settings&quot; menu. Now, any existing settings associated with a selected model are automatically populated, making it easier for users to review and adjust settings (previously, these settings were not visible even if applied).&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you have Python DLL error on startup, reinstall the last beta update using the full package instead, then the small installer from the newer patch.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;If you see a different usage of VRAM than with previous Roformer beta version, it could also be because the new beta version doesn&#39;t rely on &#39;inference.dim_t&#39; value anymore (if you were using edited &quot;dim_t&quot; value)</span></p><p class="c1"><span>You have to edit audio.chunk_size now (see </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1324901146002849925&amp;sa=D&amp;source=editors&amp;ust=1765035742107750&amp;usg=AOvVaw3VrSV5SmHb5hJd8j3L2fyY">here </a></span><span class="c0">for conversion between dim_t and chunk_size&rdquo; it&rsquo;s &ldquo;In model yaml config file, at top of it, chunk_size is first parameter (...) you can edit model config files directly inside UVR now.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Unfortunately, SCnet is not compatible with DirectML, so AMD GPU users will have to use the CPU for those models.</span></p><p class="c1"><span class="c0">Bandit models are not compatible with MPS or DirectML. For those with AMD GPU&#39;s and Apple Silicon, those will be CPU only.</span></p><p class="c1"><span class="c0">The good news is those models aren&#39;t all that slow on CPU.&rdquo; - Anjok<br><br>Annoying CMD window will randomly pop up again when ffmpeg and Rubber Band are used. Regression will be fixed.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Newer Mel-Roformer Male/Female model was added by ZFTurbo on MVSEP (SDR: 13.03 vs 11.83 - the previous SCNet one, and much better bleedless metric 41.9392 vs 26.0247 with only 0.2 fullness decrease)<br>&ldquo; I find it acts differently from Rofo or UVR2. Sometimes it&#39;s the one of the three that gets it right., and not strictly for male/female.&rdquo; CC Karaoke</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Aufr33 released his own BS-Roformer Male/Female (currently beta) model based on BS-RoFormer Chorus Male Female by Sucial.<br>&ldquo;this model only works with vocals. You need to pre-isolate the vocals.&rdquo;</span></p><p class="c1"><span class="c0">Added on MVSEP and x-minus for premium (in the new Other menu).</span></p><p class="c1"><span>Weights: &nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/XZwV2QwB%235nvWpmvtoBMTJkpor-lMUZCbBZWDH-3i52ELJS_JmcU&amp;sa=D&amp;source=editors&amp;ust=1765035742110241&amp;usg=AOvVaw11kS_gltI2ZYIk7erjA5Eh">https://mega.nz/file/XZwV2QwB#5nvWpmvtoBMTJkpor-lMUZCbBZWDH-3i52ELJS_JmcU</a></span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Chorus_Male_Female_BS_Roformer/blob/main/config_chorus_male_female_bs_roformer.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742110714&amp;usg=AOvVaw0yaO8Ca5k0xs_w75IPWtJy">https://huggingface.co/Sucial/Chorus_Male_Female_BS_Roformer/blob/main/config_chorus_male_female_bs_roformer.yaml</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released a new version of his Mel-Kim fine-tune (ft2)<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742111137&amp;usg=AOvVaw3EZrcW7HVbYPXacinqnc0T">https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main</a></span><span class="c0"><br>It tends to muddy instrumental outputs at times, similarly like the OG Kim&rsquo;s model was doing, which didn&rsquo;t happen in the previous ft model by Unwa.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7714&amp;sa=D&amp;source=editors&amp;ust=1765035742111490&amp;usg=AOvVaw2ORGgF50XKQAcYQ0snLC6y">Metrics</a></span><span class="c0">. PS. All unwa models were trained on 3060 Ti!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released 400MB experimental BS-Roformer inst model <br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Inst-EXP-Value-Residual&amp;sa=D&amp;source=editors&amp;ust=1765035742111911&amp;usg=AOvVaw3GI5rOaGf4b3s1KuysIcX9">https://huggingface.co/pcunwa/BS-Roformer-Inst-EXP-Value-Residual</a></span><span><br>It&rsquo;s using a new Value Residual Learning added to Roformer arch by Lucidrains in the OG Roformer. If it wasn&rsquo;t made compatible with MSST repo already, replace bs_roformer.py from this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lucidrains/BS-RoFormer/tree/main/bs_roformer&amp;sa=D&amp;source=editors&amp;ust=1765035742112282&amp;usg=AOvVaw2aeIiLonnObOhFTMPToVLe">repo</a></span><span class="c0">&nbsp;and <br>from bs_roformer.attend import attend</span></p><p class="c1"><span class="c0">&#8681;</span></p><p class="c1"><span class="c0">from models.bs_roformer.attend import attend</span></p><p class="c1"><span class="c0">in bs_roformer.py file</span></p><p class="c1"><span class="c0">&ldquo;I think it sounds better than large rn but still not good, needs some [more] epoch[s]!&rdquo;</span></p><p class="c1"><span>[later the VRL was added as Roformer v2 in </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span class="c0">&nbsp;so it&rsquo;s compatible with the model]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New dereverb model(s) released by Sucial - &ldquo;fused&rdquo;: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer/blob/main/dereverb_echo_mbr_fused_0.5_v2_0.25_big_0.25_super.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742113238&amp;usg=AOvVaw2wuZewXvJo43J-C0LMK53e">model</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer/blob/main/config_dereverb_echo_mbr_v2.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742113394&amp;usg=AOvVaw39MCnl_LqhgEJJ14K22C9O">yaml</a></span><span><br>&ldquo;trained two new models specifically targeting large reverb removal. After training, I combined these two models with my v2 model through a blending process, to better handle all scenarios. At this stage, I am still unsure whether my new models outperform the anvuew&#39;s v2 model overall, but I can confidently say that they are more effective in removing large reverb.&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer&amp;sa=D&amp;source=editors&amp;ust=1765035742114064&amp;usg=AOvVaw25iv7metWEAb_QUW360RbD">More</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Becruily Mel inst and voc models added on MVSEP and inst variant on x-minus</span></p><p class="c1"><span class="c0"><br>- ZFTurbo released new models on MVSEP:<br>a) a new Male/Female separation model based on SCNet XL</span></p><p class="c1"><span class="c0">SDR on the same dataset: 11.8346 vs 6.5259 (Sucial)<br>Model only works on vocals. If the track contains music, use the option to &quot;extract vocals&quot; first. Sometimes the old Sucial model might still do a better job at times, so feel free to experiment.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">b) SCNet XL (vocals, instum)</span></p><p class="c1"><span class="c0">Inst SDR: 17.2785</span></p><p class="c1"><span class="c0">Vocals have similar SDR to viperx 1297 model, </span></p><p class="c1"><span class="c0">and instrumental has a tiny bit worse score vs Mel-Kim model.</span></p><p class="c1"><span class="c0">- &ldquo;All Ensembles on MVSep were updated with latest release [SCNet XL] increasing vocals SDR to 11.50 -&gt; 11.61 and instrum SDR: 17.81 -&gt; 17.92&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035742115730&amp;usg=AOvVaw0Axr4KiDWVZVgcRI4JXbwQ">MSST</a></span><span class="c0">) You can now inference mono files without any issue<br>- You can now use &ldquo;batch_size=1 without clicks issues (with overlap &gt;= 2 of course)&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c20">Becruily&rsquo;s released instrumental and vocal Mel-Roformer models</span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742116367&amp;usg=AOvVaw0VnG6TsEPnp-sne3XoFMtZ">Colab </a></span><span>| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span>&nbsp;beta |</span><span><br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-instrumental/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742116585&amp;usg=AOvVaw1slWLO1ONdzPdCBnP-GgNm">Instrumental</a></span><span>&nbsp;model files | Inst SDR 16.4719 | inst fullness 33.9763 | bleedless 40.4849<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-vocals/resolve/main/mel_band_roformer_vocals_becruily.ckpt?download%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035742116857&amp;usg=AOvVaw3bxbPxqjz24XvGvPqOveOX">Vocal</a></span><span>&nbsp;</span><span>model file | Vocals SDR 10.5547 | voc fullness 20.7284 | bleedless 31.2549 | <br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1V__MDSd9h47tgk3CCZUhbfcZz9A_oJee/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742117247&amp;usg=AOvVaw3rsXBFrhQdgwsRGjya-eKW">config</a></span><span class="c0">&nbsp;with ensemble fix in UVR.</span></p><p class="c1"><span>Instrumental model is as clean as unwa&rsquo;s v1, but has less noise and, and it can be got rid well by Mel </span><span class="c4"><a class="c3" href="#h.hyzts95m298o">denoise</a></span><span>&nbsp;and/or Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1zWOrzPKd-6x7vjHNqjK_bK2UOYfPzCuu/view&amp;sa=D&amp;source=editors&amp;ust=1765035742117711&amp;usg=AOvVaw22nUH_dAy5wV8tbVD6sxUr">bleed suppressor</a></span><span class="c0">. Inst variant &ldquo;removed some of the faint vocals that even the bleed suppressor didn&#39;t manage to filter out&rdquo; before&rdquo;. Doesn&rsquo;t require phase fix from Mel-Kim like unwa models below.<br>&ldquo;it handles the busy instrumentals in a way that makes VR finally an arch of the past&rdquo;<br>Correctly removes SFX voice. More instruments correctly recognized as instruments and not vocals, although not as much as Mel 2024.10 &amp; BS 2024.08 on MVSEP, but still more than unwa&rsquo;s inst v1e/v1/v2. (dca100fb8).<br>Trumpet or sax sound which on unwa model was lost, can be recovered<br>on becruily&#39;s model (hendry.setiadi)</span></p><p class="c1"><span class="c0">The instrumental model pulled out more adlibs than the released vocal model variant - it pulled out nothing (isling).<br>&ldquo;Vocal model pulling almost studio quality metal screams effortlessly. Wow, I&#39;ve NEVER heard that scream so cleanly&rdquo; (mesk)<br>The model was trained on dataset type 2 and single RTX 3090 for two days (although with months of experimentation beforehand). SDR metrics are lower than Mel-Kim model.</span></p><p class="c1"><span class="c0">If you use lower dim_t like 256 at the bottom of config for slower GPU, these are the first models to have very bad results with that setting.<br><br>You can experiment with phase fixer with santilli_ suggestion &ldquo;Using becruily&#39;s vocals as source and inst [model] as target, and changing high frequency weight from 0.8 to 2 makes for impressive results&rdquo;. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/lucassantillifuck2fa/Music-Source-Separation-Training/blob/main/Phase_Fixer.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742120141&amp;usg=AOvVaw0oiFbOa2FL_oq0L1RDO35E">Phase fixer Colab</a></span><span>&nbsp;(update 2)</span><span class="c0">&nbsp;by santilli_ released - it can use e.g. Mel-Kim model phase for unwa&rsquo;s v1e/v1/v2 models to automatically get rid of some noise during separation (it might no longer work due to the last changes in MSST repo), it includes also becruily models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- A small UVR Roformer beta patch #9 fixing mainly Apollo arch released also for Mac (UVR_Patch_12_8_24_23_30_BETA):</span></p><p class="c1"><span>Mac M1 (arm64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_1208_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742121053&amp;usg=AOvVaw2i855xxqpKSjk0fE8TiOWG">Link</a></span></p><p class="c1"><span>Mac Intel (x86_64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_1208_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742121298&amp;usg=AOvVaw2HoIf5wQIBfCfR2edAwN_H">Link</a></span><span class="c0"><br><br>- New &ldquo;MVSep Bass (bass, other)&quot; SCNet model available on MVSEP</span></p><p class="c1"><span class="c0">&ldquo;It achieved SDR: 13.81. In Ensemble it gives 14.07 - which is a new record on the Leaderboard.&rdquo; ZFTurbo<br>&ldquo;It passes Food Mart - Tomodachi Life test. That&#39;s the first model to.&rdquo;<br>&ldquo;All bass models have problems with fretless bass&rdquo;<br>There&rsquo;s already an option to combine all SCNet+BS Roformer+HTDemucs bass models for 14.07 SDR.</span></p><p class="c1"><span>Ensembles have been updated with this model too.<br><br>- Reverb removal by Sucial v2 (Mel-Roformer) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2534381169&amp;sa=D&amp;source=editors&amp;ust=1765035742122306&amp;usg=AOvVaw0g9b4mRqz5Y2NnoB5iy57Y">model</a></span><span>&nbsp;</span><span>added on MVSEP (update of the previous model)<br><br>- Lew universal upscaling </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/tag/uni&amp;sa=D&amp;source=editors&amp;ust=1765035742122576&amp;usg=AOvVaw2NVdxh245reHdefSwZpmEu">model</a></span><span>&nbsp;</span><span>has been added on x-minus/uvronline too (premium users).<br>Just a reminder - it&rsquo;s not for badly mixed music, it&rsquo;s for lossy files (also on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Apollo-Colab-Inference/blob/main/Apollo_Audio_Restoration_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742122927&amp;usg=AOvVaw1NGUBlUNU3XfWkYeab6FcJ">Colab</a></span><span>/MVSEP/UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta</a></span><span>&nbsp;</span><span>[at least support for a model file])<br><br>- ZFTurbo released a new 4 stem XL </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v1.0.13&amp;sa=D&amp;source=editors&amp;ust=1765035742123215&amp;usg=AOvVaw1bkVhpLoItnQI-k84jUPGd">model</a></span><span>&nbsp;</span><span class="c0">trained on SCNet.<br>&ldquo;I have great results comparing with SCNet Large model (by starrytong).&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">SCNet Large MUSDB test avg: 9.70 (bass: 9.38, drums: 11.15 vocals: 10.94 other: 7.31)</span></p><p class="c1"><span class="c0">SCNet XL MUSDB test avg: 9.80 (bass: 9.23, drums: 11.51 vocals: 11.05 other: 7.41)</span></p><p class="c1"><span class="c0"><br>SCNet Large Multisong avg: 9.28 (bass: 11.27, drums: 11.23 vocals: 9.05 other: 5.57)<br>SCNet XL Multisong avg: 9.72 (bass: 11.87, drums: 11.49 vocals: 9.32 other: 6.19)<br><br>A new SCNet bass model is incoming and already surpassed metrics of ZFTurbo&rsquo;s HTDemucs and BSRoformer bass models.<br><br>- Anjok released a small UVR Roformer beta patch #9 fixing mainly Apollo arch:</span></p><p class="c1"><span class="c0">UVR_Patch_12_8_24_23_30_BETA </span></p><p class="c1"><span>Windows only for now: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_12_8_24_23_30_BETA_rofo_full_install.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742124581&amp;usg=AOvVaw0AYmg6fDrqfmzTfv3ILxpO">Full</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_Patch_12_8_24_23_30_BETA_large.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742124740&amp;usg=AOvVaw3Rd2S3EBiopoYQgd2xlrcm">Patch</a></span><span>&nbsp;</span><span class="c0">(Use if you still have non-beta UVR installed) |</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_8_24_23_30_BETA_small_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742125009&amp;usg=AOvVaw1g30Ea9I6Ln4IbYSTlgV1h">Small Patch</a></span><span>&nbsp;(You must have a Roformer patch previously installed for this to work)</span><span><br>Changelog:</span></p><p class="c1"><span class="c0">Apollo fixes: &ldquo;Chunk sizes can now be set to lower values (between 1-6)</span></p><p class="c1"><span class="c0">Overlap can be turned off (set to 0)&rdquo;</span></p><p class="c1"><span class="c0">Fix both for Apollo and Roformers: now 5 seconds or shorter input files no longer cause errors.</span></p><p class="c1"><span class="c0">OpenCL was wrongly referenced in the UVR. It was actually DirectML all the way, and Anjok changed all the OpenCL names in the app into DirectML.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released a new Kim-Mel-Band-Roformer-FT vocal </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742126011&amp;usg=AOvVaw3uqreHDuck33exfcoBtwUw">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742126245&amp;usg=AOvVaw3VWXejxzLeNUPJPiEyoUcb">Colab</a></span></p><p class="c1"><span>It enhances both our new bleedless (36.95 vs 36.75) and fullness (16.40 vs 16.26) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1pPEJpu4tZjTkjPh_F5YjtIyHq8v0SxLnBydfUBUNlbI/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742126529&amp;usg=AOvVaw0LikVGMRiqLmn7-_UBPfZK">metric</a></span><span>&nbsp;for vocals vs the original Mel Kim model. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7585&amp;sa=D&amp;source=editors&amp;ust=1765035742126689&amp;usg=AOvVaw19BYFv31bRYMTmp2xrnj_V">SDR</a></span><span>-wise it&rsquo;s also a tad lower (10.97 vs 11.02)<br>(thx Bas Curtiz)<br></span><span class="c0"><br>- Male/female BS-Roformer separation model has been released by Sucial</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2525052333&amp;sa=D&amp;source=editors&amp;ust=1765035742127171&amp;usg=AOvVaw3f5-kjH57xlILd3yphtiL-">https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1#issuecomment-2525052333</a></span></p><p class="c1"><span>If they sing at intervals (one by one), they cannot be separated.<br>Works pretty good, bleed might occur occasionally. Also, it seems to pick up various people dialogues.<br><br></span><span class="c56">If you want to use the model in UVR, use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/15dxMvEanC8h_djEuHoQXHKMk0ERN02_y/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742127761&amp;usg=AOvVaw2U_ou6PcOGkAO59zpKPJPs">this</a></span><span class="c42 c36 c33 c30 c43">&nbsp;config (thx Essid)</span></p><p class="c38 c74"><span class="c56">If you have &quot;The size of tensor a (352768) must match the size of tensor b (352800) at non-singleton dimension 1&quot; e.g. in python-audio-separator, use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nomadkaraoke/python-audio-separator/releases/download/model-configs/deverb_bs_roformer_8_384dim_10depth_config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742128321&amp;usg=AOvVaw1J7Pie2ecOogyElG7YDxjs">this</a></span><span class="c56">&nbsp;config (thx Eddycrack864)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anjok released UVR Roformer beta patch #8 for Win: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_3_24_1_18_BETA_full_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742128724&amp;usg=AOvVaw1Lr4fOAHcKfVf7AjbpSV27">full</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_3_24_1_18_BETA_small_patch_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742128910&amp;usg=AOvVaw3igBze_Pk5QV36toRkci0n">patch</a></span><span>&nbsp;</span><span>| Mac: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_1203_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742129087&amp;usg=AOvVaw1kDUuyath8dbzYyOdtuEFZ">M1</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_1203_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742129258&amp;usg=AOvVaw2qjTWiOwMcwQwcpO2iVUM9">x86-64</a></span><span class="c0"><br>- UVR_Patch_12_3_24_1_18_BETA<br>Apollo arch was made compatible with MacOS MPS (metal) and OpenCL, but with it, it might be unstable and very RAM intensive - use chunk size over 7 to prevent errors (currently it&rsquo;s not certain that all models will work with less than 12GB of VRAM).<br>Apollo is now compatible with all Lew models (fixed incompatibility with any other than previously available in Download Center). Fixed (presumably regression with) Matchering.<br><br>How would I assign a yaml config to an Apollo model on the new UVR [patch]?<br>&ldquo;1. Open the Apollo models folder</span></p><p class="c1"><span class="c0">2. Drop the model into the folder</span></p><p class="c1"><span class="c0">3. From the Apollo models folder, drop the yaml into the model_configs directory</span></p><p class="c1"><span class="c0">4. From the GUI, choose the model you just added and if the model is not recognized, a pop-up window will appear, and you&#39;ll have the option to choose the yaml to associate with the model.&rdquo; - Anjok</span></p><p class="c1"><span><br>&ldquo;I found some overlapping issues in the UVR [using Apollo vs Colab]. like some short parts sounding duplicated overlaid&rdquo; The issue is caused by different chunking, which on Colab is preconfigured to use 15GB of VRAM. &ldquo;chunk_size has influence on results, colab uses 25sec (or 19 for latest lew model)&rdquo;<br></span></p><p class="c1"><span>- Anjok released UVR Roformer beta patch #7 for Windows: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_2_24_2_20_BETA_full_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742131706&amp;usg=AOvVaw3Qo1Bw2wJoBwoPCnQyr-iD">full</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_2_24_2_20_BETA_patch_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742131896&amp;usg=AOvVaw0QU-pQdaObNBwzr074MG3t">patch</a></span><span><br>- UVR_Patch_12_2_24_2_20_BETA (version for Mac probably tonight, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648&amp;sa=D&amp;source=editors&amp;ust=1765035742132131&amp;usg=AOvVaw26JJv32JndJgjGLi3V2RJl">observe</a></span><span>&nbsp;or on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/tag/uvr_update_patches&amp;sa=D&amp;source=editors&amp;ust=1765035742132243&amp;usg=AOvVaw0_6b8Yj4hTY7MnSiGusL6j">GH</a></span><span class="c0">)</span></p><p class="c1"><span>It introduces support for Apollo arch. The OG mp3 enhancer and Lew v1 vocal enhancer were added to Download Center. Probably, now you&rsquo;ll be able to add newer Lew uni enhancer and v2 vocal enhancer manually. The arch is located in Audio Tools. Sadly, this arch cannot be GPU-accelerated with OpenCL, so using AMD and Intel cards (you&rsquo;re forced to use CPU, which might be long).<br>Also, &ldquo;Phase Swapper&rdquo; a.k.a. Phase fixer for Unwa inst models was added to Audio Tools.<br><br>- New SCNet and MelBand DnR v3 (SFX) models were added on MVSEP (along with optional ensemble). &ldquo;The metrics turned out to be better than those of the similar model Bandit v2&rdquo; (25.11)<br><br>- We fixed some issues (IndexError) with jarredou&rsquo;s inference Colab due to the recent updates in the ZFTurbo code (thx for the heads-up, MrG).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anjok released UVR Roformer beta patch #6 for MacOS as well: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742133923&amp;usg=AOvVaw3uYLawTt6iyirZgAgquyHw">M1</a></span><span>&nbsp;|</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742134148&amp;usg=AOvVaw3E0q4Ds4yYW8libpIlHG0N">&nbsp;x86-64</a></span></p><p class="c1"><span><br>- Lew released a new Apollo </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/tag/uni&amp;sa=D&amp;source=editors&amp;ust=1765035742134385&amp;usg=AOvVaw3jA_UkYxihJaMtKNh0TmKU">universal model</a></span><span>&nbsp;</span><span>for upscaling various lossy audio files (added on MVSEP and x-minus premium).<br>Unlike the previous mp3 model, it&rsquo;s able to enhance any formats and not only mp3, including files with hard cutoff like in AAC 128 kbps (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/AzagEuJ&amp;sa=D&amp;source=editors&amp;ust=1765035742134966&amp;usg=AOvVaw0YYkCjgbBCn07lCdMl93kX">see</a></span><span>), it struggles with 48 kbps files.<br>&ldquo;If anyone wants to run the new model in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1Iry5A_l6Ubk6bUnVjy99vbILPXAG9L5Y&amp;sa=D&amp;source=editors&amp;ust=1765035742135263&amp;usg=AOvVaw3FB8Ah-ixl4VCS-64T0MBp">Colab</a></span><span>&nbsp;[already added]</span><span>, set chunk_size to 19. Then the model uses 14.7GB VRAM&rdquo; (Essid). Sometimes a lower setting is necessary (e.g. for a 3 minute song, otherwise memory error will appear).<br>As for 27.11.24 it doesn&rsquo;t work with MSST yet, later added support in UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">patch</a></span><span class="c0">.<br><br>&ldquo;Actually much better than the original Apollo model. It handles artifacts really well</span></p><p class="c1"><span class="c0">and also noise, it understands noise while [the] OG model doesn&#39;t for some reason&rdquo; John UVR/simplcup</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Specifically for any muddy Roformer vocals, still use Lew vocal enhancer v1/2 as they&#39;re better for this task, though they can be noisy (available in the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1Iry5A_l6Ubk6bUnVjy99vbILPXAG9L5Y&amp;sa=D&amp;source=editors&amp;ust=1765035742136881&amp;usg=AOvVaw1O07uMXrpDzyYuZDTXC8Hd">Colab</a></span><span class="c0">).<br></span></p><p class="c1"><span>&nbsp;&ldquo;I also included </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://easyupload.io/r5qzk5&amp;sa=D&amp;source=editors&amp;ust=1765035742137072&amp;usg=AOvVaw2Yy_hFEhe8SbLOISZPfVWb">checkpoint</a></span><span>&nbsp;</span><span>you can continue training from&rdquo; (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1FAokt7DfLTkaadnxTa4bUkGQoNWutW58/view?usp%3Ddrivesdk&amp;sa=D&amp;source=editors&amp;ust=1765035742137343&amp;usg=AOvVaw1zIzldrJKUWy-pzmffudF8">mirror</a></span><span class="c0">)<br>&ldquo;Q: segments: 5.4 - can I assume that chunck_size if 5.4 * 44100?<br>A: Yes, and dims 384</span></p><p class="c1"><span class="c0">The smaller one for inference and bigger one for training<br>Q: Does that model has a dataset of a wide variety of compression noise and artifacts?</span></p><p class="c1"><span>A: mp2, mp3, ogg, wma, aac, opus, low band width wavs. Random speed change augmentations were used too.&rdquo; &ldquo;It was mostly trained on music&rdquo; Lew<br><br>- Two weeks ago, unwa and 97chris released a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1zWOrzPKd-6x7vjHNqjK_bK2UOYfPzCuu/view&amp;sa=D&amp;source=editors&amp;ust=1765035742138426&amp;usg=AOvVaw3FUcvv7-pBrJpUBcVzJl-C">bleed suppressor</a></span><span>&nbsp;Mel Roformer model dedicated for instrumentals (made with unwa v1 in mind). It can work with e.g. v1 and v1e. Sometimes it can remove some bleed also after using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JOa198ALJ0SnEreCq2y2kVj-sktvPePy?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742138945&amp;usg=AOvVaw2WE90oUTYx3OwAKMMDxGux">phase fixer</a></span><span>&nbsp;(by becruily) dedicated for v1 model,</span><span>&nbsp;or used also on x-minus for premium users<br><br>- Anjok </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1310529792461770814&amp;sa=D&amp;source=editors&amp;ust=1765035742139237&amp;usg=AOvVaw2CYsQ44DZ1_frSH-5ekuRX">released</a></span><span>&nbsp;</span><span class="c0">a new UVR Roformer beta patch #6</span></p><p class="c1"><span>UVR_Patch_11_25_24_1_48_BETA (Windows: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_25_24_1_48_BETA_full_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742139631&amp;usg=AOvVaw3LZzQT2LulMknaR9nFktEW">standalone</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_25_24_1_48_BETA_patch_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742139798&amp;usg=AOvVaw2LYT3bl26v98Ub-NB3d5Cr">patch</a></span><span>&nbsp;| Mac: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742139990&amp;usg=AOvVaw2gKlj6DjQVXzz48SbfqpCP">M1</a></span><span>&nbsp;|</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742140160&amp;usg=AOvVaw1hRl3MTb4YCEA1FcCsZPjH">&nbsp;x86-64</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">addressing &ldquo;All stem&rdquo; error issue with viperx&rsquo; models.</span></p><p class="c1"><span><br>And with it, a long anticipated MDX-Net HQ_5 model has been released | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742140618&amp;usg=AOvVaw1YQLHziDXB-d728mpXCy6R">Colab</a></span><span>&nbsp;| MVSEP</span><span><br>(it&rsquo;s also added to Download Center in previous UVR patch versions).<br></span><span class="c34">New version of the HQ_5 model is announced to be released in two weeks already.</span><span class="c0"><br>Instrumentals are slightly muddier than in HQ_4, but vocal residues are also a bit quieter (although rather still present where they were before, maybe with some exceptions). </span></p><p class="c1"><span>E.g. some hi hats might get a tad quieter in the mix.<br>The new model variant in two weeks was said to have fuller instrumentals.<br><br>vs unwa&rsquo;s v1e &ldquo;HQ5 has less bleed but is prone to dips in certain situations. (...). Unwa has more stability, but the faint bleed is more audible. So I&#39;d say it&#39;s situational. Use both. (...) Splice the two into one track depending on which part works better in whichever part of the song is what I&#39;d do.&rdquo; CC Karaoke<br></span><span><br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/UVR-MDX-NET-Inst_HQ_5.onnx&amp;sa=D&amp;source=editors&amp;ust=1765035742141979&amp;usg=AOvVaw0QbtNwIuFoGUaV1_jAxuLM">Model</a></span><span>&nbsp;| config: &quot;compensate&quot;: 1.010, &quot;mdx_dim_f_set&quot;: 2560, &quot;mdx_dim_t_set&quot;: 8, &quot;mdx_n_fft_scale_set&quot;: 5120<br><br>- We have some reports about user custom ensemble presets from older versions no longer working (since 11/17/24 patch and in newer ones). Sadly, you need to get rid of them (don&rsquo;t restore their files manually) or the ensemble will not work and model choice will be greyed out. You need to start from scratch.<br><br>- Sucial released a new Mel-Roformer dereverb/echo model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2493431454&amp;sa=D&amp;source=editors&amp;ust=1765035742142783&amp;usg=AOvVaw3YmHxC5kt-H7_ZXZBhsq7F">model</a></span><span>&nbsp;| MVSEP).<br>It&rsquo;s good but doesn&rsquo;t seem to be better than the more aggresive variant of Mel anvuew&#39;s model (</span><span class="c4"><a class="c3" href="#h.5zlfuhnreff5">models list</a></span><span>).<br>Still, might depend on a use case.<br></span></p><p class="c1"><span>- People experience All stems error with viperx&rsquo;12xx models in newer versions of UVR Beta Roformer patch (patch #2 was the last confirmed to work with these older models)<br><br>- Lucida.to is undergoing some issues with Qobuz links. Tidal and Deezer work, but poorly, occasionally giving errors too, just retry. Doubledouble redirects to Lucida now. In case of problems with accessing the domain in your country, check out lucida.su or VPN.<br>If you have any problems during downloading files, try out in incognito mode without any browser extension, also download accelerators might cause issues too (FAQ).<br><br>- Unwa released a new beta 5 model dedicated for vocals | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742144265&amp;usg=AOvVaw1QNG3DVDe4uWSidlMNxXm7">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742144398&amp;usg=AOvVaw2kKhHAdJbe_1Tx9UTA07U3">MSST-GUI</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR instr</a></span><span><br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742144644&amp;usg=AOvVaw2xaDNSrdpeheEcF_0_ydSJ">https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main</a></span><span>&nbsp;| yaml: big_beta5e.yaml</span></p><p class="c1"><span class="c0">It seems to fix some issues with trumpets in vocal stem (maxi74x1).<br>It handles reverb tails much better (jarredou/Rage123).</span></p><p class="c1"><span class="c0"><br>&ldquo;It&#39;s noisy and, IDK, grainy? When the accompaniment gets too loud. (...) Definitely not muddy though, which is a welcome change IMHO. I think I prefer beta 4 overall&rdquo; - Musicalman<br>&ldquo;to me, the noise sounds similar to how VR arch models sounded, except it&#39;s not poor quality&rdquo;<br>&ldquo;Perhaps a phase problem is occurring (...) The noise is terrible when that model is used for very intense songs&rdquo; - unwa</span></p><p class="c1"><span>Phase fixer for v1 inst model doesn&rsquo;t help with the noise here (becruily).</span><span><br>&ldquo;it&#39;s a miracle LMAO, slow instrumentation like violin, piano, not too many drums... <br>it&#39;s perfect... but unfortunately it can&#39;t process Pop or Rock correctly&rdquo; gilliaan<br><br>&ldquo;feel so full AF, but it has noticeable noise similar to [Apollo] lew&#39;s vocal enhancer&rdquo;<br>&ldquo;the vocal stem of beta5e may have fullness and noise level like duality v1, but it may also suffer kind of robotic phase distortion, yet may also remove some kind of bleed present in other melrofo&#39;s.&rdquo; Alisa/</span><span class="c41">makidanyee</span></p><p class="c1"><span class="c0"><br>&ldquo;bigbeta5e is particularly helpful when you invert an instrumental and then process the track with it. It really keeps the quality. Even if the instrumental was a lossy mp3 inverted to a lossless flac file, it cleans it up without making a mess. (...) some songs gets their instrumentals leaked online. And a lot of the time it&#39;s a lossy 160kbps mp3 file or even worse, you invert that instrumental file to the real song and process the result using bigbeta5e [to clean the invert]&rdquo; gilliaan/heauxdontlast<br><br>&ldquo;Ensemble AVG Big Beta 4 + Big Beta 5e is really good to reduce the noise while keeping the fullness&rdquo; - heauxdontlast<br><br>- Unwa released a new Inst v1e model (&ldquo;The model [yaml] configuration is the same as v1&rdquo;)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742147828&amp;usg=AOvVaw3lgNaULeUlHVt9P0PCPXgp">https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742148050&amp;usg=AOvVaw0QyXWeHXAEil1JKcTmdRt-">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742148172&amp;usg=AOvVaw3F4xzk_IAl7uQjH1slnDqg">MSST-GUI</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR instructions</a></span><span>&nbsp;(added in Download Center) | x-minus (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp?test&amp;sa=D&amp;source=editors&amp;ust=1765035742148417&amp;usg=AOvVaw2lC4KaCN7vx68NyVbI8NPf">link</a></span><span class="c0">&nbsp;for premium users) | MVSEP</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;The &quot;e&quot; stands for emphasis, indicating that this is a model that emphasizes </span><span>fullness</span><span class="c0">.&rdquo;<br>&ldquo;However, compared to v1, while the fullness score has increased, there is a possibility that noise has also increased.&rdquo; &ldquo;lighter compared to v2.&rdquo;</span></p><p class="c1"><span>While SDR-wise it&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/1FMtosl&amp;sa=D&amp;source=editors&amp;ust=1765035742149101&amp;usg=AOvVaw01yB_vktuSfAkXS55y9Ldo">worse</a></span><span>&nbsp;</span><span>than previous unwa&rsquo;s models, it has the best full </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/aJ0nNdc&amp;sa=D&amp;source=editors&amp;ust=1765035742149284&amp;usg=AOvVaw3yPfgoR0WeyH5HmTohWjHX">fullness</a></span><span>&nbsp;</span><span>factor (you can read more about this new method of evaluation later in </span><span class="c4"><a class="c3" href="#h.sc2lgq9t4p19">this</a></span><span>&nbsp;</span><span class="c0">section).<br>The phase fixer doesn&rsquo;t really fix the noise in this model like in v1.<br><br>Like other unwa models, this can also confuse flute, trumpets and saxophone with vocals.<br>- You might want to use this max ensemble by dca100fb8 (e.g. the BS model here is capable of detecting flute correctly and the Mel - sax and trumpet):<br>unwa&rsquo;s v1e + Mel 2024.10 + BS 2024.08 (Max FFT; the latter models on MVSEP, also sometimes unwa&#39;s big beta5e can also retrieve missing instruments from v1e when those two fails)<br><br>- You might want to check max ensemble of instv1, instv2 and inst v1e - erdzo125</span></p><p class="c1"><span>(for even better fullness but more noise - you can consider the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JOa198ALJ0SnEreCq2y2kVj-sktvPePy?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035742150639&amp;usg=AOvVaw0EQhdbbSiw06_kO87-rnMx">phase fix</a></span><span>&nbsp;for instv1)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anjok released a new beta Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_19_24_1_23_BETA_patch_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742150967&amp;usg=AOvVaw3GXU0o0aabE3ezj1TFu_sN">patch</a></span><span class="c0">&nbsp;#5 for UVR (Windows only): UVR_Patch_UVR_11_17_24_21_4_BETA_patch_roformer</span></p><p class="c1"><span class="c0">&ldquo;- Fixed OpenCL compatibility issue with Roformer &amp; MDX23C models.</span></p><p class="c1"><span class="c0">- Fixed stem swap issue with Roformer instrumental models in Ensemble Mode.&rdquo;</span></p><p class="c1"><span class="c0">The patch is rather not standalone like patch #3, so have a previous UVR installation.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anjok released a new beta Roformer patch #4 for UVR: </span><span>UVR_Patch_11_17_24_21_4_BETA (Windows: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_11_17_24_21_4_BETA_full_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742151952&amp;usg=AOvVaw3f_g7QKJd_ZvUFxwsjVerE">full</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_11_17_24_21_4_BETA_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742152100&amp;usg=AOvVaw3uumqsU_362gdNFQq_V8cL">patch</a></span><span>&nbsp;</span><span>| Mac: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_17_24_21_4_BETA_rofo_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742152281&amp;usg=AOvVaw0pxfv6Yj5YFnXaHdFJJJD4">M1</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_17_24_21_4_BETA_rofo_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742152448&amp;usg=AOvVaw0gx3wGmblHpBh3GrCTEfk2">x86-64</a></span><span>)<br>Minor </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1307933134574063706&amp;sa=D&amp;source=editors&amp;ust=1765035742152583&amp;usg=AOvVaw2PaDo2xGsaizxXZYZ3EDPs">bug fixes</a></span><span>. Most importantly, MacOS version fix:<br>&ldquo;Roformer checkbox now visible for unrecognized Roformer models&rdquo; so now you can use custom Roformer models on MacOS Roformer patch without copying/modifying configuration files from Windows version or other users in order to circumvent the lack of option from Windows version to set that the recognized model is Roformer, so separation will work on that model. Plus it includes all the previous fixes in the previously released patch (so overlap code fixed, so no stem misalignment should occur on certain overlap settings - probably higher overlap now means longer separation)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anjok released a new beta Roformer patch #3 for UVR (Windows version for now) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_11_14_24_20_21_BETA_patch_roformer.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742154050&amp;usg=AOvVaw1RSTdKUW6RO-Y0ue88rMG3">UVR_Patch_11_14_24_20_21_BETA_patch_roformer</a></span><span>&nbsp;- &nbsp;&ldquo;this is a patch and requires an existing UVR installation&rdquo; (so either </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">previous</a></span><span>&nbsp;</span><span class="c0">beta Roformer patch or stable 5.6 version).</span></p><p class="c1"><span>The new patch fixes the issue with stem misalignment when using incorrect overlap setting for Roformers. Now it uses ZFTurbo code (also for MDX23C), meaning that probably now increasing overlap for Roformers will result in increasing separation times and potentially better SDR (the opposite of what it used to be in the previous beta Roformer patch). Potentially, it might allow using faster settings without stem misalignments or segment popping (when overlap and dim_t was set to 201 and overlap 2) for 4GB VRAM cards and some heavier models. <br>Among other minor fixes: &ldquo;Roformer stem naming issues resolved. Fixed manual download link issues in the Download Center. Roformer models can now be downloaded without issue.&rdquo;. Implementation of SCNet and Bandit archs is still in works.<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1306819453857566811&amp;sa=D&amp;source=editors&amp;ust=1765035742155604&amp;usg=AOvVaw3XCT-Xr4Gy5wsaZcMoq_YE">Full changelog</a></span><span>.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Becruily made a Python script fixing phase with unwa v1 model, so it removes its noise. </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JOa198ALJ0SnEreCq2y2kVj-sktvPePy?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742155995&amp;usg=AOvVaw2dPwaIagcRaiZeZymshjdC">Download</a></span></p><p class="c1"><span class="c0">You need to run: pip install librosa<br>in case of &ldquo;no module named librosa found&rdquo; error.<br><br>&ldquo;The results are almost, if not the same as x-minus&#39; phase correction.</span></p><p class="c1"><span class="c0">To use, you need to have the song separated with Kim&#39;s melband model and unwa&#39;s v1 model.&rdquo; 32 bit output switch added<br><br>&ldquo;the output length is few ms shorter than the input</span></p><p class="c1"><span class="c0">the output has little popping in the end&rdquo;</span></p><p class="c1"><span><br>- SYH99999/yukunelatyh released a MelBandRoformerSYHFTV3Epsilon </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/SYH99999/MelBandRoformerSYHFTV3Epsilon&amp;sa=D&amp;source=editors&amp;ust=1765035742156940&amp;usg=AOvVaw02lcxNwlj9peViFUC1zXD2">model</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">VS previous SYH&rsquo;s models &ldquo;this version is more consistent with separation. It&#39;s not what I&#39;d call a clean model; It sometimes lets background noise bleed into the vocal stem. But only somewhat, and depending on how you look at it, it can be a good thing since it makes the vocals sound less muddy.&rdquo; Musicalman</span></p><p class="c1"><span>Since then, there was also a newer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/SYH99999/MelBandRoformerBigSYHFTV1Fast&amp;sa=D&amp;source=editors&amp;ust=1765035742157920&amp;usg=AOvVaw1NIkYN3pQtBz_U8ibqnJLe">MelBandRoformerBigSYHFTV1Fast</a></span><span>&nbsp;model released.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Lew released a v2 of the vocal enhancer model for Apollo trained on Roformer vocal outputs</span></p><p class="c1"><span>Added for paid users on x-minus in the Ensemble menu or in the Restoration menu (formerly De-noise) and on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Apollo-Colab-Inference/blob/main/Apollo_Audio_Restoration_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742158505&amp;usg=AOvVaw2QbAw6h5-5LpybAxfsqxd4">Colab</a></span><span>. Model </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model_v2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742158645&amp;usg=AOvVaw26dgABmnV-fQQDqi4TabbA">files</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/2.0/config_apollo_vocal.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742158817&amp;usg=AOvVaw3zyWXAyhFKIAgmGm11AzG0">config</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">Works the best potentially on BS and Mel Roformer ensemble, but it might add some noise as well.</span></p><p class="c1"><span>The model stopped progressing during training, so probably there won&rsquo;t be any newer epoch of this model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Unwa released v2 version of the inst Mel-Roformer model.<br>&ldquo;Sounds very similar to v1 but has less noise, pretty good&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;the aforementioned noise from the V1 is less noticeable to none at all, depending on the track&rdquo;. </span></p><p class="c1"><span class="c0">&ldquo;V2 is more muddy than V1 (on some songs), but less muddy than the Kim model.</span></p><p class="c1"><span class="c0">(...) [As for V1,] sometimes it&#39;s better at high frequencies&rdquo; Aufr33</span></p><p class="c1"><span class="c0">Also, SDR got a bit bigger (16.845 vs 16.595)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742160288&amp;usg=AOvVaw2tURvH0eB9DSpfw-0MYk5d">https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742160491&amp;usg=AOvVaw1bD0ldbOHy26BY2p97EZSz">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742160619&amp;usg=AOvVaw1cnjsK3H0y3ge_xaMuO4hv">MSST-GUI</a></span><span class="c0">&nbsp;<br>&ldquo;It&#39;s the same size as the big model with depth 12 and mask_estimator_depth 3.</span></p><p class="c1"><span class="c0">The improvement was stagnant with the same model size as v1.&rdquo; - unwa</span></p><p class="c1"><span>- The model has been added to UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">Beta Roformer</a></span><span class="c0">&nbsp;Download Center and x-minus.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MSST-GUI is now included in ZFTurbo&#39;s repo, it&#39;s the &quot;gui-wx.py&quot; file&rdquo; just don&rsquo;t run it by double-clicking, but run it from CMD.</span></p><p class="c1"><span class="c0">GPU acceleration working only Nvidia GPUs will give out of memory errors on 4GB VRAM GPUs for Roformers (you can use CPU instead).</span></p><p class="c1"><span class="c0">&quot;UnicodeEncodeError&quot; means there is disallowed character in your input file name, e.g. &ldquo;doesn&#39;t work with [ and ] in the foldername - known bug&rdquo;. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Both duality models and inst v1/2 are now added to UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">Beta Roformer</a></span><span>&nbsp;Download Center (problems with duality models in UVR have been fixed)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Unwa released v2 version of the duality model, slightly a bit better SDR and fewer residues (available in the link below)</span></p><p class="c1"><span>&quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7321&amp;sa=D&amp;source=editors&amp;ust=1765035742162526&amp;usg=AOvVaw0zqsAzSkrxnY-GrEkBsa_S">other</a></span><span class="c0">&quot; is output from model</span></p><p class="c1"><span>&quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7322&amp;sa=D&amp;source=editors&amp;ust=1765035742162705&amp;usg=AOvVaw34NzpF3EmiyM4pUzvWmd50">Instrumental</a></span><span class="c0">&quot; is inverted vocals against input audio.</span></p><p class="c1"><span class="c0">The latter has lower SDR and more holes in the spectrum.</span></p><p class="c1"><span>So using MSST-GUI, leave the checkbox &ldquo;extract instrumental&rdquo; disabled for duality models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Unwa released a new inst-voc Mel-Roformer called &ldquo;duality&rdquo;, focused on both instrumental and vocal stem. </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742163566&amp;usg=AOvVaw35ux-RxIiCb9AYEd_UaPJT">https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality/tree/main</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742163766&amp;usg=AOvVaw0vnbZrTCgZtd0PmTl0x8p4">Colab</a></span></p><p class="c1"><span>Vocals sound similar to beta 4 model, instrumentals are deprived of the noise present in inst v1 model, but as a downside, they don&#39;t sound similarly muddy to previous Roformers. <br>You can use it in the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742164228&amp;usg=AOvVaw1w2rYhuaRgpvn6iOxxCqeu">MSST-GUI</a></span><span>&nbsp;for ZFTurbo</span><span>&nbsp;script (already added) or with the OG ZF repo code. The model will now work in UVR (added in Download Center, but the problem was also fixed by Anjok and added in the OG repo&rsquo;s yaml)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New Ensemble button added on x-minus for premium users for the new inst unwa&rsquo;s model. It corrects the phase and almost removes the noise existing in this model <br>&ldquo;This post-processing uses Kim&#39;s model. After post-processing, the vocals will be replaced with those of this model.&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/900904142669754399/1299210627780444202&amp;sa=D&amp;source=editors&amp;ust=1765035742165251&amp;usg=AOvVaw0zWIOEhqHhQX7j_qwb0oul">Examples</a></span></p><p class="c1"><span class="c0">Using Mel-Roformer de-noise might be better alternative:</span></p><p class="c1"><span>&ldquo;removes more noise from the song, keeping overall instrument quality more than the new button&rdquo; koseidon72. But the more aggressive variant of the model sometimes deletes parts of the mix, like snares.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New Bas Curtiz fine-tuned on MVSEP and unwa&rsquo;s inst Mel-Band added on MVSEP and x-minus.<br>Although there were only 5 submission sent to ZFTurbo for fine-tuning, and 30+ is needed, so there is not so much of a difference in the new FT.</span></p><p class="c1"><span class="c0">&ldquo;I suggest to all of you, if there is any voice left [in inst v1], use the Mel-Roformer de-noise with minimal aggression. &ldquo;not only for little voices left, but also for some background noise.</span></p><p class="c1"><span class="c0">Unfortunately, this new [unwa&rsquo;s] model doesn&#39;t eliminate vocoder voices well from an instrumental&rdquo;</span></p><p class="c1"><span>The model is much faster than beta 4.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa released a new Mel-Roformer model focused on instrumental stem this time (a.k.a. v1):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742167696&amp;usg=AOvVaw2jwOK5ZU_qcsZgJ-k5ciCY">https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742167851&amp;usg=AOvVaw2mX7j7lqgpDR4tiBUDXF4y">Colab</a></span><span>&nbsp;| UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">instructions</a></span><span class="c0">&nbsp;| MVSEP<br>&quot;much less muddy (...) but carries the exact same UVR noise from the [MDX-Net v2] models&quot;</span></p><p class="c1"><span class="c0">But it&#39;s a different type of noise, so aufr33 denoiser won&#39;t work on it. </span></p><p class="c1"><span>&ldquo;you can &quot;remove&quot; [the] noise with UVR-Denoise, aggr. -10 or 0&rdquo; although at least with -10 it will make it sound more muddy like Kim model and synths and bass are sometimes removed with the denoiser (~becruily). UVR-Denoise-Lite doesn&rsquo;t seem to damage instruments that badly, but still more than Mel denoise (recommended aggr. - 4, with 272 vs 512 windows size it&rsquo;s less muddy, TTA can stress the noise more, somewhere above 10 aggr. it gets too muddy). UVR-Denoise on x-minus is even less aggressive (it&rsquo;s medium aggression model for free users without aggression pick), but it might catch ends of some instruments like bass occasionally. Premium minimum aggression model is somehow more muddy, but doesn&rsquo;t damage instruments. Minus the noise, this is a </span><span class="c22">groundbreaking </span><span>instrumental model among public models or existing Roformers.<br>(more </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1298225992636174346&amp;sa=D&amp;source=editors&amp;ust=1765035742169942&amp;usg=AOvVaw2DxDbzdcYxfNggW3auvR4R">training details</a></span><span class="c0">)<br><br>&ldquo;Flipping the target seems to definitely have effect on the instrumental part!&rdquo; Bas Curtiz</span></p><p class="c1"><span>&ldquo;I got an error when I set num_stems to 2.&rdquo; unwa<br>You can use &ldquo;target_instrument: null&rdquo; instead, which is also required for multistem training like on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/eOSW8I7&amp;sa=D&amp;source=editors&amp;ust=1765035742170554&amp;usg=AOvVaw3opl5S_5BQ56myKFuCcPS_">this </a></span><span>example ~jarredou<br>&ldquo;It&#39;s because of the PHASE. I found a way to fix it. Today I will add a new ensemble button.&rdquo; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Similarity / Phantom Center Extractor </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2417116936&amp;sa=D&amp;source=editors&amp;ust=1765035742171078&amp;usg=AOvVaw3Q1s74ZqCfSvnw6qu8OAGy">model</a></span><span>&nbsp;</span><span class="c0">by wesleyr36 added on MVSEP (Experimental section) and x-minus.pro (Extract backing vocals). </span></p><p class="c1"><span class="c0">&ldquo;This model is similar to the Center Channel Extractor effect in Adobe Audition or Center Extract in iZotope RX [and Audacity/Bertom], but works better. </span></p><p class="c1"><span>Although it does not isolate vocals, it can be useful.&rdquo; Aufr33<br>You can find more on the topic in </span><span class="c4"><a class="c3" href="#h.3c6n9m7vjxul">Similarity Extractor</a></span><span class="c0">&nbsp;section.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- ZFTurbo released MVSEP Wind model on the site (MelBand/SCNet/ensemble)</span></p><p class="c1"><span>Some songs might be separated better vs the model on x-minus, not all.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- A GUI for ZFTurbo&#39;s Music Source Separation script for inference called MSST-GUI was released by Bas Curtiz (link with instruction in the description):<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DM8JKFeN7HfU&amp;sa=D&amp;source=editors&amp;ust=1765035742172803&amp;usg=AOvVaw1NZyLooZGA6GWfGlgQ5ER5">https://www.youtube.com/watch?v=M8JKFeN7HfU</a></span><span>&nbsp;(reupload)</span></p><p class="c1"><span class="c0">It has screen reader compatibility, although people can&#39;t navigate with the arrow keys in the web view for now, but at least you have HTML source of the page so you can just download models from there.<br>- Multiple updates were made since that excerpt was written and new models were constantly added</span></p><p class="c1"><span>- If you have &ldquo;ERROR: Could not build wheels for diffq, pesq, which is required to install pyproject.toml-based projects&rdquo; then<br>&ldquo;Edit the requirements.txt file and remove or comment out that line with asteroid&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/rh553CR&amp;sa=D&amp;source=editors&amp;ust=1765035742173863&amp;usg=AOvVaw1LTCDpsIp6-qnWHWrBhKmZ">click</a></span><span class="c0"><br>Then rerun pip install -r requirements.txt </span></p><p class="c1"><span class="c0">- If you have decent Nvidia GPU, and no GPU acceleration maybe &ldquo;Check these commands to install torch version that handle cuda&rdquo;:</span></p><p class="c1"><span class="c0">pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span class="c0">pip install torch==2.3.0+cu118 torchvision torchaudio &mdash;-extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span class="c0">pip install torch==2.3.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span class="c0">pip install torchaudio==2.3.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New beta 4 of unwa&rsquo;s Mel-Roformer fine tune of Kim&rsquo;s voc/inst model released:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742175475&amp;usg=AOvVaw0BIuZK7mf09BZARif0D7WD">https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742175600&amp;usg=AOvVaw1kUKAQStM9YjxR5bMRD2RA">Colab</a></span></p><p class="c1"><span class="c0">Be aware that the yaml config has changed, and you need to download the new beta4 yaml.</span></p><p class="c1"><span class="c0">&ldquo;Metrics on my test dataset have improved over beta3, but are probably not accurate due to the small test dataset. (...) The high frequencies of vocals are now extracted more aggressively. However, leakage may have increased.&rdquo; - unwa</span></p><p class="c1"><span class="c0">&ldquo;one of the best at isolating most vocals with very little vocal bleed and still doesn&#39;t sound muddy&rdquo; &ldquo;gives fuller vocals&rdquo;. Can be a better choice on its own than some ensembles.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- ZFTurbo, the owner of MVSEP, seeks help on improving Bas Curtiz&rsquo; ft Mel-Roformer model on MVSEP. How can you help?<br>1) Find a badly separated song with this model (e.g. bleeding)<br>2) Find other model which separates your song correctly<br>3) Send the good results (instrumental stem + vocal stem in stereo/44kHz with the same length) to ZFTurbo on Discord (or </span><span class="c4"><a class="c3" href="mailto:turbo@mvsep.com">email</a></span><span class="c0">)</span></p><p class="c1"><span>The result will be used as input for training a new, fine-tuned model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;1) All [MVSEP] ensembles now use Bas Curtiz MelRoformer model. SDR for Multi dataset stayed almost the same, but greatly increased for Synth</span></p><p class="c1"><span class="c0">2) Drums model were updated for all Ensembles too.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7197&amp;sa=D&amp;source=editors&amp;ust=1765035742177938&amp;usg=AOvVaw0tAw_LMCvUJDbjmh1vTWA-">https://mvsep.com/quality_checker/entry/7197</a></span><span>&rdquo; ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New SCNet Large Drums model added on MVSEP</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://studio.gaudiolab.io&amp;sa=D&amp;source=editors&amp;ust=1765035742178323&amp;usg=AOvVaw3-RGKNrwfqwQdWzjlSFA8m">https://studio.gaudiolab.io</a></span><span>&nbsp;introduced new Noise Reduction feature</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- For those having problems with too slow functioning of lucida.to, you can use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mp3-daddy.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742178699&amp;usg=AOvVaw2heuEwNzYfmlRjY2hrbAsm">https://mp3-daddy.com/</a></span><span class="c0">. Sometimes FLAC option might not work, then download mp3 first, and then FLAC will work (the files have full 22kHz spectrum). Although, sometimes it may fail anyway (not always in incognito mode and with third party cookies allowed, and after long wait after error appeared). Downloading might be possible by manual download with Inspect option in your browser (it starts downloading and interrupts like on GSEP in the old days). Don&rsquo;t even bother reading their site description - it&rsquo;s full of AI-written sh&amp;t. Contrary to what they say, it doesn&rsquo;t support YT or YT Music/Tidal/Deezer links, so you need to use their search engine. So probably the max output quality is 44kHz/16 bit. It doesn&rsquo;t seem to use Tidal (maybe Deezer).</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://doubledouble.top/&amp;sa=D&amp;source=editors&amp;ust=1765035742179948&amp;usg=AOvVaw18btrqNgleurrMZ3RpibVa">https://doubledouble.top/</a></span><span class="c0">&nbsp;is now also back online and supports Apple Music unlike Lucida, but it might be slower and go offline eventually as before.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Strings model based on MDX23C arch added on MVSEP. It has low SDR yet (3.84), so it&rsquo;s hit or miss whether it will work for your song, but some people had even good results at times. ZFTurbo plans to work on it further.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Finally, HQ_4 released in March has been added also on MVSEP (it was also added on x-minus/uvronline.app not long ago via </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035742180989&amp;usg=AOvVaw08bCUoQJLDIRXv39hd2nAz">this</a></span><span>&nbsp;link at least)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Beta 3 of the unwa&rsquo;s Mel-Roformer fine-tuned Kim&rsquo;s model released. Fine-tuning was started from scratch on enhanced dataset made with help of Bas Curtiz. As the result, the model is free from the high frequency ringing present in the previous beta models. </span></p><p class="c1"><span class="c0">&ldquo;I&#39;ve added hundreds of GB worth of data to my dataset&rdquo;.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742181767&amp;usg=AOvVaw3DrK98bits5B_zoH1jKVs5">Download</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742181905&amp;usg=AOvVaw0MYWMn6LRehyVASULIlOA4">Colab</a></span></p><p class="c1"><span>&quot;definitely better than Kim&#39;s now&quot; although vocal residues might occur yet, and then use unwa&rsquo;s BS-Roformer fine-tune instead. SDR is slightly lower than Kim Mel-Roformer. It&rsquo;s good for RVC.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- The Lew&rsquo;s model was added to jarredou&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Apollo-Colab-Inference/blob/main/Apollo_Audio_Restoration_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742182603&amp;usg=AOvVaw3hlMI4jym_WFqHBfbBABVy">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Lew released a model for Apollo, serving to enhance vocal results of Roformers </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ufile.io/09560o34&amp;sa=D&amp;source=editors&amp;ust=1765035742182907&amp;usg=AOvVaw2sTH1HIrXN3Ai50RNmbacO">https://ufile.io/09560o34</a></span></p><p class="c1"><span>&ldquo;You can use it in Music Source Separation Training </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/&amp;sa=D&amp;source=editors&amp;ust=1765035742183109&amp;usg=AOvVaw18-54SGkcJPZjxjWzq78_m">repo</a></span><span>, and it should be compatible with jarredou Apollo Colab&rdquo; Links a bit below (not compatible with UVR).</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span>- Beta 2 of the unwa&rsquo;s Mel-Roformer fine-tuned model released (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742183540&amp;usg=AOvVaw26psXc2lRQDD2LPP2f7E5x">Colab</a></span><span class="c0">).</span></p><p class="c1"><span>Be aware that both models have some ringing issues in higher frequencies. Hard to say if it will be fixed in the further training, Unwa explaining said it was mainly made with vocals in mind so it&rsquo;s not sure.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Unwa released beta version of still-in-training Mel-Roformer fine-tuned model of Kim&rsquo;s. Not tested SDR-wise, but might give better results than the old Unwa&rsquo;s BS-Roformer model already. Download:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742184529&amp;usg=AOvVaw30kY1rbjYw222cAOXy7RXJ">https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>In UVR consider using dim_t = 1501 at the bottom of the yaml (can be slow), but 1333 or 1301 can be better for e.g. 40 second snippets, while the biggest SDR is for 1101 for all Roformers, but it still depends on a song what gives the best results (in reality, even SDR for each song is different, and bigger SDR not always means better quality, the quality using specific parameters might even differ in certain fragments).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (uvronline.app/x-minus) New electric and acoustic guitar models by viperx&#39; added on the site for premium users.</span></p><p class="c1"><span class="c0">Acoustic seems to be good, while electric might be more problematic at times.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Now lalal.ai have some voc/inst models sounding like some ensemble of public Roformers, but still not as good, although close. Some of their specific models are worth trying out, e.g. lead guitars - the model got better by the time, or also piano model</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/JusperLee/Apollo&amp;sa=D&amp;source=editors&amp;ust=1765035742186264&amp;usg=AOvVaw3YVJdTzauP95i0ENKN3ObO">https://github.com/JusperLee/Apollo</a></span><span>&nbsp;| jarredou </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Apollo-Colab-Inference/blob/main/Apollo_Audio_Restoration_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742186462&amp;usg=AOvVaw37hBc2hzf0q2eBZmX3f9hD">Colab</a></span></p><p class="c1"><span class="c0">jarredou: &ldquo;New tool for heavily compressed mp3 restoration, using bandsplitting and roformers. It does work really great if the audio was compressed at 44.1khz sample rate, whatever bitrate [&lt;=128kbps]. BUT if there was some resampling leading to hard cutoff, it will wrongly behave.</span></p><p class="c1"><span>The current model of Apollo was only trained on mp3 compressed audio. If you use ogg/opus/m4a/whatever else compressed audio as input, it&#39;s not guaranteed that it will work as expected.</span><span>&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It was also added on MVSEP as &quot;Apollo MP3 Enhancer&quot;:</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20240919224117-f0bb276157-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035742187676&amp;usg=AOvVaw0I0uVVw0xBzXWMDl1xGrF1">https://mvsep.com/result/20240919224117-f0bb276157-mixture.wav</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Advice</span></p><p class="c1"><span>&quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/REvevJh&amp;sa=D&amp;source=editors&amp;ust=1765035742187918&amp;usg=AOvVaw271o4KOK7tARf96ptMwrtY">Good use case</a></span><span class="c0">:</span></p><p class="c1"><span class="c0">Input has no hard cutoff (quality slowly degrades toward high freq).</span></p><p class="c1"><span>Generated output is as expected. It can fill holes, and it can remove artifacts (and probably bleeding too) and is working great with highly degraded audio here. If trained on clean source vs separated stem, which is not as much degraded content than 32kbps mp3 like previous example, I think it could work really great&rdquo; [</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/4ePVWYP&amp;sa=D&amp;source=editors&amp;ust=1765035742188667&amp;usg=AOvVaw3PxsmRUUBZt9daNXUFNpP0">bad use case</a></span><span class="c0">]</span></p><p class="c1"><span class="c0">&ldquo;so far the overlap magic is needed, cause u hear the transition&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;It seems to alter the tempo. It&#39;s not a constant alteration, it just shifts stuff, and you can&#39;t invert&rdquo; becruily</span></p><p class="c1"><span class="c0">&gt; &ldquo;I&#39;ve seen this too in my tests, but it seems to happen only at the end of the chunk.</span></p><p class="c1"><span class="c0">In the updated version (in which the end of chunks is ditched), I haven&#39;t seen that issue again.</span></p><p class="c1"><span class="c0">&gt;Overlap feature added [to the Colab].</span></p><p class="c1"><span class="c0">New inference.py created for easier local CLI use.</span></p><p class="c1"><span class="c0">I have set chunk_size at 3 seconds as default in the Colab because it was the chunk_size used to train the model, but it seems that the highest is the best.&rdquo; jarredou</span></p><p class="c1"><span>It was also added into ZFTurbo&rsquo;s training dataset (read </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1286122948318724127&amp;sa=D&amp;source=editors&amp;ust=1765035742190077&amp;usg=AOvVaw0MHg3UDXjtEH0HiDFTqBtH">more</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">Also, for non-mp3 input files, you might want to experiment with compressing them to 64kbps first.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Also, TS-BSmamba2 was added to the repo. So it&#39;s available for training now too. But currently it works only on Linux.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aufr33 added MDX HQ4 to x-minus/uvronline via this link: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035742190877&amp;usg=AOvVaw39MJ9uptbkFumrggY-bSWm">https://uvronline.app/ai?hp&amp;test-mdx</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus/uvronline.app) &ldquo;viperx has updated the piano model!</span></p><p class="c1"><span class="c0">I just replaced it on the website.&rdquo; Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The new piano model is incredible, I have even been able to separate a harpsichord by passing it over and over again through the model until the other instruments are left alone and it doesn&#39;t sound bad at all.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There was some update to MVSEP piano models lately too, and there are SCNet and viperx models and ensemble with metrics added on the website (at least on separate page beside multi song dataset chart).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;both similar but mvsep has a teeny bit more bleed during the choruses and whatnot&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;I added possibility to use Bas Curtiz&rsquo; MelRoformer model with large score on Synth dataset. You must choose it from MelRoformer options. By default, my model is used.</span></p><p class="c1"><span class="c0">The problem with Bas&#39;s model is that it&#39;s very heavy and slow, with almost the same score on Multi dataset.&rdquo; Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I&#39;ve tried some songs and have great result! Music sounds fuller than original Kim&#39;s one &amp; the finetuned version from ZFTurbo. Even [though] the SDR is smaller than BS Roformer finetuned last version, but almost song has the best result in instrumental. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1 song I found is bad result is from Wham - Where did your hearts go. The trumpet or sax whatever sound was lost, the model detects it as vocal, and the 1st beginning of vocal still heard. On other mel roformer, that trumpet or sax sound can still separate it as well.&rdquo; Henry</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;Guitar model was updated. I added BSRoformer model by viperx with SDR: 7.16. And</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- I replaced [guitar] Ensemble. Earlier it was MDX23C + Mel. Now its BS + Mel. SDR increased from 7.18 to 7.51.</span></p><p class="c1"><span>Demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20240914110542-7ab0356600-song-000-mixture.wav&amp;sa=D&amp;source=editors&amp;ust=1765035742194705&amp;usg=AOvVaw0Ds54Uc5QHoScRawuKsAA7">https://mvsep.com/result/20240914110542-7ab0356600-song-000-mixture.wav</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>All these models are available for all users.&rdquo; ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The new MDX HQ5 beta model is now online!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Use this link to access it:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035742195489&amp;usg=AOvVaw3_WVfY5iK7DwdcGdsHTs4_">https://uvronline.app/ai?hp&amp;test-mdx</a></span><span>&nbsp;</span><span class="c0">- link for premium users</span></p><p class="c1"><span class="c0">Go to &quot;music and vocals&quot; and there you will see it (scroll down).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s not a final model yet, and the model is in training from April and is still in progress.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It seems to be muddier than HQ_4 (and more than Kim&rsquo;s and MVSEP&rsquo;s Mel-Roformer), it has less vocal bleeding than before, but more than Kim Mel-Roformer. Sometimes struggles with reverb.</span></p><p class="c1"><span class="c0">&quot;Almost perfectly placed all the guitar in the vocal stem&quot; it might get potentially fixed in the final version of the model, which is planned for release in the mid-November as Anjok said at 04.11.24.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The model is not available in UVR yet (only on uvronline.app)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Using the </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR Roformer</a></span><span>&nbsp;beta</span><span>&nbsp;patch for Mac doesn&rsquo;t allow you to choose the Roformer parameter to check for manually copied Roformer models to UVR like: Kim Mel-Roformer or unwa&rsquo;s Roformer, and only config name can be chosen, but no confirm button is available to make the model work. Place </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/14IfdqN3tDjXVe0hQ9i5-1KejIJTO09xX?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742197728&amp;usg=AOvVaw3CRw30gwVZ0PCsTyAoDveP">corresponding</a></span><span>&nbsp;hash-named file to models\MDX_Net_Models\model_data after placing model file to MDX_Net_Models and non-hased model&rsquo;s yaml to mdx_c_configs and start the UVR.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Aufr33 released files for the new UVR de-reverb model made with jarredou </span></p><p class="c1"><span class="c0">(based on VR 5.1 arch).</span></p><p class="c1"><span>&ldquo;1. Download </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/CFRBHLRK%23uhRexQFJVo8_Owr8x9sEEohDcCNZbl3UgeX5eyD7IFA&amp;sa=D&amp;source=editors&amp;ust=1765035742198589&amp;usg=AOvVaw2KEyz1oD9IfZ6mQj4RMSrS">this</a></span><span>&nbsp;</span><span class="c0">and unzip into your Ultimate Vocal Remover folder</span></p><p class="c1"><span class="c0">2. Select VR architecture and DeReverb model from the menu</span></p><p class="c1"><span>3. Set the parameters as shown </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/dZAJwef&amp;sa=D&amp;source=editors&amp;ust=1765035742198981&amp;usg=AOvVaw2ip7U1DCFC7I7G6t_T16_e">here</a></span><span class="c0">&rdquo; </span></p><p class="c1"><span class="c0">(PS: Dry, Bal: 0, VR 5.1, Out:32/128/Param: 4band_v4_ms_fulband -</span></p><p class="c1"><span class="c0">An already existing json config file in modelparams folder has the same checksum)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Bas Curtiz&rsquo; &ldquo;Conclusion so far:</span></p><p class="c1"><span class="c0">- MDX[23C] De-Reverb seems to be cleaner, takes the reverb away, also between the words,</span></p><p class="c1"><span class="c0">whereas VR leaves a little reverb</span></p><p class="c1"><span class="c0">- [The new] VR De-Reverb seems to sound more natural, maybe therefore actually.</span></p><p class="c1"><span class="c0">Also, MDX tends to &#39;pinch&#39; some stuff away to the background, which sounds unnatural.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">This is just based on my experience with 3 songs/comparisons, but both points are a pattern.</span></p><p class="c1"><span>Overall, they&#39;re both great when u compare them against the original reverbed/untouched vocals.&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1279223128848863338&amp;sa=D&amp;source=editors&amp;ust=1765035742200538&amp;usg=AOvVaw2oW-1XfOA78RS8hobsZKYS">Video</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- SCNet Large vocal model on MVSep published.</span></p><p class="c1"><span class="c0">Multisong dataset:</span></p><p class="c1"><span class="c0">SDR vocals: 10.74</span></p><p class="c1"><span class="c0">SDR other: 17.05</span></p><p class="c1"><span class="c0">&ldquo;just like the new bs roformer ft model, but with more bleed. [BS] catches vocals with more harmonies/bgv&rdquo; isling</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Cyrus repaired pip issues with </span><span class="c4"><a class="c3" href="#h.s4sjh68fo1sw">Medley Vox</a></span><span class="c0">&nbsp;Colab</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Aufr33 released MDX23C de-reverb model files</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://a19p.uvronline.app/public/dereverb_mdx23c_sdr_6.9096.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742201681&amp;usg=AOvVaw245aEogfH-GSS7bnM5lCsf">https://a19p.uvronline.app/public/dereverb_mdx23c_sdr_6.9096.ckpt</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1dQHfce4VKYSmWZ3IgIj4SZq_uTicD4At/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742201814&amp;usg=AOvVaw3EEamk9nvWRgHGpwqGV_Mj">config</a></span></p><p class="c1"><span class="c0">&ldquo;If you will use this model in your project, please credit us (me and jarredou)&rdquo;</span></p><p class="c1"><span class="c0">Also added on MVSEP.</span></p><p class="c1"><span class="c0">UVR instruction:</span></p><p class="c1"><span class="c0">&ldquo;1. Just copy model to Ultimate Vocal Remover\models\MDX_Net_Models</span></p><p class="c1"><span class="c0">2. Copy .yaml config to Ultimate Vocal Remover\models\MDX_Net_Models\model_data\mdx_c_configs</span></p><p class="c1"><span class="c0">3. When opening UVR, selecting dereverb_mdx23c_sdr_6.9096 from the MDX-Net process method, don&#39;t click &#39;RoFormer model&#39; cause it&#39;s not.</span></p><p class="c1"><span class="c0">4. Select config_dereverb_mdx23c from the dropdown. Done.&rdquo; ~Bas Curtiz</span></p><p class="c1"><span class="c0">5*. In case of &ldquo;no key&rdquo; error in UVR, changed line 30 in the config to:</span></p><p class="c1"><span class="c0">No dry</span></p><p class="c1"><span>But it doesn&rsquo;t happen to everyone.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New UVR Dereverb model added on uvronline.app for premium users.</span></p><p class="c1"><span>It seems to handle room reverb better than the previous MDX23C model, and the Foxy&rsquo;s model sometimes cut &ldquo;way too much&rdquo; than this new model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- People cannot separate using Ripple since longer than August 12th. There&#39;s an error &quot;couldn&#39;t complete processing please try again&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (</span><span>x-minus.pro/uvronline.app</span><span>) &ldquo;Hipolink was a temporary solution. Now I can accept payment via Patreon as well.&rdquo; Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX23C De-reverb model by Aufr33 released for premium users of uvronline.app.</span></p><p class="c1"><span>&ldquo;Thanks to jarredou for helping me create the dataset&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Jarredou released v. 2.5 of MDX23 Colab adding the new Kim Mel-Roformer model. Final SDR is higher (17.64 vs 17.41 for instrumentals, with 2024.08.15 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035742204811&amp;usg=AOvVaw0kKMXI32CPVbBWk_TRsToZ">MVSEP</a></span><span>&nbsp;</span><span class="c0">Ensemble being 17.81).</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742205230&amp;usg=AOvVaw3mKC6S1jjVICTWHt9WSpWZ">https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb</a></span></p><p class="c1"><span class="c0">&ldquo;Baseline ensemble is made with Kim Melband rofo, InstVocHQ and selected 1296 or 1297 BS Rofo&rdquo; switching from 1296 to 1297 produces more muddy/worse instrumentals in this Colab (more sudden jumps of dynamics from residues).&rdquo; VitLarge is no longer used by default.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;I&#39;ve opened a donation account for those who would want to support me: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ko-fi.com/jarredou&amp;sa=D&amp;source=editors&amp;ust=1765035742205977&amp;usg=AOvVaw3DFDVYXMsZDl5wkqw-00jM">https://ko-fi.com/jarredou</a></span><span>&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- unwa&rsquo;s fine-tuned BS-Roformer model released (12.59 for instr) - worse SDR than other fine-tuned models on MVSEP by ZFTurbo, but better SDR than Kim&rsquo;s MelRoformer and viperx base model </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Q_M9rlEjYlBZbG2qHScvp4Sa0zfdP9TL/view&amp;sa=D&amp;source=editors&amp;ust=1765035742206552&amp;usg=AOvVaw3E0pc5Rrg8oUqxGYtGOXjc">https://drive.google.com/file/d/1Q_M9rlEjYlBZbG2qHScvp4Sa0zfdP9TL/view</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;Mel-RoFormer Karaoke / Lead vocal isolation model files released by Aufr33 and viperx</span></p><p class="c1"><span>&ldquo;If you will use this model in your project, please credit us&rdquo; (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/qQA1XTrb%23LUNCfUMUwg4m4LZeicQwq_VdKSq9IQN34l0E1bb0fz4&amp;sa=D&amp;source=editors&amp;ust=1765035742206999&amp;usg=AOvVaw3lqTfOksXxCfR0Hf3PvALL">download</a></span><span class="c0">)</span></p><p class="c1"><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR instructions</a></span><span>. Be aware that online version on uvronline/x-minus seems to work better.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- doubledouble.top will be soon replaced by </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://lucida.to/&amp;sa=D&amp;source=editors&amp;ust=1765035742207453&amp;usg=AOvVaw2wBSdz1dEs9u96EINY2gSj">https://lucida.to/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Kimberley Jensen released her Mel-Band Roformer vocal model publicly (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/KimberleyJensen/Mel-Band-Roformer-Vocal-Model&amp;sa=D&amp;source=editors&amp;ust=1765035742207730&amp;usg=AOvVaw12OTvhaI4uy1zDojQYZPNV">download</a></span><span class="c0">)</span></p><p class="c1"><span>(simple </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1tyP3ZgcD443d4Q3ly7LcS3toJroLO5o1?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742207910&amp;usg=AOvVaw01M3rkBr5c6pG58VXA0W_z">Colab</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/KimberleyJensen/Mel-Band-Roformer-Vocal-Model&amp;sa=D&amp;source=editors&amp;ust=1765035742208026&amp;usg=AOvVaw109eDoCVM1Kjk1myFLIlgg">CML inference</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035742208094&amp;usg=AOvVaw01UexPABse1_QLKwqRRk46">x-minus</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742208156&amp;usg=AOvVaw1_8iJ3jkm1izRVU9i2WTLA">MVSEP</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742208343&amp;usg=AOvVaw37R5dFKoYEA8Jvi_be5lnv">jarredou Colab</a></span><span>&nbsp;too now</span><span class="c0">)</span></p><p class="c1"><span>Works in UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta Roformer</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/KimberleyJSN/melbandroformer/resolve/main/MelBandRoformer.ckpt?download%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035742208622&amp;usg=AOvVaw09Xj-iRP0-bVzG3QWdhO9C">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1U1FnACm-ontQSjhneq-WKk1GHEiTW97s/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742208743&amp;usg=AOvVaw15LBd2uCgY_Ol09RIRYl8T">config</a></span><span class="c0">&nbsp;- place the model file to models\MDX_Net_Models and config to model_data\mdx_c_configs subfolder and &ldquo;when it will ask you for the unrecognised model when you run it for the first time, you&#39;ll get some box that you&#39;ll need to tick &quot;roformer model&quot; and choose it&#39;s yaml&rdquo;.</span></p><p class="c1"><span class="c0">Use overlap 2 for best SDR, or 8 for faster inference in UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- SCNet model published on MVSEP. Similar metrics to MDX23C model, but seems to leave lot of vocal residues.</span></p><p class="c1"><span class="c0">&ldquo; it is based on SCNet-small config from the paper, the SCNet-large config is almost 1 &nbsp;SDR above in the reported eval, so hopefully, next SCNet model trained by ZFTurbo with that large config will be better too.&rdquo; So far he had some problems training on large config, sadly.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Slightly better Roformer 2024.08 model (0.1 SDR+) was added on MVSEP</span></p><p class="c1"><span class="c0">vs 2024.04 model &ldquo;it seems to be much better at taking the vocals when there are a lot of vocal harmonies.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus.pro/uvronline.app) &ldquo;In the new interface, the BS-RoFormer model now also has De-mudder</span></p><p class="c1"><span class="c0">Select the Music and vocals, BS-RoFormer and after processing you will see the De-mudder button appear.&rdquo; Aufr33</span></p><p class="c1"><span class="c0">It works for premium.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you got an error while using jarredou&rsquo;s Drumsep Colab (</span><span class="c20">object is not subscriptable</span><span class="c0">):</span></p><p class="c1"><span class="c0">change to this on line 144 in inference.py:</span></p><p class="c1"><span class="c6">&nbsp; &nbsp; if type(args.device_ids) != int:</span></p><p class="c1"><span class="c6">&nbsp; &nbsp; &nbsp; model = nn.DataParallel(model, device_ids = args.device_ids)</span></p><p class="c1"><span>(thx DJ NUO)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (GSEP) I received email about deletion of my files on one of my accounts which is inactive, if I don&rsquo;t buy premium (haven&rsquo;t received it on my main account with premium), so it&#39;s probably due to inactivity and no premium. It&rsquo;s probably for accounts not using the service since the release of the new paid site and/or maybe didn&rsquo;t have premium since then (email is from July 9th, so 3 months after the release of the new site, so possibly your files can get deleted after 3 months after premium was disabled on your account). Normally, new separations for free users are deleted after 3 days now, but older files were preserved at least for accounts using beta till now. The account wasn&rsquo;t used since the end of October 2022.</span></p><p class="c1"><span class="c0">Check your mailbox to ensure, I didn&rsquo;t find that mail in spam on the main account with premium, so hopefully it&rsquo;s not for everyone (at least not for those with premium or who used the site since the last 3 months):</span></p><p class="c1"><span class="c0">&ldquo;All files from Gaudio Studio will be deleted on August 7, 2024 [Wednesday]. (...) If you purchase a Studio Plan, your files will be preserved.&rdquo;</span></p><p class="c1"><span class="c0">Be aware that they function in Japan, which is GMT+9, so it&rsquo;s 6 hours sooner than CEST (Warsaw, Skopje, Zagreb). </span></p><p class="c1"><span class="c34">If you currently have premium, you can download all your previous separations in WAV without any charge (at least that&rsquo;s how it used to be), without premium</span><span>&nbsp;it says </span><span class="c34">(misleadingly, I assume)</span><span>&nbsp;&ldquo;The song processed in the beta service do not support WAV file downloads.&rdquo; </span><span class="c34">but probably you&rsquo;ll be able to do that if you buy premium if nothing has changed. </span><span class="c0">It&rsquo;s no loner possible, and there are no references to WAV in dev tools as before.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Aufr33 released files of his Mel-Roformer de-noise models publicly:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/rIRQGJ4D%239SHaPIXt8GRoi2SL29WUILW0g9dk26I5njyFPZuPJQ8&amp;sa=D&amp;source=editors&amp;ust=1765035742214349&amp;usg=AOvVaw1mzOYxsXfWHfkElGUJUaiR">Less aggressive</a></span><span>&nbsp;&amp; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/vM4mHTYQ%23f_uCxxS_olfTR4iAsOc-XS6sfUecfbF-ZKXrk3IjbnY&amp;sa=D&amp;source=editors&amp;ust=1765035742214484&amp;usg=AOvVaw0aguBAn088avJXtg5A25dR">More aggressive</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1uwInhwgjOMIdOMTgj_oNR_dmaq7E-b3g/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742214612&amp;usg=AOvVaw1N3-OdQHBAiPZrCaAYJP7-">yaml file</a></span></p><p class="c1"><span class="c0">&ldquo;If you will use this model in your project, please credit me&rdquo;</span></p><p class="c1"><span>Added in jarredou </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742214993&amp;usg=AOvVaw3OOaZraWiIU-2hnubrpX4Q">Colab</a></span><span class="c0">&nbsp;too (and on x-minus.pro/uvronline.app for premium users and MVSEP).</span></p><p class="c1"><span>Both models work in UVR too (don&rsquo;t forget setting overlap to 2 to avoid stem misalignment issues like for other Roformers in UVR Roformer beta, overlap 3 or above will break separation)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Jarredou released manual ensemble Colab with drop-down menus (based on ZFTurbo code)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Manual_Ensemble_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742216093&amp;usg=AOvVaw20VRVLm2jzVCOx0SN_Hpje">https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Manual_Ensemble_Colab.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- To fix issues with BS variant of anvuew&rsquo;s de-reverb model in UVR &ldquo;change stft_hop_length: 512 to stft_hop_length: 441 so it matches the hop_length above&rdquo; in the yaml file. It doesn&rsquo;t happen on &nbsp;(thx lew).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If that line is not present in your model config go to the settings, then choose MDX In the advanced menu, then click the &quot;clear auto-set cache&quot; button.</span></p><p class="c1"><span>Then go back to the main settings, click &quot;reset all settings to default&quot; and restart the app (thx santilli_).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you still have error on every attempt of using GPU Conversion in UVR on AMD GPU (you might potentially use outdated drivers and/or Windows), go to Ultimate Vocal Remover\torch_directml and replace DirectML.dll from C:\Windows\System32\AMD\ANR (make backup before). Experimentally, you can use this older </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1dxmG0cfclGMkFLfdoKAfQaDkx3Rcspku/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742217639&amp;usg=AOvVaw1MnBjabn6IFwBzmvnF2_YQ">1.9.1.0</a></span><span class="c0">&nbsp;version of the library. Restart UVR after replacing the file! </span></p><p class="c1"><span class="c0">Be aware that results achieved without GPU Conversion that way, at least on certain configurations, might have noisy static instead of bleeding in less noisy parts of stems vs when using only CPU (basically, MDX noise can be somehow different on GPU and denoise standard only alleviates the issue to some extent, and you need to use Denoise Model option to get rid of this noise, or better solution - min spec manual ensemble of denoise disabled result and denoise model to get rid of more noise. Aufr&rsquo;s Mel-Roformer minimum denoise works worse for it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- GSEP introduced a new model called &ldquo;Vocal Remover&rdquo; dedicated for vocal extraction and is only used for vocals, instrumental stem still uses the old model. Might be good at extracting SFX as well. (becruily/wancite)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app&amp;sa=D&amp;source=editors&amp;ust=1765035742219235&amp;usg=AOvVaw1OsIwxzOB28Oat1qsdpdas">uvronline.app</a></span><span class="c0">) Mel-Roformer De-noise released for premium users.</span></p><p class="c1"><span class="c0">&ldquo;This model is optimized for music and vocals. You can choose between two aggressiveness settings:</span></p><p class="c1"><span class="c0">minimum - removes fewer effects such as thunder rolls</span></p><p class="c1"><span class="c0">average - usually removes more noise&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;The new model works as good as my UVR De-noise model, or even better.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.2u19k7ty9b00">drumsep</a></span><span>&nbsp;</span><span>model by aufr33 and jarredou added on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742220152&amp;usg=AOvVaw2pm4xGFJDlXUIj8tl1MzmQ">MVSEP</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai&amp;sa=D&amp;source=editors&amp;ust=1765035742220245&amp;usg=AOvVaw3675Uw6NV_tXiFIh4ZwClh">uvronline.app</a></span><span class="c0">&nbsp;too</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Not Eddy&rsquo;s multi-arch Colab released in form of UI (like in e.g. KaraFan)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Eddycrack864/UVR5-UI/blob/main/UVR_UI.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742220718&amp;usg=AOvVaw3Nh-1Qmttr4qsluXlDs2DY">https://colab.research.google.com/github/Eddycrack864/UVR5-UI/blob/main/UVR_UI.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>In case of &ldquo;FileNotFoundError: [Errno 2]&rdquo; try other location than &ldquo;input&rdquo;, or other Google account in case of ERROR - mdxc_separator (helps for both).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New Mel-Roformer de-reverb model by anvuew was released</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2226805511&amp;sa=D&amp;source=editors&amp;ust=1765035742221529&amp;usg=AOvVaw1ylGaxCsYcXzvfN8iL4T9U">https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1#issuecomment-2226805511</a></span></p><p class="c1"><span class="c0">(to make it work with UVR, delete &ldquo;linear_transformer_depth: 0&rdquo; from the YAML file, copy the model to MDX_Net_Models and YAML config to model_data\mdx_c_configs)</span></p><p class="c1"><span class="c0">Also added on MVSEP.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I&#39;m definitely hanging onto it. It reminds me of the equivalent dereverb mdx model, which I&#39;ve always liked (when it works). The roformer model is cleaner in some ways, though slightly more filtered and aggressive.</span></p><p class="c1"><span class="c0">Neither the roformer or mdx models respond to mono reverb. However, adding a stereo reverb on top solves that, especially with roformer.&rdquo; (Musicalman)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;anvuew&#39;s models can remove reverb effect only from vocals. Old FoxJoy&#39;s model works with full track.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- BS-Roformer -||- - a bit better SDR</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2229279531&amp;sa=D&amp;source=editors&amp;ust=1765035742223196&amp;usg=AOvVaw2AkZYC42F9Tbc3nwv9ax0c">https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1#issuecomment-2229279531</a></span></p><p class="c1"><span class="c0">(To fix &ldquo;The size of tensor a&rdquo;... error with BS variant of anvuew&rsquo;s de-reverb model &ldquo;change stft_hop_length: 512 to stft_hop_length: 441 so it matches the hop_length above&rdquo; in the yaml file.) thx lew</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Added in the Colab:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742224118&amp;usg=AOvVaw2D_5UTOMqnJKiWy710aKC2">https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The below model has been added. Ensembles updated as well.</span></p><p class="c1"><span>Some users report &ldquo;bleed from some synths and bass guitar&rdquo; &ldquo;Some drums instruments are low volume on drums only. While mel roformer makes a good clean one&rdquo; &ldquo;On some parts it&#39;s almost like it doesn&#39;t separate anything for a few seconds and on some other parts, it&#39;s working just really great. The demucs one is way more stable when listening to individual model separations on the same song.&rdquo; (or simply older ensemble)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) I finished my drums models. Results:</span></p><p class="c1"><span class="c0">MelRoformer SDR: 12.76</span></p><p class="c1"><span class="c0">Demucs4 (finetuned) SDR: 12.04</span></p><p class="c1"><span class="c0">Ensemble Mel + Demucs4 SDR: 13.05</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">for comparison:</span></p><p class="c1"><span class="c0">Old Best Demucs4 SDR: 11.41</span></p><p class="c1"><span class="c0">Old Best Ensemble SDR: 11.99</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">New models will be added on site soon.&rdquo; ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For comparison, the Mel-Roformer available on x-minus trained by viperx has 12.5375 SDR.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-</span><span class="c22">&nbsp;</span><span>(for models trainers)</span><span class="c22">&nbsp;</span><span>&ldquo;Official SCNet repo has been updated by the author with training code: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/starrytong/SCNet&amp;sa=D&amp;source=editors&amp;ust=1765035742226310&amp;usg=AOvVaw0YrqhVxboT9OBerBk4a66k">https://github.com/starrytong/SCNet</a></span><span class="c23 c15 c30">&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;ZF&#39;s script already can train SCNet, but currently it doesn&#39;t give good results&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v.1.0.6&amp;sa=D&amp;source=editors&amp;ust=1765035742226713&amp;usg=AOvVaw0OmCjq9NQcA5iC_5GYb5TL">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/</a></span></p><p class="c1"><span class="c0">The author&rsquo;s checkpoint:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1CdEIIqsoRfHn1SJ7rccPfyYioW3BlXcW/view&amp;sa=D&amp;source=editors&amp;ust=1765035742227018&amp;usg=AOvVaw09gC_oTlS8zTjMTEf8JAO-">https://drive.google.com/file/d/1CdEIIqsoRfHn1SJ7rccPfyYioW3BlXcW/view</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;One diff I see between author config and ZF&#39;s one, is that dev has used learning rate of 5e-04 while it&#39;s 4e-05 in ZF config. And main issue ZF was facing was slow progress (while author said it worked as expected using ZF training script </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/starrytong/SCNet/issues/1%23issuecomment-2063025663&amp;sa=D&amp;source=editors&amp;ust=1765035742227624&amp;usg=AOvVaw0Kw5h06qrytapSF768y-hM">https://github.com/starrytong/SCNet/issues/1#issuecomment-2063025663</a></span><span class="c0">)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The author:</span></p><p class="c1"><span class="c0">&ldquo;All our experiments are conducted on 8 Nvidia V100 GPUs.</span></p><p class="c1"><span class="c0">When training solely on the MUSDB18-HQ dataset, the model is</span></p><p class="c1"><span class="c0">trained for 130 epochs with the Adam [22] optimizer with an initial</span></p><p class="c1"><span class="c0">learning rate of 5e-4 and batch size of 4 for each GPU. Nevertheless,</span></p><p class="c1"><span class="c0">we adjust the learning rate to 3e-4 when introducing additional data</span></p><p class="c1"><span class="c0">to mitigate potential gradient explosion.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Q: So that mean that you have to modulate the learning rate depending on the size of the dataset?</span></p><p class="c1"><span class="c0">I think it&#39;s the first time I read something in that way.</span></p><p class="c1"><span class="c0">A: Yea, I suppose because the dataset is larger you need to ensure the model sees the whole distribution instead of just learning the first couple of batches&rdquo;</span></p><p class="c1"><span>- </span><span class="c0">jarredou/frazer</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span>SCNet p</span><span>aper: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2401.13276&amp;sa=D&amp;source=editors&amp;ust=1765035742229359&amp;usg=AOvVaw0EOdfgc34_GzTw-Hk5ESSZ">https://arxiv.org/abs/2401.13276</a></span></p><p class="c1"><span class="c0">On the same dataset (MUSDB18-HQ), it performs a lot better than Demucs 4 (Demucs HT).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Melband is still SOTA cause if you increase the feature dimensions and blocks it gets better</span></p><p class="c1"><span class="c0">you can&#39;t scale up scnet cause it isn&#39;t a transformer. It&#39;s a good cheap alt version tho&rdquo;</span></p><p class="c1"><span class="c0">Still, it might potentially give interesting results when training will be mastered to the point when e.g. SDR will be in pair with at least MDX-Net models as they can still be better than Roformers for instrumentals in many cases (e.g. MDX-Net tend to have less muddy instrumentals - every arch can have its own unique sound characteristics and might be potentially useful for ensembling).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (jarredou) &ldquo;I&#39;ve released the Drums Separation model trained by aufr33</span></p><p class="c1"><span class="c0">(on my not-that-clean drums dataset).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Stems: kick, snare, toms, hihat, ride, crash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It can already be used, but training is not fully finished yet.</span></p><p class="c1"><span class="c0">The config allows training on not so big GPUs [n_fft 2048 instead of 8096], it&#39;s open to anyone to resume/fine-tune it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For now, it&#39;s struggling a bit to differentiate ride/hh/crash correctly, kick/snare/toms are more clean.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Download </span></p><p class="c1"><span>[attached config includes also necessary training parameters for training further using ZFTurbo </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742231958&amp;usg=AOvVaw1LVHt1gOG0kEGNlOIgXQ6C">repo</a></span><span>]</span><span>: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/models/releases/tag/aufr33-jarredou_MDX23C_DrumSep_model_v0.1&amp;sa=D&amp;source=editors&amp;ust=1765035742232224&amp;usg=AOvVaw2W-jbRjdccLmuLBiB5LPnK">https://github.com/jarredou/models/releases/tag/aufr33-jarredou_MDX23C_DrumSep_model_v0.1</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Use on Colab: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742232757&amp;usg=AOvVaw2TaAVDX4_xd9rRguVpnhHv">https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb</a></span><span>&rdquo; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It works in UVR too. All models should be located in the following folder:</span></p><p class="c1"><span class="c0">Ultimate Vocal Remover\models\MDX_Net_Models </span></p><p class="c1"><span class="c0">Don&#39;t forget about copying the config file to: model_data\mdx_c_configs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The model achieved much better SDR on small private jarredou&#39;s evaluation dataset compared to the previous drumsep model by Inagoy which was based on a worse dataset and older Demucs 3 arch.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>The dataset for further training is available in the drums section of </span><span class="c4"><a class="c3" href="#h.k3cm3bvgsf4j">Repository of stems/multitracks</a></span><span class="c0">&nbsp; - you can potentially clean it further and/or expand the dataset so the results might be better after resuming the training from checkpoint. Using the current dataset, the SDR might stall for quite some amount of epochs or even decrease, but it usually increases later, so potentially training it further to 300-500-1000 epochs might be beneficial.</span></p><p class="c1"><span class="c0">&ldquo;I&rsquo;ve had models where SDR changes by 0.01 but fullness/bleedless change with 10-15 points, I wouldn&rsquo;t trust it that much&rdquo; - becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Current model metrics:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Instr SDR kick: 18.4312</span></p><p class="c1"><span class="c0">Instr SDR snare: 13.6083</span></p><p class="c1"><span class="c0">Instr SDR toms: 13.2693</span></p><p class="c1"><span class="c0">Instr SDR hh: 6.6887</span></p><p class="c1"><span class="c0">Instr SDR ride: 5.3227</span></p><p class="c1"><span class="c0">Instr SDR crash: 7.5152</span></p><p class="c1"><span class="c0">SDR Avg: 10.8059&rdquo; Aufr33 </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">And if evaluation dataset hasn&#39;t changed since then, the old Drumsep SDR:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;kick &nbsp;: 13.9216</span></p><p class="c1"><span class="c0">snare : &nbsp;8.2344</span></p><p class="c1"><span class="c0">toms &nbsp;: &nbsp;5.4471</span></p><p class="c1"><span class="c0">(I can&#39;t compare cymbals score as it&#39;s different stem types)&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">After initial jarredou&rsquo;s training in Colab, Aufr33 decided to train the model for additional 7 days, to at least above epoch 113 (perhaps around 150, it wasn&#39;t said precisely), while using the same config, but on a faster GPU (2x 4090).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Even epoch 5 trained on jarredou&#39;s dataset casually in free Colab (which uses Tesla T4 15GB with performance of RTX 3050, but with more VRAM) with multiple Colab accounts and very light and fast training settings, already achieved better SDR than Drumsep:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;epoch 5:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instr SDR kick: 13.9763</span></p><p class="c1"><span class="c0">Instr SDR snare: 8.4376</span></p><p class="c1"><span class="c0">Instr SDR toms: 6.7399</span></p><p class="c1"><span class="c0">Instr SDR hh: 0.7277</span></p><p class="c1"><span class="c0">Instr SDR ride: 0.8014</span></p><p class="c1"><span class="c0">Instr SDR crash: 4.4053</span></p><p class="c1"><span class="c0">SDR Avg: 5.8480</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">epoch 15:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instr SDR kick: 15.3523</span></p><p class="c1"><span class="c0">Instr SDR snare: 10.8604</span></p><p class="c1"><span class="c0">Instr SDR toms: 10.3834</span></p><p class="c1"><span class="c0">Instr SDR hh: 4.0184</span></p><p class="c1"><span class="c0">Instr SDR ride: 2.7248</span></p><p class="c1"><span class="c0">Instr SDR crash: 6.1663</span></p><p class="c1"><span class="c0">SDR Avg: 8.2509&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Don&#39;t forget to use already well separated drums (e.g. from Mel-Roformer for premium users on x-minus) from well separated instrumental as input for that model, or Jarredou MDX23 Colab fork v. 2.4 or MVSEP 4/+ ensemble (premium).</span></p><p class="c1"><span class="c0">Purely for drums separation from even instrumentals, the model might not give good results. It was trained just on percussion sounds and not vocals or anything else.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, e.g. the kick and toms might have a bit weird looking spectrograms. It&rsquo;s due to:</span></p><p class="c1"><span>&ldquo;mdx23c subbands splitting + unfinished training, these artifacts are [normally] reduced/removed along [further] training.&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/900904142669754399/1258441408109613209&amp;sa=D&amp;source=editors&amp;ust=1765035742239021&amp;usg=AOvVaw22ZlE7_K8rky11lesfrgDl">Examples</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- BTW, just for inference (separation), &ldquo;ONNX and Demucs models don&#39;t work with multi-GPU&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- In the &ldquo;experimental&rdquo; section of MVSEP, there&rsquo;s been added a new multispeaker model at the bottom.</span></p><p class="c1"><span class="c0">E.g. it can work well splitting rapping and singing overlapped in the same, previously well separated vocal stem, but:</span></p><p class="c1"><span class="c0">&ldquo;It works more or less ok on my validation [5 quite different &quot;songs&quot;], but it&#39;s a disaster on real data. I opened it for everyone, but don&#39;t expect really good results&rdquo; ZFTurbo</span></p><p class="c1"><span class="c0">- Also, there has been added a new multichannel section in &ldquo;experimental&rdquo; it&rsquo;s just for songs with 3 or more audio channels like e.g. Dolby Atmos (FLAC/WAV input supported). It&rsquo;s just BS-Roformer and there&rsquo;s &ldquo;no reason to process stereo tracks with it&rdquo;. Also, the original sample rate of the input file is preserved here.</span></p><p class="c1"><span>- One of MVSEP&rsquo;s GPU died recently, so the separations will be probably slower than usual.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- jarredou updated his </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/AudioSR-Colab-Fork/blob/main/AudioSR_Colab_Fork.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742240962&amp;usg=AOvVaw0TsqLc_fLIOtnlQ5Pl6z8m">AudioSR Colab</a></span><span class="c0">. Now &ldquo;each processed chunk is normalised at same LUFS level (fixes the volume drop issue)&rdquo; plus &ldquo;input audio is resampled accordingly to &#39;input_cutoff&#39; (instead of lowpass filtering)&rdquo;</span></p><p class="c1"><span>Now also some errors associated with mono files are fixed.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New drums model available on x-minus.pro</span></p><p class="c1"><span class="c0">&ldquo;SDR is: 12.4066.</span></p><p class="c1"><span class="c0">Thanks to @viperx for model training! The model is trained on 995 songs. A small number of my pairs were included in the dataset.&rdquo; Aufr33</span></p><p class="c1"><span>Very positive reviews so far.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New guitar model added on MVSEP</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Previous old model mdx23c: 4.87</span></p><p class="c1"><span class="c0">New mdx23c model: 6.34</span></p><p class="c1"><span class="c0">New MelRoformer model: 6.91</span></p><p class="c1"><span class="c0">Ensemble MDX23c + MelRoformer: 7.10</span></p><p class="c1"><span class="c0">Extract vocals and after apply ensemble MDX23C + MelRoformer: 7.28&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If x-minus.pro site doesn&rsquo;t work for you, use the clone instead:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp&amp;sa=D&amp;source=editors&amp;ust=1765035742242763&amp;usg=AOvVaw3OWJSjI_1XnsWk0l8UrAhD">https://uvronline.app/ai?hp</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Demudder on x-minus was updated on 13.06 (cosmetic differences)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;Some interesting updates to SL 11</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D2BoEgBGiafM&amp;sa=D&amp;source=editors&amp;ust=1765035742243224&amp;usg=AOvVaw2htmeFjjWzLQ6Kx3ZMuNCh">https://www.youtube.com/watch?v=2BoEgBGiafM</a></span><span class="c0">&rdquo;</span></p><p class="c1"><span class="c0">Seemingly, separation features got better. Coming on 19th June.</span></p><p class="c1"><span>Their new algo was </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/6689&amp;sa=D&amp;source=editors&amp;ust=1765035742243542&amp;usg=AOvVaw01Wtd12AqXP_DLkz_LrewM">evaluated</a></span><span>, and SDR is a bit worse than </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/287&amp;sa=D&amp;source=editors&amp;ust=1765035742243679&amp;usg=AOvVaw3qWpBDAKI7ubpMeaDbyAmu">htdemucs</a></span><span class="c0">&nbsp;4 stem non ft model.</span></p><p class="c1"><span class="c0">Every stem has some bleed, vocals are decent, and actually have better SDR than Demucs_ft. GPU processing in options has low utilization and is slow, they say it&rsquo;s planned to be fixed in patch. 16GB VRAM recommended at least while using brass and saxophone. Around 18 models can be used in total.</span></p><p class="c1"><span class="c0">Unmix Mulitple Voices is for speech case, not for singing case.</span></p><p class="c1"><span class="c0">Unmix Drums option can serve for further separation of drums</span></p><p class="c1"><span class="c0">&ldquo;the residual kick/snare problem is much better, but the cymbal split does still contain bleed from the rest of the song sadly&rdquo; [vs drumsep] - jasper waffles</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Eddycrack864/UVR5-NO-UI/blob/main/UVR5_NO_UI.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742244911&amp;usg=AOvVaw2GtUHHL-8gPzqvkDurpp7k">Multi-arch Colab by Not Eddy</a></span></p><p class="c1"><span class="c0">incorporates: MDX-Net, MDX23C, Roformers (incl. 1053), Demucs, and all VR models, YouTube support and batch separation. It uses broken overlap from OG beta UVR code. Use the one below for just Roformers and now also 1053 instead:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742245522&amp;usg=AOvVaw2Ny84bMdqv8-kFia9nGxcx">Colab with Roformers</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New Mel-Roformer De-Crowd model released on MVSEP. It slightly surpassed SDR of the previous MDX23C model.</span></p><p class="c1"><span class="c0">It&#39;s also available publicly in the repository below:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035742246148&amp;usg=AOvVaw3eJnd-cdfUyV0DCs9iUFIJ">https://github.com/ZFTurbo/Music-Source-Separation-Training</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>To use it in UVR, Go to UVR\models folder, and paste </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1eO6rDhxh77eC-l0IHF16mQNwrrWOX31h&amp;sa=D&amp;source=editors&amp;ust=1765035742246442&amp;usg=AOvVaw1pqBu5XJwBj_kYj4S1xP-Q">that</a></span><span class="c0">&nbsp;there.</span></p><p class="c1"><span>Then change &quot;dim_t&quot; value to 801 at the very bottom of: &ldquo;model_mel_band_roformer_crowd.yaml&rdquo; in mdx_c_configs subfolder. Don&rsquo;t use overlap above 4.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Drums Roformer model shared publicly by Yolkis</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2156069553&amp;sa=D&amp;source=editors&amp;ust=1765035742247126&amp;usg=AOvVaw2C-pYO-LpkXIZ0FZjAn3sw">https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1#issuecomment-2156069553</a></span></p><p class="c1"><span>Not totally bad results as for 7.68 SDR, but it was trained on subpar GPU for Roformers for only 5 days. To use it in UVR, delete linear_transformer_depth line in the config.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;(x-minus.pro) &ldquo;The new Strings model by viperx has been added!&rdquo; based on Mel-Roformer arch.</span></p><p class="c1"><span class="c0">Good results reported so far.</span></p><p class="c1"><span class="c0">Sometimes it can pick up brass.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus.pro) &ldquo;Demudder has been added!</span></p><p class="c1"><span class="c0">This only works with the mel-roformer inst/vocal model. You need premium to use it.&rdquo;</span></p><p class="c1"><span class="c0">It works only for instrumentals. Vocals are unaffected. It fills holes in the spectrum, basing on both vocals and instrumental stems (e.g. it won&rsquo;t serve to just recover lossy mp3).</span></p><p class="c1"><span class="c0">The option shows after you uploaded/processed a track (at least with mel-roformer model).</span></p><p class="c1"><span class="c0">It&rsquo;s capable of providing better results than max_mag a.k.a. BS and Mel Roformer ensemble (premium), depends on a song.</span></p><p class="c1"><span>SDR-wise, it&rsquo;s not much worse than original model results (16.48 vs 17.32).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;New VST for real time source separation (probably same models [like in] MPC stems)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D0Js5bWQWY7M&amp;sa=D&amp;source=editors&amp;ust=1765035742249297&amp;usg=AOvVaw1wOxi798q76pw6dDfvWdWH">https://www.youtube.com/watch?v=0Js5bWQWY7M</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://products.zplane.de/products/peelstems/&amp;sa=D&amp;source=editors&amp;ust=1765035742249541&amp;usg=AOvVaw14VVOlapFiuBJX_56tdf8J">https://products.zplane.de/products/peelstems/</a></span><span>&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mel-RoFormer de-crowd by aufr33 and viperx model files have been released publicly.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>DL: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://buzzheavier.com/f/GV6ppLupAAA&amp;sa=D&amp;source=editors&amp;ust=1765035742250061&amp;usg=AOvVaw3GeB_1mPxqnvYX30enZ8Rr">https://buzzheavier.com/f/GV6ppLupAAA</a></span></p><p class="c1"><span>Conf: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://buzzheavier.com/f/GV6psmJpAAA&amp;sa=D&amp;source=editors&amp;ust=1765035742250245&amp;usg=AOvVaw2-2Ze70wczfTGJPsJEVf0s">https://buzzheavier.com/f/GV6psmJpAAA</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;You can use ZFTurbo&#39;s code [check his GitHub] to run this model. If you use it in your project, please credit us&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To use it in UVR 5, change &ldquo;the name of the model itself to the name of the YAML file.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">This model only works the best when at 2 overlap, since anything higher than that it&#39;ll stop isolating parts of the song entirely.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or else, you can also check out setting &nbsp;&ldquo;inference.dim_t&rdquo; parameter at the bottom of the yaml file to 801. &ldquo;Leaving dim_t at 256 (2.5seconds) makes the model only usable with overlap=2 (2 seconds) with current beta code. Higher value will result is missing/non-processed parts.&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The Roformer model does a better job at retaining the instruments and vocals as well as some sound effects and synths better than the MDX-NET decrowd, but at the cost of crowd bleed. While the MDX-NET decrowd model does a better job at removing most of the crowd at the cost of instrumental bleed into the crowd stem.</span></p><p class="c1"><span class="c0">Sometimes [the old model] mistakes the fuzzy sounds of guitar as crowd noise</span></p><p class="c1"><span class="c0">Also isolates some kicks in songs&rdquo; - Kashi</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;For really difficult live songs (where the crowd is overwhelmingly loud to the point where you can&#39;t hear the band properly) sometimes filtering vocals with mel roformer on xminus THEN running the vocals stem through the mdx decrowd model sometimes helps&rdquo; - isling</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus) &ldquo;The new Wind / Saxophone model has been added! It completely replaces the old UVR model [on the site]. Thanks to viperx for model training.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Really great model! Big step since the last VR winds model.&rdquo; It works better for brass instruments than wind.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus) &ldquo;BS-RoFormer Bass model added! This is a model by viperx.&rdquo; Aufr33</span></p><p class="c1"><span class="c0">&rdquo;much better at treble-heavy bass tones than demucs&rdquo;</span></p><p class="c1"><span>It&rsquo;s different from the latest MVSEP bass model. Viperx&rsquo; model might be cleaner, but pick up less bass at times. Both are improvement over demucs_ft ~</span><span class="c10">drypaintdealerundr</span></p><p class="c1"><span class="c41">It&rsquo;s best in no piano stem.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (x-minus) &ldquo;Piano beta model added! Thanks to viperx for model training.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus) &ldquo;Now all models except BVE are available for free, even without registration!</span></p><p class="c1"><span class="c0">The only restrictions:</span></p><p class="c1"><span class="c0">Only mp3 downloads are available</span></p><p class="c1"><span class="c0">No ensemble</span></p><p class="c1"><span class="c0">10 minutes of audio per day (past 24 hours). This is enough for testing 2-3 songs.</span></p><p class="c1"><span class="c0">Max song duration is 8 minutes</span></p><p class="c1"><span class="c0">It&#39;s not available through Tor, and it&#39;s not available in some countries.&rdquo; Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Why BVE models are excluded? [from free option]</span></p><p class="c1"><span>A: &ldquo;Because in the free version, wav files are deleted immediately after processing is complete. This makes it impossible to download some stems. In addition, this model necessarily uses MDX for preprocessing, which is very compute-intensive.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (mvsep) Bass model is online. The metrics:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Single models:</span></p><p class="c1"><span class="c0">HTDemucs4 bass SDR: 12.5295</span></p><p class="c1"><span class="c0">BSRoformer bass SDR: 12.4964</span></p><p class="c1"><span class="c0">MelRoformer bass SDR: 11.86</span></p><p class="c1"><span class="c0">MDX23C bass SDR: 11.20</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Models on site:</span></p><p class="c1"><span class="c0">HTDemucs4 + BSRoformer Ensemble (It&#39;s available on site as MVSep Bass (bass, other)): 13.25</span></p><p class="c1"><span class="c0">Ensemble 4 stems and All-In (from site): 13.34</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For comparison:</span></p><p class="c1"><span class="c0">Ripple lossless (bass): 13.49</span></p><p class="c1"><span>Sami-ByteDance v1.0: 13.82</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- GSEP announced works on a new model</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-RoFormer Karaoke model added on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035742257285&amp;usg=AOvVaw23AfpKXzNBmyho-OkjyQw4">x-minus.pro</a></span></p><p class="c1"><span class="c0">&ldquo;one of the cleanest lead vocals result[s]&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;I noticed that the new karaoke model considers vocals as lead vocals, even if they are quite wide. In other words, it has a much larger tolerance for vocal width than other karaoke models. This means that backing vocals that sound almost centered can be removed along with the lead vocal. If I apply a stereo expander, the model produces more adequate results. So when I add the Lead vocal panning setting, the &quot;center&quot; will actually work as &quot;stereo -20%&quot; (for example).&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Q: wouldn&rsquo;t this mean that there will be more backing vocal bleed in the lead vocal stem too?</span></p><p class="c1"><span class="c0">A: The model behaves differently. In some cases, it completely isolates vocals, in other cases it gets confused and vocals appear in both stems at once, in other cases it doesn&#39;t isolate at all.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What are the differences between mel-roformer karaoke and the last model?</span></p><p class="c1"><span class="c0">A: &ldquo;If the vocals don&#39;t contain harmonies, this model (Mel) is better. In other cases, it is better to use the MDX+UVR Chain ensemble for now.&rdquo;</span></p><p class="c1"><span class="c0">Although your mileage will still vary on a song, e.g. &ldquo;For most of the songs I tried it worked very well. Example: &quot;From Souvenirs to Souvenirs&quot; by Demis Roussos. It&#39;s the only model as of now which can seperate the lead from the back vocals correctly&rdquo; dca100fb8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Izotope RX11 officially released. Seeing by the unencrypted onnx model file names, it uses demucs_ft for stem separation now, but maybe it&rsquo;s not the same model as the public one, as all stems &ldquo;null back to the input stereo which is something standard demucsht doesn&#39;t appear to do (...) mdx seems to always null luckily.&rdquo; The feature still doesn&rsquo;t use CUDA/Nvidia GPU for processing (and there&rsquo;s no such option anywhere). It&rsquo;s still an improvement over RX8-10 as they used in-house Spleeter 22kHz models before.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1240418057491447829&amp;sa=D&amp;source=editors&amp;ust=1765035742260524&amp;usg=AOvVaw19XDhCQCVqyapHlIWG5sc9">Comparison</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DMhUEmvneerc&amp;sa=D&amp;source=editors&amp;ust=1765035742260761&amp;usg=AOvVaw019DMtaBdCBB3NT6t7ZkMW">https://www.youtube.com/watch?v=MhUEmvneerc</a></span></p><p class="c1"><span>New </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.izotope.com/en/products/rx.html&amp;sa=D&amp;source=editors&amp;ust=1765035742260903&amp;usg=AOvVaw1b8lN9xamq57d8xRxanmds">features</a></span><span class="c0">&nbsp;(e.g. clean up dialogue in real time).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Logic Pro 11 now incorporates a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://support.apple.com/pl-pl/guide/logicpro/lgcp61bae908/mac&amp;sa=D&amp;source=editors&amp;ust=1765035742261187&amp;usg=AOvVaw01duCE86sBXxCbT44-Up9c">Stem Splitter</a></span><span>. Results vary from good to bad (and worse than known solutions) depending on a song.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mel-Roformer De-crowd model added on x-minus.pro.</span></p><p class="c1"><span>Results are more accurate than in the old MDX model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.yy2jex1n5sq">GSEP</a></span><span class="c0">&nbsp;has been updated.</span></p><p class="c1"><span class="c0">Free option for all stems has been removed. There&#39;s only a 20 minutes free trial. WAV is only for paid users.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Vocals and all other stems (including instrumentals/others) are paid, and length for each stem is taken from your account separately for each model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">No credit is not required for the trial. </span></p><p class="c1"><span class="c0">For free, only mp3 output and 10 minutes input limit.</span></p><p class="c1"><span class="c0">For paid users there&#39;s a 20 minutes limit, and mp3/wav output, plus paid users have faster queue, shareable links, and long term results storage.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://studio.gaudiolab.io/pricing&amp;sa=D&amp;source=editors&amp;ust=1765035742262889&amp;usg=AOvVaw1Y9KoHOh1PfrubnCpQS5f2">Pricing</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">7$/60 minutes </span></p><p class="c1"><span class="c0">16$/240 minutes </span></p><p class="c1"><span class="c0">50$/1200 minutes</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Seems like there weren&#39;t many changes in the model (if there weren&rsquo;t even more vocal residues introduced since then). People still have similar complaints to it. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DOGWaoBOkiMg&amp;sa=D&amp;source=editors&amp;ust=1765035742263476&amp;usg=AOvVaw1puzC22OsqWj8lEq9vJz4w">Comparison</a></span><span class="c0">&nbsp;video.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>There was an average of 0.13 SDR increase for mp3 output and first 19 songs from multisong dataset evaluation, but judging by no audible difference for most people, they could simply change some parameters for inference.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The old files from previous separations on your account didn&#39;t get deleted so far.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus) max_mag of (?-)Roformer and Demucs (drums only) added </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;now the synths and everything else feels muddy</span></p><p class="c1"><span class="c0">noticed the drums in some places (mainly louder-ish bits) sound a bit weird</span></p><p class="c1"><span class="c0">mostly lower end like bass drum instead of hi hats</span></p><p class="c1"><span>great improvement overall&rdquo; isling</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Doubledouble might have some occasional hiccups on downloading. If you encounter very slow download, don&rsquo;t attempt retrying the same download, but generate a new download query. Do it even three times in a row if necessary or wait half an hour and retry. Also, you can check the option to upload your result on external hosting.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus) &ldquo;Added max_mag ensemble for Mel-RoFormer model! It combines Mel and BS results, making the instrumentals even less muddy, while better preserving saxophone and other instruments.&rdquo;</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1"><span>- New Mel-Roformer model trained by Kimberley Jensen on Aufr33 dataset dropped exclusively on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035742265897&amp;usg=AOvVaw1vAJIysLuA5Ihf-MdhLZNL">x-minus</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">&ldquo;This model will now be used by default and in ensemble with MDX23C (avg).&rdquo;</span></p><p class="c1"><span class="c0">It&rsquo;s less muddy than viperx model, but can have more vocal residues e.g. in silent parts of instrumentals, and can be more problematic with wind instruments putting them in vocals, plus it might leave more instrumental residues in vocals. </span></p><p class="c1"><span class="c0">&ldquo;godsend for voice modulated in synth/electronic songs&rdquo;</span></p><p class="c1"><span>SDR is higher than viperx model (UVR/MVSEP) but lower than fine-tuned 04.24 model on MVSEP.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New UVR patch has been released. It fixes using OpenCL on AMD and Intel GPUs (just make sure you have GPU processing turned on in the main window and (perhaps only in some cases) OpenCL turned on in the settings).</span></p><p class="c1"><span class="c0">Plus, it fixes errors when the notification chimey in options is turned on.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_4_14_24_18_7_BETA_full_Roformer.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742267599&amp;usg=AOvVaw0vUXz3bn2sCxf2vlVYQQil">https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_4_14_24_18_7_BETA_full_Roformer.exe</a></span><span class="c0">&nbsp;(be aware that you can lose your current UVR settings after the update)</span></p><p class="c1"><span class="c0">To use BS-Roformer models, go to download center and download them in MDX-Net menu (probably temp solution).</span></p><p class="c1"><span class="c0">For 4GB VRAM and at least AMD/Intel GPUs, you can try out segments 32, overlap 2</span></p><p class="c1"><span class="c0">and dim_t 201 with num_o 2 (dim_t is at the bottom of e.g. model_bs_roformer_ep_368_sdr_12.9628.yaml) to avoid crashes.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You might want to check a new recommended ensemble:</span></p><p class="c1"><span class="c0">1296+1297+MDX23C HQ</span></p><p class="c1"><span>Instead of 1297 and for faster processing and similar result, make a manual ensemble with a copy of 1296 result instead. It might work in similar fashion like weighting in 2.4 Colab and model ensemble on MVSEP (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1228818808261840976&amp;sa=D&amp;source=editors&amp;ust=1765035742268932&amp;usg=AOvVaw1MY3Vyt6C5lF9lUCBhloy9">source</a></span><span>).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- VIP code allowing access to extra models in UVR currently doesn&rsquo;t work using </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">Roformer beta patch</a></span><span class="c0">&nbsp;older than #10, and MDX23C Inst Voc HQ 2 models disappeared from download center and GH. You can try to download VIP model files manually from this link and place them in Ultimate Vocal Remover\models\MDX_Net_Models directory:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/UVR-MDX-NET_Main_406.onnx&amp;sa=D&amp;source=editors&amp;ust=1765035742269944&amp;usg=AOvVaw0Ks4hpRUWomdBilJjw27vR">https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/UVR-MDX-NET_Main_406.onnx</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/UVR-MDX-NET_Main_427.onnx&amp;sa=D&amp;source=editors&amp;ust=1765035742270288&amp;usg=AOvVaw3AviElQafTB4AYFeJT3NVB">https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/UVR-MDX-NET_Main_427.onnx</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/MDX23C-8KFFT-InstVoc_HQ_2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742270675&amp;usg=AOvVaw3YpcbHuPbS3Cjix28uifWK">https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/MDX23C-8KFFT-InstVoc_HQ_2.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Of course, it&rsquo;s not all.</span><span class="c0">&nbsp;E.g. 390 340 models and old beta MDX-Net v2 fullband inst models epochs are not reuploaded. This situation might cause errors on an attempt of using Inst Voc HQ 2 in AI Hub fork of Karafan.</span></p><p class="c1"><span>Decrypted VIP repo leads to links which are offline, and also it doesn&rsquo;t contain all models. Possibly the only way to access all the VIP models in beta UVR, is to roll back to stable 5.6 version from UVR official repo, and after downloading all desired VIP models, update to the latest patch.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- According to their forum leak, iZotope RX11 might be released between May and July, and contain some &ldquo;pretty big changes&rdquo;, among others, a novel arch for separation is rumored, and a lot of options reworked. &nbsp;(cali_tay98)</span></p><p class="c1"><span class="c0">Official announcement is out:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.izotope.com/en/learn/rx-11-coming-soon.html&amp;sa=D&amp;source=editors&amp;ust=1765035742272258&amp;usg=AOvVaw0FcwTSMW4JUQEB9zgIqW8S">https://www.izotope.com/en/learn/rx-11-coming-soon.html</a></span></p><p class="c1"><span>(overhauled repair assistant, real time dialogue isolation for better separation of noise and reverb from voice recording)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- GSEP announced an update on May 9th with a WAV download option and redesigned UI.</span></p><p class="c1"><span class="c0">The site will be unavailable on 8th May.</span></p><p class="c1"><span class="c0">Noraebang (karaoke) service &ldquo;due to low usage&rdquo; will be shutdown, and your separated files deleted (you can make a backup of your files before).</span></p><p class="c1"><span class="c0">Paid plan will be offered with faster processing times and &ldquo;additional features&rdquo;.</span></p><p class="c1"><span>No model changes are announced so far. The update schedule might change.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MDX23-Colab Fork </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.4/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742273599&amp;usg=AOvVaw3vYXJn6J65RCP8ZtQP8HEn">v2.4</a></span><span class="c0">&nbsp;is out. Changes: </span></p><p class="c1"><span>&ldquo;BS-Roformer models from viperx added, MDX-InstHQ4 model added as optional, FLAC output, control input volume gain, filter vocals below 50Hz option, better chunking algo (no clicks), some code cleaning&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (x-minus) &ldquo;Added mixing of MDX23C and BS-RoFormer results (avg/bs-roformer option). So far, it works only for MDX23C.&rdquo; Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;Output has released a free AI based generator that create multitrack stem packs</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://coproducer.output.com/pack-generator&amp;sa=D&amp;source=editors&amp;ust=1765035742274782&amp;usg=AOvVaw3vsxamfWMdivPsrtw8AAxo">https://coproducer.output.com/pack-generator</a></span><span>&rdquo;</span></p><p class="c1"><span class="c0">12-seconds long audio, fullband, 8 stems (drums in one stem, electric and rhythm guitar, hammond organ, trumpet, vocals) with 8 variations</span></p><p class="c1"><span class="c0">&ldquo;this looks more like it&#39;s mixing different real instruments, rather than actually making up songs (like a diffusion based generator)&rdquo; ~jarredou/becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ensemble on MVSEP updated </span></p><p class="c1"><span class="c0">- The site is up and running after some outage </span></p><p class="c1"><span class="c0">- ZFTurbo released fine-tuned viperx model (&ldquo;ver. 2024.04&rdquo;) on MVSEP (further trained from checkpoint on a different dataset). Ensembles will be updated tomorrow. Clicking issue has been fixed.</span></p><p class="c1"><span class="c0">SDR vocals: 11.24, instrumental: 17.55 (from 17.17 in the base model)</span></p><p class="c1"><span class="c0">Depends on a song if it&rsquo;s better. Some vocals can be worse vs the previous model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Test out ensemble 1296 + 1143 (BS-Roformer in beta UVR) + Inst HQ4 (dopfunk)</span></p><p class="c1"><span>Ensembles with BS-Roformer models might not work for everyone, use manual ensemble if needed.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Viperx model added also to beta Colab by jarredou. It gives only vocals, so perform inversion on your own to get instrumental</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1pd5Eonbre-khKK_gn5kQPFtB1T1a-27p?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742277052&amp;usg=AOvVaw0sj_W_7pmOc8wsFnW9kVN5">https://colab.research.google.com/drive/1pd5Eonbre-khKK_gn5kQPFtB1T1a-27p?usp=sharing</a></span></p><p class="c1"><span>Update: now BS-Roformer is also added in the newer v.2.4 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.4/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742277357&amp;usg=AOvVaw0H1E_XYYfDsh-BajGQLYb_">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Viperx&rsquo; BS-RoFormer models have been implemented by Anjok to UVR</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.6y2plb943p9v"><span class="c50">- </span><span class="c18 c15">BS/Mel-Roformer UVR beta patch </span></h5><h5 class="c5" id="h.2qyf9msureul"><span class="c0">For GPU acceleration, UVR currently supports: <br>CUDA (NVIDIA GPUs)/DirectML (AMD and Intel GPUs; previously misnamed as OpenCL)/MPS (Mac M1 [ARM]/x86-64),<br>and even old CPUs (AMD A6-9225 Dual-Core or Intel Core 2 Quad [models with SSE4.1 tested]). DirectML is not supported for Apollo, Bandit (also incompatible with MPS), SCNet and probably Demucs 2 archs - CPU will be used automatically.<br><br>Model architectures supported: <br>MDX-Net, MDX23C (archs by kuielab), VR (voice-remover by tsurumeso, v. 4, 5 [UVR fork], 5.1), Demucs (arch by Meta; v. 1-4, only models trained on OG code, not MSST ones), BS-Roformer, Mel-Roformer (arch by Bytedance &amp; impl. by lucidrains; issues on Linux explained later), SCNet, Apollo (in Tools; for upscaling, no DirectML acceleration), BandIt (SFX, no DirectML).</span></h5><h5 class="c5" id="h.vj0a7ygbiga3"><span class="c0">It has also a feature of ensemble MDX models with different archs like MDX23C/v3 or Roformers, VR.<br>Demudder added in newer patches (currently not on Linux).</span></h5><h5 class="c5" id="h.drc68iunnhd"><span class="c0">Models for Roformers/SCNet/Bandit arch are located altogether in the MDX-Net menu.</span></h5><h5 class="c5" id="h.s4j1694osvre"><span class="c50">Apollo upscaler (Apollo) is located in Tools.<br><br>Don&rsquo;t forget to enable GPU Conversion - if it works, it speeds up separation hugely.<br><br>- Min. 4GB VRAM GPUs tested (with chunk_size = 112455 in model yaml for Roformers; more below), On AMD, 16GB VRAM recommended (so no config modifications are required). <br>- Min. NVIDIA Maxwell/900 series GPUs/compute compatibility 5 is the minimum requirement for UVR to work (at least NVIDIA GTX 650 and GT 700 series and older are unsupported returning: &ldquo;AssertionError: &quot;&quot; Traceback Error:&rdquo; or &quot;CUDNN_STATUS_NOT_INITIALIZED), although DirectML should be theoretically supported by all DX12 GPUs.<br>- For AMD, at least RX 4GB models tested (not sure about R9 200 4GB GPUs - either if on newer modded Radeon-ID drivers and/or with downgraded DirectML.dll attached with drivers, copied to UVR\torch_directml folder, but seems like someone had occasional memory issues on HD 7870 2GB, but GPU Conversion still worked). &ldquo;AssertionError: &quot;&quot; Traceback Error:&rdquo; also exist when your AMD driver/Windows is outdated (then use e.g. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1dxmG0cfclGMkFLfdoKAfQaDkx3Rcspku/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742281247&amp;usg=AOvVaw2w72nh1zLSjTNEMC9unV4U">1.9.1.0</a></span><span class="c50">&nbsp;library).</span></h5><p class="c1"><span class="c0">- Intel was confirmed to work with ARC GPUs, and Xe integrated graphics (e.g. Tiger Lake 2021) with at least MDX-Net HQ (v2) models.</span></p><p class="c1"><span>- If your separation on DirectML stuck, decrease </span><span class="c4"><a class="c3" href="#h.57eblyiq5076">chunk_size</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- RTX 5000 series support on Windows was added in a separate UVR </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mediafire.com/file_premium/4jg10r9wa3tujav/UVR_Patch_4_24_25_20_11_BETA_full_cuda_12.8.zip/file&amp;sa=D&amp;source=editors&amp;ust=1765035742282037&amp;usg=AOvVaw0ZFPbJd3YokWse4T3moh8M">patch</a></span><span class="c0">&nbsp;(or you can use OpenCL (DirectML) in options instead [slower]). The patch is not compatible with Intel/AMD GPUs, and potentially also older NVIDIA GPUs, giving the following error:</span></p><p class="c1"><span class="c0">AttributeError: module &#39;torch_directml&#39; has no attribute &#39;is_available&rsquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In patch #12 a new &ldquo;Inference mode&rdquo; option in Advanced MDX-Net&gt;Multi Network was implemented (disabled by default). In the current state, it fixes silence in separation on GTX 10XX and maybe older, but might make separations longer for other compatible GPUs. So if you have slower separations after updating UVR, check if GPU Conversion is still enabled (it&rsquo;s rather disabled by default on new installations) and you can try to turn on Inference Mode if you have RTX GPU, or potentially GTX 16XX.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Download</span></p><p class="c1"><span>(</span><span class="c20">if your download speed gets slow, use e.g. &ldquo;Free Download Manager&rdquo; on Windows or any other increasing connection count)</span><span>.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- for </span><span class="c20">Linux</span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sadly, the currently released branch working on Linux is old and doesn&rsquo;t support all models (at least without some workarounds below) and you can&rsquo;t use WINE and keep GPU acceleration.</span></p><p class="c1"><span>Some installation </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1224237442488602684&amp;sa=D&amp;source=editors&amp;ust=1765035742284259&amp;usg=AOvVaw2Jc3ZPKjbOUOB7xkQSG1HQ">directions</a></span><span>&nbsp;(from our </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/ZPtAU5R6rP&amp;sa=D&amp;source=editors&amp;ust=1765035742284361&amp;usg=AOvVaw2DIbjX35ytG_9_82bbN1Tb">Discord</a></span><span>)</span><span>&nbsp;from Roformer patch #1/2 period (or also </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1259017843211636816&amp;sa=D&amp;source=editors&amp;ust=1765035742284538&amp;usg=AOvVaw2qitBVBBFs_TFVl3pypu48">here</a></span><span>), plus comment out segmentation-models-pytorch 0.3.3 in requirements.txt </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1223850400482988143&amp;sa=D&amp;source=editors&amp;ust=1765035742284829&amp;usg=AOvVaw3k-5Mpwfceg7sBYq0519xl">here</a></span><span>&nbsp;(line 136) (</span><span>for Nvidia/CPU).<br>Current code repository for Roformers with DirectML support is located here (although at certain periods it might lack current patches):<br>(might work for non-Nvidia GPUs):<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/tree/v5.6.0_roformer_add%252Bdirectml&amp;sa=D&amp;source=editors&amp;ust=1765035742285487&amp;usg=AOvVaw1PzB3Gv0fSTZI0mvXzHTFE">https://github.com/Anjok07/ultimatevocalremovergui/tree/v5.6.0_roformer_add%2Bdirectml</a></span></p><p class="c1"><span class="c0">Judging by the date of files from 9 December 2024 in the repo at the moment, they seem to derive from outdated 12_8_24_23_30_BETA beta #9 patch (some newer models will fail with that codebase, plus it&rsquo;s before chunk_size implementation, so it rather still uses dim_t).<br>Some other potentially useful information:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/issues/1674&amp;sa=D&amp;source=editors&amp;ust=1765035742286226&amp;usg=AOvVaw3rMnLX11g8gY66278CkFbb">https://github.com/Anjok07/ultimatevocalremovergui/issues/1674</a></span></p><p class="c1"><span class="c0">Or &ldquo;you just need to use export PYGLET_SHADOW_WINDOW=0 and it&#39;ll work&rdquo;</span></p><p class="c1"><span>If you get errors anyway, like </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/issues/1890%23issue-3174151206&amp;sa=D&amp;source=editors&amp;ust=1765035742286562&amp;usg=AOvVaw1ysSq2rOXTBM1fjjcSDTJd">here</a></span><span class="c0">: <br>&ldquo;Getting requirements to build wheel did not run successfully. ... ModuleNotFoundError: No module named &#39;imp&#39;&rdquo; </span></p><p class="c1"><span class="c0">edit requirements.txt:<br>pyrubberband==0.3.0</span></p><p class="c1"><span class="c0">PyYAML==6.0</span></p><p class="c1"><span class="c0">scipy==1.9.3</span></p><p class="c1"><span class="c0">playsound</span></p><p class="c1"><span class="c0">numpy==1.23.5</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Workarounding issues with Python 3.12:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/issues/1789&amp;sa=D&amp;source=editors&amp;ust=1765035742287387&amp;usg=AOvVaw0ZgKDv_cc7v0jc_zFU5j6X">https://github.com/Anjok07/ultimatevocalremovergui/issues/1789</a></span></p><p class="c1"><span class="c0">Becruily karaoke model error fix:</span></p><p class="c1"><span class="c0">&ldquo;Those of you on linux running the current roformer_add+directml branch that cant get becruily&#39;s karaoke model working due to the same error: it seems editing line 790 in separate.py setting the keyword argument strict to False when calling load_state_dict seems to make the karaoke model load and infer properly, so I think it will work</span></p><p class="c1"><span class="c0">model.load_state_dict(checkpoint, strict=False)</span></p><p class="c1"><span class="c0">I don&#39;t know if this is a robust workaround, but I haven&#39;t observed anything behaving differently than it should yet, so if you want to give it a shot I think it will work</span></p><p class="c1"><span class="c0">TL;DR change line 790 in separate.py to the codeblock and then run again and karaoke model should work&rdquo; stephanie</span></p><p class="c1"><span class="c0">ROCm instructions for AMD (also for Windows, but currently only using WSL) <br>- for better separation speed than DirectML:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/issues/1822%23issuecomment-2824363747&amp;sa=D&amp;source=editors&amp;ust=1765035742289125&amp;usg=AOvVaw0Wl5ZpBOpHO29BXMT50BIK">https://github.com/Anjok07/ultimatevocalremovergui/issues/1822#issuecomment-2824363747</a></span></p><p class="c1"><span>You won&rsquo;t get DirectML acceleration to work using just WINE (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/issues/1888&amp;sa=D&amp;source=editors&amp;ust=1765035742289368&amp;usg=AOvVaw3MTpDtBd5NcYOFsyMXMg8u">error</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">Fix for&rdquo; &ldquo;ModuleNotFoundError: No module named &#39;audioread&rsquo;&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/issues/1797%23issuecomment-3315191055&amp;sa=D&amp;source=editors&amp;ust=1765035742289839&amp;usg=AOvVaw10kF3F_-nzm_etZD5w8byW">https://github.com/Anjok07/ultimatevocalremovergui/issues/1797#issuecomment-3315191055</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Fixing issues in Matchering on Linux:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Succeeded to run after modifying UVR.py :</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">match.process(</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; target=target,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reference=reference,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; results=[match.save_audiofile(save_path, wav_set=self.wav_type_set),],</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; )</span></p><p class="c1"><span class="c0">to</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">match.process(</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; target=target,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reference=reference,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; results=[match.pcm16(save_path)]</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; )</span></p><p class="c1"><span class="c0">&ldquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Below you&rsquo;ll find a download of ready packages <br></span><span class="c6">(they contain isolated Python environment - so you don&rsquo;t have to mess with your local Python installation - you don&rsquo;t even have to have Python installed on your computer)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">- Fixing matching errors</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/issues/2018%23issue-3564850746&amp;sa=D&amp;source=editors&amp;ust=1765035742292622&amp;usg=AOvVaw0lhvGLtz5Nc2lg-j6p7BYT">https://github.com/Anjok07/ultimatevocalremovergui/issues/2018#issue-3564850746</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span><br>- </span><span class="c6">for macOS</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">- UVR Roformer beta patch #13.1</span></p><p class="c1"><span class="c0">(beta_0115_MacOS_arm64_hf)</span></p><p class="c1"><span class="c0">which applies a hotfix to address a few graphics issues. Be aware that it doesn&rsquo;t incorporate demudder from Windows patch #14:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mac M1 (arm64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_arm64_hf.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742293536&amp;usg=AOvVaw0PKKzNBUuh7KlcMzQZSSC0">Link</a></span></p><p class="c1"><span>- Mac Intel (x86_64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_x86_64_hf.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742293800&amp;usg=AOvVaw1SJIRsu03VzE1TVStkGL0W">Link</a></span><span class="c0">&nbsp;(it went offline for some reason; older version below)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Note: Some people get error about failed malicious software check. Then check patch #9 below or read &ldquo;MacOS Users: Having Trouble Opening UVR?&rdquo; section in the </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui?tab%3Dreadme-ov-file%23macos-installation&amp;sa=D&amp;source=editors&amp;ust=1765035742294337&amp;usg=AOvVaw3IY1h6RtYfZrEZUaTsvMCj">repo</a></span><span class="c6">. Plus:</span></p><p class="c1"><span class="c6">&ldquo;Functionality for systems running macOS Catalina or lower is not guaranteed&rdquo;.</span></p><p class="c1"><span class="c20">Also: &ldquo;What ended up working for me was to make sure that UVR lived in my root level Applications folder. I normally have an &#39;Installs&#39; folder inside of Applications to help me keep track of things I have downloaded and installed. Nothing would load from the Installs folder, but worked fine from the root Applications folder.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older Mac versions:</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">UVR beta Roformer patch #13</span></p><p class="c1"><span class="c58">V</span><span class="c0">R_Patch_1_15_25_22_30_BETA:</span></p><p class="c16 c1"><span>- Mac M1 (arm64) users -</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742296116&amp;usg=AOvVaw3epHzn9nfXMssMxUfrwg-m">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742296339&amp;usg=AOvVaw0GzN26pfEHDv3d3ZnMEHbG">Link</a></span></p><p class="c16 c1"><span>- Mac Intel (x86_64) users -</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742296628&amp;usg=AOvVaw34cD24SL9ooH4WMtF4-a9e">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742296789&amp;usg=AOvVaw04UBjNbGUab7h3jMVUrSdD">Link</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">UVR Roformer beta patch #9:<br>UVR_Patch_12_8_24_23_30_BETA:</span></p><p class="c1"><span>Mac M1 (arm64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_1208_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742297276&amp;usg=AOvVaw3WVC8yAvJN0COBe1Jkchby">Link</a></span></p><p class="c1"><span>Mac Intel (x86_64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_1208_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742297636&amp;usg=AOvVaw3-ZmoMVXPRt9k8trCrrDAf">Link</a></span><span><br>(Patch #9 fixes mainly Apollo arch issues) <br></span></p><p class="c1"><span>Apollo arch was made compatible with MacOS MPS (metal) but it might be unstable and very RAM intensive - use chunk size over 7 to prevent errors.<br>Apollo is now compatible with all Lew models (fixed incompatibility with any other than previously available in Download Center). Fixed Matchering (presumably regression).<br><br>C</span><span class="c0">hangelog for Mac since patch #2 (older patches later below):</span></p><p class="c1"><span>&ldquo;Roformer checkbox now visible for unrecognized Roformer models&rdquo; so now you can use custom Roformer models on MacOS Roformer patch without copying/modifying configuration files from Windows version or other users. Plus it includes all the previous fixes in the previously released patch (overlap code fixed, so no stem misalignment should occur on certain overlap settings - higher overlap now means longer separation - so it&#39;s the opposite now)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span>for </span><span class="c6">Windows</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">- (optional) UVR Roformer beta patch #15 (or more precisely 14b) fixing issues with not working CUDA on RTX 5000 series GPUs. It might not be compatible with older GPUs.</span></p><p class="c1"><span>- Full Install: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mediafire.com/file_premium/4jg10r9wa3tujav/UVR_Patch_4_24_25_20_11_BETA_full_cuda_12.8.zip/file&amp;sa=D&amp;source=editors&amp;ust=1765035742300058&amp;usg=AOvVaw34KXnc8eQojYHdWmjTENsB">Download</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">- UVR Roformer beta patch #13 fixing issue with no sound on some Roformer models (like avvuew&rsquo;s de-reverb) on GTX 10XX or older:</span></p><p class="c1"><span class="c0">UVR_Patch_1_15_25_22_30_BETA:</span></p><p class="c16 c1"><span>&ldquo;- Full Install:</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_1_15_25_22_30_BETA_full.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742300755&amp;usg=AOvVaw2y8VVDSoWE8DhXlTmcd87x">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_1_15_25_22_30_BETA_full.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742300892&amp;usg=AOvVaw38GpAp27eDQNcVHXNPD8Ok">Link</a></span></p><p class="c16 c1"><span>- Patch Install (use if you still have non-beta UVR installed, e.g. 5.6, not 5.6.x):</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_Patch_1_15_25_22_30_BETA_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742301199&amp;usg=AOvVaw0Czg8iB7xUfX0JeEayLUS3">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_Patch_1_15_25_22_30_BETA_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742301327&amp;usg=AOvVaw33Yr41PkULXLLg1zR5lM0t">Link</a></span></p><p class="c16 c1"><span>- Small Patch Install (have any Roformer patch previously installed for this to work):</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_15_25_22_30_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742301665&amp;usg=AOvVaw0XltjxYVTEBihgOj_Qqx0C">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_15_25_22_30_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742301789&amp;usg=AOvVaw2tboWnkzyqOxr2UHZQyYKP">Link</a></span></p><p class="c16 c1"><span>The issue was some older GPU&#39;s are not compatible with Torches &quot;Inference Mode,&quot; (which is apparently faster) so it&#39;s now using &quot;No Grad&quot; mode instead. Users can switch back to using &quot;Inference Mode&quot; via the advanced multi-network options. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1329312294521405493&amp;sa=D&amp;source=editors&amp;ust=1765035742302362&amp;usg=AOvVaw1Er2NR_Jc2cvtOy3VK5qHG">More</a></span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c1"><span>- UVR Roformer beta small patch #14 - the long anticipated </span><span class="c22">demudder </span><span class="c0">added:</span></p><p class="c1"><span>UVR_Patch_1_21_25_2_28_BETA: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_21_25_2_28_BETA_small_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742302866&amp;usg=AOvVaw0EoSYPrePZuaa7Dke0kuvj">Link</a></span><span><br>It&rsquo;s a small patch (you must have a </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">Roformer Patch</a></span><span class="c0">&nbsp;[e.g. #13 above] previously installed for this to work).<br>Also, minor bugs fixed, calculate compensation for MDX-Net v1 models added. </span></p><p class="c16 c1"><span class="c0">The MacOS version will be released later.</span></p><p class="c16 c1"><span class="c0">Demudder troubleshooting:</span></p><p class="c16 c1"><span class="c0">- Be aware that at least Phase Rotate doesn&rsquo;t work on AMD and 4GB VRAM GPUs on even 88200 chunk size (prev. dim_t 201 - 2 seconds) and 800MB Roformers like Becruily&rsquo;s, while 112455 (2,55s, prev. dim_t = 256) works fine for normal separation.</span></p><p class="c1"><span class="c0">- In case of file not found error on attempt of using demudder, reinstall UVR.<br>- In case of Format not recognised error for demudder, keep Match freq cut-off enabled in MDX settings.</span></p><p class="c1"><span class="c0">- &ldquo;For Roformer models, it must detect a stem called &quot;Instrumental&rdquo; so for some models like Mel-Kim, you need to open model&rsquo;s corresponding yaml, and change &ldquo;other&rdquo; to &ldquo;instrumental&rdquo;.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;With the new config editor feature you could probably edit the configs of models to have the vocal stem labelled as the Instrumental stem so the demudder demuds the vocal stem, it definitely still makes a difference </span></p><p class="c1"><span class="c0">I accidentally did this when installing another model, but it seems to actually have an effect on vocal stems too&rdquo; stephanie<br><br>Demudder usage:</span></p><p class="c1"><span class="c0">Go to options:&gt;Advanced MDX-Net options&gt;Enable Demudder</span></p><p class="c1"><span class="c0">Then you can pick what Demudder variant you want and it will be used in every separation using MDX-Net models.</span></p><p class="c1"><span class="c20"><br></span><span class="c0">Demudder consists of three methods to choose from: </span></p><ul class="c9 lst-kix_l60gvbdij7aj-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Phase Rotate</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Phase Remix (Similar to X-Minus) - &ldquo;the fullest sounding, but can leave a lot of artifacts with certain models. I only recommend that method for the muddiest models. Otherwise, Combined Methods is the best&rdquo; &ldquo;I don&#39;t recommend using phase remix on the Instrumental v1e model. I recommend combined methods or phase rotate for models produce fuller instrumentals.&rdquo; Anjok</span></li><li class="c1 c25 c8 li-bullet-0"><span>Combine Methods (weighted mix of the final instrumentals generated by the above). More in the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1331189771078471721&amp;sa=D&amp;source=editors&amp;ust=1765035742306473&amp;usg=AOvVaw0tN2-SZfuQOwDE4iSiV16i">full changelog</a></span><span class="c0">.</span></li><li class="c1 c25 c8 li-bullet-0"><span>You can also use phase remix in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742306714&amp;usg=AOvVaw2vwqyWJwtPl8NpBHkihX2C">SESA</a></span><span class="c0">&nbsp;Colab</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Demudder is &ldquo;meant to solely target instrumentals. The vocals should stay exactly as before.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;It works best on tracks that are spectrally dense (ex. Metal, Rock, Alternative, EDM, etc.)</span></p><p class="c1"><span class="c0">I don&#39;t recommend it for acoustic or light tracks.</span></p><p class="c1"><span>I don&#39;t recommend using it with models that emphasize fuller instrumentals (like Unwa&#39;s v1e model).&rdquo; Anjok<br>&ldquo;I&#39;ve noticed with the few amounts of tracks I&#39;ve tried, demudding can sometimes accentuate instances of bleeding or otherwise entirely missed vocal-like sounds&rdquo;. More in the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1331189771078471721&amp;sa=D&amp;source=editors&amp;ust=1765035742307960&amp;usg=AOvVaw0litPmYPaPMxGMl8BdgsBa">full changelog</a></span><span class="c0">.<br>&ldquo;I put the demudded instrumental in the bleed suppressor, and it sounds really good, almost noise free. I either do a bleed suppressor or a V1/bleed suppressor ensemble&rdquo; gilliaan<br>&ldquo;I found that Phase Remix also works well on pop and other genres of music, but it only works using the vocal models (Phase Remix and VOICE-MelBand-Roformer Kim FT (from Unwa) or</span></p><p class="c1"><span class="c0">VOICE-MelBand-Roformer Kim FT 2 (by Unwa).&rdquo; Fabio<br></span></p><p class="c1"><span class="c0">&ldquo;I do plan on adding options to tweak the phase rotation.</span></p><p class="c1"><span class="c0">I also plan on adding another combination method that may work better on certain tracks.&rdquo; Anjok</span></p><p class="c1"><span class="c0">If you set 64-bit float output in Options&gt;Additional settings, the results might be slightly less muddy, but also in very big size.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">OG Discord </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648&amp;sa=D&amp;source=editors&amp;ust=1765035742309354&amp;usg=AOvVaw18wZ-5oxOF0nrx2jXwc77b">channel</a></span><span class="c20">&nbsp;to follow for updates</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Older patches</span></p><p class="c1"><span class="c6">____________</span></p><p class="c1"><span>(old) Potential fixing of RTX 5000 series CUDA acceleration for #14 patch -<br>now unnecessary since dedicated patch was released above<br>(although there&rsquo;s no full success with the below, so also refer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/CarlGao4/Demucs-Gui/issues/115&amp;sa=D&amp;source=editors&amp;ust=1765035742309999&amp;usg=AOvVaw2fWU06U5EQBvNYgXrkJZ4F">here</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Some people reported that following the steps below might still result in slow separations:</span></p><p class="c1"><span>Probably you&rsquo;ll be able to install required CUDA 12.8 and nightly PyTorch to fix the compatibility issue when following steps for </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui%23manual-windows-installation&amp;sa=D&amp;source=editors&amp;ust=1765035742310592&amp;usg=AOvVaw1h1G_972n_CC4AYd4hO14i">manual installation</a></span><span>&nbsp;(unfold it), so UVR won&#39;t use its own Python environment. In addition to the above link, use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/tree/v5.6.0_roformer_add%252Bdirectml&amp;sa=D&amp;source=editors&amp;ust=1765035742310858&amp;usg=AOvVaw1ZIv-QeT1-jux-YQxld_kU">this</a></span><span class="c0">&nbsp;repo with newer code, although for now, not the newest code is attached from the patches below... and all if you fix &quot;Getting requirements to build wheel ... error&quot; afterwards. Then you&rsquo;ll have a bug causing no GPU Conversion option functional - then you need to use:</span></p><p class="c1"><span class="c0">python.exe -m pip install --upgrade torch --extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">instead of cu117 as in the instruction above (although for RTX 5090 it probably won&rsquo;t work, and you can use this https://download.pytorch.org/whl/nightly/cu128 instead.</span></p><p class="c1"><span class="c0">- Similar issue might occur when you don&rsquo;t install &quot;onnxruntime-gpu&quot;</span></p><p class="c1"><span class="c0">when the current is &quot;onnxruntime&quot; library (which does not support GPU)</span></p><p class="c1"><span class="c0">- For Demucs UnpicklingError issue using manual installation:</span></p><p class="c1"><span class="c0">modify the demucs/stats.py:</span></p><p class="c1"><span class="c6">package = torch.load(path, &#39;cpu&#39;, weights_only=False)</span></p><p class="c1"><span class="c0">Sometimes it still happens for e.g. Becruily inst model anyway. It can be the indicator that the model file is corrupted and has wrong CRC (most likely wrongly downloaded) - redownload the model.</span></p><p class="c1"><span class="c0">On the old 5.6.0 version, there&#39;s OpenCL in options instead of DirectML in newer patches (although it&#39;s the latter).</span></p><p class="c1"><span>Alternatively, you can use </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST-GUI</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">__________</span></p><p class="c1 c7"><span class="c42 c12 c15 c33"></span></p><p class="c1"><span class="c0">- Anjok released a new UVR beta Roformer patch #11 (Windows only for now)</span></p><p class="c1"><span class="c0">It fixes 4 bugs: with VR post-processing threshold, Segment default in multi-arch menu, CMD will no longer pop-in during operations, and error in phase swapper.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1328267582871961620&amp;sa=D&amp;source=editors&amp;ust=1765035742313792&amp;usg=AOvVaw2JjgexOahJquE8_NkJ6IiJ">More</a></span><span class="c0">&nbsp;details/potential updates.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Standalone (for non-existent UVR installation)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_1_13_0_23_46_BETA_full.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742314206&amp;usg=AOvVaw3ilVXknST0NW7VVTdWzmcd">UVR_1_13_0_23_46_BETA_full.exe</a></span></p><p class="c1"><span class="c0">For 5.6 stable (so for non-beta Roformer installation)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_Patch_1_13_0_23_46_BETA_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742314612&amp;usg=AOvVaw17VP3ClDKQeSW0PfZIyVti">UVR_Patch_1_13_0_23_46_BETA_rofo.exe</a></span></p><p class="c1"><span class="c0">Small (for already existing Roformer beta patch installation)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_13_25_0_23_46_rofo_small_patch.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742314996&amp;usg=AOvVaw2SMbUQtrsdSdXkTYFKa9NO">UVR_Patch_1_13_25_0_23_46_rofo_small_patch.exe</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Patch #12 which is a hotfix for the </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">4 stem</a></span><span class="c0">&nbsp;BS-Roformer model by ZFTurbo (trained on MUSDB)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_13_0_23_46_BETA_rofo_fixed.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742315475&amp;usg=AOvVaw0lc1_JLAnJI5aUypCO4ggc">UVR_Patch_1_13_0_23_46_BETA_rofo_fixed.exe</a></span><span>&nbsp;(Windows only)</span></p><p class="c1 c7"><span class="c42 c12 c15 c33"></span></p><p class="c1"><span class="c0">Users undergo some issues (no sound) with Mel-Roformer de-reverb by anvuew (a.k.a. v2/19.1729 SDR) since the latest UVR beta #11 or #12 update. Patch #10 works.</span></p><p class="c1"><span class="c0">The issue seems to occur only on GTX 10XX series, and maybe older.</span></p><p class="c1"><span class="c0">You should be able to use more than one UVR installation at the same time when one&rsquo;s been copied before updating (potentially patch #10 will still work) or use MSST repo and/or its GUIs.</span></p><p class="c1"><span class="c12"><br></span><span class="c0">UVR Roformer beta patch #9:</span></p><p class="c1"><span class="c0">UVR_Patch_12_8_24_23_30_BETA </span></p><p class="c1"><span>Windows: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_12_8_24_23_30_BETA_rofo_full_install.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742316755&amp;usg=AOvVaw1c38rV8KgHFqLzc67FR8u8">Full</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_Patch_12_8_24_23_30_BETA_large.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742316971&amp;usg=AOvVaw2DexKyGcybpq5KpqL272vS">Patch</a></span><span class="c0">&nbsp;(Use if you still have non-beta UVR installed) |</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_8_24_23_30_BETA_small_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742317314&amp;usg=AOvVaw26-LBNGCFBVsMoftcpVLf1">Small Patch</a></span><span class="c0">&nbsp;(for this you must have a Roformer patch previously installed for this to work)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR Roformer beta patch #10 </span></p><p class="c1"><span>UVR_Patch_1_9_25_23_46_BETA_rofo_small_patch - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_9_25_23_46_BETA_rofo_small_patch.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742317823&amp;usg=AOvVaw0iz4ql8yec7fEjWCcy4RBw">Link</a></span></p><p class="c1"><span class="c0">For now, only small patch for already existing beta Roformer installation above is available, and only for Windows.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you have Python DLL error on startup, reinstall the last beta update using the full package instead, then the small installer from the newer patch.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Since beta version #10, </span><span class="c22">UVR doesn&#39;t rely on &#39;inference.dim_t&#39; value for Roformers anymore</span><span class="c0">&nbsp;(if you were using edited &quot;dim_t&quot; value in yaml configuration files).</span></p><p class="c1"><span class="c0">You have to edit audio.chunk_size instead if need it (e.g. for 4-12GB VRAM on AMD/Intel).</span></p><p class="c1"><span class="c0">It&rsquo;s located &ldquo;In model yaml config file, at top of it, chunk_size is first parameter (...) you can edit model config files directly inside UVR now.&rdquo; or in the new config editor in newer versions.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Conversion between dim_t and chunk_size</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">dim_t = 801 is chunk_size = 352800 (8.00s)</span></p><p class="c1"><span class="c0">dim_t = 1101 is chunk_size = 485100 (11.00s)</span></p><p class="c1"><span class="c0">dim_t = 256 is chunk_size = 112455 (2,55s)</span></p><p class="c1"><span class="c0">dim_t = 1333 is chunk_size = 587412 (13,32s)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">[more values later below]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The formula is: chunk_size = (dim_t - 1) * hop_length)&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Generally, to have the best SDR, use chunks not lower than 11s in the yaml for inference, which is usually training chunks value (rarely higher). Although, at times people get better results with 2,55s chunks, although some models behave worse than others with such small values.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;most of the time using higher chunk_size than the one used during training gives a bit better SDR score, until a peak value, and then quality degrades.</span></p><p class="c1"><span class="c0">For Roformers trained with 8sec chunk_size, 11 sec is giving best SDR (then it degrades with higher chunk size)</span></p><p class="c1"><span class="c0">For MDX23C, when trained with ~6sec chunks, iirc, peak SDR value was around 24 sec chunks (I think it was same for vit_large, you could make chunks 4 times longer)</span></p><p class="c1"><span class="c0">How much chunk_size can be extended during inference seems to be arch dependant.&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Changelog #10:</span></p><p class="c1"><span class="c0">Added SCNet and Bandit archs with models in Download Center, fixed compatibility with some newer Roformer models (prob. the Phantom center and 400MB small Unwa models, not sure yet), new Model Installer option added, model configuration menu enhanced, allowing aliases to selected models, added compatibility for Roformer/MDX23C Karaoke models with the vocal splitter, VIP code issue is gone, issues with secondary models options and minor bugs and interface annoyances are addressed, &ldquo;improved the &quot;Change Model Settings&quot; menu. Now, any existing settings associated with a selected model are automatically populated, making it easier for users to review and adjust settings (previously, these settings were not visible even if applied).&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;Unfortunately, SCnet is not compatible with DirectML, so AMD GPU users will have to use the CPU for those models.</span></p><p class="c1"><span class="c0">Bandit models are not compatible with MPS or DirectML. For those with AMD GPU&#39;s and Apple Silicon, those will be CPU only.</span></p><p class="c1"><span class="c0">The good news is those models aren&#39;t all that slow on CPU.&rdquo; - Anjok</span></p><p class="c1"><span class="c0"><br>Changelog #9:</span></p><p class="c1"><span class="c0">Apollo fixes: &ldquo;Chunk sizes can now be set to lower values (between 1-6)</span></p><p class="c1"><span class="c0">Overlap can be turned off (set to 0)&rdquo;</span></p><p class="c1"><span class="c0">Fix both for Apollo and Roformers: now 5 seconds or shorter input files no longer cause errors.</span></p><p class="c1"><span class="c0">OpenCL was wrongly referenced in the UVR. It was actually DirectML all the way, and Anjok changed all the OpenCL names in the app into DirectML.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>C</span><span>hangelog for all platforms:<br>Patch #3 fixed the issue with stem misalignment when using incorrect overlap setting for Roformers. Now it uses ZFTurbo code (also for MDX23C), meaning that </span><span class="c22">now increasing overlap for Roformers will result in increasing separation times</span><span>&nbsp;and potentially better SDR [the opposite of what it used to be in the previous beta Roformer patches #1 and #2]. Also, it &ldquo;Fixed manual download link issues in the Download Center. Roformer models can now be downloaded without issue.&rdquo;). Also, new Roformer models were added to Download Center, so you don&#39;t have to download them manually.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>- UVR Roformer beta patch #8 for Win: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_3_24_1_18_BETA_full_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742326183&amp;usg=AOvVaw38uSF9GwS7aM3SiLDgT1R2">full</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_3_24_1_18_BETA_small_patch_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742326387&amp;usg=AOvVaw0_UEY6R5mpJ88MI3hikxPL">patch</a></span><span>&nbsp;| Mac: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_1203_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742326551&amp;usg=AOvVaw0rKVZs0EotQf_dg_pxlj6S">M1</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_1203_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742326731&amp;usg=AOvVaw1steHZFOJZ3tHPIf6Jbfro">x86-64</a></span><span class="c0">:</span></p><p class="c1"><span class="c0">UVR_Patch_12_3_24_1_18_BETA<br>Apollo arch was made compatible with OpenCL too, but it might be unstable and very RAM intensive - use chunk size over 7 to prevent errors (currently it&rsquo;s not certain that all models will work with less than 12GB of VRAM). At least in newer patches, it can straight up say that Apollo is not compatible with DirectML, and fall back to CPU mode.<br>Apollo is now compatible with all Lew models (fixed incompatibility with any other than previously available in Download Center). Fixed (presumably regression with) Matchering.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>UVR Roformer beta patch #7 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_2_24_2_20_BETA_full_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742327952&amp;usg=AOvVaw0eioc_ymVk5euPM8-Fp8i-">full</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_12_2_24_2_20_BETA_patch_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742328114&amp;usg=AOvVaw0MWNL5rUNOKhPpYWJiRJcE">patch</a></span><span class="c0">) Win<br>UVR_Patch_12_2_24_2_20_BETA.</span></p><p class="c1"><span>It introduces support for Apollo arch. The OG mp3 enhancer and Lew v1 vocal enhancer were added to Download Center. The arch is located in Audio Tools. Sadly, this arch cannot be GPU accelerated with OpenCL so AMD and Intel cards (you&rsquo;re forced to use CPU which might be long).<br>Also, &ldquo;Phase Swapper&rdquo; a.k.a. Phase fixer for Unwa inst models was added to Audio Tools.</span></p><p class="c1"><span>Roformer beta patch #6: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742328989&amp;usg=AOvVaw0qavCOVlTjtn8h4R_rl895">M1</a></span><span>&nbsp;|</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742329210&amp;usg=AOvVaw1N6iQnMAZgpemKMKqQrPLl">&nbsp;x86-64</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR Roformer beta patch #6: Win</span></p><p class="c1"><span>UVR_Patch_11_25_24_1_48_BETA (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_25_24_1_48_BETA_full_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742329794&amp;usg=AOvVaw0cNkbvYY-_Q5KkuHoVUtiJ">standalone</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_25_24_1_48_BETA_patch_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742330071&amp;usg=AOvVaw1pZXU6dOAy1-j77Jfj0sCi">patch</a></span><span class="c0">&nbsp;- you can install it on stable 5.6 version already installed) <br>Fixes issues with viperx&rsquo; models.</span></p><p class="c1"><span>And with it, a long anticipated MDX-Net HQ_5 model was released (available for older versions in Download Center too. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1310529792461770814&amp;sa=D&amp;source=editors&amp;ust=1765035742330787&amp;usg=AOvVaw26pnMX4Qw1NnQo2dd99WNe">Changelog</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>UVR_Patch_UVR_11_17_24_21_4_BETA_patch_roformer (Beta </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_19_24_1_23_BETA_patch_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742331268&amp;usg=AOvVaw1Ic-o7tdYeqaa4NVWDgrhH">patch</a></span><span class="c0">&nbsp;#5 for UVR, Windows only): </span></p><p class="c1"><span class="c0">&ldquo;- Fixed OpenCL compatibility issue with Roformer &amp; MDX23C models.</span></p><p class="c1"><span class="c0">- Fixed stem swap issue with Roformer instrumental models in Ensemble Mode.&rdquo;</span></p><p class="c1"><span class="c0">That patch is probably not standalone like patch #3, so have a previous UVR installation.<br></span></p><p class="c1"><span>Roformer patch #4 for MacOS: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_17_24_21_4_BETA_rofo_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742332066&amp;usg=AOvVaw2e80a5Ob7w4E4OZEIpjX6c">M1</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/Ultimate_Vocal_Remover_v5_6_1_11_17_24_21_4_BETA_rofo_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742332369&amp;usg=AOvVaw15OgSNwa9mWK_fxJdNGx7k">x86-64</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>UVR_Patch_11_17_24_21_4_BETA (Windows: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_11_17_24_21_4_BETA_full_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742332799&amp;usg=AOvVaw1_orZPGIX04JmKRr2Y_0n6">full</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_11_17_24_21_4_BETA_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742333004&amp;usg=AOvVaw3XrjVBPMdG0V4dBB66tkIO">patch</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1307933134574063706&amp;sa=D&amp;source=editors&amp;ust=1765035742333139&amp;usg=AOvVaw2ZZcHRjiWpOrfIsGphLlZU">changelog</a></span><span class="c0">) beta patch #4</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://uvr_patch_11_14_24_20_21_beta_patch_roformer.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742333413&amp;usg=AOvVaw3KG4W6qB3W75IoNef47zXk">UVR_Patch_11_14_24_20_21_BETA_patch_roformer</a></span><span>&nbsp;(beta patch #3 &ldquo;requires an existing UVR installation&rdquo; so either the previous beta Roformer patch above or stable </span><span class="c4"><a class="c3" href="#h.k3vca4e9ena8">5.6 patch</a></span><span>.<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1306819453857566811&amp;sa=D&amp;source=editors&amp;ust=1765035742333831&amp;usg=AOvVaw1tr78UTS84DQjGzF498N-S">Full changelog</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_4_14_24_18_7_BETA_full_Roformer.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742334246&amp;usg=AOvVaw0Igl5biAsH_L2_3pRKrtVh">UVR_Patch_4_14_24_18_7_BETA_full_Roformer</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://buzzheavier.com/f/GWqIXjFpAAA&amp;sa=D&amp;source=editors&amp;ust=1765035742334389&amp;usg=AOvVaw2lQ9iDK4Zpp8cAcVOz_XIo">mirror</a></span><span class="c0">&nbsp;(standalone Roformer beta patch #2, fixed OpenCL separation for AMD/Intel GPUs)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_3_29_24_5_11_BETA_full_roformer.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742334882&amp;usg=AOvVaw2z0WK6jXbjRARH_ILClw5A">UVR_Patch_3_29_24_5_11_BETA_full_roformer.exe</a></span><span class="c0">&nbsp;(older Roformer patch #1) </span></p><p class="c1"><span class="c0">With the following issue fixed in the newer patch #2 above - </span></p><p class="c1"><span class="c0">if you have playsound.py errors, disable notification chimneys in settings&gt;additional settings, using OpenCL GPU acceleration (AMD) for BS-Roformer doesn&rsquo;t work (or at least not for everyone)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Older Roformer patch #1/2 for </span><span class="c20">MacOS </span><span class="c0">(ARM only) got deleted from the Discord server <br>____________<br></span></p><p class="c1"><span>(Roformer models are also added on MVSEP and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://x-minus.pro/uvronline.app&amp;sa=D&amp;source=editors&amp;ust=1765035742335880&amp;usg=AOvVaw0gzRVFBuv_YPk1anzHJIte">x-minus.pro/uvronline.app</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742336040&amp;usg=AOvVaw1zycw_69meAOEVPxdKoQS9">MSST-GUI</a></span><span>, and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training-Colab-Inference&amp;sa=D&amp;source=editors&amp;ust=1765035742336177&amp;usg=AOvVaw3o10wvynp5ok3EyuCe0Ife">inference</a></span><span>&nbsp;Colab and MDX23 v.2.4/2.5 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742336358&amp;usg=AOvVaw2_CDKpOuyRmcZ4spObST_F">Colab</a></span><span class="c0">)<br></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.eopfi619c6zr"><span class="c22">Instructions</span><span class="c0">&nbsp;for UVR Roformer patches and installing custom models</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Your current settings might be lost after patching your current UVR installation</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Applying newer UVR Roformer versions over some older UVR versions might cause errors on startup - then perform clean installation to fix the issue. Just make sure that after uninstalling UVR, nothing is inside the old UVR folder</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- To perform clean installation of the latest version, for now you need:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Windows</span><span class="c0">:<br>Roformer full patch #13:</span></p><p class="c55"><span>UVR_Patch_1_15_25_22_30_BETA:</span><span class="c44"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_1_15_25_22_30_BETA_full.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742338001&amp;usg=AOvVaw0fEJ_R_8wCmEXVzSmBoPnh">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_1_15_25_22_30_BETA_full.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742338148&amp;usg=AOvVaw1VZt2uGPDdGtKrfgNSJCu3">Link</a></span></p><p class="c55"><span class="c0">And then install small patch #14:</span></p><p class="c64"><span>UVR_Patch_1_21_25_2_28_BETA:</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_21_25_2_28_BETA_small_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742338506&amp;usg=AOvVaw1RaIUItHxmfdLgkcRsAJht">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_1_21_25_2_28_BETA_small_rofo.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742338673&amp;usg=AOvVaw2rzdHWaRJuE3aBS1gUyoZh">Link</a></span></p><p class="c64"><span class="c0">RTX 5000 full patch #14: </span></p><p class="c64"><span>UVR_Patch_4_24_25_20_11_BETA: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mediafire.com/file_premium/4jg10r9wa3tujav/UVR_Patch_4_24_25_20_11_BETA_full_cuda_12.8.zip/file&amp;sa=D&amp;source=editors&amp;ust=1765035742339009&amp;usg=AOvVaw0FY28WL80SopL6oHN_5-xh">Link</a></span><span class="c0"><br>(iirc uses newer PyTorch and CUDA)</span></p><p class="c64"><span>The above is enough for complete installation. Installing the 2023 5.6.0 version before is unnecessary.<br><br></span><span class="c20">MacOS</span><span class="c0">:<br>- Roformer full patch #13.1 (standalone)</span></p><p class="c1"><span class="c0">(beta_0115_MacOS_arm64_hf)</span></p><p class="c1"><span class="c0">which applies a hotfix to address a few graphics issues:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mac M1 (arm64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_arm64_hf.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742339929&amp;usg=AOvVaw38f595KiGpJTs31eZdxpBG">Link</a></span></p><p class="c1"><span>- Mac Intel (x86_64) users - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_x86_64_hf.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742340223&amp;usg=AOvVaw2zkW_Z2LpNM4d6_rtdmC2l">Link</a></span><span class="c0">&nbsp;(it went offline for some reason; older version #13 below</span></p><p class="c16 c1"><span><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742340543&amp;usg=AOvVaw2PHN9SMw5zhCLziNipBBCo">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/Ultimate_Vocal_Remover_v5_6_Roformer_beta_0115_MacOS_x86_64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742340693&amp;usg=AOvVaw3K-ZabOCL13Qpgb9kY2T3g">Link</a></span><span class="c0">)</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c20">Linux <br></span><span class="c0">Old patch #9 only for now (no demudder, some fixable issues with certain models):</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/tree/v5.6.0_roformer_add%252Bdirectml&amp;sa=D&amp;source=editors&amp;ust=1765035742341274&amp;usg=AOvVaw2AwAzILwwdHnmQzbm8mRxc">https://github.com/Anjok07/ultimatevocalremovergui/tree/v5.6.0_roformer_add%2Bdirectml</a></span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c1"><span>(for older patches and more infoand troubleshooting refer </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">here</a></span><span class="c0">)</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Some newer Mel/BS models really require the newest Roformer patches (otherwise you&rsquo;ll get MLP error).</span></p><p class="c1 c7"><span class="c0"><br></span></p><p class="c1"><span>- In the Download Center you&rsquo;ll find some BS/Mel models, but not all. Refer to the full list of models </span><span class="c4"><a class="c3" href="#h.2vdz5zlpb27h">here</a></span><span class="c0">. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Installing custom Roformer models in UVR<br>(those unavailable in Download More Models a.k.a. Download Center)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">- Since patch #10 new &ldquo;Install Model&rdquo; option was added.<br>Click RBM on the models&rsquo; list to access the option and follow the instructions on your screen. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Models for Mel/BS Roformer, SCNet and Bandit Plus/v2 are located in the MDX-Net menu.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For most models, you need both ckpt and yaml file for the model to work (if it&rsquo;s not the same with any config you already downloaded before - some models share the same config file - e.g. one folder with models in the repository might have only one yaml)</span></p><p class="c1"><span class="c0">If you opened yaml file to download, but its content opened instead of its downloading started, press CTRL+S or go to options of your browser and find the option called &ldquo;Save As&rdquo;.</span></p><p class="c1"><span class="c0">Now you&rsquo;ll have a txt extension, but we need it to be yaml (otherwise UVR won&rsquo;t detect it), so choose All files in Extension, and edit it there manually to yaml (or after download). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you don&rsquo;t see ckpt on the extensions list, perform clean UVR installation from the patches above </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- In &ldquo;Set Model Type&rdquo;, most Roformers will use Roformer non-v2 (and most are Mel). <br>For now, you should pick v2 Roformer type probably only for unwa 400MB experimental model (if you have lots of </span><span class="c20">layers </span><span class="c0">errors using Roformers, it means you picked v2 config unnecessarily). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Manual model installation for e.g. Demucs which doesn&rsquo;t have &ldquo;Install model&rdquo; option (or for patch before #10) - on example of MDX/Roformers/SCNet/Bandit.<br>To install models from external sources (those unavailable in Download Center) you can copy the model file to models\MDX_Net_Models and .yaml config to models\model_data\mdx_c_configs, then after choosing the model in the app, press yes to recognize the model, wait a while. In older beta check also &ldquo;roformer model&rdquo; option when asked for configuration file and confirm (you cannot press confirm or check the option on the oldest Mac Roformer patch, the issue is explained below, and fixed in newer versions).</span></p><p class="c1"><span>(or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708595418400817162/1366720855824142458&amp;sa=D&amp;source=editors&amp;ust=1765035742346315&amp;usg=AOvVaw35X_0eTbu1RCSFE2KTIlCa">step by step</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Misc</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- You might want to decrease default chunk_size in Edit Model Param (or yaml) for AMD/Intel GPUs with VRAM lower than 16GB if you have memory errors with GPU Conversion enabled or your separation is stuck on e.g. 5% (read more in </span><span class="c4"><a class="c3" href="#h.c4nrb8x886ob">Common issues</a></span><span class="c0">&nbsp;later below)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">- </span><span class="c0">How would I assign a yaml config to an Apollo model on the new UVR [patch]?<br></span></p><p class="c1"><span class="c0">&ldquo;1. Open the Apollo models folder</span></p><p class="c1"><span class="c0">2. Drop the model into the folder</span></p><p class="c1"><span class="c0">3. From the Apollo models folder, drop the yaml into the model_configs directory</span></p><p class="c1"><span class="c0">4. From the GUI, choose the model you just added and if the model is not recognized, a pop-up window will appear, and you&#39;ll have the option to choose the yaml to associate with the model.&rdquo; - Anjok</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;batch_size = 2 (not less or more)&rdquo; - &ldquo;1 can lead to some clicks in output, while with batch_size&gt;=2, there are no clicks. Clicks are obvious in low freq of log spectrogram&rdquo;</span></p><p class="c1"><span class="c0">edit. iirc clicks with batch_size=1 could have been fixed (at least were with MSST from which the inference code was implemented in newer UVR patches, but iirc it wasn&rsquo;t used, and later the clicks were fixed in MSST).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Segment size in the UVR UI does nothing for these Roformer models due to Advanced arch options being set by default to Segment Default which makes it being read from the yaml file. While &quot;Segment_Default&quot; in Advanced MDX-NET23 settings is checked, it will use the dim_t value from the bottom of the config. Simply dim_t is the segments. Although now chunk_size is used in newer patches instead.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;The overlap value in yaml files is never used by UVR, only the value in GUI is used.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;UVR uses inference.dim_t from config as segment_size, but the inference.num_overlap is not used by UVR, it&#39;s always using the value in the GUI</span></p><p class="c1"><span class="c0">(while ZFTurbo original script is using audio.chunk_size and inference.num_overlap but not inference.dim_t . That&#39;s a mess) &rdquo; jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.w0ygt5gjwmwn"><span class="c6">Overlap comparisons for Roformers</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>4 is a balanced value in terms of speed/SDR according to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/KyCtncG&amp;sa=D&amp;source=editors&amp;ust=1765035742350571&amp;usg=AOvVaw0XwOfd5HpTfdALKzUHaMb7">measurements</a></span><span>&nbsp;(since the beta patch #3 or later used above, overlap 16 is now the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/JtxzRZD&amp;sa=D&amp;source=editors&amp;ust=1765035742350802&amp;usg=AOvVaw0SF1OLTXcYIer77PnNE_X0">slowest</a></span><span class="c0">&nbsp;in UVR (not overlap 2 is the slowest anymore when it was set the opposite) and overlap 4 has a bigger SDR than overlap 2 now. <br>Some people still prefer using overlap 8, while for others it&rsquo;s already an overkill.<br>There&rsquo;s very little SDR improvement for overlap 32, and for 50 there&rsquo;s even a decrease to the level of overlap 4, and 999 was giving inferior results to overlap 16. <br>Compared to overlap 2, for 8 &ldquo;I noticed a bit more consistency on 8 compared to 2 (less cut parts in the spectrogram).&rdquo; Instrumentals with overlap higher than 2 can get gradually muddier.<br>The info is based on evaluations conducted on multisong dataset on MVSEP. Search for e.g. overlap 32 and overlap 16 below, and you will see the results to compare:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?algo_name_filter%3Dkim&amp;sa=D&amp;source=editors&amp;ust=1765035742352254&amp;usg=AOvVaw1X1Lxorqe44qSuCNkjdvLM">https://mvsep.com/quality_checker/multisong_leaderboard?algo_name_filter=kim</a></span></p><p class="c1"><span class="c0">&ldquo;overlap=1 means that the chunk will not overlap at all, so no crossfades are possible between them to alleviate the click at edges.&rdquo; fixed in MSST.<br>The setting in GUI overrides the one in yaml&rsquo;s setting.<br></span></p><p class="c1"><span class="c6">chunk_size</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Most of the time using higher chunk_size than the one used during training gives a bit better SDR score, until a peak value, and then quality degrades.</span></p><p class="c1"><span class="c0">For Roformers trained with 8 sec chunk_size [can be found in the yaml], 11 sec is giving best SDR (then it degrades with higher chunk size)&rdquo; - jarredou</span></p><p class="c1"><span class="c0">All the notable chunk_sizes are described later below.</span></p><p class="c1"><span class="c0">Sometimes chunk_size can influence the ability of picking up e.g. some screams in the model (&ldquo;kim&#39;s can do it if you mod the chunk size&rdquo;).<br>Lower chunks might sound a bit less muddy.<br>Unless they&rsquo;re set too high and VRAM is exceeded, while separation still doesn&rsquo;t fail on AMD/Intel, various values should provide similar separation times, esp. for NVIDIA users.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">batch_size</span><span class="c0">&nbsp;(not used in UVR, but in MSST)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Leave it default, but for faster inference, e.g. Gabox used 6. Using above 2 might increase VRAM usage. 1 is forced in the inference Colab (it has the clicking issue with that setting fixed in newer MSST code).</span></p><p class="c1"><span class="c0">&ldquo;i.e. instead of running a single song at batch_size = 1 you can run 2 at the same time (batch_size = 2)&rdquo; so &ldquo;you can use more than one song to process&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.c4nrb8x886ob"><span class="c18 c15">Most common issues</span></h6><h6 class="c1 c27 c7" id="h.yi48j115twqs"><span class="c18 c15"></span></h6><p class="c1"><span class="c0">- Some models might occasionally disappear from your list (most likely sideloaded outside Download Center) and change their name (probably once they got added to Download Center - e.g. Melband Roformer karaoke ckpt)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Since patch #3, Roformers&rsquo; separation times with even smaller overlap are longer than before. Also, remember about inference mode added in one of the later patches. It&rsquo;s disabled by default as it causes silent separation issues on GTX 10XX GPUs and probably older. Enabling it on newer GPUs might be beneficial for performance</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If UVR freezes your PC occasionally during separation, you can change priority of UVR to Idle in Task manager, and the issue is gone sooner or later.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You can force it to remember every time you run UVR with Process Lasso (it autostarts with the OS, so you don&#39;t have to see the splash screen for a free user every time you want to use it).</span><span class="c18 c15"><br></span></p><p class="c1"><span>-</span><span class="c22">&nbsp;</span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">Read</a></span><span>&nbsp;</span><span class="c0">for RTX 5000 series issue, or use OpenCL (DirectML) in options (slower)</span></p><h5 class="c5" id="h.n7cj4aukaan3"><span class="c42 c36 c51 c33 c24 c30">Ensembling impossible - model not visible in vocal splitter in UVR</span></h5><h5 class="c5" id="h.juyfjn4e54pi"><span class="c0">- If user-imported Roformers aren&#39;t recognized in &quot;instrumental/vocals&quot; in ensemble or in vocal splitter, but are in &quot;multi-stem ensemble&quot;:<br>&ldquo;The .yaml associated with the model usually needs to be updated to match UVR&#39;s stem naming conventions. For example, if your config shows the instruments as &quot;other&quot; and &quot;vocals&quot;, it will need to be updated to &quot;Instrumental&quot; and &quot;Vocals&quot; (case-sensitive)&rdquo; - Anjok</span></h5><p class="c1"><span class="c0">E.g. for Karaoke models, you need to change &ldquo;Karaoke&rdquo; to &ldquo;Vocals&rdquo;.<br><br>But you can also use Tools&gt;Manual Ensemble instead for ready separations.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Ensemble vs multi-stem ensemble explained (by stephanie)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The multi-stem ensemble mode is designed to ensemble every stem in all the models that were selected. I&#39;ll explain how it&#39;s related:</span></p><p class="c1"><span class="c0">Let&rsquo;s say you have two vocal/instrumental models selected, and two 4-stem models selected (vocals, drums, bass, other), then it will process the song through all of the models. As a result, the final ensembled output will be 5 stems: vocals, instrumental, drums, bass, and other. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The drums, bass, and other stems will just be the ensemble of the 2 models in that selection that shared those outputs. However, all models in that particular selection shared a vocal output so it will be the ensemble of each model&#39;s vocal output </span></p><p class="c1"><span>I&#39;m not sure if that&#39;s very clear, but that&#39;s how it works and why the way it handles each stem is different from the other stem pair modes&rdquo;<br></span></p><h6 class="c1 c27" id="h.wlfnosg1t1le"><span class="c0">- Roformers might be sometimes slow/stuck/give memory allocation error during separation on AMD/Intel GPUs with VRAM lower than 16GB, if you don&rsquo;t lower default &ldquo;chunk_size&rdquo; during importing the model, or in the corresponding yaml in: models\MDX_Net_Models\model_data\mdx_c_configs <br>or in Choose Model&gt;Edit Models Config&gt;Change Parameters&gt;Edit Model Param.<br>Start with min. chunk_size = 112455 (dim_t 256 equivalent) and increase it depending on GPU or model size till you start getting errors to get the best possible SDR.</span></h6><h6 class="c1 c27 c7" id="h.s8e1lwjubar3"><span class="c0"></span></h6><h6 class="c1 c27" id="h.r91zzvmown9q"><span class="c0">For older beta 1-9 and 4GB VRAM GPUs, lower dim_t at the bottom of the yaml (not at the top) to e.g. 256 or 201, sometimes 301 - some Roformers will require lower dim_t/chunk_size - the higher, the better till 1101, or training chunks value in the config. </span></h6><h6 class="c1 c27" id="h.uta5qhorw8pj"><span class="c0">So since patch #10 &ldquo;new beta version[s] doesn&#39;t rely on &#39;inference.dim_t&#39; value anymore (if you were using edited &quot;dim_t&quot; value).</span></h6><p class="c1"><span class="c0">Now you have to edit audio.chunk_size now &ldquo;In model yaml config file, at top of it, chunk_size is first parameter (...) you can edit model config files directly inside UVR now.</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.57eblyiq5076"><span>Memory issues - c</span><span class="c42 c36 c51 c33 c24 c30">hunk_size table</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">dim_t to chunk_size conversion for Roformers and hop_length = 441 in the model&rsquo;s yaml</span></p><p class="c1"><span class="c0">- useful if you see insufficient memory error</span></p><p class="c1"><span class="c0">The formula is: chunk_size = (dim_t - 1) * hop_length</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">dim_t = 1700 is chunk_size = 749259 (17s)</span></p><p class="c1"><span class="c0">dim_t = 1333 is chunk_size = 587412 (13,32s)</span></p><p class="c1"><span class="c0">dim_t = 1201 is chunk_size = 529200 (12s, used by some newer models)</span></p><p class="c1"><span class="c0">dim_t = 1101 is chunk_size = 485100 (11.00s) - that dim_t value was giving the highest SDR for models trained with 8s chunks, atl least in times of models released in beta Roformer beta patch #2 period, it&rsquo;s default for e.g. duality models</span></p><p class="c1"><span class="c0">dim_t = 801 is chunk_size = 352800 (8.00s) - default for most models, max working on Intel/AMD 8GB GPUs on 900MB models</span></p><p class="c1"><span class="c0">dim_t = 401 is chunk_size = 176400 (4s)</span></p><p class="c1"><span class="c0">dim_t = 356 is chunk_size = 156555 (3,55s) - max supported dim_t for some becruily inst and AMD 4GB VRAM (when in previous beta, dim_t needed to correspond with overlap to avoid stem misalignment, so probably halves caused misalignment before),</span></p><p class="c1"><span class="c0">it can be more muddy in certain parts of songs vs 256, the highest working value with becruily instrumental on AMD 4GB VRAM GPU</span></p><p class="c1"><span class="c0">dim_t = 301 is chunk_size = 132300 (3s)</span></p><p class="c1"><span class="c0">dim_t = 256 is chunk_size = 112455 (2,55s) - max working with e.g. becruily and smaller unwa&rsquo;s 400MB exp. models on 4GB AMD GPU</span></p><p class="c1"><span class="c0">dim_t = 201 is chunk_size = 88200 (2s) - required value for some more resource-hungry/bigger Roformers on AMD 4GB VRAM (some models only worked with that dim_t with earlier beta patches and here&rsquo;s it&rsquo;s probably the same or with 256 equivalent), but is still not low enough for most Roformers when demudder is used, and give &ldquo;Could not allocate tensor&rdquo; while single model separation previously worked with even bigger chunk setting. You shouldn&rsquo;t go lower with that parameter, as even a 2 seconds chunk might sometimes give audio skips every two seconds, at least on UVR Roformer patch #2. 2 or 2,5 seconds will be rather bare minimum.&rdquo; - jarredou (DTN edit)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">All inst/voc Roformers seem to use hop_length: 441 (but ensure in yaml), so you always multiply that hop value by the desired dim_t - 1 to get correct chunk_size (e.g. corresponding with old dim_t values you were using in older beta patches)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- We have some reports about user custom ensemble presets from older versions no longer working (since 11/17/24 patch). </span></p><p class="c1"><span class="c0">- Sadly, you need to get rid of them (don&rsquo;t restore their files manually) or the ensemble will not work and model choice will be greyed out. You need to start from scratch</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Errors troubleshooting<br></span></p><p class="c1"><span class="c24">&ldquo;got an unexpected keyword argument &#39;linear_transformer_depth&rsquo; &rdquo;</span><span class="c0"><br>In case of the error with any external Roformer model: </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- delete &ldquo;linear_transformer_depth: 0&rdquo; line from the YAML file</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- To fix issues with BS variant of e.g. anvuew&rsquo;s de-reverb model in UVR, additionally to the above, also change the following in the yaml file:</span></p><p class="c1"><span class="c0">&ldquo;stft_hop_length: 512 to stft_hop_length: 441 so it matches the hop_length above&rdquo; (thx lew).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If that line is not present in your model&rsquo;s yaml config file, go to the settings, then choose MDX In the Advanced menu, and click the &quot;Clear auto-set cache&quot; button.</span></p><p class="c1"><span class="c0">Then go back to the main settings, click &quot;Reset all settings to default&quot; and restart the app (thx santilli_).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">These issues don&rsquo;t happen in the ZFTurbo&rsquo;s CML inference code of:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/&amp;sa=D&amp;source=editors&amp;ust=1765035742369548&amp;usg=AOvVaw2z3EeMtaEr7zrEhhF-Dgn0">https://github.com/ZFTurbo/Music-Source-Separation-Training/</a></span></p><h5 class="c5" id="h.1t2y5bokaz3h"><span>&#39;use_amp&#39; </span><span class="c42 c36 c51 c33 c24 c30">&ldquo;Key error&rdquo;</span></h5><p class="c1"><span class="c0">using the GH repo above, and referencing (separating) some models: </span></p><p class="c1"><span class="c0"><br>- &ldquo;add:</span></p><p class="c1"><span class="c6">use_amp: true </span></p><p class="c1"><span>in the training part of [models&rsquo; yaml] config file (it&#39;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/tYov1Zj&amp;sa=D&amp;source=editors&amp;ust=1765035742370247&amp;usg=AOvVaw31WBbhmlPHl4frLhdTzljE">missing</a></span><span class="c0">)&rdquo;</span></p><h5 class="c5" id="h.vrtjkbqu3t9r"><span class="c42 c36 c51 c33 c24 c30">&ldquo;&rdquo;&rsquo;norm&rsquo;&rdquo;&rdquo; attributeError using e.g. unwa beta 5e model in UVR</span></h5><p class="c1"><span>- a) Ensure you installed </span><span class="c4"><a class="c3" href="#h.eopfi619c6zr">UVR Roformer patch</a></span><span class="c0">&nbsp;(5.6.1), and you&#39;re not using the old 5.6 version (but 5.6.1 is reported once you open the app)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">b) You could pick wrong model architecture in Install model option (so not Roformer, and generally v1), or haven&rsquo;t turned on &ldquo;Roformer model&rdquo; option during importing the model into UVR (option present in the older beta versions)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">c) Or &ldquo;Edit the yaml file [of the model] from this -</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">training:</span></p><p class="c1"><span class="c0">&nbsp; instruments:</span></p><p class="c1"><span class="c0">&nbsp; - vocals</span></p><p class="c1"><span class="c0">&nbsp; - other</span></p><p class="c1"><span class="c0">&nbsp; target_instrument: vocals</span></p><p class="c1"><span class="c0">&nbsp; use_amp: True</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">to this - </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">training:</span></p><p class="c1"><span class="c0">&nbsp; instruments:</span></p><p class="c1"><span class="c0">&nbsp; - Vocals</span></p><p class="c1"><span class="c0">&nbsp; - Instrumental</span></p><p class="c1"><span class="c0">&nbsp; target_instrument: Vocals</span></p><p class="c1"><span>&nbsp; use_amp: True&rdquo; - Anjok<br><br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1226334240250269797/1263302732715134986&amp;sa=D&amp;source=editors&amp;ust=1765035742372401&amp;usg=AOvVaw1z9NyEtNLelHtC5hmyGKeX">More</a></span><span class="c0">&nbsp;troubleshooting on the &ldquo;norm&rdquo; issue</span></p><p class="c1"><span><br></span><span class="c24">E.g. BS-Roformer_LargeV1 is stuck on 5%</span><span class="c0"><br></span></p><p class="c1"><span class="c0">- Decrease chunk_size to 112455 (new patches)<br>(pre-10# patches) &ldquo;Go to MDX settings, MX23C specific, turn off default segment size and use segment size 256, it&#39;s probably filling up your VRAM&rdquo;<br>The setting resets itself. You should be able to set it permanently in the yaml configuration file of the model at the bottom (dim_t parameter). <br>It might be required for AMD/Intel 4GB VRAM GPUs (or potentially even 201, although it was using Rofo patch #2).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Q: &ldquo;is there a way to </span><span class="c24">reset </span><span>which </span><span class="c24">yaml </span><span class="c0">file to use? I chose the incorrect yaml file for a particular ckpt file, and now I cannot change it&rdquo;</span></p><p class="c1"><span class="c0">A: Go to models list&gt;Edit Model Config&gt;Change parameters and choose the yaml from the list.</span></p><p class="c1"><span>Or go to Ultimate Vocal Remover\models\MDX_Net_Models\model_data and if it was done just now, the last modified yaml in this folder will be the one corresponding to your model. You can just open that json, and edit it to write the config name located in mdx_c_configs you want to use with that model. You should find proper hashed yaml by the saved model of your choice, but if you really feel lost, you can delete all hashed yamls, so you&rsquo;ll need to go through the process of choosing configs for all custom MDX and Roformer models, but remember to not delete &quot;model_data.json&quot; and &quot;model_name_mapper.json&quot; as they cover models added to Download Center or written to be recognized automatically by UVR, so it&rsquo;s rather not a place you look for. Also, you can decode hashed json names corresponding to specific models </span><span class="c4"><a class="c3" href="#h.cb6cxq8g7i0v">here</a></span><span class="c0">.</span></p><p class="c1"><span><br></span><span class="c24">Layers error</span><span class="c0">&nbsp;- for issues with Unwa 400MB model </span></p><p class="c1"><span class="c0">-&ldquo;First make sure you&#39;re running the latest patch. If you&#39;re on the latest patch, It might be trying to associate with an incompatible YAML&rdquo;, but resetting the parameters below might be enough. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Go into the mdx_c_configs folder</span></p><p class="c1"><span class="c0">Find and delete BS_Inst_EXP_VRL.yaml</span></p><p class="c1"><span class="c0">Go back into the &quot;Download Center&quot;</span></p><p class="c1"><span class="c0">Select &quot;MDX-Net&quot; and give it a moment.</span></p><p class="c1"><span class="c0">Close the Download Center and try again.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If that doesn&#39;t work, you might have a previous json model file that&#39;s interfering:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Select the model in the MDX-Net model menu</span></p><p class="c1"><span class="c0">Then select &quot;Edit Model Config&quot;</span></p><p class="c1"><span class="c0">From the popup, click &quot;Reset Parameters&quot;&rdquo; Anjok</span></p><h5 class="c5" id="h.pf78vej16do"><span class="c42 c36 c51 c33 c24 c30">Layers errors - general</span></h5><p class="c1"><span class="c0">a) You didn&rsquo;t install the newest patch and still use e.g. beta 2 with some newer model</span></p><p class="c1"><span class="c0">b) You could check Roformer v2 instead of v1 during installing custom model</span></p><h5 class="c5" id="h.jdtv9ixizqgw"><span>TypeError: (...) freqs_per_bands</span></h5><p class="c1"><span class="c0">You probably set Mel-Roformer model type instead of BS-Roformer when it was necessary.</span></p><p class="c1"><span class="c0">Go to MDX-Net, pick the model&gt;Edit model config&gt;Choose parameters. </span></p><p class="c1"><span class="c0">There you should change Model type.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c18 c15">More troubleshooting</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">- If you have: </span></p><p class="c1"><span class="c0">RuntimeError: &quot;&quot;</span></p><p class="c1"><span class="c0">Traceback Error: &quot;</span></p><p class="c1"><span>without any text in these lines on AMD GPU on every attempt of using GPU Conversion in UVR for all archs and models (you probably use outdated GPU drivers and/or Windows), go to Ultimate Vocal Remover\torch_directml and replace DirectML.dll from C:\Windows\System32\AMD\ANR (make backup before). Experimentally, you can use this older </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1dxmG0cfclGMkFLfdoKAfQaDkx3Rcspku/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742378626&amp;usg=AOvVaw2M0hr7McM4b5k6NVxd_xfM">1.9.1.0</a></span><span class="c0">&nbsp;version of the library. Restart UVR after replacing the file!<br>If you use an incompatible library version, you&rsquo;ll encounter the &ldquo;Unhandled exception&rdquo; startup issue.<br>Be aware that the linked older version of the library might cause additional noise for MDX-Net v2 models like HQ_X (the issue is gone when you turn off GPU Conversion).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- All MDX-Net v2 models (maybe beside 4 stem variants), have so called MDX noise, which can be cancelled by using Options&gt;Advanced MDX-Net Settings&gt;Denoise Output&gt;Standard (or Model) &nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- At least beta #2 Roformer update caused some stability and performance issues with other archs than Roformers for some people when specific parameters started to take more time than before.</span></p><p class="c1"><span class="c0">Roll back to stable 5.6 (non 5.6.1) in these cases if necessary. Possibly make a copy of the old installation. Your configuration files might be lost. You can use both installations at the same time (or at least when one, e.g. Roformer patch is installed or symlinked in the default location).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (I think I covered that issue above more thoroughly)</span></p><p class="c1"><span class="c0">Roformer models in at least patch #2 work only in &ldquo;Multi-Stem&rdquo; mode in UVR. Using them in Ensemble causes layers errors (you can use manual Ensemble instead).<br>Iirc, it&rsquo;s caused by yaml config where instead of Instrumental + Vocals (with V as capital letter) there&rsquo;s written other + vocals, and you need to change it. Iirc it doesn&rsquo;t happen on models downloaded from Download Center as Anjok was fixing the issue, but the problem might still exist in yamls of some custom models outside the center </span></p><p class="c1"><span class="c0">- If you have sudden issues with not being able to separate, try to reinstall the app, and/or possibly make sure you didn&rsquo;t turn on some power saving option in your laptop. Plus, you can simply try to reopen UVR (few fail tries on incompatible DirectML.dll with your GPU driver/OS will hang UVR on &ldquo;Loading Model&rdquo; till you close UVR manually from Task Manager).</span></p><p class="c1"><span class="c0">_______</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">You&rsquo;ll find more UVR troubleshooting in </span><span class="c4 c20"><a class="c3" href="#h.ul5en196k909">this</a></span><span class="c20">&nbsp;section</span></p><p class="c1"><span class="c0">_____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Problems fixed in newer patches</span></p><p class="c1"><span><br>- (deprecated since patch #10 - now convert dim_t it to chunk_size) dim_t = 1101 seems to be a sweet spot in terms of speed/SDR according to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/jTRoTDg&amp;sa=D&amp;source=editors&amp;ust=1765035742382982&amp;usg=AOvVaw1UfY_dHEWn8c2mWx7ZFsoE">measurements </a></span><span class="c0">(although on 1 minute files); use 1120 if UVR refuses to accept 1101 in GUI (or edit yaml file)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (deprecated since patch #10) Some Roformer configs have wrong dim_t at the bottom of the yaml by default (e.g. 256), change it at the bottom of the yaml config for better SDR (not the one at the top), e.g. to 1101 (more explanations on it later).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (fixed in patch #10) VIP code in Roformer beta patch #2-9 (and probably #1) doesn&rsquo;t work - </span></p><p class="c1"><span class="c0">Download all the VIP models you need before patching older 5.6 to beta Roformer or use two installations of the UVR if you can&rsquo;t use patch #10 with the fix.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (fixed in patch #6)</span><span class="c22">&nbsp;</span><span class="c0">People experience All stems error with viperx&rsquo; 12xx models in newer versions of UVR Beta Roformer patch (patch #2 was the last confirmed to work with these older models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c24">- </span><span class="c0">(fixed in patch #10) mlp_expansion_factor: 1 or (when mlp line is deleted from yaml) mismatch for MelBand Roformer error <br>You probably use older Roformer patch incompatible with newer models (e.g. #2)</span></p><p class="c1"><span class="c0">It also appears when you wrongly set v2 model type.<br></span></p><p class="c1"><span class="c6"><br>Fixed in the beta patch #3 and #4 for all platforms</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Don&#39;t set overlap higher than 11 for 1101 dim_t (</span><span class="c22">at the bottom</span><span class="c0">&nbsp;of yaml file in the &ldquo;inference&rdquo; section, not above) and overlap 8 for 801 - these two are the fastest settings before stem misalignment issues occur. Otherwise, it can lead occasionally to some effects or synths missing from the instrumental stem (although some rules can be broken here with various settings). Also, the problems with clicks are alleviated with these good settings.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- In beta #2 patch, best measured SDR for both Mel and BS-Roformers is when dim_t = 1101 in the inference section of yaml config and when overlap is set to 2 in GUI (although 1 wasn&rsquo;t tested, and is actually lower). But the last beta patches, all bigger overlap values are slower, so SDR might be higher with higher values.</span></p><p class="c1"><span class="c0">Be aware that it will increase separation time. Maximum allowed value before error is 1801, but 1501 or 1601 depending on a model will be the max reasonable for experiments before some unwanted downsides of too high or too low dim_t appear (disappearing of some stem elements). In some specific cases, 1333 (or potentially 1301) was giving better results than 1101 or 1501, but it depended on song length - usually it happened on short fragments.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Instruction for overlap and dim_t above applies to other Roformer models as well, and not only those in Download Center. With the instructions, you can achieve faster separation times, as you&rsquo;re not forced to use the most time-consuming overlap 2 in older patches to avoid stem misalignment issues</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_______________</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c22">Model characteristics</span><span class="c0">&nbsp;</span></p><p class="c1"><span>(the list might be getting outdated, read models list at the </span><span class="c4"><a class="c3" href="#h.2vdz5zlpb27h">top</a></span><span>)<br></span><span class="c20">Note: E.g. unwa&rsquo;s duality models v1/2 and inst v1/2/v1e are now added to UVR Beta Roformer Download Center (so you don&rsquo;t have to mess with models and configs manually)</span><span class="c0"><br></span></p><p class="c1"><span class="c0">- 1053 model separates drums and bass in one stem, and it&#39;s very good at it</span></p><p class="c1"><span>(although now it might be better to use Mel-Roformer drums on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://x-minus.pro/uvronline&amp;sa=D&amp;source=editors&amp;ust=1765035742388768&amp;usg=AOvVaw2r7OZqMutsx-U0Fix4662x">x-minus.pro/uvronline</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">&ldquo;Target is drums and bass, and &quot;other&quot; is the rest. Despite that, it says vocals&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa released a new Inst v1e </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742389175&amp;usg=AOvVaw1V3XTTw5y3BJswqe-V--j9">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742389365&amp;usg=AOvVaw3Gpl4QGLRX3mp1qOKh7We3">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742389490&amp;usg=AOvVaw0ORRpC83LYbSeqVHsUXSDt">MSST-GUI</a></span><span class="c0">&nbsp;(&ldquo;The model [yaml] configuration is the same as v1&rdquo;) <br>&ldquo;The &quot;e&quot; stands for emphasis, indicating that this is a model that emphasizes fullness.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa inst v2 - it gets muddier than v1 at times, but it has less of noise</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa inst v1 - focused on instrumental stem:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742390147&amp;usg=AOvVaw0-HMG56GjnxGCdlcVVnMyc">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742390283&amp;usg=AOvVaw1Q1hVcdRKYdMdX1VVCKe45">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742390411&amp;usg=AOvVaw2HxEcIR2lf9pDJSvKEObTL">MSST-GUI</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JOa198ALJ0SnEreCq2y2kVj-sktvPePy?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035742390543&amp;usg=AOvVaw3tfEzvniDYn9pL8U0OuuVg">phase fixer</a></span><span class="c0"><br>&quot;much less muddy (..) but carries the exact same UVR noise from the [MDX-Net v2] models&quot;</span></p><p class="c1"><span class="c0">But it&#39;s a different type of noise, so aufr33 denoiser won&#39;t work on it. </span></p><p class="c1"><span>&ldquo;you can &quot;remove&quot; [the] noise with uvr denoise aggr -10 or 0&rdquo; although with -10 it will make it sound more muddy like Kim model and synths and bass are sometimes removed with the denoiser (~becruily). Mel-Roformer denoise might be better for it. <br>becruily released a Python </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JOa198ALJ0SnEreCq2y2kVj-sktvPePy?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742391355&amp;usg=AOvVaw1o1P_gjKNluvJV8O6dqdx4">script</a></span><span class="c0">&nbsp;fixing the noise issue (execute &ldquo;pip install librosa&rdquo; in case of module not found error) - it sound similar to the method used for premium user on x-minus.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa beta 4 Mel-Roformer (fine tune of Kim&rsquo;s voc/inst model ):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742392028&amp;usg=AOvVaw2tr6USemsO_CzvzFzK7KAi">https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742392155&amp;usg=AOvVaw3yvm79ZU1v5NhBG7Po3Nro">Colab</a></span></p><p class="c1"><span class="c0">Be aware that the yaml config has changed, and you need to download the new beta4 yaml.</span></p><p class="c1"><span class="c0">&ldquo;Metrics on my test dataset have improved over beta3, but are probably not accurate due to the small test dataset. (...) The high frequencies of vocals are now extracted more aggressively. However, leakage may have increased.&rdquo; - unwa</span></p><p class="c1"><span class="c0">&ldquo;one of the best at isolating most vocals with very little vocal bleed and still doesn&#39;t sound muddy&rdquo; &ldquo;gives fuller vocals&rdquo;. Can be a better choice on its own than some ensembles.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa duality model - focused on both stems, and instrumental is similarly muddy like in beta 4</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Kim Mel-Band Roformer vocal model </span></p><p class="c1"><span class="c0">It&rsquo;s less muddy than 1296/1297.</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/KimberleyJensen/Mel-Band-Roformer-Vocal-Model&amp;sa=D&amp;source=editors&amp;ust=1765035742393594&amp;usg=AOvVaw2s1A39Pmal-nT5OtNR_qa3">original repo</a></span><span>&nbsp;- CML faster on CUDA than in UVR | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/KimberleyJSN/melbandroformer/resolve/main/MelBandRoformer.ckpt?download%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035742393778&amp;usg=AOvVaw0cmASPDDoQVbziWZMkhk2M">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1U1FnACm-ontQSjhneq-WKk1GHEiTW97s/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742393923&amp;usg=AOvVaw2LG8_MrOy99uJNlhuD7sDe">config</a></span><span class="c0">&nbsp;- place the model file to models\MDX_Net_Models and .yaml config to model_data\mdx_c_configs subfolder and &ldquo;when it will ask you for the unrecognised model when you run it for the first time, you&#39;ll get some box that you&#39;ll need to tick &quot;roformer model&quot; and choose it&#39;s yaml&rdquo; (Mac issue explained in the section above).</span></p><p class="c1"><span>(simple </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1tyP3ZgcD443d4Q3ly7LcS3toJroLO5o1?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742394558&amp;usg=AOvVaw2yS-i7J5pC5Lq76-iu28kM">Colab</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/KimberleyJensen/Mel-Band-Roformer-Vocal-Model&amp;sa=D&amp;source=editors&amp;ust=1765035742394677&amp;usg=AOvVaw3_Gx1uloQr_KnCwUNL2rwO">CML inference</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035742394747&amp;usg=AOvVaw3RVSVELtN0KFSwnV7hwIt0">x-minus</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742394811&amp;usg=AOvVaw3duvh_Sdm6SJ_jWTWHlk26">MVSEP</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742395000&amp;usg=AOvVaw2h0-Ol4OG9NpDs0CBzjMAO">jarredou Colab</a></span><span class="c0">&nbsp;too now)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- unwa BS-Roformer finetuned a.k.a. large (further trained viperx 1297 model) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Q_M9rlEjYlBZbG2qHScvp4Sa0zfdP9TL/view&amp;sa=D&amp;source=editors&amp;ust=1765035742395361&amp;usg=AOvVaw2vRG7F8BdSdd_72p3fNZ0b">download</a></span></p><p class="c1"><span class="c0">More muddy than Kim above, a bit less of vocal residues, a bit more artificial sound.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- &nbsp;Mel-RoFormer Karaoke / Lead vocal isolation model files released by Aufr33 and viperx (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/qQA1XTrb%23LUNCfUMUwg4m4LZeicQwq_VdKSq9IQN34l0E1bb0fz4&amp;sa=D&amp;source=editors&amp;ust=1765035742395825&amp;usg=AOvVaw26n41OnxQ2y8rQ_Iu7mmDQ">download</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"><br></span></p><p class="c1"><span class="c6">Older models in Download Center</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- older viperx&rsquo; 1297 model tend to be a bit better for instrumentals, and 1296 for vocals (both more muddy than Kim and Unwa models, but &ldquo;still pretty good for voice cleaning&rdquo; and dealing with noise) - BS-Large model by Unwa is a fine-tune of that model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- 1143 model is the first Mel-Roformer trained by viperx before Kim introduced changes to the config, which fixed the problem of lower SDR vs models trained on BS-Roformer. Use Kim Mel-Roformer instead</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Both models struggle with saxophone and e.g. some Arabic guitars. It can still depend on a song whether these are better than even the second oldest Roformer than on MVSEP (from before viperx model got fine-tuned version). They tend to have more problems with recognizing instruments. Other than that, they&#39;re very good for vocals (although Mel-Roformer by Kim on x-minus tends to be better).</span></p><p class="c1"><span class="c0">Muddy instrumentals when not ensembled with other archs.</span></p><p class="c1"><span class="c0">Be aware that names of these models on UVR refer to SDR measurements of vocals conducted on private viperx dataset, not even older Synthetic dataset, instead of on multisong dataset on MVSEP, hence the numbers are higher than in the multisong chart on MVSEP.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Infos and fixes for older patch #1/2 <br>(with matching overlap (reversed) and dim_t necessity)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- To avoid separation errors for 4GB VRAM and AMD/Intel GPUs using Roformers, set segments 32, overlap 2 and dim_t 201 with num_overlap 2 both at the bottom of yaml config in \models\MDX_Net_Models\model_data\mdx_c_configs </span></p><p class="c1"><span class="c0">(dim_t 301 and overlap 3 also works, although not on all models [e.g. not for beta 3, but inst v1] and seems to be less muddy and fewer clicks appear). </span></p><p class="c1"><span class="c0">dim_t 201 is not optimal setting and might lead to more occasional quiet residues, clicks or sudden volume changes (like chunk was changing every 2 seconds), although there&rsquo;s no stem misalignment issue with these settings (they work both for Mel and BS Roformers). dim_t 301 with lighter models seems to be a bare minimum to avoid the majority of audible artefacts (after patch #3 dim_t 256 is allowed - &ldquo;make sure you check the &quot;Segment Default&quot; in MDXNET23 Only Options for it to take effect&rdquo;).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Using the settings above on patch #2, with GPU acceleration it will take 39m 28s for 3:28 song using 1296 model on RX 470 4GB and 18 minutes for Kim Mel-Roformer and 3:01 song.</span></p><p class="c1"><span class="c0">Using HQ_4 is much faster than realtime using default settings, but even longer than accelerated Roformer, when on CPU only using old Core 2 Quad @3.6 DDR2 800MHz.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>On Mac M1 using the patch above, it takes 9 minutes to process a 3-minute song using BS-Roformer (dim_t 1101, batch size 2, overlap 8) with &ldquo;constant throttling&rdquo;. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/6900&amp;sa=D&amp;source=editors&amp;ust=1765035742400847&amp;usg=AOvVaw1_qPUN83-GudOdXLtHUxtK">Click</a></span></p><p class="c1"><span>And below 4 minutes for Kim Mel-Roformer (overlap 1, dim 801). </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/6959&amp;sa=D&amp;source=editors&amp;ust=1765035742401104&amp;usg=AOvVaw2fTprXl5w9MODkFnoho3ps">Click</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Settings working for 6GB AMD GPUs: dim_t 601 or 701 at the bottom of the yaml file and overlap 6 or 7 in GUI.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Like I mentioned, overlap 8 can be good enough too when dim_t=801 is set (the fastest setting before SDR getting drastically reduced), at least in other cases you shouldn&rsquo;t exceed 6, while 2 should provide the best quality in most cases.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- 1602 (or rather 1601) dim_t might lead to less wateriness, but turns out in cost of a bit more of vocal residues. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;In theory, max overlap value [for Roformer separations without mentioned issues in UVR] can be known with formula:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(dim_t - 1) / 100 = Max_overlap_value</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">if dim_t = 801:</span></p><p class="c1"><span class="c0">(801 - 1) / 100 = 8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">if_dim_t = 1101:</span></p><p class="c1"><span class="c0">(1101 -1) / 100 = 10 [jarredou wrote 10 here, but it&rsquo;s actually 11]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Above that max value, some parts of the input will not be processed.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The lower the overlap value is, the more overlap is used, so better SDR.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Some Rofos models still have wrong config by default, with dim_t=256, so max overlap value for that is 2. That&#39;s why I&#39;ve advised to stick to overlap=2&rdquo; - jarredou </span></p><p class="c1"><span class="c0">So in times before dim_t was known how to be correctly set, so now overlaps can be even set to 8 now when dim_t=801 is set]).&rdquo;</span></p><p class="c1"><span class="c0">The same thing applies for both BS and Mel Roformers in UVR.</span></p><p class="c1"><span class="c0">&ldquo;audio.dim_t value is not used with roformers in ZFTurbo script, it uses audio.chunk_size and then it&#39;s parameters in the model part of config.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Using older Roformer beta patches for </span><span class="c22">Mac M1</span><span class="c0">&nbsp;doesn&rsquo;t allow you to choose the Roformer parameter to check for custom Roformer models and only config name can be chosen, but no confirm button is available. So the error &ldquo;File &quot;libv5/tfctdfv3.py&quot;, line 152, in __init&rdquo; appears.</span></p><p class="c1"><span>&gt; Place the corresponding json file with your model from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/14IfdqN3tDjXVe0hQ9i5-1KejIJTO09xX?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742405170&amp;usg=AOvVaw3nOZDAetFhclVH0W16c4S6">this</a></span><span class="c0">&nbsp;repo into: models\MDX_Net_Models\model_data beforehand, to fix the issue.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In some cases, you may still get the same error anyway and to get rid of it, you need to edit manually model_data.json adding desired model line at the end like your custom model was downloaded from download center. On example of unwa&rsquo;s beta 3:</span></p><p class="c1"><span class="c0">},</span></p><p class="c1"><span class="c0">&quot;d43f93520976f1dab1e7e20f3c540825&quot;:{</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &quot;config_yaml&quot;: &quot;config_melbandroformer_big.yaml&quot;,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &quot;is_roformer&quot;: true</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; }</span></p><p class="c1"><span class="c0">Additionally, you need the model at the end of model_data_mapper.json:<br> &nbsp; &nbsp;&quot;model melband_roformer_big_beta3.ckpt&quot;: &quot;config_melbandroformer_big&quot;</span></p><p class="c1"><span class="c0">}</span></p><p class="c1"><span class="c0">Now copy the hash-named json file (d43f93520976f1dab1e7e20f3c540825.json for beta 3) to model_data folder. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>All the three modified files for beta 3 and other models </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1-uqL0AOAJyMM8mEAODXxJsdDTKLTXmdW?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742406980&amp;usg=AOvVaw2S0bO4_wxANzF1s1njqKlD">here</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you have problems generating hash on first launch of the model and your model is not uploaded in the repo above or json is not generated then use Windows installation in VM, or ask some PC user for the config. Potentially reading </span><span class="c4"><a class="c3" href="#h.cb6cxq8g7i0v">Hash decoding</a></span><span class="c0">&nbsp;can be helpful.<br>But maybe your hashed config name will be generated correctly already after you imported the model into UVR (although no confirmation button might prevent it), and now it will be enough to just place the following line like in the jsons presented above: &quot;is_roformer&quot;: true&rdquo; (so after &ldquo;,&rdquo; in the yaml line above).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- More in-depth - Settings per model SDR vs Time elapsed -||- (incl. dim_t and overlap evaluation for Roformers) - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1XNjAyKwA2RkyOA_agmaV_6Xp2xXOHjJV09t-ho0nngk/edit?gid%3D1530726921%23gid%3D1530726921&amp;sa=D&amp;source=editors&amp;ust=1765035742408428&amp;usg=AOvVaw18AvW1cR5mYFCrrV3REuJd">click</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/pGjPZec&amp;sa=D&amp;source=editors&amp;ust=1765035742408518&amp;usg=AOvVaw1wWvjZSe5i9uD-BJPKJVAR">here</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/KBYHdNK&amp;sa=D&amp;source=editors&amp;ust=1765035742408626&amp;usg=AOvVaw31PA7QYoswrW_hAdDsCYcn">conclusion </a></span><span>- made before patch #3</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Older news follow</span></p><p class="c1"><span class="c0">___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The viperx model was also added on MVSEP</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New ensembles with higher SDR were added on MVSEP</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- BS-Roformer model trained by viperx was added on x-minus (it&#39;s different from the v2 model on MVSEP, and has higher SDR, it&#39;s the &ldquo;1.0&rdquo; one). If it&#39;s better vs V2 might depend on a song.</span></p><p class="c1"><span>It struggles with saxophone and e.g. some Arabic guitars.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus - aufr33) &ldquo;I have just completed training a new UVR De-noise model. Unlike the previous version, it is less aggressive and does not remove SFX.</span></p><p class="c1"><span class="c0">It was trained on a modified dataset. I reduced the noise level and made it more uniform, removed footsteps, crowd, cars and so on from the noise stems. On the contrary, the crowd is now a useful / dry signal. (...) The new model is designed mainly to remove hiss, such as preamp noise.&rdquo;</span></p><p class="c1"><span>For vocals that have pops or clipping crackles or other audio irregularities, use the old denoise model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Dango.ai updated their model, also giving some kind of demudder to the instrumentals, enhancing their results. Results might be better than MDX23C and BS-Roformer v2. Still, it&rsquo;s pretty pricey (8$ for 10 separations). 5x 30 seconds fragments per IP can be obtained for free, and usually it doesn&rsquo;t reset. &ldquo;It&rsquo;s $8 for 10 tracks x 6 minutes, all aggressiveness modes included (but vocal and inst models are separate). The entire multisong dataset for proper SDR check would cost around $133.&rdquo; becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Be aware that queues on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://doubledouble.top/&amp;sa=D&amp;source=editors&amp;ust=1765035742411818&amp;usg=AOvVaw0Ofch5-oMaFoOmhAJq_70I">https://doubledouble.top/</a></span><span>&nbsp;are much shorter for Deezer than Qobuz links. If there&rsquo;s no 24 bit versions for your music, use Deezer instead. <br>[outdated; currently there&rsquo;s no longer any MQA files on Tidal] Also, avoid Tidal and 16 bit FLACs from &ldquo;Max&rdquo; quality, which is slightly lossy MQA. Use 24 bit MQA from Tidal only when there&rsquo;s no 24 bit on Qobuz. Most older albums under 2020 are 16 bit MQA instead of 24 bit MQA on Tidal, and are lossy compared to Deezer and Qobuz which doesn&rsquo;t use MQA (so doubledouble doesn&rsquo;t convert MQA to FLAC like on Tidal). MQA is only &ldquo;slightly&rdquo; lossy, because it affects frequencies mainly from 18kHz and up, and not greatly.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Members of neighboring AI Hub server made a fork of KaraFan Colab updated with the new HQ_4 and InstVoc HQ2 models. It has slow separation fix applied. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Eddycrack864/KaraFan/blob/master/KaraFan_Improved_Version.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742413229&amp;usg=AOvVaw3nnDC8b04UL8ECI8KQtuNi">Click</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- HQ_4 and Crowd models added to HV Colab temp </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1GwMEjhczFzdS0Ld7eZzMcZgEmz6Jgv6m&amp;sa=D&amp;source=editors&amp;ust=1765035742413493&amp;usg=AOvVaw1sGqeaubM1qLY5zFsK6cVt">fork</a></span><span class="c0">&nbsp;before merge with main GH repo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (MVSEP) &ldquo;We have added longer filenames disabling option to mvsep, you can access it from Profile page</span></p><p class="c1"><span class="c0">20240312034817-b3f2ef51cb-ballin_bs_roformer_v2_vocals_[mvsep.com].wav -&gt; ballin_bs_roformer_v2_vocals.wav</span></p><p class="c1"><span>Due to browser caching, you might want to hard refresh the page if you have downloaded onc&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The ensembles for 2 and 5 stems on MVSEP have been updated with bigger SDR bag of models containing now new BS-Roformer v2 (with MDX23C, VitLarge23, and for multistem, the old demucsht_ft, deumcs_ht, demucs_6s and demucs_mmi models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- All the Discord direct links leading to images in this document have expired. I already reuploaded some more important stuff. Please ping me on Discord if you need access to some specific image. Provide page and expired link.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://free-mp3-download.net&amp;sa=D&amp;source=editors&amp;ust=1765035742415210&amp;usg=AOvVaw3dEk8d_2WD_Uwa-GgSsapU">https://free-mp3-download.net</a></span><span>&nbsp;has been shut down. Check out alternatives </span><span class="c4"><a class="c3" href="#h.ataywcoviqx0">here</a></span><span class="c0">.</span></p><p class="c1"><span>New Apple Music ALAC/Atmos downloader added, but its installation is a bit twisted and subscription is required. Murglar added.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX-Net HQ_4 model (SDR 15.86) released for UVR 5 GUI! Go to Models list&gt;Download center&gt;MDX-Net and pick HQ_4 for download. It is an improved and faster than HQ_3, trained for epoch 1149 (only in rare cases there&rsquo;s more vocal bleeding, more often instrumental bleeding in vocals, but the model is made with instrumentals in mind. </span></p><p class="c1"><span class="c0">Along with it, also UVR-MDX-NET Crowd HQ 1 has been added in download center.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- HQ_4 model added to the Colab:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kae0-0/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742416752&amp;usg=AOvVaw0qLu-FodE1nlqJiB4VFW9r">https://colab.research.google.com/github/kae0-0/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New BS-Roformer v2 model released on MVSEP. It&rsquo;s more aggressive model than above.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1HwCKsVMGotBvkHe1bfR8Q5POZsrRx-iu&amp;sa=D&amp;source=editors&amp;ust=1765035742417207&amp;usg=AOvVaw0JL7XiUoWjGoZyUTSSbZ1X">Fixed</a></span><span>&nbsp;</span><span class="c0">KaraFan Colab with the fix for slow non-MDX23 models. You&#39;ll no longer stack on voc_ft using any other preset than 1, but be aware that it will take 8 minutes more to initialize. (same fix as suggested before, but w/o console, as it wasn&#39;t defined, and faster ort nightly fix doesn&#39;t work here).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Turns out, there has been an official non-nightly package released, and it works with KaraFan correctly (no need to wait 8 minutes any longer):</span></p><p class="c1"><span>!python -m pip -q install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus.pro) &ldquo;Since Boosty is temporarily not accepting PayPal and generally working sucks, I made the decision to go back to Patreon. Please be aware that automatic charges will resume on March 22, 2024. If you have Boosty working correctly and do not intend to use Patreon, please cancel your Patreon subscription to avoid being charged.</span></p><p class="c1"><span>If you wish to switch from Boosty to Patreon, please wait for further instructions in March.&rdquo; Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you suffer from bleeding in other stem of 4 stems Ripple, beside decreasing volume by e.g. 3/4dB also &ldquo;when u throw the &#39;other stem&#39; back into ripple 4 track split a second time, it works pretty well [to cancel the bleeding]&rdquo; if it&#39;s still not enough, put other stem through Bandlab Splitter.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you suffer from vocal residues using Ensemble 4 models on MVSEP.com, decrease volume of input file by -8dB &ldquo;now it&#39;s silent. No more residue&rdquo; usually 3 or 4dB was doing the trick for Ripple, but here it&rsquo;s different. Might depend on a song too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Image Line &ldquo;released an update for FL Studio, and they improved the stem separation and it&#39;s better, but it has quite a bit of bleeding still, but it also seems they may have improved the vocal clarity&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (probably fixed in new HV MDX) Our newly fixed VR and newer HV MDX Colabs started to have issues with very slow initialization for some people (even 18 minutes/+ instead of normally 3). It&rsquo;s probably due to very slow download of some dependencies. Possible solutions: use other Google account, use VPN, make another Google account (maybe using Polish VPN). Let us know if it happens only for some specific dependency or all of them. You can try to uncomment the ORT nightly line in mounting cell (add # before), as it triggers more dependencies to be installed, which can be slow in that case. The downside is - there won&#39;t be GPU acceleration, and one song will be processed in 6-8 minutes instead of ~20 seconds. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New paid drum separation service:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://remuse.online/remusekit&amp;sa=D&amp;source=editors&amp;ust=1765035742422262&amp;usg=AOvVaw2ZUooufWG91PkoJdD1_lrH">https://remuse.online/remusekit</a></span></p><p class="c1"><span>It uses free </span><span class="c4"><a class="c3" href="#h.jmjab44ryjjo">drumsep</a></span><span>&nbsp;</span><span>model (same model hash: 9C18131DA7368E3A76EF4A632CD11551)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MDX Colab seem to not work due to Numpy issues. I already fixed them in Similarity Colab, and hopefully reimplement the fixes elsewhere soon. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742422954&amp;usg=AOvVaw0XHl3l_mkSohoPnD4PmPIo">VR Colab</a></span><span class="c0">&nbsp;fixed too. </span></p><p class="c1"><span>Tech details about introduced changes described below </span><span class="c4"><a class="c3" href="#h.3c6n9m7vjxul">Similary Extractor</a></span><span>&nbsp;section.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://music.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035742423361&amp;usg=AOvVaw0LpIkBZFn5UuJFtd-r4Pe3">Music AI</a></span><span>&nbsp;surfaced. Paid - $25 per month or pay as you go (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://music.ai/pricing/&amp;sa=D&amp;source=editors&amp;ust=1765035742423529&amp;usg=AOvVaw3puUcyxR-cViTJqcv3PPZk">pricing chart</a></span><span>). No free trial. Good </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1206684280625963018/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035742423725&amp;usg=AOvVaw1wOtEDW2iueA_iRTttdstp">selection </a></span><span>of models and interesting </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1206353306767728752/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035742423906&amp;usg=AOvVaw20Y9iq1295WTA62_IluNt6">module stacking</a></span><span class="c0">&nbsp;feature. To upload files instead of using URLs &ldquo;you make the workflow, and you start a job from the main page using that custom workflow&rdquo; [~ D I O ~].</span></p><p class="c1"><span class="c0">Allegedly it&rsquo;s made by Moises team, but the results seem to be better than those on Moises.</span></p><p class="c1"><span class="c0">&ldquo;Bass was a fair bit better than Demucs HT, Drums about the same. Guitars were very good though. Vocal was almost the same as my cleaned up work. (...) I&#39;d say a little clearer than mvsep 4 ensemble. It seems to get the instrument bleed out quite well, (...) An engineer I&#39;ve worked with demixed to almost the same results, it took me a few hours and achieve it [in] 39 seconds&rdquo; Sam Hocking</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;I just got an email from Myxt saying they&#39;re going to limit stem creation to 1 track per month. For creator plan users (the $8 a month one) and 2 per month for the highest plan.</span></p><p class="c1"><span class="c0">So I may assume with that logic, they&#39;re gonna take it away for free users?&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (probably fixed) For all jarredou&#39;s MDX23 v. 2.3 Colab fork users:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Components of VitLarge arch are hosted on Huggingface... when their maintenance will be finished it will work again. I can&#39;t do anything about it in the meantime.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2.2 and 2.1 and MVSEP.com 4-8 models ensemble (premium users) should work fine.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ripple now has fade in and clicking issues fixed. Also, there&#39;s less bleeding in the other stem (but Bas Curtiz&rsquo; trick for -3dB/-4dB input volume decreasing can be still necessary).</span></p><p class="c1"><span class="c0">&ldquo;Ripple&rsquo;s lossless outputs are weird, some stems like the drums are semi full band (kicks go full band, snares not etc) and the &ldquo;other&rdquo; stem looks like fake full band&rdquo;. These fixes are applied also for old versions of the app.</span></p><p class="c1"><span class="c0">Also, the lossless option fixes to some extend the offset issue so it&#39;s more similar to input now, but not identical (lossless option might require updating). Also no more abrupt endings </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ripple &nbsp;= better than CapCut as of now (and fullband).</span></p><p class="c1"><span class="c0">plus Ripple fixed the click/artifacts using cross-fade technique between the chunks.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- ViperX currently doesn&#39;t plan to release his BS-Roformer model</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New &ldquo;uvr de-crowd (beta)&rdquo; model added on x-minus. Seems to provide better results than the MVSEP model. Also, an MDX arch model version is planned for training.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;At minimum aggressiveness value, a second model is now used, which removes less crowd but preserves other sounds/instruments better.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Ripple seems to have a lossless export option now. &ldquo;First make sure the app is updated then click the folder then click the magnet icon then export and change it to lossless&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Seems like CapCut now has added separation inside Android Capcut app in unlocked Pro version</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://play.google.com/store/apps/details?id%3Dcom.lemon.lvoverseas&amp;sa=D&amp;source=editors&amp;ust=1765035742429378&amp;usg=AOvVaw1abg89HUgALrdGH6Pz09NB">https://play.google.com/store/apps/details?id=com.lemon.lvoverseas</a></span><span>&nbsp;(made by ByteDance)</span></p><p class="c1"><span class="c0">Seems like there is no other Pro variant for this app.</span></p><p class="c1"><span class="c0">At least unlocked version on apklite.me have a link to regular version, so it doesn&#39;t seem to be Pro app behind any regional block. But -</span></p><p class="c1"><span>&quot;Indian users - Use VPN for Pro&quot; as they say, so similar situation like we had on PC </span><span class="c4"><a class="c3" href="#h.f0orpif22rll">Capcut</a></span><span>&nbsp;before. Can&#39;t guarantee that unlocked version on apklite.me is clean. I&#39;ve never downloaded anything from there.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mega, GDrive and direct link support for input files added on MVSep. If you want to apply MVSep algorithm to result of other algorithm, you can use &quot;Direct link&quot; upload and point https link on separated audio-file on MVSep.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you have an issue with Demucs module not found in e.g. MDX23 v.2.3 Colab (now fixed there and also in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742431042&amp;usg=AOvVaw0iZy1fc0ZuWwOyi-yXXdPj">VR Colab</a></span><span class="c0">), here&#39;s a solution:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;In the installation code, I added `!pip install samplerate==0.1.0` right before the `!pip install -r requirements.txt &amp;&gt; /dev/null` and I managed to get all the dependencies from the requirements.txt installed properly.&rdquo; (derichtech15)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;If you repost your images or files from Discord elsewhere while cutting link after &quot;ex=&quot; for all new posted files, it will make your files expire pretty soon (17.02.24). If you leave the full link with &quot;ex=&quot; and so on, it won&#39;t expire so fast, but who knows if not later.</span></p><p class="c1"><span class="c0">So far, all the old Discord images shared elsewhere with &quot;ex=&quot; cut, work (also in incognito without Discord logged in), but it&#39;s not certain that it will be that way forever.</span></p><p class="c1"><span>Discord announced in the end of 2023, that they&#39;ll update their mechanisms of sharing links, so they&#39;ll expire after some time when they&#39;re shared, to avoid some security vulnerabilities allowing scams. Or they just want to offload the servers.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/intel/openvino-plugins-ai-audacity&amp;sa=D&amp;source=editors&amp;ust=1765035742432973&amp;usg=AOvVaw3aY2fmKXGZNdUol010em66">OpenVINO&trade;</a></span><span>&nbsp;AI Plugins for Audacity </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://www.github.com/audacity/audacity/releases/tag/Audacity-3.4.2&amp;sa=D&amp;source=editors&amp;ust=1765035742433128&amp;usg=AOvVaw0vpAYXXS6UWaJwacK-1qMA">3.4.2</a></span><span class="c0">&nbsp;64-bit introduced.</span></p><p class="c1"><span class="c0">4 stems separation, noise suppression, Music Style Remix - uses Stable Diffusion to alter a mono or stereo track using a text prompt, Music Generation - uses Stable Diffusion to generate snippets of music from a text prompt, Whisper Transcription - uses whisper.cpp to generate a label track containing the transcription or translation for a given selection of spoken audio or vocals.</span></p><p class="c1"><span class="c0">Not bad results. They use Demucs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- For people with low VRAM GPUs (e.g. 4GB or less), you can test out </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.tryreplay.io/&amp;sa=D&amp;source=editors&amp;ust=1765035742434172&amp;usg=AOvVaw1G35A25lh8U8IHLHnAKbSV">Replay</a></span><span>&nbsp;app, which provides voc_ft model and tends to crash less than UVR. Sadly, the choice of models is much smaller, but it has some de-reverb solution. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1196043224846962749/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035742434563&amp;usg=AOvVaw13uzI-9VBdExoTjUe9YAmJ">Screenshot</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Latest MVSep changes:</span></p><p class="c1"><span class="c0">1) All ensembles now have option to output intermediate waveforms from independent algorithms + additional max_mag, min_mag.</span></p><p class="c1"><span>2) Ensemble All-In now includes DrumSep results extracted from Drum stem.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- resemble-enhance (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/resemble-ai/resemble-enhance&amp;sa=D&amp;source=editors&amp;ust=1765035742435446&amp;usg=AOvVaw3KP6KEMYepYYJm1LfMmSxk">GH</a></span><span>) model added on x-minus in denoise mode. It can work better than the latest denoise model on x-minus. It is intended only for vocals. For music use UVR De-noise model on x-minus.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (fixed in kae, 2.1, 2.2 [and KaraFan irc] Colabs) All Colabs using MDX-Net models are currently very slow. GPU acceleration is broken and separations now only work on CPU with onnxruntime warnings.</span></p><p class="c1"><span class="c0">To work around the issue, go to Tools&gt;Command palette&gt;Use fallback runtime version (while it&#39;s still available).</span></p><p class="c1"><span class="c0">Downgrading CUDA to 11.8 version fixes the issue too, but it takes 9 minutes in order to install that dependency, so it&rsquo;s faster to use fallback runtime till it&rsquo;s still available. After that period, just execute this line after initialisation cell:</span></p><p class="c1"><span class="c0">console(&#39;apt-get install cuda-11-8&#39;) and GPU acceleration will start to work as usual.</span></p><p class="c1"><span class="c0">&gt;&ldquo;Better fix [than CUDA 11.8] &nbsp;until final version is released, using that onnxruntime-gpu nightly build for cuda12:</span></p><p class="c1"><span class="c0">!python -m pip install ort-nightly-gpu --index-url=https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nig</span></p><p class="c1"><span class="c0">htly/pypi/simple/</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(no need to install cuda 11.8)&rdquo; jarredou</span></p><p class="c1"><span class="c0">In case of credential issues you can try out this package instead:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">!python -m pip -q install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- LarsNet model was added on MVSep. It&#39;s used to separate drums tracks into 5 stems: kick, snare, cymbals, toms, hihat. Source: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/polimi-ispl/larsnet&amp;sa=D&amp;source=editors&amp;ust=1765035742438445&amp;usg=AOvVaw2VVI_iEBX0JfmEKzCMSB-9">https://github.com/polimi-ispl/larsnet</a></span></p><p class="c1"><span>It&rsquo;s worse than Drumsep as it uses Spleeter-like architecture, but &ldquo;at least they have an extra output, so they separate hihats and cymbals.&rdquo;. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/larsnet-colab&amp;sa=D&amp;source=editors&amp;ust=1765035742438833&amp;usg=AOvVaw0g5DKUq4ND2ZsHt3aZRlwX">Colab</a></span></p><p class="c1"><span class="c0">&ldquo;Baseline models don&#39;t seem better quality than drumsep, but the provided checkpoints are trained with oly 22 epochs, it doesn&#39;t seem much. (and STEMGMD dataset was limited by the only 10 drumkits), so it could probably be better with better dataset &amp; training&rdquo;</span></p><p class="c1"><span class="c0">&ldquo; it separates the toms so much better [than Drumsep]&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Similar situation as with Drumsep - you should provide drums separated from e.g. Demucs model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Captain FLAM from </span><span class="c4"><a class="c3" href="#h.7kniy2i3s0qc">KaraFan</a></span><span>&nbsp;asks for some help due to some recent repercussions.</span></p><p class="c1"><span>You can support him on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ko-fi.com/captain_flam&amp;sa=D&amp;source=editors&amp;ust=1765035742440072&amp;usg=AOvVaw0zaF6MT1ndzH1SdDGLdYCV">https://ko-fi.com/captain_flam</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- To preserve instruments which are counted as vocals by other MDXv2 models in KaraFan, use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/1162265179271200820/1175056481956134943/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035742440506&amp;usg=AOvVaw1TvpUUoQTg-85XvpPS2LGf">these</a></span><span class="c0">&nbsp;preset 5 modified settings (dca100fb8).</span></p><p class="c1"><span class="c0">- Added more remarks from testing these settings against sax preset and others.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- drumsep added on MVSEP!</span></p><p class="c1"><span class="c0">(separation of drums from e.g. Demucs 4 stem or &ldquo;Ensemble 8 models&rdquo;/+)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New Bandid Plus model added on MVSEP</span></p><p class="c1"><span class="c0">&ldquo;I trained BandIt for vocals. But it&#39;s too far away from MDX23C&rdquo; -ZFTurbo</span></p><p class="c1"><span class="c0">&ldquo;I loved this bandit plus model!! It has great potential.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- UVR De-noise model by FoxJoy added on x-minus. It&rsquo;s helpful for light noise, e.g. vinyl. (de-reverb and de-echo are up already)</span></p><p class="c1"><span class="c0">New MDX de-noise model is in the works and beta model was also added!</span></p><p class="c1"><span class="c0">&ldquo;the instruments in the background are preserved much better than the FoxJoy model&rdquo;</span></p><p class="c1"><span class="c0">It works for hiss, interference, crackle, rustles and soft footsteps, technical noise.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New hifi-gan-bwe Colab fork made by jarredou:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/hifi-gan-bwe/blob/main/HIFIGAN_BWE.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742442790&amp;usg=AOvVaw1Tnm0XaWINmAQ5NAXlpwnn">https://colab.research.google.com/github/jarredou/hifi-gan-bwe/blob/main/HIFIGAN_BWE.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New AI speech enhancer - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.resemble.ai/introducing-resemble-enhance&amp;sa=D&amp;source=editors&amp;ust=1765035742443129&amp;usg=AOvVaw3k6HRugyJ4kk8k2uVr4ZUO">https://www.resemble.ai/introducing-resemble-enhance</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Reason 12.5 (a DAW) was released with VST3 plugin support</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- jazzpear94 &ldquo;I made a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708580573697933382/1180312079190724718/Cinematic_MDX23C.zip&amp;sa=D&amp;source=editors&amp;ust=1765035742443539&amp;usg=AOvVaw2fQADI2D6ibYwUaZY_Sa_R">new model</a></span><span class="c0">&nbsp;with a modified version of my SFX and Music dataset with the addition of other/ambiant sound and speech. It&#39;s a multistem model and should even work in UVR GUI as it is MDX23C.</span></p><p class="c1"><span class="c0">Note: You may want to rename the config to .yaml as UVR doesn&#39;t read .yml and I didn&#39;t notice till after sending. Renaming it fixes that, however&rdquo; </span></p><p class="c1"><span class="c0">&ldquo;You put config in models\mdx_net_models\model_data\mdx_c_configs. Then when you use it in UVR it&#39;ll ask you for parameters, so you locate the newly placed config file.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Keep in mind that the cinematic model focus is mainly on sfx vs instruments</span></p><p class="c1"><span class="c0">voice stems are supplemental. Usually I remove voices first&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/karnwatcharasupat/bandit&amp;sa=D&amp;source=editors&amp;ust=1765035742444811&amp;usg=AOvVaw1oyVdFViMCP52u4msggnL2">https://github.com/karnwatcharasupat/bandit</a></span></p><p class="c1"><span>Better SDR for </span><span class="c22">Cinematic</span><span class="c0">&nbsp;Audio Source Separation (dialogue, effect, music) than Demucs 4 DNR model on MVSEP (mean SDR 10.16&gt;11.47)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- &quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn2.imagearchive.com/quadraphonicquad/data/attach/77/77907-Demucs-CC-Stereo-to-5.1v0.2b.zip&amp;sa=D&amp;source=editors&amp;ust=1765035742445385&amp;usg=AOvVaw3rBVYFXZY2tWhcJWanDNI7">Demucs+CC_Stereo_to_5.1</a></span><span>&quot; - it&#39;s a script where you can convert Stereo 2.0 to 5.1 surround sound. Full </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.quadraphonicquad.com/forums/threads/demucs-centrecutcl-stereo-to-5-1-script-v-0-2b.32788/&amp;sa=D&amp;source=editors&amp;ust=1765035742445651&amp;usg=AOvVaw0yQeGqD7qQmtx4PaSrF0vd">discussion </a></span><span class="c0">about script. They use MVSep to get steams and after use script on them.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/17SSjougcnVhX6WewW88QoKKFuFiKNz8t?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742446037&amp;usg=AOvVaw34IdkGhXG8Uf7WZnDAawYE">Colab</a></span><span class="c0">&nbsp;by jazzpear96 for using ZFTurbo&#39;s MSS training script. &ldquo;I will add inference later on, but for now you can only do the training process with this!&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New djay Pro 5.0 has &ldquo;very good realtime stems with low CPU&rdquo; Allegedly &ldquo;faster and better than Demucs, similar&rdquo; although &ldquo;They are not realtime, they are buffered and cached.&rdquo; it uses AudioShake. It can be better for instrumentals than UVR at times.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- AudiosourceRE Demix Pro new version has lead/backing vocals separation</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New </span><span class="c22">crowd</span><span class="c0">&nbsp;model added on MVSEP (applause, clapping, whistling, noise) (and got updated by the time 5.57 -&gt; 6.06; added hollywood laughts, old models also available)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- VitLarge23 model on MVSEP got updated (9.78&gt;9.90 for instrumentals)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MelBand RoFormer (9.07 for vocals) model added on MVSEP for testing purposes</span></p><p class="c1"><span class="c0">&ldquo;The model is really good at removing the hi-hat leftovers. These e.g. in the Jarredou colab sometimes when you can hear the hi-hats from the acapella. And Melband roformer can almost remove all the hi-hat leftovers from the acapella.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;are the stems not inverted result? for me it sounds like there is insane instrument loss in the instrumental stem and vocals loss in the vocal stem, yet there is no vocal bleed in instrumental stem and vice versa&rdquo; &ldquo;I also think that the vocals are surprisingly clean considering the instrumentals sound quite suppressed but also clean&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Goyo Beta plugin for dereverb stopped working on December 2nd (as it required internet connection and silent authorization on every initialization). They transitioned to paid Supertone Clear. They send BETA29 coupon over emails (with it, it&rsquo;s $29).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New MVSep-MDX23 Colab Fork v2.3 by jarredou published under new Colab link </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.3/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742449764&amp;usg=AOvVaw0IZuJYLRt40Lu7-Irknrlf">here</a></span></p><p class="c1"><span class="c0">Now it has Vitlarge23 model (previously used exclusively on MVSEP) instead of HQ3-Instr, also improved BigShifts and MDXv2 processing.</span></p><p class="c1"><span class="c0">Doesn&#39;t seem to be better than RipX which is better in preserving some instruments, and also removes vocals completely</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Check out new </span><span class="c4"><a class="c3" href="#h.vg1wnx1dc4g0">Karaoke</a></span><span class="c0">&nbsp;recommendations (dca100fb8)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Dango.ai finally received English web interface translation</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New SFX model based on Mel roformer was released by jazzpear94. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1174160853877129326&amp;sa=D&amp;source=editors&amp;ust=1765035742451135&amp;usg=AOvVaw3SBRIvhXRTLftm0GmPDZF1">More info</a></span></p><p class="c1"><span>- User friendly </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1YBpeGj66FfIHS1WH8uYBcshITOGVYOHY?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742451337&amp;usg=AOvVaw1phqiIg0khAnCfeqa54wh8">Colab</a></span><span>&nbsp;made by jarredou and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1jrw-cAi-JqZpBi6wyT3YIp3x-XHhDm1W?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742451502&amp;usg=AOvVaw1ngGAHclQH6svwt05s6YeC">forked</a></span><span>&nbsp;by jazzpear94 with new feature. In case of some problems, use WAV file.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Seems like Ripple got updated, &quot;it sounds a lot better and less muddied&quot; doesn&rsquo;t seem to give better results for all songs, though. Might be similar case with Capcut too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Hit &#39;n&#39; Mix RipX DAW Pro 7 released. For GPU acceleration, min. requirement is 8GB VRAM and NVIDIA 10XX card or newer (mentioned by the official document are: 1070, 1080, 2070, 2080, 3070, 3080, 3090, 40XX, so with min. 8GB VRAM). Additionally, for GPU acceleration to work, exactly &ldquo;Nvidia CUDA Toolkit v.11.0&rdquo; is necessary. Occasionally, during transition from some older versions, separation quality of harmonies can increase. Separation time with GPU acceleration can decrease from even 40 minutes on CPU to 2 minutes on decent GPU.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- UVR BVE v2 beta has been updated on x-minus</span></p><p class="c1"><span class="c0">&ldquo;It now performs better on songs with 2 people singing the lead</span></p><p class="c1"><span>No longer separates the second lead along with it&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-dca100fb8 found out new </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/1162265179271200820/1173570485733302312/karafan.PNG&amp;sa=D&amp;source=editors&amp;ust=1765035742453665&amp;usg=AOvVaw3XCSsDNVwfLLJaOVEZBGeq">settings</a></span><span>&nbsp;for </span><span class="c4"><a class="c3" href="#h.7kniy2i3s0qc">KaraFan</a></span><span class="c0">&nbsp;which give good results for some difficult songs (e.g. Juice WRLD) for both instrumental and acapella. It&rsquo;s now added as preset 5.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Debug mode and God mode can be disabled, as it&#39;s like that by default.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It&#39;s like an improved version of Max Spec ensemble algorithm [from UVR]&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Processing time for 6:16 track on medium setting is 22 minutes.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New MDX23C model added exclusively on MVSEP:</span></p><p class="c1"><span class="c0">vocals SDR 10.17 -&gt; 10.36</span></p><p class="c1"><span class="c0">instrum SDR 16.48 -&gt; 16.66</span></p><p class="c1"><span>Also ensemble 4 got updated by new model (10.32&gt;10.44 for vocals)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For some people using mitmproxy scripts for Capcut (but not everyone), they &ldquo;changed their security to reject all incoming packet which was run through mitmproxy. I saw the mitmproxy log said the certificate for TLS not allowed to connect to their site to get their API. And there are some errors on mitmproxy such as events.py or bla bla bla... and capcut always warning unstable network, then processing stop to 60% without finish.&rdquo; ~hendry.setiadi</span></p><p class="c1"><span class="c0">&ldquo;At 60% it looks like the progress isn&#39;t going up, but give it idk, 1 min tops, and it splits fine.&rdquo; - Bas</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-ZFTurbo published his training code:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035742456315&amp;usg=AOvVaw1zvUD27PSNcbCSJZkVzrDm">https://github.com/ZFTurbo/Music-Source-Separation-Training</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It gives the ability to train 5 types of models: mdx23c, htdemucs, vitlarge23, bs_roformer and mel_band_roformer.</span></p><p class="c1"><span class="c0">I also put some weights there to not start training from the beginning.&quot;</span></p><p class="c1"><span class="c0">It contains checkpoint of e.g. 1648 (1017 for vocals) MDX23C model to train it further.</span></p><p class="c1"><span class="c0">Be aware that the older bs_roformer implementation is very slow to train IRC.</span></p><p class="c1"><span class="c0">Vitlarge23 &ldquo;is running 2 times faster than MDX models, it&#39;s not the best quality available, but it&#39;s the fastest inference&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;change the batch size in config tho</span></p><p class="c1"><span class="c0">I think zfturbo sets the default config suited for a single a6000 (48gb)</span></p><p class="c1"><span>and chunksize&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-&quot;A small update to the backing vocals extractor [on X-Minus]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Now you can more accurately specify the panning of the lead vocal.&quot; ~Aufr33 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/900904142669754399/1170201735722188810/bve.png&amp;sa=D&amp;source=editors&amp;ust=1765035742458112&amp;usg=AOvVaw1hEbqM1ZdD3crsvgY3Z2Il">Screen</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- IntroC created a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/12m1qrRNpsTrCxfioG9xzcZUYTV0Gl8Ap&amp;sa=D&amp;source=editors&amp;ust=1765035742458370&amp;usg=AOvVaw1MDr5P6g__rMyUcvkZsMJA">script</a></span><span>&nbsp;</span><span>for mitmproxy for Capcut allowing fullband output, by slowing down the track. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D-34Q5rJ68pI&amp;sa=D&amp;source=editors&amp;ust=1765035742458581&amp;usg=AOvVaw1I0wsHRFb-mLP7lnlZYlyv">Video</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Jazzpear created new VR SFX model. Sometimes it&rsquo;s better, sometimes it&rsquo;s worse than </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/12CnfpIph5Ipd9ocoD6RsbOWzWsCeWAeT?usp%3Dshare_link&amp;sa=D&amp;source=editors&amp;ust=1765035742458926&amp;usg=AOvVaw3ABn8Eb5XbP4G54qWp6Sv7">Forte&rsquo;s</a></span><span>&nbsp;model. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.dropbox.com/scl/fo/lcpknm3rvehxhryzcd6mb/h?rlkey%3Dzpi8pnpda30d0n71tqckiocod%26dl%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035742459066&amp;usg=AOvVaw0L6VulBdjGIlks0KbVhvC9">Download</a></span></p><p class="c1"><span class="c0">For UVR 5.x GUI, use these parameters (irc same as Forte):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">User input stem name: SFX</span></p><p class="c1"><span class="c0">Do NOT check inverse stem!</span></p><p class="c1"><span class="c0">1band sr44100 hl 1024</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Now KaraFan should work locally on 4GB GTX GPUs (e.g. laptop 1060), on presets 2 or 3, and with chunk 500K, speed can be slowest. Download on GitHub the Code &gt; ZIP</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-Bas Curtiz&#39; new video on how to install and use Capcut for separation incl. exporting:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dppfyl91bJIw&amp;sa=D&amp;source=editors&amp;ust=1765035742460370&amp;usg=AOvVaw06umyL_Y6JGyRmc_rzsYC2">https://www.youtube.com/watch?v=ppfyl91bJIw</a></span></p><p class="c1"><span>and saving directly as FLAC, although the core source of FLAC is still AAC in this case:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DgEQFzj6-5pk&amp;sa=D&amp;source=editors&amp;ust=1765035742460764&amp;usg=AOvVaw3JugTdgJYJLI-xbw2FULof">https://www.youtube.com/watch?v=gEQFzj6-5pk</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It&#39;s a bit of a hassle to set it up, but do realize:</span></p><p class="c1"><span class="c0">- This is the only way (besides Ripple on iOS) to run ByteDance&#39;s model (best based on SDR).</span></p><p class="c1"><span class="c0">- Only the Chinese version has these VIP features; now u will have it in English</span></p><p class="c1"><span class="c0">- Exporting is a paid feature (normally); now u get it for free</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The instructions displayed in the video are also in the YouTube description.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Capcut normalizes the input, so you cannot use Bas&rsquo; trick to decrease volume by -3dB like in Ripple to workaround the issue of bleeding (unless you trick out the CapCut, possibly by adding some loud sound in the song with decreased volume, something like presented </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/1129475305950687372/1169341419945721916/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035742462436&amp;usg=AOvVaw0QId_7rfAGoV_00whKxgHO">here</a></span><span class="c0">).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (fixed) KaraFan Colab will be fixed on 27th at morning.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- There&rsquo;s a workaround for people not able to split using Capcut. The app discriminate based on country (poor/rich) and paywalls Pro option. &nbsp;</span></p><p class="c1"><span>The </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1166823721831501834/Testing_CapCut_workaround.mp4&amp;sa=D&amp;source=editors&amp;ust=1765035742463230&amp;usg=AOvVaw1IJZbJxnvaioT5IEQ8DMFK">video</a></span><span class="c0">&nbsp;demonstration for below</span></p><p class="c1"><span class="c0">0. Go offline.</span></p><p class="c1"><span>1. Install the Chinese version from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.capcut.cn/&amp;sa=D&amp;source=editors&amp;ust=1765035742463587&amp;usg=AOvVaw3DSecmVvz-L-AyalJEefNT">capcut.cn</a></span></p><p class="c1"><span>2. Use </span><span>these </span><span class="c0">files copied over your current Chinese installation, and don&rsquo;t use English patch. </span></p><p class="c1"><span class="c0">3. Open CapCut, go online after closing welcome screen, happy converting!</span></p><p class="c1"><span class="c0">4. Before you close the app, go offline again (or the separation option will be gone later). </span></p><p class="c1"><span class="c0">Before reopening the app, go offline again, open the app, close welcome screen, go online, separate, go offline, close. If you happen to missed that step, you need to start from the beginning of the instruction. </span></p><p class="c1"><span>(replacing </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1167169672580440195/SettingsSDK.zip&amp;sa=D&amp;source=editors&amp;ust=1765035742464872&amp;usg=AOvVaw3UI-e5cfpj2aoj_aSQ_IYT">SettingsSDK</a></span><span class="c0">&nbsp;folder no longer works after transition from 4.6 to 4.7, it freezes the app)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>FYI - the app doesn&rsquo;t separate files locally.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Bas Curtiz found out that decreasing volume of mixtures for Ripple by -3dB eliminates problems with vocal residues in instrumentals in </span><span class="c4"><a class="c3" href="#h.f0orpif22rll">Ripple</a></span><span>. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1165647205600854118/Ripple_vs_-6db_example_2.mp4&amp;sa=D&amp;source=editors&amp;ust=1765035742465813&amp;usg=AOvVaw0-MzU4tKElxyS6uaC7Exp1">Video</a></span><span>.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">This is the most balanced value, which still doesn&#39;t take too many details out of the song due to volume attenuation.</span></p><p class="c1"><span class="c0">Other good values purely SDR-wise are -20dB&gt;-8dB&gt;-30dB&gt;-6dB&gt;-4dB&gt; /wo vol. decr. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>The method might be potentially beneficial for other models and probably work best for the loudest tracks with brickwalled waveforms.</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.k3vca4e9ena8-1"><span class="c42 c36 c51 c33 c24 c30">- Stable 5.6 OpenCL (DirectML) version of UVR 5 GUI for Windows</span></h5><h5 class="c5" id="h.ych3p8fftzi0"><span class="c42 c36 c51 c33 c24 c30">Supporting AMD and Intel GPUs acceleration but no Roformers yet</span></h5><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_v5.6.0_setup_directml_old.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742467229&amp;usg=AOvVaw0VLQaRDhiRVMHKer_Bl4vx">https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_v5.6.0_setup_directml_old.exe</a></span></p><p class="c1"><span>Mac: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/&amp;sa=D&amp;source=editors&amp;ust=1765035742467477&amp;usg=AOvVaw0F5ajR84nPW75RkPvMT6BK">https://github.com/Anjok07/ultimatevocalremovergui/releases/</a></span></p><p class="c1"><span>(newer </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta Roformer</a></span><span>&nbsp;[with &ldquo;roformer&rdquo; in the installer name] supports both DirectML and CUDA out of the box already; for Mac M1 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1224923138958299146&amp;sa=D&amp;source=editors&amp;ust=1765035742467877&amp;usg=AOvVaw04uotLVlh7oyPevp2Bd4J6">click</a></span><span class="c0">).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c24">- For CUDA (NVIDIA GPUs)</span><span class="c0">&nbsp;- non-OpenCL installer in the name from here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_v5.6.0_setup.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742468429&amp;usg=AOvVaw2k5vYVpvviu2XejuFtFZvb">https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.6/UVR_v5.6.0_setup.exe</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(Following based on previous OpenCL build)</span></p><p class="c1"><span class="c0">8GB VRAM for 3:00/3:30 tracks using MDX23C HQ model with 12GB VRAM probably enough for 5:00 track which is more than in CUDA.</span></p><p class="c1"><span class="c0">Now the issue should be mitigated, and less memory crashes should occur.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ensembles might require more memory due to memory allocation issues not met in CUDA before. Also, VRAM is fully freed only after closing the application.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Acceleration for only Demucs 2 (and 1?) arch on AMD is not supported. All others archs should work.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Be aware that there was also </span><span class="c22">full MPS (GPU) acceleration introduced for Mac M1</span><span>&nbsp;for all MDX-NET Original Models (HQ3, etc.), all MDX23C Models, all Demucs v4 models (no VR models acceleration on GPU). So don&rsquo;t use Windows in VM to run UVR anymore, but separate using dmg installer from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/anjok07/ultimatevocalremovergui/releases&amp;sa=D&amp;source=editors&amp;ust=1765035742470263&amp;usg=AOvVaw0E8iAoCuKLYdax2gyYCT0u">releases</a></span><span>&nbsp;section (ARM)</span><span>. GPU acceleration is 3x faster than separation took on CPU before.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;MDX23C-InstVoc HQ 2 is out as a VIP model [for UVR 5]! It&#39;s a slightly fine-tuned version of MDX23C-InstVoc HQ. The SDR is a tiny bit lower, but I found that it leaves less vocal bleeding.&rdquo; ~Anjok</span></p><p class="c1"><span class="c0">It&rsquo;s not always the case, sometimes it can be even the opposite, but as always, all can depend on specific song.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- jarredou&rsquo;s MDX23 </span><span><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742471725&amp;usg=AOvVaw2soWEmRB7TiWOF6tX4YAaZ">2.2</a></span><span>&nbsp;Colab should allow separating faster, and also longer files now (tech </span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/MVSEP-MDX23-Colab_v2/pull/2%23issuecomment-1763052970&amp;sa=D&amp;source=editors&amp;ust=1765035742471993&amp;usg=AOvVaw3iGf-wd9ao9zrYYON4iwYX">details</a></span><span>)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- All-in ensemble added for premium users of MVSEP - it has vocals, vocals lead, vocals back, drums, bass, piano, guitar, other. Basically 8 stems (and from drums stem you can further separate single percussion instruments using </span><span><a class="c3" href="#h.jmjab44ryjjo">drumsep</a></span><span>&nbsp;</span><span>- up to 4 instruments, so it will give 10 stems in total).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.capcut.cn/&amp;sa=D&amp;source=editors&amp;ust=1765035742473158&amp;usg=AOvVaw0JYdMSVc6eQUB9rlO9N3bl">https://www.capcut.cn/</a></span><span>&nbsp;(outdated section: </span><span class="c4"><a class="c3" href="#h.f0orpif22rll">read</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">Is a new Windows app which contains Ripple/SAMI-Bytedance inst/vocal model (not 4 stems like in Ripple).</span></p><p class="c1"><span>&ldquo;At the moment the separation is only available in Chinese version which is jianyingpro, download at capcut.cn [probably </span><span><a class="c3" href="https://www.google.com/url?q=https://www.capcut.cn/?ts%3D1697285758505&amp;sa=D&amp;source=editors&amp;ust=1765035742473912&amp;usg=AOvVaw0vV2A-ASCJmL-y-zWmKJ6M">here</a></span><span class="c0">&nbsp;- it&rsquo;s where you&rsquo;re redirected after you click &ldquo;Alternate download link&rdquo; on the main page, where download might not work at all]</span></p><p class="c1"><span class="c0">Separation doesn&#39;t require sign up/login, but exporting does, and requires VIP.</span></p><p class="c1"><span class="c0">Separated vocal file is encrypted and located in C:\Users\yourusername\AppData\Local\JianyingPro\User Data\Cache\audioWave&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The unencrypted audio file in AAC format is located at \JianyingPro Drafts\yourprojectname\Resources\audioAlg (ends with download.aac)</span></p><p class="c1"><span>Drag and drop it in Audacity or convert to WAV (</span><span><a class="c3" href="https://www.google.com/url?q=https://cloudconvert.com/aac-to-wav&amp;sa=D&amp;source=editors&amp;ust=1765035742475379&amp;usg=AOvVaw02NWQ4tD2HQJqvEh3QdYiC">https://cloudconvert.com/aac-to-wav</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;To get the full playable audio in mp3 format a trick that you can do is drag and drop the download.aac file into capcut and then go to export and select mp3. It will output the original file without randomisation or skipping parts&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Trying out Capcut, the quality seems the same as the Ripple app (low bitrate mp3 quality)</span></p><p class="c1"><span class="c0">at least the voice leftover bug is fixed, lol&rdquo;</span></p><p class="c1"><span class="c0">Random vocal pops from Ripple are fixed here.</span></p><p class="c1"><span class="c0">Also, it still has the same clicks every 25 seconds as before in Ripple.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Some people cannot find the settings on </span><span><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/875539590373572648/1163477679736102932/image.png?ex%3D653fb807%26is%3D652d4307%26hm%3D567a1806a464224601faa2e16b43ba2ff856d8a70355e3926d116869cefb1360&amp;sa=D&amp;source=editors&amp;ust=1765035742477261&amp;usg=AOvVaw0pwzV5s7O-JKybgwBpGZph">this </a></span><span>screen in order to separate. Maybe it&rsquo;s due to lack of Chinese IP, or Chinese regional settings in Windows, but logging wasn&rsquo;t necessary from what someone told.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Looks like the guitar model on MVSEP can pick up piano better than the available there piano model in lots of cases (isling)</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.tvbntqdvkn9n"><span class="c0">- AudioSep has been released</span></h6><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Audio-AGI/AudioSep&amp;sa=D&amp;source=editors&amp;ust=1765035742478688&amp;usg=AOvVaw047jzhLpKuiZ6bBSu4ZpEP">https://github.com/Audio-AGI/AudioSep</a></span></p><p class="c1"><span class="c0">(separate anything you describe)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://replicate.com/cjwbw/audiosep?prediction%3Dj7dsrvtbyxfm3gjax3vfzbf7py&amp;sa=D&amp;source=editors&amp;ust=1765035742479214&amp;usg=AOvVaw242HuBCQK7JGszQuHsRolp">https://replicate.com/cjwbw/audiosep?prediction=j7dsrvtbyxfm3gjax3vfzbf7py</a></span></p><p class="c1"><span class="c0">(use short fragments as input)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/badayvedat/AudioSep/blob/main/AudioSep_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742479796&amp;usg=AOvVaw3L3AB3MuxQtpHdX3PHTMZe">https://colab.research.google.com/github/badayvedat/AudioSep/blob/main/AudioSep_Colab.ipynb</a></span><span>&nbsp;</span><span class="c0">(basic Colab)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/badayvedat/AudioSep&amp;sa=D&amp;source=editors&amp;ust=1765035742480156&amp;usg=AOvVaw2ZoaA_eFZEUi0ELwsO3jMn">https://huggingface.co/spaces/badayvedat/AudioSep</a></span><span class="c0">&nbsp;(it&rsquo;s down)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&quot;so far it&#39;s ranged from mediocre to absolutely horrible from samples I&#39;ve tried&quot;</span></p><p class="c1"><span class="c0">&quot;So far[,] it does [a] great job with crowd noise/cheering.&quot;</span></p><p class="c1"><span class="c0">Didn&#39;t pick piano.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Output is mono 32kHz. Where input is 30s, the output can be 5s.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- UVR started to process slower for some people using Nvidia 532 and 535 drivers (at least Studio ones on at least W11). </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/vladmandic/automatic/discussions/1285&amp;sa=D&amp;source=editors&amp;ust=1765035742481641&amp;usg=AOvVaw17NXJ1pN5ROqW-4KTXAevd">More</a></span><span class="c0">&nbsp;about the issue. Consider rolling back to 531.79.</span></p><p class="c1"><span>&ldquo;Took 10 seconds to run Karaoke 2 on a full song (~5[]mins), with the latest drivers it took like 20 minutes&rdquo;. The problem may occur once you reboot your system.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- AMD GPU acceleration has been introduced in the official UVR repo under a new branch on GH. Beta as exe patch will be released in the following days. Currently, it supports only MDX-Net, but not MDX23C, and Demucs 4 models (not 3) and VR arch (5.0, but not 5.1).</span></p><p class="c1"><span>Currently, GPU memory is not clearing, so you need a lot of VRAM in order to use ensembles.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus) &quot;Added additional download buttons when using UVR BVE model.**</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Now you can download:</span></p><p class="c1"><span class="c0">- song without backing vocals</span></p><p class="c1"><span class="c0">- backing vocals</span></p><p class="c1"><span class="c0">- instrumental without vocals</span></p><p class="c1"><span>- all vocals&quot; Anjok</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MacOS UVR versions should be fixed now - redownload the latest 5.6 patches. GPU processing on M1 is fully functioning with MacOS min. Monterey 12.3/7 (only VR models will crash with GPU processing). It&rsquo;s very fast for the latest MDX23C fullband model - 11 minutes vs 1 hour on CPU previously.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Cyrus version of MedleyVox Colab with chunking introduced, so you don&#39;t need to perform this step manually</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1StFd0QVZcv3Kn4V-DXeppMk8Zcbr5u5s?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742485887&amp;usg=AOvVaw2Gdk5IqdatkEpq_2lkhQfT">https://colab.research.google.com/drive/1StFd0QVZcv3Kn4V-DXeppMk8Zcbr5u5s?usp=sharing</a></span></p><p class="c1"><span class="c0">&ldquo;Run the 1st cell, upload song to folde infer_file, run 2nd cell, get results from folder results = profit&rdquo; </span></p><p class="c1"><span>&ldquo;one annoying thing is that is always converts the output to mono 28k&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Separation times since the UVR 5.6 update increased double for some people. Almost the same goes to RAM usage. </span></p><p class="c1"><span class="c0">Having lots of space on your system disk or additional partition assigned for pagefile can be vital in fixing some crashes, especially for long tracks. Be aware that CPU processing tends to crash less, but it&#39;s much slower in most cases.</span></p><p class="c1"><span class="c0">&quot;I realized that with 2-3h long audio files, I was able to use Demucs, after I added another 32GB of RAM. In Total my system got 64GB and I increased the swap file to 128GB, which is located on an NVME drive.... so just in case the 64GB RAM are not enough, which I experienced with the &quot;Winds&quot; model, it&#39;s not crashing UVR, instead using the swap.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Segments set to default 256 instead of 512 is &#8531; faster for the new MDX23C fullband model at least for 4GB cards. But it&#39;s still very slow on such RTX 3050 mobile variant (20 minutes for 3:40 song).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sometimes inverting vocals with mixture using MDX23C instead of using instrumental output can give better results and vice versa.</span></p><p class="c1"><span>&ldquo;Differences were more significant with D1581 [than fullband], but secondary vocals stem has &quot;a bit&quot; higher score&rdquo; (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/767947630403387393/1158828208028926022/image.png?ex%3D651daa5e%26is%3D651c58de%26hm%3D47ee7874240d427aee4ba65ed953678597004d2223a4d21bfaddb5e5136aa5b5%26&amp;sa=D&amp;source=editors&amp;ust=1765035742490028&amp;usg=AOvVaw1hQ4tqXcNCgVC3WmPW8SrE">click</a></span><span>). Generally inversion of these MDX23C models (but not spectral) was giving sometimes better results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MedleyVox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/17G3BPOPBPcwQdXwFiJGo0pKrz-kZ4SdU&amp;sa=D&amp;source=editors&amp;ust=1765035742490652&amp;usg=AOvVaw2puuCJganuzkHilui7QMCW">Colab</a></span><span class="c0">&nbsp;preconfigured to use with Cyrus model</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Newer model epochs can be found here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Cyru5/MedleyVox/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742491245&amp;usg=AOvVaw1glKPlvK-NTl1XEwuoX5y7">https://huggingface.co/Cyru5/MedleyVox/tree/main</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What is isrnet?</span></p><p class="c1"><span class="c0">A: It&#39;s basically just another model that builds on top of what I&#39;ve built so far that performs better. That&#39;s the surface level explanation, at least.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Settings for v2.2.2 Colab</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742492118&amp;usg=AOvVaw13LJoOq_jtEQ0hlMC9rjWI">https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you stuffer from some vocal residues, try out these settings</span></p><p class="c1"><span class="c0">BigShifts_MDX: 0</span></p><p class="c1"><span class="c0">overlap_MDX: 0.65</span></p><p class="c1"><span class="c0">overlap_MDXv3: 10</span></p><p class="c1"><span class="c0">overlap demucs: 0.96</span></p><p class="c1"><span class="c0">output_format: float</span></p><p class="c1"><span class="c0">vocals_instru_only: disabled</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, you can manipulate with weights.</span></p><p class="c1"><span class="c0">E.g. different weight balance, with less MDXv3 and more VOC-FT.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- As an addition to </span><span class="c4"><a class="c3" href="#h.37hhz9rnw7s8">AI-killing tracks</a></span><span>&nbsp;section, and in response to deletion of &quot;your poor results&quot; channel, there was recently created a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1umHpYbh1NzXIkoLj_7aM2tFwX5SHFMdaxJnhe75j8bA/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742494040&amp;usg=AOvVaw32BzfU-WPc4SJrhXEN8UyD">Gsheet</a></span><span>&nbsp;with your problematic tracks to fill in. It is open to everyone to contribute.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Video </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/VbM4qp0VP80&amp;sa=D&amp;source=editors&amp;ust=1765035742494398&amp;usg=AOvVaw0l-4d20_QBv9m1NOFHihDT">tutorial</a></span><span class="c0">&nbsp;by Bas Curtiz how to install Medley Vox (based on Vinctekan fixed source). Cyrus trained a model. MD serves to separation of various singers from a track. It sometimes does a better job than BVE models in general. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sadly, it has 24kHz output sample rate, but AudioSR works pretty good for upscaling the results.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/haoheliu/versatile_audio_super_resolution&amp;sa=D&amp;source=editors&amp;ust=1765035742495246&amp;usg=AOvVaw3m24qynXubnfoAN106OdoL">https://github.com/haoheliu/versatile_audio_super_resolution</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://replicate.com/nateraw/audio-super-resolution&amp;sa=D&amp;source=editors&amp;ust=1765035742495603&amp;usg=AOvVaw0hL22p3KV-zq353N16HE4J">https://replicate.com/nateraw/audio-super-resolution</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1ILUj1JLvrP0PyMxyKTflDJ--o2Nrk8w7?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742495988&amp;usg=AOvVaw3PK5Akw1jbAN5KYLehGYua">https://colab.research.google.com/drive/1ILUj1JLvrP0PyMxyKTflDJ--o2Nrk8w7?usp=sharing</a></span></p><p class="c1"><span>Be aware that it may not work with full length songs - you might need to divide them into smaller 30 seconds pieces.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;Ensemble 4/8 algorithms were updated on MVSep with new VitLarge23 model. All quality metrics were increased:</span></p><p class="c1"><span class="c0">Multisong Vocals: 10.26 -&gt; 10.32</span></p><p class="c1"><span class="c0">Multisong Instrumental: 16.52 -&gt; 16.63</span></p><p class="c1"><span class="c0">Synth Vocals: 12.42 -&gt; 12.67</span></p><p class="c1"><span class="c0">Synth Instrumental 12.12 -&gt; 12.38</span></p><p class="c1"><span class="c0">MDX23 Leaderboard: 11.063 -&gt; 11.098</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I added Ensemble All-In algorithm which includes additionally piano, guitar, lead/back vocals. Piano and guitar has better metrics comparing to standard models, because they are extracted from high quality &quot;other&quot; stem. Lead/back vocals also has slightly better metrics.</span></p><p class="c1"><span class="c0">piano: 7.31 -&gt; 7.69</span></p><p class="c1"><span>guitar: 7.77 -&gt; 8.95&quot; ZFTurbo </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New vocal model added on MVSEP:</span></p><p class="c1"><span>&quot;VitLarge23&quot; it&#39;s based on new transformers arch. SDR wise (9.78 vs 10.17) it&#39;s not better than MDX23C, but works &quot;great&quot; for ensemble consisting of two models with weights 2, 1.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSEP-MDX23-Colab fork v2.2.2 is out.</span></p><p class="c1"><span class="c0">It is now using the new InstVocHQ model instead of D1581:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/MVSEP-MDX23-Colab_v2/&amp;sa=D&amp;source=editors&amp;ust=1765035742498450&amp;usg=AOvVaw0qUAqNbI4yBiz4IcKg0t7B">https://github.com/jarredou/MVSEP-MDX23-Colab_v2/</a></span></p><p class="c1"><span>Memory issues with 5:33 songs fixed (even 19 minutes long with 500K chunks supported)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It should be slightly faster than the previous version, as the extra processing for the fullband trick is not needed anymore with the new model.</span></p><p class="c1"><span class="c0">Q: Why is &quot;overlap_MDX&quot; set to 0.0 by default in MVSEP-MDX23-Colab_v2 ? </span></p><p class="c1"><span>A: because it&#39;s a &quot;doublon&quot; with MDX BigShifts (that is better)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Stable final version of UVR v5.6.0 has been released along with MDX23C fullband model (the same as on MVSEP) - SDR is 10.17 for vocals &amp; 16.48 for instrumentals. </span></p><p class="c1"><span class="c0">It&rsquo;s called MDX23C-InstVoc HQ.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/&amp;sa=D&amp;source=editors&amp;ust=1765035742499782&amp;usg=AOvVaw2412ZUiJxxuArolx0c8puC">https://github.com/Anjok07/ultimatevocalremovergui/releases/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Be aware it&rsquo;s taking much more time to process a song with it, then all previous models. Also, it doesn&rsquo;t require volume compensation set. It can leave more vocal residues than HQ_3 models for some songs. On the other hand, it can give very good results with song with &ldquo;super dense mix like Au5 - Snowblind&rdquo; but also for older tracks like Queen - March Of The Black Queen (always caused issues, but it gave the best result so far, although still lot of BV is missed).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Performance:</span></p><p class="c1"><span class="c0">- 3:30 track with HQ_3 takes up to 24 minutes on i3-3217u while the new model takes 737 minutes (precisely 1:34 vs 41:00 for 15 seconds song).</span></p><p class="c1"><span>- RTX 3060 12 GB - takes around 15 minutes to process a 25 minutes file with the new model. </span></p><p class="c1"><span class="c0">- GTX 1080 Ti took about 4 minutes to process, about a 5 min 30 song</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you upgraded from beta, Matchering might not work correctly. In order to fix the error:</span></p><p class="c1"><span class="c0">Go to the Align tool.</span></p><p class="c1"><span class="c0">Select another option under &quot;Volume Adjustment&quot;, it can be anything.</span></p><p class="c1"><span class="c0">Now, matchering should work. The fix may not apply for Linux installations.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- KaraFan </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Captain-FLAM/KaraFan/blob/master/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742502020&amp;usg=AOvVaw2HtZTtLzBURagTiljHdZfv">original</a></span><span>&nbsp;</span><span class="c0">Colab seems to work now (v. 3.1) but one track with default settings takes 30 minutes for 3:37 track on free T4 (the last files processed are called Final) and it can get you disconnected from runtime quick (especially if you miss some multiple captcha prompts). V. 3.1 can have more vocal residues than in 1.x version and even more than in HQ_3 model on its own.</span></p><p class="c1"><span>You might want to consider using older versions of KF with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kubinka0505/colab-notebooks/blob/master/Notebooks/AI/Audio_Separation/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742502874&amp;usg=AOvVaw3ICYeXhNuY83vDmBGCz3Id">Kubinka</a></span><span>&nbsp;</span><span class="c0">Colab.</span></p><p class="c1"><span class="c0">- Now 3.2 version was released with less vocal residues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">As mentioned before, after runtime disconnection error, output folder still constantly populated with new files, while progress bar is not being refreshed after clicking close or even after closing your tab with Colab opened.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-&quot;Image-Line the company that made Fl Studio 21 took to instagram announcing a beta build that allows the end users to separate stems from the actual program itself, this is in beta and isn&rsquo;t final product&quot;</span></p><p class="c1"><span class="c0">People say it&#39;s Demucs 4, but maybe not ft model and/or with low parameters applied or/and it&#39;s their own model.</span></p><p class="c1"><span class="c0">&quot;Nothing spectacular, but not bad.&quot;</span></p><p class="c1"><span class="c0">&quot;- FL Studio bleeds beats, just like Demucs 4 FT</span></p><p class="c1"><span class="c0">- FL Studio sounds worse than Demucs 4 FT</span></p><p class="c1"><span>- Ripple clearly wins&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-Org. KaraFan </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Captain-FLAM/KaraFan/blob/master/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742504602&amp;usg=AOvVaw0VCKFv6cJNGPjKPGSt-CYY">Colab</a></span><span>&nbsp;with v. 3.0 should work with the large GPU option disabled (now done by default).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-You may be experiencing issues with KaraFan 3.0 alpha (e.g. lack of 5_F-music with which the result was better before), and using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kubinka0505/colab-notebooks/blob/master/Notebooks/AI/Audio_Separation/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742505194&amp;usg=AOvVaw3JFgNvAkj6b_oSUj-gICdt">Kubinka Colab</a></span><span>&nbsp;which uses the older version for now has some problems with GPU acceleration. Maybe the previous KF commit will work or even the one before (2.x is used </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1153747778938359909&amp;sa=D&amp;source=editors&amp;ust=1765035742505538&amp;usg=AOvVaw11bd2wXY1Cz2X2crreC_sq">here</a></span><span class="c0">).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-New UVR beta patches for Windows/Mac/M1 at the bottom of the release note</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/&amp;sa=D&amp;source=editors&amp;ust=1765035742505953&amp;usg=AOvVaw1fw-T98ejmS5oZAmSR3WZJ">https://github.com/Anjok07/ultimatevocalremovergui/releases/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Usually check for newer versions above, but this one currently fixes long error on using the new BVE model</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.5.0/UVR_Patch_9_20_23_20_40_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742506510&amp;usg=AOvVaw3RLctOvV4HVsREEWlLFD_-">https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.5.0/UVR_Patch_9_20_23_20_40_BETA.exe</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;The new BVE (Background Vocal Extractor) model [in UVR 5 GUI] has been released!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>To use the BVE model, please make sure you use the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.5.0/UVR_Patch_9_18_23_18_50_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742507078&amp;usg=AOvVaw05pxMG0ufciyaADnQbILXj">UVR_Patch_9_18_23_18_50_BETA</a></span><span>&nbsp;patch (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.5.0/Ultimate_Vocal_Remover_v5.BETA.9_19_23_16_57_MacOS_arm64.dmg&amp;sa=D&amp;source=editors&amp;ust=1765035742507279&amp;usg=AOvVaw0f8u3HXorR-thWyLRCicU8">Mac</a></span><span class="c0">). Remember, it&#39;s designed to be used in a chain ensemble, not on its own. It&#39;s better to utilize it via &quot;Vocal Splitter Options&quot;. ~Anjok&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Using Lead vocal placement &nbsp;= stereo 80% is still only available on X-Minus only. UVR GUI doesn&#39;t support this yet - it&rsquo;s for the situation when your main vocals are confused with backing vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- In the latest UVR GUI beta patch, vocal stems of MDX instrumental models have polarity flipped. You might want to flip it back in your DAW.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Investigating KaraFan shapes issue &gt; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1153747778938359909&amp;sa=D&amp;source=editors&amp;ust=1765035742508697&amp;usg=AOvVaw0U29epVaEu7ODaDJBanq58">link</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New piano and guitar models added on MVSEP. Use other stem from e.g. &ldquo;Ensemble 8 models&rdquo; or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742509269&amp;usg=AOvVaw1HRZL9xCm4aH2R-A2ersJ0">MDX23 Colab</a></span><span class="c0">&nbsp;or htdemucs_ft for better results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- To separate electric and acoustic guitar, you can run a song (e.g. other stem) through the Demucs guitar model and then process the guitar stem with GSEP (or MVSEP model instead of one of these).</span></p><p class="c1"><span>Gsep only can separate electric guitar so far, so the acoustic one will stay in the &quot;other&quot; stem.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New UVR beta patch implements chain ensemble from x-minus for splitting backing and lead vocals. To use it: </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1. Enable &quot;Help Hints&quot; (so you can see a description of the options), </span></p><p class="c1"><span class="c0">2. Go to any option menu </span></p><p class="c1"><span class="c0">3. Click the &quot;*Vocal Splitter Options*&quot;</span></p><p class="c1"><span class="c0">4. From there you will see the new chain ensemble options.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.5.0/UVR_Patch_9_15_23_6_35_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742511217&amp;usg=AOvVaw3LPB1VRNV_nbJGB4yHlwbs">Patch</a></span><span>&nbsp;(patching from the app may cause startup issues)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- &quot;New MDX23C model improved on [MVSEP] Leaderboard from 10.858 up to 11.042&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;For those of you who were running into errors related to missing *&quot;msvcp140d.dll&quot;* and *&quot;VCRUNTIME140D.dll&quot;* after installing the latest patch, it&#39;s been fixed.&quot; -Anjok</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.5.0/UVR_Patch_9_13_23_17_17_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742512102&amp;usg=AOvVaw2Bv2Qepkl8PzJ1V_otq0J5">UVR_Patch_9_13_23_17_17_BETA</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- The UVR&#39;s latest beta 9 patch causes startup issue for lots of people on even clean Windows 10. No fix for it. Copying libraries manually or installing all possible redistributables doesn&#39;t work. In such case, use beta 8 patch.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you see an error that you&#39;re disconnected from KaraFan Colab, it can still separate files in the background and consume free &quot;credits&quot; till you click Environment&gt;Terminate session. It happens even if you close the Colab.</span></p><p class="c1"><span class="c0">So, you can see your GDrive output folder still constantly populated with new files, while progress bar is not being refreshed after error of runtime disconnection or even after Closing your tab with Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- KaraFan got updated to 1.2 (eg. model picking was added). Deleting your old KaraFan folder on GDrive can be necessary to avoid an error now in Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- KaraFun - next version of MDX23 fork (originally developed by ZFTurbo, enhanced and forked by jarredou) has been created by Captain FLAM (with jarredou&rsquo;s assistance on tweaks).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Official </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Captain-FLAM/KaraFan/blob/master/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742514241&amp;usg=AOvVaw0lAZJn2nEFK94LaUSgPP2Y">Colab</a></span><span>&nbsp;(video </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/XZAF2rzc2Q4&amp;sa=D&amp;source=editors&amp;ust=1765035742514339&amp;usg=AOvVaw0odIxwMvaISxrP-AfdJPEl">guide</a></span><span>&nbsp;in case of problems)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kubinka0505/colab-notebooks/blob/master/Notebooks/AI/Audio_Separation/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742514620&amp;usg=AOvVaw3W5sub6O3becREpTAL_jKO">Colab</a></span><span class="c0">&nbsp;forked by Kubinka (can show error now after 1.2 update)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>GUI for offline use: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Captain-FLAM/KaraFan/tree/master&amp;sa=D&amp;source=editors&amp;ust=1765035742514987&amp;usg=AOvVaw1b3Ms5JI9yxch6SMmL9jXo">https://github.com/Captain-FLAM/KaraFan/tree/master</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It gives very clean instrumentals with much less of consistent vocal residues than in MDX23 2.0-2.2 and Ripple/Bytedance.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(might have been changed) You can also disable SRS there to get a bit cleaner result, but in cost of more vocal residues. How detestable it will be without SRS, depends on a track - e.g. if it has heavy compressed modern vocals and lots of places with not busy mix (when not a lot of instruments play). Disabled SRS adds a substantial amount of information above 17.7kHz.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">One of our users had problems caused seemingly by empty Colab Notebooks folder which he needed to delete. Could have been something else they did too, though.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New epoch of new BVE model has been added to x-minus</span></p><p class="c1"><span class="c0">&ldquo;In some parts the new BVE is better, in some it&#39;s worse. Still a great model&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt; To get better results, you can downmix the result to mono and repeat the separation</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For people having issues with Boosty x-minus payment:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://boosty.to/uvr/posts/5d88402e-9eb1-4046-a00a-cf8b09e27561&amp;sa=D&amp;source=editors&amp;ust=1765035742517092&amp;usg=AOvVaw1hoo4m0IOWY8GLjqBV9PR6">https://boosty.to/uvr/posts/5d88402e-9eb1-4046-a00a-cf8b09e27561</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sometimes for instrumental residues in vocals, AIs for voice recorded with home microphone can be used (e.g. Goyo [now Supertone Clear], or even Krisp, RTX Voice, AMD Noise Suppression, Elgato Wave Link 3.0 Voice Focus or Adobe Podcast as a last resort) it all depends on type of vocals and how destructive the AI can get.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Izotope Ozone 11 has been released. It&rsquo;s 1200$ for Advanced Edition. It&rsquo;s the only version possessing Spectral Recovery. Music Rebalance is said to have Demucs instead of Spleeter now.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.izotope.com/en/products/ozone.html&amp;sa=D&amp;source=editors&amp;ust=1765035742518311&amp;usg=AOvVaw0GTu2cRmbixxfYPqJs6c9F">https://www.izotope.com/en/products/ozone.html</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Acon Digital has released </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://acondigital.com/products/remix&amp;sa=D&amp;source=editors&amp;ust=1765035742518590&amp;usg=AOvVaw1BQ6boBWYkQYD3Z2YiCr7J">Remix</a></span><span class="c0">, their first plug-in capable of real-time separation to five stems: Vocals, Piano, Bass, Drums, and Other.</span></p><p class="c1"><span class="c0">&ldquo;Just listened to the demo, not great but still&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.713q0eyar6o3"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/mattricesound/RemFx&amp;sa=D&amp;source=editors&amp;ust=1765035742519063&amp;usg=AOvVaw0YSpTyukvXP7Aoc8R-zel8">RemFX</a></span><span>&nbsp;for detection and removal of the following effects: chorus, delay, distortion, dynamic range compression, and reverb. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/mattricesound/RemFx&amp;sa=D&amp;source=editors&amp;ust=1765035742519343&amp;usg=AOvVaw0BxDvYGahuF1jz6jtn014c">Huggingface</a></span><span>&nbsp;(currently stopped working) </span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://csteinmetz1.github.io/RemFX/&amp;sa=D&amp;source=editors&amp;ust=1765035742519493&amp;usg=AOvVaw21tECBG0PSE1bHlAhftKtm">Samples</a></span></h6><p class="c1"><span>The </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1LoLgL1YHzIQfILEayDmRUZzDZzJpD6rD&amp;sa=D&amp;source=editors&amp;ust=1765035742519695&amp;usg=AOvVaw02E_2TprCW6kw_xnB62Y0Z">Colab</a></span><span>&nbsp;is slow while downloading </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/mhrice/RemFx/blob/main/scripts/download_ckpts.sh&amp;sa=D&amp;source=editors&amp;ust=1765035742519867&amp;usg=AOvVaw06z1iIyz3mUFa8DPPXBiII">checkpoints</a></span><span>&nbsp;</span><span class="c0">from zenodo (400KB/s for 1GB file out of 6), later it stopped working.</span></p><p class="c1"><span class="c0">Outputs in at least Huggingface are mono, may not work in every case, the website in general doesn&#39;t work well with big files, keep them short, 0-30 seconds.<br>Sometimes 30 seconds is still not enough on Colab and it throws OutOfMemoryError.</span></p><p class="c1"><span class="c0">It&#39;s not better than our dereverb model in UVR.</span></p><p class="c1"><span class="c0">To fix Colab:</span></p><p class="c1"><span>&ldquo;speechbrain lib API was totally changed in recent 1.0.0 version, it&#39;s working if you downgrade it:<br>!pip install speechbrain==0.5.16&rdquo;<br>OG </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/mhrice/RemFx&amp;sa=D&amp;source=editors&amp;ust=1765035742520976&amp;usg=AOvVaw0puibjfodAX19Y17KlC6Ja">repo</a></span><span>&nbsp;for running locally.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Beta UVR patch also released for x86_64 &amp; M1 Macs:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_8_28_23_2_9_BETA_MacOS_x86_64.zip&amp;sa=D&amp;source=editors&amp;ust=1765035742521611&amp;usg=AOvVaw0O_w80Vv6I8Vl0TotLzIqn">https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_8_28_23_2_9_BETA_MacOS_x86_64.zip</a></span></p><p class="c1"><span class="c0">&ldquo;If you have any trouble running the application, and you&#39;ve already followed the &quot;MacOS Users: Having Trouble Opening UVR?&quot; instructions here, try the following:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Right-click the &quot;Ultimate Vocal Remover&quot; file and select &quot;Show Package Contents&quot;.</span></p><p class="c1"><span class="c0">Go to -&gt; Contents -&gt; MacOS -&gt;</span></p><p class="c1"><span class="c0">Open the &quot;UVR&quot; binary file.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>In case of further issues, check this out:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DHQsazeOd2Iw%26feature%3Dyoutu.be&amp;sa=D&amp;source=editors&amp;ust=1765035742522625&amp;usg=AOvVaw1yn5bOIUH0TulIp5glNoYN">https://www.youtube.com/watch?v=HQsazeOd2Iw&amp;feature=youtu.be</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Looks like e.g. with Denoise Lite models it can ask for parameters. Set 4band_v3 and 16 channels, press yes on empty window.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;The Mac beta is not stable yet.&rdquo; - Anjok</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-&quot;The new beta [UVR] patch has been released! I made a lot of changes and fixed a ton of bugs. A public release that includes the newest MDX23 model will be released very soon. Please see the change log via the following message - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/785664354427076648/1145622961039101982&amp;sa=D&amp;source=editors&amp;ust=1765035742524022&amp;usg=AOvVaw0Nlbx9q3iZHEwtet_qNIY0">https://discord.com/channels/708579735583588363/785664354427076648/1145622961039101982</a></span><span class="c0">&quot;</span></p><p class="c1"><span class="c0">Patch:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_8_28_23_2_9_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742524451&amp;usg=AOvVaw0Ll43cGM5qB44Wcda2A3xA">https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_8_28_23_2_9_BETA.exe</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-&quot;I found a way to bypass the free sample limits of Dango.ai. With VPN and incognito, when the limit appears, change the date on the computer or other device (I set the next day) and close and re-open the incognito tab. Sometimes it can show network error, in such case restart the VPN and re-enter in incognito again&quot; Tachoe Bell</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Bas&#39; guide to change region to US for Ripple on iOS</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708595418400817162/1146727313963237406/Ripple_iOS_iPad_mini_2_-_demo.mp4&amp;sa=D&amp;source=editors&amp;ust=1765035742525567&amp;usg=AOvVaw3tFT7tmTjcOE8LU9zLPTKP">https://media.discordapp.net/attachments/708595418400817162/1146727313963237406/Ripple_iOS_iPad_mini_2_-_demo.mp4</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Another way to use Ripple without Apple device</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Sign up at </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://saucelabs.com/sign-up&amp;sa=D&amp;source=editors&amp;ust=1765035742525955&amp;usg=AOvVaw36eqFo_isEDQ8akKBceGMP">https://saucelabs.com/sign-up</a></span></p><p class="c1"><span>Verify your email, upload this as the IPA: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://decrypt.day/app/id6447522624/dl/cllm55sbo01nfoj7yjfiyucaa&amp;sa=D&amp;source=editors&amp;ust=1765035742526273&amp;usg=AOvVaw3inUyclOwEl9Xnhhf-03QH">https://decrypt.day/app/id6447522624/dl/cllm55sbo01nfoj7yjfiyucaa</a></span></p><p class="c1"><span class="c0">Rotating puzzle captcha for TikTok account can be tasking due to low framerate. Some people can do it after two tries, others will sooner run out of credits, or completely unable to do it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Every 8 seconds there is an artifact of chunking in Ripple. Heal feature in Adobe Audition works really well for it:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DQqd8Wjqtx-8&amp;sa=D&amp;source=editors&amp;ust=1765035742527104&amp;usg=AOvVaw2H5oAi3R-4EpG35c6W3Yxm">https://www.youtube.com/watch?v=Qqd8Wjqtx-8</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-The same explained on RX 10 example and its Declick feature:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DpD3D7f3ungk&amp;sa=D&amp;source=editors&amp;ust=1765035742527501&amp;usg=AOvVaw3DimyozX2mU--C_BQlEiRv">https://www.youtube.com/watch?v=pD3D7f3ungk</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ripple/SAMI Bytedance&#39;s API was found. If you&#39;re Chinese, you can go through it easier.</span></p><p class="c1"><span class="c0">The sami-api-bs-4track (the one with 10.8696 SDR Vocals) - you need to pass the Volcengine facial/document recognition apparently only available to Chinese people</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.volcengine.com/docs/6489/72011&amp;sa=D&amp;source=editors&amp;ust=1765035742528457&amp;usg=AOvVaw0gF-pNwf13VXzCnPZ3FAXf">https://www.volcengine.com/docs/6489/72011</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>We already evaluated its </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/4750&amp;sa=D&amp;source=editors&amp;ust=1765035742528710&amp;usg=AOvVaw26uVGu0QRMpocyVeUq8Kd2">SDR</a></span><span class="c0">, and it even scored a bit better than Ripple itself.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">This is the Ripple audio uploading API:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/bitelchux/TikTokUploder/blob/2a0f0241a91b558a7574e6689f39f9dd9c39e295/uploader.py&amp;sa=D&amp;source=editors&amp;ust=1765035742529260&amp;usg=AOvVaw0XM5jL89LKBYR8nn2Fd0zJ">https://github.com/bitelchux/TikTokUploder/blob/2a0f0241a91b558a7574e6689f39f9dd9c39e295/uploader.py</a></span></p><p class="c1"><span>there&#39;s a sample script on the volcengine SAMI page</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;API from volcengine only return 1 stem result from 1 request, and it offers vocal+inst only, other stems not provided. So making a quality checker result on vocal + instrument will cost 2x of its API charging</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">something good is that volcengine API offers 100 min free for new users&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">API is paid 0.2 CNY per minute.</span></p><p class="c1"><span class="c0">It takes around 30 seconds for one song.</span></p><p class="c1"><span class="c0">It was 1.272 USD for separating 1 stem out MVSEP&#39;s multisong dataset (100 tracks x 1 minute).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (outdated) Using Ripple on an M1 remote machine turned out to be successful but very convoluted.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1143710971798507520&amp;sa=D&amp;source=editors&amp;ust=1765035742530847&amp;usg=AOvVaw25WU7uk_-LRL6pvk_9oXx1">https://discord.com/channels/708579735583588363/708579735583588366/1143710971798507520</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-It is possible that &quot;a particular song that an older version of mdx23 (mdx23cmodel3.ckpt) has a much better extraction than D1581 and the current 4 model ensemble on MVSEP for preserving the instruments (also organ-like instruments)&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-Seems like Google raised Colab limit for free users from 1 hour to 5 hours. It depends on a session, but in most cases you should be able to perform tasks taking above 4 hours now.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-How to change region to US in Apple App Store to make &quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://apps.apple.com/us/app/ripple-music-creation-tool/id6447522624&amp;sa=D&amp;source=editors&amp;ust=1765035742532000&amp;usg=AOvVaw3yLdTIwYNC-ATIo3nogYMW">Ripple - Music Creation Tool</a></span><span class="c0">&quot; (SAMI-Bytedance) work.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://support.apple.com/en-gb/HT201389&amp;sa=D&amp;source=editors&amp;ust=1765035742532216&amp;usg=AOvVaw1q-JVOXYX6ZCG6acw8d_IB">https://support.apple.com/en-gb/HT201389</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.bestrandoms.com/random-address-in-us&amp;sa=D&amp;source=editors&amp;ust=1765035742532441&amp;usg=AOvVaw0LL-ZVC8b72XtQBEd9DZLG">https://www.bestrandoms.com/random-address-in-us</a></span></p><p class="c1"><span>Or use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1143659641277010033/20230822_233327.jpg&amp;sa=D&amp;source=editors&amp;ust=1765035742532627&amp;usg=AOvVaw1Nz141buKe8LXsDjXdmhLk">this</a></span><span class="c0">&nbsp;Walmart address in Texas, the number belongs to an airport.</span></p><p class="c1"><span class="c0">Do it in App Store (where you have the person-icon in top right).</span></p><p class="c1"><span class="c0">You don&#39;t have to fill credit cards details, when you are rejected,</span></p><p class="c1"><span class="c0">reboot, check region/country... and it can be set to the US already.</span></p><p class="c1"><span>Although, it can happen for some users that it won&#39;t let you download anything forcing your real country.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I got an error because the zip code was wrong (I did enter random numbers) and it got stuck even after changing it.</span></p><p class="c1"><span class="c0">So I started from the beginning, typed in all the correct info, and voil&agrave;&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If &#39;&#39;you have a store credit balance; you must spend your balance before you can change stores&#39;&#39;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>It needs (an old?) a sim card to log your old account out if necessary.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Long awaited app made by Bytedance with one of their SAMI variants from MDX23 competition which holds top of our MVSEP leaderboard was published on iOS and for US region only</span></p><p class="c1"><span class="c0">(with separate possibility to sign up for beta testing, also not for people outside US, and the app is in the official store already anyway, but it was before official release - at the end of June, so it&#39;s older news).</span></p><p class="c1"><span class="c0">It&#39;s a multifunctional app for audio editing, which also contains a separation model. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s free, called:</span></p><p class="c1"><span class="c0">&quot;Ripple - Music Creation Tool&quot;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://apps.apple.com/us/app/ripple-music-creation-tool/id6447522624&amp;sa=D&amp;source=editors&amp;ust=1765035742535686&amp;usg=AOvVaw3SGuV1b1o7NqXLmMiiy63s">https://apps.apple.com/us/app/ripple-music-creation-tool/id6447522624</a></span></p><p class="c1"><span class="c0">The app requires iOS 14.1</span></p><p class="c1"><span class="c0">(it&#39;s only for iOS).</span></p><p class="c1"><span class="c0">Output files are 4 stems 256kbps M4A (320 max).</span></p><p class="c1"><span>Currently, the best </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/4744&amp;sa=D&amp;source=editors&amp;ust=1765035742536234&amp;usg=AOvVaw31VFgtSETm2BBMLhqb5gbt">SDR</a></span><span class="c0">&nbsp;for public model/AI, but it gives the best results for vocals in general. For instrumentals, it rather doesn&rsquo;t beat paid Dango.ai (and rather not KaraFan too).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;My only thought is trying an iOS Emulator, but every single free one I&#39;ve tried isn&#39;t far-fetched where you can actually download apps, or import files that is&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sideloading of this mobile iOS app is possible on at least M1 Macs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&quot;If you&#39;re desperate, you can rent an M1 Mac on Scaleway and run the app through that for $0.11 an hour using this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/PlayCover/PlayCover&amp;sa=D&amp;source=editors&amp;ust=1765035742537439&amp;usg=AOvVaw3CNi7K9oB3ud5W49rBlV3y">https://github.com/PlayCover/PlayCover</a></span><span class="c0">&quot;</span></p><p class="c1"><span class="c0">IPA file:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.dropbox.com/s/z766tfysix5gt04/com.ripple.ios.appstore_1.9.1_und3fined.ipa?dl%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035742537816&amp;usg=AOvVaw1Z_MbDfU-5FfcdN20Xdbgt">https://www.dropbox.com/s/z766tfysix5gt04/com.ripple.ios.appstore_1.9.1_und3fined.ipa?dl=0</a></span></p><p class="c1"><span class="c0">&quot;been working like a dream for me on an M1 Pro&hellip; I&#39;ve separated 20+ songs in the last hour&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;bitrise.com claims to have M1s and has a free trial&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Scaleway method:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1146136170342920302/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035742538683&amp;usg=AOvVaw3KiPKQJAv0mZRD96qjDEtU">https://cdn.discordapp.com/attachments/708579735583588366/1146136170342920302/image.png</a></span></p><p class="c1"><span class="c0">&ldquo;keep in mind that the vm has to be up for 24 hours before you can remove it, so it&#39;ll be a couple bucks in total to use it&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I used decrypted ipa + sideloadly</span></p><p class="c1"><span>seems that it doesn&#39;t have internet access or something&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So far, Ripple didn&#39;t beat voc_ft (although there might be cases when it&#39;s better) and Dango. Samples we got months ago are very similar to those from the app, also *.models files have SAMI header and MSS in model files (which use their own encryption), although processing is probably fully reliable on external servers as the app doesn&#39;t work offline (also model files are suspiciously small - few megabytes, although it&#39;s specific for mobilenet models). It&#39;s probably not the final iteration of their model, as they allegedly told someone they were afraid that their model will leak, but better than the first iteration judging by SDR with even lossy input files.</span></p><p class="c1"><span class="c0">Later they told that it&rsquo;s different model than the one they previously evaluated, and that time it was trained with lossy 128kbps files due to some &ldquo;copyright issues&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Most importantly, it&#39;s the good for vocals, also cleaning vocal inverts, and surprisingly good for e.g. Christmas songs, (it handled hip-hop, e.g. Drake pretty well). It&#39;s better for vocals than instrumentals due to residues in other stem - bass is &ldquo;so&rdquo; good, drums also decent. Vocals can be used for inversion to get instrumentals, and it may sound clean, but rather not as good as what 2 stem option or 3 stem mixdown gives.</span></p><p class="c1"><span class="c0">Other stem residues appear due to the fact they told the other stem is taken from the difference of all remaining stems - they didn&rsquo;t train the other stem model to save on separation time.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;One thing you will notice is that in the Strings &amp; Other stem there is a good chunk of residue/bleed from the other stems, the drum/vocal/bass stems all have very little to no residue/bleed&quot; doesn&#39;t exist in all songs.</span></p><p class="c1"><span class="c0">It&#39;s fully server-based, so they may be afraid of heavy traffic publishing the app worldwide, and it&#39;s not certain that it will happen.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Thanks to Jorashii, Chris, Cyclcrclicly, anvuew and Bas.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Press information:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://twitter.com/AppAdsai/status/1675692821603549187/photo/1&amp;sa=D&amp;source=editors&amp;ust=1765035742543221&amp;usg=AOvVaw09WgdOqcrIlErTB1YChmD3">https://twitter.com/AppAdsai/status/1675692821603549187/photo/1</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://techcrunch.com/2023/06/30/tiktok-parent-bytedance-launches-music-creation-audio-editing-app/&amp;sa=D&amp;source=editors&amp;ust=1765035742543631&amp;usg=AOvVaw0Y1JswZ3y-cryZhs1IMu3J">https://techcrunch.com/2023/06/30/tiktok-parent-bytedance-launches-music-creation-audio-editing-app/</a></span></p><p class="c1"><span class="c0">Beta testing</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.ripple.club/&amp;sa=D&amp;source=editors&amp;ust=1765035742543876&amp;usg=AOvVaw11Kj9TDQVI16ptdsLXytSv">https://www.ripple.club/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Following models added on MVSep:</span></p><p class="c1"><span class="c0">UVR-De-Echo-Aggressive</span></p><p class="c1"><span class="c0">UVR-De-Echo-Normal</span></p><p class="c1"><span class="c0">UVR-DeNoise</span></p><p class="c1"><span class="c0">UVR-DeEcho-DeReverb</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>They are all available under the &quot;Ultimate Vocal Remover HQ (vocals, music)&quot; option (MDX FoxJoy MDX Reverb Removal model is available as a separate category). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you looked for possibility to pay for Dango using Alipay - they recently introduced the possibility to link foreign cards, and if that option fails (sometimes does), you can open 6 months &ldquo;tourcard&rdquo;, and open new later if necessary, but only Visa, Mastercard, Diners Club and JCB cards are supported to top tourcard up</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ltl-beijing.com/alipay-for-foreigners/&amp;sa=D&amp;source=editors&amp;ust=1765035742545469&amp;usg=AOvVaw2HOstTHWu-UKQmuYZaae6x">https://ltl-beijing.com/alipay-for-foreigners/</a></span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span>- Dango no longer supports Gmail email accounts</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New piano model added on MVSEP. SDR-wise it&rsquo;s better than GSep, but GSep is probably also using some kind of processing in order to get better separation results, but e.g. Dango instrumentals can be inverted to get just vocals despite the fact they claim to use some recovery technology.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.vktvthhthrvh">arigato78 method</a></span><span class="c0">&nbsp;for main vocals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-Captain Curvy method for instrumentals added in instrumentals models list section (the top link)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For canceling room reverb check out:</span></p><p class="c1"><span class="c0">Reverb HQ</span></p><p class="c1"><span class="c0">then</span></p><p class="c1"><span class="c0">De-echo model (J2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Sometimes vox_ft can pick up SFX</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Install UVR5 GUI only in the default location picked by the installer. Otherwise, you might get python39.dll error on startup. If you see that error after installing the beta patch, reinstall the whole app.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Few of our users finally evaluated sonically new dango.ai 9.0 models. Turns out the models are not UVR&#39;s (or no longer), and actually give pretty close results to original instrumentals, but not so good vocals. </span></p><p class="c1"><span class="c0">&quot;It&#39;s slightly better but still voc_ft keeps more reverb/delays</span></p><p class="c1"><span class="c0">but again, it&#39;s 99% close, Dango has maybe more noise reduction&quot; maybe even less instrumental residues (can be a result of noise reduction).</span></p><p class="c1"><span class="c0">&quot;A bit cleaner than voc_ft in terms of having synths/instruments, but they do sound a bit filtered at times. [In] overall it&#39;s close tho&quot;</span></p><p class="c1"><span class="c0">&quot;I discovered Dango&#39;s conservative mode keeps instrumentals even fuller, but might introduce some background vocals</span></p><p class="c1"><span class="c0">still quite better than what we have.</span></p><p class="c1"><span class="c0">I&#39;m still surprised how it&#39;s so clean, as if not having vocal residues like any other MDX model. Sometimes the Dango sounds like a blend of VR&#39;s architecture, but I&#39;m probably wrong, it could be the recovery technology&quot; - becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tuanziai.com/vocal-remover/upload&amp;sa=D&amp;source=editors&amp;ust=1765035742549717&amp;usg=AOvVaw3kQ_hJ5p9TDd4QGOCT8qS4">https://tuanziai.com/vocal-remover/upload</a></span></p><p class="c1"><span class="c0">You must use the built-in site translate option in e.g. Google Chrome, because it&#39;s Chinese.</span></p><p class="c1"><span class="c0">On Android, it may not work correctly. In case of further issues, use Google Translate or one of Yandex apps with image to text translators.</span></p><p class="c1"><span class="c0">You are able to pay for it using Alipay outside China.</span></p><p class="c1"><span class="c0">Dango redirects to Tuanziai site - it&#39;s the same.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tuanziai.com/encouragement&amp;sa=D&amp;source=editors&amp;ust=1765035742550816&amp;usg=AOvVaw2cE0wazNFtyjhcE-vPUfr-">https://tuanziai.com/encouragement</a></span></p><p class="c1"><span class="c0">Here you might get 30 free points (for 2 samples) and 60 paid points (for 1 full songs) &quot;easily&quot;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Dango.ai scores bad in SDR leaderboards due to recovery algorithms applied. Similar situation probably like in GSep.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New BVE model on X-Minus for premium users. One of, if not the best so far. It uses voc_ft as a preprocessor. </span></p><p class="c1"><span class="c0">&quot;BVE sounds good for now but being an (u)vr model the vocals are soft (it doesn&rsquo;t extract hard sounds like K, T, S etc. very well)&quot;</span></p><p class="c1"><span>&quot;Pretty good, if still [in] training. Seems to begin a phrase with a bit of confusion between lead and backing, but then kicks in with better separation later in the phrase. Might just be the sample I used, though.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Jarredou published the final </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742552507&amp;usg=AOvVaw3VMOnqfx4nAUkj8QlrIp9L">2.2 version</a></span><span class="c0">&nbsp;of MDX23 Colab (don&#39;t confuse it with MDX23C single models v3 arch) - gives more vocal residues than 2.0/2.1, but better SDR. Now it has SRS trick, bigshifts, new fine-tuning, separated overlap parameters for MDX, MDXv3 and Demucs models, and also possess one narrowband MDX23C model D1581 among other MDX ones, which states a new set of models now (also said to use VOC-FT Fullband SRS instead of UVR-MDX-Instr-HQ3, although HQ3 is still listed during processing). You can also use faster optional 2 stem only output (demucs_ft vocal stem is used here only). Float parameter returns WAV 32-bit. Don&rsquo;t set overlap v3 to more than 10, or you&rsquo;ll get error. It can be way more frequent with odd values. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Changing weights added: &ldquo;For residues, I would first try a different weight balance, with less MDXv3 and more VOC-FT, as model D1581, and current MDXv3 models in general tend to have more residues than VOC-FT.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New &quot;8K FFT full band&quot; model published on MVSEP. Currently, a better score than only 2.2 Colab above from commonly available solutions, although more vocal residues than current default on MVSEP at least in some cases, and &ldquo;voice sounded more natural [in default] than the new 10 SDR model&rdquo; but in some problematic songs it can even give the best results so far.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Sometimes 8K FFT model is false detect the vocals, in the vocal stem synth was treated as vocal. On instrumental stem, mostly are blur result compared with 12K FFT. But 12K FFT seems to be some vocal residue but very less heard (like a whisper) and happened for several songs, not all songs.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- &quot;The karaoke ensemble works best with isolated vocals rather than the full track itself&quot; Kashi</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Center isolation method further explained in </span><span class="c6">Tips to enhance separation, step 19</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- VR Kara models freeze on files over ~6 minutes in UVR beta 2 (GTX 1080).</span></p><p class="c1"><span>&gt;Divide your song into two parts.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New public dataset published by Moises (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://developer.moises.ai/blog/moises-news/introducing-moisesdb-the-ultimate-multitrack-dataset-for-source-separation-beyond-4-stems&amp;sa=D&amp;source=editors&amp;ust=1765035742556473&amp;usg=AOvVaw1Mr_qzVHvlnn2BuSiWCK6Q">MoisesDB</a></span><span>). There are some problems with downloading it now, and it&rsquo;s 82,7GB and link expires during downloading after 600 seconds. Not enough for 30MB/s, but good for 10Gbps one. Moises team works on the issue. Probably it&#39;s fixed already.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- RipX inside the app uses UVR for gathering stems now. Consider also comparing its stem cleanup feature to RX 10 debleed in RX Editor.</span></p><p class="c1"><span>- &ldquo;RipX is badass for removing residues and harmonics from vocals. The ability to remove harmonics &amp; BGVs using RipX is amazing but is very tedious but so far so good&rdquo; (Kashi)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Sometimes using vocal model like voc_ft on the result from instrumental model might give less vocal residues or sometimes even none (Henry)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- mvsep1.ru from now on, contains a content of mvsep.com, so without MDX23/C and login features, while mvsep.com has the richer content of mvsep1.ru</span></p><p class="c1"><span class="c0">The old leaderboard link has changed and is now:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep1.ru/quality_checker/leaderboard2.php?sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035742558961&amp;usg=AOvVaw1TBQ6ipeJeV2Op6M_VzCrD">https://mvsep1.ru/quality_checker/leaderboard2.php?sort=instrum</a></span></p><p class="c1"><span class="c0">- old domain is also fixed now, redirecting leaderboard links.</span></p><p class="c1"><span class="c0">If you&rsquo;re uploading in quality checker is stopped, clear your browser and start over.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Dereverb and denoiser for VR arch is not compatible with any VR Colab and manual installation of such model will fail with errors. It requires modifying nets and layers. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708595418400817162/1116150594512625686&amp;sa=D&amp;source=editors&amp;ust=1765035742559821&amp;usg=AOvVaw3c-mF9NZhhCl5n1MoE8PR6">More</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New best ensemble (all Avg/Avg) </span></p><p class="c1"><span>(read entries details on the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035742560226&amp;usg=AOvVaw3hdENNRrd4o0Y_j1nVrS-K">chart</a></span><span>&nbsp;</span><span class="c0">for settings - they can have very time-consuming parameters and differ in that aspect)</span></p><p class="c1"><span class="c0">#1 MDX23C_D1581 + Voc FT | #2 MDX23C_D1581 + Inst HQ3 + Voc FT &nbsp;| #3</span></p><p class="c1"><span class="c0">MDX23C_D1581 + Inst HQ3 + Voc FT</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that above can sound noisy/have vocal leaks at times; consider using HQ_3 or kim inst then, also: </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The best ensembles so far in Kashi&#39;s testing for general use:</span></p><p class="c1"><span class="c0">Kim Vocal 2 + Kim FT other + Inst Main + 406 + 427 + htdemucs_ft avg/avg, or:</span></p><p class="c1"><span class="c0">Voc FT, inst HQ3, and Kim FT other (kim inst)</span></p><p class="c1"><span class="c0">&ldquo;This one&#39;s much faster than the first ensemble and sometimes produces better results&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It all depends on a song. Also, sometimes &quot;running one model after another in the right order can yield much better results than ensembling them&quot;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Disable &quot;stem combining&quot; for vocal inverted against the source. Might be less muddy, possibly better SDR.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>It&#39;s there in MDX23C because now the new arch supports multiple stems separation in one model file.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Disabling &quot;match freq cutoff&quot; in advanced MDX settings seems to fix issues with 10kHz cutoff in vocals of HQ3 model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New explanations on Demucs parameters added in Demucs 4 section</span></p><p class="c1"><span>(shifts 0, overlap 0.99 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/3848&amp;sa=D&amp;source=editors&amp;ust=1765035742563097&amp;usg=AOvVaw3SUcRxGZaNOpB5aSlwVryg">won</a></span><span>&nbsp;in SDR </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/3772&amp;sa=D&amp;source=editors&amp;ust=1765035742563265&amp;usg=AOvVaw0dPcb1SFhKr13Li8ECVUhS">vs</a></span><span>&nbsp;shifts 1, overlap 0.99 and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/435&amp;sa=D&amp;source=editors&amp;ust=1765035742563430&amp;usg=AOvVaw3svnfg88yFiR6rhYq76npL">even</a></span><span>&nbsp;shifts 10, overlap 0.95)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;Last update of Neutone VST plugin has now a Demucs model to use in realtime in a DAW</span></p><p class="c1"><span class="c0">(it&#39;s a &#39;light&#39; version of Demucs_mmi)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://neutone.space/models/1a36cd599cd0c44ec7ccb63e77fe8efc/&amp;sa=D&amp;source=editors&amp;ust=1765035742564193&amp;usg=AOvVaw0fk8k_vuHpcCTm_pJgw-bS">https://neutone.space/models/1a36cd599cd0c44ec7ccb63e77fe8efc/</a></span></p><p class="c1"><span>It doesn&#39;t use GPU, and it&#39;s configured to be fast with very low parameters, also the model is not the best on its own. It doesn&#39;t give decent results, so it&#39;s better to stick to other realtime alternatives (see document outline)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Turns out that with a GPU with lots of VRAM e.g. 24GB, you can run two instances of UVR, so the processing will be faster. You only need to use 4096 segmentation instead of 8192.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">SDR difference between overlap 0.95 and 0.99 for voc_ft MDX model in (new/beta) UVR is 0.02.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0.8 seems to be the best point for ensembles</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">12K segmentation performed worse than 4K SDR-wise</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Recommended balanced values between quality and time for 6GB graphic cards in the latest beta:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VR Architecture:</span></p><p class="c1"><span class="c0">Window Size: 320</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX-Net: </span></p><p class="c1"><span class="c0">Segment Size: 2752 (1024 if it&rsquo;s taking too long)</span></p><p class="c1"><span class="c0">Overlap: 0.7-/0.8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Demucs: </span></p><p class="c1"><span class="c0">Segment: Default</span></p><p class="c1"><span class="c0">Shifts: 2 (def)</span></p><p class="c1"><span class="c0">Overlap: 0.5 </span></p><p class="c1"><span class="c0">(exp. 0.75, </span></p><p class="c1"><span class="c0">def. 0.25)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Overlap can reduce/remove artifacts at audio chunks/segments boundaries, and improve a little bit the results the same way the shift trick works (merging multiple passes with slightly different results, each with good and bad).</span></p><p class="c1"><span class="c0">But it can&#39;t fix the model flaws or change its characteristics&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Best SDR is a hair more SDR and a shitload of more time.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In case of Voc_FT it&#39;s more nuanced... there it seems to make a substantial difference SDR-wise.</span></p><p class="c1"><span class="c0">The question is: how long do u wanna wait vs. quality (SDR-based quality, tho)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- A script with guide for </span><span class="c4"><a class="c3" href="#h.ak53injalbkf">separating multiple speakers</a></span><span>&nbsp;in a recording added</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you&#39;re stuck at 5% of separation in UVR beta, try to divide your audio into smaller pieces (that&#39;s beta&#39;s regression)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- A new separation site appeared, giving seemingly better results than Audioshake:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://stemz.mwm.io/&amp;sa=D&amp;source=editors&amp;ust=1765035742568785&amp;usg=AOvVaw101MUHz-JZkqXub95jyViX">https://stemz.mwm.io/</a></span></p><p class="c1"><span>&ldquo;Guitar stem seems better than Demucs, piano maybe too. Drums sound like Spleeter. Vocal bleeds in most of the stems, or not vocals are picked up, so they end up in the synths. But that&#39;s just from one song test&rdquo; becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Drumsep </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1wws3Qm3I1HfMr-3gAyW6lYzUHXG_kuyz?usp%3Dsharing%23scrollTo%3DZHabZkRf4ZNK&amp;sa=D&amp;source=editors&amp;ust=1765035742569481&amp;usg=AOvVaw3X14Kfdtc8wj-KqFER3Ptd">Colab</a></span><span>&nbsp;</span><span>now has GPU acceleration and much better max quality optional settings</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- 1620 MDX23C model added on x-minus. Opposing the model on UVR, it&#39;s fullband and not released yet (16.2 SDR).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Even if the separations have more bleeding than VOC-FT (and it&#39;s an issue), the voice sound itself is much fuller, &quot;in your face&quot; compared to VOC-FT, that I now find it like blurry sounding compared to MDXv3 models.</span></p><p class="c1"><span>I think that&#39;s why the new MDXv3 models are scoring better despite having more bleeding (at the moment, like I said before, trainers/finetuners have to get familiar with new arch, and that will probably help with that new bleed issue).&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New MDX23C model added on MVSEP (better SDR - 16.17)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- UVR beta </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_7_11_23_20_51_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742571213&amp;usg=AOvVaw3Q5VilZXkiqEXktx-ZlvVu">patch 2</a></span><span class="c0">&nbsp;repairing no audio issue with GPU separation on the GTX 1600 series using MDX23C arch. Fixes some other bugs too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Narrowband MDX23C vocal model (MDX23C_D1581 a.k.a. model_2_stem_061321) trained by UVR team has been released. SDR is said to be better than voc_ft (but the latter was evaluated with older non-beta patch). Be aware that CPU processing returns errors for MDX23C models, at least on some configs (&ldquo;deserialize model on CUDA&rdquo; error). Fullband models will be released in a few weeks (and as it was usually before, on x-minus first for a few weeks later). </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/MDX23C_D1581.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742572362&amp;usg=AOvVaw3clSlFL2N5vRqY_iSpZOLR">Download</a></span><span>&nbsp;(install </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_7_11_23_20_51_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742572543&amp;usg=AOvVaw3S1FpH_wV0CnNZB8NvEmKb">beta patch</a></span><span class="c0">&nbsp;first and drop it into the MDX-Net models folder). The patch is for only Windows now, with an upcoming Mac patch planned later. For Linux, there&#39;s probably a source of the patch already out.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX23C_D1581 parameters are set up with its yaml config file and its n_fft value is 12288, not 7680. It has cutoff at 14.7khz (while VOC-FT cutoff is 17.5khz)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;(Probably all) models are stereo and can&#39;t handle mono audio. You have to create a fake stereo file with the same audio content on the L and R channel if the software doesn&#39;t make it by itself.&quot; Make sure that the other channel is not empty when isolation is executed - it can produce silent bleeding of vocals in the opposite channel (happens in e.g. MDX23 and GSEP, and errors with mono in MDX-Net)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &rdquo;For Unbound local&rdquo; error while you do anything in UVR since the new model installation, you might be forced to rollback the update </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Clear the Auto-Set Cache in the MDX-Net menu if you set wrong parameter and end up with error</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Pitch shift is the same as soprano mode except in the GUI beta you can choose how many semitones to pitch the conversion</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Dango.ai released a 9.0 model. We received a very positive report on it so far. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- UVR beta patch released. Potentially new SDR increases with the same models.</span></p><p class="c1"><span class="c0">Added segmentation, overlap for MDX models, batch mode changes.</span></p><p class="c1"><span class="c0">Soprano trick added. Basically, you can set it by semi-tones. </span></p><p class="c1"><span class="c0">Support for MDX-NET23 arch. For now, it uses only basic models attached by Kuielab (low SDR, so don&#39;t bother for now), but UVR team already trained their own model for that arch, which will be released later, and a few weeks after x-minus and MVSep. And it&#39;s performing well already. Wait&trade;. Don&#39;t exceed an overlap 0.93-0.95 for MDX models, it&#39;s getting tremendously long with not much of a difference, 0.8 might be a good choice as well. Also, segments can ditch the performance AF. 2560 might be still a high but balanced value. &nbsp;</span></p><p class="c1"><span class="c0">Sadly, it looks like max mag for single models is no longer available - you can use it only under Ensemble Mode for now.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What is Demucs Pre-process model?</span></p><p class="c1"><span class="c0">A: You can process the input with another model that could do a better job at removing vocals for it to separate into the other 3 stems</span></p><p class="c1"><span class="c20">Beta UVR patch</span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/uvr_update_patches/UVR_Patch_7_7_23_6_34_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035742578486&amp;usg=AOvVaw3CTC3dFMt3fK-JC6umq4r_">link</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;Post-Process [for VR] has been fixed, the very end bits of vocals don&#39;t bleed anymore no matter which threshold value is used&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New BVE model will be ready at the beginning of August (Aufr33).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX23C by ZFTurbo model(s) added on mvsep.com. They&#39;re trained by him using the new 2023 MDX-Net V3 arch.</span></p><p class="c1"><span class="c0">Slightly worse SDR than MDX23 2.1 Colab on its own.</span></p><p class="c1"><span class="c0">Might be good for rock, the best when all three models are weighted/ensembled)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MDX23C ensemble/weighted available on mvsep.com </span><span class="c0">for premium users (best SDR for public 2 stem model).</span></p><p class="c1"><span class="c0">It might still leave some instrumental residues in vocals of some tracks (which can be cleared with MDX-UVR HQ_3 model) but it can be also vice versa - &nbsp;the same issue as kim vocal models, where the vocals are slightly left in the instrumentals [vs e.g. MDX23 2.1 free of the issue]</span></p><p class="c1"><span class="c0">On some Modern Talking and CC tracks it can give the best results so far).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you have problems with &ldquo;Error when uploading file&rdquo; on MVSEP, use VPN. Similar issues can happen for free X-Minus for users in Turkey.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- lalal.ai cooperation with MVSEP was fake news. Go along.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- As for Drumsep, besides in fixed </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1wws3Qm3I1HfMr-3gAyW6lYzUHXG_kuyz?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742582453&amp;usg=AOvVaw3yBxqphOI-vxfp0lRaFKSW">Colab</a></span><span class="c0">, you can also use it (the separation of single percussion instruments from drums stem) in UVR GUI. How to do this:</span></p><p class="c1"><span class="c0">Go to UVR settings and open the application directory.</span></p><p class="c1"><span class="c0">Find the folder &quot;models&quot; and go to &quot;demucs models&quot; then &quot;v3_v4&quot;</span></p><p class="c1"><span>Copy and paste both the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1S79T3XlPFosbhXgVO8h3GeBJSu43Sk-O/view&amp;sa=D&amp;source=editors&amp;ust=1765035742583514&amp;usg=AOvVaw0qR09p4zdSMG9cqrpscfwv">.th</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1124699600717094932/drumsep.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742583752&amp;usg=AOvVaw31SHna1Y5MY_8XXjVZVEGT">.yaml</a></span><span class="c0">&nbsp;files, and it&#39;s good to go.</span></p><p class="c1"><span class="c0">Overlap above 0.6 or 0.7 becomes placebo, at least for dry track, with no effects. </span></p><p class="c1"><span class="c0">- Drumsep benefits from shifts a lot (you can use even 20). </span></p><p class="c1"><span class="c0">- For better results, test out potentially also -6 semitones in UVR beta, or with 31183Hz sample rate with changed tempo.</span></p><p class="c1"><span class="c0">12 semitones from 44100Hz is 22050 and should be rather less usable in most cases, the same for tempo preservation on.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you have a long band_net </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1124780489522282686/Captura_de_pantalla_2023-07-01_121518.png&amp;sa=D&amp;source=editors&amp;ust=1765035742585445&amp;usg=AOvVaw1ds6V1Zma2-zGIAWFn7a80">error</a></span><span>&nbsp;</span><span class="c0">log while using DeNoise model by Fox Joy in UVR, reinstall the app.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- It can happen that every second separation using MDX Colab will fail due to memory issues, at least with Karaoke 2 model. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New fine-tuned vocal model added to UVR5 GUI download center and HV Colab (slightly better SDR than Kim Vocal 2) it&#39;s called &quot;UVR-MDX-Net-Voc_FT&quot; and is narrowband (because it&#39;s based on previous models).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Audioshake 3 stem model is added to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://myxt.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742587140&amp;usg=AOvVaw3eeLs3MaL_QVJ6VEVG6air">https://myxt.com/</a></span><span class="c0">&nbsp;for free demo accounts. Unfortunately, it has WAVs with 16kHz cutoff which Audioshake normally doesn&#39;t have. No other stem. Results, maybe slightly better than Demucs.</span></p><p class="c1"><span class="c0">Might be good for vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Spectralayers 10 received an update of an AI, and they no longer use Spleeter, but Demucs 4, and they now also good kick, snare, cymbals separation too. Good opinions so far. Compared to drumsep sometimes it&#39;s better, sometimes it&#39;s not. Versus MDX23 Colab V2, instrumentals sometimes sound much worse. &ldquo;SpectraLayers is great for taking Stems from UVR and then carrying on separating further and editing down. (...) Receives a GPU processing patch soon&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (? some) MDX Colabs started causing errors of insufficient driver version.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt; &quot;As a temp workaround you can go to &quot;Tools&quot; in the main menu, and &quot;Command Palette&quot;, and search for &quot;Use fallback runtime version&quot;, and click on it, this will restart the notebook with the previous Ubuntu version in Colab, and things should works as they were before (at least till mid July or earlier [how it was once] where it is currently scheduled to be deleted)&quot; probably it will be fixed.</span></p><p class="c1"><span class="c0">X: Some people have an error that fallback runtime is unavailable.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New v2 version of </span><span class="c22">ZFTurbo&#39;s MDX23</span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/MVSEP-MDX23-Colab_v2/&amp;sa=D&amp;source=editors&amp;ust=1765035742590977&amp;usg=AOvVaw1RKeRpNDs1x80FuW-0mY8v">Colab</a></span><span class="c0">&nbsp;released by jarreadou (now also with denoiser off memory fix added). Now it should have less bleeding in general.</span></p><p class="c1"><span class="c0">It includes models changed for better ones (Kim Vocal 2 and HQ_3), volume compensation, fullband of vocals, higher frequency bleeding fix. It all manifests in increased SDR.</span></p><p class="c1"><span class="c22">Instrum</span><span class="c0">&nbsp;is inverted of vocals stem</span></p><p class="c1"><span class="c22">Instrum2</span><span class="c0">&nbsp;is the sum of drums+bass+other stems (I used to prefer it, but most people rarely see any difference between both, and it also depends on specific fragments, although instrum gets better SDR and is less muddy, so it&rsquo;s rather better to stick with instrum)</span></p><p class="c1"><span class="c0">If your separation ends up instantly with path written below, you wrongly wrote it in the cell.</span></p><p class="c1"><span class="c0">Simply remove the `file - name.flac` at the end and leave only path leading to a file.</span></p><p class="c1"><span class="c0">It&#39;s organized in a way that it catches all files within that path/folder.</span></p><p class="c1"><span class="c0">Suggestion: go to drive.google.com and create a folder `input`,</span></p><p class="c1"><span class="c0">and drop the tracks you want to process in there.</span></p><p class="c1"><span class="c0">When the process is done, delete them, and add others you want to process.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Overlap large and small are the main settings, higher values = slightly higher score, but way longer processing.</span></p><p class="c1"><span class="c0">Colab doesn&#39;t allow much higher value for chunk size, but you can try little higher ones and see when it crashes because of memory. Higher chunk size give better results.</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1123687734003904552/inference.py&amp;sa=D&amp;source=editors&amp;ust=1765035742595377&amp;usg=AOvVaw1D116-gxaMz19XiJUjy04w">Updated</a></span><span>&nbsp;inference with voc_ft model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/deton24/MVSEP-MDX23-Colab_v2.1/blob/main/MVSep_MDX23_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742595734&amp;usg=AOvVaw0kUoqahUDFHWEqRq2KjFsr">Colab</a></span><span class="c0">&nbsp;v2.1 has denoiser now on, but updated inference not and is essentially what 2.2 currently is).</span></p><p class="c1"><span class="c6">- Volume compensation fine-tuning - it is in line 359 (voc_ft), 388 (for ensembling the vocals stem), 394 (for HQ_3 instrumental stem inversion).</span></p><p class="c1"><span class="c0">- chunk_size = 500000 will fail with 5:30 track, decrease it to at least 300K in such case.</span></p><p class="c1"><span class="c0">Overlap 0.8 is a good balance between duration and quality.</span></p><p class="c1"><span class="c0">- In case of system error wav not found, simply retry separation.</span></p><p class="c1"><span>Nice </span><span class="c4"><a class="c3" href="#h.jmb1yj7x3kj7">instruction</a></span><span class="c0">&nbsp;how to use the Colab.</span></p><p class="c1"><span class="c0">The v. 2.1 Colab was firstly evaluated with lower parameters, hence it received slightly worse SDR. Then it was evaluated again and got better score than v2.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">WiP Colabs</span></p><p class="c1"><span>- 2.2 Beta </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/MVSEP-MDX23-Colab_v2/tree/2d82810d0b6ff5781a5b64cef13ca7387fc95b77&amp;sa=D&amp;source=editors&amp;ust=1765035742598351&amp;usg=AOvVaw1e3n4Lkar_HRWMX5xQClfl">1</a></span><span class="c0">&nbsp;(no voc_ft yet)</span></p><p class="c1"><span>- 2.2 Beta </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/MVSEP-MDX23-Colab_v2/tree/7171c4704992c3a878452f52df57c8455ec7cff9&amp;sa=D&amp;source=editors&amp;ust=1765035742598719&amp;usg=AOvVaw0188Y0yI7CT0LWPAo_bb_2">1.5</a></span></p><p class="c1"><span>- 2.2 Beta (1.5.1, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1QbNuY2acGnuJZD0Fczsul4kqJKRFBEgO/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742599067&amp;usg=AOvVaw2Ymn-PLYifV-1XE_QGRz-s">inference</a></span><span class="c0">&nbsp;with voc_ft, replace in the Colab above; no fine-tuning)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/597b5b7f653e4593a0a94938a3923077d66f8767/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742599571&amp;usg=AOvVaw3ddEOo4HoQPvxqqTrfPBKE">v2.2</a></span><span>&nbsp;beta 2/3 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1igkChOCO9L2zyrUp9roZ5TWff2aOhOQc/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742599838&amp;usg=AOvVaw2Yrc11-ul9Tl30qGIV8I_P">working inference</a></span><span class="c0">) (MDX bigshifts, overlap added, fine-tuning, no 4 stems &gt; experimental, no support for now, 22 minutes for vocals only, mdx: bsf 21, ov 0.15, 500k, 5:30 track)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/597b5b7f653e4593a0a94938a3923077d66f8767/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742600601&amp;usg=AOvVaw2CgutHVpcs6U-50xxSkjk-">v2.2</a></span><span>&nbsp;(w/ voc_ft </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1bpZKZynmdsYcriF-M8t8yLtVLm7zRz5U/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742600859&amp;usg=AOvVaw3_nqwCW6IK80k5wWd7us4j">inference</a></span><span class="c0">) pre beta 3 w/o MDX v3 yet - comment out both bigshifts in the cell - they won&rsquo;t work</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- current beta </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742601501&amp;usg=AOvVaw3usSTy0POgrKj9RDFWEM1a">link</a></span><span class="c0">&nbsp;(WiP, might be unstable at times; e.g. here for 19.07 bigshifts doesn&rsquo;t work, and you need to look for working inference in history or delete the two bigshifts references in the cell; doesn&rsquo;t seem that MDX v3 model is here yet)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In general - </span></p><p class="c1"><span class="c0">MDX23 is quite an improvement over htdemucs_ft (...).</span></p><p class="c1"><span class="c0">Drum stem makes htdemucs_ft sound like lossy in comparison, absolutely beautiful</span></p><p class="c1"><span class="c0">Bass is significantly more accurate, identifies and retains actual bass guitar frequencies with clarity and accuracy</span></p><p class="c1"><span class="c0">&quot;Other&quot;, equally impressive improvement over htdemucs_ft, much more clarity in guitars&quot;</span></p><p class="c1"><span>And problems with vocals they originally described are probably fixed in V2 Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;I just added 2 new denoise models that were made by FoxJoy. They are both very good at removing any residual noise left by MDX-Net models. You can find them both in the &quot;Download Center&quot;. - Anjok</span></p><p class="c1"><span class="c0">Be aware that they&#39;re narrowband (17.7kHz cutoff). Good results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">To download models from Download Center -</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In UVR5 GUI, click the tools icon &gt; click Download Center tab &gt; Click radio button of VR architecture &gt; click dropdown &gt; select the model &gt; hit Download button &gt; wait for it to download... Profit.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New MDX-UVR &ldquo;HQ_3&rdquo; model released in UVR5 GUI! The best SDR for a single instrumental model so far. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/767947630403387393/1117709857223606300/UVR-MDX-NET-Inst_HQ_3.onnx&amp;sa=D&amp;source=editors&amp;ust=1765035742606050&amp;usg=AOvVaw0usN4UO4pF3-shU3iBTH-o">Model file</a></span><span class="c0">&nbsp;(but visiting download center is enough). On X-Minus I think too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-HQ_3 model added to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kae0-0/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742606687&amp;usg=AOvVaw3eHFT6QF-NU1PnCFqE8Tfh">MDX Colab</a></span><span class="c0">&nbsp;(old)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>-HV just made a new version of her own </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742607211&amp;usg=AOvVaw2HBe8emHCk-xRxtUCjf1Am">updated MDX Colab</a></span><span class="c0">&nbsp;with all new models, including HQ_3. It lacks e.g. Demucs 2 for Instrumentals of vocal models, but in return it allows using YouTube and Deezer links for lossless tracks, with providing ARL, and allows specifying manually more than one file name to process at the same time. Also, for any new models in the future, there&#39;s optional input for model settings, to bypass parameters of parameters autoloader. IRC, the Colab stores its files in different path, so be aware about it when uploading tracks for separations on GDrive.</span></p><p class="c1"><span class="c0">- she has added volume compensation in new revision (they&rsquo;re applied automatically for each model)</span></p><p class="c1"><span>In previous </span><span class="c4"><a class="c3" href="#h.aa2xhwp434">MDX Colabs</a></span><span class="c0">&nbsp;there were also min, avg, max, and chunks, but they&#39;re gone in HV Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- HV also made a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1VnqwFkpjPLjMwUPmgjoZJQR1S8hd6CBJ&amp;sa=D&amp;source=editors&amp;ust=1765035742609555&amp;usg=AOvVaw1a4lbqlw6UroPpIsIidzXw">new</a></span><span class="c0">&nbsp;VR Colab which irc, now don&rsquo;t clutter all your GDrive, but only downloads models which you use (but without VR ensemble) and probably might work without GDrive mounting, but it lacks VR ensemble.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New MDX models added to both variants of MVSep (Kim inst, Vocal 1/2, Main [vocal model], HQ_2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- ZFTurbo&rsquo;s MDX23 code now requires less GPU memory. &ldquo;I was able to process file on 8 GB card. Now it&#39;s default mode.&rdquo;: 6GB VRAM is not enough. Lowering overlaps (e.g. 500000 instead of 1000000) or chunking track manually might be necessary in this case. Also now you can control everything from options: so you can set chunk_size 200000 and single ONNX. It can possibly work with 6GB VRAM that way.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Overlap large and small - controls overlap of song during processing. The larger value the slower processing but better quality (both)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you have fail to allocate memory error, use --large_gpu parameter</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes turning off use large GPU and reducing chunk size from 1000000 to 500000 helps</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Models/AIs of the 1st and 2nd place winners in MDX23 music challenge (ByteDance&rsquo;s and quickpepper947&rsquo;s) sadly won&rsquo;t be released to the public (at least won&rsquo;t be open-sourced). Maybe in June, ByteDance will be released as an app in worse quality.</span></p><p class="c1"><span class="c0">Judging by the few snippets we had:</span></p><p class="c1"><span class="c0">&quot;the vocal output, yes, better than what can be achieved right now by any other model, it seems.</span></p><p class="c1"><span class="c0">the instrumental output... meh. I can hear vocals in it, on a low volume level.&quot; but be aware that improved their model by the time by a lot.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MDX23 4 stem model and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/MVSEP-MDX23-music-separation-model&amp;sa=D&amp;source=editors&amp;ust=1765035742613130&amp;usg=AOvVaw0ao48_-jKY7ebjv39MzqJm">source code</a></span><span>&nbsp;with dedicated app by ZFTurbo (3rd place) was released publicly with the whole AI and instructions how to run it locally. No longer requires minimum 16GB VRAM Nvidia GPU. It even has a neat GUI (3rd place in leaderboard C, better SDR than demucs ft). You can still use the model online on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep1.ru/&amp;sa=D&amp;source=editors&amp;ust=1765035742613656&amp;usg=AOvVaw0zYdqfkNHiXtNlneYFsrH7">mvsep1.ru</a></span><span class="c0">&nbsp;(now mvsep.com).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The command: </span></p><p class="c1"><span class="c0">&quot;conda install -c intel icc_rt&quot; </span></p><p class="c1"><span class="c0">SOLVES the LLVM ERROR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For above, you can get less vocal residues by replacing the Kim Vocal 1 model there manually by newer Kim Vocal 2 and kim inst by and Kim Inst with UVR Inst HQ 292 (&ldquo;full 292 is a lot more aggressive than kim_inst&rdquo;).</span></p><p class="c1"><span class="c0">jarredou forked it with better models and settings already.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Short technical </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1107002345704927362&amp;sa=D&amp;source=editors&amp;ust=1765035742614702&amp;usg=AOvVaw3RnyCfnXxr0xUOyS099VUF">summary</a></span><span>&nbsp;of ZFTurbo about what is under the hood and small </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2305.07489.pdf&amp;sa=D&amp;source=editors&amp;ust=1765035742614883&amp;usg=AOvVaw0V51mChoO5O3LjJ5OeIh6k">paper</a></span><span class="c0">.</span></p><p class="c1"><span>From what I see in the code, it uses inverted vocals output for instrumentals from - Demucs ft, with - hdemucs_mmi, and - Kim vocal 1 and - Kim inst (ft other). More explanations in </span><span class="c4"><a class="c3" href="#h.jmb1yj7x3kj7">MDX23</a></span><span class="c0">&nbsp;dedicated section of this doc.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- jarreadou made a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSep-MDX23-Colab/blob/main/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742615536&amp;usg=AOvVaw1AghLh2uOkodX4ELra48WF">Colab</a></span><span class="c0">&nbsp;version of ZFTurbo MDX23:</span></p><p class="c1"><span class="c0">&quot;(It&#39;s working with `chunk_size = 500000` as default, no memory error at this value after few tests with Colab free)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Output files are saved on Colab drive, in the &quot;results&quot; folder inside MVSep installation folder, not in *your* GDrive.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">On 19.05 its SDR was tested, and had better score for instrumentals than UVR5 ensemble for that time being. Currently not, but there are new versions of the Colab planned.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- ByteDance-USS was released with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1lRjlsqeBhO9B3dvW4jSWanjFLd6tuEO9?usp%3Dshare_link&amp;sa=D&amp;source=editors&amp;ust=1765035742616736&amp;usg=AOvVaw05F6KyNJmqlljQVCgMyHO1">Colab</a></span><span class="c0">&nbsp;by jazzpear. It works better than zero-shot for SFX and &ldquo;user-friendly wise&rdquo; while zero-shot stil better for instruments.</span></p><p class="c1"><span>&quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.dropbox.com/sh/fel3hunq4eb83rs/AAA1WoK3d85W4S4N5HObxhQGa?dl%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035742617187&amp;usg=AOvVaw2TuiPJt0WNU6qW3KXYlehT">https://www.dropbox.com/sh/fel3hunq4eb83rs/AAA1WoK3d85W4S4N5HObxhQGa?dl=0</a></span></p><p class="c1"><span class="c0">Queries for ByteDance USS taken from the DNR dataset. Just DL and put these on your drive to use them in the Colab as queries.&quot;</span></p><p class="c1"><span class="c4"><a class="c3" href="#h.4svuy3bzvi1t">QA</a></span><span class="c0">&nbsp;section added.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- The </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CO3KRvcFc1EuRh7YJea6DtMM6Tj8NHoB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742617719&amp;usg=AOvVaw30C5sZFq1nkY-v1RGKyttq">modified</a></span><span>&nbsp;</span><span class="c0">MDX Colab - now with automatic models downloading (no more manual GDrive models installations) and Karaoke 2 model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&gt; Separate input for 3 models parameters added, so you don&rsquo;t need to change models.py every time you switch to some other model. Settings for all models listed in Colab. From now on, it uses reworked main.py and models.py (made by jarredou) downloaded automatically. Don&rsquo;t replace models.py from packages with models from </span><span class="c4"><a class="c3" href="#h.aa2xhwp434">here</a></span><span>&nbsp;now. Now denoiser optionally added!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX Colab with newer models is now reworked to use with current Python 3.10 runtime which all Colabs now use. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Since 28.04 lots of Colabs started having errors like &quot;onnxruntime module not found&quot;. Probably only MDX Colab (was) affected.</span></p><p class="c1"><span class="c0">(not needed anymore)</span></p><p class="c1"><span class="c0">&gt; &quot;As a temp workaround you can go to &quot;Tools&quot; in the main menu, and &quot;Command Palette&quot;, and search for &quot;Use fallback runtime version&quot;, and click on it, this will restart the notebook with the previous python version, and things should works as they were before&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/189nHyAUfHIfTAXbm15Aj1Onlog2qcCp0?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742619869&amp;usg=AOvVaw3-vTNGZpGHxOu8v81C8eUu">OG</a></span><span class="c0">&nbsp;MDX HV Colab is (also) broken due to torch related issues (reported to HV). To fix it, add new code row with:</span></p><p class="c1"><span class="c0">!pip install torch==1.13.1 </span></p><p class="c1"><span class="c0">below mounting and execute it after mounting </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&gt; or use fixed MDX </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CO3KRvcFc1EuRh7YJea6DtMM6Tj8NHoB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742620487&amp;usg=AOvVaw1bvdBcpbK2iLd_Xd5xpQnE">Colab</a></span><span>&nbsp;</span><span class="c0">with newer models and fix added (now with also old Karaoke models).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- While using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/blob/main/Vocal%2520Remover%25205_arch.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742620905&amp;usg=AOvVaw2bp9Kq_-MpT9ZssDPHSD8A">OG</a></span><span>&nbsp;HV VR Colab, people are currently encountering issues related to </span><span class="c22">librosa</span><span class="c0">. The issues are already reported to HV (the author of the Colab). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&gt; &nbsp;use this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742621395&amp;usg=AOvVaw2GPLFRSPwRD13iQd29-x_P">fixed</a></span><span class="c0">&nbsp;VR Colab for now (04.04.23). (the issue itself was fixed by uncommenting librosa line and setting 0.9.1 version &nbsp;- &nbsp;deleted &quot;#&quot; before the lines in Mount to Drive cell, now also fresh installation issues are fixed - probably the previous fix was based on too old HV Colab revision). VR Colab is not affected by May/April runtime issues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you have fast CPU, consider using it for ensemble if you have only 4GB VRAM, otherwise you can encounter more vocal residues in instrumentals. 11GB VRAM is good enough, maybe even 8GB.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New Kim&#39;s instrumental &quot;ft other&quot; model. Already added to UVR&#39;s download center with parameters.</span></p><p class="c1"><span>Manual settings - dim_f = 3072 n_fft = 7680 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/19-jUNQJwols7UyuWO5PWWVUlJQEwpn78&amp;sa=D&amp;source=editors&amp;ust=1765035742622975&amp;usg=AOvVaw1p9PXA0Wdr9xcdcGyqM4kY">https://drive.google.com/drive/folders/19-jUNQJwols7UyuWO5PWWVUlJQEwpn78</a></span></p><p class="c1"><span>(Unlike HQ models, it has cutoff, but better SDR than even inst3/464, added to Colab)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Anjok (UVR5) &quot;I released an additional HQ model to the Download Center today. **UVR-MDX-NET Inst HQ 2** &nbsp;(epoch 498) is better at removing long drawn out vocals than UVR-MDX-NET Inst HQ 1.&quot; It has already evaluated slightly better SDR vs HQ_1 both for vocals and instrumentals (HQ_1 evaluation was made once more since introducing Batch Mode which slightly decreases SDR for only single models vs previous versions incl. beta, but mitigates an issue when there are sudden vocal pop-ins using &lt;11GB VRAM cards)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anjok (UVR5, non-beta) &ldquo;So I fixed MDX-Net to always use </span><span class="c22">Batch Mode,</span><span class="c0">&nbsp;even when chunks are on. This means setting the chunk and margin size will solely be for audio output quality. Regardless of PC specs, users will be able to set any chunk or margin size they wish. Resource usage for MDX-Net will solely depend on Batch Size.&rdquo;</span></p><p class="c1"><span class="c0">Edit. Batch size set to default instead of chunks enabled on 11GB cards for ensemble achieves better SDR, but separation time is longer.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Public UVR5 patch with batch mode and final </span><span class="c22">full band</span><span>&nbsp;model was released (</span><span class="c22">MDX HQ_1</span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- 293/403 and 450/498 (HQ_1 and 2) full band MDX-UVR models added to </span><span class="c4"><a class="c3" href="#h.zaimpsi6j19a">Colab</a></span><span>&nbsp;and (also in UVR) (PyTorch fix added for Colab)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c22">Wind</span><span class="c0">&nbsp;model (trumpet, sax) beside x-minus, added also to UVR5 GUI</span></p><p class="c1"><span>You&#39;ll find </span><span>it</span><span class="c0">&nbsp;in UVR5 in Download Center -&gt; VR Models -&gt; select model 17</span></p><p class="c1"><span class="c0">(10 seconds of audio separated with Wind model, from a 7-min track, takes 29 minutes to isolate on a 3rd gen i7 - might be your last resort if it crashes your 4GB VRAM GPU as some people reported)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus/Aufr33) &quot;1. **Batch mode** is now enabled. This greatly speeds up processing without degrading quality.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2. The **b.v.** models have been renamed to **kar**.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>3. A new **</span><span class="c22">Soprano voice</span><span class="c0">** setting has been added for songs with the high-pitched vocals. </span></p><p class="c1"><span class="c0">*This only works with mdx models so far.*&quot;</span></p><p class="c1"><span class="c0">It slows down the input file similarly to the method we described in our tip section below.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- New </span><span>MDX23 vocal model</span><span class="c0">&nbsp;added to beta MVSEP site.</span></p><h2 class="c27 c71" id="h.r1e43uhgi5h"><span class="c36 c20 c31">- (no longer necessary) </span><span class="c4 c36 c20 c31"><a class="c3" href="https://www.google.com/url?q=https://github.com/Aloereed/ultimatevocalremovergui-directml&amp;sa=D&amp;source=editors&amp;ust=1765035742627714&amp;usg=AOvVaw37mBex0GSn3RvU31lyLHvq">Fork of UVR GUI</a></span><span class="c36 c20 c31">&nbsp;and </span><span class="c4 c36 c20 c31"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/bw13MI-jMZ4&amp;sa=D&amp;source=editors&amp;ust=1765035742627839&amp;usg=AOvVaw2oLk7REeMB5agwixclZfVD">How to install</a></span><span class="c36 c20 c31">&nbsp;- </span><span class="c36 c20 c31">support for AMD and Intel GPUs appeared (works only for VR and MDX architectures), Besides W11, also W10 confirmed working, MDX achieves speeds of i5-4460s using 6700 XT, while for VR, speeds are v. fast and comparable to CUDA, so CPU processing might be slower in VR, but for MDX you might want to stick with the official UVR5 GUI. </span></h2><p class="c1"><span class="c20">- Batch mode seems to fix problems with vocal popping using low chunks values in MDX models, and also enhance separation quality while eliminating lots of out of memory issues. It decreases SDR very slightly for single models, and increases SDR in ensemble.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (outdated) New beta MDX model &ldquo;Inst_full_292&rdquo; without 14.7kHz cutoff released (performs better than Demucs 4 ft). If the model didn&rsquo;t appear on your list in UVR 5 GUI, make sure you&rsquo;ve redeemed your code </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035742629658&amp;usg=AOvVaw2ecVaiWHowAJT5YQC8R1f8">https://www.buymeacoffee.com/uvr5/vip-model-download-instructions</a></span></p><p class="c1"><span>Or use </span><span class="c4"><a class="c3" href="#h.aa2xhwp434">Colab</a></span><span class="c0">.</span></p><p class="c1"><span>Newer epochs available for </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://boosty.to/uvr&amp;sa=D&amp;source=editors&amp;ust=1765035742630014&amp;usg=AOvVaw1O2DuamNPAuBhqjtAyZDsw">paid</a></span><span>&nbsp;users of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/ai?hp%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035742630208&amp;usg=AOvVaw3577GhM-8m3ymKbe_IEZOI">https://x-minus.pro/ai?hp&amp;test-mdx</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- To use Colabs in mobile browsers, you probably no longer need to switch your browser to PC Mode first.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">News section continues in </span><span class="c4"><a class="c3" href="#h.yx8u0ahol7ao">older</a></span><span class="c0">&nbsp;news/update logs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.jx9um5zd7fnp"><span class="c0">General reading advice</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20 c31">- If you found this document elsewhere (e.g. as PDF), </span><span class="c4 c20 c31"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/17fjNvJzj8ZGSer7c7OFe_CNfUKbAxEh_OBv94ZdRG5%2520c/&amp;sa=D&amp;source=editors&amp;ust=1765035742631209&amp;usg=AOvVaw0dq3XI0TL58bZMQLo-25hR">here</a></span><span class="c20 c31">&nbsp;</span><span class="c23 c15 c20">is always up-to-date version of the doc</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c20 c31">- If you have anything to add to this doc, ping me @deton24 on our Discord </span><span class="c4 c20 c31"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/ZPtAU5R6rP&amp;sa=D&amp;source=editors&amp;ust=1765035742631631&amp;usg=AOvVaw3xVoch4uKAWZA_qLPZ_KAR">server</a></span><span class="c23 c15 c20">&nbsp;from the footer, but rather refrain from PMing directly if not necessary. Every time you request writing privileges via GDoc, God kills a cat.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c20 c31">- You can use (rather outdated) </span><span class="c4 c20 c31"><a class="c3" href="#h.sm5m61aib1vx">Table of content</a></span><span class="c20 c31">&nbsp;section, but better go to Options and show &ldquo;</span><span class="c12 c31">document outline</span><span class="c20 c31">&rdquo; to see up-to-date clickable table of content. If you don&#39;t have Google Docs installed, and you opened the doc in a mobile browser and no Table of content option appear, use </span><span class="c4 c20 c31"><a class="c3" href="#h.sm5m61aib1vx">Table of content</a></span><span class="c23 c15 c20">&nbsp;or go to options of the mobile browser and run the site in PC mode to show document outline (but it&#39;s better to have Google Docs installed on your phone instead as it&rsquo;s more convenient in use). Downloaded docx will have similar document outline (but more messy - with all headers used in the GDoc). If you have error on attempt of opening the docx file on Windows, go to RBM&gt;Properties and check Unlock below Attributes.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- Be aware that the document can hang for a while on the attempt of accessing a specific section of the document - it doesn&#39;t happen often on a PC browser - it&rsquo;s the most stable form of reading the doc online. At least on a decent PC (so not C2Q, but even a decade old i7). But it can be stable on Android phone too (e.g. Snapdragon 700 series instead of old 400 series). Google&rsquo;s app support for old 32-bit ROMs in e.g. Android 9 and older is terrible.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- Search and navigating through the document outline works faster when you download the doc as PDF or DOCX, but in the latter you&rsquo;ll have access to the document outline on the left like in GDoc (if not, press CTRL+F&gt;Headings, or check View&gt;Navigation window). </span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- When visiting online version of the doc, you can paste whole phrase when searching instead of single letters to avoid severe stuttering during using search function online.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- Use the search bar in Google Documents, not the one from the browser - the browser&rsquo;s search won&rsquo;t find everything unless all the pages were shown before - the doc is huge.<br> </span></p><p class="c1"><span class="c23 c15 c20">- Sometimes if you search for a specific keyword in the mobile app and the result doesn&#39;t show up, you need to go to the document outline, and open its last section and search again (so the whole document will be loaded first, otherwise you won&#39;t get all the search results in some cases). But it might happen mostly if you use the wrong search function.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c36 c20 c31">- Make sure you&#39;ve joined our </span><span class="c20 c31">Discord</span><span class="c36 c20 c31">&nbsp;</span><span class="c4 c36 c20 c31"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/ZPtAU5R6rP&amp;sa=D&amp;source=editors&amp;ust=1765035742635919&amp;usg=AOvVaw2xH-OdDMNO3zhhRVO86CQG">server</a></span><span class="c20 c31">&nbsp;</span><span class="c36 c20 c31">to open some of the Discord links attached below (those without any file extension </span><span class="c20 c31">at</span><span class="c36 c20 c31">&nbsp;the end)</span><span class="c20 c31">.</span><span class="c23 c15 c20">&nbsp;</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c20 c31">- Download links</span><span class="c36 c20 c31">&nbsp;from Discord with file extensions at the end</span><span class="c20 c31">&nbsp;</span><span class="c36 c20 c31">no longer work, but I re</span><span class="c20 c31">uploaded most of the important links already</span><span class="c36 c20 c31">.</span><span class="c15 c20 c23">&nbsp;If you need to download from previously shared Discord link anyway:<br>1) Join our Discord server via invitation at the top of the document 2) Delete file name from the link 3) Open our Discord server in the browser 4) Leave everything in the link before the first slash and delete the rest (so channels\xxxx\ 5) paste two identifiers divided by slashes afterwards, but without file name (so channels\xxxx\xxxx\xxxx - where the last two are taken from inactive file link) *) If you paste offline link in any channel on the source server, the link will work again</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c36 c20 c31">- If you have a crash on opening the doc e.g. on Android - reset the app cache and data. Keep </span><span class="c20 c31">the app updates or find some old version (e.g. even from period when your phone was released or uninstall all updates if it&#39;s GDoc is your stock app</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c20 c31">- </span><span class="c36 c20 c31">If it loads 4 minutes/infinitely in the doc app, update your Google Docs app and reset the app cache/data, e</span><span class="c20 c31">.g.</span><span class="c36 c20 c31">&nbsp;if you started to have crashes after the app update.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c36 c20 c31">- You can share a specific section of this document by opening it on PC or </span><span class="c20 c31">on a mobile</span><span class="c36 c20 c31">&nbsp;browser set in PC mode by clicking on one of the </span><span class="c20 c31">sections </span><span class="c36 c20 c31">in the document outline (or hyperlinks leading to specific sectio</span><span class="c20 c31">ns)</span><span class="c36 c20 c31">. Now it will add a reference to the section in the link in your address bar, which you can copy and paste, so opening this link will redirect someone </span><span class="c20 c31">straight </span><span class="c20 c31 c36">to the section after opening </span><span class="c20 c31">the </span><span class="c36 c20 c31">link (in some specific cases, some people won&rsquo;t be redirected, but in fa</span><span class="c20 c31">ct, you only need to wait a few seconds after the first page of the doc has been shown, and then the proper redirect starts</span><span class="c36 c20 c31">).</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c36 c20 c31">&nbsp;- </span><span class="c20 c31">In the GDoc app </span><span class="c36 c20 c31">sometimes you need to tap &ldquo;wait&rdquo; </span><span class="c20 c31">a few</span><span class="c36 c20 c31">&nbsp;times when the app freezes. Afterwards, searching will start working all the time (at least till the next time). The doc is huge </span><span class="c20 c31">and the GDoc</span><span class="c36 c20 c31">&nbsp;app on at least low-end Androids is cursed (desktop version on PC beh</span><span class="c20 c31">aves the most stable, as long as decent phones)</span><span class="c36 c20 c31">. You&#39;ve been warned.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- If you feel overwhelmed by the doc size, you can load the doc into Google Gemini or Google NotebookLM and ask questions from there, but I encourage befriending with the document outline and the content of an interesting section yourself - asking the AI chat for the best models leads to hallucinating and providing list of outdated models. Also, they all miserably fail with generating model and config links from even cut fragments of the GDoc. They also cannot edit the document directly (unless you paste the text, but it will rather delete all the formatting and hyperlinks which are essential to the task), maybe Office 365 with paid subscription is capable of editing docs with AI directly.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- Descriptions on the list of models are usually shortened compared to the news section information added when the model was released. You can use search with the model name for more possible descriptions.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- Published audio demos of models pasted from MVSEP get online after a while, so most links to audio files from there will be offline after a week or more.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- To be redirected after a moment to proper section from outside links with &ldquo;heading&rdquo; in the URL, you should open these links with GDoc app installed, or on PC browser, or mobile browser with PC Mode turned on (in Chrome that option appears when you open a page already).</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- Sometimes when you click on an entry in the document outline, it might not react the first time straight up after you load the document. Most likely it&#39;s still loading and you need to click it twice or more and then you&#39;ll be redirected.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- Even on a powerful phone with lots of RAM, GDoc app can occasionally crash, esp. while browsing it before it&rsquo;s fully loaded, and even deleting the app and reopening it won&rsquo;t help.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- If you click on any hotlink redirecting to a specific part of this document from the mobile version of GDoc in the browser, you won&#39;t be able to show options to display the document outline after switching your browser into PC mode - it will remain in the mobile layout. It&#39;s because redirections in mobile versions have their own linking scheme adding to the site address - you need to delete its ending or reopen the doc.</span></p><p class="c1 c7"><span class="c23 c15 c20"></span></p><p class="c1"><span class="c23 c15 c20">- Besides me and jarredou (Discord: rigo2) and dca100fb8 currently no one else has writing privileges to this document, although they&#39;re reluctant to be active editors, they were granted the privileges as the last resort for possible cases of my longer absence.</span></p><p class="c1"><span class="c20 c31"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; </span><span class="c36 c11">(I&rsquo;m trying to keep the following list always </span><span class="c11">updated</span><span class="c36 c11">&nbsp;with the Last updates</span><span class="c11">/news </span><span class="c42 c15 c36 c11 c30">section at the top)</span></p><h2 class="c27 c84" id="h.1787bzu93ob7"><span class="c36">___________</span><span class="c42 c15 c36 c46 c30">___________________________________________________</span></h2><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Everyone asks </span><span class="c22">which service and/or model is the best</span><span>&nbsp;for </span><span class="c12">instrumentals, vocals or stems</span><span>. The answer is - we have listed a few models and services which behave the best in most cases, but the truth is - the result also strictly depends on the genre, specific song, and how aggressive and heavily processed vocals it has. Also, how much distortion instruments have, style of mixing, etc. Sometimes one specific album gets the best results with one specific tool/AI/model, but there might be some exceptions for specific songs, so just feel free to experiment with each, to get the best result possible using various models, ensembles and services/AIs from those listed. SDR on MVSEP doesn&#39;t always reflect bleeding well. That&rsquo;s why we introduced bleedless and fullness metrics for evaluation of the models as well. You&rsquo;ll read more about it in </span><span class="c4"><a class="c3" href="#h.le80353knnv5">this</a></span><span>&nbsp;</span><span class="c0">section.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;Some people don&#39;t realize that if you want something to sound as clean as possible, you&#39;ll have to work for it. Making an instrumental/acapella sounding good takes time and effort. It&#39;s not something that can be rushed. Think of it like (...) love to a woman. You wouldn&#39;t want to just rush through it, would you? Running your song through different models/algorithms, then manually filtering, EQing, noise/bleed removing the rest is a start. You can&#39;t just run a song through one of these models and expect it to immediately sound like this&rdquo; rAN<br><br>Sometimes you might want to combine results of specific models in specific song fragments.<br>If the song is too muddy, you might want to use demudder in </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">newer</a></span><span>&nbsp;</span><span>UVR patches and/or use some free </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.i7mm2bj53u07&amp;sa=D&amp;source=editors&amp;ust=1765035742647883&amp;usg=AOvVaw2nLPe4XV3cMwFE8_rA-jNT">AIs</a></span><span>&nbsp;like AudioSR, Apollo or other, to further enhance the result.<br>If you&rsquo;re still not happy, you might want to manually mix separated song stems and/or master it using plugins or AI mastering services (more about it </span><span class="c4"><a class="c3" href="#h.k34y1vaaneb1">here</a></span><span class="c0">).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes you might be capable of creating a loop out of the fade ins/outs/intros/outros so you could totally refrain from using AI separation in the key fragments of the song, so you could just only use AI as reference to arrange the song as it was, and only fill missing fragments with separation.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>A good starting point is to have </span><span class="c4"><a class="c3" href="#h.nspwy0bkpiec">a lossless song</a></span><span>&nbsp;(the result will be a bit less muddy after separation)</span><span class="c0">. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Now,</span><span class="c33 c50">&nbsp;from free separation AIs/models, to get a decent instrumental/vocal</span><span>s,</span><span class="c33 c50">&nbsp;you can </span><span>use </span><span class="c33 c50">the solutions below</span><span>, starting from the models at top (every song might work differently with different models - find the best for your song - also, various headphones and speakers might be more or less sensitive to show you bleeding in song - lots of the time it will be imminent without phase fixer in songs with dense mix):</span><hr style="page-break-before:always;display:none;"></p><h3 class="c67 c27" id="h.rz0d5zk9ms4w"><span class="c22 c30 c32">The best models </span></h3><h3 class="c67 c27" id="h.8o01ot6sjxel"><span class="c32 c22 c30">for specific stems</span></h3><p class="c1 c7"><span class="c42 c15 c36 c45 c30"></span></p><p class="c1"><span class="c42 c15 c36 c20 c11">There&#39;s no such thing like the best model. It depends on a song, even in specific genre, mixing, effects, etc. <br>You need to test the best models posted at the top here, and see what fits the best for your song.</span></p><p class="c1 c7"><span class="c42 c15 c36 c20 c11"></span></p><p class="c1"><span class="c11">- Most models here are Mel-Roformer and BS-Roformer model type in the compatible </span><span class="c4 c11"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span class="c11">&nbsp;version - not v2 model type <br>(there&#39;s only one V2 model so far); don&rsquo;t confuse it with e.g. v2 versions/iterations of models below, which are just their names<br>- </span><span class="c20 c11">Reading about </span><span class="c4 c11 c20"><a class="c3" href="#h.sc2lgq9t4p19">SDR</a></span><span class="c20 c11">&nbsp;and </span><span class="c4 c11"><a class="c3" href="#h.le80353knnv5">fullness</a></span><span class="c20 c82">&nbsp;</span><span class="c20 c11">metric. </span><span class="c4 c20 c11"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035742651583&amp;usg=AOvVaw30fW47ykfuwxOczHyHzINy">Evaluations</a></span><span class="c20 c11">&nbsp;made on the multisong dataset on MVSEP. (table can be sorted by also fullness/bleedless and other metrics, once you open a result, fullness/bleedless metrics are shown too, excluding old results)</span></p><p class="c1 c7"><span class="c42 c15 c36 c30 c79"></span></p><p class="c1"><span class="c22">2 stems:</span></p><h6 class="c1 c27" id="h.2vdz5zlpb27h"><span>&gt; for instrumentals </span><span class="c20 c11">(click </span><span class="c4 c20 c11"><a class="c3" href="#h.n8ac32fhltgg">here</a></span><span class="c20 c11">&nbsp;f</span><span class="c42 c15 c36 c20 c11">or vocal models)</span></h6><p class="c1"><span class="c11">- Model names starting with MVSEP can be used only on </span><span class="c4 c11"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742652432&amp;usg=AOvVaw1PvVXTPmZXl5vOX3ZyQxZ3">MVSEP</a></span><span class="c11">&nbsp;</span><span class="c11">(no download links available)</span><span><br></span></p><p class="c1"><span class="c6">Good all-rounders from various categories (balanced, fullness, bleedless):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742652946&amp;usg=AOvVaw1USvAzSi3si_8BgMkG1tXb">BS-Roformer Resurrection inst</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742653082&amp;usg=AOvVaw1U74WmDqhrIwqwcCuW6El_">yaml</a></span><span>) | a.k.a. &ldquo;unwa high fullness inst&quot; on MVSEP | uvronline.app/x-minus.pro | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742653367&amp;usg=AOvVaw14ygWchJTEY43kczfqwXjs">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span class="c0">&nbsp;(don&rsquo;t confuse with Resurrection vocals variant)</span></p><p class="c1"><span class="c0">Inst. fullness: 34.93, bleedless: 40.14, SDR: 17.25</span></p><p class="c1"><span class="c0">MVSEP BS 2025.07 works as a reference for phase fix with 3000/5000 settings.</span></p><p class="c1"><span class="c0">Only 200MB. Some people might prefer it over V1e+, although it&rsquo;s more muddy.</span></p><p class="c1"><span class="c0">&ldquo;use if the others [below] are noisy&rdquo;</span></p><p class="c1"><span class="c0">Models working for phase fixer (to alleviate the noise) are only BS-Roformer 1296/1297 by viperx and BS Large V1 by unwa, but generally the model might require phase fixing less than other models here - dca</span></p><p class="c1"><span class="c0">&ldquo;One of my favorite fullness inst models ATM. Sounds like v1e to me, but cleaner. Especially with guitar/piano where v1e tended to add more phase distortion, I guess that&#39;s what you&#39;d call it lol. This model preserves their purity better IMO&rdquo; - Musicalman</span></p><p class="c1"><span class="c0">&ldquo;I like resurrection inst for segments of piano, a lot of other models are too noisy there (...) I also needed to turn overlap up for piano&rdquo; (from 2 to 8). FNO was less noisy for it, but &ldquo;the hit to fullness was extremely apparent&rdquo; - rainboomdash</span></p><p class="c1"><span class="c0">&ldquo;The way it sounds, is indeed the best fullness model, it&#39;s like between v1e and v1e+, so not so noisy and full enough, though it creates problems with instruments gone in the instrumental sadly, but apparently it seems Roformer inst models will always have problems with instruments it seems, seems like a rule. (...) Instrument preservation (...) is between v1e and v1e+&rdquo; - dca100fb8</span></p><p class="c1"><span class="c0">&ldquo;it seems to just nip some bits of random instruments like saxophone or guitar whereas v1e+ leaves them intact.&rdquo; - dennis777</span></p><p class="c1"><span class="c0">&ldquo;Some songs leaves vocal residue. It is heard little but felt&rdquo; - Fabio</span></p><p class="c1"><span class="c0">&ldquo;Almost loses some sounds that v1e+ picks up just fine&rdquo; - neoculture</span></p><p class="c1"><span class="c0">Mushes some synths a bit in e.g. trap/drill tune compared to inst Mel-Roformers like INSTV7/Becruily/FVX/inst3, but the residues/vocal shells are a bit quieter, although the clarity is also decreased a bit. Kind of a trade.</span></p><p class="c1"><span class="c0">BS 2025.07/BS 2024.04/BS 2024.08/SW removes less noise than viperx models for phase fixer.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-HyperACE/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742657073&amp;usg=AOvVaw3OVWITWjDv5O_UesT0LujB">BS-Roformer-HyperACE</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1lqHRm_h122qgpxLyx3xfHsrVei6ASx1t?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742657223&amp;usg=AOvVaw3KGZClBkxHSRc7-0WzhHC3">separate Colab</a></span><span>&nbsp;(doesn&rsquo;t work in UVR)</span></p><p class="c1"><span class="c0">Inst. fullness 36.91, bleedless 38.77, SDR 17.27</span></p><p class="c1"><span class="c0">&ldquo;sounding just like v1e+ after phase fix, but straight out of one single model </span></p><p class="c1"><span class="c0">(...) &nbsp;quite bleedy, but honestly it&#39;s a fair price to pay, I guess&rdquo; - santilli_</span></p><p class="c1"><span class="c0">Although for some people it can be even on pair with v1e+ bleed-wise, so check it out too (more fullness).</span></p><p class="c1"><span>Note: It uses its own inference script. &ldquo;You can use this model by replacing the </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST </a></span><span class="c0">repository&#39;s models/bs_roformer.py with the repository&#39;s bs_roformer.py.&rdquo;</span></p><p class="c1"><span>To not affect functionality of other BS-Roformer models by it, you can add it as new model_type by editing utils/settings.py and models/bs_roformer/init.py </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/dkGXo2r&amp;sa=D&amp;source=editors&amp;ust=1765035742658562&amp;usg=AOvVaw2BsxpeslesAHqPSVXJvZra">here</a></span><span class="c0">&nbsp;(thx anvuew).</span></p><p class="c1"><span class="c0">Metrically less fullness than v1e+: 37.89, but more bleedless: 36.53, SDR: 16.65 (v1e+).</span></p><p class="c1"><span class="c0">While using locally, consider changing overlap from default 4 to 2 in the yaml of the model. The difference won&rsquo;t be really noticeable for most people, but it will be faster.</span></p><p class="c1"><span class="c0">&ldquo;Currently, this model holds the highest aura_mrstft score on the instrumental side of the Multisong dataset. (...)</span></p><p class="c1"><span>This weight is based on the following </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/BS-RoFormer&amp;sa=D&amp;source=editors&amp;ust=1765035742659511&amp;usg=AOvVaw3Od0gy8Xbp-KzSronc26yi">weights</a></span><span class="c0">. Thank you, anvuew!&rdquo; - unwa</span></p><p class="c1"><span class="c0">&ldquo;Does seem like HyperACE is picking up more instruments than v1e+</span></p><p class="c1"><span class="c0">does seem like slightly worse vocal bleed overall (still need to test this more, though)... haven&#39;t encountered the super tinny vocal bleed like v1e+, at least</span></p><p class="c1"><span class="c0">still fails to pick up that brass instrument on one song... Not really any worse than v1e+, though (...) resurrection inst does sound more muddy, but also a lot less noise.. which makes sense... IDK, a little muddy for my tastes.</span></p><p class="c1"><span class="c0">I did find one song/spot and resurrection inst was on par with hyperace in picking up the wind instrument, v1e+ lost it for a bit.</span></p><p class="c1"><span class="c0">I have found in the past that resurrection inst generally picks up more instruments than v1e+ (...) fullness of HyperACE is much closer to v1e+ than resurrection inst (...) it gets pretty staticy compared to v1e+ [on some drums] (...) v1e+ does this to a lot less extent</span></p><p class="c1"><span class="c0">it&#39;s not super common, though&hellip; (...) I&#39;m very confident in saying bshyperace picks up more stuff than v1e+.</span></p><p class="c1"><span class="c0">resurrection inst does pick it up much better than v1e+, but I think it&#39;s still too quiet</span></p><p class="c1"><span class="c0">resurrection inst really does just pick up so much more instruments, despite having a lot less fullness&rdquo; - rainboomdash</span></p><p class="c1"><span class="c0">&rdquo;fullness that is comparable to v1e+, but has significant more vocal crossbleeding in instrumental than BS Roformer Resurrection Inst, but still less than v1e+ and v1e&rdquo; - dca100fb8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa Mel-Roformer V1e+ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/blob/main/inst_v1e_plus.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742662282&amp;usg=AOvVaw0Ialk67DnjfJHzrsMlFMVL">model</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/blob/main/config_melbandroformer_inst.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742662426&amp;usg=AOvVaw0k-1L53UB2XEy5kwQxUl_G">yaml</a></span><span>)</span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="#h.eopfi619c6zr">guide</a></span><span>)</span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742662616&amp;usg=AOvVaw1mr1q6wk8Gp_RId5FdUYwS">MVSEP</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/ai&amp;sa=D&amp;source=editors&amp;ust=1765035742662710&amp;usg=AOvVaw2eGS81J754IDifVpXLkxKC">x-minus</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai&amp;sa=D&amp;source=editors&amp;ust=1765035742662788&amp;usg=AOvVaw2wa3G0vfpDH-eCZgSD3cEs">uvronline</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742662971&amp;usg=AOvVaw0Dw_RInAR2WHxGhE_tHNke">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742663092&amp;usg=AOvVaw0OpL16a7JobkbkbBR3h4ji">SESA</a></span><span>&nbsp;Colab | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742663209&amp;usg=AOvVaw0bALVOYEhBYaL9saQ5iumN">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742663327&amp;usg=AOvVaw3WhkKFdsu-9XbQYi5c9rv9">2</a></span></p><p class="c1"><span class="c0">Inst. fullness: 37.89, bleedless: 36.53, SDR: 16.65</span></p><p class="c1"><span>*) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/lucassantillifuck2fa/Music-Source-Separation-Training/blob/main/Phase_Fixer.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742663642&amp;usg=AOvVaw2Ts296wna09kz2MKwe-KvO">Phase fixer</a></span><span>&nbsp;Colab (e.g. with FT3 as src)/</span><span class="c4"><a class="c3" href="#h.j14b9cv2s5d9">UVR</a></span><span class="c0">&gt;Tools, or on x-minus with becruily vocal model used as reference model (premium) - for less noise.</span></p><p class="c1"><span>*) introC </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://file.garden/Z3gSJFxsb21HAqp6/scripts/v1ep_resonance_remover.zip&amp;sa=D&amp;source=editors&amp;ust=1765035742664050&amp;usg=AOvVaw1dlW5TmF351I9KVIQjqh2c">script</a></span><span class="c0">&nbsp;to get rid of vocal leakage in this model</span></p><p class="c1"><span>*) &ldquo;If you use Gabox Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/denoisedebleed.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742664341&amp;usg=AOvVaw0AGlLwZvKPgjQqaKMDTImn">denoise/debleed</a></span><span>&nbsp;model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742664488&amp;usg=AOvVaw3wTNSISm1-D_QOSMqsRViL">yaml</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035742664603&amp;usg=AOvVaw25lVtxjN3wmJ-aeL9NC8Y2">Colab</a></span><span class="c0">) on mixture then put the &ldquo;denoised&rdquo; inst stem of that into unwa inst v1e+ you get a very clean result with good fullness and very little noise&rdquo; - 5b. But it can&rsquo;t remove vocal residues, just vocal noise.</span></p><p class="c1"><span class="c0">Might also sound interesting when using as target in Phase fixer, and with source set as Becruily inst model (overlap 50/chunk_size 112455 was used; very slow - gustownis).</span></p><p class="c1"><span class="c0">Or bigbeta5e as a source to get rid of vocal residues - santilli_</span></p><p class="c1"><span class="c6">(single model inference descriptions below)</span></p><p class="c1"><span class="c0">&ldquo;strange leakage [robot-like] in the vocal-only section with no instrumentation&rdquo; - Unwa</span></p><p class="c1"><span class="c0">&rdquo;less noise than v1e (probably due to different loss function), but it&rsquo;s also less full, &ldquo;somewhere between v1e and v1&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;sometimes a detail piece of instrumental sound was lost, while on becruily inst [below] can pick that sound&rdquo;. Might be too strong for MIDI sounds - kittykatkat_uwu.</span></p><p class="c1"><span class="c0">Problems with broken lead-ins not happening in instv7 and v1e. Some issues with cymbals bleed in vocals - dca.<br>Better than v1+. &rdquo;has fewer problems with quiet vocals in instrumentals than the V1+, &ldquo;issues with harmonica, saxophone, electric guitar and synth seem to have been fixed&rdquo; - dca100fb8.<br>&ldquo;has this faint pitched noise whenever vocals hit in dead silence, you may need to manually cut it out.&rdquo; - dynamic64. Check out also BS_ResurrectioN later below, it&rsquo;s like v1e++ (more fullness).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_Fv4.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742667040&amp;usg=AOvVaw0LHDXNePVk94VlJAj2nm2z">inst_fv4</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742667197&amp;usg=AOvVaw1wT0oksDDjkpl2d8x0yGgK">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742667384&amp;usg=AOvVaw0V0Ql9uB2t07yWbVsnSeNj">Colab</a></span></p><p class="c1"><span>Inst. fullness 39.40, bleedless 33.49, SDR 16.44</span></p><p class="c1"><span class="c0">Don&rsquo;t confuse it with inst_fv4noise - the regular variant was never released before (and with voc_fv4).</span></p><p class="c1"><span class="c0">&ldquo;Seems to be erasing a xylophone instrument. Does sound not too noisy and not muddy, I like it. (...) A little noisy with piano (I split the song up and process with resurrection inst there). (...) Does have some issues that resurrection inst doesn&#39;t have, but it doesn&#39;t sound muddy! It usually works great. (...) In my opinion, fv4 still has vocal traces, I don&#39;t know if in all of its songs and v1e plus doesn&#39;t have them, but the noise can bother you even though it&#39;s not much. Does have more vocal bleed at times. I think a lot of what I thought was vocal bleed was a synth, it did a pretty good job... There was one segment on a song where it caught vocal residues, though&rdquo; - rainboomdash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep SCNet vocals model: SCNet XL IHF (high instrum fullness by bercuily).</span></p><p class="c1"><span>Inst. </span><span>fullness</span><span class="c0">&nbsp;32.31, inst. bleedless 38.15, SDR 17.20</span></p><p class="c1"><span class="c0">&ldquo;One of my favorite instrumental models, Roformer-like quality.</span></p><p class="c1"><span class="c0">For busy songs it works great, for trap/acoustic etc. Roformer is better due to SCNet bleed&rdquo; - becruily</span></p><p class="c1"><span class="c0">&ldquo;bring[s] such near perfect instrumentals&rdquo;</span></p><p class="c1"><span class="c0">vs the previous XL models &ldquo;It&#39;s high fullness version for instrumental prepared by becruily.&rdquo;</span></p><p class="c1"><span class="c0">It can also be an insane vocal model too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Inst_GaboxFv8 v1 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/b06c7d6ee7c21a58d9096d6184727da8d1b98e0f/melbandroformers/instrumental/Inst_GaboxFv8.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742669896&amp;usg=AOvVaw3zqEXjdXy1VHmAjsK0yhn2">model</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742670032&amp;usg=AOvVaw3B9Q511QFllY2sJU9TtV2K">yaml</a></span><span>) <br></span><span>Inst. fullness: 35.57, bleedless: 38.06, SDR: 16.51<br>The OG link to the model changed to the v2 variant of the model, but the old link to the v1 was retrieved above.</span></p><p class="c1"><span class="c0">VS V1e+ &ldquo;A bit cleaner-sounding and has less filtering/watery artifacts. Both models are prone to very strange vocal leakage [&ldquo;especially in the chorus&rdquo;]. </span></p><p class="c1"><span class="c0">And because Fv8 can be so clean at times, the leakage can be fairly obvious. For now, my vote is for Fv8, but I&#39;ll still probably be switching back and forth a lot. Still has ringing&rdquo; - Musicalman. Although, you might still prefer it over V1e+.</span></p><p class="c1"><span class="c0">Might have some &ldquo;ugly vocal residues&rdquo; at times (Phil Collins - In The Air Tonight) - 00:46, 02:56 - dca. </span></p><p class="c1"><span class="c0">&ldquo;Sometimes V1e+ has vocal residues which sound like you were speaking through a fan/low quality mp3&rdquo; - dca</span></p><p class="c1"><span class="c0">&rdquo;Seems to pick up some instruments better&rdquo; Gabox.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Inst_FV8b.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742671790&amp;usg=AOvVaw0pGhfIJPGd3k6ijEgIsctQ">Inst_FV8b</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742671943&amp;usg=AOvVaw0T-Zu-y3tFiN7Pebh1WcvP">yaml</a></span><span>) | probably on uvronline via special link (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742672083&amp;usg=AOvVaw1fTR226o1e2QbxCMbddHjc">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742672162&amp;usg=AOvVaw3MuAO52boLSAzrRZgoPVtS">premium</a></span><span>),<br>Inst. fullness: 35.05, bleedless: 36.90, SDR 16.59<br>If so, it&rsquo;s called V8 there (at least it&rsquo;s not INSTV8), maybe not fv8 v1.</span></p><p class="c1"><span class="c0">Muddier than V1e+, but cleaner. Some people might prefer it over INSTV7.</span></p><p class="c1"><span class="c0">&ldquo;Preserves its volume stability to the original sound of the songs, it does not go down or lose strength, which is the most important thing, it manages to capture clear vocal chops, the voice is eliminated to 99 or 100% depending on its condition, it captures the entire instrumental and when making a mix it remains like the original that with other models the volume was lowered,&rdquo; - Billie O&rsquo;Connell</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Others</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">- Gabox </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/Inst_GaboxV7.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742673553&amp;usg=AOvVaw1EfuJy5bWf-bOWlNpWSpME">INSTV7</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742673698&amp;usg=AOvVaw1nXxCihsCRb6iILZ78yrLK">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742673771&amp;usg=AOvVaw0xH_e7N3pg_wmN8hgMvvgl">MVSEP </a></span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742673961&amp;usg=AOvVaw1wqD6w0CvuVdVmBwxe2q2X">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742674064&amp;usg=AOvVaw2qlpLHwEKWBCNVcCDtgaIk">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742674145&amp;usg=AOvVaw0LjUKAyemhosK8x1k1Gb8O">2</a></span><span>&nbsp;| </span><span>uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742674288&amp;usg=AOvVaw0TOc0RLn9XHkc7dfES_8mj">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742674371&amp;usg=AOvVaw1xGRI3TZiWV8DXZPXAix7x">premium</a></span><span>&nbsp;| </span><span class="c0">&ldquo;F&rdquo;, for fullness, &ldquo;V&rdquo; for version.</span></p><p class="c1"><span>Inst. fullness: 33.22, bleedless: 40.71, SDR: 16.51<br>*) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/lucassantillifuck2fa/Music-Source-Separation-Training/blob/main/Phase_Fixer.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742674736&amp;usg=AOvVaw1Ifj44RDZ2jJlmw-00NaZs">Phase fixer</a></span><span class="c0">&nbsp;Colab/UVR&rsquo;s Phase Swapper (for less noise; e.g. with FT3 by Unwa vocal model as source).</span></p><p class="c1"><span class="c0">&ldquo;I hear less noise compared to v1e, but it has a worse bleedless metric&rdquo; and might be less full.</span></p><p class="c1"><span class="c0">It might still have too much noise like v1e for some people, but less.<br>&ldquo;Relatively full/noisy model. Fvx [below] is a sort of middle ground between v3 and v7.&rdquo;<br>More fullness than V6, but vs v1e, sometimes &ldquo;leaves noises throughout the song, sometimes vocal remnants in the verse of the song, and some instruments are erased.&rdquo;<br>Less muddy than Mel 2024.10 on MVSEP, and V7 doesn&rsquo;t preserve vocal chops/SFX.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv8.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742675917&amp;usg=AOvVaw1PgogbEGqGwSsDC4P3FUMi">Inst_GaboxFv8</a></span><span>&nbsp;v2 model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742676090&amp;usg=AOvVaw1JqYFvPn8Ytqvok09vh0Lk">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742676284&amp;usg=AOvVaw2swSaNWywBGNJT9LAOS0Bc">Colab</a></span><span>&nbsp;</span></p><p class="c1"><span class="c0">Inst. fullness: 33.21, bleedless: 40.73, SDR: 16.57</span></p><p class="c1"><span class="c0">Usually refrerred as just Inst_GaboxFv8 without v2. Since its release, the checkpoint has been updated on 11.05.25 (same file name), metrics have changed (updated above).</span></p><p class="c1"><span class="c0">&ldquo;v8 from uvronline and Fv8 from huggingface are completely different models&rdquo; - maybe it&rsquo;s the v1 model. Also, don&rsquo;t confuse with INSTV8.<br>&ldquo;Good result for bleedless instead, fullness went down instead of up a little.&rdquo;<br>Might be an interesting competitor to Unwa inst v2 which is muddier. </span></p><p class="c1"><span class="c0">Inst. fullness: 35.57, bleedless: 38.06, SDR: 16.51 are the metrics of the old v1 model (unavailable). Unsure if uvronline uses the old fv8.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Becruily&rsquo;s inst | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-instrumental/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742677641&amp;usg=AOvVaw0oXMa0XA04R6lfkUI-wu0C">Model files</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742677838&amp;usg=AOvVaw056u-JmxCYRa7_9AGMRAMr">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742677948&amp;usg=AOvVaw2NTmRxVXtuhcSjSQ2nJQOq">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742678038&amp;usg=AOvVaw1bkr9uAXRpc6hgOk_4JsKy">2</a></span><span>&nbsp;| on MVSEP a.k.a. Mel-Roformer &ldquo;high fullness&rdquo; | uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742678245&amp;usg=AOvVaw2DY8POopciB9oJhaebhthu">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742678325&amp;usg=AOvVaw1WRaLZ8M641kiNUAqaR-bT">premium</a></span><span class="c0">&nbsp;(scroll down)</span></p><p class="c1"><span>Inst. </span><span class="c4"><a class="c3" href="#h.le80353knnv5">fullness</a></span><span>&nbsp;33.98, inst. bleedless 40.48, SDR 16.47<br>or on</span><span>&nbsp;x-minus/uvronline (with optional phase correction feature in premium) | </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span><br>*) For less vocal residues use phase fixer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1uDXiZAHYk7dQajOLtaq8QmYXL1VtybM2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742678865&amp;usg=AOvVaw1_BxVNKPxtBWVsGYWWj42R">Colab</a></span><span class="c0">&nbsp;(also in UVR&gt;Tools) and &ldquo;becruily&#39;s vocals as source and inst as target&rdquo;.</span></p><p class="c1"><span>Alone, it&rsquo;s as clean as unwa&rsquo;s v1, but has less noise, and it can also be got rid well by:<br>*) Mel </span><span class="c4"><a class="c3" href="#h.hyzts95m298o">denoise</a></span><span>&nbsp;and/or Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1zWOrzPKd-6x7vjHNqjK_bK2UOYfPzCuu/view&amp;sa=D&amp;source=editors&amp;ust=1765035742679348&amp;usg=AOvVaw0lhW5r9ZUYyQ0hYYK543He">bleed suppressor</a></span><span class="c0">&nbsp;by unwa/97chris. That model &ldquo;removed some of the faint vocals that even the bleed suppressor didn&#39;t manage to filter out&rdquo; before&rdquo;. Doesn&rsquo;t require phase fix. Try out denoising on a mixture first, then use the model.</span></p><p class="c1"><span class="c0">On its own, the inst model correctly removes SFX voices. The instrumental model pulled out more adlibs than the released vocal model variant, when it can pull out nothing.<br>Currently, the only model capable of keeping vocal chops. <br>&ldquo;Struggles a lot with low passed vocals&rdquo;</span></p><p class="c1"><span class="c0">More instruments correctly recognized as instruments and not vocals, although not as much as Mel 2024.10 &amp; BS 2024.08 on MVSEP, but still more than unwa&rsquo;s inst v1e/v1/v2.</span></p><p class="c1"><span>- If you use lower </span><span class="c4"><a class="c3" href="#h.c4nrb8x886ob">dim_t</a></span><span>&nbsp;like 256 (or maybe also corresponding </span><span class="c4"><a class="c3" href="#h.c4nrb8x886ob">chunk_size</a></span><span class="c0">) on weaker GPUs, these are the first Mel inst models to have muddy results with it.</span></p><p class="c1"><span>- In the phase fixer you can experiment with &ldquo;using becruily&#39;s vocals as source and inst as target, and changing high frequency weight from 0.8 to 2 makes for impressive results&rdquo; you can do it automatically after separation in this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/lucassantillifuck2fa/Music-Source-Separation-Training/blob/main/Phase_Fixer.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742681421&amp;usg=AOvVaw1B4wqYzwm-XH2BPIqRKeHP">Colab</a></span><span class="c0">&nbsp;(santilli_ suggestion).<br>Using Kim Mel FT2 as source instead might be more problematic as it tends to be more harmful to instruments, and in noise removal both are similar (dca).</span></p><p class="c1"><span>- To demud the results from phase fixer, you can use Matchering and a well sounding fragment of single instrumental model separation with high fullness metric (e.g. 7N) as a reference and becruily inst/voc phase fixed result set as target (e.g. in UVR&gt;Tools&gt;Matchering). It will have less bleeding than models with low bleedless metric, but still fuller than phase-fixed results (more </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1345895513324785788&amp;sa=D&amp;source=editors&amp;ust=1765035742682408&amp;usg=AOvVaw0LTqkMVuQ0xiw9HaK0AwC1">here</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1347158763542679573&amp;sa=D&amp;source=editors&amp;ust=1765035742682552&amp;usg=AOvVaw11jNokHK9VrllwJ9m34CGt">here</a></span><span>). Phase fixer can also be used in a standalone Python </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JOa198ALJ0SnEreCq2y2kVj-sktvPePy?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035742682757&amp;usg=AOvVaw2Z6Hd24UzUAe_3VUaywk23">script</a></span><span>&nbsp;or in the </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">latest UVR</a></span><span>. Matchering can be used in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kubinka0505/matchering-cli/blob/master/Documents/Matchering-CLI.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742683074&amp;usg=AOvVaw33dCaWN1FewjuvBB3ybYWW">Colab</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.songmastr.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742683171&amp;usg=AOvVaw3rIFUB-OiAQc8P87ZXXuJ4">songmastr</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/kubinka0505/matchering-cli&amp;sa=D&amp;source=editors&amp;ust=1765035742683266&amp;usg=AOvVaw2IUbwY8AevvhCb3N6OOsg7">locally</a></span><span class="c0">&nbsp;(it&rsquo;s very lightweight and doesn&rsquo;t require a GPU).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Recent bleedless models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">- Unwa </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Inst-FNO&amp;sa=D&amp;source=editors&amp;ust=1765035742683719&amp;usg=AOvVaw1Ex_32SvlvjS60jwyUQrZB">BS-Roformer-Inst-FNO</a></span><span class="c6">&nbsp;</span></p><p class="c1"><span class="c0">Inst. fullness: 32.03, bleedless: 42.87, SDR: 17.60</span></p><p class="c1"><span>Incompatible with UVR, install </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span>, then read model instructions </span><span class="c4"><a class="c3" href="#h.hjuoj68tot6v">here</a></span><span class="c0">&nbsp;(requires modifying bs_roformer.py file in MSST, potentially also models_utils.py in some cases).</span></p><p class="c1"><span class="c0">Actually similar results to BS-Resurrection inst model above, less fullness.</span></p><p class="c1"><span class="c0">Some people even prefer Gabox BS_ResurrectioN instead.</span></p><p class="c1"><span class="c0">&ldquo;Very small amount of noise compared to other fullness inst models, while keeping enough fullness IMO. I don&#39;t even know if phase fix is needed. Maybe it&#39;s still needed a little bit.&rdquo; dca</span></p><p class="c1"><span class="c0">&ldquo;seems less full than the Resurrection, which I would expect given the MVSEP [metric] results. (...) I&#39;d say it&#39;s roughly comparable to Gabox inst v7&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;I replaced the MLP of the BS-Roformer mask estimator with FNO1d [Fourier Neural Operator], froze everything except the mask estimator, and trained it, which yielded good results. (...) While MLP is a universal function approximator, FNO learns mappings (operators) on function spaces.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;(The base weight is Resurrection Inst)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">- Gabox</span><span class="c20"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv7z.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742685809&amp;usg=AOvVaw3DzVhZcxkRimjf_3peGiS5">&nbsp;</a></span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv7z.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742685960&amp;usg=AOvVaw0D6XTUo1DMY8oPCpsx_AcN">Inst_GaboxFv7z</a></span><span>&nbsp;Mel Roformer (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742686118&amp;usg=AOvVaw2aKFhy5nkYIlF0tAChPqaf">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742686300&amp;usg=AOvVaw2EbRSCJUxiNnQxVCo-gvAm">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai&amp;sa=D&amp;source=editors&amp;ust=1765035742686394&amp;usg=AOvVaw2rLn_ApvLoE2_UHEreSerb">uvronline.app</a></span><span class="c0">/x-minus.pro</span></p><p class="c1"><span>Inst. fullness: 29.96, </span><span>bleedless</span><span class="c0">: 44.61, SDR: 16.62</span></p><p class="c1"><span class="c0">Becruily vocal used for phase fixer on x-minus.pro/uvronline (premium feature).</span></p><p class="c1"><span class="c0">&ldquo;Focusing on the less amount of noise, keeping fullness&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;the results were similar to INSTV7 but with less noise&rdquo; but &ldquo;the drums are totally fine with this model &rdquo;- neoculture</span></p><p class="c1"><span class="c0">&ldquo;it seems to capture some vocals better&rdquo; - Gabox</span></p><p class="c1"><span class="c0">In some songs, &ldquo;it leaves a lot of reverb or noise from the vocals. unva v1e+ &nbsp;a little better&rdquo; - GameAgainPL</span></p><p class="c1"><span class="c0">&ldquo;[one of the] best bleedless, good fullness, almost noiseless&rdquo; - Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/inst_fv7b.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742687726&amp;usg=AOvVaw0zf43FTIG7xehay0KN3_vJ">inst_fv7b</a></span><span>&nbsp;Mel Roformer | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742687883&amp;usg=AOvVaw3_d2rDEZlVaB8dVGytFvdw">yaml</a></span></p><p class="c1"><span>Inst. fullness 27.07, </span><span class="c22">bleedless </span><span class="c0">47.49, SDR 16.71</span></p><p class="c1"><span class="c0">Fullness worse than even most vocal Mel-Roformers (incl. BS-RoFormer SW and Mel Kim OG model).</span></p><p class="c1"><span class="c0">&ldquo;on the fuller side, somewhere around inst v1e+, maybe a tiny bit below. The main thing I notice is it captures more instruments than v1e+, but isn&#39;t muddy like [HyperACE] (which also captures more instruments)</span></p><p class="c1"><span class="c0">can be a little on the noisy side sometimes... but it at least isn&#39;t muddy and sounds natural (...) I&#39;d still ensemble if you want the noise reduced - rainboomdash</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1441680934129631325&amp;sa=D&amp;source=editors&amp;ust=1765035742688964&amp;usg=AOvVaw14RdVP382ltUNo2Av7jOt6">src</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Lower fullness models</span><span class="c42 c12 c15 c33">&nbsp;</span></p><p class="c1"><span class="c20">(if you find the ones above too muddy, but here you get more noise)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">0) Gabox </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox3.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742689578&amp;usg=AOvVaw0_ySxtUqIkEVa7-rrrI3C7">inst_gabox3</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742689725&amp;usg=AOvVaw3lRzId2hKQz9qksx_SJ0JC">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742689925&amp;usg=AOvVaw1GY0c9pywV6qEKm3qVLw9l">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742690035&amp;usg=AOvVaw0exr8NojgoS2bYaLYlPudW">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742690149&amp;usg=AOvVaw2BDH14i48SZcItEniKxDDo">2</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/lucassantillifuck2fa/Music-Source-Separation-Training/blob/main/Phase_Fixer.ipynb%23scrollTo%3DCCRJCgf9fmjw&amp;sa=D&amp;source=editors&amp;ust=1765035742690341&amp;usg=AOvVaw09pDcpj-G1ioj0VLcf6yWG">Phase fixer Colab</a></span></p><p class="c1"><span class="c0">Inst. fullness 37.69, bleedless 35.93, SDR 16.50<br>Actually worse fullness than v1e+ (37.89), and lower bleedless (36.53).</span></p><p class="c1"><span class="c0">When used with Unwa&rsquo;s beta 6 as reference for phase fixer (thx John UVR), slightly less muddy results than phase-fixed Becruily inst-voc results, but also slightly more vocal residues and a bit more inconsistent sound, fluctuations across the whole separation at times. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/INSTV7N.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742691332&amp;usg=AOvVaw01gq1NSmvxT4fhKvxKKosE">INSTV7N</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742691443&amp;usg=AOvVaw37UrJ9ZF4SUu0vtzw41Rja">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742691525&amp;usg=AOvVaw3FeKH8O3r2t8uMGXrMCsEs">2</a></span></p><p class="c1"><span class="c0">Inst. fullness 36.83, bleedless 35.47, SDR: 16.65</span></p><p class="c1"><span class="c0">More noisy than INSTV7; &ldquo;it&#39;s [even] closer to v7 than inst3&rdquo;</span></p><p class="c1"><span class="c0">__</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) SCNet XL model called &ldquo;very high fullness&rdquo; | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://mvsep.com&amp;sa=D&amp;source=editors&amp;ust=1765035742692017&amp;usg=AOvVaw1wTcbsPmQgtQYWNzziF3Xt">MVSEP</a></span></p><p class="c1"><span class="c0">Inst. fullness 34.04, bleedless 35.15, SDR 16.60</span></p><p class="c1"><span class="c0">It might work better than Roformers for less noisy/loud/busy mixes or genres like alt-pop, orchestral tracks with choir, sometimes giving more full results than even v1e, but at the cost of more noise. Might struggle with some vocal reverbs or effects.<br>&ldquo;Very hit or miss. When they&#39;re good they&#39;re really good but when they&#39;re bad there&#39;s nothing you can do other than use a different model&rdquo;<br>Compared to the high fullness variant, more crossbleeding of vocals in instrumentals (along with SCNet XL basic model). Some songs which sound full enough even with basic SCNet XL (and HF variant) while others will sound muddy (dca)</span></p><p class="c1"><span class="c0">&ldquo;has a lot of noise/bleed, and I haven&#39;t found the best way to get rid of it, but it does tend to pick up harmonies and subtle BGV that other models don&#39;t.&rdquo; dynamic64</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) MVSEP SCNet XL high fullness</span></p><p class="c1"><span class="c0">Inst. fullness 31.95, bleedless 34.06, SDR 17.26</span></p><p class="c1"><span class="c0">&ldquo;I have a few examples where it&#39;s better than v1e+</span></p><p class="c1"><span class="c0">Sometimes there is too much residue but most of the time it&#39;s fine&rdquo; dca<br>&ldquo;Really loving the way SCnet high fullness [variant] handles lower frequencies, below 2K [let&rsquo;s] say. Roformers are better with the transients up high, but decay on guitars/keys on the SCnet is more natural&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;seems to also confuse less &quot;difficult&quot; instruments for vocals&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;I noticed classic SCNet XL preserves more instruments than the high fullness one, but has more vocal crossbleeding in instrumental compared to high fullness</span></p><p class="c1"><span class="c0">So if you want instrument preservation use SCNet XL 1727 but if you want less crossbleeding of vocals in instrumental use SCNet XL high fullness</span></p><p class="c1"><span class="c0">I ignore the very high fullness one because it has too much vocal residue&rdquo; dca</span></p><p class="c1"><span class="c6">(regular SCNet XL moved below)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">_</span></p><p class="c1 c7"><span class="c6"></span></p><h6 class="c1 c27" id="h.v4wq54do0m30"><span>- Gabox BS_ResurrectioN </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/BS_ResurrectioN.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742695382&amp;usg=AOvVaw26qIwhe0F0TWeva_ZzEvXE">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742695530&amp;usg=AOvVaw1BcdjWDE0wrGnNnNs32ykg">yaml</a></span></h6><h6 class="c1 c27" id="h.g439g32fh5b2"><span class="c0">&ldquo;It is a fine-tune of BS Roformer Resurrection Inst but with higher fullness (like v1e for example), it needs [MVSEP&rsquo;s] BS 2025.07 (as a source/reference) phase fix </span></h6><h6 class="c1 c27" id="h.2p6pxv5r54a2"><span>I requested it because I found some songs where Resur Inst was producing muddy instrum results (...) I requested it not just for me because I saw other people were looking for something like v1e++&rdquo; - dca </span></h6><p class="c1 c7"><span class="c6"></span></p><h6 class="c1 c27" id="h.fb0456lvep0d"><span class="c22">Higher fullness </span><span class="c0">(but with more noise)</span></h6><p class="c1"><span class="c20">(</span><span class="c6">sorted by fullness)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>0) Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/INSTV6N.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742696801&amp;usg=AOvVaw3wiyawNAybut5qnNWtwchI">INSTV6N</a></span><span>&nbsp;(N for noise/fullness) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742696982&amp;usg=AOvVaw0WlCbbcw5Udd3WHZJC2su8">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742697168&amp;usg=AOvVaw1ST6x7KpbqElgoyM367PRw">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742697327&amp;usg=AOvVaw3lAjZV8LbDxLS_4NS79een">SESA</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742697441&amp;usg=AOvVaw2S5xYOG193R9cAMYJgfENG">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742697525&amp;usg=AOvVaw2bQu_-_rOPcINsclf9Ob05">2</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7915&amp;sa=D&amp;source=editors&amp;ust=1765035742697636&amp;usg=AOvVaw30ls-88MnB0j1OHSJZws1P">metrics</a></span><span>: <br>Inst. </span><span class="c22">fullness</span><span class="c0">: 41.68 (more than v1e), bleedless: 32.63 (N &ldquo;noisier but fuller&rdquo;)</span></p><p class="c1"><span>To get rid of noise in INSTV6N, use Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/denoisedebleed.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742698044&amp;usg=AOvVaw23WepAj7EXf4M2ORFSJvsL">denoise/debleed</a></span><span>&nbsp;model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742698198&amp;usg=AOvVaw0D2GOOn4MHwHa7U0AjchWE">yaml</a></span><span class="c0">) on mixture first, then use INSTV6N - &ldquo;for some reason it gives cleaner results&rdquo; (Gabox), but it can&rsquo;t remove vocal residues.</span></p><p class="c1"><span class="c0">Some people find it having less noise vs v1e and more fullness.<br>Also, it has more fullness vs INSTV6, and more noise, but some people might still prefer v1e. </span></p><p class="c1"><span class="c0">&ldquo;v1e sounds like an &quot;overall&quot; noise on the song, while v6n kind of mixes into it.</span></p><p class="c1"><span class="c0">v6n also sounds like two layers, one of noise that&#39;s just there. And the other one mixes into the song somehow. Using the phase swap barely makes it any better than phase swapping with v1e though&rdquo; - vernight<br>Also Kim model for phase swap seems to give less noise than unwa ft2 bleedless</span></p><p class="c1"><span class="c0">&ldquo;Comparing V6N with v1e and couldn&#39;t hear a fullness difference despite the metrics being approx 39 for v1e and 41 for V6N&rdquo; - dca</span></p><p class="c1"><span class="c0">&ldquo;my all-time favorite&rdquo; - ezequielcasas</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_Fv4Noise.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742699883&amp;usg=AOvVaw1aQtwe2ShS3z4cfFkxEmpZ">inst_Fv4Noise</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml?download%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035742700052&amp;usg=AOvVaw0EragV-6VOF_3-anW7C-jP">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035742700182&amp;usg=AOvVaw29qTpph3K4rK5qBUW2XZvX">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742700290&amp;usg=AOvVaw0zhFHLbqAfbj14_72HiAA-">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742700378&amp;usg=AOvVaw0UZ8iDV3Dl-wZzwshx1yBp">2</a></span></p><p class="c1"><span class="c0">Inst. fullness 40.40, bleedless 28.57, SDR 15.25</span></p><p class="c1"><span class="c0">Can be better than INSTV6 for some people, but overkill for others. Bigger fullness metric than even v1e.</span></p><p class="c1"><span class="c0">&ldquo;Despite v4&#39;s significant amount of noise, it seems to be the only model [till 8 February] that gave me a fuller sounding result compared to v1e that&#39;s actually perceivable by my ears.&rdquo; - Shintaro</span></p><p class="c1"><span class="c0">&ldquo;although the fullness metric increases when there is more noise, it doesn&#39;t always mean it&#39;s a better instrumental &mdash; an example of this is the fv4noise metrics&rdquo; - Gabox</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/natanworkspace/melband_roformer/blob/main/Neo_InstVFX.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742701479&amp;usg=AOvVaw3IrgvksaO3h0oceB9pU-nz">Neo_InstVFX</a></span><span>&nbsp;Mel-Roformer by neoculture | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/natanworkspace/melband_roformer/blob/main/config_neo_inst.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742701641&amp;usg=AOvVaw2kKBPiI1yNjJTUVSYnFQwn">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742701824&amp;usg=AOvVaw203DdgF6on9NwGyr71Iqhn">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742701931&amp;usg=AOvVaw1b5Gfi6a6PgNxhB5g8cn91">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742702020&amp;usg=AOvVaw3VhmIYbdj6QVPjvEV5Q52q">2</a></span></p><p class="c1"><span class="c0">Inst. fullness 39.88, bleedless: 32.56, SDR: 14.35<br>Focused on preserving vocal chops.</span></p><p class="c1"><span class="c0">&ldquo;great model (at least for K-pop it achieved the clarity and quality that no other model managed to have) it should be noted that it has a bit of noise even in its latest update, its stability is impressive, how it captures vocal chops, in blank spaces it does not leave a vocal record, sometimes the voice on certain occasions tries to eliminate them confusing them with noise, but in general it was a model that impressed me. It captures the instruments very clearly&rdquo; - billieoconnell.</span></p><p class="c1"><span class="c0">&ldquo;NOISY AF, this is probably the dumbest idea ever had for an instrumental model. Don&rsquo;t use it as your main one, some vocals will leak because I added tracks with vocal chops to the dataset. Just use this model for songs that have vocal chops&rdquo; - neoculture</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Unwa Inst V1e (don&rsquo;t confuse with newer +/plus variant above) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742703634&amp;usg=AOvVaw0aGwagBZkxB-tCjz-Tq2tV">Model files</a></span><span class="c0">&nbsp;(yaml from v1)</span></p><p class="c1"><span class="c0">Inst. fullness 38.87, bleedless 35.59, SDR 16.37</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742704010&amp;usg=AOvVaw21Hf4kJd-G1BhrNO0SjjJs">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742704145&amp;usg=AOvVaw3jQcru4E2UUsUO5Isl_ABy">MSST-GUI</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR instructions</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742704320&amp;usg=AOvVaw1Yv3WBfUmyljBRiuUr0idO">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742704409&amp;usg=AOvVaw3tvH0o8onBBfHTn4EIrW6j">2</a></span><span>&nbsp;| uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742704537&amp;usg=AOvVaw1MLbDUx64HvZG7ESUFOL2p">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742704620&amp;usg=AOvVaw1Z6-4Ogr3tFru3BKUQsuDr">premium</a></span><span class="c0">&nbsp;(scroll down) | MVSEP</span></p><p class="c1"><span>One of the first Mel Kim model fine-tunes trained with instrumental (other) target. High fullness metric, noisy at times and on some songs. To alleviate it, it can be used with automated </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1uDXiZAHYk7dQajOLtaq8QmYXL1VtybM2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742705103&amp;usg=AOvVaw2pdiBDqEAtzhxf_tUuJzY6">phase fixer Colab</a></span><span>&nbsp;or UVR&gt;Tools (Kim Mel as reference removes more noise than 2024.10 vs muddier Unwa v1/2 on their own; optionally use VOCALS-MelBand-Roformer by Becruily or unwa&#39;s kim ft; you can also use FT2 as reference, but it &ldquo;cuts instruments&rdquo; vs FT3 which can be rather better alternative). Optionally, in Phase Fixer you can set 420 for low and 4200 for high or 500 for both and Mel-Kim model for source; and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1zWOrzPKd-6x7vjHNqjK_bK2UOYfPzCuu/view&amp;sa=D&amp;source=editors&amp;ust=1765035742705939&amp;usg=AOvVaw2BjATk0TmNlQUNQL6ARItC">bleed suppressor</a></span><span class="c0">&nbsp;(by unwa/97chris) to alleviate the noise further (e.g. phase fixer on its own works better with v1 model to alleviate the residues). Besides the default UVR default 500/5000 and Colab default 500/9000 values, you could potentially &ldquo;even try like 200/1000 or even below for 2nd value.&rdquo; &nbsp;&ldquo;I would say that the more noisy the input is, the lower you have to set the frequency for the phase fixer.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>V1e might catch more instruments and vocals than INSTV6N. Even fuller model with more noise is instfv4noise below by Gabox.</span></p><p class="c1"><span>&ldquo;The &quot;e&quot; stands for emphasis, indicating that this is a model that emphasizes fullness.&rdquo;<br>&ldquo;However, compared to v1, while the </span><span class="c4"><a class="c3" href="#h.le80353knnv5">fullness</a></span><span>&nbsp;</span><span class="c0">score has increased, there is a possibility that noise has also increased.&rdquo; &ldquo;lighter compared to v2.&rdquo; Like other unwa&rsquo;s models, it can struggle with flute, sax and trumpet (unlike Mel 2024.10, and BS 2024.08 on MVSEP respectively - you can max ensemble all the three as a fix [dca100fb8]). Also, sometimes unwa&#39;s big beta5e can retrieve missing instruments vs v1e when those two above fails. Possible residues of dual layer vocals from suno songs. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gaboxFv3.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742708171&amp;usg=AOvVaw3rnfaPzkmB3m0a3Wkl3WOs">inst_gaboxFv3</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml?download%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035742708383&amp;usg=AOvVaw3EqmzQmeZr7L3AzAxd5h2Y">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742708528&amp;usg=AOvVaw1QmkXlirX6aU0cMmdZQbDL">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742708631&amp;usg=AOvVaw3RwhMcDSW3oykFVgt-9qa4">2</a></span><span class="c0">&nbsp;- F for fullness</span></p><p class="c1"><span class="c0">inst. fullness 38.71, inst. bleedless 35.62 (&ldquo;F&rdquo; stands for fuillness) | Inst SDR 16.43<br>Like v1e when it comes to fullness, but less bleeding.</span></p><p class="c1"><span class="c0">Vs v1e &ldquo;it&#39;s slightly better with some instruments&rdquo;, It might pick up an entire sax in the vocal stem.</span></p><p class="c1"><span class="c0">It doesn&#39;t have that weird fullness noise that fullness models produce, but still gives pretty full results and the phase swapper (with big beta 6 as reference) gets rid of that weird buzzing sound&rdquo; John UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Gabox experimental &ldquo;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Fullness.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742709771&amp;usg=AOvVaw0p4mtbUtdOgI7fduULdCe4">fullness.ckpt</a></span><span>&rdquo; inst Mel-Roformer (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742709963&amp;usg=AOvVaw3eWL7dROv8FT3CY9PvDWIz">yaml</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">Inst. fullness: 37.66, bleedless: 35.53, SDR: 15.91</span></p><p class="c1"><span class="c0">&ldquo;this isn&#39;t called fullness.ckpt for nothing.&rdquo; - Musicalman</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____________________________________</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Sorted by the biggest fullness metric on the list:</span></p><p class="c1"><span class="c0">INSTV6N (41.68)&gt;inst_Fv4Noise (40.40)/INSTV7N (no metrics)/Inst V1e (38.87)&gt;Inst Fv3 (38.71).<br>While V1e+ (37.89) might be already muddy in some cases.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Sorted by bleedless metric </span><span class="c4"><a class="c3" href="#h.6ypgpf4ku4d0">here</a></span></p><p class="c1"><span class="c0">_____________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Lower bleedless models/balanced</span></p><p class="c1"><span class="c42 c15 c36 c37 c30">Still less noise even when using without phase fixer</span></p><p class="c1 c7"><span class="c15 c36 c37 c30 c42"></span></p><p class="c1"><span>0) Unwa </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742711723&amp;usg=AOvVaw1FuMyHxONJjCH4EcdvfSoi">BS-Roformer Resurrection inst</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742711939&amp;usg=AOvVaw1EN3tbSdlN9oF1UKMZQ3FY">yaml</a></span><span>) | a.k.a. &ldquo;unwa high fullness inst&quot; on MVSEP | uvronline.app/x-minus.pro | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742712259&amp;usg=AOvVaw3jDwJLmavfTJXPfewAlal6">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span class="c0">&nbsp;(don&rsquo;t confuse with Resurrection vocals variant)</span></p><p class="c1"><span class="c0">Inst. fullness: 34.93, bleedless: 40.14, SDR: 17.25</span></p><p class="c1"><span class="c42 c15 c36 c37 c30">(duplicate from the above, because it fits metrically and categorization-wise here, more info above)</span></p><p class="c1 c7"><span class="c42 c15 c36 c37 c30"></span></p><p class="c1"><span>0) Unwa </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/resolve/main/melband_roformer_inst_v1.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742713134&amp;usg=AOvVaw2GEAPQrHmNIUOuQTfhqRnA">Mel-Roformer inst v1</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/resolve/main/melband_roformer_inst_v1.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742713314&amp;usg=AOvVaw078cc1MU2W2X7tNr5jKDQh">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742713491&amp;usg=AOvVaw2CTFahVh_SRzU08ZQtNwQs">Colab</a></span><span>&nbsp;| UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">installation</a></span><span>&nbsp;| MVSEP | uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742713748&amp;usg=AOvVaw2QpfEBt8SN-U_x8A8XwLQR">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742713844&amp;usg=AOvVaw3YQfU_jhZjsCaH6a8DiRKY">premium</a></span><span>&nbsp;(scroll down)<br>inst. fullness 35.69, bleedless 37.59<br>*) Denoising for v1/2/1e recommended with: 1) ensemble noise/phase fix option for x-minus premium 1b) Becruily </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1304002277375213700&amp;sa=D&amp;source=editors&amp;ust=1765035742714252&amp;usg=AOvVaw0dXXWdJwmYU2hISpdJM_XD">phase fixer</a></span><span>&nbsp;(also since UVR beta patch #7) 2) Mel-Roformer </span><span class="c4"><a class="c3" href="#h.hyzts95m298o">de-noise</a></span><span>&nbsp;non-agg. (might be better solution) 3) UVR-Denoise medium aggression (default for free users) 4) minimum aggression for premium/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742714757&amp;usg=AOvVaw0aQiMYv9xoFQFt54HN0Ion">link</a></span><span class="c0">&nbsp;(damages some instruments less) 5) UVR-Denoise-Lite [agg. 4, no TTA] in UVR - more aggressive method 6) UVR-Denoise [agg. 30/25, hi-end proc., 320 w.s., p.pr.] - even more muddy but preserves trumpets better</span></p><p class="c1"><span class="c23 c15 c30">v1 might have more instruments missing vs v1e and less noise</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span>0) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742715635&amp;usg=AOvVaw0YNGHPnj5T9Ud7uu6zn68K">inst_gabox2</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742715794&amp;usg=AOvVaw1_086x6JhjEZpU_vfPO_7s">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742715960&amp;usg=AOvVaw1jJ0aNzS5b3nQFBK5dEqWP">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742716071&amp;usg=AOvVaw09ykdbgApogtp8j-UHQ6zi">2</a></span></p><p class="c1"><span class="c0">inst. fullness 36.03, bleedless: 38.02</span></p><p class="c1"><span class="c0">-</span></p><p class="c1"><span>0) Becruily&rsquo;s inst </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-instrumental/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742716464&amp;usg=AOvVaw2btSvrRQCwA6H9JYGC_H1R">model</a></span><span class="c0">&nbsp;(again, because it fits here metrically)</span></p><p class="c1"><span>Inst. </span><span class="c4"><a class="c3" href="#h.le80353knnv5">fullness</a></span><span>&nbsp;33.98, bleedless 40.48, SDR 16.47<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742716870&amp;usg=AOvVaw3-oN9pUvzWL4pPHCsFYg-U">Colab</a></span><span>&nbsp;| on MVSEP a.k.a. &ldquo;high fullness&rdquo; (the same model) | x-minus (w/ optional phase correction feature in premium) | </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span><br>For less vocal residues use phase fixer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1uDXiZAHYk7dQajOLtaq8QmYXL1VtybM2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742717361&amp;usg=AOvVaw1RQBpFw3JL7C5wFCrf3dCX">Colab</a></span><span class="c0">&nbsp;(also in UVR&gt;Tools) and &ldquo;becruily&#39;s vocals as source and inst as target&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv8.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742717789&amp;usg=AOvVaw2z0w3zTi4mMLMs0KW8e-r-">Inst_GaboxFv8</a></span><span>&nbsp;v2 model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742717992&amp;usg=AOvVaw0vgVtwfBBNj_CVAlcMwdES">yaml</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742718196&amp;usg=AOvVaw0eg0ihjHhqk1oEkUVM7zs1">Colab</a></span></p><p class="c1"><span class="c0">Inst. fullness: 33.21, bleedless: 40.73, SDR: 16.57</span></p><p class="c1"><span class="c42 c15 c36 c37 c30">(again, just for metrics)</span></p><p class="c1 c7"><span class="c42 c15 c36 c37 c30"></span></p><p class="c1"><span>0) Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/instv7plus.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742718713&amp;usg=AOvVaw1x2so3_JySUQoEbgqKADbV">instV7plus</a></span><span class="c0">&nbsp;bleedless model (experimental)</span></p><p class="c1"><span class="c0">inst. fullness: 29.83, bleedless: 39.36, SDR 16.51<br>_</span></p><p class="c1"><span class="c0"><br>0) MVSEP SCNet XL (don&rsquo;t confuse with undertrained weights on ZFTurbo&rsquo;s GitHub)</span></p><p class="c1"><span class="c0">inst. fullness 28.74, bleedless 39.42, SDR 17.27</span></p><p class="c1"><span>&ldquo;I&#39;ve come across a lot of songs where high fullness [SCNet variant above] gives that annoying static noise. I&#39;m starting to like basic SCNet XL more to the high fullness [model]. And also, less vocal residues.&rdquo; - dca. There is crossbleeding of vocals in some songs. You can find the dca&rsquo;s list for that model in further parts of </span><span class="c4"><a class="c3" href="#h.37hhz9rnw7s8">this</a></span><span class="c0">&nbsp;section.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) MVSEP SCNet XL IHF</span></p><p class="c1"><span class="c0">inst. fullness 28.87, bleedless 40.37, SDR 17.41</span></p><p class="c1"><span class="c0">Some songs struggling with previous models might yield better results.</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c0">0) MVSEP SCNet Large</span></p><p class="c1"><span class="c0">inst. fullness 27.10, bleedless 41.47, SDR 17.05</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><h6 class="c1 c27" id="h.j9yql03jre5k"><span class="c6">Higher bleedless (not so full)<br></span></h6><p class="c1"><span>0) Gabox B/bleedless v3 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gaboxBv3.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742720669&amp;usg=AOvVaw1Aa0DePfVftXRg3nn1pR-w">inst_gaboxBv3</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742720787&amp;usg=AOvVaw3V1C6twIc-uKlRfpQmmzPH">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742720876&amp;usg=AOvVaw1xAwM5rDJAxw4MiFbs7N4b">2</a></span></p><p class="c1"><span class="c0">Inst. fullness: 32.13, bleedless: 41.69, SDR 16.60</span></p><p class="c1"><span>&ldquo;can be muddy sometimes&rdquo; but still fuller than the older one below</span></p><p class="c1"><span class="c31"><br></span><span class="c0">0) Unwa Mel-Roformer inst v2 (similar but fewer vocal residues (not always), muddier, bigger, heavier model)</span></p><p class="c1"><span class="c0">Inst. fullness 31.85, bleedless 41.73 (less bleeding than Gabox instfv5/6)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742759327&amp;usg=AOvVaw1pEa4jkH_0JDAW2HFi4-37">Model files</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742759706&amp;usg=AOvVaw3aMHJWynhNc2sCDsa2YqHN">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742759902&amp;usg=AOvVaw3fBo01pjM2pnPHraiq4dJK">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742760027&amp;usg=AOvVaw0mNJ3H9L1Mj5gP3KmEafvn">2</a></span><span>&nbsp;| uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742760210&amp;usg=AOvVaw1fLCSKy5poyuddqFVKG4dw">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742760319&amp;usg=AOvVaw34wjERgm6CdAj5lqWnR_hH">premium</a></span><span>&nbsp;(scroll down) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742760519&amp;usg=AOvVaw3gikFwRbccKV42BPXU8aRq">MSST-GUI</a></span><span>&nbsp;(or OG </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035742760646&amp;usg=AOvVaw3khrAB3oDX0d0GWLfHC5LF">repo</a></span><span>) | </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span class="c0">&nbsp;Download Center)</span></p><p class="c1"><span class="c0">Might miss flute. &ldquo;Sounds very similar to v1 but has less noise, pretty good&rdquo; &ldquo;the aforementioned noise from the V1 is less noticeable to none at all, depending on the track&rdquo;. &nbsp;&ldquo;V2 is more muddy than V1 (on some songs), but less muddy than the Kim model. (...) [As for V1,] sometimes it&#39;s better at high frequencies&rdquo; Aufr33<br>Might miss some samples or adlibs while cleaning inverts. SDR got a bit bigger (16.845 vs 16.595).</span></p><p class="c1"><span class="c0">&ldquo;Significantly less noise than v1e, sounds full enough, despite the fullness inst score, and that it recognizes more instruments than v1 and v1e, added to the fact it has higher SDR so also slightly less vocal crossbleeding in instrumental.&rdquo; - dca100fb8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Unwa </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Inst-FNO&amp;sa=D&amp;source=editors&amp;ust=1765035742762143&amp;usg=AOvVaw1NH9Ei4sIuBt5x1XRubU67">BS-Roformer-Inst-FNO</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span>Inst. fullness: 32.03, bleedless: 42.87, SDR: 17.60<br></span><span class="c42 c15 c36 c37 c30">(again, because it fits metrically, more info moved near the top to recent bleedless section)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Gabox</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv7z.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742762703&amp;usg=AOvVaw1eKg1z_hazzo7udE-QY1IK">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/Inst_GaboxFv7z.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742762882&amp;usg=AOvVaw3yzaaKI_G7Z5CJCr0EAZ0k">Inst_GaboxFv7z</a></span><span>&nbsp;Mel Roformer |</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742763060&amp;usg=AOvVaw05lsHGiD-Z1v8XccPiO98P">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742763200&amp;usg=AOvVaw2EGuq62NfOfoAQzdG7SVEe">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742763419&amp;usg=AOvVaw2JGmYxjKvU0utlkEc6es3f">Colab</a></span><span class="c0">&nbsp;| &nbsp;uvronline/x-minus.pro</span></p><p class="c1"><span class="c0">Becruily vocal used for phase fixer on x-minus.pro/uvronline (premium).</span></p><p class="c1"><span>Fullness: 29.96, </span><span class="c22">bleedless</span><span class="c0">: 44.61</span></p><p class="c1"><span class="c42 c15 c36 c37 c30">(again, because it fits metrically, -||-)</span></p><p class="c1"><span class="c0">_________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Last resort &nbsp;- muddier but cleaner single vocal models with more bleedless tested for instrumentals (sorted by bleedless) </span><span class="c4 c20"><a class="c3" href="#h.6f1v88my7hfk">here</a></span><span class="c20">&nbsp;| </span><span class="c4 c20"><a class="c3" href="#h.3mrz4632uifx">descriptions</a></span></p><p class="c1"><span class="c0">_________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Other or older instrumental models (less muddy than vocal models)</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span>- Full release of mesk&rsquo;s rifforge Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/meskvlla33/rifforge/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742764978&amp;usg=AOvVaw35kMINj11yJjqOnsXiFGp9">model</a></span><span class="c0">&nbsp;focused on inst/voc separation for metal music</span></p><p class="c1"><span class="c0">&ldquo;The model can have some quirks (just like most models) but it&#39;s all around clean for me to release.&rdquo; &ldquo;It kinda also fucks up in like cleans [not distorted/non-metal vocals]&rdquo;</span></p><p class="c1"><span class="c0">Training details:<br>&ldquo;Characteristics:</span></p><p class="c1"><span class="c0">This is a dimension 512 depth 24 model (so fairly large file size at 1.9 GB!), with an SDR of 14.2436.</span></p><p class="c1"><span class="c0">It&#39;s finetuned from an older Melband Roformer checkpoint with an SDR of 13.7.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;I think I found the (IMO) the best process for metal:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1. inferencing using the BS 07.2025 model on MVSEP</span></p><p class="c1"><span class="c0">2. inferencing using my rifforge model</span></p><p class="c1"><span class="c0">3. ensembling both with a min_fft ensemble&rdquo; - mesk</span></p><p class="c1"><span class="c0">it keeps the &quot;fullness&quot; of the rifforge model being an instrumental focused model but then also removes more stuff than my base model thanks to 07.2025&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (old) mesk&rsquo;s &ldquo;Rifforge&rdquo; metal Mel-Roformer fine-tune instrumental model (focused more on bleedless).</span></p><p class="c1"><span class="c0">Inst. fullness: 28.49, bleedless: 42.38, SDR 16.67</span></p><p class="c1"><span>&ldquo;training is still in progress, that&#39;s why it&#39;s a beta test of the model; It should work fine for a lot of things, but it HAS quirks on some tracks + to me there&#39;s some vocal stuff still audible on some tracks, I&#39;m mostly trying to get feedback on how I could improve it&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1405719212592464003&amp;sa=D&amp;source=editors&amp;ust=1765035742767537&amp;usg=AOvVaw0_CMzs63vKRBo2Z_8EbXSd">known issues</a></span><span class="c0">.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.proton.me/urls/5XM3PR1M7G%23F3UhCU8RDGhX&amp;sa=D&amp;source=editors&amp;ust=1765035742767749&amp;usg=AOvVaw19032_dCfoTcyn9464HyxS">https://drive.proton.me/urls/5XM3PR1M7G#F3UhCU8RDGhX</a></span></p><p class="c1"><span class="c0">Be aware that MVSep&rsquo;s BS-Roformer 2025.07 can be better for metal both for vocal and instrumentals than these mesk&rsquo;s models, a lot of the times. It was also trained on mesk&rsquo;s metal dataset.</span></p><p class="c1"><span class="c0">- Custom model import Colab has currently some issues with it. Probably, using that old version will work (at least locally).</span></p><p class="c1"><span class="c0">&quot;My old MSST repo I&#39;m using, but I removed all the training stuff</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.proton.me/urls/P530GFQR4W%23VCAsF0E1TPje&amp;sa=D&amp;source=editors&amp;ust=1765035742768678&amp;usg=AOvVaw2--OgKzrsxqlzRU3WWypaC">https://drive.proton.me/urls/P530GFQR4W#VCAsF0E1TPje</a></span></p><p class="c1"><span class="c0">pip install -r requirements.txt (u gotta have Python and PyTorch installed as well) for the script to work.</span></p><p class="c1"><span class="c0">You just gotta put all the tracks you want to test on in the **&quot;tracks&quot;** folder then double-click on **&quot;inference.bat&quot;** to run the inference script</span></p><p class="c1"><span class="c0">its like if you were to type in the command in cmd but its simpler, and I&#39;m lazy&quot; - mesk</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Older Mesk metal Mel-Roformer preview instrumental model </span></p><p class="c1"><span class="c0">Inst. fullness: 28.81, bleedless: 42.16, SDR 16.66<br>Retrained from Mel Kim on metal dataset consisting of a few thousands of songs.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/meskvlla33/metal_roformer_preview/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742769932&amp;usg=AOvVaw2VNRdSSOsyvuTZQnpYcb9g">https://huggingface.co/meskvlla33/metal_roformer_preview/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742770120&amp;usg=AOvVaw04-w9Fc3HHkg8Rj_7CAJC8">Colab</a></span></p><p class="c1"><span class="c0">(previous metrics were made on private dataset)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Should work fine for all genres of metal, but doesn&#39;t work on:</span></p><p class="c1"><span class="c0">- hard compressed screams</span></p><p class="c1"><span class="c0">- some background vocals</span></p><p class="c1"><span class="c0">- weird tracks (think Meshuggah&#39;s &quot;The Ayahuasca Experience&quot;)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>P.S: Use the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742770985&amp;usg=AOvVaw0wj55ZTOAllPLbHyyT-rlj">Colab</a></span><span>&nbsp;&ldquo;or training repo </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">(MSST)</a></span><span>&nbsp;if you want to [separate] with it. UVR will be abysmally slow (because of chunk_size [introduced since </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR Roformer beta</a></span><span class="c0">&nbsp;#3])&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/INSTV6.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742771487&amp;usg=AOvVaw0MYe13YCmhw_EbOPKyjfg6">INSTV6</a></span><span>&nbsp;by Gabox |</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742771629&amp;usg=AOvVaw10amYPzKnpWwjnfyJ4H2Kn">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742771743&amp;usg=AOvVaw0eJjLTo_RFWnrB7rozO88b">yaml</a></span><span>&nbsp;| x-minus | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742771943&amp;usg=AOvVaw0YAI--A_gbP4gNWdh7gai2">Colab</a></span></p><p class="c1"><span class="c0">Inst. fullness 37.62, bleedless 35.07, SDR 16.43</span></p><p class="c1"><span class="c0">v1e still gives better fullness, but the noise in it is a problem</span></p><p class="c1"><span class="c0">Opinions are divided whether v5 or v6 is better.</span></p><p class="c1"><span class="c0">&ldquo;Seems like a mix between brecuily and unwa&#39;s models&rdquo;<br>&ldquo;Slightly better than v5 (...) less muddy and also removes the vocals without adding that low EQ effect when the vocals would come in, so I feel it&#39;s better&rdquo; zzz<br>Old viperx&rsquo; 12xx models have fewerproblems with sax.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/Inst_GaboxFVX.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742772947&amp;usg=AOvVaw3Dh_Dr9CwZmf1LNsDTGZVf">Inst_GaboxFVX</a></span><span>&nbsp;|</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742773077&amp;usg=AOvVaw2inaJLYDRBON1ZYRY_c7fv">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742773197&amp;usg=AOvVaw2zxJtH1O-5MvcMtpUzv8Ro">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742773298&amp;usg=AOvVaw0KUQ2TDNbC9ehmvFhFQFgg">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742773383&amp;usg=AOvVaw38yskKmSNul4k32lHYiEBs">2</a></span></p><p class="c1"><span>Inst. fullness 38.25, bleedless </span><span class="c41">35.35</span><span class="c0">, SDR 16.49</span></p><p class="c1"><span class="c0">&ldquo;instv7+3&rdquo; - fuller than instv3</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/experimental&amp;sa=D&amp;source=editors&amp;ust=1765035742773836&amp;usg=AOvVaw1Tr9ExhpUz4U4RXiQzZYQA">instv10</a></span><span>&nbsp;(experimental) |</span><span><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742773996&amp;usg=AOvVaw1Q8FAn5SUjliwRt5b4cnmf">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742774112&amp;usg=AOvVaw3IUzQv5L_6tCv5ogc_gdhI">yaml</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">Less noise and vocal residues than V7, but muddier</span></p><p class="c1"><span class="c0">__</span></p><p class="c1"><span>0) Gabox Mel-Roformer instrumental model &ldquo;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/intrumental_gabox.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742774524&amp;usg=AOvVaw2COHbZ04LH8fPN7VX4PZvT">inst_gabox.ckpt</a></span><span class="c0">&rdquo; (Kim/Unwa/Becruily fine-tuned) </span></p><p class="c1"><span>Gabox&rsquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers&amp;sa=D&amp;source=editors&amp;ust=1765035742774731&amp;usg=AOvVaw3TGehOSCmHo3dzbjEmhc_4">models</a></span><span>&nbsp;repo | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035742774852&amp;usg=AOvVaw2ow3Mk1xDbQxHwY4rJC6fk">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742774955&amp;usg=AOvVaw0R4PG935Fv-fWLVRRabMhP">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742775043&amp;usg=AOvVaw3ZnIPu2ZOPlmXljufYtJyP">2</a></span></p><p class="c1"><span class="c0">inst fullness 37.07 (better than unwa inst v1 and v2), bleedless 37.40 (better than v1e by 1.8, slightly worse than unwa&rsquo;s v1)</span></p><p class="c1"><span class="c0">&ldquo;It&rsquo;s like the v1 model with phase fixer, but it gets more instruments,</span></p><p class="c1"><span class="c0">like, it prevents some instruments from getting into the vocals&rdquo;, &ldquo;sometimes both models don&#39;t get choirs&rdquo;.</span></p><p class="c1"><span class="c0">_____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Faster inference models<br></span><span class="c0">(small model size/potentially workable on not ancient CPUs):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX-Net HQ_3, 4, 5 (the last is the fastest, 56 MB)</span></p><p class="c1"><span class="c0">MDX-Net inst3, Kim inst (older, narrowband, but can be useful too in some cases, 63 MB)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Not sure if on CPU, but rather light, small (the lightest Roformers, while most have 870 MB):</span></p><p class="c1"><span class="c0">Unwa BS-Roformer-Inst-FNO (works only in MSST after modifying py file like in the model card, similar to decently performing Resurrection inst model, 332 MB)</span></p><p class="c1"><span>Gabox Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/small_inst.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742776826&amp;usg=AOvVaw0oN4Z6-dKZEhYRHBw0Lnwy">small_inst</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742776966&amp;usg=AOvVaw0N1YwZ3qA-DeVp57N4zJ1C">yaml</a></span><span class="c0">&nbsp;(experimental. even smaller - 203 MB)</span></p><p class="c1"><span class="c0">Unwa BS-Roformer-Inst-EXP-Value-Residual (low performance, use v2 model type in UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Older fullness models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Gabox F/fullness v1 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742777625&amp;usg=AOvVaw3ByhbBnwBbkhdttKgdiD8W">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742777713&amp;usg=AOvVaw2lZb-1GbfvPSSLrWd8Ciom">2</a></span></p><p class="c1"><span class="c0">inst fullness 37.26 | bleedless: 37.19</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) &nbsp;Gabox F/fullness v2 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742778016&amp;usg=AOvVaw3nj4eyTJnt6ypQj3sMIMEa">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742778098&amp;usg=AOvVaw1-UpNfnpMkOe0mObnPn6Fu">2</a></span></p><p class="c1"><span class="c0">inst fullness 37.46 | bleedless: 37.09</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>*) Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_Fv4&amp;sa=D&amp;source=editors&amp;ust=1765035742778402&amp;usg=AOvVaw1RJoqNB42LNDd5AUWoJgG0">inst_Fv4</a></span><span>&nbsp;(F - fullness/v4) | (don&rsquo;t confuse with vocal fv4) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml?download%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035742778624&amp;usg=AOvVaw0UuZVduv81rpSjwOLhn-dc">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742778815&amp;usg=AOvVaw0hLwIhwTjIWo9Q4i2NdcSH">Colab</a></span></p><p class="c1"><span class="c0">inst fullness 39.40 | bleedless 33.49</span></p><p class="c1"><span class="c42 c15 c36 c37 c30">Duplicate from the above</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Others </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) </span><span class="c4 c38"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/intrumental_gabox.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742779325&amp;usg=AOvVaw13_i-88-mDXX6aAGYsvjqP">intrumental_gabox</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742779468&amp;usg=AOvVaw0q9QmLbwAjJMTRpNP7zKRv">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742779575&amp;usg=AOvVaw1fKCLjPzc7x-pcijvGrDIH">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742779659&amp;usg=AOvVaw3l8PE1qWZqKo1pHQWdMp01">2</a></span></p><p class="c1"><span class="c0">__</span></p><p class="c1"><span>0) Gabox B/bleedless v1 instrumental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gaboxBv1.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742779928&amp;usg=AOvVaw06OdYMDOqk3iInfqLCSruZ">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742780065&amp;usg=AOvVaw3PrWUnVqr_NxtNP1NJJeLK">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742780170&amp;usg=AOvVaw0DJQVRGLp0tD5M9TDiSwIz">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742780273&amp;usg=AOvVaw3sKShicG3KYb7P7ldJGLcm">2</a></span></p><p class="c1"><span class="c0">Inst. fullness 35.03, bleedless 39.10, SDR 16.49</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Gabox B/bleedless v2 instrumental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gaboxBv2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742780693&amp;usg=AOvVaw3L-bnqv3ybautAOM6nFPp5">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742780841&amp;usg=AOvVaw1fpmkSqbYnz6e3bTPKqSh7">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742780958&amp;usg=AOvVaw2qFkogqxaRi-A8dOxVCWIM">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742781044&amp;usg=AOvVaw2-Ft6Ip9tl5LzhWbzjzdf4">2</a></span><span class="c0"><br>Inst. fullness 35.09, bleedless 38.38, SDR 16.49</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(</span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers&amp;sa=D&amp;source=editors&amp;ust=1765035742781351&amp;usg=AOvVaw1WcnNVSoRDdsELE6o1yF1o">Gabox models repo</a></span><span class="c20">)</span></p><p class="c1"><span class="c0"><br>0) Cut your song into fragments consisting from the best moments of e.g. v1e/v1/v2 into one (and optionally Mel-Roformer Bas Curtiz FT on MVSEP as it will give you even less vocal bleeding, but more muddiness if necessary)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Propositions of models for phase fixer to alleviate vocal residues (from the above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">a) Becruily voc with Becruily inst (muddy but very few residues if any)</span></p><p class="c1"><span class="c0">b) FT3 with V1e+ </span></p><p class="c1"><span class="c0">c) Unwa Beta 6 with inst_gabox3 (although it might be less consistent than the top)</span></p><p class="c1"><span class="c0">d) Unwa Revive model is also good with any instrumental model</span></p><p class="c1"><span class="c0">e) Unwa Bigbeta5 used to be not bad either.</span></p><p class="c1"><span class="c0">f) Or any of the vocal models above with e.g. V1e (it&#39;s pretty full, and it might be not enough for it nevertheless)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">How to use the phase fixer in UVR?</span></p><p class="c1"><span class="c0">Separate with vocal model, then with instrumental model. Go to Audio Tools&gt;Phase swapper, and use vocal model result as reference, and instrumental as target</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">__</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.nk4nvhlv1pnt"><span class="c18 c15">Ensembles</span></h6><p class="c1"><span>(for instrumentals; check out also </span><span class="c4"><a class="c3" href="#h.oxd1weuo5i4j">DAW ensemble</a></span><span>&nbsp;with the below</span><span class="c0">)</span></p><p class="c1"><span class="c52">If you find some phase fixer results (e.g. ensembled) unsatisfactory, use the Phase Fixer </span><span class="c4 c52"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/lucassantillifuck2fa/Music-Source-Separation-Training/blob/main/Phase_Fixer.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742784611&amp;usg=AOvVaw10yiLEIuT-GACnp0yCY2Lx">Colab</a></span><span class="c52">&nbsp;</span><span class="c52">- it&#39;s tweaked for better results than UVR and standalone scripts</span><span class="c23 c15 c30">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) BS HyperACE + BS 2025.07 (Max FFT with BS 2025.07 as phase fix reference and 3000/5000 for the values)</span></p><p class="c1"><span class="c0">&mdash;-&gt;My favorite ensemble right now. Though, I notice it produce vocal bleed sometimes and it can be noisy at some parts of the songs while the noise might be totally absent in other parts of the song. </span></p><p class="c1"><span class="c0">- dca100fb8 (if not said otherwise)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) BS-Roformer Resurrection Inst (phase fixed with BS 2025.07 using Low Cutoff 3000 and High Cutoff 5000) + BS 2025.07 (Max Spec)</span></p><p class="c1"><span class="c0">&mdash;-&gt;Former best</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Unwa Mel inst v1e+ with FNO with Becruilly inst (Max Spec)</span></p><p class="c1"><span class="c0">&mdash;-&gt; The best result back then</span></p><p class="c1"><span class="c0">- sakkuhantano</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Unwa Mel inst V1e + MVSEP BS 2025.07 (Max Spec) using BS 2025.07 as phase fix reference with </span><span class="c34">200/200</span><span class="c0">&nbsp;100/100 (it&#39;s better) as Low Cutoff and High Cutoff values</span></p><p class="c1"><span class="c0">&mdash;-&gt;It&#39;s very aggressive values because V1e is noisy, and it works quite well.</span></p><p class="c1"><span class="c0">The older best for then, &ldquo;BS Roformer Resur Inst [ensemble right below] is muddy compared to v1e, and I think fullness is the way. After phase fix the noise is barely noticeable&rdquo; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Unwa BS Roformer Resurrection Inst (BS 2025.07 as a reference for phase fix) + MVSEP BS Roformer 2025.07 (Max Spec)</span></p><p class="c1"><span>&nbsp;&mdash;-&gt;The least vocal crossbleeding (step-by-step process explained </span><span class="c4"><a class="c3" href="#h.8rocw7cwj55">here</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">Alternatively, you can use becruily vocal model instead of 2025.07 for the ensemble -<br>&ldquo;Becruily vocal correctly recognize instruments far better than the instrumental one&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(Note: BS 2025.07, BS 2024.04, BS 2024.08 and SW were worse for Resurrection model as a phase fix source, viperx BS-Roformer 1297 better, but not so good for instruments preservation as BS-2025.07)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) unwa v1e + Mel becruily vocal (Max Spec) + phase fix (using becruily vocal again as a source)</span></p><p class="c1"><span class="c0">&nbsp;&mdash;-&gt;The best instruments preservation (with more possible crossbleed)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Mel Gabox Fv7z + BS 2025.07 (Max Spec)</span></p><p class="c1"><span class="c0">&mdash;-&gt;The least amount of noise (with more possible crossbleed) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Mel Gabox Inst V8 + BS 2025.07 (Max Spec) + phase fix (becruily vocal as reference)</span></p><p class="c1"><span class="c0">&mdash;-&gt;A good balance between presence of noise and level of fullness</span></p><p class="c1"><span class="c0">(occasional vocal crossbleeding)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Mel Becruily Instrumental (with phase fix, becruily vocal as reference) + SCNet XL IHF (Max FFT)</span></p><p class="c1"><span class="c0">&mdash;-&gt;Why SCNet? Because it&#39;s better than Mel Roformer at the low frequencies, so why not ensemble both arch. (...) SCNet is already noisy from the start so the fullness models are even noisier obviously</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0a) Unwa v1e+ + BS-Roformer 12xx by viperx (Max Spec) - musicalman</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0a) FNO inst by unwa + BS-Roformer 12xx by viperx (might be optional) + v1e+ (or becruily inst Mel-Roformer)</span></p><p class="c1"><span class="c0">&ldquo;beware of the song where there&#39;s a vocal at the beginning of the song, using v1e+ will leave vocal residue. So decide to change into becruily inst as well.&rdquo; - Sakkuhantano</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0*) Mesks&rsquo;s metal min_fft ensemble of BS 07.2025 model on MVSEP + rifforge </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/meskvlla33/rifforge/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742792631&amp;usg=AOvVaw1ZnLakt6hadTLNvcWR3mEp">model</a></span><span class="c0"><br>&ldquo;it keeps the &quot;fullness&quot; of the rifforge model being an instrumental focused model but then also removes more stuff than my base model thanks to 07.2025&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0*) Chained separation method by fabio06844 for &ldquo;very clean and full&rdquo; instrumental.</span></p><p class="c1"><span class="c0">1) Go to MVSep and separate your song with the latest Karaoke BS-Roformer by MVSep Team</span></p><p class="c1"><span class="c0">2) On its instrumental stem result use DEBLEED-MelBand-Roformer (by unwa/97chris)</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/bleed_suppressor_melband_rofo_by_unwa_97chris/resolve/main/bleed_suppressor_v1.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742793784&amp;usg=AOvVaw3hhW2KXZi4fgWVnN1CQOLb">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/bleed_suppressor_melband_rofo_by_unwa_97chris/resolve/main/config_bleed_suppressor_v1.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742794012&amp;usg=AOvVaw328vpvcMa2fnKukzf4WRYB">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742794209&amp;usg=AOvVaw0s_zBK7J_GxRQkejqczTV2">Colab</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">(despite the fact that &ldquo;the MVSep Team Karaoke uses the MVSep BS model to extract/remove vocals, then applies [the] karaoke model to that&rdquo;, it was told to be not enough to just use BS 2025.07 model instead, leaving a little more residues).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0b) v1e phase swapped from Becruily vocals + BS 2025.07 (Max Spec)<br>(Phase fixer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/lucassantillifuck2fa/Music-Source-Separation-Training/blob/main/Phase_Fixer.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742794944&amp;usg=AOvVaw3qPYtKvgVhOhRayZ4Mgtge">Colab</a></span><span class="c0">/or UVR&rsquo;s phase swapper+MVSEP separation&gt;UVR Manual Ensemble)</span></p><p class="c1"><span class="c0">(&ldquo;brings: max fullness without a lot of noise since phase fix, rarely missing instruments, no robotic voice problem, rare vocal crossbleeding in instrumental &rdquo;) - older favourite dca100fb8&rsquo;s ensemble</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) v1e + Becruily vocal (Max Spec) (&ldquo;If you had to keep one ensemble right now. v1e+ unfortunately is muddier than v1e and has that robotic issue sometimes&rdquo;) - dca100fb8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c34">0b) v1e + Becruily inst + Becruily vocal (Max Spec) </span><span class="c0">(Becruily inst turned out to be &ldquo;useless&rdquo; in this bag of models) - -||-</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0b) Unwa v1e (with phase fix) + BS Large V1 (Max Spec) (doesn&#39;t need </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-vocals/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742796209&amp;usg=AOvVaw0SRJ2ImSgKq6WPPHuQ6pKa">Becruily vocal</a></span><span class="c0">&nbsp;here as the third) - -||-</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) v1e + INSTV7 (Max Spec) - neoculture</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Use MVSEP&rsquo;s SCNet XL high fullness below 1000 Hz, and unwa&rsquo;s v1e above 1000 Hz, and join the two in e.g. Izotope RX - &ldquo;You can use vertical select in RX with feathering set to 1.00&rdquo; (heuhew) or you can use linear phase EQ like e.g. free &ldquo;lkjb QRange&rdquo; (ensure to not overlap frequencies in the output spectrogram in the crossover point)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) v1e+ + becruily inst </span></p><p class="c1"><span class="c0">&mdash;&gt; fixes some missing instruments occasionally in v1e+</span></p><p class="c1"><span class="c0">- Sakku </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) INSTV7 + Inst_FV8 (to check)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) unwa&rsquo;s instv1e+, instv1+, instv2 and inst gabox, instv8 and instv7 - max FFT </span></p><p class="c1"><span class="c0">&ldquo;Then, I upscaled using Apollo. Afterward, I applied [Mel-Roformer] de-noise to remove background noise as needed and performed mastering&rdquo; (Sir Joseph)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) Max Spec manual ensemble of: v1e+ + MVSEP BS-Roformer 2025.07 model </span></p><p class="c1"><span class="c0">- It&rsquo;s a Senn&rsquo;s method below, simplified (IntroC)</span></p><p class="c1"><span class="c0">&ldquo;I think (...) [it] would be good enough. The way v1e+ keeps the noise is usually fine, and the mvsep 2025.07 model should bring back the lost masked frequencies for v1e+. Otherwise, just adjust the weight of v1e+ for maxspec to reduce the noise&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) Max Spec manual ensemble of: v1e+ + MVSEP BS-Roformer 2025.07 model + Becruily inst</span></p><p class="c1"><span class="c0">- Senn&rsquo;s method simplified (IntroC/Sakku)</span></p><p class="c1"><span class="c0">&ldquo;sometimes becruily can catch a tiny instr while v1e+ can&#39;t&rdquo; - Sakku</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">*) Senn&rsquo;s OG method:</span></p><p class="c1"><span class="c0">Use the highest SDR BS Roformer model on MVSEP and the best Fullness Melband Ro-Former model (unwa instrumental v1e plus) - mixed both with one of them phase-inverted, then use Soothe2 to filter out resonants, leaving mostly only noise, further filter and mix them, use a few plugins to do a spectral flattening, very minor.</span></p><p class="c1"><span class="c0">In other words:</span></p><p class="c1"><span class="c0">&ldquo;Pass the music through BS RoFormer&#39;s best SDR and the best Fullness, which is Unwa Instrumental v1e plus</span></p><p class="c1"><span class="c0">in iZotope RX, Invert the phase of any of the tracks, and copy n paste to the other track, the result should be some ghastly sounding reverb of the vocals</span></p><p class="c1"><span class="c0">using iZotope RX&#39;s Deconstruct, you wanna filter out the tonal signal of the voice as to remove the more obvious &quot;sinusoidal&quot; signals. It has to be fairly subtle as to not damage the noisy residuals</span></p><p class="c1"><span class="c0">Now with Soothe2, you wanna filter out any of the more aggressive noisy components, I use this setting, but it might not work 100% for everyone https://imgur.com/2A5yn3c (You can replace this with any plugin that acts similar to Soothe2, but Soothe2 is the best compromise)</span></p><p class="c1"><span class="c0">If needed, you can use Deconstruct as well but reducing the noisy aspects just to wipe out that aggressive noisy artifact</span></p><p class="c1"><span class="c0">Mess with the gain, and then add it back to the BS RoFormer track (don&#39;t forget to invert the phase again), Ideally it should be fairly subtle</span></p><p class="c1"><span class="c0">For post-processing:</span></p><p class="c1"><span class="c0">I use MSpectralDynamics to add a slight spectral flattening to the track, and Unchirp to denoise very slightly the higher frequencies to remove that digital hissy artifact and also tighten more of the sound</span></p><p class="c1"><span class="c0">A very subtle Gullfoss can also brighten the track slightly as well to compensate</span></p><p class="c1"><span class="c0">here is the result&rdquo; (thx senn)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c23 c15 c30">Older ensembles (from before becruily inst/voc Mel models release)</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c23 c15 c30">UVR&gt;Audio Tools&gt;Manual ensemble (for models from outside UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Unwa&rsquo;s v1e inst + phase fixer/swapper (from Mel-Kim or sometimes Mel 2024.10 on MVSEP for less noise) + BS 2024.08 on MVSEP (Max Spec)<br>(fullness with less noise + retrieved missing wind instruments from v1e) - dca100fb8<br>Becruily vocal is even better at recognizing instruments compared to Mel 2024.10 or BS 2024.08 (vocal Roformer models have fewer problems with recognizing instruments than inst Roformers)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Other dca&rsquo;s Max Spec ensembles of v1e with other Roformer models</span></p><p class="c1"><span class="c0"><br>II) v1e + phase fixer/swapper + Mel 1143 (because of fullness with less noise + retrieved missing wind instruments from v1e)</span></p><p class="c1"><span class="c0">III) v1e + phase fixer/swapper + BS 1296 (because of fullness with less noise + retrieved missing wind instruments from v1e)</span></p><p class="c1"><span class="c0">IV) v1e + phase fixer/swapper + BS 1297 (because of fullness with less noise + retrieved missing wind instruments from v1e)<br>V) v1e + phase fixer/swapper + BS Large V1 (because of fullness with less noise + retrieved missing wind instruments from v1e)<br>Recommended (or with v2/v1 instead) esp. when using a phase fixer due to bleed of instruments in the vocal track in Kim or its fine-tunes used for the tool.</span></p><p class="c1"><span class="c0">VI) (extra) for slow CPU/GPU: Voc FT + HQ5 (Max Spec)</span></p><p class="c1"><span class="c0">VII) HQ_5 with UVR&rsquo;s Phase Rotate (which now can replace the above)</span></p><p class="c1"><span class="c0">VIII) v1e + BS 2025.06 (Max Spec) - manual ensemble - the latter on MVSEP (because it keeps instruments in instrumental correctly [though less than becruily vocal] and it has less vocal crossbleeding in instrumental compared to becruily vocal)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) Unwa&rsquo;s Inst V2 and Inst Gabox (Avg) (1120 segments [6GB GPU]/4 overlaps) - cypha_sarin</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) Max ensemble of: instv1, instv2 and inst v1e &nbsp;- erdzo125<br>(better fullness than inst v1e itself, but more noise)</span><span class="c0"><br></span></p><p class="c1"><span>0b) Models ensembled - available only for premium users on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742805248&amp;usg=AOvVaw1vsU8DyuMvVH9JexQzxfOA">mvsep.com</a></span></p><p class="c1"><span class="c0">Now also added &ldquo;instrumental high fullness&rdquo; variant for inst, voc ensemble.</span></p><p class="c1"><span>For example, some lower inst, voc SDR ensembles available might be less muddy than 11.50 (e.g. 10.44), but the 11.50 one has the fewer amounts of vocal residues according to </span><span class="c22">bleedless </span><span>metric, but it can also sound very filtered. Newer ensembles added since then (track </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035742805953&amp;usg=AOvVaw3KmU8GX_pWZIx2RqXGLQwV">the leaderboard</a></span><span>&nbsp;and click on entries to see also bleedless/fullness metrics).<br></span><span class="c23 c15 c30">(ensembles on MVSEP provide currently the best of SDR scores for 2 and 4 stem separators, higher SDR than free v.2.4/2.5 Colabs below; 2025.06.28 has currently the biggest SDR metric, and surpassed ByteDance private model)</span></p><p class="c1"><span class="c23 c15 c30">There are shorter queues for single model separation for registered users with at least one point.</span></p><p class="c1"><span class="c42 c15 c36 c20 c11">Possibly shorter queues between 10:00 PM - 1:00 AM UTC.</span></p><p class="c1"><span class="c20 c11">The ensemble option fixes some issues with general muddiness of older vocal Roformer models (but 11.50 is muddier than v. 2.4 Colab).</span></p><p class="c1"><span><br></span><span>0) </span><span class="c4"><a class="c3" href="#h.7kniy2i3s0qc">KaraFan</a></span><span>&nbsp;(e.g. preset 5; fork of original ZFTurbo&#39;s MDX23 fork with new features by Captain FLAM with jarredou&#39;s help on some tweaks), </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Captain-FLAM/KaraFan/tree/master&amp;sa=D&amp;source=editors&amp;ust=1765035742807295&amp;usg=AOvVaw3u5UC1dQPPURRNra-neniv">offline version</a></span><span>, org. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Captain-FLAM/KaraFan/blob/master/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742807433&amp;usg=AOvVaw272oIb742XMOVam8Pp7HqR">Colab</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kubinka0505/colab-notebooks/blob/master/Notebooks/AI/Audio_Separation/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742807595&amp;usg=AOvVaw3i0kS8PjiXGA9PzHcQ4Ov4">Kubinka</a></span><span>&nbsp;Colab (older version, less vocal residues vs. v.3.1, although v.3.2-4.2/+ were released with fewer residues)</span><span class="c0">.</span></p><p class="c1"><span class="c31">Used to be one of the best free solutions for instrumentals (before some newer Roformers like unwa&rsquo;s inst </span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742808076&amp;usg=AOvVaw2EAx2IGKJ3AeW3AV6wIWC6">v1</a></span><span class="c23 c15 c30">&nbsp;were released), with not big amounts of vocal residues (sometimes more than below), and clear outputs. But no 4 stems unlike below:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0a) </span><span class="c20">MDX23</span><span class="c0">&nbsp;by ZFTurbo (weighted UVR/ZF/VPR models) -</span></p><p class="c1"><span>free modified Colab fork </span><span>v. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/deton24/MVSEP-MDX23-Colab_v2.1/blob/main/MVSep_MDX23_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742808655&amp;usg=AOvVaw1ss1AycEJl-cbuorOAQiQn">2.1</a></span><span>&nbsp;- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.4/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742808787&amp;usg=AOvVaw1ipYyt7iVA85K4eWwN7ogY">2.4</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742808914&amp;usg=AOvVaw1GzkNUYaHGHLJ2AwhAnMTz">2.5</a></span><span class="c0">&nbsp;with fixes and enhancements by jarredou</span></p><p class="c1"><span class="c31">(one of the best SDR scores for publicly available 2-4 stem separator, <br></span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742809268&amp;usg=AOvVaw04cpQZs6336y_xzKnl0EdU">v2.2.2</a></span><span class="c31">&nbsp;Colab with fullband MDX23C model might have more residues in instrumentals vs v. 2.1, but better SDR, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/deton24/MVSEP-MDX23-Colab_v2.1/blob/2.7/MVSep_MDX23_Colab_2_7_Version_Updated.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742809670&amp;usg=AOvVaw3-kCYI1UzMpzMKlvKtkigZ">2.7b</a></span><span>&nbsp;(with SCNet XL, not SDR evaluated - weight set by ear),</span><span class="c31">&nbsp;</span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.3/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742809902&amp;usg=AOvVaw1KATFJyncC9rZMZGBjJ_ZT">2.3</a></span><span class="c31">, 2.4 with also 12xx BS-Roformer, v. 2.5 with also Kim&rsquo;s Mel-Roformer (default settings can be already good and balanced, and weights further adjusted, </span><span class="c4 c31"><a class="c3" href="#h.jmb1yj7x3kj7">read</a></span><span class="c23 c15 c30">&nbsp;for more settings. <br>The caveat - it haven&rsquo;t been updated by newer Roformer instrumental models at the top). </span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c31">0a) dango.ai (</span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=http://tuanziai.com&amp;sa=D&amp;source=editors&amp;ust=1765035742810509&amp;usg=AOvVaw3lUm4KlZQit_P5OgMkgNF9">tuanziai.com/en-US</a></span><span class="c23 c15 c30">) - 8$ every 10 songs, currently one of (if not) the best instrumental separator so far; at least till unwa inst models came to the level of fullness of Dango now (you might find the latter even too muddy), but in cost of more noise, although &ldquo;it can hande complex vocals/songs well so it&#39;s more reliable, and no vocal bleed in background of instrumental&rdquo;.<br>Dango&rsquo;s 10 Conservative mode give more fullness to instrumentals in cost of whispering artefacts (experimental for the time being - along with the Aggressive mode), and it doesn&rsquo;t fix vocal popping using Smart Mode (default). Now Dango 11 is available. More crossbleeding than Unwa Bs-Roformer inst. What changed for better is less noise and better instrument detection</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c20 c37"><br></span><span class="c31">Ensembles (from before becruily models release; less noisy single models later below)</span><span class="c37"><br><br></span><span class="c0">0b) Avg Spec ensemble of unwa inst v1 and v2<br></span></p><p class="c1"><span>0b) Min Spec manual ensemble of vocals stems from these models&gt;inversion with the original song (fuller, more noise) &nbsp;<br>(UVR&gt;Audio Tools&gt;Manual Ensemble)<br></span></p><p class="c1"><span class="c0">0b) Max ensemble of: unwa&rsquo;s v1e + Mel 2024.10 + BS 2024.08 - dca100fb8 <br>(older bag of models; 2024.08 on MVSEP; fixes the flute and trumpet issues)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0b) Separate the song twice - first with v1e, then with Unwa&rsquo;s BS-Roformer Large and do a Manual Max Spec Ensemble via UVR - dca100fb8 <br>(old; BS-Roformer is here to retrieve the missing instruments from v1e result, though BS 2024.08 &amp; Mel 2024.10 on MVSEP work better for this task already)<br></span><span class="c42 c15 c36 c20 c37"><br>(Ensembles from before unwa inst. models release - you might also try out replacing all the 12xx BS-Roformers below with newer unwa&rsquo;s/becruily/Gabox models)<br></span></p><p class="c1"><span>0b) Models ensembled - available only for premium users on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035742813325&amp;usg=AOvVaw12WPEmYFvTbQ5NJx0gidPH">x&ndash;minus.pro</a></span></p><p class="c1"><span class="c0">- max_mag ensemble (with viperx 1297 Roformer)</span></p><p class="c1"><span class="c0">- demudder (on Mel-Roformer)</span></p><p class="c1"><span>- Mel-Roformer + MDX23C</span></p><p class="c1 c7"><span class="c42 c15 c36 c20 c11"></span></p><p class="c1"><span>UVR 5 ensembles (although beta 4 and inst </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742813821&amp;usg=AOvVaw3jPYGGA9dZU825NCZ7RjcS">v1</a></span><span class="c0">&nbsp;on their own might be better already)</span></p><p class="c1"><span class="c6">For Roformers, min. RTX 3050 8GB or faster AMD/Intel ARC/Apple M1-3 recommended </span></p><p class="c1"><span class="c20">(OpenCL is not as fast as CUDA in UVR; 6GB VRAM on CUDA </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://twitter.com/izutorishima/status/1816204774246879725&amp;sa=D&amp;source=editors&amp;ust=1765035742814241&amp;usg=AOvVaw2KEmksA-OLPeURKYKDjU3l">should</a></span><span class="c6">&nbsp;be enough too, min. 2K+ CUDA cores recommended) </span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>0b) 1296 + 1143 (BS-Roformer in </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta</a></span><span class="c0">&nbsp;UVR) + MDX-Net HQ_4 (dopfunk) </span></p><p class="c1"><span class="c0">[potentially try out Mel Kim instead of 1143 above already]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) Manual ensemble (in UVR&rsquo;s Audio Tools) of:</span></p><p class="c1"><span>BS-Roformer 1296 + file copy of the result + MDX23C HQ (jarredou; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1228818808261840976&amp;sa=D&amp;source=editors&amp;ust=1765035742815129&amp;usg=AOvVaw2eANSkt4xIP_p2_tMwMdUj">src</a></span><span class="c0">) </span></p><p class="c1"><span class="c0">or just 1296 + 1297 + MDX23C HQ for slower separation and similar result</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) Manual ensemble of:</span></p><p class="c1"><span class="c0">- BS-Roformer 1296 + drums stem from demucs_ft or</span></p><p class="c1"><span class="c0">- Bs-Roformer 1143 result passed through demucs_ft for drums to ensemble with 1296 (max/max)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) MDXv2 HQ_4 + BS-Roformer 1296 + BS-Roformer 1297 + Melband RoFormer 1143 (Max Spec) &ldquo;Godsend ensemble for demuddiness&rdquo; (dca100fb8)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0b) Manual ensemble of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035742816241&amp;usg=AOvVaw1wirSdXv8Ih0sfsHCI8fcL">HQ_5</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035742816336&amp;usg=AOvVaw1QzjZxSBRsDlGCBKy4PIEL">paid users</a></span><span>) and Kim&#39;s Mel-</span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">Roformer</a></span><span class="c0">&nbsp;(max_spec)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) &nbsp;(for metal) &ldquo;1 &ndash; pass through Kim&#39;s Vocal Melband Roformer (link in Single models below)</span></p><p class="c1"><span class="c0">2 - Multi-stem Ensemble (Average algo):</span></p><p class="c1"><span class="c0">1_HP-UVR</span></p><p class="c1"><span class="c0">MGM_HIGHEND_v4</span></p><p class="c1"><span class="c0">MGM_LOWEND_A_v4</span></p><p class="c1"><span class="c0">(VR advanced settings: 320 window size, 5 aggression setting, batch size default, TTA enabled | Post Process and High-End Process CHECKED OFF)&rdquo;</span></p><p class="c1"><span class="c0">3 &ndash; Manual Ensemble both your Melband output and the Multi-stem instrumental output (with Average algorithm)</span></p><p class="c1"><span class="c0">&ldquo;best settings/models for metal&rdquo; (~mesk)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0b) (older version of the above) 1_HP_UVR + UVR_MDX-NET-Inst HQ 4 + UVR_MDX-NET-Inst_Main 438 (</span><span class="c4"><a class="c3" href="#h.ma01ud7qwboo">VIP</a></span><span class="c0">&nbsp;model)</span></p><p class="c1"><span class="c0">(Min Spec / Average, WS 512, TTA Enabled, Post-Process and High-End Process off) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) 9_HP2-UVR and Kim Mel-Roformer (newer one for metal; mesk)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">but not in multi-stem cos you need 3 or more models </span></p><p class="c1"><span class="c0">VR: 320 window size, 1 aggression setting, Default batch size, TTA enabled (post process and high-end process isn&#39;t enabled)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0b) Mateus Contini&#39;s </span><span class="c4"><a class="c3" href="#h.79cxg1a64b11">method</a></span><span class="c0">&nbsp;e.g. #2 or #4</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) 9_HP2-UVR + BS-Roformer 1297</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) BS-Roformer ver. 2024.08 + MelBand Roforrmer (Bas Curtiz edition) + MDX-Net HQ4 + SCNet Large, Max Spec Ensemble (dca100fb8)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) BS-Roformer ver. 2024.08 + MelBand Roforrmer (Bas Curtiz edition) (Max Spec Ensemble) --&gt; result. Result + MDX-Net HQ4 + SCNet Large (Average Ensemble) - -||-</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) 1297 (ev. 1296) + MDX23C HQ2 (CZ-84)</span></p><p class="c1"><span class="c0">[or potentially unwa&rsquo;s BS-Roformer instead of 12xx]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">See also </span><span class="c4 c20"><a class="c3" href="#h.oxd1weuo5i4j">DAW ensemble</a></span><span class="c6">&nbsp;(older ensembles later below)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">(more about) unwa&rsquo;s instrumental Mel-Roformer v1 model | MVSEP | x-minus.pro</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742820604&amp;usg=AOvVaw1v_sJIzGbSa4c46P6DErBP">https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742820784&amp;usg=AOvVaw2tAWzHH6HXf6VM4AE7JHyG">Colab</a></span><span>&nbsp;| UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">instructions</a></span><span class="c0"><br></span></p><p class="c1"><span class="c0">&quot;much less muddy (..) but carries the exact same UVR noise from the [MDX-Net v2] models&quot;</span></p><p class="c1"><span class="c0">But it&#39;s a different type of noise, so aufr33 denoiser won&#39;t work on it. </span></p><p class="c1"><span class="c0">&ldquo;you can &quot;remove&quot; [the] noise with uvr denoise aggr -10 or 0&rdquo; although with -10 it will make it sound more muddy like Kim model and synths and bass are sometimes removed with the denoiser (~becruily)</span></p><p class="c1"><span class="c0">&ldquo; if there is any voice left [or also background noise], use the Mel-Roformer de-noise with minimal aggression. </span></p><p class="c1"><span class="c0">This inst model &ldquo;doesn&#39;t eliminate vocoder voices well from an instrumental&rdquo;.</span></p><p class="c1"><span class="c0">For the noise in the model, vs the ensemble trick on x-minus using Mel-Roformer de-noise might be better alternative:</span></p><p class="c1"><span class="c0">&ldquo;removes more noise from the song keeping overall instrument quality more than the new button [on x-minus]&rdquo; koseidon72. But the more aggressive variant of the Mel model sometimes deletes parts of the mix, like snares. UVR-Denoise-Lite doesn&rsquo;t seem to damage instruments like non-lite UVR-Denoise in UVR, but still more than Mel denoise (recommended aggr. - 4, with 272 vs 512 windows size it&rsquo;s less muddy, TTA can stress the noise more, somewhere above 10 aggr. it gets too muddy). UVR-Denoise on x-minus is even less aggressive (it&rsquo;s medium aggression model for free users who don&rsquo;t have aggression pick), but it might catch ends of some instruments like bass occasionally. Premium minimum aggression model is somehow more muddy, but doesn&rsquo;t damage instruments.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For more muddy Roformers consider using Aufr&rsquo;s </span><span class="c4"><a class="c3" href="#h.sv6j1ndk4oq5">demudder</a></span><span class="c0">&nbsp;(it&rsquo;s used for premium on x-minus for Kim Mel model) although it might increase vocal residues, and UVR demudder (explained there later below).<br></span></p><p class="c1"><span class="c6">____</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.3mrz4632uifx"><span class="c20">Muddier but cleaner </span><span class="c20">single models </span><span class="c0">(Roformer vocal models with fewer instrumental residues vs instrumental models without necessity of using phase fixer)</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0c) MVSep BS-Roformer (2025.07.20)</span></p><p class="c1"><span class="c0">Inst. fullness 27.83, vleedless 49.12, inst SDR 18.20</span></p><p class="c1"><span class="c0">Probably a retrain of the SW model on a bigger dataset.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0c) BS-RoFormer SW 6 stem (MVSEP/Colab/undef13 splifft) / vocals only</span></p><p class="c1"><span class="c0">Inst. fullness 27.45, bleedless 47.41, inst SDR 17.67</span></p><p class="c1"><span class="c0">(use inversion from vocals and not mixed stems for better instrumental metrics)</span></p><p class="c1"><span class="c0">Known for being good on some songs previously giving bad results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0c) 10.2024 Mel-Roformer vocal model on MVSEP<br>Inst. fullness 27.84, bleedless 47.37, inst SDR 17.59</span></p><p class="c1"><span class="c0">The cleanest, but muddy compared to models trained for instrumentals</span></p><p class="c1"><span class="c0">Capable of detecting sax and trumpet, but still muddier than instrumental models above.<br>Bas Curtiz vocal model fine-tuned by ZFTurbo. &nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0c) Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_fv4.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742826117&amp;usg=AOvVaw09ELkNuNYDjaer4-qFwaim">voc_fv4</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742826263&amp;usg=AOvVaw1fju4ac-ftZygBKdmJivEN">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742826453&amp;usg=AOvVaw3YL8JzMpLx5MyVfs9vvdtX">Colab</a></span></p><p class="c1"><span class="c0">Good for anime and RVC purposes (codename)</span></p><p class="c1"><span class="c0">And also for instrumentals, if you need less vocal residues than typical instrumental Roformers (even less than Mel Kim, FT2 Bleedless, or Beta 6X - makidanyee).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0c) Unwa&rsquo;s beta 5e model originally dedicated for vocals | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742827300&amp;usg=AOvVaw33w6b9__Md2nZXv-uAPATP">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742827429&amp;usg=AOvVaw2REgWUaulMKsDdw_4VZ-Ck">MSST-GUI</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR instr</a></span><span><br>Model </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742827586&amp;usg=AOvVaw23aKmzht_4iyI0cY8AsS1d">files</a></span><span>&nbsp;| yaml: big_beta5e.yaml or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1YRv1j0zMs9hk3-On2z6uwfZbsQ7l1LFP/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742827738&amp;usg=AOvVaw2Se_u8XYXN6QukKbqC6cF6">fixed </a></span><span class="c0">for AttributeError in UVR<br>Inst. fullness: 27.63 (bigger than Mel-Kim) | bleedless 45.90 (bigger than Kim FT by unwa, worse than Mel-Kim) | Inst. SDR 16.89</span></p><p class="c1"><span>Mainly for vocals, but can be still a decent all-rounder deprived of noise present in unwa&rsquo;s inst v1e/v1/v2 models, also with fewer residues than in Kim FT by unwa, and also more consistent model than Kim Mel model in not muffling instrumental a bit in sudden moments.<br>The third highest bleedless instrumental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1pPEJpu4tZjTkjPh_F5YjtIyHq8v0SxLnBydfUBUNlbI/edit?gid%3D1468543363%23gid%3D1468543363&amp;sa=D&amp;source=editors&amp;ust=1765035742828640&amp;usg=AOvVaw1WiHbTZ7VB51Hr6-Rh6Eqm">metric</a></span><span>&nbsp;after Mel-Kim model (after unwa ft2 bleedless in </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">vocals</a></span><span class="c0">).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It seems to fix some issues with trumpets in vocal stem (maxi74x1).<br>It handles reverb tails much better (jarredou/Rage123).</span></p><p class="c1"><span class="c0">Noisier/grainier than beta 4 (a bit similarly to Apollo lew&#39;s vocal enhancer), but less muddy.<br>&ldquo;The noise is terrible when that model is used for very intense songs&rdquo; - unwa</span></p><p class="c1"><span>Phase fixer for v1 inst model doesn&rsquo;t help with the noise here (becruily).<br>&ldquo;It&#39;s a miracle LMAO, slow instrumentation like violin, piano, not too many drums... <br>it&#39;s perfect... but unfortunately it can&#39;t process Pop or Rock correctly&rdquo; gilliaan<br>&ldquo;the vocal stem of beta5e may have fullness and noise level like duality v1, but it may also suffer kind of robotic phase distortion, yet may also remove some kind of bleed present in other melrofo&#39;s.&rdquo; Alisa/</span><span class="c41">makidanyee</span><span class="c0"><br>&ldquo;particularly helpful when you invert an instrumental and then process the track with it.&rdquo; gilliaan</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0c) Unwa&rsquo;s Kim Mel-Band Roformer FT2 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742830425&amp;usg=AOvVaw2XurZAEZ4H-i3XWGHFC9RU">download</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742830615&amp;usg=AOvVaw3SLhJ_1UrRslHv5t6nFxkF">Colab</a></span></p><p class="c1"><span class="c0">Inst. fullness: 28.36, bleedless: 45.58</span></p><p class="c1"><span class="c0">Decent all-rounder too, sometimes less bleeding in instrumentals than 5e.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0c) Unwa Kim Mel-Band Roformer Bleedless FT2 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742831222&amp;usg=AOvVaw2kH3WYEZuuC7j1avnmf_qZ">download</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035742831346&amp;usg=AOvVaw0hIilJU9H13g6c92WNAMyw">Colab</a></span><span class="c0"><br></span></p><p class="c1"><span class="c0">0c) Bas Curtiz&#39; edition Mel-Roformer vocal model on MVSEP</span></p><p class="c1"><span class="c0">(it was trained also on ZFTurbo dataset)</span></p><p class="c1"><span class="c0">&ldquo;Music sounds fuller than original Kim&#39;s one &amp; the finetuned version from ZFTurbo [iirc below]. Even [though] the SDR is smaller than BS Roformer finetuned last version, but almost song has the best result in instrumental.&rdquo; Henri</span></p><p class="c1"><span class="c0">It can struggle with trumpets more than the other Mel-Roformer on MVSEP [whether 08.2024 or Mel-Kim, can&rsquo;t remember].</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0c) BS-Roformer 2024.08.07 vocal model on MVSEP</span></p><p class="c1"><span class="c0">Inst. fullness 26.56 (less than Mel-Kim), Inst. bleedless 47.48 (the only single model with that better metric than Mel-Kim)</span></p><p class="c1"><span class="c0">Inst SDR 17.62</span></p><p class="c1"><span class="c0">vs 2024.04 model +0.1 SDR and &ldquo;it seems to be much better at taking the vocals when there are a lot of vocal harmonies&rdquo; also good for Dolby channels.</span></p><p class="c1"><span class="c0">Capable of detecting flute correctly</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0c) Mel-Roformer vocal model by KimberleyJSN - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/KimberleyJSN/melbandroformer/resolve/main/MelBandRoformer.ckpt?download%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035742833195&amp;usg=AOvVaw3bW3LpzZTlvzlTiLEDlDKL">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1U1FnACm-ontQSjhneq-WKk1GHEiTW97s/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742833402&amp;usg=AOvVaw3_1bY0PsNmP4beDOkX6Huv">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742833666&amp;usg=AOvVaw1drCym0E4GqpbzVLJbuooI">Colab</a></span></p><p class="c1"><span class="c0">Inst. fullness 27.44 (worse than beta 5e and duality, but better than current BS-Roformers)</span></p><p class="c1"><span>Inst. bleedless 46.56 (the best </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1pPEJpu4tZjTkjPh_F5YjtIyHq8v0SxLnBydfUBUNlbI/edit?gid%3D1468543363%23gid%3D1468543363&amp;sa=D&amp;source=editors&amp;ust=1765035742834188&amp;usg=AOvVaw1aHirA5ABecTBgfUBd20sa">metric </a></span><span class="c0">from public models)</span></p><p class="c1"><span class="c0">Inst SDR 17.32</span></p><p class="c1"><span class="c0">It became a base for many Mel-Roformer fine-tunes here.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(works in UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta Roformer</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742834739&amp;usg=AOvVaw0KKmyAm3sFOfzO0s7Zay86">Colab</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/KimberleyJensen/Mel-Band-Roformer-Vocal-Model&amp;sa=D&amp;source=editors&amp;ust=1765035742834862&amp;usg=AOvVaw2jVAjLmI_bFwey5l_MDMJN">CML inference</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035742834935&amp;usg=AOvVaw1JrNumMNnjUiMGToeuNuRN">x-minus</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742835072&amp;usg=AOvVaw1bw6n8Y3wFt-RCA945dGbf">MDX23 2.5</a></span><span>&nbsp;(when weight is set only for Mel model)/simple model </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1tyP3ZgcD443d4Q3ly7LcS3toJroLO5o1?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742835266&amp;usg=AOvVaw0G3gvKIHKhtgJ0tzs1co17">Colab</a></span><span class="c0">&nbsp;(might have problems with mp3 files)</span></p><p class="c1"><span class="c0">It&rsquo;s less muddy than older viperx&rsquo; Roformer model, but can have more vocal residues e.g. in silent parts of instrumentals, plus, it can be more problematic with wind instruments putting them in vocals, and it might leave more instrumental residues in vocals. SDR is higher than viperx model (UVR/MVSEP) but lower than fine-tuned 2024.04 model on MVSEP.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0c) Unwa Revive 2 BS-Roformer (&ldquo;my first impression is it may have less low end noise than fv4 but not the best in the overall quality and amount of residues in vocal&rdquo; - makidanyee)</span></p><p class="c1"><span><br>0c) BS-Roformer Large vocal model by unwa (viperx 1297 model fine-tune) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Q_M9rlEjYlBZbG2qHScvp4Sa0zfdP9TL/view&amp;sa=D&amp;source=editors&amp;ust=1765035742836604&amp;usg=AOvVaw3dMMGGx0rm_iv2hcmGU84B">download</a></span><span class="c0"><br>Older BS model. It picks more instruments than 12xx models. More muddy than Kim&rsquo;s Roformer, a bit less of vocal residues, a bit more artificial sound. Also tends to be more muddy than viperx 1297, sometimes muffling instrumental at times, but a bit less of vocal residues, a bit more artificial sound/a bit less musical. Sometimes it has more vocal residues than beta 5e.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Compared to BS, Mel-Roformers can be a good balance between muddiness and clarity for some instrumentals.</span></p><p class="c1"><span class="c0">Compared to ZFTurbo (MVSEP) and viperx models, Kim&rsquo;s trained on Aufr33&rsquo;s and Anjok&rsquo;s dataset. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>UVR manual model installation (Model install option added in newer </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">patches</a></span><span class="c0">):<br>Place the model file to Ultimate Vocal Remover\models\MDX_Net_Models and the config to model_data\mdx_c_configs subfolder and &ldquo;when it will ask you for the unrecognised model when you run it for the first time, you&#39;ll get some box that you&#39;ll need to tick &quot;Roformer model&quot; and choose its yaml&rdquo; some models here are available in Download Center too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Other unwa fine-tunes (originally vocal models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0c) Mel-Roformer Kim | FT (by unwa) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742839164&amp;usg=AOvVaw0RiYBh4j-8Td8kWICOx97I">Colab</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742839416&amp;usg=AOvVaw1SkzydX4Q4Y6T7Sr90beI6">https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main</a></span></p><p class="c1"><span class="c0">Inst. fullness 29.18 (lower than only unwa inst models) </span></p><p class="c1"><span class="c0">Inst. bleedless 45.36 (lower than Beta 5e)</span></p><p class="c1"><span class="c0">Inst. SDR 17.32</span></p><p class="c1"><span class="c0">Has more vocal residues than Beta 5e</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aname Mel-Roformer </span><span class="c34">duality </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/Mel-Band-Roformer_Duality&amp;sa=D&amp;source=editors&amp;ust=1765035742840025&amp;usg=AOvVaw1N1g-M882yeWWzRdTQxBn0">model</a></span><span class="c0">&nbsp;. <br>It&rsquo;s focused more on bleedless than fullness metric contrary to the unwa&rsquo;s duality v2 model, but with bigger SDR. </span></p><p class="c1"><span class="c0">Inst. fullness 24.36, bleedless 46.52, SDR: 17.15</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mel-Roformer unwa&rsquo;s inst-voc model called &ldquo;duality v1/2&rdquo; (focused on both instrumental and vocal stem during training; two independent and not inversible stems inside one weight file). </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality&amp;sa=D&amp;source=editors&amp;ust=1765035742840875&amp;usg=AOvVaw2fRONptM4ZTQxvCUm9Csmc">https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742841075&amp;usg=AOvVaw3tp3PwQys8QQKcYmhaViIM">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742841146&amp;usg=AOvVaw2koEqWtYDiIzqeMgV8QKyi">MVSEP</a></span><span class="c0"><br>V1: Inst fullness 28.03, bleedless 44.16, SDR 16.69. </span></p><p class="c1"><span class="c0">V2: Inst SDR 16.67</span></p><p class="c1"><span class="c0">Outperformed in both metrics by the unwa&rsquo;s Kim FT.</span></p><p class="c1"><span class="c0">Vocals sound similar to beta 4 model, instrumentals are deprived of the noise present in inst v1/e models, but in result, they don&#39;t sound similarly muddy to previous Roformers.</span></p><p class="c1"><span>Compared to beta 4 and BS-Roformer Large or other archs&rsquo; models, it has fewer problems with reverb residues, and vs v1e, with vocal residues in e.g. Suno AI songs.<br>&quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7321&amp;sa=D&amp;source=editors&amp;ust=1765035742842077&amp;usg=AOvVaw04KMT72P_Nr0oRAzz570Vq">other</a></span><span>&quot; is output from model, &quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7322&amp;sa=D&amp;source=editors&amp;ust=1765035742842210&amp;usg=AOvVaw3LCNGtxKZe52gOnHlpPIQW">Instrumental</a></span><span class="c0">&quot; is inverted vocals against input audio.</span></p><p class="c1"><span>The latter has lower SDR and more holes in the spectrum, using MSST-GUI, leave the checkbox &ldquo;extract instrumental&rdquo; disabled for duality models (now it&rsquo;s also in the Colab with &ldquo;extract_instrumental&rdquo; option) and probably for inst vx models.<br>You can use it in the Bas Curtiz&rsquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742842871&amp;usg=AOvVaw112QRqOjxiw7bro87bFe11">GUI</a></span><span class="c0">&nbsp;for ZFTurbo script or with the OG ZF&rsquo;s repo code.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa&rsquo;s Mel-Roformer fine-tuned beta 3 (based on Kim&rsquo;s model)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742843338&amp;usg=AOvVaw0zgSFriWvR-ClQnj_sif7c">https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742843465&amp;usg=AOvVaw2a86Fwm-Wv1sY5vmDjt5DL">Colab</a></span><span class="c0"><br>Inst SDR: 17.30</span></p><p class="c1"><span class="c0">Since beta 3 there&rsquo;s no ringing issues in higher frequencies like in previous betas.<br>Sometimes better for instrumentals than beta 4 - but tends to be too muddy at times, but with fewer vocal residues than beta 5.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa&rsquo;s Mel-Roformer beta 4 (Kim&rsquo;s model fine-tuned)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742844205&amp;usg=AOvVaw2Hc3SXyai0GpxUM3-Gp0Ki">https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1e9dUbxVE6WioVyHnqiTjCNcEYabY9t5d&amp;sa=D&amp;source=editors&amp;ust=1765035742844320&amp;usg=AOvVaw2XiztrSl1VLAKUHLB_ejkN">Colab</a></span></p><p class="c1"><span class="c0">Outperformed in both metrics by beta 5e.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that the yaml config is different in this model.</span></p><p class="c1"><span class="c0">&ldquo;Metrics on my test dataset have improved over beta3, but are probably not accurate due to the small test dataset. (...) The high frequencies of vocals are now extracted more aggressively. However, leakage may have increased.&rdquo; - unwa</span></p><p class="c1"><span class="c0">&ldquo;one of the best at isolating most vocals with very little vocal bleed and still doesn&#39;t sound muddy&rdquo; Can be a better choice on its own than some ensembles.</span></p><p class="c1"><span class="c0">0c) SCNet XL (vocals, instum)</span></p><p class="c1"><span class="c0">Inst SDR: 17.2785</span></p><p class="c1"><span class="c0">Vocals have similar SDR to viperx 1297 model, </span></p><p class="c1"><span class="c0">and instrumental has a tiny bit worse score vs Mel-Kim model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0c) Older SCNet Large vocal model on MVSEP</span></p><p class="c1"><span class="c0">&ldquo;just like the new BS-Roformer ft model, but with more bleed. [BS] catches vocals with more harmonies/bgv&rdquo; - isling. &ldquo;it&#39;s like improved HQ4&rdquo; - dca100fb8<br>Issues with horizontal lines on spectrogram.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0d) Aname Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/Mel_Band_Roformer_Full_Scratch&amp;sa=D&amp;source=editors&amp;ust=1765035742846260&amp;usg=AOvVaw3Rrb4ogj4Ep2ra5zocVM1q">model</a></span><span class="c0">&nbsp;trained from scratch a.k.a. Full Scratch</span></p><p class="c1"><span class="c0">Inst. fullness: 25.10, bleedless: 37.13</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.7znr3r5gprdy"><span class="c6">Models for older archs</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c23 c15 c30">0c) MDX23C 1666 model exclusively on mvsep.com </span></p><p class="c1"><span class="c23 c15 c30">(vocal Roformers are much more muddy than MDX23C/MDX-Net in general, but can be cleaner)</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c0">0c) MDX23C 1648 model in UVR 5 GUI (a.k.a. MDX23C-InstVoc HQ / 8K FFT) and mvsep.com, also on x-minus.pro/uvronline.app</span></p><p class="c1"><span class="c0">Both sometimes have more bleeding vs MDX-Net HQ_3, but also less muddiness.</span></p><p class="c1"><span class="c0">Possible horizontal lines/resonances in the output - fix DC offset and or use overlap &ldquo;starting from 7 and going multiples up - 14 and so on.&rdquo; Artim Lusis</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0c) MDX23C-InstVoc HQ 2 - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035742847828&amp;usg=AOvVaw1Ot80YC93AuvBM0mxiJpuF">VIP</a></span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/MDX23C-8KFFT-InstVoc_HQ_2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742847976&amp;usg=AOvVaw0Ev9fdgdH-tdzPxlwOTVAp">model</a></span><span class="c0">&nbsp;for UVR 5. It&#39;s a slightly fine-tuned version of MDX23C-InstVoc HQ. &ldquo;The SDR is a tiny bit lower, but I found that it leaves less vocal bleeding.&rdquo; ~Anjok</span></p><p class="c1"><span class="c0">It&rsquo;s not always the case, sometimes it can be even the opposite, but as always, all may depend on a specific song.<br></span></p><p class="c1"><span>0d) MDX-Net HQ_4/3/2 (UVR/MVSEP/x-minus/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1GwMEjhczFzdS0Ld7eZzMcZgEmz6Jgv6m&amp;sa=D&amp;source=editors&amp;ust=1765035742848631&amp;usg=AOvVaw0FHYBkY_Rx_wQD-Pb_4dLL">Colab</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kae0-0/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742848797&amp;usg=AOvVaw0zNaRQNZrh6r4byWZJ2K1i">alt</a></span><span class="c0">) - small amounts of vocal residues at times, while not muffling the sound too much like in old BS-Roformer v2 (2024.02) on MVSEP, although it still can be muddy at times (esp. vs MDX23C HQ models), HQ_4 tends to be the least muddy out of all HQ_X models (although not always), and is faster than HQ_3 and below, it tends to have less vocal residues vs MDX23C.</span></p><p class="c1"><span class="c0">Final MDX-Net HQ_5 seems to be muddier for instrumentals, although slightly less noisy, but better for vocals than HQ_4.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0d) MDX HQ_5 final model in UVR (available in its Download center and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742850106&amp;usg=AOvVaw3ABidc3YH6gY5Xa3-sYjH1">Colab</a></span><span>)<br>Versus HQ_4, less vocal residues, but also muddier at times and a bit lower, 21,5kHz cutoff. <br>Sometimes even more muddy than narrowband inst 3 to the point it can spoil some hi hats occasionally.<br>Versus unwa&rsquo;s v1e &ldquo;HQ5 has less bleed but is prone to dips in certain situations. (...) Unwa has more stability, but the faint bleed is more audible. So I&#39;d say it&#39;s situational. Use both. (...) Splice the two into one track depending on which part works better in whichever part of the song is what I&#39;d do.&rdquo; CC Karaoke<br><br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/UVR-MDX-NET-Inst_HQ_5.onnx&amp;sa=D&amp;source=editors&amp;ust=1765035742851873&amp;usg=AOvVaw3zpSwMLvgM5-Q3fu9XR5J7">Model</a></span><span class="c0">&nbsp;| config: &quot;compensate&quot;: 1.010, &quot;mdx_dim_f_set&quot;: 2560, &quot;mdx_dim_t_set&quot;: 8, &quot;mdx_n_fft_scale_set&quot;: 5120</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0d) MDX HQ5 beta model on &nbsp;uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742852265&amp;usg=AOvVaw2W8Y5HxFluytMeNoRsJ_xf">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742852343&amp;usg=AOvVaw12JMmUoVy3FCIa2X7kuQjt">premium</a></span><span class="c0">&nbsp;(scroll down)</span></p><p class="c1"><span class="c0">Go to &quot;music and vocals&quot; and there you will see it </span></p><p class="c1"><span class="c0">It&#39;s not a final model yet, the model was in training since April.</span></p><p class="c1"><span class="c0">It seems to be muddier than HQ_4 (and more than Kim&rsquo;s and MVSEP&rsquo;s Mel-Roformer), it has less vocal bleeding than before, but more than Kim Mel-Roformer.</span></p><p class="c1"><span class="c0">&quot;Almost perfectly placed all the guitar in the vocal stem&quot; it might get potentially fixed in the final version of the model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0e) Other single MDX23C full band models on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742853347&amp;usg=AOvVaw19kUWK9cKEws8UVA_DBJJW">mvsep.com</a></span><span class="c0">&nbsp;(queues for free unregistered users can be long)</span></p><p class="c1"><span class="c23 c15 c30">(SDR is better when three or more of these models are ensembled on MVSEP; alternatively in UVR 5 GUI&rsquo;s via &ldquo;manual ensemble&rdquo; of single models (worse SDR) or at best, weighted manually e.g. in DAW, but the MVSEP &ldquo;ensemble&rdquo; option is specific method - not all fullband MDX23C models on MVSEP, that&rsquo;s including 04.24 BS-Roformer model are available in UVR)</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c0">- BS-Roformer model ver. 2024.04.04 on MVSEP (further trained from viperx&rsquo; checkpoint on a different dataset). SDR vocals: 11.24, instrumental: 17.55 (vs 17.17 in the base viperx model). Bad on sax. Less muddy than the three below.</span></p><p class="c1"><span class="c0">Though, all might share same advantages and problems (filtered results, muddiness, but the least of residues)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mel-Roformer model ver. 2024.08.15 on MVSEP (fine-tuned on prob. Kim&rsquo;s model)</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c31">- </span><span>BS-Roformer 12xx models by viperx model in UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta</a></span><span class="c0">/MVSEP and x-minus (struggles with saxophone too, but less (also vs Gabox inst v6), also struggles with some Arabic guitars, bad on vocoders)</span></p><p class="c1"><span class="c0">&ldquo;does NOT pick up on large screams that much (example being Shed by Meshuggah in my tests), well at least [vs] [kim&rsquo;s] x-minus mel-rofo&rdquo;</span></p><p class="c1"><span class="c0">1297 variant is being used on x-minus. It tends to be better for instrumentals than the 1296 model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Older BS-Roformer v2 model on MVSEP (2024.02) (a bit lower SDR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">All vocal Roformer models may sound clean, but filtered at the same time - a bit artificial [it tends to be characteristic of the arch], but great for instrumentals with heavy compressed vocals and no bass and drums - the least amount of residues and noise - very aggressive.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c23 c15 c30">- old MelBand Roformer model on MVSEP (don&rsquo;t confuse with the Kim&rsquo;s one x-minus - they&rsquo;re different)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c31">- </span><span class="c4 c31"><a class="c3" href="#h.yy2jex1n5sq">GSEP</a></span><span class="c23 c15 c30">&nbsp;(now paid) - </span></p><p class="c1"><span class="c23 c15 c30">Inst fullness: 28.83, bleedless: 31.18, SDR: 12.59</span></p><p class="c1"><span class="c23 c15 c30">Check out also 4-6 stem separation option and perform mixdown for instrumental manually, as it can contain less noise/residues vs 2 stem in light mix without bass and drums too (although more than first vocal fine-tunes of like MVSEP&rsquo;s BS-Roformer v2 back then). Regular 2 stem option can be good for e.g. hip-hop, and 4/+ stems a bit too filtered for instrumentals with busy mix. GSEP tends to preserve flute or similar instruments better than some Roformers and HQ_X above (for this use cases, check out also kim inst and inst 3 models in UVR) and is not so aggressive in taking out vocal chops and loops from hip-hop beats. Sometimes might be good or even the best for instrumentals of more lo-fi hip-hop of the pre 2000s era, e.g. where vocals are not so bright but even still compressed/heavily processed/loud or when instrumental sound more specific to that era. For newer stuff from ~2014 onward, it produces vocal bleeding in instrumentals much sooner than the above models. &quot;gsep loves to show off with loud synths and orchestra elements, every other mdx v2/demucs model fail with those types of things&quot;. </span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c20">Older ensembles (among others from the </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035742858876&amp;usg=AOvVaw2unUdxNp6vWHdYEqKdEMwg">leaderboard</a></span><span class="c23 c15 c20">)</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c23 c15 c30">Q: How to ensemble BS-Roformer 1296 with Kim Mel-Roformer using UVR GUI? </span></p><p class="c1"><span class="c23 c15 c30">I choose max/max vocal/instrumental, but on the list there is only 1296, and no Kim Mel-Roformer like in MDX-Net option [might have been fixed already]</span></p><p class="c1"><span class="c23 c15 c30">A: &ldquo;You have to set the stem pair to multi-stem ensemble, it can generate both vocal and instrumental from both models at the same time. Be sure to set the algorithm to max/max. Once that&#39;s done, find the ensemble folder and put the two instrumental files/two vocal files onto the input, provided that you have to go to audio tools first. Then set the algorithm to average and click on the start processing button&rdquo; - imogen</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span>0f. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/4626&amp;sa=D&amp;source=editors&amp;ust=1765035742860225&amp;usg=AOvVaw1e7zfBCQ9C4TBSYatqHkGb">#4626</a></span><span class="c0">:</span></p><p class="c1"><span class="c0">MDX23C_D1581 + Voc FT</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0g) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/4595&amp;sa=D&amp;source=editors&amp;ust=1765035742860484&amp;usg=AOvVaw0q-bWqhQqYQruwiWlP9YPd">#4595</a></span><span class="c0">:</span></p><p class="c1"><span class="c0">MDX23C_D1581 + HQ_3 (or HQ_4 now)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0h) Kim Vocal 2 + Kim Inst (a.k.a. Kim FT/other) + Inst Main + 406 + 427 + htdemucs_ft (avg/avg)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0i) Voc FT, inst HQ3, and Kim Inst</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0j) Kim Inst + Kim Vocal 1 + Kim Vocal 2 + HQ 3 + voc_ft + htdemucs ft (avg/avg).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0k) MDX23C InstVoc HQ + MDX23C InstVoc HQ 2 + MDX23C InstVoc D1581 + UVR-MDX-NET-Inst HQ 3 (or HQ 4)</span></p><p class="c1"><span class="c0">&ldquo;A lot of that guitar/bass/drum/etc reverb ends up being preserved with Max Spec [in this ensemble]. The drawback is possible vocal bleed.&rdquo; ~Anjok</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0l) MDX23C InstVoc HQ + MDX23C InstVoc HQ 2 + UVR-MDX-Net Inst Main (496) + UVR-MDX-Net HQ 1</span></p><p class="c1"><span class="c0">&quot;This ensemble with Avg/Avg seems good to keep the instruments which are counted as vocals by other MDXv2/Demucs/VR models in the instrumental (like saxophone, harmonica) [but not flute in every case]&quot; ~dca100fb8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0m) MDX23C InstVoc HQ + HQ4</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c31">0n) </span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://apps.apple.com/us/app/ripple-music-creation-tool/id6447522624&amp;sa=D&amp;source=editors&amp;ust=1765035742862427&amp;usg=AOvVaw2PPmTgkJYvzOFQkq30tgwG">Ripple</a></span><span class="c23 c15 c30">&nbsp;(no longer works) / Capcut.cn (uses SAMI-ByteDance a.k.a. BS-Roformer arch) - Ripple is for iOS 14.1 and US region set only - despite high SDR, it&#39;s better for vocals than instrumentals which are not so good due to noise in other stem (can be alleviated by decreasing volume by -3dB). </span></p><p class="c1"><span class="c31">0n) Capcut (for Windows) allows separation only for the Chinese version above (and returns stems in worse quality). See </span><span class="c4 c31"><a class="c3" href="#h.f0orpif22rll">more</a></span><span class="c23 c15 c30">&nbsp;for a workaround. Sadly, it normalizes input already, so -3dB trick won&rsquo;t work in Capcut. Also, it has worse quality than Ripple</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c0">The best single MDX-UVR non-Roformer models for instrumentals explained in more detail </span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035742863710&amp;usg=AOvVaw3FR3clsz6niwB9V0YPCJvv">UVR 5 GUI</a></span><span class="c0">/Colabs/MVSEP/x-minus):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0. full band MDX-Net </span><span class="c22">HQ_4</span><span class="c0">&nbsp;- faster, and an improvement over HQ_3 (it was trained for epoch 1149). In rare cases there&rsquo;s more vocal bleeding vs HQ_3 (sometimes &ldquo;at points where only the vocal part starts without music then you can hear vocal residue, when the music starts then the voice disappears altogether&rdquo;). Also, it can leave some vocal residues in fadeouts. More often instrumental bleeding in vocals, but the model is made mainly for instrumentals (like HQ_3 in general)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b) full band MDX-Net HQ_5 - similarly fast, might be less noisy, but more muddy, although better for vocals, but &ldquo;it seems it&#39;s the best workaround when there is vocal bleed caused by Roformers&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>1. full band MDX-Net </span><span class="c22">HQ_3</span><span class="c0">&nbsp;- like above, might be sometimes simply the best, pretty aggressive as for instrumental model, but still leaving small amounts of vocal residues at times - but not like BS-Roformer v2/viperx, so results are not so filtered like in these. </span></p><p class="c1"><span class="c0">HQ_3 filters out flute into vocals. Can be still useful to this day for specific use cases &ldquo;the only model that kept some gated FX vocals I wanted to keep&rdquo;.</span></p><p class="c1"><span class="c0">It all depends on a song, what&rsquo;s the best - e.g. the one below might give better clarity:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>2. full band </span><span class="c22">MDX23C-InstVoc HQ </span><span class="c0">(since UVR 5.60; 22kHz/fullband as well) - tends to have more vocal residues in instrumentals, but can give the best results for a lot of songs.</span></p><p class="c1"><span>Added also in MDX23 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742866512&amp;usg=AOvVaw0yFcvvEVYczeUZIJoXOKEA">2.2.2</a></span><span>&nbsp;Colab, possibly when weights include only that model, but UVR&#39;s implementation might be more correct for only that single model. Available also in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Captain-FLAM/KaraFan/blob/master/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742866897&amp;usg=AOvVaw340iar2c3K7hjiaMKP6KLG">KaraFan</a></span><span class="c0">&nbsp;so it can be used there only as a solo model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2b. MDX23C-InstVoc HQ 2 - worse SDR, sometimes less vocal residues</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older MDX models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>2c. narrowband </span><span class="c22">MDX23C_D1581 </span><span>(model_2_stem_061321, 14.7kHz)</span><span class="c22">&nbsp;</span><span>- better SDR vs HQ_3 and voc_ft (single model file </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/MDX23C_D1581.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742867645&amp;usg=AOvVaw1sSHPaIbq0yYbo6_uv5rUF">download</a></span><span class="c0">&nbsp;[just for archiving purposes]) </span></p><p class="c1"><span class="c0">&quot;really good, but (...) it filters some string and electric guitar sounds into the vocals output&quot; also has more vocal residues vs HQ_3.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>*</span><span>. narrowband </span><span class="c22">Kim inst</span><span class="c0">&nbsp;(a.k.a. &ldquo;ft other&rdquo;, 17.7kHz) - for the least vocal residues than both above in some cases, and sometimes even vs HQ_3</span></p><p class="c1"><span>*. narrowband </span><span class="c22">inst 3</span><span class="c0">&nbsp;- similar results, a bit more muddy results, but also a bit more balanced in some cases</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox &ldquo;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/small_inst.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742868672&amp;usg=AOvVaw2h0p4oJMbwKjdC9o8SP_ba">small</a></span><span>&rdquo; inst Mel Roformer model for faster inference than most Roformers | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-small/resolve/main/config_melbandroformer_small.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742868900&amp;usg=AOvVaw3WQMD_E5XiSpgdONRS1Xnh">yaml</a></span><span class="c0"><br>Be aware that it can have some audible faint constant residues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">*. narrowband inst 1 (418) - might preserve hihats a bit better than in inst 3. </span></p><p class="c1"><span class="c0">3. narrowband voc_ft - sometimes can give better results with more clarity than even HQ_3 and kim inst for instrumentals, but it can produce more vocal residues, as it&rsquo;s typically a vocal model and that&rsquo;s how these models behave in MDX-Net v2 arch (you can use it e.g. as input for Matchering for cleaner, but more muddy model result)</span></p><p class="c1"><span class="c0">*. less often - inst main (496) [less aggressive vs inst3, but gives more vocal residues] </span></p><p class="c1"><span class="c0">*. or eventually also try out HQ_1 - (epoch 450)/HQ_2 (epoch 498) or earlier 403, 338 epochs, or even 292 is also used frequently from time to time) when VIP code is used.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4 c20"><a class="c3" href="#h.6q2m0obwin9u">Recommended MDX and Demucs parameters</a></span><span class="c20">&nbsp;in UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ensemble of only models without bleeding in single models results for specific song</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.oxd1weuo5i4j">DAW ensemble</a></span><span class="c0">&nbsp;of various separation models - import the results of the best models into DAW session set custom weights by changing their volume proportions</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Captain Curvy method:</span></p><p class="c1"><span>&quot;I just usually get the instrumentals [with MDX23C] to phase invert with the original song, and later [I] clean up [the result using] with voc ft&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4 c20"><a class="c3" href="#h.p1fyricuv1j8">How to check whether a model in UVR5 GUI is vocal or instrumental?</a></span></p><p class="c1"><span>(although in MDX23C there is no clear boundary in that regard)</span><hr style="page-break-before:always;display:none;"></p><h6 class="c1 c27" id="h.n8ac32fhltgg"><span class="c22">&gt;</span><span>&nbsp;</span><span class="c42 c12 c15 c33">for vocals</span></h6><h6 class="c1 c27" id="h.hkry3b4x7kv0"><span class="c20 c11">(click </span><span class="c4 c20 c11"><a class="c3" href="#h.vg1wnx1dc4g0">here</a></span><span class="c20 c11">&nbsp;for Karaoke, or </span><span class="c4 c20 c11"><a class="c3" href="#h.2vdz5zlpb27h">here</a></span><span class="c20 c11">&nbsp;for instrumentals)</span></h6><p class="c1"><span class="c42 c15 c36 c11 c30">MVSEP models without download links can be used only on MVSEP</span></p><p class="c1"><span class="c20 c37">(removing/isolating vocals from AI music can give muddy results and capture other unrelated instruments easily; also, Roformers tend to stress plosives which weren&rsquo;t in the original vocals at time - cristouk)<br>* - commonly used public models at the moment</span><span class="c0"><br></span></p><p class="c1"><span class="c23 c15 c20">There&rsquo;s no one, the best model. It depends on a song. <br>Most commonly used models for the doc&rsquo;s date (categorized below):</span></p><p class="c1"><span class="c0">BS-Roformer 2025.07, Big Beta 6X/6, vocfv7beta1 &amp; 2, voc_fv4, Big Beta 5e</span></p><p class="c1"><span class="c0">Resurrection (voc. variant below), Revive 3e/2.<br>Anvuev BS-Roformer vocals, Mel FT2 Bleedless, voc_fv6, voc_fv5, Becruily voc, FT3 Preview.</span></p><p class="c1"><span><br></span><span class="c6">Bleedless models #1</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- BS-Roformer 2025.07 only on MVSEP - free with longer queue</span></p><p class="c1"><span class="c0">Vocals bleedless: 38.25, fullness: 17.23, SDR: 11.89<br>The biggest bleedless metric for a single model so far. Compared to previous models, picks up backing vocals and vocal chops greatly where 6X struggles, and fixes crossbleeding and reverbs where in some songs previous models struggled before. <br>Sometimes you might still get better results with Beta 6X or voc_fv4 (depending on a song). &ldquo;Very similar to SCNet very high fullness without the crazy noise&rdquo; - dynamic64, &ldquo;handles speech very well. Most models get confused by stuff like birds chirping (they put it in the vocal stem), but this model keeps them out of the vocal stem way more than most. I love it!&rdquo;</span></p><p class="c1"><span>Works the best for orchestral choirs out of the long </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1421129357677559970/1421447212881154068&amp;sa=D&amp;source=editors&amp;ust=1765035742875803&amp;usg=AOvVaw3lZoGND-D_7qQyQA7VMVl8">list</a></span><span class="c0">&nbsp;of other models (.elgiano).</span></p><p class="c1"><span class="c0">It can be better for metal both for vocal and instrumentals than the mesk&rsquo;s models, a lot of the times (and sometimes the best).</span></p><p class="c1"><span class="c0">The first iteration of the model (2025.06: 37.83/17.30/11.82) received two small updates and was replaced by 2025.07.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer 2024.10 (Bas Curtiz model fine-tuned by ZFTurbo) on MVSEP <br>Vocals bleedless: 37.80, fullness: 17.07, SDR 11.28<br>Small amounts of bleeding from instrumentals (inst. bleedless 39.20), might struggle with flute occasionally, good enough for </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rentry.co/RVC-dataset-RX11&amp;sa=D&amp;source=editors&amp;ust=1765035742876942&amp;usg=AOvVaw2EKLh6H9rfgMUUPndJ3vjW">creating RVC datasets</a></span><span>.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mel-Roformer Bas Curtiz edition (/w Marekkon5) (trained on also ZFTurbo dataset) on MVSEP (older version of 2024.10 model)</span></p><p class="c1"><span class="c0">Vocals bleedless: 39.20, fullness: 16.24, SDR 11.18.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa Kim Mel-Band Roformer Bleedless FT2 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742877791&amp;usg=AOvVaw2M32rAWk_aaG2Vk9KHxYNp">download</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742877988&amp;usg=AOvVaw0_UQjkP8yX_rlo5HkZcaMN">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742878102&amp;usg=AOvVaw2b5fYoAsVPYGJ86AnpOr5t">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742878190&amp;usg=AOvVaw2-YcY5_DeikXKcKqvXcdcR">2</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR instruction</a></span></p><p class="c1"><span class="c0">Vocals bleedless 39.30 (better than Mel-Kim), fullness 15.77 | SDR 11.05<br>(voc. fullness is worse than Mel Kim - 16.26, <br>inst. bleedless is still lower than base Mel-Kim model: 46.30 vs 46.56)</span></p><p class="c1"><span class="c0">&ldquo;I usually use big beta 6x, big beta 5e if that fails and FT2 bleedless if I want very low noise or instruments are quiet (it gets muddy quick)&rdquo; - Rainboom Dash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anvuew BS-Roformer vocal model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/BS-RoFormer&amp;sa=D&amp;source=editors&amp;ust=1765035742879094&amp;usg=AOvVaw0krM89ulRWi83jOenfqP5Y">download</a></span></p><p class="c1"><span>Doesn&#39;t work on the UVR&rsquo;s RTX 5000 patch - then use </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span class="c0">&nbsp;instead.</span></p><p class="c1"><span>Can be muddy. Not so balanced like Beta6X or vocfv7beta1, but &ldquo;it properly doesn&#39;t capture the instrument </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1KdZEEMTezU4iQhv9-_zLpwPL9A84G8_m/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742879621&amp;usg=AOvVaw0OmK2YGLkXUMgqI3rEqfqD">here</a></span><span>. E</span><span class="c0">ven FT2 bleedless gets tricked by this part, but this does just fine.&rdquo; - rainboomdash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa&rsquo;s BS-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/resolve/main/BS-Roformer-Resurrection.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742880044&amp;usg=AOvVaw25fyP3kNdGDxJoPkjDwWmo">Resurrection</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/resolve/main/BS-Roformer-Resurrection-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742880220&amp;usg=AOvVaw2vTk5qm_ULIZQ0BLFuAlzl">yaml</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742880432&amp;usg=AOvVaw2fpfqVZpuMe0y7Sw6r1M2C">Colab</a></span><span>&nbsp;*</span></p><p class="c1"><span class="c0">Vocal bleedless: 39.99, fullness: 15.14, SDR: 11.34</span></p><p class="c1"><span class="c0">Shares some similarities with the SW model, including small size (might be a retrain). The default chunk_size is pretty big, so if you run out of memory, decrease it to e.g. 523776.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/resolve/main/bs_roformer_revive2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742881124&amp;usg=AOvVaw2cYyDKbWKUVySVym5PNkeC">Revive 2</a></span><span>&nbsp;BS-Roformer fine-tune of viperx 1297 model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/resolve/main/config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742881318&amp;usg=AOvVaw3kqkKEW3cyYHqTM6cJ-Hvf">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742881538&amp;usg=AOvVaw18Zn3khwGgNwStpyNBiDvL">Colab</a></span></p><p class="c1"><span>Voc. </span><span class="c22">bleedless</span><span class="c0">: 40.07, fullness: 15.13, SDR: 10.97</span></p><p class="c1"><span class="c0">&ldquo;has a Bleedless score that surpasses the FT2 Bleedless&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;can keep the string well&rdquo;</span></p><p class="c1"><span class="c0">It&rsquo;s depth 12 and dim 512, so the inference is much slower than some newer Mel-Roformers.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- BS-Roformer 2024.08 (viperx model fine-tuned v2 by ZFTurbo) on MVSEP <br>Vocals </span><span class="c20">bleedless</span><span class="c0">: 37.61, fullness: 15.89, SDR: 11.32<br>Good for inverts, Dolby, lots of harmonies, BGVs. Good or even the best vocal fullness for some genres ~Isling, decent all-rounder, but might be muddier than Mel models here, although it gives less vocal residues than all the Mel Kim fine-tune models here, can be also used for RVC). &ldquo;I&#39;ve found it very useful for extremely quiet vocals that Mel couldn&#39;t extract&rdquo; - Dry Paint Dealer. It&rsquo;s a second MVSEP&rsquo;s fine-tune of viperx model.<br>Iirc, it&rsquo;s used as a preprocessor model for &quot;Extract from vocals part&quot; feature on MVSEP.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Ensemble 11.93 (vocals, instrum) (2025.06.28) - only for paid premium users</span></p><p class="c1"><span class="c0">Vocals bleedless: 36.30, fullness: 17.73, SDR: 11.93</span></p><p class="c1"><span class="c0">Surpassed sami-bytedance-v.1.1 on the multisong dataset SDR-wise.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- BS-Roformer SW 6 stem </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/undef13/splifft/releases&amp;sa=D&amp;source=editors&amp;ust=1765035742884120&amp;usg=AOvVaw0-8OyU14qNP0thpagk9K9_">(</a></span><span>MVSEP, Colab</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Colab_Inference_BSRofo_SW_fp16.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742884305&amp;usg=AOvVaw22hUpXdo2eiE9mi2y4bcWb">)</a></span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/folder/R3BzBSgD%23sz2XIOk3y0-LS4hIQOQKYQ&amp;sa=D&amp;source=editors&amp;ust=1765035742884399&amp;usg=AOvVaw0-PV2u8FTdDW5VOqu7HeE7">/</a></span><span class="c0">&nbsp;Vocals only *</span></p><p class="c1"><span class="c0">Vocals bleedless: 36.06, fullness: 16.95, SDR 11.36</span></p><p class="c1"><span class="c0">Good for some deep voices.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Bleedless #2 (less)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa Mel-Roformer Big Beta 6X vocal </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/resolve/main/big_beta6x.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742884975&amp;usg=AOvVaw35IzffmCLao29xdTE0H9o3">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/resolve/main/big_beta6x.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742885101&amp;usg=AOvVaw374mTYysl4P8PEzHYlDLk1">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742885280&amp;usg=AOvVaw07I5C2dnKLo0kIpzaWKzEf">Colab</a></span><span>&nbsp;| AI Hub </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Eddycrack864/UVR5-UI/blob/main/UVR_UI.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742885422&amp;usg=AOvVaw1L_d5nkwt0zagddU3TTaog">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742885521&amp;usg=AOvVaw0P3-5-y0GpB9CQd9DepEzV">Huggingface</a></span><span>&nbsp;| uvronline</span><span><br>voc bleedless: 35.16, </span><span class="c20">fullness</span><span class="c0">: 17.77, SDR: 11.12</span></p><p class="c1"><span class="c0">&ldquo;it is probably the highest SDR or log wmse score in my model to date.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;There&#39;s some noise audible, it doesn&#39;t sound as clean when you compare to a more bleedless model (...) but it&#39;s certainly not fullness... (...) I think calling it bleedless wouldn&#39;t be crazy... makes more sense than &quot;middle of the road&quot; - rainboomdash<br>&ldquo;Significantly better&rdquo; than 5e for some people, although slower. Some leaks into vocal might occur, plus &ldquo;The biggest problem with the model is the remaining background noise. If it were cleaner, it would already be an almost perfect result.&rdquo; - musictrack</span></p><p class="c1"><span class="c0">&ldquo;6X has a lot less noise on vocals, but it&#39;s pretty muddy. I would prefer something in between [5e and 6X]. I tried to apply the phase [fixer/swapper] to the vocals and the noise was reduced, but only slightly.&rdquo; - Aufr33</span></p><p class="c1"><span class="c0">Some people might prefer fv5 instead [at least on some songs] ~5b</span></p><p class="c1"><span class="c0">&ldquo;6x is picking up BV just fine, where voc fv4 is failing&rdquo; - Rainboom Dash</span></p><p class="c1"><span class="c0">Training details:</span></p><p class="c1"><span class="c0">&ldquo;dim 512, depth 12. It is the largest Mel-Band Roformer model I have ever uploaded.&rdquo; - &ldquo;the same as Bas Curtiz Edition&rdquo; model. It has a bigger SDR vs smaller depth 6 Big Beta 6 model. &ldquo;I&#39;ve added dozens of samples and songs that use a lot of them to the dataset&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Fullness models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- * Unwa </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/blob/main/bs_roformer_revive3e.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742888130&amp;usg=AOvVaw0h5W-SwoL_WfneGs9XwEDE">bs_roformer_revive3e</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/resolve/main/config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742888264&amp;usg=AOvVaw3ZMSUsgfQpseC-1jnaGq2c">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742888502&amp;usg=AOvVaw1XBW-FuJh9m4T7c0eiHaNv">Colab</a></span><span><br>voc bleedless: 30.51, </span><span class="c22">fullness</span><span>: 21.43, SDR: 10.98</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8337&amp;sa=D&amp;source=editors&amp;ust=1765035742888705&amp;usg=AOvVaw26EXRSxGTj0Q-FrM83Wv7O">&lsquo;</a></span></p><p class="c1"><span class="c0">&ldquo;A vocal model specialized in fullness.</span></p><p class="c1"><span class="c0">Revive 3e is the opposite of version 2 &mdash; it pushes fullness to the extreme.</span></p><p class="c1"><span class="c0">Also, the training dataset was provided by Aufr33. Many thanks for that.&rdquo; - Unwa</span></p><p class="c1"><span class="c0">&ldquo;seems to sound better than beta5e, it sounds fuller, but this also means it sounds noisier&rdquo; - gilliaan. For some people, it&rsquo;s even the best.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">More fullness less bleedless</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- * Gabox experimental Mel-Roformer voc_fv6 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_fv6.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742889827&amp;usg=AOvVaw11NYs-fQjZSR1EBT1c8Yqu">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742889968&amp;usg=AOvVaw2jiIVTS4_6P8KmNpBgTXIJ">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742890150&amp;usg=AOvVaw0V7XGFpR4bWjdKPUQMv1kr">Colab</a></span></p><p class="c1"><span>voc bleedless: 26.61, </span><span class="c12">fullness</span><span class="c0">: 24.93, SDR: 10.64 <br>&ldquo;Definitely not bleedless&rdquo; - rainboomdash, &ldquo;Sounds like b5e with vocal enhancer. Needs more training, some instruments are confused as vocals&rdquo; - Gabox. &ldquo;fv6 = fv4 but with better background vocal capture&rdquo; - neoculture</span></p><p class="c1"><span class="c0">&ldquo;very indecisive about whether to put vocal chops in the vocal stem or instrumental stem.</span></p><p class="c1"><span class="c0">sometimes it plays in vocals and fades out into instrumental stem and sometimes it just splits it in half kinda and plays in both at the same time lol&rdquo; - Isling</span></p><p class="c1"><span class="c0">&ldquo;I think is the fullest vocal model I&#39;ve heard, aside from maybe the scnet high fullness ones lol/ Oh and revive 3e and b5e are full too but yeah.&rdquo; - Musicalman</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- SCNet XL very high fullness on MVSEP</span></p><p class="c1"><span class="c0">voc bleedless: 25.30, fullness: 23.50, SDR: 10.40</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- SCNet XL IHF (high instrum fullness by bercuily)</span></p><p class="c1"><span class="c0">voc bleedless: 25.48, fullness: 22.70, SDR: 10.87</span></p><p class="c1"><span class="c0">(it was made mainly for instrumentals, but &ldquo;It can also be an insane vocal model too&rdquo;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">- MVSEP SCNet XL IHF</span></p><p class="c1"><span class="c0">voc bleedless 28.31, fullness 17.98, SDR: 11.11</span></p><p class="c1"><span class="c0">&ldquo;It has a better SDR than previous versions. Very close to Roformers now.&rdquo; also, vocal bleedless is the best among all SCNet variants on MVSEP. Metrics. IHF - &ldquo;Improved high frequencies&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;Certainly sounds better than classic SCNet XL (...) less crossbleeding of vocals in instrumental so far, and handle complex vocals better&rdquo; - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20 c58">Middle of the road #1 (lower fullness)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox vocfv7 beta 2 Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/vocfv7beta2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742893329&amp;usg=AOvVaw0NXWwatcKf1R9rVl_wH--N">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742893474&amp;usg=AOvVaw0wxTC8-rVuNd-lLi-8p_r-">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742893668&amp;usg=AOvVaw1fhuTsojwS8GSjaalfIaH8">Colab</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">voc bleedless: 31.55, fullness: 20.44, SDR: 10.87</span></p><p class="c1"><span class="c0">&ldquo;fullness went down a little bit&rdquo; vs beta 1 (...) Definitely an improvement over fv4 (...) still quite a bit fuller than big beta 6x, but has less noise than even fv4 (...) at least when the instruments are loud, fv7beta2 is usually quite a bit less noisy than fv4, while still maintaining a decent amount of fullness... it is a bit less, but not too much (...) both are pretty noisy with fv4 (...) sometimes the noise can be pretty significant with fv7beta1, and fv7beta2 may have the fullness you desire. (...) &ldquo;I&#39;m really liking the balance of fullness and noise for most songs. fv4 and fv6/fv7beta1 are usually pretty noisy... this is less noisy, but still has a good amount of fullness.&rdquo; still gonna have an issue with backing vocals compared to fv7beta1 sometimes&hellip; (...) &ldquo;Fv7beta2 has still been significantly better with BV than fv4, despite quite a bit less noise&rdquo; but &ldquo;significant issues on one song, while fv6/fv7beta1 didn&#39;t&rdquo; - rainboomdash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/vocfv7beta3.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742895740&amp;usg=AOvVaw0Yfrb6bZtWDxad3XarU1wK">vocfv7beta3</a></span><span>&nbsp;Mel-Roformer | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742895899&amp;usg=AOvVaw2LdPbCAzFR15msbmajHwsr">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742896082&amp;usg=AOvVaw0yMwdpCirarXlpfbBKhH7H">Colab</a></span></p><p class="c1"><span class="c0">voc bleedless 30.83, fullness 21.82, SDR 10.80</span></p><p class="c1"><span class="c0">&ldquo;beta 1 and 2... eh, pretty close to same instrumental bleed,</span></p><p class="c1"><span class="c0">but beta 3 def a step up from the two songs I compared (...)</span></p><p class="c1"><span class="c0">most songs so far, fv7beta3 is fuller than fv7beta1,</span></p><p class="c1"><span class="c0">def less robotic sounding at times (when a voice gets quiet/hard to capture, and it just fails).</span></p><p class="c1"><span class="c0">Just had another song where fv7beta1 was fuller than fv7beta3, but it was also a lot noisier</span></p><p class="c1"><span class="c0">large majority of the songs I tested, fv7beta3 was fuller... I think fv7beta3 is usually a bit noisier than fv7beta1? But also sounds fuller in those cases, I&#39;d say it&#39;s generally worth it</span></p><p class="c1"><span class="c0">instrumental bleed, usually worse with fv7beta3 versus fv7beta1, but it depends</span></p><p class="c1"><span class="c0">fv7beta2 is always less full/less noise, but only slightly less instrumental bleed than fv7beta1&rdquo; - rainboomdash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox Mel-Roformer voc_fv7 beta 1 (a.k.a. vocfv7beta1) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/vocfv7beta1.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742898004&amp;usg=AOvVaw0Ru9aVgbdskCMfxS5jOJGi">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742898149&amp;usg=AOvVaw3mXUYO0Bd4holyGldh1fCK">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742898326&amp;usg=AOvVaw0qUM1nQeIQZYkTkc-KfBFD">Colab</a></span></p><p class="c1"><span class="c0">voc bleedless: 30.81, fullness: 21.21, SDR: 10.96 </span></p><p class="c1"><span class="c0">&ldquo;one step below the extreme fullness models (...) fv6 on average is more full&rdquo; - rainboomdash. &quot;Just a better fv4 it seems, better bleedless&quot; (fullness: 21.33, bleedless: 29.07, SDR 10.58)</span></p><p class="c1"><span class="c0">vs voc_fv4 &quot;It is noisier... Kinda closer to beta 5e?&rdquo; &ldquo;It&#39;s slightly less noise and fullness than beta 5e but picking up the backing vocals REALLY well, significantly better than beta 5e&rdquo;</span></p><p class="c1"><span class="c0">But it&#39;s pulling the backing vocals out even better than 5e&rdquo; &ldquo;the backing vocals are so good!</span></p><p class="c1"><span class="c0">&ldquo;it does have significant synth bleed, too... &nbsp; it at least wasn&#39;t coming through at full volume</span></p><p class="c1"><span class="c0">when I say fullness, I specifically mean how muddy it sounds&rdquo; - Raiboom Dash</span></p><p class="c1"><span class="c0">_</span></p><p class="c1"><span>- Gabox Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_fv4.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742899851&amp;usg=AOvVaw10_XF_F9GnvVz1fFKoSGPZ">voc_fv4</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742900017&amp;usg=AOvVaw1wwONqw5_HVvVV-PfNcWR1">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742900203&amp;usg=AOvVaw1rWG-Xu4oASIJ1hN9yqyXB">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742900304&amp;usg=AOvVaw1m8ynxxK6bV6Ws1w0GPhoS">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742900386&amp;usg=AOvVaw2mAdQWAJ2FUvxS151FtPnt">2</a></span><span class="c0">&nbsp;*</span></p><p class="c1"><span class="c0">voc bleedless 29.07, fullness 21.33, SDR 10.58</span></p><p class="c1"><span class="c0">&ldquo;Very clean, non-muddy vocals. Loving this model so far&rdquo; (mrmason347)</span></p><p class="c1"><span>Good for anime and </span><span class="c22">RVC </span><span class="c0">purposes, currently the best public model for it (codename)</span></p><p class="c1"><span class="c0">&ldquo;The important thing for an RVC dataset is to get lead vocals so fv4 is good for that</span></p><p class="c1"><span class="c0">The newer karaoke models are also helpful&rdquo; - Ryan</span></p><p class="c1"><span class="c0">Some might prefer voc_gabox2 instead, occasionally - chroniclaugh.</span></p><p class="c1"><span class="c0">The opposite of Beta6x which has &ldquo;lower noise but [is] less full/muddier (...) noise/muddiness seems between 6x and 5e, but even 6x is picking up BV just fine, where voc fv4 is failing&rdquo;</span></p><p class="c1"><span class="c0">Some people might want to test it with even overlap 32, and then:</span></p><p class="c1"><span class="c0">&ldquo;It&#39;s close to perfect, the only thing is it kinda struggled with picking up the adlibs and the delay, but the lead vocal is almost perfect I think. (...) on another song (...) 5e is just too noisy and 6x is muddy, fv4 is best of both worlds (...) has segments with constant significant vocal bleed (for the most part, it&#39;s not audible at all) (...) I was trying to get an acapella and every model failed except this one. It&#39;s not perfect, but I guess some songs are just too hard for the AI.&rdquo; - Rainboom Dash</span></p><p class="c1"><span class="c0">Good also for instrumentals, if you need less vocal residues than typical instrumental Roformers (even less than Mel Kim, FT2 Bleedless, or Beta 6X - makidanyee.</span></p><p class="c1"><span class="c0">&ldquo;even beta 6x is a lot better at pulling that background vocal out than voc fv4...</span></p><p class="c1"><span class="c0">and that&#39;s a less full model. hmm, fv6 is noisier and also not picking up the backing vocals as full as the last mel band roformer&rdquo; - Rainboom Dash</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa Mel big beta 5e vocal model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742903502&amp;usg=AOvVaw2_0FgOP58Kk43_DpjagBXs">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742903620&amp;usg=AOvVaw0_jPWdNTnx8VurGAJa_iR-">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742903708&amp;usg=AOvVaw2Rq-9hB1jxsOTYqt6Wijmm">2</a></span><span>&nbsp;| </span><span>MVSEP | uvronline via special link </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742903848&amp;usg=AOvVaw2LTqjegVs7nR1wR13cvL1e">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742903929&amp;usg=AOvVaw2CLWwxSZRM5DOpSWNnoEWs">premium</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742904063&amp;usg=AOvVaw3F1Si-hsY50XHUNNyV0qX9">MSST-GUI</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span><br>Model </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742904213&amp;usg=AOvVaw3UmkSYk5g5S_mE9AK0f5Dz">files</a></span><span>&nbsp;| yaml: big_beta5e.yaml or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1YRv1j0zMs9hk3-On2z6uwfZbsQ7l1LFP/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742904362&amp;usg=AOvVaw0Wjg3ltDMWaWbeKdQ0o08k">fixed</a></span><span class="c0">&nbsp;yaml for AttributeError in UVR<br>voc bleedless: 32.07, fullness: 20.77 (the biggest for now), vocals SDR: 10.66</span></p><p class="c1"><span class="c0">&ldquo;feel so full AF, but it has noticeable noise similar to lew&#39;s vocal enhancer&rdquo;<br>You can alleviate some of this noise/residues by using phase fixer/swapper and using becruily vocals model as reference (imogen).<br>It seems to fix some issues with trumpets in vocal stem - maxi74x1.<br>&ldquo;It&#39;s noisy and, IDK, grainy? When the accompaniment gets too loud. (...) Definitely not muddy though, which is a welcome change IMHO. I think I prefer beta 4 overall&rdquo; - Musicalman &ldquo;ending of the words also have a robotic noise&rdquo; - John UVR<br>&ldquo;Perhaps a phase problem is occurring&rdquo; - unwa. Phase swapper doesn&rsquo;t fix the issue (it works for inst unwa&rsquo;s models).<br>If you try big beta 5e on a song that has lots of vocal chops, the vocal chops will be phasing in and out and sound muddy (Isling).</span></p><p class="c1"><span class="c0">&ldquo;Excellent for ASMR, for separating Whispers and noise, the quality is super good</span></p><p class="c1"><span class="c0">That&#39;s good when your mic/pc makes a lot of noise. All the denoise models are a bit too harsh for ASMR (giliaan)&rdquo;</span></p><p class="c1"><span class="c0">Worse for RVC than Beta 4 model below (codename/NotEddy)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer vocal by becruily </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-vocals/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742906423&amp;usg=AOvVaw3I-A5g_qmEPzpvUOV9foEY">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1V__MDSd9h47tgk3CCZUhbfcZz9A_oJee/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742906553&amp;usg=AOvVaw270EgPgWSQKMtA9WacRnIT">config</a></span><span>&nbsp;for ensemble in UVR | MVSEP | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742906772&amp;usg=AOvVaw27Eku6-TwsFF58cDHuycMK">Colab<br></a></span><span>voc bleedless: 31.26, fullness: 20.72 (on pair with 5e), SDR: 10.55 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742906970&amp;usg=AOvVaw2yDCujGuCWS7nywczBbEbd">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742907059&amp;usg=AOvVaw1-8PCTqCYq-Bpd5SdWxHkm">2</a></span></p><p class="c1"><span class="c0">Lower bleedless than 5e,&ldquo;pulling almost studio quality metal screams effortlessly, wOw ive NEVER heard that scream so cleanly&rdquo;</span></p><p class="c1"><span class="c0">(on older UVR beta patches) If you use lower dim_t like 256 at the bottom of config for slower GPU these are the first models to have muddy results with it.<br>Consider setting 485100 chunk_size in the yaml for the highest SDR.<br>Currently used on x-minus/uvronline as a model for phase fixer.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_fv5.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742908001&amp;usg=AOvVaw3Uz8EkLomZDBZ-9MDjAQHN">voc_fv5</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742908135&amp;usg=AOvVaw35-jgSkvrM0S77Al-8iymx">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742908331&amp;usg=AOvVaw3S-_y3uCuAdeXob-b6qW48">Colab</a></span></p><p class="c1"><span class="c0">voc bleedless: 29.50, fullness: 20.67, SDR: 10.56</span></p><p class="c1"><span>&ldquo;fv5 sounds a bit fuller than fv4, but the vocal chops end up in the vocal stem. In my opinion, fv4 is better for removing vocal chops from the vocal stem&rdquo; - neoculture. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1369232029291511881&amp;sa=D&amp;source=editors&amp;ust=1765035742908969&amp;usg=AOvVaw2DYCLNwtaqnAHzzD9Aax_3">Examples</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Other/older models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/vocals/voc_gabox2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742909396&amp;usg=AOvVaw3-F1cklCBcI9M2uaRyhtJS">voc_gabox2</a></span><span>&nbsp;model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/vocals/voc_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742909561&amp;usg=AOvVaw0wqzXAl-ifeQ_abtN8NuLv">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742909784&amp;usg=AOvVaw0kxGnTu59udEuSYTYu0M6B">Colab</a></span></p><p class="c1"><span class="c0">Vocal bleedless: 33.13, fullness: 18.98, SDR: 10.98</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox Mel-Roformer Vocal F (fullness) v3 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/vocals&amp;sa=D&amp;source=editors&amp;ust=1765035742910166&amp;usg=AOvVaw0wbPnY2gqXPVFlvFTHfDEd">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742910347&amp;usg=AOvVaw2ReE8EPm1Kqt-FrCugbMGi">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742910452&amp;usg=AOvVaw3evjtsSRBa9ziukk7tsB5Q">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742910535&amp;usg=AOvVaw2LCjwpOmm7xqSqHdier91W">2</a></span></p><p class="c1"><span class="c0">voc bleedless: 32.15, fullness 19.97</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox Mel-Roformer Vocal F (fullness) v2 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/vocals&amp;sa=D&amp;source=editors&amp;ust=1765035742910897&amp;usg=AOvVaw2uXPaVZuxwXfWC3KWcEc3z">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742911020&amp;usg=AOvVaw2QIMngO-GDhGvMQ_xIwGiL">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742911122&amp;usg=AOvVaw0s9YVDjcsnaF1nqD9V3mSE">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742911206&amp;usg=AOvVaw0vfN6GTGz5e5nspdNWhwio">2</a></span></p><p class="c1"><span class="c0">voc bleedless: 33.40, fullness: 19.31</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aname Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/MelBandRoformers/blob/main/FullnessVocalModel.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742911529&amp;usg=AOvVaw2OUIw88owrHtJSunEovDjD">FullnessVocalModel</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/MelBandRoformers/blob/main/config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742911635&amp;usg=AOvVaw0fPbMg4loBm-Obcq_g5o6_">yaml</a></span><span>) model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742911762&amp;usg=AOvVaw1NoLUymKBxvblcL4P8M2HE">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742911875&amp;usg=AOvVaw2K-8ncYRaZI6pF6HUQ9UFT">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742911956&amp;usg=AOvVaw1PJhISQ3N8HWo_pyb8iewG">2</a></span></p><p class="c1"><span class="c0">Vocals bleedless: 32.98 (less than beta 4), fullness: 18.83 (less than big beta 5e/voc_fv4/becruily, more than beta 4)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox Mel-Roformer voc_gabox (Kim/Unwa/Becruily FT) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers&amp;sa=D&amp;source=editors&amp;ust=1765035742912451&amp;usg=AOvVaw2jjOm9Z-Dutj5cC-JP433e">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742912587&amp;usg=AOvVaw0xON7ZENqiMTyf8L1AKpJW">Colab</a></span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742912683&amp;usg=AOvVaw1KZcEJNPuuLAjXpGTCHIIY">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742912762&amp;usg=AOvVaw008dz65ypXNhhrp0rdT1CA">2</a></span></p><p class="c1"><span class="c0">voc bleedless: 34.66 (better than 5e, beta 4 and becruily voc), fullness 18.10 (on pair with beta 4, worse than 5e and becruily)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer unwa&rsquo;s beta 4 (Kim&rsquo;s model fine-tuned) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742913298&amp;usg=AOvVaw0-4VNoTEE6xirZCHQklabP">download</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742913479&amp;usg=AOvVaw2OQ-YetKQEaDbDXQGuzn6U">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742913589&amp;usg=AOvVaw24Re36ujfdW7ggZU9VhVEz">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742913672&amp;usg=AOvVaw3txxDAP0xXJeOM_nubvOaS">2</a></span></p><p class="c1"><span class="c0">Vocals bleedless: 33.76, fullness: 18.09<br>&ldquo;Clarity and fullness&rdquo; - even compared to newer models above.</span></p><p class="c1"><span class="c0">Beta 1/2 were more muddy than Kim&rsquo;s Roformer, potentially a bit less of residues, a bit more artificial sound. Ringing issues in higher frequencies fixed in beta 3 and later. It&rsquo;s good for RVC (and favourite codename&rsquo;s public model for RVC before voc_fv4 was released). Fuller vocals than Bas Curtiz FT on MVSEP (but can bleed more synths) ~becruily<br>Unwa&rsquo;s vocal models are capable of handling sidechain in songs - John UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Bleedless models #2</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- BS-Roformer Revive unwa&rsquo;s vocal </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/resolve/main/bs_roformer_revive.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742914902&amp;usg=AOvVaw1axPeVzHnGt5Oi5BUeGHIV">model</a></span><span>&nbsp;experimental | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Revive/resolve/main/config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742915031&amp;usg=AOvVaw2mLUx28dDTBPKZUmQsdNEL">yaml</a></span><span class="c0">&nbsp;<br>(viperx 1297 model fine-tuned) </span></p><p class="c1"><span class="c0">Voc. bleedless: 38.80, fullness: 15.48, SDR: 11.03</span></p><p class="c1"><span>&ldquo;Less instrument bleed in vocal track compared to BS 1296/1297&rdquo; but it still has many </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1226334240250269797/1371215438352224307&amp;sa=D&amp;source=editors&amp;ust=1765035742915478&amp;usg=AOvVaw3zBInzJywXQduDMnp4Dsms">issues</a></span><span class="c0">, &ldquo;has fewer problems with instruments bleeding it seems compared to Mel. (...) 1297 had very few instrument bleeding in vocal, and that Revive model is even better at this.</span></p><p class="c1"><span class="c0">Works great as a phase fixer reference to remove Mel Roformer inst models noise&rdquo; (dca)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- SYHFT V5 Beta - only on x-minus/uvronline (still available only with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742916135&amp;usg=AOvVaw0CctO9kK--eY1RFtuFSVUL">this</a></span><span>&nbsp;link for premium users, and for </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?test&amp;sa=D&amp;source=editors&amp;ust=1765035742916254&amp;usg=AOvVaw34mlRHKoCyPGjWwEcICtIz">free</a></span><span>)</span></p><p class="c1"><span class="c0">Vocal bleedless: 37.27, fullness, 16.18, SDR: 10.82</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Other models #2</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa&rsquo;s Kim Mel-Band Roformer FT2 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742916738&amp;usg=AOvVaw2xKXFz-OLpYfI89JBpVuCP">model</a></span><span>&nbsp;|</span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742916969&amp;usg=AOvVaw1ew65JVVdg9EL6FAEbzlm1">Colab</a></span><span><br>Vocals bleedless: 37.06, fullness: 16.61 (fullness worse vs the previous FT, but both metrics are better than Kim&rsquo;s)</span><span><br>It tends to muddy instrumental outputs at times, similarly like the OG Kim&rsquo;s model was doing, which didn&rsquo;t happen in the previous FT below. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7714&amp;sa=D&amp;source=editors&amp;ust=1765035742917501&amp;usg=AOvVaw3ovFGlLJ0HdTGdmpMKwWkV">Metrics</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa Kim Mel-Band Roformer FT3 Preview | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/blob/main/kimmel_unwa_ft3_prev.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742917822&amp;usg=AOvVaw0Nx8MDnObLwKYfnCGKRa-t">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/resolve/main/config_kimmel_unwa_ft.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742917955&amp;usg=AOvVaw2soI_JOHHfO194LxR_ddQx">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742918139&amp;usg=AOvVaw2aIP2GJCJUzxazlRn7rNTF">Colab</a></span><span>&nbsp;| uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742918274&amp;usg=AOvVaw15_QCJKoaN0gKTThrGPlfr">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742918381&amp;usg=AOvVaw1wpYEtXgOwKkD32QN-n1Yk">premium</a></span><span class="c0">&nbsp;(scroll down)</span></p><p class="c1"><span class="c0">Vocal bleedless: 36.11, fullness: 16.80, SDR: 11.05</span></p><p class="c1"><span class="c0">&ldquo;primarily aimed at reducing leakage of wind instruments to vocals.&rdquo;</span></p><p class="c1"><span class="c0">For now, FT2 has less leakage for some songs (maybe till the next FT will be released)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa&rsquo;s Mel Big Beta 6 vocal </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/resolve/main/big_beta6.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742919104&amp;usg=AOvVaw2k8HL1cb-olLM10VsbSTho">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/blob/main/big_beta6.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742919222&amp;usg=AOvVaw1BcjqwjVeIVnRNR3xj8eTo">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742919409&amp;usg=AOvVaw2ktESoPRE8OPbzwGtiDzZ-">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742919545&amp;usg=AOvVaw1XGjg8K8a7ZpllI_rlvcUK">Huggingface</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742919647&amp;usg=AOvVaw3WyIB5PD8pIhNJ-yQhq1B_">2</a></span><span>&nbsp;| AI Hub </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Eddycrack864/UVR5-UI/blob/main/UVR_UI.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742919798&amp;usg=AOvVaw3nqgYU4M9uhHTBANtJm303">Colab</a></span><span class="c0"><br>Similar to FT series. &ldquo;Although it belongs to the Big series, the characteristics of the model are similar to those of the FT series. (...) this model is based on FT2 bleedless with the dim increased to 512&rdquo;.</span></p><p class="c1"><span class="c0">Muddier than Big Beta 5[e], might be better than FT2 at times.<br>&ldquo;If you liked the output of the Big Beta 5e model, you may not like 6 as much; it does not have the output noise problem of 5e, but instead sacrifices Fullness. (...) Simply put, it is a more conservative model&rdquo; (unwa)</span></p><p class="c1"><span class="c0">For anime and RVC &ldquo;isn&#39;t as audibly and spectrally full as fv4 + can at times have flat-line artifact at the very top, but then, fv4 can sometimes have &quot;crunchy&quot; noise present at some places, so an ensemble of those 2 is probs a good idea (or might be fv4 flash more on less aggressive scenes).&rdquo; codename</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa&rsquo;s Kim Mel-Band Roformer FT vocal </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Kim-Mel-Band-Roformer-FT/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742921244&amp;usg=AOvVaw1EDGmhNlBkHN0gumVZos4Q">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742921431&amp;usg=AOvVaw2OkVCPHkHcMy2_1cb14dAI">Colab</a></span><span><br>Enhanced both voc bleedless 36.75 (vs 36.95) and fullness 16.40 (vs 16.26) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1pPEJpu4tZjTkjPh_F5YjtIyHq8v0SxLnBydfUBUNlbI/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742921669&amp;usg=AOvVaw0_sJG9lt19rRiycbwK9tU-">metric</a></span><span>&nbsp;for vocals vs the original Mel Kim model. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7585&amp;sa=D&amp;source=editors&amp;ust=1765035742921809&amp;usg=AOvVaw3rwww8-nAw2ZoQno1J3NWs">SDR</a></span><span class="c0">-wise it&rsquo;s a tad lower (10.97 vs 11.02).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Tips for separating vocals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Separate with becruily Mel Vocal model and its instrumental model variant, then get vocals from the vocal model, and instrumental from instrumental model, import both stems for the DAW of your choice (can be Audacity) so you&rsquo;ll get a file sounding like original file, then export - so perform a mixdown of both stems, then separate it with vocal model (mrmason347 /Havoc)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;In my testing, I&#39;ve found that SCNet very high fullness (on MVSEP) put through Mel-Roformer denoise (average) and UVR denoise (minimum) has the best acapella result&rdquo; dynamic</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- You can consider using Lew vocal enhancer v1 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/1.0/apollo_model.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742923353&amp;usg=AOvVaw3Tdgqo4wW7twOL-9-FyXAQ">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://config_apollo_vocal.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742923448&amp;usg=AOvVaw13dfbsd_4kOkQ6a6YVO6mw">config</a></span><span>), v2 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model_v2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742923585&amp;usg=AOvVaw15OLimHbvlZd3ZRqWKGs-K">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/config_apollo_uni.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742923731&amp;usg=AOvVaw3jJGo2s0LHQLs_WX5ivOfI">config</a></span><span>) and added to the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Apollo-Colab-Inference/blob/main/Apollo_Audio_Restoration_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742923902&amp;usg=AOvVaw0EhVZDI4Di_LevmMAj6uih">Colab</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1lHnu9-rVvNp5VtU7MFjWx92501Qwfdyf&amp;sa=D&amp;source=editors&amp;ust=1765035742924011&amp;usg=AOvVaw095dPfBDNRMSnq8UEDgZwJ">this</a></span><span>&nbsp;now probably works instead), and it also can be used in the latest UVR Roformer </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sometimes using EQ stressing vocals properly might be beneficial for separation too</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You might potentially also try to experiment with demudder added with the beta patch #14 linked above. Normally demudder works only for instrumentals, but when you switch in the config editor to vocal stem being instrumental and in reverse, then demudder will work vocals. If your model have &ldquo;other&rdquo; stem instead of &ldquo;instrumental&rdquo; or &ldquo;vocal&rdquo;, you&rsquo;ll need to rename it. Demudder requires stem labelled as instrumental to work with.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.i7k483hodhhu"><span class="c18 c15">Ensembles </span></h6><p class="c1"><span class="c6">(for vocals)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- BS Revive 3e + BS 2025.07 (Max FFT) (&ldquo;the best Ensemble for vocals for now&rdquo;) (dca100fb8)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mel Becruily Vocal + MVSEP&rsquo;s BS 2025.07 (Max FFT) (former &ldquo;best vocal ensemble&rdquo;) (-||-)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa&rsquo;s bigbeta5 + becruily vocal - Max spec (midol)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- voc_gaboxFv2 + becruilys vocal (heauxdontlast /gilian)</span></p><p class="c1"><span class="c0"><br>- Unwa &ldquo;Big Beta 4 + Big Beta 5e - Average Spec (&ldquo;really good to reduce the noise while keeping the fullness&rdquo;) (heauxdontlast)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- unwa beta6 + voc_fv4 (good for anime and </span><span class="c22">RVC</span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa beta6x + voc_fv4 (&ldquo;some songs I can use big beta 6x, and it&#39;s enough, others I need to ensemble it with voc_fv4&rdquo;) (Rainboom Dash)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- unwa beta6x + voc_fv6 (&ldquo;would make a good ensemble, but the amount of noise is horrific</span></p><p class="c1"><span>and I heard that </span><span class="c4"><a class="c3" href="#h.j14b9cv2s5d9">phase swapper</a></span><span class="c0">&nbsp;would fix it&rdquo;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- BSRoformer-Viperx1297, BSRoformer-LargeV1 by Unwa, unwa_ft2_bleedless, mel_band_roformer_vocals_becruily, Gabox voc_fv4 - Average/Average Spec (good for cleaning inverts) (AG89)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Models ensembled (inst, voc) available for premium users on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742927681&amp;usg=AOvVaw0rHpam4H7PZsIBymDvqglz">mvsep.com</a></span></p><p class="c1"><span class="c0">(SDR 10.44-11.93 and &ldquo;High Vocal Fullness&rdquo; variants)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.phr57dt8x5mj"><span class="c22">RVC models choice by </span><span class="c4 c22"><a class="c3" href="https://www.google.com/url?q=https://docs.aihub.gg/rvc/resources/dataset-isolation/%23best-models-for-local-eddy-uvr5-ui&amp;sa=D&amp;source=editors&amp;ust=1765035742928115&amp;usg=AOvVaw3qrhILGMhyzc-fgs72uHMg">AI Hub</a></span><span class="c22">&nbsp;</span><span>(subject to change;<br>read their current docs too)</span></h6><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span>If you can separate with these models downloaded from above locally, see also </span><span class="c4"><a class="c3" href="#h.wbc0pja7faof">here</a></span><span class="c0">&nbsp;for the list of all cloud sites and Colabs.</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">&ldquo;If you need to remove multiple noises, follow this pipeline for the best results: </span></p><p class="c1"><span class="c20">Remove instrumental -&gt; Remove reverb [probably on vocals] -&gt; Extract main vocals -&gt; Remove noise</span><span class="c0">&rdquo;</span></p><p class="c1"><span class="c0">Or also Isling&rsquo;s approach &ldquo;gives insanely clean results&rdquo;:</span></p><p class="c1"><span class="c6">Vocals&gt;De-reverb&gt;Karaoke</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Vocals</span></p><p class="c1"><span>- MelBand Roformer | Vocals FV4 (a.k.a. voc_fv4) by Gabox also <br>(Gabox </span><span>vocfv7beta1 &ldquo;seems to give better results than fv4&rdquo;</span><span class="c0">, also Mel 2024.10 is mentioned in MVSEP section, but BS-Roformer 2025.07 now has all the metrics better, unwa beta6/x + voc_fv4 ensemble is also good for RVC, unwa beta 4 was better than big beta v5e (NotEddy/codename), research also voc_gabox2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Instrumentals</span></p><p class="c1"><span class="c0">- MelBand Roformer | INSTV7 by Gabox <br>(unwa instrumental v1e+ OR Mel 2024.10 are also mentioned in their MVSEP section and Gabox Fv7z is mentioned in the x-minus)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">De-reverb</span></p><p class="c1"><span class="c0">- MelBand Roformer | De-Reverb by anvuew <br>(it&rsquo;s probably v2 variant [also mentioned there], or also Sucial V2 (MelRoformer) mentioned in their MVSEP section [&ldquo;if I&#39;m unhappy with the results I go for Sucial</span></p><p class="c1"><span>- isling&rdquo;] - it probably follows the model naming scheme of UVR UI on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742931005&amp;usg=AOvVaw0aNN4a0qPZ7kUuWi54fcwL">HF</a></span><span>, also the new mono-dereverb model is being used occasionally</span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Backing Vocals</span></p><p class="c1"><span class="c0">- Mel-Roformer-Karaoke-Aufr33-Viperx (surpassed by Becruily and Frazer Karaoke, but the first can be more consistent; anvuew&#39;s Karaoke model have fuller lead vocals; also older Model fuzed gabox &amp; aufr33/viperx (SDR: 9.85) is mentioned in their MVSEP section)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">De-noise</span></p><p class="c1"><span class="c0">- Mel-Roformer-Denoise-Aufr33-Aggr (they mention also &ldquo;Mel denoiser v2&rdquo; in UVR section)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Restoration</span></p><p class="c1"><span class="c0">- For lossy mp3/mixtures: Apollo Universal by Lew (sometimes AudioSR can be better)</span></p><p class="c1"><span class="c0">- For voice: AP-BWE or ClearerVoice-Studio&#39;s Clear Voice &ldquo;my favorite is the 2nd one&rdquo; - codename0)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.19elh4q7egl6"><span class="c18 c15">Fast inference models</span></h6><p class="c1"><span class="c20">Above an hour on i3-7100u, rather light, small - the lightest Roformers, while most have 870 MB):</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c6">For vocals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/resolve/main/BS-Roformer-Resurrection.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742933325&amp;usg=AOvVaw1WIbv_x-RmZSmN7gD3X13m">Unwa Resurrection</a></span><span>&nbsp;BS-Roformer (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/resolve/main/BS-Roformer-Resurrection-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742933503&amp;usg=AOvVaw12aOqrRq5ZaAey9KwYC9dc">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742933710&amp;usg=AOvVaw0hYBI9rOk-nVJNtT9ADb-_">Colab</a></span><span class="c0">, 195 MB)</span></p><p class="c1"><span>- BS-Roformer SW vocals only (mask_estimators.0 on the regular 6 stem model, 195 MB</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/folder/R3BzBSgD%23sz2XIOk3y0-LS4hIQOQKYQ&amp;sa=D&amp;source=editors&amp;ust=1765035742934011&amp;usg=AOvVaw1M9h2nV-e6OUHcfF7Rn9zl">)</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older models</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/Mel_Band_Roformer_small&amp;sa=D&amp;source=editors&amp;ust=1765035742934354&amp;usg=AOvVaw3XYYTuhSL_n6hL_YNS7sap">Aname Mel-Roformer small</a></span><span class="c0">&nbsp;(203MB)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-small&amp;sa=D&amp;source=editors&amp;ust=1765035742934564&amp;usg=AOvVaw22Gc80tH6sexHuUQyJCmAh">Unwa Mel-Roformer small</a></span><span class="c0">&nbsp;(203MB)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older arch (faster; 25-60 minutes+ on weak i3u/C2Q respectively)</span></p><p class="c1"><span class="c0">- voc_ft (probably the fastest, but uses outperformed MDX-Net v2 arch, also it&rsquo;s narrowband)</span></p><p class="c1"><span class="c0">- Kim Vocal 2 (or ev. 1, -||-, older model)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">For instrumentals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742935477&amp;usg=AOvVaw3pr0KzSh417baPx1xSnb2q">BS-Roformer Resurrection inst</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742935616&amp;usg=AOvVaw2D0nBvPzjOCJVY9v_NjkGr">yaml</a></span><span>) | a.k.a. &ldquo;unwa high fullness inst&quot; on MVSEP | uvronline </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742935778&amp;usg=AOvVaw3CVoom5Fmuu8kclXw6BhNI">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742935868&amp;usg=AOvVaw3oy3H93JYdV6z0Qk95v7bG">premium</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742936058&amp;usg=AOvVaw0lkedyShjgEPjaAirnzbSJ">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span class="c0">&nbsp;(don&rsquo;t confuse with Resurrection vocals variant, 204 MB)</span></p><h6 class="c1 c27" id="h.9una7hhstsnk"><span>- Gabox BS_ResurrectioN (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/BS_ResurrectioN.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742936408&amp;usg=AOvVaw3T8D0ZD7QdqeIHNrHnwjj6">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Resurrection/blob/main/BS-Roformer-Resurrection-Inst-Config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742936556&amp;usg=AOvVaw0f1fO-6zVVmZ1jl2zYPfAR">yaml</a></span><span class="c0">, 204 MB)</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older</span></p><p class="c1"><span class="c0">- Unwa BS-Roformer-Inst-FNO (works only in MSST after modifying py file like in the model card, similar to decently performing Resurrection inst model, 332 MB)</span></p><p class="c1"><span>- Gabox Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/small_inst.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742937187&amp;usg=AOvVaw0cFJuxI2FMCyJdcUNXoLMb">small_inst</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742937324&amp;usg=AOvVaw0ziKTx5GQ-Goi5rSrzajE5">yaml</a></span><span class="c0">&nbsp;(experimental, 203 MB)</span></p><p class="c1"><span class="c0">- Unwa BS-Roformer-Inst-EXP-Value-Residual (low performance, use v2 model type in UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">MDX-Net (faster, usually lower quality)</span></p><p class="c1"><span class="c0">- MDX-Net HQ_3, 4, 5 (the last is the fastest, 56 MB)</span></p><p class="c1"><span>- MDX-Net inst3, Kim inst (older, narrowband, but can be useful too in some cases, 63 MB)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">4 stems</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">- Faster FP16 version of BS-Roformer 6 stems called splifft (by undef13; a tad lower SDR; only 334MB vs 700 MB in the OG weight, CPU/NVIDIA compatible, and potentially AMD ROCm, only bigger variant works in UVR; the OG &ldquo;Conversion done after 2 hours for a 2 minute 49 second file&rdquo; on 2/4 i3 7100u) - on CPU it might be slower than the OG, as it might not support FP16 natively due to even possible emulation. But probably Turing GPUs with tensors (e.g. RTX or T4) and newer, probably have FP16 acceleration, while non-RTX 16XX sometimes not.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Faster, lower quality:</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1M24__8Qnd648ceXOH5PLVWenVeh6maGo/view&amp;sa=D&amp;source=editors&amp;ust=1765035742939210&amp;usg=AOvVaw2hCYonGzB6QwKCv8Oof_fH">KUIELab-MDXNET23C</a></span><span class="c0">&nbsp;(4 stems) - its first scores were probably from ensemble of its five models, and in that configuration it had better SDR than demucs_ft on its own, and drums had better SDR than &ldquo;SCNet-large_starrytong&rdquo; (so single models&rsquo; score of any of these MDX23C models is probably lower than in demucs_ft). <br>&gt; Lighter &ldquo;model1&rdquo; drums sounds surprisingly better than htdemucs non_ft v4 on previously separated instrumental. It handles trap really well and preserves hi-hats correctly, but in cost of other stem bleeding. v4 model can be used to clean it a bit further,</span></p><p class="c1"><span class="c0">- htdemucs v4 non-ft (UVR default) - it can clean up other stem bleeding of the above</span></p><p class="c1"><span class="c0">- htdemucs_mmi - probably faster, but worse quality, v3</span></p><p class="c1"><span class="c0">- kuielab_b - lighting-fast, but quality is mediocre (but rather still better than Spleeter)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Older vocal models (legacy section)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mel-Roformer unwa&rsquo;s inst-voc model called &ldquo;duality v1/2&rdquo; (focused on both instrumental and vocal stem during training, but you can now test newer V1e+ single stem for this purpose too). </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality&amp;sa=D&amp;source=editors&amp;ust=1765035742941339&amp;usg=AOvVaw0O6qMGFXj6Dc9m1v-Ezjj4">https://huggingface.co/pcunwa/Mel-Band-Roformer-InstVoc-Duality</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742941587&amp;usg=AOvVaw2ZIEQiIV69oMSTPNaS4kiQ">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742941671&amp;usg=AOvVaw1wfbILDgo-uc48U1a1PiYb">MVSEP</a></span></p><p class="c1"><span class="c0">Vocals sound similar to beta 4 model, but with more noise, <br>instrumentals are deprived of the noise present in inst v1 and later inst models, but as a downside, they&rsquo;re more muddy for instrumentals.<br>v2 have slightly a bit better SDR and fewer residues</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Because duality is a two stems target model.<br>&quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7321&amp;sa=D&amp;source=editors&amp;ust=1765035742942340&amp;usg=AOvVaw0BNTXxYjR3jyN6YdoHUj_H">other</a></span><span class="c0">&quot; is output from model</span></p><p class="c1"><span>&quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7322&amp;sa=D&amp;source=editors&amp;ust=1765035742942517&amp;usg=AOvVaw0j153P1M_bx_a0mNBSDYy3">Instrumental</a></span><span class="c0">&quot; is inverted vocals against input audio.</span></p><p class="c1"><span class="c0">The latter has lower SDR and more holes in the spectrum.</span></p><p class="c1"><span>So, using MSST-GUI, leave the checkbox &ldquo;extract instrumental&rdquo; disabled for duality models.<br>You can use it in the Bas Curtiz&rsquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742943058&amp;usg=AOvVaw08FyUQ8Gvw1iN6-xi9vHJm">GUI</a></span><span class="c0">&nbsp;for ZFTurbo script (already added) or with the OG ZF&rsquo;s repo, or in the Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aname duality Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/Mel-Band-Roformer_Duality&amp;sa=D&amp;source=editors&amp;ust=1765035742943404&amp;usg=AOvVaw3nXK9xv-PioxWaQlgI482u">model</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Aname Full Scratch Mel-Band Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/Mel_Band_Roformer_Full_Scratch&amp;sa=D&amp;source=editors&amp;ust=1765035742943642&amp;usg=AOvVaw1cksjLEw0yw_zUneL3ZRBB">model</a></span></p><p class="c1"><span class="c0">bleedless 30.75 fullness 13.24, SDR: 8.01</span></p><p class="c1"><span><br>- SYHFT (a.k.a. SYH99999/yukunelatyh) MelBandRoformer V3 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/SYH99999/MelBandRoformerSYHFTV3Epsilon&amp;sa=D&amp;source=editors&amp;ust=1765035742944029&amp;usg=AOvVaw3HwfK1yaPbyEfqmK1kx8cg">model</a></span></p><p class="c1"><span class="c0">VS previous SYH&rsquo;s models &ldquo;this version is more consistent with separation. It&#39;s not what I&#39;d call a clean model; It sometimes lets background noise bleed into the vocal stem. But only somewhat, and depending on how you look at it, it can be a good thing since it makes the vocals sound less muddy.&rdquo; Musicalman</span></p><p class="c1"><span><br>- </span><span>MelBandRoformerBigSYHFTV1Fast</span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/SYH99999/MelBandRoformerBigSYHFTV1Fast&amp;sa=D&amp;source=editors&amp;ust=1765035742944737&amp;usg=AOvVaw2-QAbtNVJXI776kRmDU1Mc">model</a></span><span>&nbsp;</span><span>- more vocal fullness metric, but more bleeding (although less than duality models and even Kim&rsquo;s purely </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1pPEJpu4tZjTkjPh_F5YjtIyHq8v0SxLnBydfUBUNlbI/edit?gid%3D1468543363%23gid%3D1468543363&amp;sa=D&amp;source=editors&amp;ust=1765035742945052&amp;usg=AOvVaw1boPP2ItyAqK0OwvSRuY9F">metric-wise</a></span><span class="c0">). &ldquo;same parameters size with Kim&#39;s. Other models are 2x scale parameter size to compare my model&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c22">Mel-Roformer model by Kim</span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/KimberleyJSN/melbandroformer/resolve/main/MelBandRoformer.ckpt?download%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035742945496&amp;usg=AOvVaw1SzNlxDhR47H2ikzDf3RP6">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/15TF3sAWCxWIaKaYRduyqTBBm7VPPcbNv/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742945623&amp;usg=AOvVaw0sj5IJRJQ4A58z-EvyTN0o">config</a></span></p><p class="c1"><span>Vocals bleedless: 36.75 | fullness: 16.26 | SDR: 11.07</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742945970&amp;usg=AOvVaw19nRH92nsf4K1SGXv0bSN0">Colab</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742946113&amp;usg=AOvVaw0iudTMRPUvQevbq5f5jKB0">Huggingface</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035742946206&amp;usg=AOvVaw06kEbyiBAZoe_qd8XHV4TI">2</a></span><span>/</span><span>MVSEP/uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742946347&amp;usg=AOvVaw1P2e6HmS6X2uXa-OLzfW51">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742946426&amp;usg=AOvVaw1KLtmIXtpwrCm2Pq-4yVj1">premium</a></span><span>&nbsp;(scroll down)/UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta Roformer</a></span><span>&nbsp;(available in Download Center)</span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742946679&amp;usg=AOvVaw32mqew04-0r03pCHu5d3MG">MSST-GUI</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1tyP3ZgcD443d4Q3ly7LcS3toJroLO5o1?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742946839&amp;usg=AOvVaw0xhy6Ec0xMWOao61JY8D4M">simple Colab</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/KimberleyJensen/Mel-Band-Roformer-Vocal-Model&amp;sa=D&amp;source=editors&amp;ust=1765035742946965&amp;usg=AOvVaw10K06yGAautY7lkI3I3KbR">CML inference</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">Usual base for lots of Mel fine-tunes on that list.</span></p><p class="c1"><span class="c0">Sometimes might leave instrumental residues in vocals, but can be less muddy than other BS-Roformers - the same goes to any fine-tunes of this model vs BS 2024.08, so effectively all the Mel models above)</span></p><p class="c1"><span class="c0">&ldquo;godsend for voice modulated in synth/electronic songs&rdquo; vs 1296 can be more problematic with wind instruments putting them in vocals.</span></p><p class="c1"><span class="c0">- unwa&rsquo;s instrumental Mel-Roformer v1e+<br><br>- unwa&rsquo;s instrumental Mel-Roformer v2 model (similar to v1, but less noise, muddier, bigger, heavier model)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-Inst/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742948070&amp;usg=AOvVaw1vlplLkac07P8cWaUJiKTw">Model files</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742948255&amp;usg=AOvVaw2rP4BwHGkqvjXNriq_JI8A">Colab</a></span><span>&nbsp;| &nbsp;uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742948387&amp;usg=AOvVaw3ASrHvtBKLwXYOLU3FK735">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742948471&amp;usg=AOvVaw1oEH-vVN1lsimK9WH-ltvy">premium</a></span><span>&nbsp;(scroll down) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035742948615&amp;usg=AOvVaw1VP4oGKE7JjBMJKqJtHCMV">MSST-GUI</a></span><span>&nbsp;(It&#39;s now included in ZFTurbo&#39;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035742948755&amp;usg=AOvVaw2UkxR4b-VEU889OVxuI1l3">repo</a></span><span class="c0">, it&#39;s the &quot;gui-wx.py&quot; file)</span></p><p class="c1"><span class="c0">Might miss some samples or adlibs while cleaning inverts. SDR got a bit bigger (16.845 vs 16.595) &ldquo;Sounds very similar to v1 but has less noise, pretty good&rdquo; &ldquo;the aforementioned noise from the V1 is less noticeable to none at all, depending on the track&rdquo;. &nbsp;&ldquo;V2 is more muddy than V1 (on some songs), but less muddy than the Kim model. (...) [As for V1,] sometimes it&#39;s better at high frequencies&rdquo; Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- older BS-Roformer 2024.02 on MVSEP (generally BS-Roformer models &ldquo;can be slappy with choir-like vocals and background vocals&rdquo; but &ldquo;hot on pre-2000 rock&rdquo;)</span></p><p class="c1"><span class="c0">These older Roformers &ldquo;kinda does poorly on large screams&rdquo; in metal music, but not always. Sometimes even HQ_4 can catch them better than, e.g. viperx models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mel-Roformer fine-tuned 17.48 model on MVSEP (works e.g. for live shows that have crowd)</span></p><p class="c1"><span class="c0">(it&rsquo;s different from the one on x-minus)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox BS-Roformer instrumental, which doesn&rsquo;t struggle so much with choirs like most Mel-Roformers, although it may not help in all cases (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/BSRoformerVocTest/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035742950705&amp;usg=AOvVaw1oDT0oJSpa6o5TYk8qMc0I">link</a></span><span>) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- &ldquo;ver. 2024.04&rdquo; SDR 17.55 on MVSEP - fine-tuned viperx model v1 (can pick in adlibs better, occasionally picks some SFX&rsquo;, sometimes one, sometimes the other is &ldquo;slightly worse at pulling out difficult vocals&rdquo;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- BS-Roformer Large unwa&rsquo;s vocal model (viperx 1297 model fine-tuned) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Q_M9rlEjYlBZbG2qHScvp4Sa0zfdP9TL/view&amp;sa=D&amp;source=editors&amp;ust=1765035742951393&amp;usg=AOvVaw1wrWy6z7M8vlm4MeoyQdvz">download</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742951588&amp;usg=AOvVaw2-l5ZGHOkVgYVGhLdJh63x">Colab</a></span></p><p class="c1"><span class="c0">More muddy than Kim&rsquo;s Roformer, potentially a bit less of residues, a bit more artificial sound. Better than viperx model - &ldquo;captures more nuances, subtle elements and details&rdquo; ~A5<br>It can be better for some older music like The Beatles than above models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- BS-Roformer viperx 1297 model (UVR beta/MVSEP a.k.a. SDR 17.17 for &ldquo;1296&rdquo; variant iirc/called just &ldquo;BS-Roformer&rdquo; on uvronline via special link for: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035742952368&amp;usg=AOvVaw03yz2AyLOnsD1a-vDECITy">free</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742952448&amp;usg=AOvVaw27cj9okwPRNi1SvbnFAkoc">premium</a></span><span class="c0">&nbsp;(scroll down)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mel-Roformer viperx 1143 model (UVR&gt;Download More Models)</span></p><p class="c1"><span class="c0">(don&#39;t confuse with 1053 which separates drums and bass in one stem).</span></p><p class="c1"><span class="c0">The first Mel-Roformer vocal model trained by viperx before Kim model which introduced changes to the config, which fixed the problem of lower SDR vs models trained on BS-Roformer. </span></p><p class="c1"><span class="c0">Most people back then preferred Kim Mel-Roformer instead, but Mel viperx&rsquo; &ldquo;does background voices correctly not unlike Kim&#39;s (it does not recognise background &#39;breee&#39;s)&rdquo; &ldquo;Iirc Viperx Mel Rofo doesn&#39;t struggle with instruments counted as vocals&rdquo;.</span></p><p class="c1"><span class="c0">Also, both Mel and BS variants of viperx model struggle with saxophone and e.g. some Arabic guitars. It can still depend on a song whether these are better than even the second oldest Roformer than on MVSEP (from before viperx model got fine-tuned version). Beside problems with recognizing instruments, they&#39;re very good for vocals (although Mel-Roformer by Kim on x-minus tends to be better).</span></p><p class="c1"><span class="c0">Muddy instrumentals when not ensembled with other archs (but we didn&rsquo;t have typically instrumental stem target models back then), maybe Mel variant less.</span></p><p class="c1"><span class="c0">Be aware that names of these models on UVR refer to SDR measurements of vocals conducted on private viperx dataset, not even older Synthetic dataset, instead of on multisong dataset on MVSEP, hence the numbers are higher than in the multisong chart on MVSEP.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Depending on a model, Roformers might be muddy</span><span>. Consider using ensembles or Apollo enhancer model by Lew v2 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Apollo-Colab-Inference/&amp;sa=D&amp;source=editors&amp;ust=1765035742955204&amp;usg=AOvVaw03rr7Sy0_DK6H7wAlSJefw">Colab</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ufile.io/09560o34&amp;sa=D&amp;source=editors&amp;ust=1765035742955289&amp;usg=AOvVaw3xPqyHvpHR9Fcoaw8zz_lk">Model</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/&amp;sa=D&amp;source=editors&amp;ust=1765035742955398&amp;usg=AOvVaw3ZRZ4aLA32LPMXvMj7-6c6">Inference</a></span><span class="c0">), although it might be noisy. Might work the best on BS+Mel ensembles (max spec, though avg might work better in some cases).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Older ensembles for vocals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Models ensembled option on x-minus.pro (available only for premium users)</span></p><p class="c1"><span class="c0">&gt; Mel-Roformer + MDX23C (can be picked after you uploaded/processed a track [at least with Mel-Roformer model chosen]).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt; Mel-Roformer + demudder</span></p><p class="c1"><span class="c0">&ldquo;I recommend mel-roformer + demudder to remove vocals from songs that contain only backing vocals that are so faint that our ears can barely hear them.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MDX23 by ZFTurbo (</span><span>v. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742956761&amp;usg=AOvVaw11OdB-7LCefhGsiY-CWn9V">2.5</a></span><span class="c0">&nbsp;jarredou Colab fork)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ensembles on MVSEP.com (for premium users)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ensembles in UVR 5:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>a) 1296 + 1143 (BS-Roformer in </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta</a></span><span>&nbsp;</span><span class="c0">UVR) + Inst HQ4 (dopfunk)</span></p><p class="c1"><span class="c0">(there might be instrumental residues from HQ4 in some cases)</span></p><p class="c1"><span class="c0">b) 1296 + 1297 + MDX23C HQ</span></p><p class="c1"><span class="c0">c) Manual ensemble in UVR of models BS-Roformer 1296 + copy of the result + MDX23C HQ (jarredou) - for faster result and similar quality vs the one above</span></p><p class="c1"><span class="c0">More ensembles beneath</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.7kniy2i3s0qc">KaraFan</a></span><span>&nbsp;(preset 4, but may give worse results than Mel-Roformer)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Older single models</span><span>&nbsp;for vocals (available in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035742958416&amp;usg=AOvVaw2EJ5yS72VFTGWzaH6_S9lH">UVR 5</a></span><span>&nbsp;| inference </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742958619&amp;usg=AOvVaw3mg0lYobTJs5D5qLSdsHNp">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742958752&amp;usg=AOvVaw1YFwnQUL2_BGnieg0lv5VS">MDX-Net</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com&amp;sa=D&amp;source=editors&amp;ust=1765035742958820&amp;usg=AOvVaw3ITK9dHk8YZTTZKeFLpHgz">MVSEP</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c22">UVR-MDX-Net-Voc_FT</span><span class="c0">&nbsp;(narrowband, further trained, fine-tuned version of the Kim vocal model; Roformers might be better now)</span></p><p class="c1"><span class="c0">&gt;If you still have instrumental bleeding, process the result with Kim vocal 2</span></p><p class="c1"><span class="c0">&gt;Alternatively use MDX23C narrowband (D1581) then Voc-FT, &quot;great combination&quot; (or MDX23C-InstVoc HQ instead of D1581) </span></p><p class="c1"><span class="c0">(so separate with the D1581 or InstVoc model first, then use the separated result as input, and separate it further with voc_ft)</span></p><p class="c1"><span class="c0">- Kim Vocal 1 (can bleed less than 2, but more than voc_ft, might depend on a song)</span></p><p class="c1"><span class="c0">- Kim Vocal 2</span></p><p class="c1"><span>&gt;MDX-Net HQ_3/4/</span><span class="c22">5</span><span class="c0">&nbsp;(HQ_4 can be sometimes not bad on vocals too, even less muddy than voc_ft, though more noisy, and e.g. HQ_3 had more vocal residues then Kim Vocal 2 in general, HQ_5 have stronger and fuller vocals than HQ_4)</span></p><p class="c1"><span>&gt;</span><span class="c22">MDX23C-InstVoc HQ</span><span class="c0">&nbsp;(can have some instruments residues at times, but it&rsquo;s fullband - better clarity vs voc_ft and Kim Vocal 1/2 -</span></p><p class="c1"><span class="c0">&ldquo;This new model is [vs the narrowband vocal models], by far, the best in removing the most non-vocal information from an audio and recovering formants from buried passages... But in some cases, also removes some airy parts from specific words, and some non-verbal sounds (breathing, moaning).&rdquo;</span></p><p class="c1"><span class="c0">- newer MDX23C epochs available on MVSEP like 16.66. </span></p><p class="c1"><span class="c0">MDX23C models are go-to models for live recorded vocals </span></p><p class="c1"><span class="c0">(available also in MDX23 Colab v2.3/2.4 when weight set only for InstVoc model)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older UVR ensembles (from before Roformer models release)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt;Voc FT + MDX23C_D1581 (avg/avg)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&gt;</span><span>292, 496, 406, 427, Kim Vocal 1, Kim Inst + Demucs ft (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/1449&amp;sa=D&amp;source=editors&amp;ust=1765035742962092&amp;usg=AOvVaw3ZHF-aODsF4ig0n0xo8z8P">#1449</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt;Kim Inst, Kim Vocal 1 (or/and voc_ft), Kim Vocal 2, UVR-MDX-NET Inst HQ 2 (or 3/4), UVR-MDX-NET_Main_427, htdemucs_ft (avg/avg IRC)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt;Kim Vocal 1+2, MDX23C-InstVoc HQ, UVR-MDX-NET-Voc_FT </span></p><p class="c1"><span class="c0">(jaredou)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&gt; </span><span class="c4"><a class="c3" href="#h.xya7mtyl0m39">More ensembles</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&gt;You can also check some ensembles for </span><span class="c4"><a class="c3" href="#h.2vdz5zlpb27h">instrumentals</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Your choice of the best vocal models only (up to 4-5 max for the best SDR - </span><span class="c4"><a class="c3" href="#h.tb9spo3rgthx">more</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If your separation still bleeds, consider processing it further with models in </span><span class="c4"><a class="c3" href="#h.tv0x7idkh1ua">Debleeding </a></span><span class="c0">section further below.</span></p><p class="c1"><span class="c0">___</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.vyz1ol39n8d2"><span class="c0">Other services (multipurpose)</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.f0orpif22rll">Ripple</a></span><span class="c0">&nbsp;(no longer works; since BS-Roformer models release it might be obsolete; it&#39;s very good at recognizing what is vocals and what&#39;s not and tends to not bleed instrumental into vocal stem; very good if not the best solutions for vocals)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- music.ai (paid; presumably in-house BS-Roformer models) </span></p><p class="c1"><span class="c0">&ldquo;almost the same as my cleaned up work (...) It seems to get the instrument bleed out quite well&rdquo;)</span></p><p class="c1"><span class="c0">&ldquo;Beware, I&#39;ve experienced some very weird phase issues with music.ai. I use it for bass, but vocals are too filtered/denoised IMO, and you can&#39;t choose to not filter it all so heavily. &rdquo; - Sam Hocking</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://myxt.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742965217&amp;usg=AOvVaw3ynecfw2PJ-djtL41asSWI">https://myxt.com/</a></span><span class="c0">&nbsp;(paid; uses Audioshake)</span></p><p class="c1"><span class="c0">- moises.ai (paid; uses in-house BS-Roformer models, sometimes better results than the one on MVSEP)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- ZFTurbo&rsquo;s VitLarge23 e.g. on MVSEP or 2.3/2.4 Colab (it&#39;s based on a new transformers arch. SDR-wise it&#39;s not better than MDX23C (9.78 vs 10.17), but works &quot;great&quot; for an ensemble consisting of two models with weights 2, 1. It&#39;s been added in 4 models ensembled on MVSEP (although the bag of current models is a subject to change any time)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- ZFTurbo&rsquo;s Bandit Plus (MVSEP)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Other decent single UVR models</span></p><p class="c1"><span>- Main (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1sxDUXVO9cBagfv1owuWCzLmDf-rJumeh?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035742966466&amp;usg=AOvVaw28F8Q6On4KuuijjnDEFo2w">427</a></span><span>) or 406, 340, MDXNET_2_9682</span><span>&nbsp;- all available in UVR5, some appear in download center after entering </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035742966768&amp;usg=AOvVaw06XKuBbBjCGYEGsxbHwQ2M">VIP</a></span><span class="c0">&nbsp;code)</span></p><p class="c1"><span class="c0">- or also instrumental models: Kim Inst and HQ_3 (via applied inversion automatically)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Other models </span></p><p class="c1"><span>- ZFTurbo&#39;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035742967227&amp;usg=AOvVaw0NsmQKCry99Q_mPIf74aHs">Demucs v4 vocals 2023</a></span><span class="c0">&nbsp;(on MVSEP, unavailable in Colab, good when everything else fails)</span></p><p class="c1"><span>- </span><span>MDX23 Colab fork </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/deton24/MVSEP-MDX23-Colab_v2.1/blob/main/MVSep_MDX23_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742967545&amp;usg=AOvVaw1BC3RuH7PoC4t2K-v1l_wt">2.1</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742967685&amp;usg=AOvVaw1hBeZyrOuGsn__REFQcmBS">2.2</a></span><span>&nbsp;(this might be slow) / </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/MVSEP-MDX23-Colab_v2/&amp;sa=D&amp;source=editors&amp;ust=1765035742967802&amp;usg=AOvVaw36EfXbOJSybAqtVFA_meaz">2.3</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.4/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742967936&amp;usg=AOvVaw2nObwbe_TPBEN4zzVltxTi">2.4</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035742968064&amp;usg=AOvVaw2bSdmNa8U0I5l8w6j472NL">2.5</a></span><span>&nbsp;(it&#39;s generally better than UVR ensembles SDR-wise, but it&#39;s not available in UVR5) </span><span class="c0">(MDX23 Colab is good also for instrumentals and 4 stems, very clean, sometimes more vocal residues in specific places vs single MDX-UVR inst3/Kim inst/HQ models, but it sounds better in overall, especially the Colab modification/fork with fixes made by jarredou)</span></p><p class="c1"><span class="c0">- HQ_3 (inverted result giving vocals from instrumental in 2nd stem) - more instrumental residues than e.g. Kim Vocal 2, but no 17.7 cutoff)</span></p><p class="c1"><span class="c0">- Narrowband MDX23C_D1581 &ldquo;Leaves too much instrumental bleeding / non-vocal sounds behind the vocals. Formants are less refined than on any of the top vocal models (Voc FT, Kim 1, Kim 2 and MDX23C-InstVoc HQ).&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Kavas&#39; methods for HQ vocals:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ensemble (Max/Max) - Low pass filter (brickwall) at 2k:</span></p><p class="c1"><span class="c0">- MDX23C</span></p><p class="c1"><span class="c0">- Voc FT</span></p><p class="c1"><span class="c0">Voc FT - High Pass Filter (brickwall) at 2k</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(&ldquo;Sometimes it leaves some synth bleeding in the mids&quot; then try out min/min)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or:</span></p><p class="c1"><span class="c0">Multiband EQ split at 2kHz with a low &amp; high pass brickwall filter with: </span></p><p class="c1"><span class="c0">-MDX23C-InstVoc from 0 to 2kHz and:</span></p><p class="c1"><span class="c0">-Voc_FT from 2kHz onwards</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(InstVoc gives fuller mids, but leaves transients from hats in the high end, whereas Voc ft lacks the mids, but gets rid of most transients. Combine the best of both for optimal results.)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Any </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard2.php?%26sort%3Dinstrum%26page%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035742970930&amp;usg=AOvVaw1gMh3mCoxOd3-QzczQPB10">top</a></span><span class="c0">&nbsp;ensemble or AI appearing on MVSEP leaderboard (but it depends, - sometimes it can be better for instrumental, sometimes vocals</span></p><p class="c1"><span class="c0">Ensembles are resource consuming, no cutoff if one model is fullband and the other is narrowband. Random ensembles can result in more vocal or instrumental residues, as mentioned above.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Models not exclusive for MVSEP are all available in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035742971678&amp;usg=AOvVaw01El3rEljRqc_AeJMpKBKM">UVR5 GUI</a></span><span>,</span><span>&nbsp;or optionally you can separate MDX models in </span><span class="c4"><a class="c3" href="#h.aa2xhwp434">Colab</a></span><span>&nbsp;and perform manual ensemble in UVR5 (no GPU or fast CPU required for this task) or use manual ensemble in </span><span class="c4"><a class="c3" href="#h.surlvvp6mr8f">Colab</a></span><span>&nbsp;[may not work anymore]</span><span class="c0">) or also in DAW by importing all the stems together and decreasing volume (you might want to turn on limiter on the sum). </span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.o6au7k9vcmk6"><span class="c22">S</span><span class="c18 c15">peech separation</span></h6><p class="c1"><span>&ldquo;There isn&#39;t one specifically trained for anime, try your luck with the current available models&rdquo;</span></p><h6 class="c1 c27" id="h.urdva440mfl2"><span class="c20">The list by Musicalman</span><span>&nbsp;(mostly from before the Gabox models release, check </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">vocals</a></span><span class="c0">&nbsp;too)</span></h6><p class="c1"><span class="c0">&ldquo;Any vocal model in the past few years should work for speech separation. My favorites at the moment are:</span></p><p class="c1"><span class="c0">- MDX23c Inst-Voc HQ </span></p><p class="c1"><span class="c0">- other similar MDX models for least aggressive, but bleedy, only really useful for denoising </span></p><p class="c1"><span class="c0">- Unwa&#39;s Mel-Roformer big beta 4 or beta 5e vocal models - for less bleed. Atm, 5e is my go-to as it sounds less filtered.</span></p><p class="c1"><span class="c0">~ I&#39;ve heard people praise BS-Roformers a lot, haven&#39;t really tested those much, though.</span></p><p class="c1"><span class="c0">- Becruily&#39;s vocal model can also be better at SFX separation, but can overestimate reverb in vocal stem sometimes.</span></p><p class="c1"><span class="c0">- Mel-Roformer Karaoke by viperx and aufr33 - for more aggressive separation (removes a bit more SFX)</span></p><p class="c1"><span class="c0">- And the most aggressive are Bandit models and the DNR v3 models on MVSEP, though they tend to be a bit too aggressive for my taste, so I only use them selectively.</span></p><p class="c1"><span class="c0">This is just my own opinions though, subject to change at a moment&#39;s notice lol&rdquo; </span></p><p class="c1"><span>[you&rsquo;ll find them in </span><span class="c4"><a class="c3" href="#h.owqo9q2d774z">SFX </a></span><span class="c0">section]</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/modelscope/ClearerVoice-Studio/tree/main/clearvoice&amp;sa=D&amp;source=editors&amp;ust=1765035742974779&amp;usg=AOvVaw29XWVJI67Mf72RajMdpGRi">clearvoice</a></span><span class="c0">&nbsp;- it&#39;s a set of speech enhancement/separation models. My favorite model of the set is MossFormer2_SE_48K. Its dialog extraction seems to be similar to Bandit v2, though clearervoice sounds fuller to me, and separation is usually a bit better. Might be especially good in an ensemble with Bandit or vocal sep models eg. unwa, gabox etc.</span></p><p class="c1"><span class="c0">- BS-Roformer 2025.06 on MVSEP - &ldquo;handle speech very well. Most models get confused by stuff like birds chirping (they put it in the vocal stem), but this model keeps them out of the vocal stem way more than most. I love it!&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.ma01ud7qwboo"><span class="c6">Can&rsquo;t find a model?</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Results containing models in e.g. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/946&amp;sa=D&amp;source=editors&amp;ust=1765035742976066&amp;usg=AOvVaw3BaN223uPgQvoF5ettRM31">#946</a></span><span>&nbsp;(e.g. 406, 427, 438) or other ensembles mentioned above,</span><span>&nbsp;still have public models available in UVR, but you can access them by entering the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035742976414&amp;usg=AOvVaw0AwZNDEn2IFgxyvYKww_H4">download/vip code</a></span><span>&nbsp;in UVR, so </span><span class="c0">more models will show up</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You cannot use VIP code on older beta UVR Roformer patches (</span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">updates</a></span><span class="c0">), then to use any other VIP model with Roformers (e.g. D1581), you need to install the stable 5.6 from official GH repo, download the model, and update the installation with the old Roformer patch afterwards if you need such version</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Be aware that MDX23C Inst Voc HQ2 is not accessible in beta Roformer patch when VIP code is inserted. You need to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/MDX23C-8KFFT-InstVoc_HQ_2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742977468&amp;usg=AOvVaw1Oy8_U3nI1661qgwuqhIiQ">download </a></span><span class="c0">the model file manually, and paste into models\MDX_Net_Models folder. </span></p><p class="c1"><span class="c0">(Config is detected automatically, as it uses existing model_2_stem_full_band_8k config - the same as for Inst Voc HQ)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- UVR Denoise non-lite model disappeared from Download Center. Here it is: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/UVR-DeNoise.pth&amp;sa=D&amp;source=editors&amp;ust=1765035742978194&amp;usg=AOvVaw2pKxnpZLgco3UXLHvlZFJ1">https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/UVR-DeNoise.pth</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You cannot use some models from x-minus/uvronline.app or used on MVSEP, e.g. used for Ensemble of 4 and 8 models in UVR, as they contain models not available in UVR, and not available for download. You can only perform manual ensemble of single models processed by MVSEP or x-minus, in UVR, but it will not give the same result as ensemble on MVSEP, as it uses code more similar to MDX23 Colab code, so sometimes weighted ensemble instead of. e.g. avg spec (don&rsquo;t confuse with MDX23C arch models).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- E.g. for 16.10.23, &ldquo;MVSep Ensemble of 4&rdquo; consists of 1648 previous epoch (maybe later updated to 16.66), VitLarge, and Demucs 2023 Vocals and beside the first, none of these models work in UVR, even if downloaded manually (plus VitLarge arch is not supported in UVR at all). Currently, there are various ensembles to choose from on MVSEP.</span></p><p class="c1"><span class="c0">As for 4/8 models ensemble on MVSEP - they&rsquo;re all only for premium users, as many resources and models are being used to output these results</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- 1648 on MVSEP is MDX23C HQ1 model (a.k.a. 8K FFT)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- SYHFT V4 and V5 beta by SYH99999 were never publicly released.</span></p><p class="c1"><span class="c0">V5 Beta is only on x-minus.pro/uvronline and got deleted from the main models view, but might be still accessible via the following links:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035742980586&amp;usg=AOvVaw1ccrc1QSFFCEI8NCEVbDGq">https://uvronline.app/ai?hp&amp;test</a></span><span class="c0">&nbsp;(premium)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?test&amp;sa=D&amp;source=editors&amp;ust=1765035742980758&amp;usg=AOvVaw0KOM2UFXHkt1jqvZLYWTcM">https://uvronline.app/ai?test</a></span><span class="c0">&nbsp;(free)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.1xexlusjxgs8"><span>UVR m</span><span class="c0">odels repository</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR5 single models&#39; repository backup as separate links (excluding VIP models, which are offline after decrypting):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/tag/all_public_uvr_models&amp;sa=D&amp;source=editors&amp;ust=1765035742981520&amp;usg=AOvVaw0ZeqN9SrG8vLAth_inWXsS">https://github.com/TRvlvr/model_repo/releases/tag/all_public_uvr_models</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>All of publicly available MVSEP models (including checkpoints just for further training):<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases&amp;sa=D&amp;source=editors&amp;ust=1765035742981954&amp;usg=AOvVaw2SgL2eoZzJywu6jQoUzdLn">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases</a></span></p><p class="c1"><span class="c0">(refer to the list of models in this document for descriptions of the best models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Alternatives models&rsquo; links list repo:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://bascurtiz.x10.mx/models-checkpoint-config-urls.html&amp;sa=D&amp;source=editors&amp;ust=1765035742982493&amp;usg=AOvVaw1j-Ihm5gmRX4vLHIK0fzI3">https://bascurtiz.x10.mx/models-checkpoint-config-urls.html</a></span><span class="c0">&nbsp;(some can be offline)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/SiftedSand/MusicSepGUI/blob/main/models.json&amp;sa=D&amp;source=editors&amp;ust=1765035742982785&amp;usg=AOvVaw3ONN2EmKO6Ka2LdfXFbqxa">https://github.com/SiftedSand/MusicSepGUI/blob/main/models.json</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI/blob/main/assets/models.json&amp;sa=D&amp;source=editors&amp;ust=1765035742983110&amp;usg=AOvVaw1LWKUZ2Vi5icnyELpMWead">https://huggingface.co/spaces/TheStinger/UVR5_UI/blob/main/assets/models.json</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Some of the older UVR5 GUI models described in this guide can be downloaded via expansion packs:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.3.0/v5_model_expansion_pack.zip&amp;sa=D&amp;source=editors&amp;ust=1765035742983839&amp;usg=AOvVaw182t8SZsjldWJjnRHnQ7so">https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.3.0/v5_model_expansion_pack.zip</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.3.0/models.zip&amp;sa=D&amp;source=editors&amp;ust=1765035742984198&amp;usg=AOvVaw1yPUcr7nVwQCCMuqNyUK-b">https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.3.0/models.zip</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v4.0.1/models.zip&amp;sa=D&amp;source=editors&amp;ust=1765035742984525&amp;usg=AOvVaw0-NMzZ-huR6hd09ET-VoI2">https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v4.0.1/models.zip</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Some of the models used by KaraFan:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Eddycrack864/KaraFan/releases/tag/karafan_models&amp;sa=D&amp;source=editors&amp;ust=1765035742984914&amp;usg=AOvVaw1B7W7Q3gTEVhUKqv6aVUXr">https://github.com/Eddycrack864/KaraFan/releases/tag/karafan_models</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX23C HQ 2</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/MDX23C-8KFFT-InstVoc_HQ_2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742985342&amp;usg=AOvVaw11WzsfEIc49IOz5nsXt74Y">https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/MDX23C-8KFFT-InstVoc_HQ_2.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">427:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/16sEox9Z_rGTngFUtJceQ63O5S9hhjjDk?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035742985705&amp;usg=AOvVaw1UKB9gnoE6PxTqscs7nB-y">https://drive.google.com/drive/folders/16sEox9Z_rGTngFUtJceQ63O5S9hhjjDk?usp=drive_link</a></span><span class="c0">&nbsp;(just in case)</span></p><p class="c1"><span class="c0">Copy it to Ultimate Vocal Remover\models\MDX_Net_Models and rename the model name to: UVR-MDX-NET_Main_427</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Jarredou&rsquo;s models mirror</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou&amp;sa=D&amp;source=editors&amp;ust=1765035742986234&amp;usg=AOvVaw08D48FVnNkcxeoefJCAB96">https://huggingface.co/jarredou</a></span><span class="c0">&nbsp;(6+ models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Some direct links</span></p><p class="c1"><span class="c0"><br>VOCALS-InstVocHQ</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/main/configs/config_vocals_mdx23c.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742986780&amp;usg=AOvVaw1jZxcc0lgxcxDHAncglrMa">https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/main/configs/config_vocals_mdx23c.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v1.0.0/model_vocals_mdx23c_sdr_10.17.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742987171&amp;usg=AOvVaw24nBjAqPo-dQgxgYp8OqYe">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v1.0.0/model_vocals_mdx23c_sdr_10.17.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VOCALS-MelBand-Roformer (by KimberleyJSN)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/main/configs/KimberleyJensen/config_vocals_mel_band_roformer_kj.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742987759&amp;usg=AOvVaw1GWhPonxDEKt5m6Di3y6Cn">https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/main/configs/KimberleyJensen/config_vocals_mel_band_roformer_kj.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/KimberleyJSN/melbandroformer/resolve/main/MelBandRoformer.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742988114&amp;usg=AOvVaw1yBBtMtcfYS8muKHXBLsJm">https://huggingface.co/KimberleyJSN/melbandroformer/resolve/main/MelBandRoformer.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VOCALS-BS-Roformer_1297 (by viperx)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/main/configs/viperx/model_bs_roformer_ep_317_sdr_12.9755.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742988682&amp;usg=AOvVaw1wKuyVrd63SjSNBMpMD6zi">https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/main/configs/viperx/model_bs_roformer_ep_317_sdr_12.9755.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_317_sdr_12.9755.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742989103&amp;usg=AOvVaw3VzcdW3xV0qx-TBQt-13mw">https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_317_sdr_12.9755.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VOCALS-BS-Roformer_1296 (by viperx)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/mdx_c_configs/model_bs_roformer_ep_368_sdr_12.9628.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742989673&amp;usg=AOvVaw1vmCebMfFA0LSR8JfKA5_9">https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/mdx_c_configs/model_bs_roformer_ep_368_sdr_12.9628.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_368_sdr_12.9628.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742990086&amp;usg=AOvVaw1NpqpPI5VX5rzQjFadLaAW">https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_368_sdr_12.9628.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VOCALS-BS-RoformerLargev1 (by unwa)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/unwa_bs_roformer/raw/main/config_bsrofoL.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742990512&amp;usg=AOvVaw2tMT-tWtTsdM9kJsdGccT-">https://huggingface.co/jarredou/unwa_bs_roformer/raw/main/config_bsrofoL.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/unwa_bs_roformer/resolve/main/BS-Roformer_LargeV1.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742990949&amp;usg=AOvVaw23Q5RNU_5Au3oFQR2b_l8E">https://huggingface.co/jarredou/unwa_bs_roformer/resolve/main/BS-Roformer_LargeV1.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">KARAOKE-MelBand-Roformer (by aufr33 &amp; viperx)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/aufr33-viperx-karaoke-melroformer-model/resolve/main/config_mel_band_roformer_karaoke.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742991665&amp;usg=AOvVaw3N24iw3RLl-wZqbAr0x3-u">https://huggingface.co/jarredou/aufr33-viperx-karaoke-melroformer-model/resolve/main/config_mel_band_roformer_karaoke.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/aufr33-viperx-karaoke-melroformer-model/resolve/main/mel_band_roformer_karaoke_aufr33_viperx_sdr_10.1956.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742992142&amp;usg=AOvVaw3eA7vjVZEmaTeidp3YdyXd">https://huggingface.co/jarredou/aufr33-viperx-karaoke-melroformer-model/resolve/main/mel_band_roformer_karaoke_aufr33_viperx_sdr_10.1956.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">OTHER-BS-Roformer_1053 (by viperx)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/mdx_c_configs/model_bs_roformer_ep_937_sdr_10.5309.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742992923&amp;usg=AOvVaw1O58OoMOJfwFIg2Qeup95A">https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/mdx_c_configs/model_bs_roformer_ep_937_sdr_10.5309.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_937_sdr_10.5309.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742993491&amp;usg=AOvVaw3keUKEddzBe9g3WQgK1Wlw">https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/model_bs_roformer_ep_937_sdr_10.5309.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">CROWD-REMOVAL-MelBand-Roformer (by aufr33)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.4/model_mel_band_roformer_crowd.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742994204&amp;usg=AOvVaw32NzGuQEdw3bJEYwMVRmgE">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.4/model_mel_band_roformer_crowd.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.4/mel_band_roformer_crowd_aufr33_viperx_sdr_8.7144.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742994696&amp;usg=AOvVaw3ubxC-GWwzwUCpATmH6xNX">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.4/mel_band_roformer_crowd_aufr33_viperx_sdr_8.7144.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VOCALS-VitLarge23 (by ZFTurbo)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/refs/heads/main/configs/config_vocals_segm_models.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742995232&amp;usg=AOvVaw1cyGq0EafhhmIHduRFaYL6">https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/refs/heads/main/configs/config_vocals_segm_models.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v1.0.0/model_vocals_segm_models_sdr_9.77.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742995646&amp;usg=AOvVaw3Zj20Bnt8VjfOgYfGFWKVr">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v1.0.0/model_vocals_segm_models_sdr_9.77.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">CINEMATIC-BandIt_Plus (by kwatcharasupat)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.3/config_dnr_bandit_bsrnn_multi_mus64.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742996227&amp;usg=AOvVaw1Te3dLdgtqpsHCRbRMZRR0">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.3/config_dnr_bandit_bsrnn_multi_mus64.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.3/model_bandit_plus_dnr_sdr_11.47.chpt&amp;sa=D&amp;source=editors&amp;ust=1765035742996702&amp;usg=AOvVaw2fRvO1CXQV2qQRorj4Al1i">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.3/model_bandit_plus_dnr_sdr_11.47.chpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">DRUMSEP-MDX23C_DrumSep_6stem (by aufr33 &amp; jarredou)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/models/releases/download/aufr33-jarredou_MDX23C_DrumSep_model_v0.1/aufr33-jarredou_DrumSep_model_mdx23c_ep_141_sdr_10.8059.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742997412&amp;usg=AOvVaw2Vi4R1rmdOnAh6jXxHgFoo">https://github.com/jarredou/models/releases/download/aufr33-jarredou_MDX23C_DrumSep_model_v0.1/aufr33-jarredou_DrumSep_model_mdx23c_ep_141_sdr_10.8059.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/models/releases/download/aufr33-jarredou_MDX23C_DrumSep_model_v0.1/aufr33-jarredou_DrumSep_model_mdx23c_ep_141_sdr_10.8059.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742997937&amp;usg=AOvVaw3d7SWS7J3KSfkBd4z9PX6n">https://github.com/jarredou/models/releases/download/aufr33-jarredou_MDX23C_DrumSep_model_v0.1/aufr33-jarredou_DrumSep_model_mdx23c_ep_141_sdr_10.8059.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4STEMS-SCNet_MUSDB18 (by starrytong)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.6/config_musdb18_scnet.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742998437&amp;usg=AOvVaw3CrsHYtDQi4YF-QLZg5BhB">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.6/config_musdb18_scnet.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.6/scnet_checkpoint_musdb18.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742998823&amp;usg=AOvVaw3jUV7tUYkpHzI-ENXk3cU0">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.6/scnet_checkpoint_musdb18.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">DE-REVERB-MDX23C (by aufr33 &amp; jarredou)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/aufr33_jarredou_MDXv3_DeReverb/resolve/main/config_dereverb_mdx23c.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035742999318&amp;usg=AOvVaw3_ccRShb8X1PfI9_20OsGi">https://huggingface.co/jarredou/aufr33_jarredou_MDXv3_DeReverb/resolve/main/config_dereverb_mdx23c.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/aufr33_jarredou_MDXv3_DeReverb/resolve/main/dereverb_mdx23c_sdr_6.9096.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035742999707&amp;usg=AOvVaw2kdbA6n0nsvuE-y5VWLDLe">https://huggingface.co/jarredou/aufr33_jarredou_MDXv3_DeReverb/resolve/main/dereverb_mdx23c_sdr_6.9096.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">DENOISE-MelBand-Roformer-1 (by aufr33)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/aufr33_MelBand_Denoise/resolve/main/model_mel_band_roformer_denoise.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743000182&amp;usg=AOvVaw0ywzDZ58OiDd7zCoz6IpBA">https://huggingface.co/jarredou/aufr33_MelBand_Denoise/resolve/main/model_mel_band_roformer_denoise.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/aufr33_MelBand_Denoise/resolve/main/denoise_mel_band_roformer_aufr33_sdr_27.9959.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743000564&amp;usg=AOvVaw3xAjhpu9Mm4OBmM_DtS4Ru">https://huggingface.co/jarredou/aufr33_MelBand_Denoise/resolve/main/denoise_mel_band_roformer_aufr33_sdr_27.9959.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">DENOISE-MelBand-Roformer-2 (by aufr33)</span></p><p class="c1"><span>Config: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/aufr33_MelBand_Denoise/resolve/main/model_mel_band_roformer_denoise.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743001184&amp;usg=AOvVaw2j0YT-BujrsaaSYjh-qDkx">https://huggingface.co/jarredou/aufr33_MelBand_Denoise/resolve/main/model_mel_band_roformer_denoise.yaml</a></span></p><p class="c1"><span>Checkpoint: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/aufr33_MelBand_Denoise/resolve/main/denoise_mel_band_roformer_aufr33_aggr_sdr_27.9768.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743001652&amp;usg=AOvVaw317P69ZGiMdekLvhYBSkwI">https://huggingface.co/jarredou/aufr33_MelBand_Denoise/resolve/main/denoise_mel_band_roformer_aufr33_aggr_sdr_27.9768.ckpt</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For a more recent list see </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743002024&amp;usg=AOvVaw0xjtkNZei1AqPICoRrZcwY">this</a></span><span>&nbsp;</span><span class="c0">Colab and cells containing all the links there too.</span></p><p class="c1"><span class="c0">____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Why not to use more than 4-5 models for ensemble in UVR</span><span>&nbsp;- </span><span class="c4"><a class="c3" href="#h.tb9spo3rgthx">click</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Other models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://studio.gaudiolab.io/gsep&amp;sa=D&amp;source=editors&amp;ust=1765035743002851&amp;usg=AOvVaw3nwUJq7tGz4ipHehp3NCWI">GSEP AI</a></span><span class="c0">&nbsp;- new model called &ldquo;Vocal Remover&rdquo;, and old instrumental, vocal, 4-6 stem model (it applies additional denoiser for 4/6 stems) - piano and guitar (free). As for 2 stems, it gives very good instrumentals for songs with very loud and harsh vocals and a bit lo-fi hip-hop beats, as it can remove vocals very aggressively. Sometimes even more than HQ_3. The new model might be good at removing SFX (instrumental stem is the old model).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In specific cases (can have more vocal residues in instrumentals vs HQ_3 at times - less in jarredou&#39;s Colab):</span></p><p class="c1"><span>- original </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/MVSEP-MDX23-music-separation-model&amp;sa=D&amp;source=editors&amp;ust=1765035743004200&amp;usg=AOvVaw3-Wljl8yk2G8NF76WpNgBZ">MDX23</a></span><span class="c0">&nbsp;by ZFTurbo (only this OG version of MDX23 still works in the offline app, min. 8GB Nvidia card required [6GB with specific parameters]) - sounds very clean though, and not that muddy like inst MDX models, in this means, comparable with even VR arch or better (because of much less vocal residues).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.m9ndauawzs5f">Demucs</a></span><span>_</span><span class="c0">ft model (both 3 stems to mix in e.g. Audacity for instrumental) / sometimes 6s model gives better results, or in very specific cases when vocals are easy to filter out - even the old 4 stem mdx_extra model (but SDR wise full band MDX 292 is already better than even ft model). The 6s model is worth checking with shifts 20.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Might be still usable in some specific cases, despite the fact that MDX23 uses demucs_ft and other models combined.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.wjd2zth0azhs">VR models</a></span><span>&nbsp;settings + VR-only </span><span class="c4"><a class="c3" href="#h.rv7wwzcmuq3s">ensemble settings</a></span><span>&nbsp;(generally deprecated, but sometimes more clarity vs MDX v1, though frequently more vocal residues. Some people still uses it e.g. for some rock, when it can still can give better results than other models, and also for fun dubs, but for it if you have two language tracks of the same movie, you can test out </span><span class="c4"><a class="c3" href="#h.3c6n9m7vjxul">Similarity Extractor</a></span><span class="c0">&nbsp;instead, but Audacity center extraction works better than that linked Colab)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Alternatively, you can consider using narrowband Kim other ft model with fullband model settings parameters in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CO3KRvcFc1EuRh7YJea6DtMM6Tj8NHoB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743007245&amp;usg=AOvVaw0UN3txTTOeaEg7D8fNJl_B">this</a></span><span>&nbsp;or the new HV Colab instead. Useful in some specific parts of songs like chorus, where there are still no persistent vocal residues using this method (clearer results than even Max-Spec) or e.g. MDX23 still doesn&#39;t give you enough clarity in such places to maybe merge fragments manually of results from different models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Paid</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://indie.audioshake.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743008005&amp;usg=AOvVaw2gJakQjwmc6TM7llEOi88A">Audioshake</a></span><span>&nbsp;</span><span class="c0">(non-copyrighted music only, can be more aggressive than above and pickup some lo-fi vocals where other fails [a bit in manner of HQ models])</span></p><p class="c1"><span>How to bypass the non-copyright music restriction (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1120828059247980645/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743008479&amp;usg=AOvVaw3oI6uJOYQL_GZkU5TPNzhz">1</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1120828171873423380/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743008606&amp;usg=AOvVaw3uKDAls-I3v8JoJy30IA-O">2</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">&quot;They also reserve themselves the right to keep your money and not let you download the song you split if they discover that you are using a commercially released song and that you don&#39;t have the rights to it.&quot; but generally we didn&#39;t have such a case with slowed down songs (otherwise they might not pass anyway)</span></p><p class="c1"><span class="c0">4 stems might be better at times then Demucs ft model.</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://dango.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743009589&amp;usg=AOvVaw0YfuVw0jT9tFZdduRCMTNr">Dango.AI</a></span><span>&nbsp;(a.k.a. tuanziai.com) free 30 seconds samples; can be the most aggressive for instrumentals vs, e.g. inst 3, tested on Childish Gambino - Algorithm). Since then, models/arch were updated and instrumentals in 9.0 seem to be </span><span class="c22">the cleanest </span><span>or the closest to original instrumentals </span><span class="c0">for 12.08.23 at least in some cases (despite low SDR).</span></p><p class="c1"><span class="c0">&gt; If you care only about specific snippet in a song, then since 30 second samples to separate are taken randomly from a whole song, to have specific fragment separated, you can copy the same fragment over and over to make a full-length track of it, and it will eventually pick up a whole snippet for separation.</span></p><p class="c1"><span class="c0">X Uploading snippet shorter than or exactly 30 seconds will not result in the whole fragment being processed from the beginning to the ending.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt;Sometimes using other devices or virtual machine in addition to incognito/VPN/new email might even be necessary to reset free credits. It&#39;s pretty persistent.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tuanziai.com/encouragement&amp;sa=D&amp;source=editors&amp;ust=1765035743011667&amp;usg=AOvVaw2a2BYjnagrkT9VW6zhKTdt">https://tuanziai.com/encouragement</a></span></p><p class="c1"><span class="c0">Here you might get 30 free points (for 2 samples) and 60 paid points (for 1 full songs) &quot;easily&quot;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt;&gt;&gt;</span></p><p class="c1"><span class="c0">Everything else for 2 or 4 stems than above is worse for separation tasks:</span></p><p class="c1"><span class="c0">Lalal, RipX (although now it uses some UVR models (?), Demix, RX Editor 8-11, Spleeter and its online derivatives.</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.tv0x7idkh1ua"><span class="c18 c15">Debleeding/cleaning vocals/instrumentals/inverts</span></h6><p class="c1"><span class="c0">- Roformers: Mel 2024.10 on MVSEP a.k.a. Bas Curtiz FT (for vocals) <br>- Or earlier Kim Mel-Roformer model (for vocals; if other model was prev. used)</span></p><p class="c1"><span class="c0">- Unwa inst v1 (to clean-up vocals from Mel 2024.10 model) </span></p><p class="c1"><span class="c0">- unwa&rsquo;s inst v1/e/2 (for OG instrumentals with bleeding [better than Dango for it])<br>- unwa big beta 5 (&ldquo;my go-to clean-up artifacts model after phase inverting master + official instrumental&rdquo;)</span></p><p class="c1"><span class="c0">- Unwa Revive 3e</span></p><p class="c1"><span class="c0">- voc_fv6 (for vocal inverts - ezequielcasas)</span></p><p class="c1"><span>- DEBLEED-MelBand-Roformer (by unwa/97chris) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/bleed_suppressor_melband_rofo_by_unwa_97chris/resolve/main/bleed_suppressor_v1.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743014068&amp;usg=AOvVaw3w4bdIpUBfttfELlVoIsNJ">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/bleed_suppressor_melband_rofo_by_unwa_97chris/resolve/main/config_bleed_suppressor_v1.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743014237&amp;usg=AOvVaw34I28fTHvhl76vX-FNv3EQ">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743014440&amp;usg=AOvVaw0G-So6hucIjSxDltIeJjgc">Colab</a></span></p><p class="c1"><span class="c0">(it can work with e.g. inst v1 and its noise, or with v1e, or even MVSEP Karaoke BS-Roformer instrumental stem for &ldquo;very clean and full&rdquo; result. Also, sometimes the debleed model can remove some bleed also after using phase fixer)</span></p><p class="c1"><span>- Mel avuew&rsquo;s v2 </span><span class="c4"><a class="c3" href="#h.5zlfuhnreff5">de-reverb</a></span><span>&nbsp;or unwa&rsquo;s BS Large, MDX-Net HQ_5 <br>(&ldquo;great for cleaning acapellas from bits of instrumentals&rdquo;) <br>- syftbeta 5 on x-minus.pro (probably still available with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035743015437&amp;usg=AOvVaw08JF9aSeDvUCert7LWyJYd">this</a></span><span>&nbsp;link for premium, and for </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?test&amp;sa=D&amp;source=editors&amp;ust=1765035743015566&amp;usg=AOvVaw1O01_sW2hAikqbVckn0GLD">free</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">- Ensemble of BSRoformer-Viperx1297, Unwa BSRoformer-LargeV1, unwa_ft2_bleedless, mel_band_roformer_vocals_becruily, Gabox voc_fv4 on Average/Average <br>(good for cleaning inverts - AG89) </span></p><p class="c1"><span class="c0">- Ensemble of big beta6x, roformer revive2, unwa ft2 bleedless <br>(for cleaning instrumental inverts - AG89)</span></p><p class="c1"><span>- Or just use models with the highest bleedless metric (</span><span class="c4"><a class="c3" href="#h.2vdz5zlpb27h">instrumental</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">vocals</a></span><span>)<br></span><span class="c4"><a class="c3" href="#h.5zlfuhnreff5"><br></a></span><span>- RX10 De-bleed feature for instrumentals (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/nwyJJMiYGUI&amp;sa=D&amp;source=editors&amp;ust=1765035743016648&amp;usg=AOvVaw3p3xnSQDMcxSYYwZq5LekB">video</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">(older methods)</span></p><p class="c1"><span>- Gabox Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/denoisedebleed.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743016943&amp;usg=AOvVaw0GwgM5zUcTeUuu3BTvs77p">denoise/debleed</a></span><span>&nbsp;model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743017098&amp;usg=AOvVaw2yWZx4lvJLdB6WXsjS7DcI">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743017283&amp;usg=AOvVaw0kNbJjTI5vJYMeFQOq9CL-">Colab</a></span><span>&nbsp;| SESA </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743017437&amp;usg=AOvVaw02mufPUE132n0u7ypDBVRc">Colab v3</a></span><span>&nbsp;- for noise from fullness models (tested on v5n) - it can&#39;t remove the vocal residues<br>- Mel </span><span class="c4"><a class="c3" href="#h.hyzts95m298o">denoise</a></span><span class="c0">&nbsp;- that model &ldquo;removed some of the faint vocals that even the bleed suppressor didn&#39;t manage to filter out&rdquo; before&rdquo;. Try out denoising on a mixture first, then use the model.</span></p><p class="c1"><span>- (</span><span class="c20">for saxophone bleeding</span><span class="c0">) ~&ldquo;1. Take the original song in FLAC or WAV 2. Use MVSEP Saxophone 3. Take the other stem from it - there should be everything else and most of the sax should be gone (for me, there was a small part left) 4. Use Unwa Big Beta 5 on it (so Other-&gt; uvronline/xminus/Colab Unwa Big Beta 5) - then vocals should be very clean no sax bleeding&rdquo; cali_tay98</span></p><p class="c1"><span class="c0">- (&ldquo;In case there&#39;s any wind instruments that could potentially bleed into the vocals&rdquo;)<br>MVSep Wind</span></p><p class="c1"><span>- (</span><span class="c20">when &ldquo;models don&#39;t pick up the noise</span><span class="c0">), gently bring back a bit of the original music/instrumental on the inverted track and use AI again.</span></p><p class="c1"><span class="c0">By gently, I mean no more than 6 dB&ldquo; - becruily</span></p><p class="c1"><span>- (</span><span class="c20">&ldquo;If your result have &quot;vocal chops&quot;</span><span class="c0">) left in the instrumental separation and no models could remove them completely, then it&#39;s likely MDX HQ_5 or VitLarge23 v2 will fix it&rdquo; dca</span></p><p class="c1"><span>- Acon Digital DeBleed:Drums &ldquo;it&#39;s just an advanced gate. It doesn&#39;t remove bleed when it&#39;s overlapping the wanted audio (we can still hear hihat/cymbals on snare with the plugin enabled in their </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DhCFPa8_QquE&amp;sa=D&amp;source=editors&amp;ust=1765035743019923&amp;usg=AOvVaw1CxQb5DXNBpTAuIPpsdFsp">demo</a></span><span class="c0">)&rdquo; - jaredou.</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/its-rajesh/Audio-Bleeding-Removal&amp;sa=D&amp;source=editors&amp;ust=1765035743020135&amp;usg=AOvVaw0IK66KyAzK45-_8aIijgA7">Audio-Bleeding-Removal</a></span><span class="c0">&nbsp;- by its-rajesh</span></p><p class="c1"><span>- Try out some L/R inverting, try out to separate multiple times to get rid of some vocal pop-ins like this (fix for ~&quot;ah ha hah ah&quot; vocal residues)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older models</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.f0orpif22rll">Ripple</a></span><span>&nbsp;(defunct) </span><span class="c0">&ldquo;AWESOME to use after inverting songs with the official instrumental&rdquo;</span></p><p class="c1"><span>Instrumentals can be also further cleaned with Ripple, and then with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.bandlab.com/splitter&amp;sa=D&amp;source=editors&amp;ust=1765035743021062&amp;usg=AOvVaw0rxRc-H88ofZc8Us0CH00n">Bandlab Splitter</a></span></p><p class="c1"><span>(Roformer models may potentially replace Ripple models in that matter now)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.xya7mtyl0m39">Top</a></span><span class="c0">&nbsp;ensemble in UVR5 (starting from point 0d)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.yy2jex1n5sq">GSEP</a></span><span class="c0">&nbsp;- very minor difference between both for cleaning vocals (maybe GSEP is better by a pinch).</span></p><p class="c1"><span class="c0">You can try separating e.g. vocal result double using different settings (e.g. voc_ft&gt;kim vocal 2)</span></p><p class="c1"><span class="c0">- MVSEP 11.50 Ensemble (the least amount of bleeding in inst. separations at least)</span></p><p class="c1"><span>- MDX23 jarredou&#39;s fork Colab (maybe </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/deton24/MVSEP-MDX23-Colab_v2.1/blob/main/MVSep_MDX23_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743022255&amp;usg=AOvVaw1WoIbRsL2JdrIIC-KmVdGz">this</a></span><span class="c0">&nbsp;version at first)</span></p><p class="c1"><span class="c0">- use voc_ft model on the result you got (so separate twice if you already used that model)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>C</span><span class="c6">leaning inverts means - cleaning up residues - e.g. left by the instrumental after an imperfect phase cancellation, e.g. when audio is lossy, or maybe even not from the same mixing session -</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Aligning</span></p><p class="c1"><span>&quot;</span><span class="c4"><a class="c3" href="#h.8vosdwb10mjo">Utagoe</a></span><span>&nbsp;bruteforces alignment every few ms or so to make sure it&#39;s aligned in the case that you&#39;re trying to get the instrumental of a song that was on [e.g.] vinyl.&quot;</span></p><p class="c1"><span class="c0">[The previous] UVR&#39;s align tool is handy just for digital recordings&hellip; [so those] which don&#39;t suffer from that [issue] at all.&quot;</span></p><p class="c1"><span class="c0">Utagoe will not fix fluctuating speed issues, only the constant ones.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Anjok already &quot;cracked&quot; how that specific Utagoe feature works, and introduced it to UVR.</span></p><p class="c1"><span class="c0">&ldquo;Updated &quot;Align Tool&quot; [is] to align inputs with timing variations, like Utagoe.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Some users had good results with Auto Align Post 2 plugin to resync tracks before inverting them.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For problematic inverts, you can also try out azimuth correction in e.g. iZotope RX.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Declicking vocals</span></p><p class="c1"><span class="c0">- BS-Rofomer (&ldquo;Can also fix hard clicks in vocals. It is even better than RX in this, but still there is a tiny wave fade residue in some cases&rdquo;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c20">Kim vocal</span><span>&nbsp;first and then separate with instrumental model (e.g. </span><span class="c20">HQ_3 or 4</span><span class="c0">). You might want to perform additional separation steps to clean up the vocal from instrumental residues first, and invert it manually to get cleaner instrumental to separate with instrumental model to get rid of vocal residues </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Removing metronome</span></p><p class="c1"><span class="c0">- Use a good instrumental model so you will be left with metronome + vocals in one stem, then use a drums model - &ldquo;Then the drum trick worked better but still not very good, a regular extraction worked better this time though!&rdquo; - brianghost</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Removing bleeding of hi-hats in vocals</span></p><p class="c1"><span class="c0">- Kim Mel-Roformer model</span></p><p class="c1"><span>- </span><span>Use MelBand RoFormer v2 on MVSEP (e.g. after using MDX23C Inst HQ)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Bleeding in other stems</span></p><p class="c1"><span class="c0">- RipX Stem cleanup feature (possibly)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- SpectraLayers 10 (eliminates lots of bleeding and noise from MDX23 Colab ensembles)</span></p><p class="c1"><span class="c0">&quot;You debleed the layer to debleed from using the debleed source. Results vary. Usually it&#39;s better to debleed using Unmix and then moving the bleed to where it belongs&quot; Sam Hocking</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DwZ4hlC4CM2M&amp;sa=D&amp;source=editors&amp;ust=1765035743027714&amp;usg=AOvVaw3b9LS_P2Qi_nF6Fv1lWF34">Video</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Bleeding of claps in vocals </span></p><p class="c1"><span class="c0">- Reverse polarity and/or remove DC offset of the input file</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Captain-FLAM/KaraFan/blob/master/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743028361&amp;usg=AOvVaw2Fk8uDhFBhR9pceCjl0s37">KaraFan</a></span><span>&nbsp;(for general drum artefacts, but it doesn&rsquo;t work well for inverts, try out modded preset 5 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/coxj6Zs.png&amp;sa=D&amp;source=editors&amp;ust=1765035743028649&amp;usg=AOvVaw3zOMQozor5J6TF24SyZSlR">here</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">- Remove drums with e.g. demucs_ft first, then separate the drumless mixture from inversion</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/BmvcUEt.png&amp;sa=D&amp;source=editors&amp;ust=1765035743028966&amp;usg=AOvVaw0BP73weH1degmoG5wQ4KO2">Settings</a></span><span class="c0">&nbsp;for VR Colab</span></p><p class="c1"><span class="c0">- Kim Vocal 2 (but it has a cutoff and creates a lot of noise in the output)</span></p><p class="c1"><span class="c0">- Denoise model with 0.1-0.2 aggressiveness</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.euyv55qdbx07">Sam Hocking method</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Bleeding of guitars/winds/synths in vocals</span></p><p class="c1"><span>- BVE (Karaoke) models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Overlapped/misrecognized stems</span></p><p class="c1"><span>- Spectralayer&#39;s 9/+ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://download.steinberg.net/downloads_software/SpectraLayers_9/help/Pro/_imprinting.html&amp;sa=D&amp;source=editors&amp;ust=1765035743029979&amp;usg=AOvVaw2u1lPZv7Mb2RdUQcRqkSIe">Cast &amp; Mold</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Low-end rumble</span></p><p class="c1"><span class="c0">- Spectral Editing:</span></p><p class="c1"><span>a) RX Editor&rsquo;s brush (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/118uALJXl_qBLtL3nkftdOxOJydEkDYZQ/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743030364&amp;usg=AOvVaw2sxxsdEOYayg-tQNj28yT7">video</a></span><span class="c0">&nbsp;by Bas)</span></p><p class="c1"><span>b) Audacity (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/PI3VJqa&amp;sa=D&amp;source=editors&amp;ust=1765035743030554&amp;usg=AOvVaw0zBS65LgcBbSyxCXvVOhk6">image</a></span><span class="c0">) - &ldquo;you can, just barely&rdquo;</span></p><p class="c1"><span class="c0">Potential alternatives for spectral painting:</span></p><p class="c1"><span>Free: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://isse.sourceforge.net/download.html&amp;sa=D&amp;source=editors&amp;ust=1765035743030913&amp;usg=AOvVaw1PGK1_CvMkFXvzLiUBIZmy">ISSE</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/echometerain/Ampter&amp;sa=D&amp;source=editors&amp;ust=1765035743031006&amp;usg=AOvVaw3ZqofE2wCXtjQqAea7xYX3">Ampter</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/HarmoniaLeo/Filter-Artist&amp;sa=D&amp;source=editors&amp;ust=1765035743031106&amp;usg=AOvVaw3WVfKEupmnn_CMpSoFbhLZ">Filter-Artist</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://www.nicolasfournel.com/?page_id%3D125&amp;sa=D&amp;source=editors&amp;ust=1765035743031220&amp;usg=AOvVaw2ETV4Zh5_JaTbjz7NEYExe">AudioPaint</a></span></p><p class="c1"><span class="c0">Paid: RipX, SpectraLayers, Melodyne </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Bleeding of instruments in vocals</span></p><p class="c1"><span class="c0">- Denoise model with 0.1-0.2 aggressiveness</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Cleaning the white noise/sizzle inside the vocals</span></p><p class="c1"><span class="c0">(from e.g. Roformer models)</span></p><p class="c1"><span class="c0">- MDX23C model (e.g. the latest on MVSEP or HQ in UVR)</span></p><p class="c1"><span>_______</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1XIbyHwzTrbs6LbShEO-MeC36Z2scu-7qjLb-NiVt09I/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743032323&amp;usg=AOvVaw3ESfVUJUB5LoziHE5B3_tt">Debleeding guide by Bas Curtis</a></span><span class="c0">&nbsp;(other methods, e.g. Audacity)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4 c20"><a class="c3" href="#h.hyzts95m298o">Denoising</a></span><span class="c20">&nbsp;and </span><span class="c4 c20"><a class="c3" href="#h.5zlfuhnreff5">dereverberation</a></span><span class="c4 c20"><a class="c3" href="#h.70231k4ydkfw">/apps</a></span><span class="c20">&nbsp;later below.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">See also &ldquo;</span><span class="c4 c20"><a class="c3" href="#h.hyzts95m298o">Vinyl noise/white noise</a></span><span class="c6">&rdquo; from the end of the list.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">_______</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.p1fyricuv1j8"><span class="c0">How to check whether a model in UVR5 GUI is vocal or instrumental?</span></h6><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_3wxxpxfz40sk-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Read carefully the models list above - they&#39;re categorized</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">If you want to experiment with other models:</span></li></ul><p class="c1"><span class="c0">The moment you see &quot;Instrumental&quot; on top (and &quot;Vocal&quot; below) in the list where GPU conversion is mentioned, you know it&#39;s an instrumental model.</span></p><p class="c1"><span class="c0">When it flips the sequence, so Vocal on top, you know it&#39;s a vocal model. </span></p><p class="c1"><span class="c0">Same happens for MDX and VR archs.</span></p><ul class="c9 lst-kix_4i10vbfgn91y-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">&ldquo;Be aware that MDX23C/MDXv3 models can be multisource - it depends on the training, so it can be only vocals, or only instrumental, or vocals+instrumental, or vocals+drums+bass+other (like baseline models are), or whatever else.</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">You can know it looking at the config file of the model, for example InstVocHQ, </span></li></ul><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/blob/master/models/MDX_Net_Models/model_data/mdx_c_configs/model_2_stem_full_band_8k.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743034869&amp;usg=AOvVaw2g5Y9JBu9IRHLOBsqgZEqT">https://github.com/Anjok07/ultimatevocalremovergui/blob/master/models/MDX_Net_Models/model_data/mdx_c_configs/model_2_stem_full_band_8k.yaml</a></span></p><p class="c1 c8"><span class="c0">Seeing by the instruments line above, D1581 and InstVocHQ models are instrumental+vocal.</span></p><p class="c1 c8"><span class="c0">Config for the rest of the models:</span></p><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/blob/master/models/MDX_Net_Models/model_data/model_data.json&amp;sa=D&amp;source=editors&amp;ust=1765035743035475&amp;usg=AOvVaw2C3P0VlR59W6ocXH3p2E97">https://github.com/Anjok07/ultimatevocalremovergui/blob/master/models/MDX_Net_Models/model_data/model_data.json</a></span><span class="c0">&nbsp;</span></p><p class="c1 c8"><span>(</span><span class="c4"><a class="c3" href="#h.ntgu6se9g0u5">decoded hashes</a></span><span>)</span></p><p class="c1"><span class="c0">____________________________________________________________________</span></p><hr style="page-break-before:always;display:none;"><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.c25tza6ak9pi"><span>Keeping only </span><span class="c22">backing vocals </span><span>in a song (lead vocal extractor):</span><span class="c18 c15">&nbsp;</span></h6><h6 class="c1 c27" id="h.vg1wnx1dc4g0"><span class="c18 c15">&gt;Karaoke</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c31">You might want to use a good </span><span class="c4 c31"><a class="c3" href="#h.n8ac32fhltgg">vocal</a></span><span class="c31">&nbsp;</span><span class="c23 c15 c30">model as a preprocessor to use with the models below (if MVSEP/x-minus don&rsquo;t do it already), but sometimes it can degrade the quality, so experiment both ways. </span></p><p class="c1"><span class="c31">Optionally you may also </span><span class="c4 c31"><a class="c3" href="#h.5zlfuhnreff5">de-reverb</a></span><span class="c23 c15 c30">&nbsp;vocals with a good model/plugin first before proceeding, but only if the specific model/method doesn&rsquo;t filter out a lot of BGVs in your vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Anvuew&rsquo;s Karaoke BS-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/karaoke_bs_roformer&amp;sa=D&amp;source=editors&amp;ust=1765035743037138&amp;usg=AOvVaw1StA0b4hQtSztKajNMXOno">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9180&amp;sa=D&amp;source=editors&amp;ust=1765035743037237&amp;usg=AOvVaw0ljBPA17N5u1dCDIDYcktY">metrics</a></span><span>&nbsp;| incompatible with UVR RTX 5000 patch | </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span>&nbsp;| MVSEP | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743037546&amp;usg=AOvVaw3Pt1Malf5Wp_rKo4b4jLPb">Colab</a></span></p><p class="c1"><span>(Lead vocals/backing with instrumental)</span></p><p class="c1"><span class="c0">&ldquo;extracts lead vocals a bit better than karaoke becruily frazer, and in some parts, the lead vocals from karaoke anvuew still sound brighter compared to karaoke becruily frazer, which sounds a bit more compressed. oh, and for some reason, the becruily frazer model doesn&rsquo;t detect vocals with radio effects, while anvuew&rsquo;s model handles them just fine&rdquo; - neoculture </span></p><p class="c1"><span class="c0">&ldquo;lead vocals leak into instrumental (...) Mel Becruily and Frazer&rsquo;s BS don&rsquo;t have this problem&rdquo;</span></p><p class="c1"><span class="c0">In that case, maybe &ldquo;isolate the acapella first in almost all cases of using a karaoke model&rdquo; or use the model below instead.</span></p><h6 class="c1 c27 c7" id="h.6qjya04u4j47"><span class="c0"></span></h6><h6 class="c1 c27" id="h.ssrnqicusu92"><span>- BS-Roformer Karaoke </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/bs-roformer-karaoke/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743038936&amp;usg=AOvVaw0piwZZNoYXEV69QgTekUHf">model</a></span><span>&nbsp;by becruily &amp; frazer | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9013&amp;sa=D&amp;source=editors&amp;ust=1765035743039068&amp;usg=AOvVaw3Dz-bqXIugxpMVuWBwc2Dn">metrics</a></span><span class="c0">&nbsp;| MVSEP | uvronline</span></h6><p class="c1"><span>(Lead vocals/backing with instrumental)</span></p><p class="c1"><span class="c0">Make sure you don&rsquo;t have the option &ldquo;Vocals only&rdquo; checked in UVR.</span></p><p class="c1"><span>8GB VRAM users of AMD and Intel ARC GPUs need to use 160000 chunk_size, or the separation will be very slow.</span></p><p class="c1"><span class="c0">&ldquo;After dozens of tests I can tell this (...) is the best (better harmony detection, better differentiation between LVs and BVs, sounds fuller, less background Roformer bleed, better uncommon panning handling etc) (...) I noticed &quot;lead vocal panning&quot; works really well&rdquo; - dca</span></p><p class="c1"><span class="c0">&ldquo;It also can detect the double vocals&rdquo; - black_as_night</span></p><p class="c1"><span class="c0">It works the best for some previously difficult songs. Aufr33 and viperx model seems more consistent, but the new BS is still the best in overall - Musicalman</span></p><p class="c1"><span class="c0">&ldquo;My OG Mel also catches some of the FX/drums, I guess quite a difficult one due to how it&#39;s mixed&rdquo; - Becruily</span></p><p class="c1"><span class="c0">&ldquo;It does do better on mono than previous, sometimes confuses which voice should be the lead, but all models do that on mono in the exact use-case I normally test&rdquo; - Dry Paint Dealer Undr</span></p><p class="c1"><span class="c0">&ldquo;[In] no way inferior to the ViperX (Play da Segunda)&rdquo; - fabio5284</span></p><p class="c1"><span class="c0">&ldquo;The new karaoke model doesn&#39;t actually differentiate between lvs &amp; bvs and there&#39;s some lead vocal bleeding in the instrumental stem&rdquo; - scdxtherevolution</span></p><p class="c1"><span class="c0">VS the newer BS-Roformer MVSEP team model: &ldquo;sound isn&#39;t as clear, but it does an infinitely better job at telling lead/bgv apart&rdquo;</span></p><p class="c1"><span class="c0">Becruily:</span></p><p class="c1"><span class="c0">&ldquo;I want to remind something regarding my (and the frazer) models</span></p><p class="c1"><span class="c0">they&#39;re made to separate true lead vocals, meaning either all of the main singer&#39;s vocals, or if it&#39;s multiple singers - theirs too</span></p><p class="c1"><span class="c0">this means if the main singer has stuff like adlibs on top of the main vocals, these are considered lead vocals too - they go together</span></p><p class="c1"><span class="c0">if there are multiple singers singing on top of each other, including harmonise each other, and if there are additional background vocals behind those - all the singers will be separated as one main lead vocal, leaving only the true background vocals&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Noticed it a couple days ago. I&#39;ve had fantastic results with it so far. Much MUCH better at holding the &#39;S&#39; &amp; &#39;T&#39; sounds than the Rofo oke (for backing vox). Generally seems to provide fuller results... but also the typical &#39;ghost&#39; residue from the main vox can end up in the backing vox sometimes, but it&#39;s usually not enough to be an issue. I won&#39;t go so far as so say that it&#39;s replacing the other backing vox models for me entirely... but it feels like the best of both worlds that Rofo and UVR2 provide.&rdquo; - CC Karaoke</span></p><p class="c1"><span class="c6">Tips for the model</span></p><p class="c1"><span class="c0">- &ldquo;I had success by setting the BS Rofo Karaoke model to 100% Right, and then taking the &#39;Other&#39; result and reprocessing it at 100% Left to get the backing vocals cleanly out.</span></p><p class="c1"><span class="c0">Curious note on something I&#39;ve never tried or had to do before but it has worked wonderfully;</span></p><p class="c1"><span class="c0">I&#39;m isolating the backing vocals on Radiohead&#39;s Let Down.&rdquo; - CC Karaoke</span></p><p class="c1"><span class="c0">- If you use e.g. vocfv7beta1 as preprocessor for the model, you may get some quieter backing vocals better - Rainboom Dash</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.o2c4nxjhv6q9"><span class="c0">- MVSEP&rsquo;s BS Roformer by MVSep Team (SDR: 10.41) </span></h6><h6 class="c1 c27" id="h.enfpgqjvvt9m"><span>under option &quot;MVSep MelBand Karaoke (lead/back vocals)&quot;, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9068&amp;sa=D&amp;source=editors&amp;ust=1765035743045626&amp;usg=AOvVaw3adGMCfMr73zuOxiyVOCWV">metrics</a></span><span class="c0">. Might be a fine-tune. Use the option extract vocals first.</span></h6><h6 class="c1 c27" id="h.qtc6ys1659d1"><span class="c0">(&ldquo;In contrast with other Karaoke models, it returns 3 stems: &quot;lead&quot;, &quot;back&quot; and &quot;instrumental&quot;.)</span></h6><p class="c1"><span class="c0">&ldquo;If I had to compare it to any of the models, it is similar to the frazer and becruily models. Sometimes it does not detect the lead vocals especially if there&#39;s some heavy hard panning, but when it does, there is almost no bleed, and it works very well with heavy harmonies in mono from what I tested.&rdquo; - smilewasfound</span></p><p class="c1"><span class="c0">&ldquo;becruily &amp; frazer is better a little when the main voice is stereo&rdquo; - daylightgay</span></p><p class="c1"><span class="c0">&ldquo;On tracks I tested, harmony preservation was better in becruily &amp; frazer (...) the new model isn&#39;t worse, I ended up finding examples like Chan Chan by Buena Vista Social Club or The Way I Are by Timbaland where it is better than the previous kar model. The thing is, with the Kar models, it&#39;s just track per track. Difficult to find a model for batch processing as it&#39;s really different from one track to another&rdquo; - dca100fb8</span></p><p class="c1"><span class="c0">As for MVsep Team: &ldquo;It&rsquo;s the only model that combines the lead vocal doubles with the lead vocals stem. It&rsquo;s far more useful for dissecting harmonies on songs with vocal doubles like Backstreet Boys&rdquo; - heuheu</span></p><p class="c1"><span class="c0">&ldquo;I also found the new model to not keep some BGVs, mainly mono/low octave ones, despite higher SDR&rdquo; - becruily</span></p><p class="c1"><span class="c0">&ldquo;I think I&#39;ve found a solution for people who don&#39;t like the new model.</span></p><p class="c1"><span class="c0">If you put an audio file through the karaoke model and then put the lead vocal result through that, it usually picks up doubles. </span></p><p class="c1"><span class="c0">Which you can then put in your BGV stem if you&#39;d like&rdquo; - dynamic64</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ensemble of Mel v1e + BS Karaoke MVSep Team with extract vocals first option, Max Spec (using BS 2025.07 as reference and 200/200 for the values)</span></p><p class="c1"><span class="c0">&ldquo;It&#39;s very aggressive values cuz v1e is noisy, and it works quite well&rdquo;, the best ensemble for now (dca100fb8)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ensemble of BS Roformer Karaoke by anvuew + BS Resurrection Inst (aka &quot;unwa high instrum fullness&quot; on mvsep) + phase fix (using BS 2025.07 as reference), older, more crossbleeding - (dca100fb8)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;Ensemble of 3 models &quot;MVSep + Gabox + frazer/becruily&quot; gives 10.6 SDR on the leaderboard. I didn&#39;t upload it yet, but I had local testing.&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Ensemble of (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9190&amp;sa=D&amp;source=editors&amp;ust=1765035743050050&amp;usg=AOvVaw0RN9MA8qY1anxIAXe8faBI">metrics</a></span><span class="c0">):</span></p><p class="c1"><span class="c0">BS-Roformer Karaoke Frazer &amp; Becruily + BS-Roformer Karaoke Anvuew (avg/avg)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSEP fusion model of Gabox Karaoke and Aufr33/viperx <br>(tend to confuse BV/LV more than single models)</span></p><p class="c1"><span>- Gonzaluigi Karaoke fusion models (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Gonzaluigi/Mel-Band-Karaoke-Fusion/resolve/main/mel_band_karaoke_fusion_standard.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743050826&amp;usg=AOvVaw1frXdZm80e8k-YjXdnIECq">standard</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Gonzaluigi/Mel-Band-Karaoke-Fusion/resolve/main/mel_band_karaoke_fusion_aggressive.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743050998&amp;usg=AOvVaw23VFi9LxPy1xxGxHl2NLlK">aggresive</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Gonzaluigi/Mel-Band-Karaoke-Fusion/resolve/main/melband_karaokefusion_gonza.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743051190&amp;usg=AOvVaw3tDd09A2OaafpB2OTnoJ45">yaml</a></span><span class="c0">) -</span></p><p class="c1"><span class="c0">also confuses BV/LV more</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep MelBand Karaoke (lead/back vocals) SCNet XL IHF by becruily (SDR: 9.53)</span></p><p class="c1"><span class="c0">Worse SDR than the top performing Roformers, but works best in busy mix scenarios, and when Mel-Roformer models fail, generally bleedier arch. To fix the bleed in the back-instrum stem, use &ldquo;Extract vocals first&rdquo;, but &ldquo;I noticed a pattern that if you hear the lead vocals in the back-instrum track already (SCNet bleed), don&#39;t try to use Extract vocals first because there will be even more lead vocal bleed&rdquo; - dca (iirc it uses the biggest SDR BS-Roformer vocal model as preprocessor).</span></p><p class="c1"><span class="c0">&ldquo;Separates lead vocals better than Mel-Roformer karaoke becruily. It&#39;s not perfectly clean, sometimes a bit of the backing vocals slips through, but for now, scent karaoke model still the most reliable for lead vocals separation (imo)&rdquo; - neoculture </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus/uvronline) Lead and Backing vocal separator (in &ldquo;Extract Backing vocals&gt;Mel-Roformer Lead/Back)</span></p><p class="c1"><span class="c34">It uses big beta 5e model as preprocessor for becruily Mel Karaoke model </span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">&ldquo;In fact, the big beta 5e model is run after becruily Mel Karaoke&rdquo; Aufr33 (so you don&rsquo;t need the additional step to use this separator), plus it also allows controlling option for lead vocal panning like for BVE v2 (It&rsquo;s to &ldquo;to &quot;tell&quot; the AI &#8203;&#8203;where the main vocals are located (how they are mixed)&rdquo;. &ldquo;Doesn&#39;t even need Lead vocal panning a lot of the time, [the] ability to recognize what is LV and what is BV [is] impressive&rdquo; - dca).</span></p><p class="c1"><span class="c0">&ldquo;The new separator is available in the free version, however, due to its resource intensity, only the first minute of the song will be processed.&rdquo; if you don&rsquo;t have a premium.</span></p><p class="c1"><span class="c0">The difference from using single becruily Kar model is that, here, &ldquo;you get the third track, backing vocals.&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Becruily: &ldquo;Probably too resource-intensive, but you could try adding demudders to each step</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1) Karaoke model + demudding</span></p><p class="c1"><span class="c0">2) Separate vocals of BGV + demudidng </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But not sure how much noise this will bring</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(Or even a 50:50 ensemble with BVE OG)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer Karaoke by becruily </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-karaoke/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743055626&amp;usg=AOvVaw0CxNNUlU7h1vSZIxqYoQau">model file</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743055837&amp;usg=AOvVaw0WJz88XUzLYlhtMXULv7bQ">Colab</a></span><span class="c0">&nbsp;| MVSEP | x-minus</span></p><p class="c1"><span class="c0">(back/main vox/instrumental - 3 stems)</span></p><p class="c1"><span class="c0">Use voc_fv4 vocal model before running it (less bleeding than voc_fv6) or:</span></p><p class="c1"><span class="c0">&ldquo;first extract the vocals with a fullness model [it was Mel becruily vocal back then] and combine the results with a fullness instrumental model.&rdquo; - becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;It&#39;s a dual model, trained for both vocals and instrumental. It sounds fuller + understands better what is lead and background vocal, <br>and to me, it is better than any other karaoke model. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Important note: This is not a duet or male/female model. If 2 singers are singing simultaneously + background vocals, it will count both singers as lead vocals. The model strictly keeps only actual background vocals. The same goes for &quot;adlibs&quot; such as high notes or other overlapping lead vocals.</span></p><p class="c1"><span class="c0">The model is not foolproof. Some songs might not sound that much improved compared to others. It&#39;s very hard to find a dataset for this kind of task.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Compared to Aufr33&rsquo;s Melband model below, it can achieve e.g. cleaner pronunciation in some songs (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1361694470403260556&amp;sa=D&amp;source=editors&amp;ust=1765035743058500&amp;usg=AOvVaw0V_RTpNNxDVhRxGySU1Ubt">examples</a></span><span class="c0">).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Better than Mel Kar, UVR BVE v2, lalal.ai, Dango...&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;For sure better than [the] older Karaoke (aufr&#39;s model) for harmonies. Though I can say Dango can remain useful in certain situations&rdquo; - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">On x-minus there&rsquo;s lead vocal panning setting added for Mel-RoFormer Kar by becruily model. It&rsquo;s to &ldquo;to &quot;tell&quot; the AI &#8203;&#8203;where the main vocals are located (how they are mixed).&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;doesn&#39;t even need Lead vocal panning a lot of the time, [the] ability to recognize what is LV and what is BV [is] impressive&rdquo; - dca<br>&ldquo;Sometimes struggles when the backing vocals are the same notes as the lead vocals&rdquo; - isling. Seems like xminus panning can&rsquo;t solve such issues either.</span></p><p class="c1"><span class="c0">&ldquo;Had a similar issue as you however with the Chase Atlantic vocal, MDX Kar V2 with stereo 80% then Chain or Max mag extracts the leftovers works very very well not perfect (at least works for most CA song) but It&#39;s enough for me to do an edit&rdquo; - cali_tay98&ldquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It seems demudder shouldn&#39;t be used when Lead vocal panning is set to something different than center, I noticed it brings back the lead vocals in the inst w/BVs as it was before changing LV panning&rdquo; - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer Karaoke (by aufr33 &amp; viperx) on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035743061323&amp;usg=AOvVaw2x_HzsPFX1BzYujyxXrbnh">x-minus.pro</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://uvronline.app&amp;sa=D&amp;source=editors&amp;ust=1765035743061445&amp;usg=AOvVaw2kf9-h0UtUwISL1EKzIOGa">uvronline.app</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743061527&amp;usg=AOvVaw1C6EEnLYo2JPqEIn-YJ4wC">mvsep</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/qQA1XTrb%23LUNCfUMUwg4m4LZeicQwq_VdKSq9IQN34l0E1bb0fz4&amp;sa=D&amp;source=editors&amp;ust=1765035743061676&amp;usg=AOvVaw1amrMYL9I1mCNlZbvjbPVX">model file</a></span><span>&nbsp;(UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">instruction</a></span><span class="c0">) - online version above might work better, not sure about preprocessor model, maybe even old voc_ft, but not necessarily.</span></p><p class="c1"><span>This Mel may extract more than</span><span class="c20">&nbsp;BVE V2</span><span class="c0">, if &quot;extract directly from mixture&quot; on MVSEP doesn&rsquo;t detect the BVs (x-minus behavior for this model), the chances are &quot;extract from vocals part&quot; on MVSEP (which uses BS-Roformer 2024.08 for it) will detect more BVs (although with possible cross bleed between lead/back in inst+bv)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you ensemble the model above with Unwa v1e (Max) it removes all the muddiness of Mel Kar (dca100fb8)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;You can do it via:</span></p><p class="c1"><span class="c0">Choose Process Method --&gt; Audio Tools --&gt; Manual Ensemble --&gt; Max Spec</span></p><p class="c1"><span class="c0">Q: How do you select both inputs?</span></p><p class="c1"><span class="c0">A: Via Select Input, but if you want to batch process Manual Ensemble it&#39;s not possible yet&quot; (dca100fb8)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ensemble algorithms like ~&ldquo;min_spec in the direct ensemble are only available if the selected type of stems in the yaml corresponds with the target in UVR. </span></p><p class="c1"><span class="c0">Example:</span></p><p class="c1"><span class="c0">If the target in the yaml is:</span></p><p class="c1"><span class="c0">&nbsp; -vocals</span></p><p class="c1"><span class="c0">&nbsp; -other</span></p><p class="c1"><span class="c0">then you can&#39;t use it in the Vocal/Instrumental selection because it&#39;s not written that way in the yaml.&rdquo; (mesk)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/kar_gabox.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743064502&amp;usg=AOvVaw1JqfZXdRzjT0SctfP5Xd8b">KaraokeGabox</a></span><span>&nbsp;model (uses Aufr&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/config_mel_band_roformer_karaoke.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743064703&amp;usg=AOvVaw3nn-x8lF_i9GbTw68GVXfp">config</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035743064833&amp;usg=AOvVaw1sbcBKVzjJF8b9gzA6cCA9">Colab</a></span><span class="c0">&nbsp;- finetune of becruily model</span></p><p class="c1"><span class="c0">&ldquo;The lead vocals are good and clean! <br>While the backing tracks are lossy for this model, [it still] provide[s] great convenient for those who need LdV&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;The model doesn&#39;t keep the backing vocals below the main vocals, sometimes the backing vocals will be lost even though there are backing vocals there.&rdquo;</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span>- BVE v2 model on x-minus.pro/uvronline.app for premium users | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/XZpXyJAD%23if8wRRDxHZ0T-HiH8ZRLhXUloNIm87kpGKrBRMlHoq8&amp;sa=D&amp;source=editors&amp;ust=1765035743065782&amp;usg=AOvVaw3wXsAMkcx5-8y_TYq6A-E5">model</a></span><span>&nbsp;(uses &ldquo;4band_v4_ms_fullband&rdquo; stock </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1aGjDkPhqPLLlOKXeIfWDw09LElHMJfos/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743066024&amp;usg=AOvVaw3Tw10CxhFDELHgWb-H5jPw">config</a></span><span class="c0">) by Aufr33</span></p><p class="c1"><span class="c0">Place the model file in Ultimate Vocal Remover\models\VR_Models and config file in lib_v5\vr_network\modelparams (if doesn&rsquo;t exist already). Then pick &ldquo;4band_v4_ms_fullband.json&rdquo; and BV when asked to recognize the model (it has the same checksum as in modelparams folder if it&rsquo;s there already). Seems like it works with &ldquo;VR 5.1 model&rdquo; checked (and probably without it too).</span></p><p class="c1"><span class="c0">&ldquo;Note that this model should be used with a rebalanced mix. </span></p><p class="c1"><span class="c0">The recommended music level is no more than 25% or -12 dB.</span></p><p class="c1"><span>If you use this model in your project, please credit me.&rdquo;</span><span class="c0"><br>(it&#39;s v1 version is also added in UVR&rsquo;s &ldquo;Download More Models&rdquo;, but also without stereo width feature which can fix some issues when BVs are confused with other vocals).</span></p><p class="c1"><span class="c0">On x-minus &ldquo;When you select stereo, it applies a stereo narrower before AI processing.&rdquo;</span></p><p class="c1"><span class="c0">It used to be one of the best models for this purpose. On x-minus at certain point it used voc_ft for all vocals as a preprocessor already (not sure if it got changed).</span></p><p class="c1"><span class="c0">&quot;BVE sounds good for now but being an (u)vr model the vocals are soft (it doesn&rsquo;t extract hard sounds like K, T, S etc. very well)&quot; </span></p><p class="c1"><span class="c0">&quot;Seems to begin a phrase with a bit of confusion between lead and backing, but then kicks in with better separation later in the phrase.&quot;</span></p><p class="c1"><span class="c0">&ldquo;If something struggles to separate on bve v2 I change the lv panning option to either 50 or 80% [stereo or center], and it separates it amazingly.</span></p><p class="c1"><span class="c0">It even allows me to separate backing backing vocals from backing vocals&rdquo;<br>- For UVR BVE v2 LV bleed in Song without LV - download the BV track and add it to inst v1e model result - no vocal bleed/residues (introC). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I tried it ensembled with Gabox&#39;s model [kar_gabox&rdquo;] and they are amazing together. Yes you have to make the primary stem of aufr33&#39;s model &quot;Instrumental&quot; if you&#39;re ensembling&rdquo; - AG89 </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Newer Gabox experimental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/karaoke&amp;sa=D&amp;source=editors&amp;ust=1765035743069690&amp;usg=AOvVaw2KiVd8_519YeLH6tHlfX0o">Karaoke model</a></span><span>&nbsp;(June 2025)</span><span class="c0">. It&rsquo;s one stem target so keep extract_instrumental enabled for the rest stem.</span></p><p class="c1"><span class="c0">&ldquo;really hard to tell the difference between this and becruily&#39;s karaoke model&rdquo; minus the latter has more target stems.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Chain ensemble mode for B.V. models (available on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://x-minus.pro&amp;sa=D&amp;source=editors&amp;ust=1765035743070904&amp;usg=AOvVaw2mS0yUve1MjTkdGuygsaNf">x-minus.pro</a></span><span>&nbsp;for premium users, added in UVR beta 5.5/9.15 beta </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.5.0/UVR_Patch_9_15_23_6_35_BETA.exe&amp;sa=D&amp;source=editors&amp;ust=1765035743071176&amp;usg=AOvVaw3NlN74Pw4nIiBkbBfVZx8y">patch</a></span><span class="c0">&nbsp;already):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It is possible to recreate this approach using non-BVE v2 models in UVR by processing the output of one Karaoke model by another (possibly VR model as the latter) with Settings&gt;Additional Settings&gt;Vocal Split Mode option (so it separates using the main model for all vocals, then it uses the result as input for the next model).</span></p><p class="c1"><span class="c0">So you might experiment with using voc_ft or Kim Vocal 2 or 1296 as the main vocal model in the main UVR window, and in Vocal Split Mode use HP5 or HP6 or BVE model, so you won&rsquo;t have to make the process in 2 steps manually, so separating the result with another model once the first separation is done. Although Vocal Split Mode was designed mainly for BVE models, so in case of any problems with HP5/6 or Karaoke, you can test out also Settings&gt;Choose Advanced Menu&gt;[model arch]&gt;Secondary model instead.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Don&#39;t forget reading </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">vocals</a></span><span>&nbsp;to find the best</span><span class="c0">&nbsp;separation method for your song to use it for separation with Karaoke/BVE models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Recommended ensemble settings for Karaoke in UVR 5 GUI (instrumentals with backing vocals):</span></p><p class="c1"><span class="c0">- 5_HP-Karaoke-UVR, 6_HP-Karaoke-UVR, UVR-MDX-NET Karaoke 2 (Max Spec)</span></p><p class="c1"><span class="c0">(in e.g. &ldquo;min/max&rdquo; the latter is for instrumental)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Alternatively, use Manual Ensemble with UVR with Max Spec using x-minus&rsquo; </span><span class="c4"><a class="c3" href="#h.4bbgbbg4mfqq">UVR BVE v2 </a></span><span class="c0">result and the UVR ensemble result from the above.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or single model:</span></p><p class="c1"><span class="c0">- HP_KAROKEE-MSB2-3BAND-3090 (a.k.a. VR&#39;s 6HP-Karaoke-UVR)</span></p><p class="c1"><span class="c0">- UVR BV v2 on x-minus (and download &quot;Song without L.V.&quot;. Better solution, newer, different model)</span></p><p class="c1"><span class="c0">- 5HP can be sometimes better than 6HP</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035743074627&amp;usg=AOvVaw335BkpYiHr0DWuQz2D8j82">UVR5 GUI</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035743074746&amp;usg=AOvVaw24bER5QP-f4wJ2rt8FNCnz">x-minus.pro</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/blob/main/Vocal%2520Remover%25205_arch.ipynb%23scrollTo%3DCT8TuXWLBrXF&amp;sa=D&amp;source=editors&amp;ust=1765035743074931&amp;usg=AOvVaw05byd7yfJXeeIMCAd2w0dY">Colab</a></span><span class="c0">) - you might want to use Kim Vocal 2 or voc_ft or 1296 or MDX23C first for better results.</span></p><p class="c1"><span class="c0">- UVR-BVE-4B_SN-44100-1</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What are the differences between Mel-Roformer Karaoke and the last model?</span></p><p class="c1"><span class="c0">A: If the vocals don&#39;t contain harmonies, this model (Mel) is better. In other cases, it is better to use the MDX+UVR Chain ensemble for now.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox denoise/debleed Mel-Roformer | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/instrumental/denoisedebleed.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743075890&amp;usg=AOvVaw2aHQb1Kt4Esjbxr58yvdLX">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743076037&amp;usg=AOvVaw380S2EIr_HMPt7dXWT00N2">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035743076152&amp;usg=AOvVaw2PLnvy9gMb54c9jliKK0fV">Colab</a></span></p><p class="c1"><span class="c0">&ldquo;better results than kar v2&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox kar v2 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Karaoke_GaboxV2.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743076499&amp;usg=AOvVaw3j3uHs2ZSp6XU7hJon9KwE">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/karaoke/karaokegabox_1750911344.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743076678&amp;usg=AOvVaw25yeUVExBCU2hlRGwkn94Y">yaml</a></span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- De-echo VR model in UVR5 GUI set to maximum aggression</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.s4sjh68fo1sw">MedleyVox</a></span><span class="c0">&nbsp;with our trained model (more coherent results than current BV models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or ensemble in UVR:</span></p><p class="c1"><span class="c0">&quot;The karaoke ensemble works best with isolated vocals rather than the full track itself&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- VR Arc: 6HP-Karaoke-UVR</span></p><p class="c1"><span class="c0">- MDX-Net: UVR-MDX-NET Karaoke 2</span></p><p class="c1"><span class="c0">- Demucs: v4 | htdemucs_ft</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or:</span></p><p class="c1"><span class="c0">- VR Arc: 5HP-Karaoke-UVR</span></p><p class="c1"><span class="c0">- VR Arc: 6HP-Karaoke-UVR</span></p><p class="c1"><span class="c0">- MDX-Net: UVR-MDX-NET Karaoke 2</span></p><p class="c1"><span class="c0">(Max Spec, aggression 0, high-end process)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or:</span></p><p class="c1"><span class="c0">- VR arc: 5_HP-Karaoke </span></p><p class="c1"><span class="c0">- MDX-Net: UVR-MDX Karaoke 1 </span></p><p class="c1"><span class="c0">- MDX-Net: UVR-MDX Karaoke 2</span></p><p class="c1"><span class="c0">(you might want to turn off high-end process and post process)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or: </span></p><p class="c1"><span class="c0">- VR Arc: 5HP-Karaoke-UVR</span></p><p class="c1"><span class="c0">- VR Arc: 6HP-Karaoke-UVR</span></p><p class="c1"><span class="c0">- MDX-Net: UVR-MDX-NET Karaoke 1</span></p><p class="c1"><span class="c0">- MDX-Net: UVR-MDX-NET Karaoke 2</span></p><p class="c1"><span class="c0">(Min/Min Spec, Window Size 512, Aggression 100, TTA On)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If your main vocals are confused with backing vocals, use X-Minus and set &quot;Lead vocal placement&quot; to center (not in UVR5 at the moment).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Or </span><span class="c4"><a class="c3" href="#h.79cxg1a64b11">Mateus Contini&#39;s</a></span><span class="c0">&nbsp;method.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/page/bv-isolation&amp;sa=D&amp;source=editors&amp;ust=1765035743080439&amp;usg=AOvVaw2HBkyGDMFW5eXLRcx9Znr0">How to extract backing vocals X-Minus Guide</a></span><span class="c0">&nbsp;(can be executed in UVR5 as well)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Vinctekan Q&amp;A</span></p><p class="c1"><span class="c0">Q: Which BVE aggression settings (for VR model, e.g. uvr-bve-4b-sn-44100-1) is good for backing removal?</span></p><p class="c1"><span class="c0">A: &ldquo;I recommend starting from exactly from 0 and working from there to either - or +.</span></p><p class="c1"><span class="c0">0 is the baseline for BVE that are almost perfectly center.</span></p><p class="c1"><span class="c0">If it&#39;s off to the left or right a little bit, I would start from 50&rdquo;</span></p><p class="c1"><span class="c0">Q: How do I tell what side BVs are panned or if they are Stereo 50 % or 80 % without extracting them?</span></p><p class="c1"><span class="c0">A: &nbsp;&ldquo;It&#39;s more about listening to the track. The way I used to it is to invert the left channel with the right channel. In most cases this should only leave the reverb of the vocals in place, but if there is backing vocals that is panned either left or right, then it should be a bit louder than the reverb. Audacity&#39;s [Vocal Reduction and Isolation&gt;Analyze] feature usually can give a rough estimates as to how related the two channels are, but that does not tell where the backing vocal actually is. I would only recommend doing the above with a vocal output, though.&rdquo;</span></p><p class="c1"><span>Q: Does anyone know how to tell what side BV&#39;s (backing Vocals) are panned similar to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/900904142669754399/1170201735722188810/bve.png&amp;sa=D&amp;source=editors&amp;ust=1765035743082721&amp;usg=AOvVaw34Mp6VatiTQDl_LFNMdGp3">this</a></span><span class="c0">? Like, is there a way to tell using RipX? Or another tool. In my case I think mine might be Stereo 20 30 percent or lower</span></p><p class="c1"><span class="c0">A: &ldquo;Your ears [probably the least effective]</span></p><p class="c1"><span class="c0">If you have Audacity, select your entire track, and select [Vocal reduction and Isolation] and select the [Analyze] but it won&#39;t tell you which direction the panning is in.</span></p><p class="c1"><span class="c0">Or use it to isolate the sides, and just take a look at the output levels of each channel.</span></p><p class="c1"><span>Spectralayers&#39;s [</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DJeg2RzOvS7I&amp;sa=D&amp;source=editors&amp;ust=1765035743083909&amp;usg=AOvVaw224dbiKy8-nhUhrGGq9twJ">Unmix&gt;Multichannel Content</a></span><span class="c0">] tab can measure the output of frequencies in the spectrogram and can tell you when certain elements are not equal in loudness, which you can restore.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Dango.ai has also a good BVE model (expensive) - at least sometimes it gives better results than uvr bve v2 to get songs without lead vocals. &ldquo;meant for separating melody from harmony, not separating singer from singer, so you&#39;ll hear both [singers in one] stem&rdquo; if present<br><br>Later a new Advanced repair tool was added to &ldquo;fix any backing-vocals errors&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- AudiosourceRE Demix Pro has BVE/lead vocals model</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- lalal.ai has a new decent lead and backing vocals model</span></p><p class="c1"><span class="c0">If bve or mel karaoke model CAN do it, then they&#39;ll do it better, but if they CAN&#39;T do it, then lalal will do it better. &quot;I have seen lalal work better on mono audio than bve model.&quot; ~Isling</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">dca100fb8: &ldquo;For Instrumentals with Backing Vocals:</span></p><p class="c1"><span class="c0">If Mel Kar doesn&#39;t work, it&#39;s likely Dango Backing Vocal Keeper will not too, although it&rsquo;s not always the case, and still worth trying out - separating left and right channel with Dango Backing Vocal Keeper once fixed the issue.</span></p><p class="c1"><span class="c0">For back vocals/lead vocals model</span></p><p class="c1"><span class="c0">If neither Mel Kar or UVR BVE v2 work, it&#39;s likely lalal.ai Lead &amp; Back Vocal Splitter will work instead. Its deep Extraction seems to provide better results than Clear Cut&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.hyhpf8zg7p8x"><span>- </span><span class="c50">Advanced chain processing chart (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://lh3.googleusercontent.com/pw/AP1GczNwiJ8BSJdjCWA4Z0D7CHevRfEbOqbf4uBFZSYFEWIxoSm3tUfJVUrlTMJOolR9wD_IxNZgzf7Efe7Nh58-nAuzrZmoAOwXE-FgDFWztWCmMZcJ0ResQZCjP4PMG26BpWSSMhQO4CEiM4XGplqKggoY_mVTqXaT14EBXpweZ95Dy8SJmI69Wf3usD4pyl0E2zJyMxyWZ5MYKs3uz6eenqpF98BYowhl0Qvq55xLZEqfeUsnbhouJPctM792NzghD81lLh1gxNU5sLpyS_c9y79ZOAvPSnXpHp1vFPoqrPbYhYQ1E70HtxuPb7UOSyptwB4pnQVfuJ_JRZzLWq_GDbdWa2uBHznGLFOLnwrtwlH6Kewd2hU8sE9oJzOhPCBhWoY52bDsLqjSFct7AVfFBWUpNAUQpitAMr4pEAYIjc6EaSMyYgR_Cf8Y05htRoNmOqxn08kynl7xlXtQ-5duX1VcZj6cPZ-QSbaH6W-CyBrbPjfCsDymb4V5Yl53W1oVY5ZRQWzfkfM3_KrmP1RQVimzvAq36Vwv9IwjqL_PR9AcS6HHYukQ88ZwtUzuSo7BnzuuslRFVPMM0NxzbwkPP-MWrNzlPGdMCm8VsLnmIcEcq8CRw9CRFvWzII8LsgLDUcpBeo00BBZxRQ8P0mMtQ3OjQ0opjqb4v7OJqoteW-rTPDaIuvcfgu6udWDDSUJgYuHBHOYB3n42ASD0lShDA3yORjfgPNvkQpDIJ5ZOqlbMOZz2dlOjhzq69glN8dmEx2Kn1z2h9NZo7nhrrt8QWaHnHpGT_OxroAwxHscd6lodzSQKtS86zExbCpW3PrmslkQCeXnKL-LMd9Mmr_xN5tO_zfeEuaVhCBTwzJmbxEqg5yxpgQ1klsIzxeCiqIRzJ96i1A5Tv_BjjTGeHlMjyBbOl_iCT7TSbtP9krhYs0BymO_02BE0q1r95rCOlFHyyj1Fbnh38Zt9hBHEPYOYqsTYHvwhJIjmb2M89xOr2KA9qyybrSa5vbZx4X1y91cSxQ03%3Dw1345-h941-s-no-gm?authuser%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035743087328&amp;usg=AOvVaw19xyVwrFxTqtohN5YAGZ3R">image</a></span><span class="c0">)</span></h5><p class="c1"><span>It&rsquo;s a method utilizing old models, and e.g. Kim Vocals 2 can be potentially replaced by unwa&rsquo;s BS/Mel-Roformer models in </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta UVR</a></span><span>&nbsp;(or other good method for </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">vocals</a></span><span class="c0">) or ensembles mentioned in this document. Check the best current methods for vocals in one stem to find what works the best for your song to get all vocals before splitting to other stems using this diagram.</span></p><p class="c1"><span>htdemucs v4 above can be replaced by htdemucs_ft, as it&#39;s the fine-tuned version of the model (or </span><span class="c4"><a class="c3" href="#h.jmb1yj7x3kj7">MDX23 Colab</a></span><span>). Even better, you can use some of the methods for </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">4 stems</a></span><span class="c0">&nbsp;in this GDoc (like drums on x-minus).</span></p><p class="c1"><span class="c0">De-echo and reverb models can be potentially replaced by some better paid plugins like:</span></p><p class="c1"><span>DeVerberate by Acon Digital, Accentize DeRoom Pro (more in the </span><span class="c4"><a class="c3" href="#h.5zlfuhnreff5">de-reverb</a></span><span class="c0">&nbsp;section).</span></p><p class="c1"><span>UVR Denoise can be potentially replaced by less aggressive Aufr33 model on x-minus.pro (used when aggressiveness is set to minimum), and there&rsquo;s also newer Mel-Roformer (read </span><span class="c4"><a class="c3" href="#h.5zlfuhnreff5">de-reverb</a></span><span class="c0">&nbsp;section).</span></p><p class="c1"><span>As for </span><span class="c4"><a class="c3" href="#h.h110k6ouf88c">Karaoke</a></span><span>&nbsp;</span><span>models, there&#39;s e.g. a Mel-Roformer model on x-minus.pro for premium users or MVSEP/jarredeou inference </span><span class="c4"><a class="c3" href="#h.wbc0pja7faof">Colab</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">&quot;If the vocals don&#39;t contain harmonies, this model (Mel) is better. In other cases, it is better to use the MDX+UVR Chain ensemble for now.&quot;. It is possible to recreate to some extent this approach while not using BVE v2 models, by processing the output of main vocal model by one of Karaoke/BVE models in UVR (possibly VR model as the latter) using Settings&gt;Additional Settings&gt;Vocal Splitter Options, so it separates using one model, then it uses the result as input for the next model (see the Karaoke section).</span></p><p class="c1"><span class="c0">MedleyVox (not available in UVR) will be useful in the end in cases when everything else fails after you obtain all vocals in one stem, as it&#39;s very narrowband. But you can use AudioSR on it afterwards.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c18 c15"></span></p><h6 class="c1 c27" id="h.kkeba46q17rq"><span>&gt;Keeping only</span><span class="c18 c15">&nbsp;lead vocals </span></h6><h6 class="c1 c27" id="h.iz432qr6xna7"><span class="c0">in a song</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c23 c15 c30">Sometimes the same model might work for lead, sometimes for back vocals depending on a song</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (x-minus/uvronline) Lead and Backing vocal separator (in &ldquo;Extract Backing vocals&gt;Mel-Roformer Lead/Back)</span></p><p class="c1"><span class="c34">It uses big beta 5e model as preprocessor for becruily Mel Karaoke model </span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">&ldquo;In fact, the big beta 5e model is run after becruily Mel Karaoke&rdquo; Aufr33 (so you don&rsquo;t need the additional step to use this separator), plus it also allows controlling option for lead vocal panning like for BVE v2 (It&rsquo;s to &ldquo;to &quot;tell&quot; the AI &#8203;&#8203;where the main vocals are located (how they are mixed).&rdquo;. &ldquo;Doesn&#39;t even need Lead vocal panning a lot of the time, [the] ability to recognize what is LV and what is BV [is] impressive&rdquo; - dca).</span></p><p class="c1"><span class="c0">&ldquo;The new separator is available in the free version, however, due to its resource intensity, only the first minute of the song will be processed.&rdquo; if you don&rsquo;t have a premium.</span></p><p class="c1"><span>The difference from using single becruily Kar model is that, here, &ldquo;you get the third track, backing vocals.&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer Karaoke by becruily </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-karaoke/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743093634&amp;usg=AOvVaw3At-E4zDFNGsPvDqCFYUk8">model file</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743093862&amp;usg=AOvVaw1kgDwZMPHwHUg461rWoFQV">Colab</a></span><span class="c0">&nbsp;| MVSEP | x-minus</span></p><p class="c1"><span class="c0">&ldquo;It&#39;s a dual model, trained for both vocals and instrumental. It sounds fuller + understands better what is lead and background vocal</span></p><p class="c1"><span>- Gabox Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/kar_gabox.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743094316&amp;usg=AOvVaw2vVmcWrDlIZPtk16WUbO1E">KaraokeGabox</a></span><span>&nbsp;model (uses Aufr&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/config_mel_band_roformer_karaoke.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743094497&amp;usg=AOvVaw26jeAKzq6AxYLi6r2MHiup">config</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035743094616&amp;usg=AOvVaw0-RhqhCbfZvyn0SxKWJPac">Colab</a></span></p><p class="c1"><span class="c0">&ldquo;The lead vocals are good and clean! <br>While the backing tracks are lossy for this model, [it still] provide[s] great convenient for those who need LdV&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;The model doesn&#39;t keep the backing vocals below the main vocals, sometimes the backing vocals will be lost even though there are backing vocals there.&rdquo;</span></p><p class="c1"><span>- Newer Gabox experimental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/tree/main/melbandroformers/karaoke&amp;sa=D&amp;source=editors&amp;ust=1765035743095365&amp;usg=AOvVaw1KfM8ANtE8b26vc-wpCbFP">Karaoke model</a></span><span class="c0">&nbsp;(June 2025). It&rsquo;s one stem target so keep extract_instrumental enabled for the rest stem.</span></p><p class="c1"><span class="c0">&ldquo;really hard to tell the difference between this and becruily&#39;s karaoke model&rdquo; minus the latter has more target stems.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- BVE v2 model on x-minus.pro/uvronline.app for premium users | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/XZpXyJAD%23if8wRRDxHZ0T-HiH8ZRLhXUloNIm87kpGKrBRMlHoq8&amp;sa=D&amp;source=editors&amp;ust=1765035743095980&amp;usg=AOvVaw0ucti9xBw2WX_zNAlh8Kuv">model</a></span><span class="c0">&nbsp;(&ldquo;4band_v4_ms_fullband&rdquo; stock config) by Aufr33</span></p><p class="c1"><span>Place the model file in Ultimate Vocal Remover\models\VR_Models and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1aGjDkPhqPLLlOKXeIfWDw09LElHMJfos/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743096310&amp;usg=AOvVaw0oM8vwNLWtr6EtKpPs2wOP">config</a></span><span class="c0">&nbsp;file in lib_v5\vr_network\modelparams. Then pick &ldquo;4band_v4_ms_fullband.json&rdquo; and BV when asked to recognize the model (it has the same checksum as in modelparams folder if it&rsquo;s there already). Also, I think it&#39;s not a VR 5.1 model.</span></p><p class="c1"><span class="c0">&ldquo;Note that this model should be used with a rebalanced mix. </span></p><p class="c1"><span class="c0">The recommended music level is no more than 25% or -12 dB.</span></p><p class="c1"><span class="c0">If you use this model in your project, please credit me.&rdquo;<br>(it&#39;s v1 version is also added in UVR&rsquo;s &ldquo;Download More Models&rdquo;, but also without the stereo width feature which can fix some issues when BVs are confused with other vocals).</span></p><p class="c1"><span class="c0">On x-minus &ldquo;When you select stereo, it applies a stereo narrower before AI processing.&rdquo;</span></p><p class="c1"><span class="c0">(sometimes it might work for lead, sometimes for back vocals)</span></p><p class="c1"><span class="c0">It used to be one of the best models so far. On x-minus it used voc_ft for all vocals as a preprocessor already.</span></p><p class="c1"><span class="c0">&quot;Seems to begin a phrase with a bit of confusion between lead and backing, but then kicks in with better separation later in the phrase.&quot;</span></p><p class="c1"><span class="c0">&ldquo;If something struggles to separate on bve v2 I change the lv panning option to either 50 or 80% [stereo or center], and it separates it amazingly.</span></p><p class="c1"><span class="c0">It even allows me to separate backing backing vocals from backing vocals&rdquo;</span></p><p class="c1"><span class="c0">&quot;BVE sounds good for now but being an (U)VR model the vocals are soft (it doesn&rsquo;t extract hard sounds like K, T, S etc. very well)&quot; <br>- For UVR BVE v2 LV bleed in Song without LV - download the BV track and add it to inst v1e model result - no vocal bleed/residues (introC). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer Karaoke (by aufr33 &amp; viperx) on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035743099108&amp;usg=AOvVaw1kcTsjyvAkIuQUfu_zj6Ta">x-minus.pro</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://uvronline.app&amp;sa=D&amp;source=editors&amp;ust=1765035743099205&amp;usg=AOvVaw2KO2TYCOihLEv5uh1pF8pV">uvronline.app</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743099277&amp;usg=AOvVaw0lhgi3ewFPZJ1bW8ni6dU7">mvsep</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/qQA1XTrb%23LUNCfUMUwg4m4LZeicQwq_VdKSq9IQN34l0E1bb0fz4&amp;sa=D&amp;source=editors&amp;ust=1765035743099422&amp;usg=AOvVaw0IL1_nEJudi-8Gj5To8LWq">model file</a></span><span>&nbsp;(UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">instruction</a></span><span class="c0">) - online version above might work better</span></p><p class="c1"><span>(may extract more than</span><span class="c20">&nbsp;BVE V2</span><span class="c0">), if &quot;extract directly from mixture&quot; on MVSEP doesn&rsquo;t detect the BVs (x-minus behavior for this model), the chances are &quot;extract from vocals part&quot; on MVSEP (which uses BS-Roformer 2024.08 for it) will detect more BVs (although with possible cross bleed between lead/back in inst+bv)</span></p><p class="c1"><span>- Gabox Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/kar_gabox.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743100253&amp;usg=AOvVaw137PhSluTJ5ZH2Cjy9j-dz">KaraokeGabox</a></span><span>&nbsp;model (uses Aufr&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/config_mel_band_roformer_karaoke.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743100431&amp;usg=AOvVaw1iudAlb0qpUvyaSgados6n">config</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035743100546&amp;usg=AOvVaw1WRQVHexma3fL5ZNX866mT">Colab</a></span></p><p class="c1"><span class="c0">&ldquo;The lead vocals are good and clean! <br>While the backing tracks are lossy for this model, [it still] provide[s] great convenient for those who need LdV&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;The model doesn&#39;t keep the backing vocals below the main vocals, sometimes the backing vocals will be lost even though there are backing vocals there.&rdquo;</span></p><p class="c1"><span>- Gabox Mel </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/experimental/kar_gabox.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743101272&amp;usg=AOvVaw3cDVrC0Q5GC-Sp4Fw1ntvo">KaraokeGabox</a></span><span>&nbsp;model (uses Aufr&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Colab-for-new-MDX_UVR_models/releases/download/v1.0.0/config_mel_band_roformer_karaoke.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743101467&amp;usg=AOvVaw11tUbtmrvanb1dT20GqBc4">config</a></span><span>) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035743101581&amp;usg=AOvVaw1LEXQFbdZfuHR3G-_Iwbwg">Colab</a></span></p><p class="c1"><span class="c0">&ldquo;The lead vocals are good and clean! <br>While the backing tracks are lossy for this model, [it still] provide[s] great convenient for those who need LdV&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;The model doesn&#39;t keep the backing vocals below the main vocals, sometimes the backing vocals will be lost even though there are backing vocals there.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- anvuew </span><span class="c4"><a class="c3" href="#h.5zlfuhnreff5">dereverb</a></span><span>&nbsp;</span><span>Mel-Roformer model v2 (&ldquo;on some songs I tried it worked better than karaoke models&rdquo;) not for duets, it debleeds too, &ldquo;cleaner backing vocals [than the below], can sometimes mistake main vocals/delay for backing vocals more often than [the below])&rdquo;<br>- karokee_4band_v2_sn a.k.a. UVR-MDX NET Karaoke 2 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743102779&amp;usg=AOvVaw0D-OpA8E1QzD5GUNnXYkkR">MVSEP</a></span><span>&nbsp;[MDX B (Karaoke)]</span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CO3KRvcFc1EuRh7YJea6DtMM6Tj8NHoB&amp;sa=D&amp;source=editors&amp;ust=1765035743102973&amp;usg=AOvVaw1aAf-1gK9EAQtNoJ9WQwNu">Colab</a></span><span>&nbsp;</span><span>/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035743103085&amp;usg=AOvVaw2YVZG_qzmpFOme4WXqbJxx">UVR5 GUI</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035743103162&amp;usg=AOvVaw0zgRlmC1npiyhDnXEfQMXm">x-minus.pro</a></span><span class="c0">) - &ldquo;best for keeping lead vocal detail&rdquo; on its own, &ldquo;cleaner main vocals, has significantly less bleeding than the MVSep counterpart&rdquo;, removes backing vocals from a track, but when we use min_mag_k it can return similar results to:</span></p><p class="c1"><span class="c0">- Demix Pro (paid, &ldquo;keeps more backing vocals [than Karaoke 2] (and somehow the lead vocals are also better most of the time, with fuller sound&rdquo; </span></p><p class="c1"><span class="c0">&ldquo;Demix is better for keeping background vocals yes, but for the lead ones they tend to sound weaker (the spectrum isn&rsquo;t as full and has more holes than karaoke 2, but this isn&rsquo;t always a bad thing because the lead vocals themselves are cleaner, the mdx karaoke 2 might produce fuller lead vocals, but you will most certainly have some background vocals left too&rdquo;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Fusion model of Gabox Karaoke and Aufr33/viperx model on MVSEP<br>(tend to confuse BV/LV more than single models)</span></p><p class="c1"><span>- Gonzaluigi Karaoke fusion models (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Gonzaluigi/Mel-Band-Karaoke-Fusion/resolve/main/mel_band_karaoke_fusion_standard.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743104810&amp;usg=AOvVaw2HbYwnmpTEMSKBYJa0R609">standard</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Gonzaluigi/Mel-Band-Karaoke-Fusion/resolve/main/mel_band_karaoke_fusion_aggressive.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743104963&amp;usg=AOvVaw1Op9RMJrLcdTEaSL6TRrh9">aggresive</a></span><span>&nbsp;</span><span>| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Gonzaluigi/Mel-Band-Karaoke-Fusion/resolve/main/melband_karaokefusion_gonza.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743105105&amp;usg=AOvVaw2tH2ewy_NNy3FMVNXaVKKq">yaml</a></span><span class="c0">) -</span></p><p class="c1"><span class="c0">also confuses BV/LV more</span></p><p class="c1"><span class="c0">- MDX B Karaoke on mvsep.com (exclusive) - good, but as an alternative you could use MDX Karaoke 2 in UVR 5 (they are different)</span></p><p class="c1"><span class="c0">&ldquo;I personally wouldn&#39;t recommend 5/6_hp karaoke, except for using 5_hp karaoke as a last resort, you could also use the x minus bve model in uvr which sometimes is good with lead vocals&rdquo;</span></p><p class="c1"><span>- UVR-BVE-4B_SN-44100-1<br>- </span><span class="c4"><a class="c3" href="#h.3c6n9m7vjxul">Center extraction</a></span><span class="c0">&nbsp;model</span></p><p class="c1"><span>- Melodyne </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/junh1024/junh1024-Documents/blob/master/Audio/Melodyne%2520Quickstart.md%23introduction&amp;sa=D&amp;source=editors&amp;ust=1765035743106032&amp;usg=AOvVaw3s1cZWTkGo8aIwIXhutsCV">guide</a></span></p><p class="c1"><span>- RipX</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(doesn&rsquo;t work for everyone) </span></p><p class="c1"><span class="c0">- MDX-UVR Inst HQ_3 - new, best in removing background vocals from a song (e.g. from Kim Vocal 2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or consecutive models processing:</span></p><p class="c1"><span class="c0">- Vocals (good vocal stem from e.g. voc_ft or 1296 or MDX23C single models or ensembles of MDX23C / MDX23 2.2 / UVR top/near top SDR / Ensemble of only vocal models: Kim 1, 2, voc_ft, MDX23C_D1581, eventually with demucs_ft </span></p><p class="c1"><span class="c0">&gt;The vocal result separated with-&gt; </span></p><p class="c1"><span class="c0">Karaoke model -&gt; Lead_Voc &amp; Backing_Voc </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/l43CRVgrv4E&amp;sa=D&amp;source=editors&amp;ust=1765035743107134&amp;usg=AOvVaw3E3KkJHbkZxhFHnmKAEArE">Tutorial</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span>&nbsp;(+ </span><span class="c20">experimentally split stereo channels and separate them on their own, then join channels back</span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.vktvthhthrvh">arigato78 method</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Karaoke 2 really won&#39;t pick up any chorus lead vocals EXCEPT for ad-libs</span></p><p class="c1"><span class="c0">6-HP will pick up the melody, although it&#39;s usually muffled as hell&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Q: is mdx karaoke 2 still the best for lead and back vocals&#39; separation?</span></p><p class="c1"><span class="c0">A: I&#39;m finding it&#39;s the best for &quot;fullness&quot; but 6-HP picks up chorus melody while K2 only usually picks up ad-libs</span></p><p class="c1"><span class="c0">I personally like mixing K2, 6-HP (and sometimes 5-HP if 6-HP sounds very thin) together</span></p><p class="c1"><span class="c0">also, let&#39;s say a verse has back vocals that are just the melody behind the lead vocal (instead of harmonies) for a doubling effect, sometimes K2 will still pick up both the lead and double.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">AG89 avg ensemble:</span></p><p class="c1"><span class="c0">UVR-5-1_4band_v4_ms_fullband_BVE_V2, </span></p><p class="c1"><span class="c0">Karaoke_GaboxV2, </span></p><p class="c1"><span class="c0">mel-band_karaoke_fusion_standard</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.9h585vwqgcvg"><span class="c18 c15">Harmonies</span></h6><p class="c1"><span class="c0">For more layers from the above (e.g. starting with voc_ft/1296/Mel/BS [or other good model]&gt;Karaoke 2 [or other])</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- becruily &amp; frazer BS-Roformer Karaoke (or </span><span class="c4"><a class="c3" href="#h.vg1wnx1dc4g0">more</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">- Stereo width feature for uvr bve v2 by setting it to 80% (it might use voc_ft as preprocessor already) - on x-minus.pro/uvronline.app</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jeonchangbin49/medleyvox&amp;sa=D&amp;source=editors&amp;ust=1765035743109850&amp;usg=AOvVaw0lR0wLgmtPxM_mMIX-H8lX">Medley Vox</a></span><span>&nbsp;(free, 24kHz SR model trained by Cyrus, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/10x8mkZmpqiu-oKAd8oBv_GSnZNKfa8r2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743110032&amp;usg=AOvVaw0ODmQvWH4CTRdfSIaBJkBH">Colab</a></span><span>, local installation </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/VbM4qp0VP80&amp;sa=D&amp;source=editors&amp;ust=1765035743110137&amp;usg=AOvVaw0nK_9itJPE4Otpv66QVksG">tutorial</a></span><span>, more </span><span class="c4"><a class="c3" href="#h.s4sjh68fo1sw">info</a></span><span>, use e.g. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.i7mm2bj53u07&amp;sa=D&amp;source=editors&amp;ust=1765035743110332&amp;usg=AOvVaw13raYzgy6DFH9p_F4LhS8x">AudioSR</a></span><span>&nbsp;afterwards</span><span class="c0">)</span></p><p class="c1"><span>- Sucial Mel-Roformer dereverb/echo model #3 called &ldquo;fused&rdquo;: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer/blob/main/dereverb_echo_mbr_fused_0.5_v2_0.25_big_0.25_super.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743110640&amp;usg=AOvVaw3KxVx2WSECucf-JYBzhoSR">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer/blob/main/config_dereverb_echo_mbr_v2.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743110773&amp;usg=AOvVaw36JfZyKFzK0EcuXORzy7T6">yaml</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.celemony.com/en/melodyne/what-is-melodyne&amp;sa=D&amp;source=editors&amp;ust=1765035743110926&amp;usg=AOvVaw0LnmophNnju0_o-V5UDJ4l">Melodyne</a></span><span>&nbsp;</span><span class="c0">(paid, 30 days trial) - &ldquo;the best way to ensure it&rsquo;s the correct voice&rdquo;, or</span></p><p class="c1"><span>- eventually Hit &#39;n&#39; Mix </span><span class="c4"><a class="c3" href="#h.1bm9wmdv6hpf">RipX</a></span><span class="c0">&nbsp;DAW Pro 7 (paid/trial)</span></p><p class="c1"><span class="c0">In Melodyne it is &quot;harder to do but can be cleaner since you can more easily deal with the incorrect harmonics than RipX sometimes choses&quot;</span></p><p class="c1"><span class="c0">&quot;every time I&rsquo;d run a song through RipX I was only able to separate 4-5&quot; harmonies</span></p><p class="c1"><span class="c0">(or also)</span></p><p class="c1"><span>- Mel-Roformer Karaoke (by becruily) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-karaoke/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743111817&amp;usg=AOvVaw3iFLuREooT_UsHNscziqWR">model file</a></span><span class="c0">&nbsp;(better than aufr&rsquo;s model)</span></p><p class="c1"><span>- Dango.ai (paid, might be still useful in certain situations)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Choral Quartets F0 Extractor - &ldquo;midi outputs, but it works&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For research</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://c4dm.eecs.qmul.ac.uk/ChoralSep/&amp;sa=D&amp;source=editors&amp;ust=1765035743112644&amp;usg=AOvVaw1fSgeYE4qTeAUsUttxBW8i">https://c4dm.eecs.qmul.ac.uk/ChoralSep/</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://c4dm.eecs.qmul.ac.uk/EnsembleSet/&amp;sa=D&amp;source=editors&amp;ust=1765035743112830&amp;usg=AOvVaw2BMcDwEmnaSwacJhSWPtiT">https://c4dm.eecs.qmul.ac.uk/EnsembleSet/</a></span><span>&nbsp;(similar results to MedleyVox)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.7bakw3ajb3ii"><span class="c22">For</span><span class="c18 c15">&nbsp;two singers in a duet from one song</span></h6><p class="c1"><span>(use on already separated </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">vocals</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">- becruily &amp; frazer BS Karaoke (sometimes can separate even 3 singers if the vocals aren&#39;t completely glued into one, especially if it&#39;s male and female - maxerv19, </span></p><p class="c1"><span class="c0">&quot;It&#39;s getting better than MedleyVox&quot; - ryanz48) </span></p><p class="c1"><span>- Becruily Mel Karaoke</span></p><p class="c1"><span class="c22">- </span><span class="c4 c22"><a class="c3" href="#h.s4sjh68fo1sw">MedleyVox</a></span><span class="c22">&nbsp;</span><span>(trained by Cyrus, 24kHz SR - use e.g. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.i7mm2bj53u07&amp;sa=D&amp;source=editors&amp;ust=1765035743114078&amp;usg=AOvVaw0eNmUjI9W71G7QwOj9xe7j">AudioSR</a></span><span>&nbsp;afterwards, MVSEP, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/10x8mkZmpqiu-oKAd8oBv_GSnZNKfa8r2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743114234&amp;usg=AOvVaw1w1OlMWAK-YKGSSOVC66y4">Colab</a></span><span>,</span><span>&nbsp;local installation </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/VbM4qp0VP80&amp;sa=D&amp;source=editors&amp;ust=1765035743114356&amp;usg=AOvVaw0cQOzaorcoo9XHVvZujO5Y">tutorial</a></span><span>&nbsp;[use vocals 238 model]</span><span>, more </span><span class="c4"><a class="c3" href="#h.s4sjh68fo1sw">info</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">&ldquo;best at it, but not guaranteed to work always. 5% chances of perfectly separating duets on MedleyVox, or else it always false detects and switches back and forth&rdquo; &ldquo;also does a pretty good job on other solo instruments&rdquo;</span></p><p class="c1"><span class="c0">- MVSEP Multispeaker model (Experimental section at the bottom)<br>Works well for rap overlapped with singing in one already separated vocal stem.</span></p><p class="c1"><span class="c0">&ldquo;Seems very picky with audio, most of the songs/files I tried didn&#39;t work</span></p><p class="c1"><span class="c0">MedleyVox works on the other side (regardless that it&#39;s of lower quality)&rdquo; - becruily</span></p><p class="c1"><span class="c0">- MVSEP Male/Female:</span></p><p class="c1"><span class="c0">a) Mel-Roformer Male/Female separation model 13.03 SDR</span></p><p class="c1"><span class="c0">a) SCNet XL Male/Female separation model on MVSEP (same model base)</span></p><p class="c1"><span class="c0">SDR on the same dataset: 11.8346 vs 6.5259 (Sucial)</span></p><p class="c1"><span class="c0">Sometimes the old Sucial model might still do a better job at times, so feel free to experiment.</span></p><p class="c1"><span>- Aufr33 BS-Roformer Male/Female beta </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/XZwV2QwB%235nvWpmvtoBMTJkpor-lMUZCbBZWDH-3i52ELJS_JmcU&amp;sa=D&amp;source=editors&amp;ust=1765035743116164&amp;usg=AOvVaw0fCUN7026SlTriDUz72SJf">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Chorus_Male_Female_BS_Roformer/blob/main/config_chorus_male_female_bs_roformer.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743116325&amp;usg=AOvVaw1T-HCmG_v5FY7pTOOkUvY6">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743116511&amp;usg=AOvVaw14nV-6VCPoVYhhskln6YSn">Colab</a></span><span class="c0">&nbsp;| x-minus (uses Kim-Mel-Band-Roformer-FT2 as preprocessor) | MVSEP</span></p><p class="c1"><span class="c0">(based on BS-RoFormer Chorus Male Female by Sucial) SDR 8.18</span></p><p class="c1"><span>- Male/female BS-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2525052333&amp;sa=D&amp;source=editors&amp;ust=1765035743116921&amp;usg=AOvVaw1bGxoaoVVI4oDS6fvVnD_t">model</a></span><span>&nbsp;by Sucial | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/15dxMvEanC8h_djEuHoQXHKMk0ERN02_y/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743117063&amp;usg=AOvVaw1NzZgr5_fzYcjD7ZJHzFkh">config</a></span><span>&nbsp;for </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span class="c56">&nbsp;</span><span class="c56">| tensor match error </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nomadkaraoke/python-audio-separator/releases/download/model-configs/deverb_bs_roformer_8_384dim_10depth_config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743117324&amp;usg=AOvVaw3vZMBBLTkto_-cYsDhtnQe">fix</a></span><span class="c56"><br></span><span>I</span><span class="c0">f they sing at intervals [one by one - not together] they cannot be separated. | MVSEP</span></p><p class="c1"><span>- Mel-Roformer Karaoke on x-minus.pro (model files in </span><span class="c4"><a class="c3" href="#h.vg1wnx1dc4g0">Karaoke</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">- MDX-UVR Karaoke models</span></p><p class="c1"><span class="c0">- VR&#39;s 5_HP or ev. 6_HP in UVR</span></p><p class="c1"><span class="c0">- BVE v2 on x-minus (already uses voc_ft as preprocessor for separating vocals)</span></p><p class="c1"><span>It might be still not enough, then continue and/or look for Dolby Atmos </span><span class="c4"><a class="c3" href="#h.ueeiwv6i39ca">rip</a></span><span>&nbsp;</span><span class="c0">and retry; works for several backing vocals when lead vocal panning is set to center, &ldquo;then running the bgv through bve v2 again, but this time set lead vocal panning to 80% but be aware the lead vocal quality will not be that good with this model&rdquo; - Isling)</span></p><p class="c1"><span>- Dry Paint Dealer Undr&rsquo;s Melband Roformer and Demucs Lead and Rhythm guitar </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JH2tjhgDcJgvdi-hrQT82RsaV2XhE8hn?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743118787&amp;usg=AOvVaw0_Sqq29qspvFBRc_cnMUMv">models</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/iamycy/duet-svs-diffusion&amp;sa=D&amp;source=editors&amp;ust=1765035743118951&amp;usg=AOvVaw20KYd3sFDfoYOjqQKS9ZUm">duet-svs-diffusion</a></span><span>&nbsp;(&ldquo;mono/16kHz, 24kHz sample rate, and quality is lower than MedleyVox models&rdquo;)</span></p><p class="c1"><span class="c0">- RipX (paid)</span></p><p class="c1"><span class="c0">- Melodyne (paid, &ldquo;with polyphonic mode, with a lot of manual finetuning in the detection tab, and this can only work if the voices are not on same pitch&rdquo;). </span></p><p class="c1"><span>- SpectraLayers 11 (but it&rsquo;s mainly dedicated for voice, not singing)</span></p><p class="c1"><span class="c6">Spectral painting:</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://isse.sourceforge.net/&amp;sa=D&amp;source=editors&amp;ust=1765035743119717&amp;usg=AOvVaw3Dq0gWMX18bhK3Cvq5duGE">ISSE</a></span><span>&nbsp;(free, you can figure out which voice is who&#39;s just by frequencies alone; use on e.g. separated vocals too)</span></p><p class="c1"><span>- RX Editor&rsquo;s brush (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/118uALJXl_qBLtL3nkftdOxOJydEkDYZQ/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743120069&amp;usg=AOvVaw19xE_4bwNdF_4NNrTMzwC4">video</a></span><span class="c0">&nbsp;by Bas) </span></p><p class="c1"><span>- Audacity (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/PI3VJqa&amp;sa=D&amp;source=editors&amp;ust=1765035743120211&amp;usg=AOvVaw285n2qRHXBNXSnYU2gybfw">image</a></span><span class="c0">) less effective </span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/echometerain/Ampter&amp;sa=D&amp;source=editors&amp;ust=1765035743120358&amp;usg=AOvVaw3vrkJ8ZO5d3qQi9KgoNsuF">Ampter</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span>-</span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/HarmoniaLeo/Filter-Artist&amp;sa=D&amp;source=editors&amp;ust=1765035743120511&amp;usg=AOvVaw2DETYQpt25QchCi5qXZ31R">Filter-Artist</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://www.nicolasfournel.com/?page_id%3D125&amp;sa=D&amp;source=editors&amp;ust=1765035743120646&amp;usg=AOvVaw0fhJCWJTDkm25BgPBCUOr9">AudioPaint</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Notes</span></p><p class="c1"><span class="c0">If artists sing the same notes, Karaoke models will rather not work in this case. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If BVs are heard in the center, don&#39;t use the MDX karaoke model but the VR karaoke model instead.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Use the chain algorithm with mdx (kar) v2 on x-minus which will use uvr (kar) v2 to solve the issue. It will be available after you process the song with MDX. (Aufr33/dca)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The MDX models seem to have a cleaner separation between lead and backing/background vocals, but they often don&#39;t do any actual separation, meanwhile the VR models are less clean, but they seem to be better at detecting lead and background&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;MDX models basically require the lead to be completely center and the BV to be stereo</span></p><p class="c1"><span class="c0">whereas VR ones don&#39;t really care as much about stereo placement&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You could also ask </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/@playdasegunda&amp;sa=D&amp;source=editors&amp;ust=1765035743122461&amp;usg=AOvVaw0o6d0jVG5Rjp9NztENMg36">playdasegunda</a></span><span>/play da primeira/viperx for separation, as he has some decent private method/models for double vocals better than becruily model (although the latter can be still close), although newer frazer &amp; becruily model is &ldquo;no way inferior to the ViperX (Play da Segunda). The rumour says, viperx model on Play da Segunda was trained on 40GB dataset allegedly (it would be small), and the model can be bought for 500$ when you contact via email. It&#39;s actually a set of models used for the final inference. <br>For the record, the open-sourced model by the duo costed 600$ on compute and probably used a bigger dataset, achieved a bit smaller SDR, but it&rsquo;s a single model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For research:</span></p><p class="c1"><span class="c0">&ldquo;These archs are [...] really promising for multiple speakers separation, and should be working for multiple singers separation if trained on singing voice:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/dmlguq456/SepReformer&amp;sa=D&amp;source=editors&amp;ust=1765035743123994&amp;usg=AOvVaw2WRBblmOgQzH0cR3gP8dxv">https://github.com/dmlguq456/SepReformer</a></span><span>&nbsp;</span><span class="c0">(current SOTA)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/JusperLee/TDANet&amp;sa=D&amp;source=editors&amp;ust=1765035743124192&amp;usg=AOvVaw2_IbTFmIKHNi58HUfOiV0W">https://github.com/JusperLee/TDANet</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/alibabasglab/MossFormer2&amp;sa=D&amp;source=editors&amp;ust=1765035743124368&amp;usg=AOvVaw2ucgB7RWjCKtCl2F4aEGmi">https://github.com/alibabasglab/MossFormer2</a></span><span class="c0">&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt; Separating two main vocals </span></p><p class="c1"><span class="c0">E.g. one panned about 30% left and the other right</span></p><p class="c1"><span>- &ldquo;use bve v2 and click the &ldquo;lead vocal panning&rdquo; button&rdquo; on x-minus premium</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">For vocals with vocoder</span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">- voc_ft</span></p><p class="c1"><span class="c0">Alternatively, you can use:</span></p><p class="c1"><span class="c0">- 5HP Karaoke (e.g. with aggression settings raised up) or </span></p><p class="c1"><span class="c0">- Karaoke 2 model (UVR5 or Colabs). Try out separating the result obtained with voc_ft as well.</span></p><p class="c1"><span class="c0">- BS-Roformer model ver. 2024.04 on MVSEP (better on vocoder than the viperx&rsquo; model).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;If you have a track with 3 different vocal layers at different parts, it&#39;s better to only isolate the parts with &#39;two voices at once&#39; so to speak&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.ea9fj444mg3m"><span class="c22">Various speakers&#39; isolation (from e.g. podcast or movie)<br></span><span class="c0"><br>- MVSEP Male/Female SCNet model </span></h6><p class="c1"><span>- MVSEP Male/Female MelRoformer model</span></p><h6 class="c1 c27" id="h.cfw9tfwd012o"><span>- Aufr33 BS-Roformer Male/Female beta </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/XZwV2QwB%235nvWpmvtoBMTJkpor-lMUZCbBZWDH-3i52ELJS_JmcU&amp;sa=D&amp;source=editors&amp;ust=1765035743126758&amp;usg=AOvVaw2JEIXXme44EWcn-JcD05Ev">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Chorus_Male_Female_BS_Roformer/blob/main/config_chorus_male_female_bs_roformer.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743126976&amp;usg=AOvVaw2SaytLbltha-9g4YYy1IGR">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743127180&amp;usg=AOvVaw3zCETV0v04u9flBE8syqv4">Colab</a></span><span class="c0">&nbsp;(based on the model below) </span></h6><h6 class="c1 c27" id="h.ji9j7dfsgs1n"><span>- Male/female BS-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2525052333&amp;sa=D&amp;source=editors&amp;ust=1765035743127478&amp;usg=AOvVaw2Dm_VzCwibQq3uSVS-InYB">model</a></span><span>&nbsp;by Sucial | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/15dxMvEanC8h_djEuHoQXHKMk0ERN02_y/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743127628&amp;usg=AOvVaw3CsZ2ZSzniq3GMRFsRid5-">config</a></span><span>&nbsp;for UVR</span><span class="c56">&nbsp;| tensor match error </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nomadkaraoke/python-audio-separator/releases/download/model-configs/deverb_bs_roformer_8_384dim_10depth_config.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743127882&amp;usg=AOvVaw2ACrsOZlZGuzetgTbCHvLV">fix</a></span><span class="c56"><br></span><span class="c0">(if they sing at intervals [one by one] they cannot be separated)</span></h6><p class="c1"><span>- Multispeaker model on MVSEP</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>____</span></p><p class="c1"><span>-</span><span>&nbsp;</span><span class="c4"><a class="c3" href="#h.ak53injalbkf">Guide and script for WhisperX</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/alexlnkp/Easy-Audio-Diarisation&amp;sa=D&amp;source=editors&amp;ust=1765035743128700&amp;usg=AOvVaw2tWHC9coVboTYA6uEUkH__">https://github.com/alexlnkp/Easy-Audio-Diarisation</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DgVpr9ewLMZg%26t%3D90s&amp;sa=D&amp;source=editors&amp;ust=1765035743128916&amp;usg=AOvVaw2VnrebRqubqVEQXIR100V5">Spectralayers</a></span><span>&nbsp;11&rsquo;s unmix multiple voices option</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(for further research) - some of these tools might get useful:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/dmlguq456/SepReformer&amp;sa=D&amp;source=editors&amp;ust=1765035743129321&amp;usg=AOvVaw1mgxB-gURwR1nXBCM6OkRi">https://github.com/dmlguq456/SepReformer</a></span><span>&nbsp;(SOTA for 2 speakers)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://paperswithcode.com/task/speaker-separation/latest&amp;sa=D&amp;source=editors&amp;ust=1765035743129634&amp;usg=AOvVaw0ZUtUHEjBNQXpuQBH2o1MX">https://paperswithcode.com/task/speaker-separation/latest</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2301.13341&amp;sa=D&amp;source=editors&amp;ust=1765035743129861&amp;usg=AOvVaw0zmsqfisX_ysFDtdmI46rG">https://arxiv.org/abs/2301.13341</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://paperswithcode.com/task/multi-speaker-source-separation/latest&amp;sa=D&amp;source=editors&amp;ust=1765035743130120&amp;usg=AOvVaw2s3sEZSryGTbN8cxsAwB5w">https://paperswithcode.com/task/multi-speaker-source-separation/latest</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">____________________________________________________________________</span></p><hr style="page-break-before:always;display:none;"><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.sjf0vefmplt"><span class="c22">&gt; 4-6 stems</span><span>&nbsp;(drums, bass, others, vocals + opt. </span><span class="c22">guitar</span><span>, </span><span class="c22">piano</span><span>):<br>- </span><span class="c42 c15 c36 c11 c30">Currently when used on AI-generated music, usually hihats will be left behind.</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- You might want to use the </span><span class="c20">already well-sounding instrumental,</span><span class="c0">&nbsp;possessed with 2 stem model in the section above first, and then separate using the following models.<br>- Furthermore, you can slow down your song by x0.75 speed - the result can be - more elements in other stem and better snaps and human claps using 4 stems. </span></p><p class="c1"><span>Read the </span><span class="c4"><a class="c3" href="#h.929g1wjjaxz7">Tips to enhance separation</a></span><span>&nbsp;#4 for more</span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/BS-ROFO-SW-Fixed/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743131607&amp;usg=AOvVaw1KeJPzUjfMlJ-EeQAhYEgn">-</a></span><span>&nbsp;Logic Pro </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Colab_Inference_BSRofo_SW_fp16.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743131791&amp;usg=AOvVaw04V9CbQcFk78iPIuR6td3P">(</a></span><span>May 2025 update</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/undef13/splifft/releases&amp;sa=D&amp;source=editors&amp;ust=1765035743131934&amp;usg=AOvVaw3fR_Vx8ZP2LjRsgt6OonTC">)</a></span><span>&nbsp;/ BS-Roformer SW 6 stem </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1ee9HBdwygactWLi_7hdZiFgFNv45Y22m&amp;sa=D&amp;source=editors&amp;ust=1765035743132084&amp;usg=AOvVaw2_fymiC_VuM5gWfiqy3aEh">|</a></span><span>&nbsp;MVSEP </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1mHbBZGcjXHwVfV5hxfyLY2d6ZhaZofkB/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743132204&amp;usg=AOvVaw2ZdZQD3S_PQ_VoOHdZ92LU">|</a></span><span>&nbsp;uvronline</span></p><p class="c1"><span class="c0">SDR bass 14.57, drums 14.05, piano 7.79, guitar 9.00, other 8.66, vocals 11.27</span></p><p class="c1"><span class="c0">Currently, the best SDR for all stems but vocals, and drums have lower fullness than MVSep SCNet XL drums 14.26 vs 21.21). Excellent guitar and piano. </span></p><p class="c1"><span class="c0">&ldquo;guitar model sounds better than demucs, mvsep, and moises&rdquo; - Sausum</span></p><p class="c1"><span class="c0">&ldquo;it&#39;s not a fullness emphasis or anything, but it&#39;s shockingly good at understanding different types of instruments and keeping them consistent sounding&rdquo; - becruily</span></p><p class="c1"><span class="c0">vocals doesn&rsquo;t have the biggest metric, but are good for deep voices. <br>Drums lacks some fullness but &ldquo;I got better drums/bass separation with that model than with any others when input is some live/rehearsal recordings with shitty sound&rdquo; - jarredou</span></p><p class="c1"><span class="c0">Although, compared with Mel-Roformer drums on uvronline:</span></p><p class="c1"><span class="c0">&ldquo;separates far far better when it&rsquo;s programmed instruments compared to actual recorded ones&rdquo; - isling</span></p><p class="c1"><span class="c0">&ldquo;Roformer SW is putting finger snaps and foot taps as vocals and in the vocal stems.&rdquo; - GodzFire</span></p><p class="c1"><span>&ldquo;gets not just drums but anything percussive/non-melodic. Which I personally don&#39;t mind, but yeah it does cause problems with </span><span class="c4"><a class="c3" href="#h.m55fp5i7rdpm">drumsep</a></span><span>&nbsp;</span><span class="c0">models because they&#39;re only expecting standard drums.&rdquo;</span></p><p class="c1"><span class="c0">Bass can be occasionally worse vs demucs_ft as bass stem Demucs &ldquo;considers not only spectrograms but also waveforms&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;can&#39;t differ an electric bass with pedal effect from an electric guitar&rdquo; - qraiqu</span></p><p class="c1"><span class="c0">&quot;better than LalalAI by a long shot too&quot; - nowarrantywarren</span></p><p class="c1"><span class="c0">As for MVSEP &ldquo;just as good a job on vocals as the paid version&#39;s ensemble preset.&rdquo;</span></p><p class="c1"><span class="c0">In UVR it takes two hours for overlap 11 for 4 minute file to separate on 6700 XT. Keep it at 2 (the fastest) - it will take also 2 hours, but on only i3-7100u (GPU Conversion disabled).<br>Highest SDR with 882000 chunk_size.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MDX23 v.2.5 by ZFTurbo, fork by jarredou (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743135669&amp;usg=AOvVaw1ZtJUSTCGtCa9Q2nEO-XqK">Colab</a></span><span class="c0">; 4 stems when it&#39;s enabled)</span></p><p class="c1"><span class="c0">Multisong dataset SDR bass: 12.58, drums: 11.97, other: 7.28, vocals: 11.10 (v2.4)</span></p><p class="c1"><span>It&rsquo;s weighted ensemble of various 4 stem Demucs models with weighted ensemble of 2 stem models for 4 stem input, so the metrics for RAW 4 stems output (without getting instrumental from ensemble first) will be a bit lower, and more for other stem - even by 1,38+, and 0.24+ for bass, and 0.02+ for drums (</span><span class="c4"><a class="c3" href="#h.jmb1yj7x3kj7">read more</a></span><span class="c0">).<br>~&quot;compared to this, demucs_ft drums sound like compressed&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Ensemble 2/4/8 stems (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743136746&amp;usg=AOvVaw0CSAJt0awZOQ-6PCgEFo5O">MVSEP</a></span><span class="c0">, paid) - similar or better results with newer single stem models combined, various ensembles to choose from, freedom to experiment.</span></p><p class="c1"><span class="c4 c20"><a class="c3" href="#h.6f1v88my7hfk">Read</a></span><span class="c6">&nbsp;all the ensembles metrics sorted by instrumental bleedless.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Chained separation order</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">With single stem models below, feel free to experiment with different orders of sequential stem separation:</span></p><p class="c1"><span class="c0">#1</span></p><p class="c1"><span class="c0">1) Instrumental model first 2) then drums or bass 3) piano or guitar 4) strings or horns <br>If your song has &ldquo;weird percussion that don&#39;t get picked up by drum models and if it&#39;s piano-heavy, I would go for piano first, but it sometimes leaves piano behind&rdquo; - Isling</span></p><p class="c1"><span class="c0">#2<br>1) Instrumental model first 2) drums 3) piano 4) strings or horns 5) bass 6) guitars <br>This way once someone &ldquo;ended up with a decent 5th-stage &ldquo;other&rdquo; stem that seemed to contain some unknown synth sounds + possible orchestra hits&rdquo; vs when bass was after drums when &ldquo;gave me a messy &ldquo;other&rdquo; with stray piano &amp; strings content&rdquo; SilSinn9821</span></p><p class="c1"><span class="c0">#3</span></p><p class="c1"><span class="c0">ZFTurbo: &ldquo;After each remove, you also remove some useful parts for next instruments. So I&#39;d propose to first use the models with the best quality. Anyway, in the end others can be very muddy&rdquo;. </span></p><p class="c1"><span class="c0">#4 </span></p><p class="c1"><span class="c0">(dynamic64)</span></p><p class="c1"><span class="c0">&ldquo;I think this is my new default [order]: </span></p><p class="c1"><span class="c0">Bass Ensemble (SCNet XL + BS Roformer + HTDemucs4), Drums MVSep SCNet XL, Piano MVSep SCNet Large, Organ MelRoformer, Saxophone MelRoformer, MVSep Wind Ensemble (SCNet + Mel), MVSep Guitar Ensemble (BSRoformer+ MelRoformer), MVSep Strings&rdquo;.</span></p><p class="c1"><span class="c0">Example: &ldquo;Personally, I like putting the instrumental through mvsep bass model (above), then putting the other stem through mvsep drums (specifically SCNet XL), then putting the other stem of that through the 6 stem model [a.k.a. SW]</span></p><p class="c1"><span class="c0">The 6 stem model is best for piano and guitar, and separating out the drums and bass beforehand helps that model not have to work as hard.</span></p><p class="c1"><span class="c0">And it also allows you to manually add anything that the first 2 models missed, because its a 6 stem model, and re-separates any missed drum and bass.</span></p><p class="c1"><span class="c0">Creates close to studio results. As close to studio as I&#39;ve ever heard&rdquo;</span></p><p class="c1"><span class="c0">#5</span></p><p class="c1"><span class="c0">In case of ensembling various models of the same stem, if the top model in terms of SDR doesn&rsquo;t have significantly lower metric, sometimes it&rsquo;s better to use it instead of ensemble [esp. if it doesn&rsquo;t have any crossbleeding] (thx dynamic64).</span></p><p class="c1"><span class="c0">Just be aware that it might vary from song to song</span></p><p class="c1"><span class="c0">#6*</span></p><p class="c1"><span class="c0">&ldquo;Drums model often bleeds the bass and 808s into the drum track, [using bass model] prevents this issue from happening&rdquo;</span></p><p class="c1 c7"><span class="c0"><br></span></p><p class="c1"><span>Single </span><span class="c22">drums </span><span class="c0">models</span></p><p class="c1"><span class="c0">- Ensemble: MVSEP Drums Mel + SCNet XL ~&rdquo;Usually works the best&rdquo; - dynamic64, but you might want to saver intermediate files and split it into different fragments to get the best of both. Consider using instrumental model result from e.g. becruily model as input.</span></p><p class="c1"><span class="c0">- Drums only/other SCNet XL model by ZFTurbo on MVSEP, SDR 13.72</span></p><p class="c1"><span class="c0">&ldquo;Very hit or miss. When they&#39;re good they&#39;re really good, but when they&#39;re bad there&#39;s nothing you can do other than use a different model&rdquo; - dynamic64</span></p><p class="c1"><span>- Drums only/other Mel-Roformer model by viperx on x-minus.pro (occasionally might work only with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035743142713&amp;usg=AOvVaw0t6-b-3TaGm282RYHxGDYY">this</a></span><span class="c0">&nbsp;link), 12.54 SDR</span></p><p class="c1"><span class="c0">&ldquo;compared to demucs_ft it was too muddy and had too much bleed at the same time</span></p><p class="c1"><span class="c0">both mvsep and xminus&rdquo; - isling</span></p><p class="c1"><span class="c0">&ldquo;I got some bad results (that could ruin the ensemble mode). On these tracks, uvronline [x-minus] melband drums model was giving better results&rdquo; - jarredou<br>Previously the best</span></p><p class="c1"><span class="c0">- Drums only/other SCNet Large (&ldquo;x-minus&rsquo; Mel band drums model is better&rdquo; - drypaintdealerundr)</span></p><p class="c1"><span class="c0">- Drums only/other Mel-Roformer model by ZFTurbo on mvsep.com, 12.76 SDR</span></p><p class="c1"><span class="c0">Older ZF&rsquo;s model</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- 1053 BS-Roformer drums/bass model in UVR Roformer beta or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743144018&amp;usg=AOvVaw2GYrXJTRZxbhAv8tebWnHh">Colab</a></span><span class="c0">.</span></p><p class="c1"><span>Very good drums with bass in one stem model - use instrumental as input to avoid vocal residues)<br>More </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/hnOvdxx&amp;sa=D&amp;source=editors&amp;ust=1765035743144304&amp;usg=AOvVaw1s0KgbhqLhRZdFR48oJUVd">metrics</a></span><span class="c0">&nbsp;for drums models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Percussion</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Tambourine</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Timpani</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Congas</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Single </span><span class="c22">bass </span><span class="c0">models<br>- MVSEP Bass SCNet XL (the best 13.81 SDR, &ldquo;It passes Food Mart - Tomodachi Life test. That&#39;s the first model to&rdquo;,</span></p><p class="c1"><span>- Ensemble of SCNet XL, BS and HTDemucs4 models (SDR 14.07); SCNet can be sometimes worse than Demucs which &ldquo;considers not only spectrograms but also waveforms&rdquo; - Unwa)<br>After separation, you might want to then apply Mel-RoFormer De-noise to remove the high noise, and finish with Apollo Universal by Lew (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/tag/uni&amp;sa=D&amp;source=editors&amp;ust=1765035743145759&amp;usg=AOvVaw1lfsJqVLCfIE62vcM1Ed3U">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Apollo-Colab-Inference/blob/main/Apollo_Audio_Restoration_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743145947&amp;usg=AOvVaw3B6QbnS4k759z7AQQThYnb">Colab</a></span><span class="c0">) to get more clarity (Tobias51).</span></p><p class="c1"><span class="c0">- MVSEP Bass BS Roformer 12.49 (integrated to 2 stem and multi/All-in stem ensemble too, worse other stem vs the below - more &ldquo;empty&rdquo; than below, problems with getting even results when bass contains a low pass filter with high resonances, picks up more &ldquo;actual bass guitar than x-minus&rdquo; model - drypaintdealerundr)</span></p><p class="c1"><span class="c0">- x-minus.pro BS (much better at treble-heavy bass tones than demucs, better other stem than above, &ldquo;catches higher end and synth basses. It makes it sound cleaner&rdquo; although might sound &ldquo;weird and muddy&rdquo; compared to demucs_ft at times, and often when it does not capture synth bass, the mvsep bass will do - isling)</span></p><p class="c1"><span class="c0">- MVSEP Bass BS Roformer SW - might be worse than the above, at least the ensemble with SW model is not better than the 14.07 - isling)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://twoshot.app/model/548&amp;sa=D&amp;source=editors&amp;ust=1765035743147534&amp;usg=AOvVaw1awkh6vn_K6TedpwPjDkUz">https://twoshot.app/model/548</a></span><span class="c0">&nbsp;(paid)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MVSep </span><span class="c22">Double Bass</span><span>&nbsp;model</span></p><p class="c1"><span class="c0">&ldquo;The BS-Roformer SW bass model should probably be used first to extract the double bass. Creates a better sound&rdquo; - dynamic64</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MVSep </span><span class="c22">Synth </span><span class="c0">(also, it can sometimes pick up bass in places where regular model&rsquo;s can&rsquo;t)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">4 stems</span><span class="c0">&nbsp;in one model</span></p><p class="c1"><span>- Demucs_ft (4 stem) - the best single Demucs&rsquo; model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/117SWWC0k9N2MBj7biagHjkRZpmd_ozu1&amp;sa=D&amp;source=editors&amp;ust=1765035743148606&amp;usg=AOvVaw25830jdWcPnoa84Q_-z7eM">Colab</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743148683&amp;usg=AOvVaw0mymh4tuPP5W-UVXkB0igb">MVSEP</a></span><span>&nbsp;</span><span>/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035743148820&amp;usg=AOvVaw0fRidDCHkhSJ1WPlSvQozM">UVR5 GUI</a></span><span class="c0">)</span></p><p class="c1"><span>Multisong dataset SDR 9.48: bass: 12.24, drums: 11.41, other: 5.84, vocals: 8.43 <br>(shifts=1, overlap=0.95)<br>Better drums and vocals than in Demucs 6 stem model, decent </span><span class="c22">acoustic guitar</span><span class="c0">&nbsp;results in 6s. Good bass stem as Demucs &ldquo;considers not only spectrograms but also waveforms&rdquo;.</span></p><p class="c1"><span>For 4 stems alternatively check MDX_extra, generally Demucs 6 stem model is worse than MDX-B (a.k.a. Leaderbord B) 4 stem model released with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/kuielab/mdx-net&amp;sa=D&amp;source=editors&amp;ust=1765035743149737&amp;usg=AOvVaw0_uYt9nhqHfVI1MJV2zLA5">MDX-Net arch</a></span><span>&nbsp;from MDX21 competition (kuielab_b_x.onnx in this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743149945&amp;usg=AOvVaw1JpRAA7Rlty7sstfSpb1Mn">Colab</a></span><span class="c0">), and is also faster than Demucs 6s. <br>For Demucs use overlap 0.1 if you have instrumental instead of mixture mixed with vocals as input (at least it works with ft model) and shifts 10 or higher. For normal use case (not instrumentals input) it will give more vocal residues, overlap 0.75 is max reasonable speed-wise, as a last resort 0.95, with shifts 10-20 max.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v1.0.9&amp;sa=D&amp;source=editors&amp;ust=1765035743150874&amp;usg=AOvVaw3AwusBTClrLTPUh9ujMHBV">SCNet-large_starrytong</a></span><span>&nbsp;</span><span>model (4 stems) (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743151116&amp;usg=AOvVaw24c-mvInuRHMGyaPHVEBy6">Colab</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035743151253&amp;usg=AOvVaw02m6cIX8omwbuqNKWCnCGp">MSST-GUI</a></span><span class="c0">)</span></p><p class="c1"><span>Multisong dataset SDR 9.29: bass: 11.28, drums: 11.24, other: 5.58, vocals: 9.06 (overlap: 4)</span></p><p class="c1"><span>It&rsquo;s 3x faster than Demucs (Nvidia GPU or CPU-only) and sounds better for some people, except for bass. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7250&amp;sa=D&amp;source=editors&amp;ust=1765035743151758&amp;usg=AOvVaw2O7W1rcd-WVFx8sPeTxLNV">SDR</a></span><span class="c0">-wise, vocals are better than in demucs_ft (which is low vs single vocal/inst models anyway). Better SDR than starrytong&rsquo;s MUSDB18 and Mamba models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ableton 12.3 update&rsquo;s high quality option separation (4 stems) - slow, works only on CPU, probably utilizes BS-Roformer. Better bleedless than ZFTurbo SCNet XL undertrained public model below, and better SDR. Might take 20 minutes for 2 minutes separation on slower CPUs (iirc mobile Sandy/Ivy). The default separation mode has very low metrics.<br></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v1.0.15&amp;sa=D&amp;source=editors&amp;ust=1765035743152786&amp;usg=AOvVaw15YPgAnR524_AeSjjvTrOs">SCNet XL IHF</a></span><span class="c0">&nbsp;model (4 stems) by ZFTurbo</span></p><p class="c1"><span class="c0">Multisong dataset SDR 9.93: bass: 11.94, drums: 11.58, other: 6.49, vocals: 9.69</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v1.0.13&amp;sa=D&amp;source=editors&amp;ust=1765035743153234&amp;usg=AOvVaw1VuEnyYiE57xNSQTZm9bLH">SCNet XL</a></span><span>&nbsp;model (4 stems) by ZFTurbo (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743153467&amp;usg=AOvVaw3T3aVC3xGRBQx4Ug2M1OO7">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035743153620&amp;usg=AOvVaw1-jvpQTy9VXYL_S2h0mcIz">MSST-GUI</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/&amp;sa=D&amp;source=editors&amp;ust=1765035743153776&amp;usg=AOvVaw11gI__Q8Pqmtxr4yv2W9mN">MSST</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR beta patch</a></span><span class="c0">)<br>Multisong dataset SDR 9.72: bass: 11.87, drums: 11.49, other: 6.19, vocals: 9.32</span></p><p class="c1"><span class="c0">Better metrics than the starrytong model but &ldquo;downgrade to the Large model since it produces a f*** ton of buzzing&rdquo; due to undertraining.</span></p><p class="c1"><span class="c0">Only bass is better in Demucs_ft - 12.24, although drums might be still better in demucs_ft.</span></p><p class="c1"><span class="c0">2 stem model on MVSEP is further trained iirc.</span></p><p class="c1"><span><br>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v1.0.12&amp;sa=D&amp;source=editors&amp;ust=1765035743154922&amp;usg=AOvVaw0q-zwOAq03LbKOQELNXecx">BS-Roformer</a></span><span>&nbsp;model (4 stems) by ZFTurbo | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035743155105&amp;usg=AOvVaw3a_3gn1PdHNX5_fkVnm5R5">MSST-GUI</a></span><span><br>Multisong dataset SDR 9.38: bass: 11.08, drums: 11.29, other: 5.96, vocals: 9.19</span><span class="c0"><br>Trained on MUSDB18HQ</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Aname-Tommy/melbandroformer4stems/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743155487&amp;usg=AOvVaw2w-jb6NvFM0zgXCIOKtiYZ">models</a></span><span>&nbsp;(4 stems) by Aname</span></p><p class="c1"><span class="c0">a) Large (4GB): multisong dataset SDR drums: 9.72, bass: 9.40, other: 5.11</span></p><p class="c1"><span class="c0">b) XL (7GB):</span></p><p class="c1"><span class="c0">Despite lower AVG SDR on musdb18 dataset (8.54 vs 9), it seems to outperform demucs_ft model (only other stem has better SDR in demucs_ft - all other metrics are better in SCNet/XL/BS-Roformer). &nbsp;</span></p><p class="c1"><span class="c0">XL is &ldquo;heavy and slow, without giving a quality boost compared to existing public 4 stems models trained on musdb18 by ZFTurbo and starrytong (BsRofo and SCNet large/XL [above])&rdquo; - jarredou (maybe minus buzzing in the public XL model).</span></p><p class="c1"><span class="c0">&ldquo;Drums are sounding really good in particular, tested a couple songs with the large model after using unwa&#39;s v1e+ for instrumental&rdquo; &ldquo;drums are absolutely the standout&rdquo;.</span></p><p class="c1"><span class="c0">&ldquo;The bass stem is definitely the weakest one from this new model. Very, very muddy and inconsistent.&rdquo; - santilli_</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Large [variant] works in like 99% use case&rdquo; &ldquo;Large split sounds amazing so far tho&rdquo;</span></p><p class="c1"><span class="c0">XL &ldquo;result would take so much longer, but the large results sounded better IMO&rdquo; - 5B</span></p><p class="c1"><span class="c0">XL model won&rsquo;t work with default settings on Colab, and very slow on e.g. RTX 3060, &ldquo;on 4070 Super it took like 6 mins on XL 4 stems compared to 30 seconds on Large 4 stems&rdquo; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v1.0.14&amp;sa=D&amp;source=editors&amp;ust=1765035743157901&amp;usg=AOvVaw3hLzzXb1XD-Gvmfoa0Y2vj">SCNet Tran</a></span><span class="c0">&nbsp;a.k.a. small model (4 stems) by ZFTurbo</span></p><p class="c1"><span class="c0">Multisong dataset SDR bass: 10.99, drums: 10.87, other: 5.63, vocals: 8.42 </span></p><p class="c1"><span class="c0">Outperformed by the above models at least SDR-wise. Cannot be used in UVR.</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1M24__8Qnd648ceXOH5PLVWenVeh6maGo/view&amp;sa=D&amp;source=editors&amp;ust=1765035743158430&amp;usg=AOvVaw3_mbTbYomSo3bWJ_jWkrx4">KUIELab-MDXNET23C</a></span><span class="c0">&nbsp;(4 stems) - its first scores were probably from ensemble of its five models, and in that configuration it had better SDR than demucs_ft on its own, and drums had better SDR than &ldquo;SCNet-large_starrytong&rdquo; above (so single models&rsquo; score of any of these MDX23C models is probably lower than in demucs_ft). <br>- Lighter &ldquo;model1&rdquo; drums sounds surprisingly better than htdemucs non_ft v4 on previously separated instrumental. It handles trap really well and preserves hi-hats correctly, but in cost of other stem bleeding. v4 model can be used to clean it a bit further, but at least using GPU Conversion on AMD and older directml.dll for some GPUs, it adds more noise/artefacts, so use CPU in that case (tested on Roformer as preprocessor for instrumental). It&rsquo;s relatively fast, but not as mdx_extra (which sounds rather lo-fi in that case).<br>- Bigger &ldquo;model2&rdquo; is heavier and doesn&rsquo;t work on at least AMD 4GB VRAM GPUs on Beta Roformer patch #2 (before the introduction of the new overlap code).<br></span></p><p class="c1"><span>To run model1/2 in UVR &ldquo;You must change the model names in &quot;mdx_C&quot; from &quot;ckpt&quot; [name] to model1.ckpt, model2.ckpt, &amp; model3.ckpt. [so simply add the name to the extension]&rdquo; and then copy the ckpts to models\MDX-Net without yamls. There are actually 3 mdx23c models there (and 2 demucs), but model3 seems to be only for vocals (and with low SDR). So the two of three most important were explained above.<br>OG KUIELab&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/kuielab/sdx23/tree/mdx_C%23reproduction&amp;sa=D&amp;source=editors&amp;ust=1765035743160613&amp;usg=AOvVaw0eruGVTe1BFeHWcKD994-M">repo</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v1.0.1&amp;sa=D&amp;source=editors&amp;ust=1765035743160906&amp;usg=AOvVaw3laVErkoujKS9VYZtpxf8a">model_mdx23c_ep_168_sdr_7.0207</a></span><span>&nbsp;(4 stems) <br>Multisong dataset SDR bass: 8.40, drums: 7.73, other: 4.57, v</span><span>ocals: 7.36</span><span class="c0"><br>4 stems, also trained on MUSDB18HQ, but by ZFTurbo, it&rsquo;s different from the above, similar size to &ldquo;model2&rdquo;.</span></p><p class="c1"><span>- Aname 4 stem BS-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/GwY1TQoB%23UmeMGO2BBtgrUXkmXXQQVXqwR_hwxaAmkycDr-fitWg&amp;sa=D&amp;source=editors&amp;ust=1765035743161544&amp;usg=AOvVaw3wU2dUgLyU4y-AFfRYtt0x">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/Pwp32DrY%23Kyl5sK3j6l5kXCe7Br52gN2CXn9c8N6lzOYT1g0FOS0&amp;sa=D&amp;source=editors&amp;ust=1765035743161652&amp;usg=AOvVaw3ScLCrVImnikDZJ83rqCiP">yaml</a></span><span class="c0"><br>Multisong dataset SDR bass: 9.79, drums: 10.21, other: 5.27, vocals: 9.13</span></p><p class="c1"><span class="c0">It has better SDR than the 7.0207 above (as in the SDR metrics link below), but worse than demucs_ft and BS-Roformer 4 stem ZFTurbo model above.</span></p><p class="c1"><span class="c0">- BS-RoFormer 4 stems model by yukunelatyh / SYH99999 added on x-minus</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035743162372&amp;usg=AOvVaw2Fm_UhviD1kvV2KeH46viU">https://uvronline.app/ai?discordtest</a></span><span class="c0"><br>Multisong dataset SDR bass: 8.68, drums: 10.37, other: 5.05, vocals: 8.57<br>Some people like it more than Demucs, but &ldquo;it&#39;s like demucs v4 but worse, I think.</span></p><p class="c1"><span class="c0">The vocals have a ton of bleed, the bass is disappointing tbh.</span></p><p class="c1"><span>The other stem has a ton of bgv and adlib bleed in it&rdquo; Isling<br>It has </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/O2qDgTQ&amp;sa=D&amp;source=editors&amp;ust=1765035743163174&amp;usg=AOvVaw0-IoQ3JoCKPY8zD_QzAvdR">SDR metrics</a></span><span class="c0">&nbsp;for all stems worse than 4 stem BS-Roformer by ZFTurbo and demuics_ft.</span></p><p class="c1"><span class="c0">- v2 of it was added on site with lower metrics for all stems in later period.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Smaller public 4 stem models and all metrics:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/pretrained_models.md%23multi-stem-models&amp;sa=D&amp;source=editors&amp;ust=1765035743163999&amp;usg=AOvVaw0e0kDw5iVn3mgbqwZ_J5go">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/pretrained_models.md#multi-stem-models</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.yy2jex1n5sq">GSEP AI</a></span><span>&nbsp;(2-4-6 stems, sonically it used to have the best other stem vs Demucs, also piano in Demucs is worse, and it picks up e-piano more frequently, GSEP</span><span class="c22">&nbsp;electric guitar</span><span>&nbsp;model doesn&#39;t include acoustic, it&#39;s only electric). In general, it used to have a very good </span><span class="c22">piano </span><span class="c0">model before many alternatives existed</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.f0orpif22rll">Ripple</a></span><span class="c0">&nbsp;(defunct; and used to be for US iOS, at one point best SDR for all-in one single 4 stem (besides the other stem), but bad, bleedy other stem. Back then could be the best bass stem, and/or kick in drums, but not the best drums in overall vs demucs_ft, &ldquo;you need something to get the rest of the drums out of the &lsquo;other&rsquo; stem and at that point might as well use a proper drum model&rdquo;, good vocals. You can minimize residues in Ripple by providing an already well separated instrumental from the section above, and/or minimizing volume of the input file by 3/6dB.</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.bandlab.com/splitter&amp;sa=D&amp;source=editors&amp;ust=1765035743166079&amp;usg=AOvVaw3AtbhrP0JB-ENIP86yN1r0">Bandlab Splitter</a></span><span>&nbsp;(4-6 stem - guitar, piano, web and iOS/Android app) - previously could be used e.g. for cleaning stems from other services, 48kHz output, stems can be misaligned, the quality got worse since one of the updates (rather not worth using anymore)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.audioshake.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743166594&amp;usg=AOvVaw1ZfpS4jBzuDaSqEK08_hkQ">Audioshake</a></span><span>&nbsp;</span><span class="c0">(paid, only non-copyrightes music, or slowed down songs [see workaround in &quot;paid&quot; above]) - sometimes better results than Demucs ft model.</span></p><p class="c1"><span class="c0">- Spectralayers 10 - mainly for bass and drum separation -</span></p><p class="c1"><span class="c0">&ldquo;I think I&#39;ve got some really comparable samples out of jarredou&#39;s MDX23 Colab fork&rdquo;, but for vocals and instrumentals it&rsquo;s mediocre [in Spectralayers 10].</span></p><p class="c1"><span class="c0">- music.ai - &ldquo;Bass was a fair bit better than Demucs HT, Drums about the same. Guitars were very good though. Vocal was almost the same as my cleaned up work. (...) I&#39;d say a little clearer than MVSEP 4 ensemble. It seems to get the instrument bleed out quite well, (...) An engineer I&#39;ve worked with demixed to almost the same results, it took me a few hours and achieve it [in] 39 seconds&rdquo; Sam Hocking</span></p><p class="c1"><span>- dango.ai (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tuanziai.com/en-US&amp;sa=D&amp;source=editors&amp;ust=1765035743168155&amp;usg=AOvVaw0CuGD4UWzmzRd5SoyhdHsN">https://tuanziai.com/en-US</a></span><span class="c0">) - also has 4 or more stems separation (expensive)</span></p><p class="c1"><span class="c0">- (old) MDX23 1.0 by ZFTurbo 4 stems (Colab, desktop app, as above, much cleaner vs demucs_ft, less aggressive, but in 1.0 more low volume vocal residues in completely quiet places in instrumentals vs e.g. HQ_3, instrumentals as input should sound similar to the current v. 2.4 fork as only 4 stem separation code didn&rsquo;t change much since then)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MVSEP has also single </span><span class="c22">piano,</span><span>&nbsp;</span><span class="c22">guitar and bass</span><span>&nbsp;</span><span class="c0">models (in many cases, guitar model can pick up piano better than piano model;</span></p><p class="c1"><span class="c0">&quot;works great for songs with grand piano, but only grand piano, since that&rsquo;s what it was trained on.</span></p><p class="c1"><span class="c0">Same with guitar, which catches more piano than piano model does, ironically&quot;).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- x-minus/uvronline.app has also single acoustic and guitar models by viperx</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- viperx&rsquo; piano model is also on x-minus/uvronline.app.</span></p><p class="c1"><span class="c0">(More on piano and guitar models later below)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>To enhance 4 stem results, you can use good instrumental obtained from other source as input for the above (before instrumental Roformers it could be e.g. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Captain-FLAM/KaraFan/blob/master/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743170654&amp;usg=AOvVaw0VRjkIEymI_rO9OPojcdha">KaraFan</a></span><span>, and its different presets ensembled in UVR5 app with Audio Tools&gt;Manual Ensemble</span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For the best results for piano or guitar models, use other stem from 4 stems from e.g. &ldquo;Ensemble 8 models&rdquo; or MDX23 Colab or htdemucs_ft as input.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Moises.ai - although drums might be better using e.g. &ldquo;MVSep Drums&rdquo; already, probably vs Mel-Roformer on MVSEP or x-minus (not sure) [Moises] can give &ldquo;better results (...) if the input material is for example cassette-tape sourced or post-FM).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">FL Studio - rather nothing better than the solutions above</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older 4 stem models in UVR (for some specific songs, e.g. while trying to fix bleeding across stems):</span></p><p class="c1"><span class="c0">htdemucs</span></p><p class="c1"><span class="c0">htdemucs_mmi</span></p><p class="c1"><span class="c0">mdx_extra</span></p><p class="c1"><span class="c0">kuielab_b</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.93froqq0fnq6"><span class="c22">&gt;</span><span class="c18 c15">Sep. parts of drums</span></h6><p class="c1"><span class="c0">(kick/hi-hat/snare/toms/&hellip;)</span></p><p class="c1"><span class="c0">For drums stem from e.g. MDX23 Colab/instrumental model&gt;Demucs_ft/GSEP or drums model (e.g. on x-minus/MVSEP)</span></p><p class="c1"><span><br>- MVSEP 8 stems ensemble of all the 4 drumsep models below (so besides Demucs model by Imagoy) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/sR5pNP3.png&amp;sa=D&amp;source=editors&amp;ust=1765035743172909&amp;usg=AOvVaw26nesC9qksfE085ixwwfZl">metrics</a></span></p><p class="c1"><span class="c0">- MVSEP&rsquo;s SCNet 4 stem (kick, snare, toms, cymbals) best SDR for kick and similar to 6s below for toms: -0.01 SDR difference) </span></p><p class="c1"><span class="c0">- MVSEP&rsquo;s SCNet 5 stem (cymbals, hi-hat, kick, snare, toms)</span></p><p class="c1"><span class="c0">- MVSEP&rsquo;s SCNet 6 stem model (ride, crash, hi-hat, kick, snare, toms) worse snare SDR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.2u19k7ty9b00">jarredou/Aufr33 MDX23C model</a></span><span class="c0">&nbsp;(kick/hi-hat/snare/toms/ride and crash stems); worse overall SDR, but it&#39;s a public model usable in UVR or inference Colab</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- SpectraLayers 11 (Unmix Drums)&gt;OG </span><span class="c4"><a class="c3" href="#h.jmjab44ryjjo">drumsep</a></span><span>&nbsp;by Imagoy/</span><span>&gt;</span><span class="c4"><a class="c3" href="#h.cz4j2d3uf48s">FactorSynth</a></span><span>&nbsp;(depending on how far you want to unmix the drums) </span><span class="c0">&gt;Regroover&gt;UnMixingStation (all the last three paid)&gt;</span></p><p class="c1"><span class="c0">Virtual DJ (Stems 2.0, barely, or doesn&rsquo;t pick those instruments at all). </span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.f067glwjzyi4">LarsNet </a></span><span class="c0">(vs OG drumsep, it also allows separating hi-hats and cymbals, toms might be better)</span></p><p class="c1"><span class="c0">- RipX (paid)</span></p><p class="c1"><span class="c0">- SpectraLayers 10 (paid, sometimes worse, sometimes better than OG Drumsep. IDK if it was added in update or main version) &quot;drumsep works a f* ton better when separating on this one song I&#39;ve tested with the pitch shifted down 2&quot;</span></p><p class="c1"><span class="c0">- FADR.com (in paid subscription)</span></p><p class="c1"><span class="c0">- Moises.ai (only for pro)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Compared to OG drumsep, Regroover allows more separations, especially when used multiple times, so allows removing parts of kicks, parts of snares etc, noises etc. More deep control. Plus, it nulls easily. But drumsep sounds better on its own, especially with higher parameters like e.g. shifts 20 and overlap 0.75-0.98. Now it can be replaced by the public MDX23C model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Strings</span></p><p class="c1"><span class="c0">- Dango.ai (e.g. violin, erhu; paid, free 30 seconds fragments) - &quot;impressive results&quot; for at least violin</span></p><p class="c1"><span class="c0">- Music.ai (paid, &ldquo;Dango.ai and Music.ai [previously] the best strings models [Dango sounds fuller meanwhile Music.ai has more accurate recognition of strings but sounds a bit too filtered]&rdquo; - from before BS Strings release)</span></p><p class="c1"><span class="c0">- MVSEP Bowed Strings BS-Roformer (&ldquo;doesn&#39;t disappoint&rdquo;, SDR 5.41)</span></p><p class="c1"><span class="c0">- MVSep Plucked Strings</span></p><p class="c1"><span class="c0">- Moises.ai (paid, not bad)</span></p><p class="c1"><span class="c0">- Audioshake</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSEP Violin (sometimes does better than the strings model for strings and has also biger SDR on strings dataset)<br>- MVSEP Strings MDX23C (it&rsquo;s &ldquo;weak&rdquo;, SDR 3.84)</span></p><p class="c1"><span>- x-minus.pro/Uvronline.app Mel-Roformer model by viperx (SDR 2.87) (sometimes with this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035743177536&amp;usg=AOvVaw0zZAPYL4lFl_I600Y2iLYU">link</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035743177655&amp;usg=AOvVaw3PqTuRhFay-krtSbBd-Giu">this</a></span><span>&nbsp;link</span><span class="c0">) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.4yn6zawn80la">Demix Pro</a></span><span class="c0">&nbsp;(paid, free trial)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.1bm9wmdv6hpf">RipX DeepRemix</a></span><span>&nbsp;(once was told to be the best </span><span>bass </span><span class="c0">model, but it doesn&rsquo;t score that good SDR-wise, probably it&rsquo;s Demucs 3 (demucs_extra) and is worse than Demucs_ft and rather also vs MDX23 above; could have been updated) (paid)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sometimes Wind model in UVR5 GUI picks up strings</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSEP Harp</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Mandolin</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Banjo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Sitar</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Ukulele</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Dobro</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Violin</span></p><p class="c1"><span class="c0">- MVSep Violin BS Roformer </span></p><p class="c1"><span class="c0">&ldquo;it can even separate violin quartets from cellos, so cool.&rdquo; - smilewasfound</span></p><p class="c1"><span class="c0">&ldquo;Very neat model. (...) Sometimes the model does seem to pick up more than just violins imo, but yeah for separating high strings in particular it is really cool.&rdquo; - Musicalman</span></p><p class="c1"><span class="c0">- Dango.ai &ldquo;impressive&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSEP Viola</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSEP Chello</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.io845jglru5c"><span class="c22">Electric guitar<br></span><span class="c6">&ldquo;For better results you might try first removing vocals.&rdquo;</span></h6><p class="c1"><span class="c4"><a class="c3" href="#h.tc4az79fufkn">Audioshake</a></span><span>&gt;</span><span class="c4"><a class="c3" href="#h.1bm9wmdv6hpf">RipX</a></span><span>/&gt;</span><span class="c4"><a class="c3" href="#h.4yn6zawn80la">Demix Pro</a></span><span>&gt;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.lalal.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743180477&amp;usg=AOvVaw06gTgXH2N8Q9Fzr985BvMS">lalal.ai</a></span><span class="c0">&nbsp;(e.g. lead guitars; the model got better by the time) </span></p><p class="c1"><span class="c0">(they&rsquo;re paid ones)/</span></p><p class="c1"><span>Logic Pro&gt;GSEP&gt;Demucs 6s (free)&lt;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://moises.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743180833&amp;usg=AOvVaw2ozX-COCu9P7hNsIeUJab3">Moises.ai</a></span><span class="c0">&nbsp;(paid &ldquo;holy shit better [vs demucs, but] still pretty bad&rdquo;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://dango.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743181096&amp;usg=AOvVaw2LiQEIpx4HhSbdPIQYOqBR">Dango.ai</a></span><span class="c0">&nbsp;(paid)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://music.ai&amp;sa=D&amp;source=editors&amp;ust=1765035743181218&amp;usg=AOvVaw2mFulNQBle6IotFo9FLt76">Music.ai</a></span><span class="c0">&nbsp;(paid, free trial)</span></p><p class="c1"><span class="c0">Logic Pro (paid, May 2025 update) / BS-Roformer 6 stems a.k.a. MVSEP Guitar SW <br>(&ldquo;really on point. So far it separated super well, also didn&rsquo;t confuse organs for guitars and certain piano sounds as well.&rdquo; - Tobias51</span></p><p class="c1"><span class="c0">&ldquo;guitar model sounds better than Demcus, MVsep, and Moises&rdquo; - Sausum</span></p><p class="c1"><span class="c0">&ldquo;guitar in particular was amazing. All other models I tried had trouble with it&rdquo; - Musicalman)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/BS-ROFO-SW-Fixed/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743182104&amp;usg=AOvVaw08Ax6r_Iy7ynE64mS6gMsg">|</a></span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/undef13/splifft/releases&amp;sa=D&amp;source=editors&amp;ust=1765035743182191&amp;usg=AOvVaw3G8lCl0gnuGxebM4SgAQsx">|</a></span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1ee9HBdwygactWLi_7hdZiFgFNv45Y22m&amp;sa=D&amp;source=editors&amp;ust=1765035743182294&amp;usg=AOvVaw3g03qcwPSsK1RU1IqAF3wm">|</a></span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1mHbBZGcjXHwVfV5hxfyLY2d6ZhaZofkB/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743182412&amp;usg=AOvVaw1XImuZ2sJd8YVdC8s2WIy6">|</a></span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Colab_Inference_BSRofo_SW_fp16.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743182620&amp;usg=AOvVaw2GWVfKAvHq7jj2dDePCMyK">|</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">MVSep Electric Guitar (&ldquo;really neat. One thing I noticed is that it seems to be better than other models at picking up midi/synth lead guitars (...) also gets tripped up a bit more by weird FX and synth sounds being partially flagged as guitar&rdquo; - Musicalman)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-guitar/resolve/main/becruily_guitar.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743183448&amp;usg=AOvVaw3w8zLvTOooJBMZmutBoDUh">Becruily Melband guitar</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/becruily/mel-band-roformer-guitar/resolve/main/config_guitar_becruily.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743183666&amp;usg=AOvVaw0E2u1iChv9IerYI27tj2WU">yaml</a></span><span>&nbsp;(&ldquo;Not SOTA, but much more efficient and comparable to existing guitar models, and for some songs it might work better because it picks up more guitars [though it can also pick some other instruments].&rdquo;)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com&amp;sa=D&amp;source=editors&amp;ust=1765035743184325&amp;usg=AOvVaw2XLRVfhYVdmpId3LeM_Aa-">Mvsep.com</a></span><span class="c0">&nbsp;(Mel-Roformer model and the previous - MDX23C one. Mel is &ldquo;pretty good but suffers some dropouts where MDX23C doesn&#39;t&rdquo;)</span></p><p class="c1"><span class="c0">uvronline.app (Mel-Roformer viperx&#39; model, it is not flawless either)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035743184912&amp;usg=AOvVaw0AFjyVyRBGfOkYfhKZqynI">uvronline.app</a></span><span>&nbsp;(</span><span>HQ_5 beta</span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035743185062&amp;usg=AOvVaw1rwHhtoh2Ugwpp_ow2hu2j">paid users</a></span><span class="c0">&nbsp;- places guitars in vocal stem pretty well)<br></span></p><p class="c1"><span class="c0">&ldquo;Rebalance volume of chans before processing&rdquo; if you have better separation results processing L and R channel separately.</span></p><p class="c1"><span><br>Consider using Apollo Universal by Lew (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/tag/uni&amp;sa=D&amp;source=editors&amp;ust=1765035743185733&amp;usg=AOvVaw04Irrqur1qin2lgKlDRWkO">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span>&nbsp;| Colab in </span><span class="c4"><a class="c3" href="#h.k34y1vaaneb1">HTMYOR</a></span><span class="c0">) to get more clarity after separation. </span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.99mh96i7mlar"><span class="c18 c15">Acoustic guitar</span></h6><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://dango.ai&amp;sa=D&amp;source=editors&amp;ust=1765035743186327&amp;usg=AOvVaw159uzmCc9JFAUEyZgvN1BZ">dango.ai</a></span><span class="c0">&nbsp;(paid, probably the best for now, better in at least some songs than the SW model)</span></p><p class="c1"><span class="c0">- MVSep Acoustic Guitar (strong competitor, outperforms moises &ldquo;like crazy&rdquo;</span></p><p class="c1"><span class="c0">- uvronline.app (viperx&#39; model for premium users - does a good job too)</span></p><p class="c1"><span class="c0">- BS-Roformer SW</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Demucs 6s - sometimes, when it picks it up</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.yy2jex1n5sq">GSEP</a></span><span class="c0">&nbsp;- when the guitar model works at all (it usually grabs the electric), the remaining &#39;other&#39; stem often is a great way to hear acoustic guitar layers that are otherwise hidden.&quot;.</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://lalal.ai&amp;sa=D&amp;source=editors&amp;ust=1765035743187945&amp;usg=AOvVaw2bkSbpm52lA0_MhMhViwC7">lalal.ai</a></span><span>&nbsp;(both paid)&gt;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://moises.ai&amp;sa=D&amp;source=editors&amp;ust=1765035743188097&amp;usg=AOvVaw1WGW_rqqZu-Fx0COUirInH">moises.ai</a></span><span class="c0">&nbsp;(It picks up acoustic and electric guitar together)</span></p><p class="c1"><span class="c0">- Audioshake (both electric and acoustic)</span></p><p class="c1"><span class="c0">- moises.ai</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Separating electric and acoustic guitar</span></p><p class="c1"><span class="c0">- Use a model from one of two the categories above, e.g.</span></p><p class="c1"><span class="c0">- MVSep Acoustic Guitar (&ldquo;it&#39;s separating acoustic from electric very well, even in fuzzy, lo-fi recordings&rdquo; - Input Output)</span></p><p class="c1"><span class="c0">- &ldquo;To separate electric and acoustic guitar, you can run a song [e.g. other stem] through the Demucs guitar model and then process the guitar stem with GSEP [or MVSEP model instead of one of these].</span></p><p class="c1"><span class="c0">GSEP only can separate electric guitar so far, so the acoustic one will stay in the &quot;other&quot; stem.&rdquo;</span></p><p class="c1"><span>- &ldquo;&#8288;</span><span class="c4"><a class="c3" href="#h.s4sjh68fo1sw">medley-vox</a></span><span class="c0">&nbsp;main vs rest model has worked for me to separate two guitars before&rdquo;</span></p><p class="c1"><span>- moises.ai &ldquo;it&#39;s not perfect, it&#39;s good when the solo guitar for example is loud then it can be isolated but when it comes in a balanced lead and rhythm guitar, it can&#39;t isolate it&rdquo;<br>- MDX23C </span><span class="c4"><a class="c3" href="#h.3c6n9m7vjxul">phantom center</a></span><span class="c0">&nbsp;model</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://moises.ai&amp;sa=D&amp;source=editors&amp;ust=1765035743190508&amp;usg=AOvVaw2RQqHVYYBLyZGwHtpKtGCu">moises.ai</a></span><span class="c0">&nbsp;(it has electric, acoustic, rhythmic, solo)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Lead and rhythm guitar</span></p><p class="c1"><span class="c0">- moises.ai (paid)</span></p><p class="c1"><span class="c0">- MVSep Lead/Rhythm Guitar (1 stage, and 2 stage variant)</span></p><p class="c1"><span class="c0">- MVSEP guitar models <br>&ldquo;I can isolate both guitars with the different models that MVSEP has, especially in rock tracks where the lead guitar is in the center channel and the rhythm guitar is on the right - left side of a stereo track, good results are not always obtained, especially when the lead guitar has long delay effects, tons of reverb or when these effects go from one channel to another, but it also depends on how the song was mixed.&rdquo; - edreamer 7</span></p><p class="c1"><span>- MDX23C </span><span class="c4"><a class="c3" href="#h.3c6n9m7vjxul">phantom centre</a></span><span class="c0">&nbsp;extraction by wesleyr36 model<br>&ldquo;First, isolate guitar, then (...) use phantom centre extraction by wesleyr36 model. Here I can find the rhytmn and the lead guitars, as I told before, results can vary&rdquo; - edreamer 7</span></p><p class="c1"><span>- Dry Paint Dealer Undr&rsquo;s Melband Roformer and Demucs Lead and Rhythm guitar </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JH2tjhgDcJgvdi-hrQT82RsaV2XhE8hn?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743192620&amp;usg=AOvVaw3AHdZMVuxA0HyOZIrbn9M7">models</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">&ldquo;my own very mediocre model for it that I never shared. it does work but has issues that I imagine any better executed model won&#39;t.&rdquo;</span></p><p class="c1"><span class="c0">- lalal.ai (&ldquo;it sucks&rdquo; - isling, Oct 25)</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.5r5gvhhmqt8n"><span class="c22">Wind instruments and wind noises<br></span><span class="c6">(trumpet/saxophone/brass/woodwinds/flute/trombone/horn/clarinet/oboe/harmonica/bagpipes/bassoon/tuba/kazoo/piccolo/fluge/horn/ocarina/shakuhachi/melodica/reeds/didgeridoo/mussette/gaida/farts)</span></h6><p class="c1"><span>- MVSep Wind BS Roforomer (2025.09) 9.77 SDR (+2.64 SDR)</span></p><h6 class="c1 c27" id="h.8lswy2qjvnhd"><span class="c20">- </span><span>MVSep Wind BS Roformer (2025.08) (more robust and cleaner than the Mel and detects instruments better, +2.5 SDR)</span><span class="c20"><br></span><span class="c0">- Wind BS-Roformer on x-minus.pro by viperx (big step forward vs the old UVR model)</span></h6><p class="c1"><span>-</span><span class="c22">&nbsp;</span><span class="c0">MVSEP Wind SCNet</span></p><p class="c1"><span>-</span><span class="c22">&nbsp;</span><span class="c0">MVSEP Wind Mel-Roformer</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSEP Trumpet (&ldquo;so clean&rdquo;)</span></p><p class="c1"><span class="c0">&ldquo;after testing [Wind 9.77] on a song where trumpet and sax play in unison, doing the trumpet model is cleaner than doing the sax model&rdquo; - dynamic64<br></span></p><p class="c1"><span class="c0">- MVSep Trombone</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Oboe</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Clarinet</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Harmonica (&ldquo;Hit or miss&rdquo; - musicbybrooks)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep French Horn</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Tuba</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Bassoon</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Accordion</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Brass</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Woodwind</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Older</span></p><p class="c1"><span>- </span><span class="c0">&quot;Wind&quot; model on UVR5 (Download Center -&gt; VR Models -&gt; select model 17)</span></p><p class="c1"><span class="c0">(You might have to use it on instrumental separation first, e.g. with HQ_4 or Kim Inst)</span></p><p class="c1"><span class="c0">- Audioshake</span></p><p class="c1"><span class="c0">- Music.ai</span></p><p class="c1"><span class="c0">- Adobe Podcast</span></p><p class="c1"><span class="c0">- karaoke 4band_v2_sn on e.g. MVSEP (worse than Wind model in UVR)</span></p><p class="c1"><span class="c0">- Probably someone had some success with one de-crowd model for wind noises</span></p><p class="c1"><span class="c0">- Lot of instrumental/vocal models confuses wind instruments with vocals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MVSEP Saxophone</span></p><p class="c1"><span class="c0">- SCNet XL (SDR saxophone: 6.15, other: 18.87)</span></p><p class="c1"><span class="c0">- MelBand Roformer (SDR saxophone: 6.97, other 19.70)</span></p><p class="c1"><span class="c0">- Ensemble Mel + SCNet (SDR saxophone: 7.13, other 19.77)</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.m6621q81n96t"><span class="c18 c15">Piano</span></h6><p class="c1"><span class="c20">Consider using Unwa BS-Roformer Resurrection inst a.k.a. &ldquo;unwa high fullness inst&quot; on MVSEP as preprocessor - rainboomdash<br></span></p><p class="c1"><span>- </span><span>Logic Pro</span><span>&nbsp;</span><span>(</span><span>paid</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1iVuweQTlL6NlGR9GC_CHEW8NNCNtUWQu?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743198551&amp;usg=AOvVaw1QpYZwYeYy1lO87Nfqdb9x">;</a></span><span>&nbsp;May 2025 update, SDR 7.79</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/undef13/splifft/releases&amp;sa=D&amp;source=editors&amp;ust=1765035743198711&amp;usg=AOvVaw1NiYmYlanaWeJEuHrFQGb9">)</a></span><span>&nbsp;/ BS-Roformer 6 stems / MVSEP Piano SW</span></p><p class="c1"><span class="c0">(&ldquo;1000 times more efficient than the Lalal.ai piano model&rdquo;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Lalal.ai (paid; no other stem with piano stem attached)</span></p><p class="c1"><span class="c0">- Demix Pro (paid; &ldquo;I often combine the two&rdquo; - Mixman, but it was before the 6 stems above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Piano Ensemble (Mel-Roformer &nbsp;+ SCNet Large piano models; SDR 6.21)<br>(Mel is viperx&#39; iirc; &ldquo;a [tiny] bit more bleed during the choruses and whatnot&rdquo; vs x-minus, &ldquo;works well maybe 7 times out of 10&rdquo;; SCNet, &ldquo;has a less watery sound, but more bleed&rdquo; vs Mel)</span></p><p class="c1"><span class="c0">- x-minus.pro (for paid users; cheap subscription; &ldquo;more consistent than MVSep piano and demucs_6s&rdquo; it knows well what piano is, but it sounds the best for other stem of piano separation, but e.g. on Carpenters - Yesterday Once More &ldquo;while not terrible, the dropouts, underwater &#39;gurgles&#39;, and general lack of piano punch/presence remains noticeable&rdquo; - Chris_tang1, while MVSEP Piano Ensemble: SCNet + Mel, SDR: 6.21, was much better in that case - might vary on a song)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Music.ai (paid)</span></p><p class="c1"><span class="c0">- Dango.ai (paid)</span></p><p class="c1"><span class="c0">- GSEP (formerly best, paid)</span></p><p class="c1"><span class="c0">- Moises (separate models for piano and keys)</span></p><p class="c1"><span class="c0">- MVSep Piano MDX23C 2024 &amp; 2023</span></p><p class="c1"><span class="c0">- htdemucs_6s (not too good)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSEP Digital Piano (much better for epiano, and sometimes also for real or synthesiser when it&#39;s picked vs the SW model)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Keys</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Harpsichord</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Synths</span></p><p class="c1"><span class="c0">- MVSep Synth (it can also pick some bass which some bass models failed to pick up)</span></p><p class="c1"><span class="c0">- MVSep Organ</span></p><p class="c1"><span class="c0">- Piano or guitar models might work (if the song doesn&#39;t have piano or guitar already) depends on a song</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.g37f4a6hnxm0">Zero Shot</a></span></p><p class="c1"><span class="c0">- lalal.ai (hit or miss, sometimes might not work)</span></p><p class="c1"><span class="c0">- Some voc/inst models might treat synths as vocals (then you could separate them using better inst/voc model)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Organs</span></p><p class="c1"><span class="c0">- MVSEP Organ (surprisingly good, and since then SDR doubled since the first version, eliminating some bleed issues or e.g. Hammond organs not being picked in some places)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Idiophones</span></p><p class="c1"><span class="c0">- MVSep Marimba</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Glockenspiel</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Triangle</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MVSep Bells (tubular bells or chimes - for sleigh bells use drums model)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MVSep Wind Chimes</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.h5cpiy7ueljn"><span class="c18 c15">Crowd</span></h6><p class="c1"><span>- UVR-MDX-NET Crowd HQ 1 (UVR/x-minus.pro/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/UVR-MDX-NET_Crowd_HQ_1.onnx&amp;sa=D&amp;source=editors&amp;ust=1765035743205251&amp;usg=AOvVaw0C31xNJzf64OimW3GA4zYo">model</a></span><span class="c0">/conf in UVR) (can be more effective than MVSEP&rsquo;s sometimes; e.g. good for live shows)</span></p><p class="c1"><span>- Mel-Roformer De-Crowd by ZFTurbo (MVSEP/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v.1.0.4&amp;sa=D&amp;source=editors&amp;ust=1765035743205837&amp;usg=AOvVaw0TOst6KxdIY87fQRnDuZd-">files</a></span><span>/UVR</span><span class="c0">)</span></p><p class="c1"><span>To use it in UVR, Go to UVR\models folder, and paste </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1eO6rDhxh77eC-l0IHF16mQNwrrWOX31h&amp;sa=D&amp;source=editors&amp;ust=1765035743206200&amp;usg=AOvVaw3Pnb9XjLKu7An6_YJhWYk0">that</a></span><span class="c0">&nbsp;folder there.</span></p><p class="c1"><span class="c0">Then change &quot;dim_t&quot; value to 801 at the very bottom of: &ldquo;model_mel_band_roformer_crowd.yaml&rdquo; file in &ldquo;mdx_c_configs&rdquo; subfolder. Don&rsquo;t use overlap above 4.</span></p><p class="c1"><span>- Mel-Roformer De-Crowd by Aufr33/viperx (x-minus.pro/UVR/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.4/mel_band_roformer_crowd_aufr33_viperx_sdr_8.7144.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743207016&amp;usg=AOvVaw0R3Y53xH-3bYot8BDXcGJA">DL</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.4/model_mel_band_roformer_crowd.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743207179&amp;usg=AOvVaw3JHLvnCWjAr4DjDeAzq0lE">conf</a></span><span>)<br>For UVR, change the model name to the one from the attached yaml, copy chkpt to models\MDX_Net_Models, and yaml to model_data subfolder, then set overlap 2 or use ZFTurbo inference </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035743207573&amp;usg=AOvVaw10UCs9OXMIpl8FJLyAGV10">script</a></span><span>]</span><span class="c0">&nbsp;- more effective than MDX below at times)</span></p><p class="c1"><span class="c0">- MDX23C De-crowd v1/v2 (MVSEP)</span></p><p class="c1"><span class="c0">- Older MVSEP model (applause, clapping, whistling, noise)</span></p><p class="c1"><span>&nbsp;- Aufr33&rsquo;s Mel-Roformer Denoise average variant (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/vM4mHTYQ%23f_uCxxS_olfTR4iAsOc-XS6sfUecfbF-ZKXrk3IjbnY&amp;sa=D&amp;source=editors&amp;ust=1765035743208161&amp;usg=AOvVaw2DpO7DMn34_n8RpHvd7Wol">link</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1uwInhwgjOMIdOMTgj_oNR_dmaq7E-b3g/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743208319&amp;usg=AOvVaw3ohdIbtEu2m_kkB7OZiJpJ">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743208548&amp;usg=AOvVaw1QfnBRew7i7byjxCrEF0CE">Colab</a></span><span class="c0">) can be also used as crowd removal </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.tvbntqdvkn9n">AudioSep</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.4svuy3bzvi1t">USS Bytedance</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.g37f4a6hnxm0">Zero Shot Audio Source Separation</a></span></p><p class="c1"><span class="c0">- GSEP (sometimes), and e.g. drums stem is able to remove applauses </span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708580573697933382/859156390537855066/chant_model.pth&amp;sa=D&amp;source=editors&amp;ust=1765035743209391&amp;usg=AOvVaw28LWC4R_Hk2hNGE1K5-Js_">Chant model</a></span><span>&nbsp;(by HV, VR arch, e.g. works for applauses; may leave some echo to separate with other models or tools below) for Colab usage - you need to copy that model to models/v5 and then use 1 band 44100 param, turn off auto-detect arch and set it to &quot;default&quot;. In UVR pick one of 44100 1 band parameter, possibly 512.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;For really difficult live songs (where the crowd is overwhelmingly loud to the point where you can&#39;t hear the band properly) sometimes filtering vocals with mel roformer on xminus THEN running the vocals stem through the mdx decrowd model sometimes helps&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.owqo9q2d774z"><span class="c18 c15">SFX</span></h6><p class="c1"><span class="c6">- &ldquo;You do need to first get an instrumental with a different model, because this isn&#39;t really trained to remove vocals. Just SFX&rdquo; or speech.</span></p><p class="c1"><span class="c20">- SFX models can be more aggressive than regular vocal models for </span><span class="c4 c20"><a class="c3" href="#h.o6au7k9vcmk6">speech</a></span><span class="c6">.</span></p><p class="c1"><span class="c6">Sometimes, some of the regular vocal models may turn out to be better suited for your task, so try out those for speech too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- BS-Roformer SW drums - &ldquo;really good to remove some SFX and foley, way better than DnR v3&rdquo; - erosunica</span></p><p class="c1"><span class="c0"><br>- MVSEP DNnR v3:</span></p><p class="c1"><span class="c0">a) SCNet </span></p><p class="c1"><span class="c0">b) MelBand </span></p><p class="c1"><span class="c0">(better metrics than Bandit v2) </span></p><p class="c1"><span><br>- Bandit v2 (MVSEP | OG </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/records/12701995&amp;sa=D&amp;source=editors&amp;ust=1765035743212010&amp;usg=AOvVaw0fv4Lo8Ef2tZxBvo6aB1ZX">weights</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/configs/config_dnr_bandit_v2_mus64.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743212216&amp;usg=AOvVaw3RGE880Xq0SuDu1FGf5eAw">yaml</a></span><span class="c0">) multilingual model (multi) </span></p><p class="c1"><span>or single ones for EN/GER/FR/SPA/CH/FAR language. <br>All </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/banditv2_state_dicts_only/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743212576&amp;usg=AOvVaw3AZOiXyM_MAfjjFLY0_U0q">models</a></span><span>&nbsp;converted (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/configs/config_dnr_bandit_v2_mus64.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743212761&amp;usg=AOvVaw33gv_HnAXZ0iSu1AKVs58i">yaml</a></span><span>)</span><span>&nbsp;for ZFTurbo inference | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743213055&amp;usg=AOvVaw3iWPFZCaLdlLlHqIIjzrxx">Colab</a></span><span>&nbsp;</span><span>| <br>in </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span>&gt;MDX-Net&gt;Download More Models&gt;Bandit v2/Plus</span><span class="c0"><br>(v2 is better on speech vs Bandid Plus, not always on SFX - experiment).</span></p><p class="c1"><span class="c0">&ldquo;Multilingual model is most of the time giving better results than French model for French content, so I would start with it&rdquo; - jarredou<br></span></p><p class="c1"><span>&ldquo;Co-developed by Netflix and Georgia Institute of Technology. The </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2309.02539&amp;sa=D&amp;source=editors&amp;ust=1765035743213884&amp;usg=AOvVaw0BjC3SsUIIiT6wNnyWSL_X">paper</a></span><span>&nbsp;</span><span class="c0">is titled &quot;A Generalized Bandsplit Neural Network for Cinematic Audio Source Separation&quot;&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older models</span></p><p class="c1"><span>- Bandit Plus (</span><span>may work good for TV shows and movies: MVSEP, jarredou </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743214745&amp;usg=AOvVaw27L7-Asu5XpmthVbMCNGlj">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span><br>&ldquo;trained on mono audio, so it&#39;s dual mono (...) when content is heavily panned left/right, it&#39;s where issues start to say &quot;hello !&quot;&rdquo; but other than that it might still handle stereo good enough or even better than others depending more on a song</span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;My suggestions from those who want best results, i suggest using either:</span></p><p class="c1"><span class="c0">resreuction inst or instfv8 to extract Music and effects audio track&rdquo; - killdubo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- jazzpear94 Mel-RoFormer model (ability to separate specific SFX groups - Ambiance, Foley, Explosions, Toon, Footsteps, Fighting and General - for all in one stem | MVSEP, fixed newer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1msFRvDn6ZbBsAC5XzIst4ABIxVL-V8T0?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743217984&amp;usg=AOvVaw2EFsF6vlRJUBWvMZwYNftr">Colab</a></span><span>,</span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1la6Piir7j-GzRFaPEt_W7x_fAwv9gYYF/view&amp;sa=D&amp;source=editors&amp;ust=1765035743218324&amp;usg=AOvVaw3KM64ibiYmiQwFmCmdEPKw">files</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/ZoaT0hn.png&amp;sa=D&amp;source=editors&amp;ust=1765035743218533&amp;usg=AOvVaw0uEczgK3D8BvpSmio4AwS3">instruction</a></span><span>, prob. broken Colabs: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1Mncjg3JLOgE1Kj6oJAaJ0nIzShLDEHr2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743218759&amp;usg=AOvVaw0eA_yuHtiRQzekzERKNizG">1</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1YBpeGj66FfIHS1WH8uYBcshITOGVYOHY?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743218942&amp;usg=AOvVaw01V6xMMViaFGRROoOXRfo-">2</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1jrw-cAi-JqZpBi6wyT3YIp3x-XHhDm1W?usp%3Dsharing%23scrollTo%3DI9-pu3zHFtFk&amp;sa=D&amp;source=editors&amp;ust=1765035743219149&amp;usg=AOvVaw23cP0_5BWTT4ZOuvoykxxA">3</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1efoJFKeRNOulk6F4rKXkjg63RBUm0AnJ&amp;sa=D&amp;source=editors&amp;ust=1765035743219314&amp;usg=AOvVaw2QrIuNfZRgCSMqe0LBgbdh">4</a></span><span class="c0">)</span></p><p class="c1"><span>- joowon bandit model: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/karnwatcharasupat/bandit&amp;sa=D&amp;source=editors&amp;ust=1765035743219704&amp;usg=AOvVaw1Q7h7dYD8m67jc9UcCCSrC">https://github.com/karnwatcharasupat/bandit</a></span></p><p class="c1"><span>(better SDR for Cinematic Audio Source Separation (dialogue, effect, music) than DNR Demucs 4 below (SDR 10.16&gt;11.47) - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1efoJFKeRNOulk6F4rKXkjg63RBUm0AnJ?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743220146&amp;usg=AOvVaw1K8EfjbxSDF_PEesHgOQ8K">Colab</a></span><span class="c0">&nbsp;/ MVSEP)</span></p><p class="c1"><span class="c0">- GAudio (a.k.a. GSEP) announced their SFX (DnR) model in their API:<br>&ldquo;DME Separation (Dialogue, Music, Effects)&rdquo; <br>So far it&rsquo;s not available for everyone on their regular site:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://studio.gaudiolab.io/&amp;sa=D&amp;source=editors&amp;ust=1765035743220643&amp;usg=AOvVaw0gvt0QXiwhV0cE2_hk1b3P">https://studio.gaudiolab.io/</a></span></p><p class="c1"><span class="c0">But the link on their Discord redirects to the site with a form to write an inquiry:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.gaudiolab.com/developers&amp;sa=D&amp;source=editors&amp;ust=1765035743220968&amp;usg=AOvVaw13b2Zzzr2XJoU_pheLQe-F">https://www.gaudiolab.com/developers</a></span></p><p class="c1"><span class="c0">Shortly after entering the one or both of the links and logging on the first, you might get an email that $20 of free credits to access their API have been added to your account</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.4svuy3bzvi1t">USS-ByteDance</a></span><span class="c0">&nbsp;(for providing any, at least, proper sample)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.g37f4a6hnxm0">Zero Shot</a></span><span class="c0">&nbsp;(currently worse for SFX vs Bytedance)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.p3wngakyrk0n">Audiosep</a></span></p><p class="c1"><span class="c0">- custom stem separation on Dango (paid, 10 seconds for free)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- DNR Demucs 4 model (repo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/MVSEP-CDX23-Cinematic-Sound-Demixing&amp;sa=D&amp;source=editors&amp;ust=1765035743222080&amp;usg=AOvVaw38J-3cesskf1WLujlAHBEN">CDX23</a></span><span>&nbsp;repo, MVSEP, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-CDX23-Cinematic-Sound-Demixing-Colab-Inference/blob/main/MVSEP_CDX23_Cinematic_Sound_Demixing_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743222283&amp;usg=AOvVaw0HaRgGOCU-8WSVxFnTd4Tq">Colab</a></span><span class="c0">) - it used to output fake stereo (at least training dataset was mono).</span></p><p class="c1"><span class="c0">&quot;I noticed [it] doesn&#39;t do well and doesn&#39;t detect water sounds, and fire sounds&quot;</span></p><p class="c1"><span class="c20">Can be used in UVR</span><span class="c0">&nbsp;(the three stems will be labelled wrong, SFX will be bass).</span></p><p class="c1"><span>&gt;For UVR, download the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/MVSEP-CDX23-Cinematic-Sound-Demixing/releases/tag/v.1.0.0&amp;sa=D&amp;source=editors&amp;ust=1765035743222928&amp;usg=AOvVaw2w2eeNVBMxXarYgZxUXklz">model files</a></span><span>, put them in the Ultimate Vocal Remover\models\Demucs_Models\v3_v4_repo, Delete &quot;97d170e1-&quot; &nbsp;from all the three file names, copy this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/15NKIgCAHGMgH53Bi94PkDRsjQtqyywen/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743223230&amp;usg=AOvVaw1biyGxBOe6w9t32j8Sk3O3">yaml</a></span><span class="c0">&nbsp;alongside the model files (it won&rsquo;t work on AMD 4GB VRAM GPUs).</span></p><p class="c1"><span class="c0">&gt;The Colab might run occasionally on CPU, and then it might be slow to the point that it might take 2.5h for a 15 min audio track (maybe change Google account or retry), and then it might take 2 mins for a similar length once it uses GPU.</span></p><p class="c1"><span>- jazzpear&rsquo;s MDX23C model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1180312079920529448&amp;sa=D&amp;source=editors&amp;ust=1765035743223980&amp;usg=AOvVaw19rD-kbGLhUMxBnRzIwOyA">files</a></span><span class="c0">) - &nbsp;rename the config to .yaml as UVR GUI doesn&#39;t read .yml. You put config in UVR&rsquo;s models\mdx_net_models\model_data\mdx_c_configs. Then when you use it in UVR it&#39;ll ask you for params, so you locate the newly placed config file.</span></p><p class="c1"><span class="c0">- Aufr33 Mel-Roformer denoise average &ldquo;27.9768&rdquo; model - dedicated for footsteps, crunches, rustling, sound of cars, helicopters</span></p><p class="c1"><span>If it&rsquo;s not available for paid users of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app&amp;sa=D&amp;source=editors&amp;ust=1765035743224830&amp;usg=AOvVaw1LJLTAypJ7kWHcrSZSiqCy">uvronline.app</a></span><span>, use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035743224938&amp;usg=AOvVaw3PcmQ66jpSp3TLiqOH8xuE">this</a></span><span class="c0">&nbsp;link | MVSEP | model files:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/rIRQGJ4D%239SHaPIXt8GRoi2SL29WUILW0g9dk26I5njyFPZuPJQ8&amp;sa=D&amp;source=editors&amp;ust=1765035743225140&amp;usg=AOvVaw1qa1XG6uvfcP-aKlurBqDS">Less aggressive</a></span><span>&nbsp;&amp; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/vM4mHTYQ%23f_uCxxS_olfTR4iAsOc-XS6sfUecfbF-ZKXrk3IjbnY&amp;sa=D&amp;source=editors&amp;ust=1765035743225302&amp;usg=AOvVaw3l6U_VXHV37oLTtSEVU02Q">More aggressive</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1uwInhwgjOMIdOMTgj_oNR_dmaq7E-b3g/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743225461&amp;usg=AOvVaw3yfDMgjpGoF2QdA8q4Qohh">yaml file</a></span><span>&nbsp;| UVR Roformer </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">patch</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb%23scrollTo%3DGS-QezQ-RG64&amp;sa=D&amp;source=editors&amp;ust=1765035743225726&amp;usg=AOvVaw1JPS9a_4NEdjIIPN3KfBMl">Colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- myxt.com (uses Audioshake)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.tvbntqdvkn9n">AudioSep</a></span><span class="c0">&nbsp;(you can try it to get e.g. birds SFX and then use as a source to debleed or maybe try to invert phase and cancel out)</span></p><p class="c1"><span class="c0">- Moises.AI (the rumour says it&rsquo;s better than Bandit v2, but it&rsquo;s expensive &ldquo;Dialogue, Soundtrack, Effects&rdquo;)</span></p><p class="c1"><span class="c0">- Older DNR model on MVSEP from &lsquo;22</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I think the most commonly used recent SFX models discussed in the server before DnR v3 ones are DNR Demucs 4 model and Bandit v2, but I haven&#39;t seen any settlement in the community on which model is the best, hence it might simply depend on a song.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- voc_ft - sometimes it can be better than Demucs DNR model (although still not perfect)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.dropbox.com/scl/fo/lcpknm3rvehxhryzcd6mb/h?rlkey%3Dzpi8pnpda30d0n71tqckiocod%26dl%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035743227400&amp;usg=AOvVaw0I5fhtavlOADoxYC-SMXI1">jazzpear94 model</a></span><span>&nbsp;(VR-arch) - put the .pth file to: Ultimate Vocal Remover\models\VR_Models. On UVR start set config: 1band sr44100 hl 1024, stem name: SFX, Do NOT check inverse stem in UVR5, 5.1 disabled. Or put that </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/15YlbTv9CypsmSDC7l0s-HPOGJTVztFkL/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743227809&amp;usg=AOvVaw2NrHN3Vw3vG3lRERklkd11">file</a></span><span class="c0">&nbsp;to model_data subfolder.</span></p><p class="c1"><span>- (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/12CnfpIph5Ipd9ocoD6RsbOWzWsCeWAeT?usp%3Dshare_link&amp;sa=D&amp;source=editors&amp;ust=1765035743228038&amp;usg=AOvVaw1d5q3QxsxxW_n8AvpoCu_8">dl</a></span><span>) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1055221556223164487&amp;sa=D&amp;source=editors&amp;ust=1765035743228185&amp;usg=AOvVaw1xDEPIKOr5-vc6O_D1sNQ0">source</a></span><span>&nbsp;by Forte (VR) &nbsp;(probably setting to: instrumental/1band_44100_hl1024 is the proper config) Might work in Colab &ldquo;I tried it with the SFX models, and I just uploaded them in the models folder and then placed the model name, and it processed them&rdquo; and may even work in UVR.</span></p><p class="c1"><span>- Or </span><span class="c4"><a class="c3" href="#h.yy2jex1n5sq">GSEP</a></span><span>&nbsp;(sometimes) esp. the new &ldquo;Vocal Remover&rdquo; model</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.ewm80hx745ur"><span class="c22">Any other</span><span class="c0">&nbsp;stem/instrument/sample if not listed above</span></h6><p class="c1"><span class="c0">- Zero Shot Audio Source Separation</span></p><p class="c1"><span class="c0">- Bytedance-USS (might be worse for instruments, but better for SFX)</span></p><p class="c1"><span class="c0">- Dango.ai custom stem separation (paid, free 10 seconds preview)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Audio-AGI/AudioSep/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743229655&amp;usg=AOvVaw2c7p1-KUh_t2-iVxzXmnGm">Audiosep</a></span><span class="c0">&nbsp;(separate everything you describe; Colab has unpickling issue)</span></p><p class="c1"><span>- </span><span class="c6">Spectral removers (software or VST):</span></p><p class="c1"><span>Quick Quack MashTactic (VST), Peel (VST, they say it&rsquo;s worse alternative of MT), Bitwig (DAW), RipX (app), iZotope Iris (VST/app), SpectraLayers (app, &ldquo;Problem with RX [Editor&#39;s spectral editing] is it doesn&#39;t support working in layers non-destructively.&rdquo;), R-Mix (old 32 bit 2010 Sonar plugin), free </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://isse.sourceforge.net/download.html&amp;sa=D&amp;source=editors&amp;ust=1765035743230596&amp;usg=AOvVaw1Qn2RVVmyYiB6hyNqjvqbn">ISSE</a></span><span>&nbsp;(app, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/Rd3prIkO5bg&amp;sa=D&amp;source=editors&amp;ust=1765035743230693&amp;usg=AOvVaw1ALv0d2p4iVVxq2frQ123u">showcase</a></span><span>), </span><span class="c4"><a class="c3" href="#h.cz4j2d3uf48s">FactorSynth</a></span><span class="c0">, Zplane Copycat &quot;but MashTactic also has a dynamics parameter that is really useful (you can isolate attack from longer sounds, or the opposite, coupled with the stereo placement and EQ isolation)&quot;</span></p><p class="c1"><span class="c0">RipX is &ldquo;not as good as UVR5 for actual separation, but RipX is very good if you need to edit what&#39;s already separated more musically. SpectraLayers is a nicer spectral editor, RipX spectral editor is not as usable&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Consecutive multi-AI separation for not listed instruments </span></p><p class="c1"><span class="c0">- Extract all other instruments &quot;one by one&quot; using other models in the chain (e.g. remove vocals with voc_ft or now e.g. inst Mel Kim derivative, use what&#39;s left to remove drums/bass with htdemucs_ft/MDX23/MVSEP ensemble, use what&#39;s left to remove guitars/piano with GSEP/demucs_6s or now any better purpose model, then use what&#39;s left to remove e.g. wind instruments (if present) with UVR wind model, or any any other purpose model applicable, even SFX, till you&#39;re left with the instrument of your choice, or as few instruments, as possible, for potentially easier work with spectral editor listed above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.m55fp5i7rdpm">Drumsep</a></span><span class="c0">&nbsp;- &ldquo;Using DrumSep on melodic stems can help separate instruments easier if you plan on sampling/editing them, but they are separated based on range rather than actual instrument. Low instruments will often be on the kick/tom stems, mid instruments will be on snare and/or tom, and higher instruments will be on the cymbals.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.kcswx79hi856"><span class="c22">De-reverb</span></h6><h6 class="c1 c27" id="h.udtfyb1ib06t"><span>- Mel-Roformer de-reverb by anvuew v2 (a.k.a. 19.1729 SDR) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/resolve/main/dereverb_mel_band_roformer_anvuew_sdr_19.1729.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743233907&amp;usg=AOvVaw3zPxd2ESWA8IqdsPdivDkh">DL</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/resolve/main/dereverb_mel_band_roformer_anvuew.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743234090&amp;usg=AOvVaw3Mnr8f0gw_DNpLpfpIVKN1">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743234306&amp;usg=AOvVaw3lIqqmQ7Hg4YOhzNjNoWli">Colab</a></span><span class="c0"><br>Probably the best de-reverb for now.</span></h6><h6 class="c1 c27 c7" id="h.eaqmnwmozv25"><span class="c0"></span></h6><h6 class="c1 c27" id="h.w2k1uzl4s2wf"><span class="c0">- and RX11&#39;s dialogue isolate for de-echo.<br></span></h6><h6 class="c1 c27" id="h.7evuubgmy2pn"><span class="c0">&ldquo;anvuew&#39;s models can remove reverb effect only from vocals, &ldquo;captures early reflections a little&rdquo;. Old FoxJoy&#39;s model works with full track.&rdquo;</span></h6><p class="c1"><span>&ldquo;sort of reminds of RX11 dialogue dereverb results but doesn&#39;t destroy singing voices&rdquo;<br>&ldquo;perfect for rvc&rdquo;<br>Both BS and Mel variant &ldquo;will also remove harmonies or vocal effects that are not in the center channel.&rdquo;<br>&ldquo;it works sort of like </span><span class="c4"><a class="c3" href="#h.3c6n9m7vjxul">that</a></span><span class="c0">&nbsp;phantom center model, removing sides basically&rdquo;<br>Sometimes &quot;noreverb&quot; stem might get empty (e.g. on MVSEP, but similar issues was fixed already once there).</span></p><p class="c1"><span class="c0">&ldquo;reminds me of the equivalent dereverb mdx model (...) cleaner in some ways, though slightly more filtered and aggressive.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;it&#39;s EXTREMELY aggressive, like very aggressive, it seems kinda muddy at a lot of parts, almost NO reverb bleed, it also caught so many effects and removed them (good thing) which is actually insane!! i also noticed that when it gets breathy or like it has falsetto, it seems to remove a lot of it, it&#39;s very weird at the breathy-ish parts of it lol, will be using this mainly if there are heavy vocal effects i want removing&rdquo; - isling<br>In fact, it was &ldquo;fine-tuned from kim&#39;s mel&rdquo; - anvuew.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To make it work with UVR, delete &ldquo;linear_transformer_depth: 0&rdquo; from the YAML file, copy the model to MDX_Net_Models and config to model_data\mdx_c_configs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Dango Reverb Remover - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tuanziai.com/en-US/de-reverb&amp;sa=D&amp;source=editors&amp;ust=1765035743237329&amp;usg=AOvVaw0okoP6CkC6GZNHxkHoTsUK">click</a></span><span class="c0">&nbsp;(&ldquo;it&#39;s very similar to [RX11] dialogue isolate good/real-time set to 5. Yeah, it&#39;s like listening to the same inference files&rdquo; John; probably also works in mono, you can get 30 seconds for free) but for other purposes, even older FoxyJoy&rsquo;s models can give better results</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.toae4851qt3d"><span>- anvuew BS-Roformer Dereverb Room </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_room&amp;sa=D&amp;source=editors&amp;ust=1765035743238042&amp;usg=AOvVaw0DXU_9mUZGJK2txO7pXiw3">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743238288&amp;usg=AOvVaw2Q_5Wstu4devX2SjWpkOtQ">Colab</a></span><span>&nbsp;| MVSEP <br>(doesn&rsquo;t work in UVR, use </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span><span>, If you have stereo errors using MSST on stereo files, update MSST [git clone and git pull commands] or see below.</span></h6><h6 class="c1 c27" id="h.bguqx29wxh6h"><span class="c0">&ldquo;specifically for mono vocal room reverb.&rdquo; as most are recorded in mono.</span></h6><p class="c1"><span class="c0">Not that long inference compared to other Roformers.</span></p><p class="c1"><span class="c0">&ldquo;Really liking the fullness in the noreverb stem. Virtually all dereverb roformers I&#39;ve tried sound muddy, but this one is just the opposite. (...) Other noises may interfere, and in my experience, makes the model underestimate the reverb. [The previous anvuew&rsquo;s mono model] is way different [from] this one in every way. So, like I say, worth a shot.&rdquo; - Musicalman</span></p><p class="c1"><span class="c0">Do the below to fix stereo error using that model, it might work with your current MSST version instead of the linked repo too, but in a different line.</span></p><p class="c1"><span>&ldquo;Edit inference.py from my </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training/tree/colab-inference&amp;sa=D&amp;source=editors&amp;ust=1765035743240424&amp;usg=AOvVaw0NwvFDBO_zQ--Ue_0QBihq">repo</a></span><span>&nbsp;</span><span class="c0">line 59:</span></p><p class="c1"><span class="c0">Replace :</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; # Convert mono to stereo if needed</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; if len(mix.shape) == 1:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mix = np.stack([mix, mix], axis=0)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">by :</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; # If mono audio we must adjust it depending on model</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; if len(mix.shape) == 1:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mix = np.expand_dims(mix, axis=0)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if &#39;num_channels&#39; in config.audio:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if config.audio[&#39;num_channels&#39;] == 2:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(f&#39;Convert mono track to stereo...&#39;)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mix = np.concatenate([mix, mix], axis=0)&rdquo;</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- anvuew </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/resolve/main/dereverb_mel_band_roformer_mono_anvuew_sdr_20.4029.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743242250&amp;usg=AOvVaw0AHoNZgSafA6yk4ztH7_mH">dereverb_mel_band_roformer_mono_anvuew_sdr_20.4029</a></span><span>&nbsp;model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/resolve/main/dereverb_mel_band_roformer_anvuew.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743242428&amp;usg=AOvVaw06d0D52yp_u6ZpufRKJYFW">yaml </a></span><span>| x-minus<br>&ldquo;supports mono, but ability to remove bleed and BV is decreased&rdquo; &ldquo;separates reverb better than v2&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Sucial Mel-Roformer dereverb/echo model #3 called &ldquo;fused&rdquo;: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer/blob/main/dereverb_echo_mbr_fused_0.5_v2_0.25_big_0.25_super.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743242985&amp;usg=AOvVaw1VBJOisaPI6IEKGrzFStR8">model</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer/blob/main/config_dereverb_echo_mbr_v2.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743243132&amp;usg=AOvVaw3PJqCWk6i_KUalKhlJFmcP">yaml</a></span><span class="c0"><br>&ldquo;more effective in removing large reverb&rdquo;<br></span></p><p class="c1"><span>&ldquo;Specifically targeting large reverb removal. After training, I combined these two models with my v2 model through a blending process, to better handle all scenarios. At this stage, I am still unsure whether my new models outperform the anvuew&#39;s v2 model overall [besides large reverbs].&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer&amp;sa=D&amp;source=editors&amp;ust=1765035743243871&amp;usg=AOvVaw26497TC_oxH6qfQKDjA7dP">More</a></span><span class="c0"><br></span></p><p class="c1"><span>- avuew v2 &ldquo;less aggressive&rdquo; variant - a bit lower SDR 18.81 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/resolve/main/dereverb_mel_band_roformer_less_aggressive_anvuew_sdr_18.8050.ckpt?download%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035743244322&amp;usg=AOvVaw18lrOFgpIEbtg0oeem5iMy">DL</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/blob/main/dereverb_mel_band_roformer_anvuew.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743244530&amp;usg=AOvVaw1394Zbkxl8nnK9dhV_DEzg">config</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox Lead Vocal Mel-Roformer de-reverb | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/experimental/Lead_VocalDereverb.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743245018&amp;usg=AOvVaw3-5uqOzZlmmXVSuJtzQ0Gm">DL</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/blob/main/melbandroformers/karaoke/karaokegabox_1750911344.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743245262&amp;usg=AOvVaw2ILZxWDMsVTNjpfe5DeUJs">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743245565&amp;usg=AOvVaw0Z5xY998N2_joFkhllCTIf">Colab</a></span></p><p class="c1"><span>&ldquo;just use it on the mixture&rdquo;</span></p><p class="c1 c7"><span class="c0"><br></span></p><p class="c1"><span class="c20">Older<br>VR </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/tag/all_public_uvr_models&amp;sa=D&amp;source=editors&amp;ust=1765035743246125&amp;usg=AOvVaw075vdhAuh0Xeo1Q9N_OgsQ">models</a></span></p><p class="c1"><span>(added to UVR 5 (GUI), works in NotEddy&rsquo;s </span><span class="c4"><a class="c3" href="#h.wbc0pja7faof">Colab</a></span><span class="c0">)</span></p><p class="c1"><span>- UVR-DeEcho-DeReverb (213 MB) - &ldquo;it removes reverb not echo&rdquo; but you could try it if everything above fails<br>&ldquo;use an aggression of 3.0 -5.0 and nothing more than that.&rdquo; e.g. 4 (0.4 in some CLI code Colabs).<br>&ldquo;Results have a frequency ceiling around 17540 Hz and a very high pitched noise above 22000 Hz, you might want to upscale your results with HQNizer or Apollo Model&rdquo; - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.i7mm2bj53u07&amp;sa=D&amp;source=editors&amp;ust=1765035743247482&amp;usg=AOvVaw39o3kMDFJMjpzyE9ya69sh">more</a></span><span>. Or use </span><span class="c4"><a class="c3" href="#h.929g1wjjaxz7">point #4</a></span><span>&nbsp;to slow down the audio and revert it back.</span></p><p class="c1"><span class="c0">__</span></p><p class="c1"><span>(below the old ones, which might only work with vocal-remover 5.0.2 by tsurumeso&rsquo;s default arch settings, [maybe 1band_sr44100_hl1024 or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/blob/master/lib_v5/vr_network/modelparams/1band_sr44100_hl512_nf1024.json&amp;sa=D&amp;source=editors&amp;ust=1765035743248245&amp;usg=AOvVaw0IxUsc8oZ62YsyIiwZIfO_">512</a></span><span>? and his </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/tsurumeso/vocal-remover/tree/develop/lib&amp;sa=D&amp;source=editors&amp;ust=1765035743248396&amp;usg=AOvVaw30hhtSPMDrw_eCyUZ_ukM2">nets and layers</a></span><span>]</span><span class="c0">)</span></p><p class="c1"><span>- VR dereverb - only works on tracks with stereo reverb (j48qny.pth, 56,5MB) (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://files.catbox.moe/7cnm62.pth&amp;sa=D&amp;source=editors&amp;ust=1765035743248666&amp;usg=AOvVaw0fG4n7IfTiNqjfEalDPYk-">dl</a></span><span>) (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1006301791354376233&amp;sa=D&amp;source=editors&amp;ust=1765035743248793&amp;usg=AOvVaw3yGFgj0PgvsLROVxiw0nTE">source</a></span><span class="c0">)</span></p><p class="c1"><span>- VR reverb and echo removal model (j48qny.pth, 56,5MB) (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://files.catbox.moe/j48qny.pth&amp;sa=D&amp;source=editors&amp;ust=1765035743249013&amp;usg=AOvVaw2l0Ags_U2b7prq5tSTyRuj">dl</a></span><span class="c0">), works with mono/stereo)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX models (less aggressive than those at the top)</span></p><p class="c1"><span class="c0">&ldquo;I use it when there&#39;s not so much reverb, but if it&#39;s more intense I will choose VR-Arch DeEcho&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&gt; FoxyJoy&#39;s dereverb V2 - works only with stereo (available in UVR&#39;s download center and Colab (eventually via </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mediafire.com/file/spgazgyafo1pmrv/Reverb_HQ_By_FoxJoy.onnx/file&amp;sa=D&amp;source=editors&amp;ust=1765035743249816&amp;usg=AOvVaw2005yG2nD-viQAB6VffTBk">this</a></span><span class="c0">&nbsp;dl link); it can spoil singing in acapellas or sometimes removes delay too). &ldquo;I do think [that] MDX is noticeably more accurate [vs VR DeEcho-DeReverb]&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;(the model is also on X-minus) Note that this model works differently from the UVR GUI. I use the rate change (but unlike Soprano mode only by 1 semitone). This extends the frequency response and shifts the MDX noise to a higher frequency range.&quot; It&#39;s 11/12 of the speed so x 0.917, but actually something else goes on here: </span></p><p class="c1"><span class="c0">(Anjok)</span></p><p class="c1"><span class="c0">&quot;The input audio is stretched to 106%, and lowered by 1 semitone using resampling. After AI processing, the speed and pitch of the result are restored.&quot;</span></p><p class="c1"><span class="c0">You&#39;ll find slowing down method explained further in &quot;tips to enhance separation&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;De-echo is superior to de-reverb in every way in my experience&quot;</span></p><p class="c1"><span class="c0">&ldquo;VR DeEcho DeReverb model removes both echo and reverb and can also remove mono reverb while MDX reverb model can only remove stereo reverb&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;You have to switch [main stem/pair] to other/no other instead of vocal/inst&quot; in order to ensemble de-echo and de-reverb models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Newer </span></p><p class="c1"><span>- UVR Dereverb model by Aufr33 &amp; jarredou for uvronline.app premium | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/CFRBHLRK%23uhRexQFJVo8_Owr8x9sEEohDcCNZbl3UgeX5eyD7IFA&amp;sa=D&amp;source=editors&amp;ust=1765035743252395&amp;usg=AOvVaw3Toeg3D7ZtbGXeRmJHzQEu">Model files</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/dZAJwef&amp;sa=D&amp;source=editors&amp;ust=1765035743252498&amp;usg=AOvVaw3-66fEzY_HgrpUGnm3Bfza">settings</a></span><span>&nbsp;(</span><span class="c0">PS: Dry, Bal: 0, VR 5.1, Out: 32/128, Param: 4band_v4_ms_fulband)</span></p><p class="c1"><span class="c0">Copy model file to Ultimate Vocal Remover\models\VR_Models and json config is probably already present lib_v5\vr_network\modelparams (and has the same checksum).</span></p><p class="c1"><span><br>- MDX23C UVR Dereverb model for uvronline.app premium | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://a19p.uvronline.app/public/dereverb_mdx23c_sdr_6.9096.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743253137&amp;usg=AOvVaw1dOgo7fso2ojwqvDfXMsSJ">Model files</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1dQHfce4VKYSmWZ3IgIj4SZq_uTicD4At/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743253263&amp;usg=AOvVaw3TlVWw8zD9XzoHltT-aE8-">config</a></span></p><p class="c1"><span class="c0">(by Aufr33 &amp; jarredou)</span></p><p class="c1"><span class="c0">Seems to pick up room reverb. Previous Foxy&rsquo;s model sometimes cut &ldquo;way too much&rdquo; than this model.</span></p><p class="c1"><span class="c0">Copy model file to Ultimate Vocal Remover\models\MDX_Net_Models and yaml config to \model_data\mdx_c_configs subfolder.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Bas Curtiz&rsquo; conclusion on both:</span></p><p class="c1"><span class="c0">- MDX23C &ldquo;seems to be cleaner, takes the reverb away, also between the words,</span></p><p class="c1"><span class="c0">whereas (U)VR leaves a little reverb</span></p><p class="c1"><span class="c0">- VR &ldquo;seems to sound more natural, maybe therefore actually.</span></p><p class="c1"><span class="c0">- MDX23C tends to &#39;pinch&#39; some stuff away to the background, which sounds unnatural.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;This is just based on my experience with 3 songs/comparisons, but both points are a pattern.</span></p><p class="c1"><span>Overall, they&#39;re both great when u compare them against the original reverbed/untouched vocals.&rdquo; showcase </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1279223128848863338&amp;sa=D&amp;source=editors&amp;ust=1765035743254958&amp;usg=AOvVaw2dytQqJTziGQwC_qKFpZ11">video</a></span><span>.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- You can find older avuew Mel versions </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/tree/main/archive%2520only&amp;sa=D&amp;source=editors&amp;ust=1765035743255228&amp;usg=AOvVaw0kfgAYLMbFK1fNm6AQJyru">here</a></span><span><br></span></p><p class="c1"><span>- BS-Roformer anvuew variant (a.k.a. 8/256/8) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2229279531&amp;sa=D&amp;source=editors&amp;ust=1765035743255471&amp;usg=AOvVaw0zcrpY59SYPO4CmCZt_BPW">DL</a></span><span class="c0">&nbsp;- a bit higher SDR than Mel v1 (8/26/6) posted firstly in ZFTurbo repo.<br>&ldquo;not good is all people say&rdquo; but it might depend on a use case or a song.</span></p><p class="c1"><span class="c0">Mel-Roformer might turn out to be better more often &ldquo;works weirdly and leaves some echo for some reason&rdquo; &ldquo;very usable for single singing voices and speech, cus it&#39;s very precise in eliminating echo and reverb,</span></p><p class="c1"><span class="c0">but if you have a choir singing or vocals with backing vocals in it, then it&#39;ll probably ruin it a bit. For such vocals it&#39;s better to use aufr33/jarredou model or dereverb deecho&rdquo; John UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To fix issues with BS variant of the model in UVR &ldquo;change stft_hop_length: 512 to stft_hop_length: 441 so it matches the hop_length above&rdquo; in the yaml file (thx lew), plus delete linear_transformer line in the config like above too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- 8 384 dim 10 depth BS variant | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/deverb_bs_roformer/blob/main/deverb_bs_roformer_8_384dim_10depth.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743257096&amp;usg=AOvVaw1LwTHMS6g2HuQvtnj5vtSQ">dl</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/deverb_bs_roformer/blob/main/deverb_bs_roformer_8_384dim_10depth.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743257254&amp;usg=AOvVaw0nZ7SPjEqFm4htY6mibTg6">config</a></span><span><br><br>- #2 Sucial Mel-Roformer dereverb/echo model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2493431454&amp;sa=D&amp;source=editors&amp;ust=1765035743257469&amp;usg=AOvVaw3uuJyeGOfl6ocW4Kszklaa">model</a></span><span>&nbsp;| MVSEP).<br>Fine-tune with more training data.<br><br>- #1 Sucial Mel-Roformer dereverb/echo model (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2534381169&amp;sa=D&amp;source=editors&amp;ust=1765035743257868&amp;usg=AOvVaw1CYO8qWttDtlbHkepIKxTj">model</a></span><span>&nbsp;| MVSEP).<br>It&rsquo;s good but doesn&rsquo;t seem to be better than the anvuew&#39;s Mel v2 model above (</span><span class="c4"><a class="c3" href="#h.5zlfuhnreff5">models list</a></span><span>).<br>Still, might depend on a use case.<br></span></p><p class="c1"><span>- older V1 de-reverb HQ MDX model by FoxyJoy (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pixeldrain.com/u/UWn7d2iH&amp;sa=D&amp;source=editors&amp;ust=1765035743258412&amp;usg=AOvVaw2UiehcUj1nGn54no0fXGYE">dl</a></span><span>) (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/872995262224818187/1062492523689418793&amp;sa=D&amp;source=editors&amp;ust=1765035743258550&amp;usg=AOvVaw3JoVW5gWj0QEzEzvM2A6Hk">source</a></span><span>)</span><span class="c0">&nbsp;(also decent results, but most likely worse).</span></p><p class="c1"><span class="c0">(&ldquo;It uses the default older architecture with the fft size of 6144&rdquo; </span></p><p class="c1"><span class="c0">&ldquo;After separation, UVR cuts off the frequencies at 15 kHz, so I found that to fix that is to invert the &quot;Vocals&quot; and mix that with the original audio file.&rdquo;</span></p><p class="c1"><span>Demonstration: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://krakenfiles.com/view/CVqVzcS3PO/file.html&amp;sa=D&amp;source=editors&amp;ust=1765035743259327&amp;usg=AOvVaw1gblEHMR0585eIkSca694p">Original</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://krakenfiles.com/view/qKFcriiLLy/file.html&amp;sa=D&amp;source=editors&amp;ust=1765035743259450&amp;usg=AOvVaw1lAn-o_b_ZN5jbPxzXJdFy">Dereverbed</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://krakenfiles.com/view/XRwAcmYvMj/file.html&amp;sa=D&amp;source=editors&amp;ust=1765035743259606&amp;usg=AOvVaw2xboxkt9fD5e_wRbTmvEvF">Detected reverb</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- To enhance the result if necessary, you can use more layers of models to dereverb vocals, e.g.:</span></p><p class="c1"><span class="c0">Demucs + karaoke model + De-reverb HQ (by FoxyJoy) </span></p><p class="c1"><span class="c0">&quot;works wonders on some of this stuff&quot;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Originally I inverted with instrumentals then I ran through deecho dereverb at 10 aggression then demucs_ft then kim vocal 2 then uvr 6_ at 10 aggression and finally deecho normal&rdquo; (isling)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For room reverb check out:</span></p><p class="c1"><span class="c0">Reverb HQ</span></p><p class="c1"><span class="c0">then</span></p><p class="c1"><span class="c0">De-echo models (J2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;from my experience, De-Reverb HQ specifically only really works when the sound is panned in the center of the stereo field perfectly with no phase differences or effects or anything that could cause the sound to be out of phase in certain frequencies.</span></p><p class="c1"><span class="c0">If the sound doesn&#39;t fit that criteria, it only accurately produces the output of whatever&rsquo;s in the mid&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I noticed that in some cases the DeEcho normal worked better than the aggressive, which was weird. That&#39;s why I ran through both, so to remove as much as possible.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For removing reverb bleed left over in the left and right channels of a 5.1 mix from TV shows/movies check out:</span></p><p class="c1"><span class="c0">Melband Roformer on MVSEP</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.70231k4ydkfw"><span class="c0">Free apps/VSTs for de-reverb/de-echo/denoise</span></h6><p class="c1"><span class="c0">- Accusonus ERA (was good, but discontinued when Facebook bought them, can be found on archive.org from when they gaveaway it without DRM)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/haoheliu/voicefixer_main&amp;sa=D&amp;source=editors&amp;ust=1765035743262844&amp;usg=AOvVaw2Cp0oExsGYYPmZqVKxGbey">Voicefixer</a></span><span>&nbsp;(CML, only for voice, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/akhaliq/VoiceFixer&amp;sa=D&amp;source=editors&amp;ust=1765035743263024&amp;usg=AOvVaw3MQIEo8y4yr8Gg5CulRtfr">online</a></span><span class="c0">)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/mhrice/RemFx&amp;sa=D&amp;source=editors&amp;ust=1765035743263174&amp;usg=AOvVaw0z8TsZYzyplzZv8FHLNU4x">RemFX</a></span><span class="c0">&nbsp;(de: chorus, delay, distortion, dynamic range compression, and reverb or custom)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/werman/noise-suppression-for-voice/releases&amp;sa=D&amp;source=editors&amp;ust=1765035743263506&amp;usg=AOvVaw27rQHWS49PXzOR8GK1XKLi">Noise Suppression for Voice</a></span><span class="c0">&nbsp;(a.k.a. RNNoise, worse, various plugin types, available in OBS; now also RRNoise 0.2/1.10 available)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://krisp.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743263778&amp;usg=AOvVaw32AJFuxwZcOb05I0xCMWR7">Krisp</a></span><span class="c0">&nbsp;app (paid, free 60 minutes per day) better (same for RTX voice) - free on Discord</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://podcast.adobe.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743264033&amp;usg=AOvVaw0t_PXwAJQbjw_D0B2g-iz7">Adobe Podcast</a></span><span>&nbsp;(online, a.k.a. Adobe Podcast Enhance Speech, only for narration, changes the tone of voice, so you might want to use only frequencies from it above 16kHz)<br>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ai-coustics.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743264346&amp;usg=AOvVaw3-b5FSIbuvEO2PWQyktCsW">AI-Coustics</a></span><span class="c0">&nbsp;(speech enhancement, 30 minutes/5 files for free per month)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://crystalsound.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743264592&amp;usg=AOvVaw1Jo_NJuQZyKMlQsLwNCaQb">CrystalSound.AI</a></span><span class="c0">&nbsp;(app)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://closedlooplabs.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743264739&amp;usg=AOvVaw0fiGmiabvWPim8rCOlwNFu">Noise Blocker</a></span><span class="c0">&nbsp;(paid, 60 minutes free per day)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://steelseries.com/gg&amp;sa=D&amp;source=editors&amp;ust=1765035743264934&amp;usg=AOvVaw1J9hTJg5-Dhuwk2cKN29bL">Steelseries GG</a></span><span class="c0">&nbsp;(app, classic noise gate with EQ and optional paid AI module, activating by voice in noisy environment may not always work correctly)</span></p><p class="c1"><span class="c0">- RTX Voice (in NVIDIA Broadcast app, currently for any GTX or RTX GPU)</span></p><p class="c1"><span class="c0">- AMD Noise Suppression (for RX 6000 series cards, or for older ones using unofficial Amernime Drivers)</span></p><p class="c1"><span>- Elgato Wave Link 3.0 - Voice Focus feature (now free for everyone, standalone VST3/AU version is paid 50$)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://meeamitech.com/ai-swb-noise-suppression/&amp;sa=D&amp;source=editors&amp;ust=1765035743265872&amp;usg=AOvVaw31itg1EuY1C8XOUHclMo7o">AI SWB Noise Suppression</a></span><span>&nbsp;(free, currently they give away that Mac/Windows driver only on </span><span class="c4"><a class="c3" href="mailto:info@meeamitech.com">email</a></span><span>&nbsp;</span><span class="c0">requests)</span></p><p class="c1"><span>- Audio Magic Eraser shipped with new Google Pixel phones (separate </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1159137836939882578/image.png?ex%3D651ecabc%26is%3D651d793c%26hm%3D02fab4a1c15a2090ac6cbd5e35aaae46b15854b228795b77b4b7df3463ca060b%26&amp;sa=D&amp;source=editors&amp;ust=1765035743266491&amp;usg=AOvVaw2DsLUYogLy9QJU3vqJAGNK">options</a></span><span class="c0">&nbsp;for cancellation of: noise, wind, crowd, speech, music)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">The best paid de-reverb plugins for vocal tracks/stems/separations:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- RX 11 Dialogue Isolate (RX Editor/VST, paid) - some people like it more than DeVerberate 3. In RX Advanced variant, there&rsquo;s additionally &ldquo;multi-band processing and a high-quality mode as an offline process&rdquo;, good companion for de-echo along with anvuew v2 model for dereverb</span></p><p class="c1"><span>- DeVerberate 3 by Acon Digital (someone while comparing said it might be even better than RX10) &quot;I find it&#39;s useful to take the reverb only track and unreverbed track and mix them to a nice level&quot; &ldquo;Acon is probably best if you can tweak to each stem separated. RX is imo too rough.&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1171587840837160980&amp;sa=D&amp;source=editors&amp;ust=1765035743268228&amp;usg=AOvVaw3xQHnLrFx4LlUUk8nLT9A0">Comparison</a></span></p><p class="c1"><span class="c0">- Accentize DeRoom Pro (&quot;great&quot; but expensive, available in DxRevive Pro, now 1.1.0)<br>- prime:vocal (multitool with also dereverb and other vocal enhancers)</span></p><p class="c1"><span class="c0">- DxRevive Pro 1.1.0 - complete dialogue restoration tool; noise removal, reverb suppression, restoration of absent frequencies, elimination of Codec Artifacts</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Izotope RX &lt;?8-10 Dialogue De-Reverb (RX Editor/VST) for voice and mixtures</span></p><p class="c1"><span>(more possible free </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/814405660325969942/1085297801749074051&amp;sa=D&amp;source=editors&amp;ust=1765035743269360&amp;usg=AOvVaw3fAbngbZ_uYwhrWmT8HPrJ">solutions</a></span><span class="c0">). Good results not only for room reflections, but also regular reverb in vocals. It picks reverb where even FoxyJoy&#39;s model fails (&ldquo;De-reverb&rdquo; and &ldquo;Dialogue de-reverb&rdquo; options). It&rsquo;s destructive for mixing raw vocals, but can just work.</span></p><p class="c1"><span class="c0">- Clear by Supertone &ldquo;equally good compared to RX10 imho. Smoother imho. It&#39;s only good on vocals though&rdquo; Simple 3 knob plugin - &ldquo;the cleverest / least-manual to get good results and is AI-based.&rdquo; previously known as Supertone Voice Clarity and defunct free GOYO.AI) Also destructive for mixing raw vocals, but can just work.</span></p><p class="c1"><span class="c0">- Waves Clarity Vx DeReverb - it cannot perform de-echoing, so you need UVR De-echo (17.7kHz cutoff) or RX Dialogue Isolate for it, simpler than RX (paid; models updated in 12/17/2023 build) - same. Maybe you could even mix the two plugins using less aggressive settings in both.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Others:</span></p><p class="c1"><span class="c0">- SPL De-Verb Plus</span></p><p class="c1"><span class="c0">- Audio Damage Deverb</span></p><p class="c1"><span class="c0">- Zynaptiq UnVeil </span></p><p class="c1"><span class="c0">- Zynaptiq Intensity</span></p><p class="c1"><span class="c0">- Thimeo Stereo Tool (one of its modules)</span></p><p class="c1"><span class="c0">- Acon Dialogue:Extract 2 (dereverb, denoise)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you want to use some of these DAW plugins for your microphone in real-time, you can use Equalizer APO.</span></p><p class="c1"><span class="c0">Go to &quot;Recording devices&quot; -&gt; &quot;Recording&quot; -&gt; &quot;Properties&quot; of the target mic -&gt; &quot;Advanced&quot;.</span></p><p class="c1"><span class="c0">To enable a plugin in Equalizer APO select &quot;Plugins&quot; -&gt; &quot;VST Plugin&quot; and specify the plugin dll. AFAIK, VST3 is unsupported.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>To run a plugin for a microphone in a simple app and send it to any output device, alternatively, you can download </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.hermannseib.com/english/savihost.htm&amp;sa=D&amp;source=editors&amp;ust=1765035743273513&amp;usg=AOvVaw0T6ZGqrHg04uYiQhMmLZQV">savihost3x64</a></span><span class="c0">, then edit downloaded exe name to the name of your plugin you want to use, placed nearby, and run the app. Now go to settings and set input and output device (can be virtual card, maybe not necessarily). Contrary to Equalizer APO (irc) it supports VST3 plugins too. Of course, you can also use DAWs for the same purpose (Reaper, Cakewalk etc. - but not Audacity irc)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">AI (paid):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://twoshot.app/model/36&amp;sa=D&amp;source=editors&amp;ust=1765035743274652&amp;usg=AOvVaw17b0o66uReoc1vHCEcevJn">https://twoshot.app/model/36</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Free:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-Enhancing.md%23dereverbers-&amp;sa=D&amp;source=editors&amp;ust=1765035743275084&amp;usg=AOvVaw0pqKJJTzyme1UteZN3Lvz7">https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-Enhancing.md#dereverbers-</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">De-echo</span></p><p class="c1"><span class="c0">- UVR-De-Echo-Aggressive (121 MB)</span></p><p class="c1"><span class="c0">- UVR-De-Echo-Normal (121 MB)</span></p><p class="c1"><span class="c0">- UVR-DeEcho-DeReverb (213 MB)</span></p><p class="c1"><span>(now added in UVR and MVSEP, won&#39;t be in Colab for now, but the first too are on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/r3gm/Ultimate-Vocal-Remover-WebUI&amp;sa=D&amp;source=editors&amp;ust=1765035743275866&amp;usg=AOvVaw38WAozfwjVlIy1b7iQnlKS">HuggingFace</a></span><span class="c0">)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pixeldrain.com/u/1Wck1P78&amp;sa=D&amp;source=editors&amp;ust=1765035743276029&amp;usg=AOvVaw0eTMo8j9lHcYW2MBdzahrd">delay_v2_nf2048_hl512.pth</a></span><span>&nbsp;(by FoxyJoy, all VR arch, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/872995262224818187/1062484995358347335&amp;sa=D&amp;source=editors&amp;ust=1765035743276186&amp;usg=AOvVaw3Rwi1hiWjFomzhF9OvzA4q">source</a></span><span>, can&#39;t remember if it was one of the above</span><span class="c0">), decent results.</span></p><p class="c1"><span class="c0">&ldquo;works in UVR 5 too. Just need to select the 1band_sr44100_hl512.json when the GUI asks for the parameters&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;You [also] can use this command to run it: python inference.py -P models\delay_v2_nf2048_hl512.pth --n_fft 2048 --hop_length 512 --input audio.wav --tta --gpu 0&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">They&rsquo;re also on X-Minus now:</span></p><p class="c1"><span class="c0">&ldquo;The &quot;minimum&quot; and &quot;average&quot; aggressiveness settings use the Normal version of the model. The Aggressive one is used only at the &quot;maximum&quot; aggressiveness.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;What&#39;s crazy is maximum aggressiveness sometimes does better at removing bgvox than actual karaoke models&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.hyzts95m298o"><span class="c18 c15">Denoising (vinyl noise/white noise/general)</span></h6><p class="c1"><span>- Denoise standard in UVR for MDX noise (like in HQ_1-5, iirc it uses HV </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/887455924845944873/1021652469320781834&amp;sa=D&amp;source=editors&amp;ust=1765035743277849&amp;usg=AOvVaw1o4cnRrgCLmeoCKQmlICt7">code</a></span><span>; explanation how it works</span><span class="c0">: it separates &quot;twice, with the second try inverted, after separation reinverted, to amplify the result, but remove the noise introduced by MDX, and then deamplified by 6dB, so it still the same volume, just without MDX noise.&rdquo;</span></p><p class="c1"><span class="c0">- Denoise model in UVR (it&rsquo;s using VR&rsquo;s UVR-DeNoise-Lite, 20kHz cutoff)</span></p><p class="c1"><span class="c0">(Options&gt;Choose Advanced Menu&gt;Advanced MDX-Net Options&gt;Denoise output) </span></p><p class="c1"><span class="c0">for filtering noise existing in almost all MDX-Net models in silent or quiet parts, but potentially also for more applications </span></p><p class="c1"><span>- Min Spec ensemble of </span><span class="c20">denoise model</span><span>&nbsp;and </span><span class="c20">denoise disabled</span><span class="c0">&nbsp;results in Advanced MDX-Net Options (Audio Tools&gt;Manual ensemble&gt;Min Spec)</span></p><p class="c1"><span class="c0">Filters more MDX noise in quieter parts than denoise standard and denoise model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer Denoise by Aufr33 | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743279539&amp;usg=AOvVaw2OsfTJ79dGbyr14Q7sRvOo">Colab</a></span><span>&nbsp;</span><span class="c0">| MVSEP | links below</span></p><p class="c1"><span class="c0">a) minimum aggressiveness model called &ldquo;27.9959&rdquo; a.k.a. &ldquo;1&rdquo; </span></p><p class="c1"><span class="c0">- good for white noise/static noise</span></p><p class="c1"><span class="c0">b) average &ldquo;27.9768&rdquo; a.k.a. &ldquo;2&rdquo; model <br>- works for footsteps, crunches, rustling, sound of cars, helicopters</span></p><p class="c1"><span class="c0">Some people like to use overlap 10 with these models.</span></p><p class="c1"><span class="c0"><br>minimum - removes fewer effects such as thunder rolls, scratching or sweeping surfaces. It&rsquo;s not as good at removing louder MDX noise when using AMD GPU instead of CPU on older system&rsquo;s DirectML.dll in UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">average a.k.a. aggressive - usually removes more noise than minimum, and also occasionally slight reverb/echo from room in vocals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The Mel-RoFormer denoise model is amazing at removing 78 RPM record crackle&rdquo;</span></p><p class="c1"><span class="c0">It&rsquo;s much better at higher frequencies than the model below (it doesn&rsquo;t damage them that bad). </span></p><p class="c1"><span class="c0">Incredibly useful as mixing tools, can pull all kinds of hum out of raw vocals, guitars, room mic&#39;s, bass, etc before mixing with zero artifacts left over. I would absolutely love to see where he takes these.<br></span></p><p class="c1"><span>If it&rsquo;s not available for paid users of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app&amp;sa=D&amp;source=editors&amp;ust=1765035743281852&amp;usg=AOvVaw1Z9DYJp7nA4QepXZvMgRVu">uvronline.app</a></span><span>,</span><span>&nbsp;use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035743281965&amp;usg=AOvVaw3GekOUwH9jpu1HhtRkdE9H">this</a></span><span>&nbsp;</span><span class="c0">link | model files:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/rIRQGJ4D%239SHaPIXt8GRoi2SL29WUILW0g9dk26I5njyFPZuPJQ8&amp;sa=D&amp;source=editors&amp;ust=1765035743282165&amp;usg=AOvVaw0ckTekKDuxjfS8WF_Gzd7M">Less aggressive</a></span><span>&nbsp;&amp; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/vM4mHTYQ%23f_uCxxS_olfTR4iAsOc-XS6sfUecfbF-ZKXrk3IjbnY&amp;sa=D&amp;source=editors&amp;ust=1765035743282325&amp;usg=AOvVaw3ULGL8XArvF2gWVk-PnAMW">More aggressive</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1uwInhwgjOMIdOMTgj_oNR_dmaq7E-b3g/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743282498&amp;usg=AOvVaw3z8bSb7JNd4oNn0NFrTZVx">yaml file</a></span><span>&nbsp;| works with UVR Roformer </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">patch</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.2y2nycmmf53">MSST</a></span></p><p class="c1"><span class="c0">For UVR - use Install model option in MDX-Net, or copy ckpt files to models\MDX-Net folder and yaml to model_data\mdx_c_configs subfofolder. Choose the new model, press yes to set parameters, enable Roformer option, pick the config file corresponding with the copied yaml name. In case of &ldquo;use_amp&rdquo; error (e.g. in MSST), add &ldquo;use_amp: true&rdquo; in the yaml under optimizer and other_fix lines.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;From most aggressive to least:</span></p><p class="c1"><span class="c0">VR Denoise</span></p><p class="c1"><span class="c0">VR Denoise Lite</span></p><p class="c1"><span class="c0">Mel-Rofo Denoise Aggr(essive)</span></p><p class="c1"><span class="c0">Mel-Rofo Denoise&rdquo; </span></p><p class="c1"><span class="c0">- Bas Curtiz<br>Rather RX11 Spectral Denoise can be more aggressive than all of them at certain settings.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Gabox </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/denoisedebleed.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743284111&amp;usg=AOvVaw0n5kE4bq8ROaJXFbejbsLo">denoise/debleed</a></span><span>&nbsp;model | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/GaboxR67/MelBandRoformers/resolve/main/melbandroformers/instrumental/inst_gabox.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743284280&amp;usg=AOvVaw2R63M2LQQw3eSNPiM0F_uh">yaml</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1U28JyleuFEW6cNxQO_CRe0B2FbNoiEet&amp;sa=D&amp;source=editors&amp;ust=1765035743284406&amp;usg=AOvVaw2qcHHwbZD0C-DqA_O2zYEa">Colab</a></span><span class="c0">&nbsp;- for noise from fullness models (tested on v5n) - it can&#39;t remove the vocal residues - try out denoising on mixture first, then use fullness model.</span></p><p class="c1"><span class="c0">&ldquo;It can preserve slightly more high frequency content in speech [than Aufr33 Mel model]&rdquo; - Musicalman. &ldquo;quite a bit slower&rdquo;. Impressive &ldquo;ability to clean up noisy vinyl or cassettes&rdquo; (padybu), might work better than Aufr33&rsquo;s model (pipedream)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Apollo Lew Uni model - tends to smooth out some even consistent noise in e.g. higher frequencies, making the spectrum more even there</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">- </span><span>UVR De-Noise by aufr33 &ldquo;minimum aggressiveness&rdquo; on </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=http://x-minus.pro/uvronline.app&amp;sa=D&amp;source=editors&amp;ust=1765035743285592&amp;usg=AOvVaw0B05dHb09nRa___vBu33cj">x-minus.pro/uvronline.app</a></span><span>&nbsp;(for premium or using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035743285715&amp;usg=AOvVaw3mrZkzvU4wGAx4srQKi5PJ">this</a></span><span>&nbsp;link)</span><span class="c6">&nbsp;</span></p><p class="c1"><span class="c0">(less aggressive than denoise model in UVR,<br>&ldquo;The (...) model is designed mainly to remove hiss, such as preamp noise. For vocals that have pops or clipping crackles or other audio irregularities, use the old denoise model&ldquo;. Grabs &ldquo;sound effects in old recordings (radio drama&rdquo;, might make &ldquo;soft voices sound weak&rdquo;).</span></p><p class="c1"><span class="c0">- UVR De-Noise by aufr33 &ldquo;medium aggressiveness&rdquo; on x-minus (same as default for free users) - it seems to be even less aggressive than UVR-DeNoise-Lite in UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer De-Crowd by Aufr33/viperx (x-minus.pro/UVR/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.4/mel_band_roformer_crowd_aufr33_viperx_sdr_8.7144.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743286891&amp;usg=AOvVaw2N4bNK7xZvuGJqnL8sVT5-">DL</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/download/v.1.0.4/model_mel_band_roformer_crowd.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743287097&amp;usg=AOvVaw3gTS7cqcyHvl1z7SdU5SU9">yaml</a></span><span class="c0">)</span></p><p class="c1"><span>(&ldquo;to remove background noise when denoise models were failing [not sure if it was rain or wind&rdquo;, can remove vinyl noises])<br>For UVR, change the model name to the one from the attached yaml, copy chkpt to models\MDX_Net_Models, and yaml to model_data subfolder, then set overlap 2 or use ZFTurbo inference </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035743287884&amp;usg=AOvVaw1gWmGpGbmy5Hnrpqeadqik">script</a></span><span class="c0">] - more effective than MDX below at times)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- yxlllc&rsquo;s harmonic noise separation VR </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/yxlllc/vocal-remover/releases/tag/hnsep_240512&amp;sa=D&amp;source=editors&amp;ust=1765035743288290&amp;usg=AOvVaw00NjDrNs3SWxX6MpaLIIRI">model</a></span><span>&nbsp;</span><span class="c0">(v. 6 or 5.x; unsure)<br></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Vocal models as denoisers</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Unwa BigBeta 5e and 6 (5e &ldquo;good when your mic/pc makes a lot of noise. All the denoise models are a bit too harsh for ASMR&rdquo; - giliaan, both &ldquo;for denoising a conversation, was better than: UVR Denoise, MDX23cInstVocHQ, HQ5, KimVocal2, VocFT, Apollo, MelRof-aufr33-Denoise, GaboxDenoise, BanditV2cinematic, ViperX-BSrof-1297&rdquo; - mixamillion) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743289255&amp;usg=AOvVaw1qU9ePWv6TqPEqbAKoqlTF">Colab</a></span><span>&nbsp;| MVSEP | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743289475&amp;usg=AOvVaw0auBk0QFZ5wOqmu2JTfaMX">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035743289605&amp;usg=AOvVaw1YHVVNAw-LGAQrx8EFzi1S">MSST-GUI</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">UVR instruction</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-big/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743289768&amp;usg=AOvVaw3X7A3akyS-Rs5ZrCuqsSxa">Model</a></span><span>&nbsp;| yaml: big_beta5e.yaml | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1YRv1j0zMs9hk3-On2z6uwfZbsQ7l1LFP/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743289929&amp;usg=AOvVaw0svT4gega5OYzD6Bh3N1eS">fixed</a></span><span class="c0">&nbsp;yaml for AttributeError in UVR</span></p><p class="c1"><span class="c20">- </span><span>BS-Roformer </span><span class="c20">viperx 1296 / </span><span>MVSEP BS-Roformer 04.24 / </span><span class="c20">Gabox BS_ResurrectioN (</span><span>denoising and derumbling working the most efficiently on vocals here too) x-minus/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743290540&amp;usg=AOvVaw0T24LeLaj1KbPVWO__pO7R">Colab</a></span><span class="c0">/UVR/MVSEP<br></span></p><p class="c1"><span class="c0">- Kim Mel-Roformer (works for denoising and debleeding vocals well)</span></p><p class="c1"><span class="c0">- Vocal model like Voc_FT or Unwa&rsquo;s ft2 bleedless (&ldquo;it can sometimes isolate the vocals without the noise. And has a better result than a normal denoiser model&rdquo; - Kashi)</span></p><p class="c1"><span class="c0">- Mel-Roformer Karaoke (by aufr33 &amp; viperx) &nbsp;(to remove noise from a dialogue, mostly rustling in the background)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035743291379&amp;usg=AOvVaw06_IVHMT0QHsiUgmN1u7N7">x-minus.pro</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://uvronline.app&amp;sa=D&amp;source=editors&amp;ust=1765035743291473&amp;usg=AOvVaw3S-GFp3seaLvoURfQRWwFk">uvronline.app</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743291540&amp;usg=AOvVaw2NBplrCHL2-zFrL75qbrYq">mvsep</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/qQA1XTrb%23LUNCfUMUwg4m4LZeicQwq_VdKSq9IQN34l0E1bb0fz4&amp;sa=D&amp;source=editors&amp;ust=1765035743291725&amp;usg=AOvVaw0nX4hI7u-AI0TA2WPAiuZF">model file</a></span><span>&nbsp;(UVR </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">instruction</a></span><span class="c0">)<br>- Mel-Roformer Duality model (excellent for pops and clicks in mixture to get clean vocals out of 45 RPM vinyl mixture - bratmix)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Other tools</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/resemble-ai/resemble-enhance&amp;sa=D&amp;source=editors&amp;ust=1765035743292281&amp;usg=AOvVaw2O3k4eiCJmUT939YgkpW8z">resemble-enhance</a></span><span class="c20">&nbsp;</span><span>(available on x-minus, but only as denoiser for voice/vocals, and on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/ResembleAI/resemble-enhance&amp;sa=D&amp;source=editors&amp;ust=1765035743292510&amp;usg=AOvVaw13S9-hcsDdQXEh1DDCutZO">HuggingFace</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.resemble.ai/enhance/&amp;sa=D&amp;source=editors&amp;ust=1765035743292617&amp;usg=AOvVaw3oRCw9plzvDRUY7s4y98A5">site</a></span><span>; works good for wind/outside noise</span><span class="c0">)</span></p><p class="c1"><span class="c20 c31">- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tape.it/denoiser&amp;sa=D&amp;source=editors&amp;ust=1765035743292859&amp;usg=AOvVaw0eABv_N-s9sN84Un0l4A5H">https://tape.it/denoiser</a></span><span class="c31">&nbsp;</span><span class="c20 c31">- </span><span class="c0">(&ldquo;great tool for removing tape hiss. Seems to be free without limitation at this point in time, though it seems to have issues with very large files [20 mins etc])&rdquo;</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://crowdunmix.org/try-rokuon/&amp;sa=D&amp;source=editors&amp;ust=1765035743293325&amp;usg=AOvVaw1TY4Qo6njeEQGWSfeFeKDz">https://crowdunmix.org/try-rokuon/</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/eloimoliner/denoising-historical-recordings&amp;sa=D&amp;source=editors&amp;ust=1765035743293572&amp;usg=AOvVaw3O4kz3-7TXGSuoOeTU28Ia">https://github.com/eloimoliner/denoising-historical-recordings</a></span><span>&nbsp;(mono, old 78rpm vinyls, fixed </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1KjlQYq5DFH0BhHSIYGaKg-syLafw6yf2&amp;sa=D&amp;source=editors&amp;ust=1765035743293729&amp;usg=AOvVaw02itqqP7SMWlvGZtmPkN_9">Colab</a></span><span class="c0">, sometimes deletes SFX, but not as much as UVR De-Noise by aufr33 in old recordings)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://audo.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743294001&amp;usg=AOvVaw2FTb6nECJT86Fs61KHXHv2">audo.ai</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/sp-uhh/avgen&amp;sa=D&amp;source=editors&amp;ust=1765035743294187&amp;usg=AOvVaw2Kz2lOqkSWQlChzFZBe6o6">https://github.com/sp-uhh/avgen</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Rikorose/DeepFilterNet&amp;sa=D&amp;source=editors&amp;ust=1765035743294378&amp;usg=AOvVaw1MPYPO84G5iLRYpQ_RSJ9A">https://github.com/Rikorose/DeepFilterNet</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/hshr/DeepFilterNet2&amp;sa=D&amp;source=editors&amp;ust=1765035743294482&amp;usg=AOvVaw3It-v587MGZiNcUI1lLVpS">Huggingface</a></span><span class="c0">&nbsp;(for speech)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://studio.gaudiolab.io&amp;sa=D&amp;source=editors&amp;ust=1765035743294651&amp;usg=AOvVaw0TKtvVuKT8d7qxKQaAG18n">https://studio.gaudiolab.io</a></span><span class="c0">&nbsp;(new Noise Reduction feature)</span></p><p class="c1"><span>- possibly </span><span class="c4"><a class="c3" href="#h.4svuy3bzvi1t">USS-Bytedance</a></span><span>&nbsp;</span><span class="c0">(when similar sample provided)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-Enhancing.md%23denoisers-&amp;sa=D&amp;source=editors&amp;ust=1765035743295134&amp;usg=AOvVaw0Im8xHg7st8EQVKMjpL4Dm">Various AI tools</a></span><span>&nbsp;- list by FORARTfe/HyMPS | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/FORARTfe/HyMPS/blob/main/Audio/Treatments.md%23noise-reducing-&amp;sa=D&amp;source=editors&amp;ust=1765035743295309&amp;usg=AOvVaw0YKRJ64YCbmWJeT7gsZ4nn">#2</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/17fjNvJzj8ZGSer7c7OFe_CNfUKbAxEh_OBv94ZdRG5c/edit?pli%3D1%23heading%3Dh.70231k4ydkfw&amp;sa=D&amp;source=editors&amp;ust=1765035743295527&amp;usg=AOvVaw08utd3akHMjIYLbFOKAQai">Free apps</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Older models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/UVR-DeNoise.pth&amp;sa=D&amp;source=editors&amp;ust=1765035743295970&amp;usg=AOvVaw1Te0nZwpOD_fjJE0LVo0GL">UVR-DeNoise</a></span><span>&nbsp;(trained by FoxJoy) - DeNoise-lite above is less aggressive</span></p><p class="c1"><span class="c0">You can use negative values in UVR for that model. -20/-25 - for cleaning vocals</span></p><p class="c1"><span class="c0">-10/-15 - when some vocals are gone - Gabox<br>&ldquo;It&#39;s decent, but it needs a little work compared to&quot; RX 10 spectral denoise.</span></p><p class="c1"><span class="c0">- voc_ft - works as a good denoiser for old vocal recordings</span></p><p class="c1"><span class="c0">- GSEP 4-6 stem (&quot;noise reduction is too damn good. It&#39;s on by default, but it&#39;s the best I&#39;ve heard every other noise reduction algorithm makes the overall sound mushier&quot;, it&rsquo;s also good when GSEP gives too noisy instrumentals with 2 stem option, it can even cancel some louder vocal residues completely)</span></p><p class="c1"><span class="c0">- UVR-MDX-NET Crowd HQ 1 (UVR/x-minus) </span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/B0kOY8I&amp;sa=D&amp;source=editors&amp;ust=1765035743297365&amp;usg=AOvVaw2nSe6ms4wrrfyd3EmuVkRs">This</a></span><span>&nbsp;VR ensemble in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl&amp;sa=D&amp;source=editors&amp;ust=1765035743297512&amp;usg=AOvVaw0-37R6mzFqIzG-gnFFgAHu">Colab</a></span><span>&nbsp;(for creaking sounds, process your separation output more than once till you get there)</span></p><h5 class="c5" id="h.3y2b7zvxvz2e"><span class="c20 c50">Plugins</span><span class="c50">&nbsp;</span><span class="c6">(different types of noise)</span></h5><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Free</span></p><p class="c1"><span>- Guide for classic denoiser tools in DAW, e.g. for debleeding (Bas Curtiz): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1XIbyHwzTrbs6LbShEO-MeC36Z2scu-7qjLb-NiVt09I/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743298409&amp;usg=AOvVaw0cT0hzeiTpJMXw7lZNxc2_">https://docs.google.com/spreadsheets/d/1XIbyHwzTrbs6LbShEO-MeC36Z2scu-7qjLb-NiVt09I/edit?usp=sharing</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://bertomaudio.com/denoiser-classic.html&amp;sa=D&amp;source=editors&amp;ust=1765035743298621&amp;usg=AOvVaw2LlYAOfe5I_SXsQLD5kNVO">Bertom Denoiser Classic</a></span><span>&nbsp;(or paid </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://bertomaudio.com/denoiser-pro.html&amp;sa=D&amp;source=editors&amp;ust=1765035743298729&amp;usg=AOvVaw15CybMPBrNeHOJErqpCCM7">Pro</a></span><span class="c0">)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://archive.org/details/era-bundle-v-6.2.00-voice-changer-v-1.3.10&amp;sa=D&amp;source=editors&amp;ust=1765035743298929&amp;usg=AOvVaw3LNRUGFrICmgmkvdxtcOB5">Accusonus ERA 6</a></span><span class="c0">&nbsp;(released for free after FB acquisition) - bundle with also de-esser, voice auto-EQ, voice leveller (better than soothe2 for de-essing for some people), deplosive, declipper and more</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Paid</span></p><p class="c1"><span class="c0">- Izotope RX 10 Spectral De-noise (&ldquo;I think RX 10&#39;s Spectral De-noise is better at removing the noise MDX [model] makes&rdquo;)</span></p><p class="c1"><span class="c0">Actually, the new UVR De-noise model is really good when you combine it with RX 10&#39;s Spectral De Noise&rdquo;, better than Lab 4 and current models, also more tweakable, but takes more time to set (now also RX 11 available - should be even a step forward)</span></p><p class="c1"><span class="c0">- Acon Restoration Suite 2&rsquo;s DeNoise &ldquo;is decent if you can build a good noise profile with the Learn option, I like to have a few in series set to do -3dB of NR.&rdquo; - theophilus3711</span></p><p class="c1"><span class="c0">- SOUND FORGE Audio Cleaning Lab 4 (formerly Magix Audio &amp; Music Lab Premium 22</span></p><p class="c1"><span class="c0">[2016/2017] or MAGIX Video Sound Cleaning Lab - basically the same stock plugin across all of these versions) </span></p><p class="c1"><span>- Unchirp VST (for musical noise, artefacts of lossy compression)</span></p><p class="c1"><span class="c0">- Izotope Dialogue Dereverb (it is also denoiser)</span></p><p class="c1"><span>- Izotope Dialogue Isolate in RX11</span></p><p class="c1"><span class="c0">- Waves Clarity Vx / Pro (designed mainly for vocals)</span></p><p class="c1"><span class="c0">- Brusfri by Klevgrand</span></p><p class="c1"><span class="c0">- prime:vocal (multitool with also dereverb and other vocal enhancers)</span></p><p class="c1"><span class="c0">- DxRevive Pro (mainly for dialogue: denoiser, declipper, dereverb, enhancer, codecs artefacts removal)</span></p><p class="c1"><span class="c0">- Acon Dialogue:Extract 2 (dereverb, denoise)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Visit also </span><span class="c4"><a class="c3" href="#h.tv0x7idkh1ua">Debleeding/cleaning</a></span><span class="c0">&nbsp;e.g. inverts</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Bird sounds</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/google-research/sound-separation/tree/master/models/bird_mixit&amp;sa=D&amp;source=editors&amp;ust=1765035743302347&amp;usg=AOvVaw2seOjhk58OLauLeTgVNhvQ">Google&#39;s bird_mixit</a></span><span>&nbsp;(code &amp; checkpoint for their bird sound separation algo. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://blog.research.google/2022/01/separating-birdsong-in-wild-for.html?m%3D1&amp;sa=D&amp;source=editors&amp;ust=1765035743302624&amp;usg=AOvVaw0uHaLnIUkTLaf_s6O8GZ-y">More</a></span><span class="c0">)</span></p><p class="c1"><span class="c4"><a class="c3" href="#h.kcswx79hi856">De-reverb</a></span><span class="c0">&nbsp;models, e.g.:</span></p><p class="c1"><span class="c0">- UVR-DeEcho-DeReverb (doesn&#39;t work for all songs)</span></p><p class="c1"><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">Vocal</a></span><span class="c0">&nbsp;models, e.g.:</span></p><p class="c1"><span class="c0">- MVSEP BS-Roformer 2025.07 (if you already have birds in a vocal stem, as most vocal models do iirc, that may do the trick)</span></p><p class="c1"><span class="c4"><a class="c3" href="#h.owqo9q2d774z">SFX</a></span><span class="c0">&nbsp;models</span></p><p class="c1"><span class="c0">Zero shot solutions:</span></p><p class="c1"><span class="c0">(you can try them to get e.g. birds SFX and then use as a source to debleed or maybe try to invert phase and cancel it out)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.tvbntqdvkn9n">AudioSep</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.4svuy3bzvi1t">USS-ByteDance</a></span><span class="c0">&nbsp;(for providing any, at least, proper sample)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.g37f4a6hnxm0">Zero Shot</a></span><span class="c0">&nbsp;(currently worse for SFX vs Bytedance)</span></p><p class="c1"><span class="c0">- custom stem separation on Dango (paid, 10 seconds for free</span></p><p class="c1"><span class="c0">Technically, if bird noises are in vocals, then equally: </span></p><p class="c1"><span class="c0">- RTX Voice, </span></p><p class="c1"><span class="c0">- AMD Noise Suppression or even </span></p><p class="c1"><span class="c0">- Krisp and </span></p><p class="c1"><span class="c0">- Adobe Podcast </span></p><p class="c1"><span class="c0">might get rid of them, but at least the last changes the tone of voice, and the previous may work good only with voice instead of vocals.</span></p><p class="c1"><span class="c0">Spectral editing</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.hk34hc4d1ah7"><span class="c22">De-clippping/de-limitter/de-compression of dynamics </span><span class="c0">(for loud or brickwalled songs with overly used compressor/clipper/limiter/distortion - transients/peaks recovery)<br></span></h6><p class="c1"><span class="c0">Free declipper plugins:</span></p><p class="c1"><span class="c0">- ReLife 1.42 by Terry West (works best for stereo tracks divided into mono, newer versions are paid)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://archive.org/details/era-bundle-v-6.2.00-voice-changer-v-1.3.10&amp;sa=D&amp;source=editors&amp;ust=1765035743306078&amp;usg=AOvVaw0Aemj5DDFS9x7Xnnb-IAeE">ERA 6</a></span><span class="c0">&nbsp;declipper (released in bundle for free after they were bought by Meta)</span></p><p class="c1"><span class="c0">- Airwindows AQuickVoiceClip - mainly for streamers yelling into the microphone &ldquo;It&rsquo;s not a &lsquo;un-clipper&rsquo; but it tames the distortion a bit.&rdquo;<br></span></p><p class="c1"><span class="c0">AI tools (not plugins):</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.713q0eyar6o3">RemFX</a></span><span class="c0">&nbsp;(contains model to get rid of distortion and compression; &ldquo;mostly for singular sounds, it won&#39;t work for whole mixes like songs&rdquo;)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://crowdunmix.org/rukai/&amp;sa=D&amp;source=editors&amp;ust=1765035743306990&amp;usg=AOvVaw1vuB9z16wtSUCn9K_sPjxI">Rukai</a></span><span class="c0">&nbsp;(for speech and instrumentals)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://crowdunmix.org/try-amis/&amp;sa=D&amp;source=editors&amp;ust=1765035743307163&amp;usg=AOvVaw1BJnxVOo08FZ2gYiH-oeZ0">Amis</a></span><span class="c0">&nbsp;(mainly for speech)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/stet-stet/DDD&amp;sa=D&amp;source=editors&amp;ust=1765035743307395&amp;usg=AOvVaw1pMHv8WDy4na3qowdSFQrt">stet-stet&rsquo;s DDD</a></span><span class="c0">&nbsp;(speech, req. decent CML knowledge to setup)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/jeonchangbin49/De-limiter&amp;sa=D&amp;source=editors&amp;ust=1765035743307662&amp;usg=AOvVaw0TZThqo6TBkE8KoZdbwy6v">jeonchangbin49&rsquo;s De-limiter</a></span><span class="c0">&nbsp;(&ldquo;if you have any squished tracks that apollo doesn&#39;t handle well, try passing it through that AI de-limiter first&rdquo; - macularguide</span></p><p class="c1"><span class="c0">&ldquo;parallel mix - &ldquo;define[s] how the normalized input and the de-limited inference will blend together. Where 0 is 100% normalized and 1 means 100% de-limited&rdquo; - santilli_)</span></p><p class="c1"><span><br>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://neutone.ai/fx&amp;sa=D&amp;source=editors&amp;ust=1765035743308401&amp;usg=AOvVaw3phwImMQ7Jo0ktW8OuJzxj">Neutone FX</a></span><span>&gt;Clipper, actually an AI plugin (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://qosmo.notion.site/Getting-started-607e99436b1243b5a6d273a76ee4811a&amp;sa=D&amp;source=editors&amp;ust=1765035743308698&amp;usg=AOvVaw0qvpRLgQdeSQaBOAJuRuim">instruction</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>More GH repos - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-Enhancing.md%23declippers-&amp;sa=D&amp;source=editors&amp;ust=1765035743309045&amp;usg=AOvVaw2sm6B3VJAJffJE-DdA5NYV">HyMPS</a></span><span>&nbsp;list | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/FORARTfe/HyMPS/blob/main/Audio/Treatments.md%23declipping-&amp;sa=D&amp;source=editors&amp;ust=1765035743309230&amp;usg=AOvVaw2vREH1-nl9_I30bQ-HcaMU">#2</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Paid: Ozone&rsquo;s 12 Delimiter, ProAudioDeclipper, Declipper in Thimeo Stereo Tool (a.k.a. Perfect Declipper - standalone; both free for Winamp), iZotope RX De-clip (in RX Editor or as plugin), DxRevive Pro (mainly for dialogue, also denoiser, dereverb, enhancer, codecs artefacts removal), Declipper in Magix/Sound Forge Cleaning Lab, Adobe Audition&rsquo;s Declipper, sometimes even Fabfilter Pro-MB multiband compressor might be useful<br><br></span><span class="c22">Clippers</span><span class="c0">&nbsp;(the opposite, but useful in the whole mastering chain, sometimes in a tandem with the above in the whole chain):<br></span></p><p class="c1"><span class="c0">Free</span></p><p class="c1"><span class="c0">- KClip Zero</span></p><p class="c1"><span class="c0">- FreeClip (sometimes you can use both in the same session for interesting results)</span></p><p class="c1"><span class="c0">- GClip</span></p><p class="c1"><span class="c0">- Limiter6 by vladg (Clipper module)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Initial Clipper<br>- Airwindows Hypersoft &nbsp;- &ldquo;a more extreme form of soft-clipper&rdquo;</span></p><p class="c1"><span class="c0">- Airwindows OneCornerClip - compared to OG ADClip, it retains the character of sound</span></p><p class="c1"><span class="c0">- Airwindows ADClip8 - &ldquo;loudenator/biggenator&rdquo;</span></p><p class="c1"><span class="c0">- Airwindows ClipOnly - &ldquo;2-buss safety clipper at -0.2dB with powerful anti-glare processing.&rdquo;</span></p><p class="c1"><span class="c0">- Hornet Magnus Lite - clipper and limiter modules<br><br>Paid: Orange Clip 3 (multiband mode), Gold Clip (widely praised lately), Gold Clip Track, Soundtheory Kraftur, KClip 3, SIR Standard Clip (popular, though KClip 3 may give better results), Izotope Trash 2, DMG Tracklimit, TR5 Classic Clipper (great for a kick), KNOCK (hard &amp; soft clipper), Boz Little Clipper 2, Flatline (clipper), Newfangled/Eventide Saturate (spectral clipper), JST Clip, Brainworx Clipper, Elysia Alpha Mastering Compressor (soft clip module), soft clipper in Cubase</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">De-expliciter</span><span class="c0">&nbsp;(removes explicit lyrics from songs)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/tejasramdas/CleanBeats&amp;sa=D&amp;source=editors&amp;ust=1765035743313399&amp;usg=AOvVaw0fQBw6coTI7j1MeTPIfFqi">https://github.com/tejasramdas/CleanBeats</a></span><span class="c0">&nbsp;(more recent fork)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c18 c15">De-breath</span></p><p class="c1"><span>- Sucial de-breath VR v1/2 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/De-Breathe-Models/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743313781&amp;usg=AOvVaw0dwRIjlP8woLr1rwRspL0k">models</a></span></p><p class="c1"><span>- Accusonus ERA Bundle (free/gave away after FB acquisition) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://archive.org/details/accusonus-era-bundle-v-6.2.00&amp;sa=D&amp;source=editors&amp;ust=1765035743314039&amp;usg=AOvVaw3mAe0mffZbQ_qbjSXaV1KD">download</a></span></p><p class="c1"><span class="c0">- Izotope RX11 breath control (paid; VST/Audio Editor)<br>(&ldquo;The &ldquo;remove breaths&rdquo; preset they have on it Usually works about 95% of the time for me&rdquo; -5b)</span></p><p class="c1"><span class="c0">- DNR v3 (Sometimes (...) (without vocal help), the grunts and breathing will be in the SFX, and the dialogue in the speech, while both will be in the music) - fal_2067</span></p><p class="c1"><span class="c6">_____</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">Manipulate various </span><span class="c4 c20"><a class="c3" href="#h.6q2m0obwin9u">MDX settings</a></span><span class="c20">&nbsp;and </span><span class="c4 c20"><a class="c3" href="#h.atxff7m4vp8n">VR Settings</a></span><span class="c6">&nbsp;to get better results </span></p><p class="c1"><span class="c6">____</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">Final resort - specific </span><span class="c4 c20"><a class="c3" href="#h.929g1wjjaxz7">tips to enhance separation </a></span><span class="c6">if you still fail in certain fragments or tracks </span></p><p class="c1"><span class="c6">____</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Get VIP models in UVR5 GUI (optional donation) - it&#39;s if you can&#39;t find some of the listed above or in top ensembles chart:</span></p><p class="c1"><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://www.buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035743315773&amp;usg=AOvVaw1SXQiypLYDiNRMt7sEtuaA">https://www.buymeacoffee.com/uvr5/vip-model-download-instructions</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">(dead links)</span></p><p class="c1"><span class="c6">List of VR models in UVR5 when VIP code is entered (w/o two denoise by FoxyJoy yet):</span></p><p class="c1"><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1104424304927592568/VR-Arch.png&amp;sa=D&amp;source=editors&amp;ust=1765035743316462&amp;usg=AOvVaw0yRIxqBK-9CKmMNCqNFCd3">https://cdn.discordapp.com/attachments/708595418400817162/1104424304927592568/VR-Arch.png</a></span></p><p class="c1"><span class="c6">List of MDX models when VIP Code is entered (w/o HQ_3 and voc_ft yet and MDX23C):</span></p><p class="c1"><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1103830880839008296/AO5jKyQ.png&amp;sa=D&amp;source=editors&amp;ust=1765035743317077&amp;usg=AOvVaw0UukLIQ_EGX_RHR1hebOUY">https://cdn.discordapp.com/attachments/708595418400817162/1103830880839008296/AO5jKyQ.png</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">More updated list can be found in that UI:<br></span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035743317445&amp;usg=AOvVaw2sUqEqalJKvsAT59ZJ_1-X">https://huggingface.co/spaces/TheStinger/UVR5_UI</a></span></p><p class="c1"><span class="c6">(some models might be not from Download Center/VIP code)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Models repository backup of all UVR5 models in separate links</span></p><p class="c1"><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/model_repo/releases/tag/all_public_uvr_models&amp;sa=D&amp;source=editors&amp;ust=1765035743319482&amp;usg=AOvVaw03jpFOLiHTED_Pp--LK2Rs">https://github.com/TRvlvr/model_repo/releases/tag/all_public_uvr_models</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Some models might be not available in the repository above, as e.g. 427 model which is available only after entering VIP code.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">(just in case, here&#39;s the link for 427:</span></p><p class="c1"><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/16sEox9Z_rGTngFUtJceQ63O5S9hhjjDk?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035743320239&amp;usg=AOvVaw2qOMPUlbRINqrYSPktPzSE">https://drive.google.com/drive/folders/16sEox9Z_rGTngFUtJceQ63O5S9hhjjDk?usp=drive_link</a></span></p><p class="c1"><span class="c6">Copy it to UVR folder\models~MDX folder and rename the model name to:<br>UVR-MDX-NET_Main_427)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">_____________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &ldquo;Hello, we are now getting very good results in turning music that includes human voice into only instrumental. Sometimes there are vocal leaks that we can call just crumbs or whispers, but this is not that important. But now we have another important problem. People who do not want to listen to vocals, that is, who only want to listen to the music that remains when the vocals are deleted, encounter a problem. Sometimes there are big gaps in the songs. Because not every song is arranged in a way that continuous instrumental music is heard, and when the vocal part is deleted, a perception of silence or emptiness can occur. It is as if the music does not have continuity, and everything is cut off in some parts of the song. The reason for this is that when the vocal is deleted, the vocal melody is also destroyed. Although it seems like a good idea at first, when we listen to music that is only instrumental with the vocals deleted, that song loses a lot of its identity. As a result, I want to learn how we can preserve the vocal melody after deleting the vocal. What I mean is, can we divide the song into instrumental and vocal and then turn the melody of the vocal part into an instrument such as piano, bass guitar, flute, etc. Then, I want to combine this vocal melody with the instrumental result.&rdquo; - sweetlittlebrowncat</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: You could try out some older, less aggressive models than Roformers. Even GSEP. </span></p><p class="c1"><span class="c0">They can sometimes leave some melody from vocals (in fact, some quiet harmonies), so the song is not so &quot;dead&quot; after separation. Actually, you could try to separate vocals into separate stems to look for something useful to mix with the instrumental quietly.</span></p><p class="c1"><span class="c0">Check Vocal models, then separate further with BV/Karaoke models or alternatively check GSEP, MDX-Net and maybe even VR models. Open document outline of this document and there you have all the interesting sections.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, you can use: </span></p><p class="c1"><span>&quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://audimee.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743324982&amp;usg=AOvVaw1KSOvsXkjHjBGO5gbtkgWE">https://audimee.com/</a></span></p><p class="c1"><span class="c0">split instrumental from vocal</span></p><p class="c1"><span class="c0">use vocal as input</span></p><p class="c1"><span class="c0">convert it into piano, bass, flute, whatever they offer</span></p><p class="c1"><span class="c0">merge</span></p><p class="c1"><span class="c0">profit&quot; Bas Curtiz</span></p><p class="c1"><span class="c0">_____________</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.k34y1vaaneb1"><span class="c0">Mixing/mastering</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you already did your best in separating your track, tried out </span><span class="c4"><a class="c3" href="#h.nk4nvhlv1pnt">ensembles</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="#h.oxd1weuo5i4j">manual weighting</a></span><span>, also read </span><span class="c4"><a class="c3" href="#h.929g1wjjaxz7">tips to enhance separation</a></span><span class="c0">, but if it lacks original track clarity, you can use: </span></p><p class="c1"><span>- Demudder added in the beta </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">Roformer patch</a></span><span class="c0">&nbsp;#14 in UVR (if it won&rsquo;t increase vocal residues too much; won&rsquo;t work with even small chuk_size in AMD/Intel 4GB VRAM GPUs with Roformers)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.ki1wmwa90cgp">AI Mastering services</a></span><span class="c0">&nbsp;(mainly for instrumentals)</span></p><p class="c1"><span>- For improving vocals&#39; clarity, you could even &ldquo;train a RVC model out of clean [artists] audio clips and then inference this audio with the model you made. It takes some time, but the results are worth it&rdquo; John UVR (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/900904142669754399/1299077849487118346&amp;sa=D&amp;source=editors&amp;ust=1765035743327412&amp;usg=AOvVaw3N1QCE9O7fih4VvleHryBV">examples</a></span><span class="c0">). Workflow explained later below.</span></p><p class="c1"><span>- Aufr33&rsquo;s expander template for Reaper 7.05 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1lFGJiGIGcvKuz1gQtlppA0sMPhCC1P9T/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743327740&amp;usg=AOvVaw0AgGZxeXCJWbCIiwCG2WK5">DL</a></span><span class="c0">) fixing ducking in instrumentals (explained later below)</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27 c7" id="h.86cdyl2tgclm"><span class="c0"></span></h6><p class="c1"><span class="c20">Mixing track from scratch using various AIs/models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Now if you&#39;re not afraid of mixing, and e.g. if you have clear instrumental already or whole track to remaster, I used for such a task:</span></p><p class="c1"><span class="c0">- v. quiet mixture (original file with mixed vocals)</span></p><p class="c1"><span>- stems from demucs_ft or BS-Roformer SW (both </span><span class="c4"><a class="c3" href="#h.jmb1yj7x3kj7">MDX23</a></span><span>&nbsp;Colab or Ensemble of various models on MVSEP can be even better than Demucs, and vs SW esp. for bass - check out </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">4 stems</a></span><span class="c0">&nbsp;section) mixed with also:</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.2u19k7ty9b00">drumsep</a></span><span class="c0">&nbsp;MDX23C free model result (but you can also test out stems from the old drumsep and LarsNet [although they have worse SDR], or newer MVSEP drumsep models)</span></p><p class="c1"><span class="c0">- GSEP result for piano or guitars (MVSEP models can be handy too, now the SW model for those stems are much better, and previously the only downloadable decent guitar model released becruily, and demucs_6s is mediocre, now we have SW)</span></p><p class="c1"><span>- for bass both GSEP and Demucs ft/MDX23 aligned and mixed together (or simply from MVSEP ensemble or MDX23 Colab) or see </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">bass models</a></span><span class="c0">&nbsp;for more recent list</span></p><p class="c1"><span class="c0">- I think &quot;other&quot; stem could have been paired that way too (but drums remained only from e.g. Demucs_ft - they were cleaner than GSEP and good enough)</span></p><p class="c1"><span class="c0">- Actually in one of those guitars weren&#39;t recognized in guitar stem, but were in other stem, so I mixed that all together (it wasn&#39;t busy mix)</span></p><p class="c1"><span>- If it&#39;s not instrumental, probably mixing more than one vocal model might do the job, check various </span><span class="c4"><a class="c3" href="#h.i7k483hodhhu">vocal ensembles</a></span><span class="c0">&nbsp;(but it&rsquo;s essentially what MDX23 and ensembles on MVSEP do, but the latter with private models, it&rsquo;s not exactly the same - you can add different effects for every of such tracks, having fuller sound and change their volume manually).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The all above gave me an opportunity for a very clean mix and instruments using various plugins while setting correct volume proportions vs mastering just instrumental separation result or plain 3 stems from Demucs.</span></p><p class="c1"><span class="c0">For example, demucs_ft or other single or incorporated drums model provides much higher quality of drums than the old Demus drumsep during mixing, so in such case you won&rsquo;t use its stems on its own, but you will use drumsep more to overdub the specific parts of instruments more (e.g. snares - that&rsquo;s the most useful part of using drumsep as normally it&rsquo;s easy to bury snare in a busy mix when hi hats kick in overly in a heavily processed instrumental stem or drums stem - not you won&rsquo;t have to push drums stems from demucs_ft or MDX23 so drastically).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Sam Hocking&rsquo;s method for enhancing separated instrumentals from a mixture (song containing instrumental and vocals):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I think looking at spectrally significant things like snares can work. We can already do it manually by isolating the transient audio/snare pattern as MIDI and then triggering a sample from the track itself to reinforce, but it&#39;s time-consuming and requires a lot of sound engineering to make it sound invisible.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can probably use Cableguys Snapback plugin for that, or maybe UVI Drum replacer.</span></p><p class="c1"><span>Sam&rsquo;s method will work the best in songs with samples instead of live recordings (if the same sounds repeat across the whole beat). </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.ww5380bbnab3&amp;sa=D&amp;source=editors&amp;ust=1765035743334547&amp;usg=AOvVaw1UOvbGR6fqEJ59hEAd9nlB">More</a></span><span class="c0">&nbsp;of those plugins.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">PS. In the late 2025 we received an info about Apple Music rejecting Atmos mixes of some legacy music made with separation models (ensembles, and then probably some for 4-6 stems), even though the mixes sounded good, and were accepted by labels and artists. Also, we know that these separation methods worked fine in the past, at least for some other engineers. We suspect that they might use automated tools catching specific artefacts usually seen in separation models on spectrograms of extracted channels from the whole Atmos mix.</span></p><p class="c1"><span>&ldquo;I don&#39;t think there&#39;s a need of really advanced and expensive method to detect source separated stems, most of the time, just looking at the background noise is enough to tell, original stem vs separated one [</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/znLIBph&amp;sa=D&amp;source=editors&amp;ust=1765035743336321&amp;usg=AOvVaw3WXuKMIEZ88xp-FCKm3sNe">click</a></span><span class="c0">]</span></p><p class="c1"><span class="c0">+ kind of &quot;aliasing&quot; artifacts and/or dither residues popping here and there...</span></p><p class="c1"><span class="c0">There are lots of patterns than can make separated audio stems identifiable, I don&#39;t think it&#39;s hard to develop a model to spot them with quite good accuracy (even if not really audible to human ears)&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To sum up:</span></p><h6 class="c1 c27 c7" id="h.7e85o4dzwoce"><span class="c0"></span></h6><p class="c2"><span>Tips to </span><span class="c4"><a class="c3" href="#h.929g1wjjaxz7">enhance separation</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="#h.bviye361m0v">Demudder</a></span><span>&nbsp;in UVR/x-minus<br>(increases vocal residues)</span></p><p class="c2 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.kmvf6iw5hfvm"><span>AI a</span><span>udio upscalers </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit%23heading%3Dh.i7mm2bj53u07&amp;sa=D&amp;source=editors&amp;ust=1765035743337821&amp;usg=AOvVaw0XfVArrXTSVirgXMAIVyEB">list</a></span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span>AI mastering </span><span class="c4"><a class="c3" href="#h.ki1wmwa90cgp">services</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="#h.p4mh61gmvsx2">Blending with RVC model</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/&amp;sa=D&amp;source=editors&amp;ust=1765035743338456&amp;usg=AOvVaw21PP9wH7WD3PnUqRK159Td">Make your own remaster</a></span><span>:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">More clarity/better quality/general audio restoration of separated stem(s)</span></p><p class="c1"><span>H</span><span class="c0">ave complete freedom over the result, using (among others) spectral restoration plugins to demudd the results of separations freely with plugins. Then you can use the result further with e.g. AI upscaler or in reverse.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>E.g. from plugins, you can start by using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.thimeo.com/stereo-tool/download/&amp;sa=D&amp;source=editors&amp;ust=1765035743339367&amp;usg=AOvVaw20NEwV2ngu9xSGkXyUEuci">Thimeo Stereo Tool</a></span><span>&nbsp;which has a fantastic re/mastering chain feasible for spectral restoration useful for instrumentals sounding too filtered from vocals and lacking clarity. Also use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.zynaptiq.com/unchirp/&amp;sa=D&amp;source=editors&amp;ust=1765035743339734&amp;usg=AOvVaw0jyRlpwArQQR7kXZ-By3t8">Unchirp</a></span><span class="c0">&nbsp;which states great complement to Thimeo Stereo Tool, although focuses more on already existing spectrum.</span></p><p class="c1"><span>You can also play with free Airwindows </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.airwindows.com/energy-vst/&amp;sa=D&amp;source=editors&amp;ust=1765035743340156&amp;usg=AOvVaw3J2OZNBG_q76YBwtji2DHp">Energy</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.airwindows.com/energy2/&amp;sa=D&amp;source=editors&amp;ust=1765035743340290&amp;usg=AOvVaw3CeKXt9gkzgIDh1Eo2FdSG">Energy2</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mediafire.com/folder/kua5r9x27mwrk/Plugins_Backup&amp;sa=D&amp;source=editors&amp;ust=1765035743340425&amp;usg=AOvVaw3OjmoqKU_Lal1YbrohT0yX">Air</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.airwindows.com/air2/&amp;sa=D&amp;source=editors&amp;ust=1765035743340530&amp;usg=AOvVaw31A_aLG5zTAYD9KLX1BQXR">Air2</a></span><span>&nbsp;(</span><span class="c34">or Air3,</span><span>&nbsp;</span><span class="c34">MIA Thin)</span><span class="c0">&nbsp;plugins for restoration, and furthermore some compressors or other plugins and effects mentioned in the link above.</span></p><p class="c1"><span>If you&#39;re not afraid of learning a new DAW, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.magix.com/us/music-editing/sound-forge/sound-forge-audio-cleaning-lab/&amp;sa=D&amp;source=editors&amp;ust=1765035743341169&amp;usg=AOvVaw1eNTSPbBgjDZk0yEeELdUd">Sound Forge Cleaning Lab 4</a></span><span>&nbsp;has great and easy built-in restoration plugins too (Brilliance, Sound Clone&gt;Brighten Internet Sources) with complete mastering chain to push even further what you already got with Unchirp and Stereo Tool</span><span class="c0">. </span></p><p class="c1"><span class="c0">Izotope RX Editor and its Spectral Recovery may turn out to be just not enough, but the rest of RX plugins also available as VST can become handy, although Cleaning Lab has lots of substitutes for filtering various kinds of noise. Working comfortably in real-time with all the plugins opened simultaneously while combined is more comfortable than RX Editor workflow. But you can use some plugins from RX Editor as separate VSTs in other DAWs including Lab 4. Ozone Advanced might turn out useful too.</span></p><p class="c1"><span class="c0">Actually, once you finish using the plugins above, now you can try out some of the mastering services and not in the opposite way (although you might want to meet some basic requirements of AI mastering services to get the best results first, e.g. in terms of volume).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &nbsp;AI vocal remover did not &quot;normalize&quot; (I don&#39;t think it&#39;s the right word) the track on the moment where the vocal was removed, so it&#39;s noticeable, especially on instrument-heavy moments. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I make things better by created backup echo track by combining stereo tracks with inverted ones and adding this to the main track with -5db, but it&#39;s still not good enough. Are there any technics that separate track with not noticeable effects or maybe there is some good restoration algorithm that I can use</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: If vocals are cancelled by AI, such a moment stands out from the instrumental parts of the song.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes you can rearrange your track in a way that it will use instrumental parts of the song when there are no vocals, instead of leaving AI separated fragments. Sometimes it&#39;s not possible, because it will lack some fragments (then you can use only filtered moments at times), and even then, you will need to take care about coherence of the final result in the matter of sound as you said.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">At times, even fade outs at the ends of tracks can have decent amounts of instrumentals which you can normalize and then use in rearrangement of the track. E.g. you normalize every snare or kick and everything later in fade out, and then till the end, so it will sound completely clean. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Generally it&#39;s all time-consuming, not always possible, and then you really have to be creative using normal mastering chain to fit filtered fragments to regular unfiltered fragments of the track. </span></p><p class="c1"><span class="c0">You can also try out layering, e.g. specific snare found in a good quality in the track. May work easier for tracks made with quantization, so when the pattern of drums is consistent throughout the track. Also, you can use 4 stem Demucs ft or MDX23 and overlap drums from a fragment where you don&rsquo;t hear vocals yet, so drums are still crispy there. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Ducking effect eliminator</span></p><p class="c1"><span class="c0">You can also check Aufr33 Reaper 7.05 project aimed at alleviating this issue:</span></p><p class="c1"><span class="c0">&ldquo;the music volume is reduced where there are vocals&rdquo;. Instruction:<br>&ldquo;Just place two stems: vocals and music. Adjust the Expander if necessary.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;It&#39;s just an expander side-chained to vocals. You can replicate this in any other DAW.&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/773763762887852072/1382544710857527358&amp;sa=D&amp;source=editors&amp;ust=1765035743347490&amp;usg=AOvVaw31Dzr81d-Y2nXF4og0ji4w">Src</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1lFGJiGIGcvKuz1gQtlppA0sMPhCC1P9T/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743347683&amp;usg=AOvVaw3Aym7hpc7uuvhrGS656Bz4">mirror</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Nice </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1123408156664533002/image.png?width%3D1206%26height%3D687&amp;sa=D&amp;source=editors&amp;ust=1765035743347961&amp;usg=AOvVaw3P7tA7X7-oidItBSskR8A3">chart</a></span><span class="c0">&nbsp;(&gt;moved to &ldquo;Advanced chain processing chart&rdquo; at the bottom of Karaoke section (use search)</span></p><p class="c1"><span>describing process </span><span class="c0">for creating AI cover (replace kim vocal with voc ft there, or MDX23 vocals/UVR top ensemble/Roformers). </span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.p4mh61gmvsx2"><span class="c22">Blending with RVC model</span><span class="c6">&nbsp;<br>(by Gabox &amp; dubpluris a.k.a. Mark | Avalaunch - text)</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;</span><span class="c20">My use Case</span><span class="c0">: </span></p><p class="c1"><span class="c0">Restoring older, lower-quality vocal recordings (e.g., camcorder recordings from the 90s) using RVC models trained on clean studio vocals from the same artist.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Practical Workflow for Using RVC in Vocal Restoration</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The idea is not to replace old performances entirely, but to enhance them. A few key points came out of the discussion:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Blending, not replacing: Using only the RVC output will usually sound artificial. The better approach is to run the old vocal stems through the trained RVC model and then blend the AI-generated stem with the original. This preserves natural performance qualities while adding clarity.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Input quality matters: Even &ldquo;decent but rough&rdquo; camcorder audio can work. Extremely degraded sources, however, will still produce artifacts (&ldquo;bad input = bad output&rdquo;).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Complementary tools:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>FlashSR &ndash; an audio super-resolution method that restores high frequencies and improves fidelity before running RVC. (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/en/demo?algorithm_id%3D60&amp;sa=D&amp;source=editors&amp;ust=1765035743351449&amp;usg=AOvVaw3f6UP7FjKbasLt6R45WjSZ">https://mvsep.com/en/demo?algorithm_id=60</a></span><span>)<br>[AudioSR might potentially giver better results, but it&rsquo;s much slower;<br>&ldquo;Imo much better candidates are: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/yxlu-0102/AP-BWE&amp;sa=D&amp;source=editors&amp;ust=1765035743351763&amp;usg=AOvVaw3H4-y2h3kXJjjSNEYEvR5A">AP-BWE</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1g4r0Ejd-AeVpNSKmFxa8ZMQkK_8yhuAq?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743351902&amp;usg=AOvVaw2G3b9J-j6Fvp6yPR8NQ7XC">Colab</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/pokepress/aero?tab%3Dreadme-ov-file&amp;sa=D&amp;source=editors&amp;ust=1765035743352010&amp;usg=AOvVaw1jqGizd5o9fH5PQjxA8uCU">new repo</a></span><span>&nbsp;[old]) and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/modelscope/ClearerVoice-Studio&amp;sa=D&amp;source=editors&amp;ust=1765035743352222&amp;usg=AOvVaw3nE4EUI1yji21GGAfcqf-H">Clearer-Voice-Studio&#39;s Clear Voice</a></span><span>&nbsp;(my favorite is the 2nd one - codename0; more simplified version by codename0 - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/13Mwk_K8K4198Bd8aQ_Ajm8vBEprAjTU_/view&amp;sa=D&amp;source=editors&amp;ust=1765035743352476&amp;usg=AOvVaw0Yoavb3181qCkUDuuEfWrI">DL</a></span><span>&rdquo;]</span></p><p class="c1"><span class="c0">Matchering &ndash; matches EQ/tonal balance of rough recordings to studio references, either standalone or integrated into UVR5. Using a clean studio version of the artist as the reference and the old performance as the target is recommended.</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://sergree.github.io/matchering/&amp;sa=D&amp;source=editors&amp;ust=1765035743353113&amp;usg=AOvVaw3Ipzx_-Vx7hTvxGE3DwOvF">https://sergree.github.io/matchering/</a></span><span>)</span><span class="c0">&nbsp;- Available on UVR</span></p><p class="c1"><span>[You can also try out </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://masterknecht.klangknecht.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743353384&amp;usg=AOvVaw2zALuIcS4WQwWn0tXYfAP0">https://masterknecht.klangknecht.com/</a></span><span>]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">General workflow:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; </span></p><p class="c1"><span class="c0">1. (Optional) Pre-process low-quality audio with FlashSR.</span></p><p class="c1"><span class="c0">2. Train RVC on clean studio stems.</span></p><p class="c1"><span class="c0">3. Run inference on the old stems with the trained model (i.e., feed the cleaned original vocal through the trained RVC model to get a converted stem.)</span></p><p class="c1"><span class="c0">4. Blend, align and mix original + RVC stem (RVC as enhancement, not replacement) until it feels natural.</span></p><p class="c1"><span class="c0">5. Use Matchering or other mastering techniques to polish.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For comprehensive remastering workflow, see </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/&amp;sa=D&amp;source=editors&amp;ust=1765035743354867&amp;usg=AOvVaw3q062BI6WxOPpJJV9LXmVM">How to make your own remaster</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The overall takeaway: RVC can be used for restoration, but it works best as part of a chain of tools (super-resolution, EQ matching, mastering), with the human performance always kept at the center through blending rather than full replacement.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.gdihug899mot"><span class="c18 c15">More descriptions of models</span></h6><p class="c2"><span class="c22">and AIs, with troubleshooting and tips<br></span><span class="c31">(most models here are dated as it lacks Roformers)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span>(Instruction moved to </span><span class="c4"><a class="c3" href="#h.jx9um5zd7fnp">Reading advice</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Older models descriptions</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Inst fullband (fb) HQ_3/4/5 x-minus, MVSEP, Colabs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">HQ_4 vs 3 has some problems with fadeouts when occasionally it can leave some vocal residues</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">HQ_3 generally has problems with strings. mdx_extra from Demucs 3/4 had better result with strings here, sometimes 6s model can be good compensation in ensemble for these lost instruments, but HQ_3 gives some extra details compared to those.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">HQ_3/4 are generally muddy models at times, but with not much of vocal residues (near Gsep at times, but more than BS-Roformer v2).</span></p><p class="c1"><span class="c0">For more clarity, use MDX23C HQ model (HQ_2 can have less vocal residues at times).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Another possibly problematic instruments are those wind ones (flute, trumpet etc.) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- use Kim inst or inst 3 then</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">HQ3 has worse SDR vs: </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- voc_ft, but given that HQ_3 is an instrumental model, the latter can leave less vocal residues at times.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard2.php?id%3D4029&amp;sa=D&amp;source=editors&amp;ust=1765035743358418&amp;usg=AOvVaw06HcQ1e4kyNbXGD0ZnEq-z">https://mvsep.com/quality_checker/leaderboard2.php?id=4029</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard2.php?id%3D3710&amp;sa=D&amp;source=editors&amp;ust=1765035743358648&amp;usg=AOvVaw2J_AYZOId9gpcojJ3EXYNs">https://mvsep.com/quality_checker/leaderboard2.php?id=3710</a></span></p><p class="c1"><span class="c0">These are SDR results from the same patch, so the voc_ft vs HQ_3 comparison is valid.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX23C_D1581 (narrowband) - usually worse results than voc_ft and probably worse SDR if evaluation for both models was made on the same patch</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Can be a bit better for instrumentals</span></p><p class="c1"><span class="c0">&ldquo;The new model is very promising</span></p><p class="c1"><span class="c0">although having noise, seems to pick vocals more accurately and the instrumentals don&#39;t have that much of the filtering effect (where entire frequencies are being muted).&rdquo;</span></p><p class="c1"><span class="c0">While others say it&rsquo;s worse than demucs_ft</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.yy2jex1n5sq">GSEP AI</a></span><span class="c20">&nbsp;</span><span class="c0">an online closed source service (cannot be installed on your computer or your own site). mp3 only, 20kHz cutoff.</span></p><p class="c1"><span>Decent results in some cases, click on the link above to read more about GSEP in the specific section below. This </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard.php&amp;sa=D&amp;source=editors&amp;ust=1765035743360567&amp;usg=AOvVaw1_ioW4YXVxyVTY9tzZ5F_z">SDR leaderboard</a></span><span class="c0">&nbsp;underestimates it very much, probably due to some kind of post-processing used in GSEP [probably noise gate and/or slight reverb or chunking). As a last resort, you can use 4-6 stems option and perform mixdown without vocal stem in e.g. Audacity or other DAW. 4-6 stem option has additional noise cancellation vs 2 stem. </span></p><p class="c1"><span class="c0">GSEP is good with some tracks with not busy mix or acoustic songs where everything else simply fails, or you&rsquo;re forced to use the RX10 De-bleed feature. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- GSEP is also better than MDX-UVR instrumental models on at least tracks with </span><span class="c22">flute </span><span class="c0">and possibly duduk/clarinet or oriental tracks, and possibly tracks with only piano, as it has a decent dedicated piano model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- To address the issue with flute using MDX-UVR, use the following ensemble: Kim_Inst, HQ1, HQ2, INST 3, Max Spec/Max Spec (Anjok).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sometimes kim inst and inst3 models are less vulnerable to the issue (not in all cases).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Also, main 406 vocal model keeps most of these trumpets/saxes or other similar instruments</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Passing through a Karaoke model may help a bit with this issue (Mateus Contini </span><span class="c4"><a class="c3" href="#h.79cxg1a64b11">method</a></span><span class="c0">).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- inst HQ_1 (450)/HQ_2 (498)/HQ_3 MDX-UVR fullband models in Download center of UVR5 - great high quality models to use in most cases. The latter a bit better SDR, possibly a bit less vocal residues. Not so few like inst3 or kim ft other in specific cases, but a good point to start.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">What you need to know about MDX-UVR models is that they&#39;re divided into instrumental and vocal models and that instrumental models will always leave some instrumental residues in vocals and vice versa - vocal models will more likely to leave some vocal residues in instrumentals. But you can still encounter specific cases of songs when breaking that rule will benefit you - that might depend on the specific song. Usually, instrumental model should give better instrumental if you&rsquo;re fighting with vocal residues. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, MDX-UVR models can sometimes pick up sound midi effects which won&rsquo;t be recovered.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- kim inst (a.k.a. ft other) - cutoff, cleaner results and better SDR than inst3/464 but tends to be more noisy than inst3 at times. Use:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- inst3/464 - to get more muddy, but less noisy results, although it all depends on a song, and sometimes HQ_1/2/3 models provides generally less vocal residues (or more detestable).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX23 by ZFTurbo v1 - the third place in the newest MDX challenge. 4 stem. Already much better SDR than Demucs ft (4) model. More vocal residues than e.g. HQ_2 or Kim inst, but very clean results, if not the cleanest among all at the time. Jarredou in his fork fixed lots of those issues and further enhanced the SDR so it&rsquo;s comparable with Ensemble on MVSEP, which was also further enhanced since the first version of the code released in 2023, and also has newer models and various enhancements.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.m9ndauawzs5f">Demucs 4</a></span><span class="c0">&nbsp;(especially ft 4 stem model; UVR5, Colab, MVSEP, 6s available) - Demucs models don&#39;t have so aggressive noise cancellation and missing instruments issue like in GSEP. Check it out too in some cases (but it tend to have more vocal bleeding than GSEP and MDX-UVR inst3/464 and HQ_3 (not always, though), and 6 stem has more bleeding than 4 stem, but not so much like the old mdx_extra 4 stem model).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard2.php?%26sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035743367226&amp;usg=AOvVaw3KOEmg_XP8mR2o_hyR1IIB">Models ensemble</a></span><span>&nbsp;in UVR5 GUI (</span><span class="c22">one of the best results </span><span>so far for both instrumentals and vocals SDR-wise).</span><span>&nbsp;Decent Nvidia GPU required, or brace for 4 hours processing on 2/4 Sandy Bridge per whole ensemble of one song. How to set up ensemble </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/767947630403387393/1070004461231149077/UVR5_-_How_to_setup_a_ensemble.mp4&amp;sa=D&amp;source=editors&amp;ust=1765035743367960&amp;usg=AOvVaw0nBv75PHxKPavY0aDmSowS">video</a></span><span class="c0">.</span></p><p class="c1"><span>General video </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/jQE3oHXfc7g&amp;sa=D&amp;source=editors&amp;ust=1765035743368139&amp;usg=AOvVaw1Ual_bmPfi6Y2imby4L6AA">guide</a></span><span>&nbsp;about UVR5.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;UVR-MDX still struggles with acoustic songs (with a lot of pianos, guitars, soft drums etc.)&quot; so in this case use e.g. GSEP instead.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Description of vocal models by Erosunica</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;That&#39;s my list of useful MDX-NET models (vocal primary), best to worst:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX23C-8KFFT-InstVoc_HQ (Attenuates some non-verbal vocalizations: short low-level and/or high-frequency sounds)</span></p><p class="c1"><span class="c0">- Kim Vocal 2</span></p><p class="c1"><span class="c0">- UVR-MDX-NET-Voc_FT</span></p><p class="c1"><span class="c0">- Kim Vocal 1</span></p><p class="c1"><span class="c0">- Main (Attenuates some low level non-verbal vocalizations)</span></p><p class="c1"><span class="c0">- Main_340 (Attenuates some non-verbal vocalizations)</span></p><p class="c1"><span class="c0">- Main_406 (Attenuates some non-verbal vocalizations)</span></p><p class="c1"><span class="c0">- Kim Inst (Attenuates some non-verbal vocalizations)</span></p><p class="c1"><span class="c0">- Inst_HQ_3 (Attenuates some non-verbal vocalizations)</span></p><p class="c1"><span class="c0">- MDXNET_2_9682 (Attenuates some non-verbal vocalizations)&quot;</span></p><p class="c1"><span class="c0">and it&rsquo;s also worth to check HQ_4.</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.4bbgbbg4mfqq"><span class="c0">&ldquo;UVR BVE v2 model [currently on x-minus] is actually full band. There is, however, a small nuance. This model uses MDX VocFT preprocessing, which is not full band. MDX VocFT model is rebalancing the song. The music is slightly mixed with the vocals (25% music + 100% vocals). This mix is then processed by the BVE model. A small amount of music can help the model better understand the context (it&#39;s important for harmony separation). We train the model on a rebalanced dataset. It contains 25% of music.&rdquo; aufr33</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____</span></p><p class="c1"><span>All the tips moved to </span><span class="c4"><a class="c3" href="#h.929g1wjjaxz7">Tips to enhance separation</a></span><span class="c0">&nbsp;section</span></p><p class="c1"><span class="c0">_____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1216488566138470442&amp;sa=D&amp;source=editors&amp;ust=1765035743371479&amp;usg=AOvVaw1Y6nN80qMG7upvPNUEUgXM">Screenshot and video showcase</a></span></p><h5 class="c5 c7" id="h.ugkdl2nqgetx"><span class="c42 c36 c51 c33 c24 c30"></span></h5><h5 class="c5" id="h.6q2m0obwin9u"><span>MDX settings &amp; ens. explanations in UVR5<br></span><span class="c37">(and also Demucs/VR/MDX v2/23C inferencing parameters)</span></h5><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">In one of the pre-5.6 UVR updates, the following min/avg/max features for single models got replaced by a better automated alternative, and</span><span>&nbsp;</span><span class="c20">you might still get cleaner results of e.g. voc_ft with max_mag on X-Minus or in </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kae0-0/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743372423&amp;usg=AOvVaw3mINBEuMT1kmKUYNZyYIu7">this</a></span><span class="c20">&nbsp;</span><span class="c6">Colab still utilizing it (or downgrade your UVR version).</span></p><p class="c1"><span class="c6">Now it&rsquo;s only applicable for Ensemble and Manual Ensemble in Audio Tools.<br>Manual Ensemble is very fast, can be used on even old dual-core CPU, as it uses already separated files and simple code - not model.</span></p><p class="c1 c7"><span class="c6"></span></p><h6 class="c1 c27" id="h.lczfb0e870z9"><span class="c44 c20">Ensemble algorithm explanations<br><br></span><span class="c0">Ensemble - a way to use multiple models to potentially get better results.</span></h6><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>Rules to be broken here, but:</span></p><p class="c1"><span class="c20">Max Spec </span><span class="c0">is generally for vocals <br>(is maximum result of each stem, e.g. in a vocal you&#39;ll get the heaviest weighted vocal from each model, and the same goes for instrumental, giving a bit cleaner results, but more artefacts)</span></p><p class="c1"><span class="c20">Min Spec</span><span class="c0">&nbsp;for instrumentals in most cases <br>(it leaves the similarity from the models)</span></p><p class="c1"><span class="c20">Avg Spec </span><span class="c0">is something in between <br>(gets the average of vocals/instrumentals)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">E.g. following the above, we get the following setting:</span></p><p class="c1"><span class="c6">&ldquo;Max Spec / Min Spec&rdquo;</span></p><p class="c1"><span class="c0">Left side = about the Vocal stem/output</span></p><p class="c1"><span class="c0">Right side &nbsp;= about the Instrumental stem/output</span></p><p class="c1"><span class="c0">&quot;Max takes the highest values between each separation to create the new one (fuller sounding, more bleed).</span></p><p class="c1"><span class="c0">Min takes the lowest values between each separation to create the new one (filtered sounding, less bleed).</span></p><p class="c1"><span>Avg is the average of each separation.&quot;</span><span class="c6"><br></span></p><p class="c1"><span class="c6">More</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">For ensemble, avg/avg got the highest SDR, then worse results for respectively max/max, min/max and min/min.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">For single MDX model, min spec was the safest for instrumental models and gave the most consistent results with less vocal residues than others.</span></p><p class="c1"><span class="c0">Max spec - is the cleanest - but can leave some artifacts (if you don&#39;t have them in your file, then Max Spec for your instrumental like now might be a good solution).</span></p><p class="c1"><span class="c0">Avg - the best of the both worlds and the only possible to test SDR e.g. at least for ensembles, maybe even to this day if it wasn&#39;t patched</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">&ldquo;Max Spec/Min Spec&rdquo; option</span></p><p class="c1"><span>For at least a single instrumental model, it&#39;s the safest approach for instrumentals and universal for vocals. E.g. Min Mag/Spec in kae Colab using the old codebase for MDX models gives me the only acceptable results with hip-hop. I usually separate using a single model, but I cannot guarantee that Min Spec in UVR and manual ensemble will necessarily work exactly like Min Mag in Colab for a single model. But the explanation remains the same. The best option might even depend on a song.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">TL;DR</span></p><p class="c1"><span class="c6">For vocals bleeding in instrumentals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can use Spectral Inversion for alleviating problems with bleeding in instrumentals.</span></p><p class="c1"><span class="c0">Max Spec/Min Spec is also useful in such scenario.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">You want less bleed of Vocal in Instrumental stem?</span></p><p class="c1"><span class="c0">Use Max-Min</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">For bleeding instruments in vocals</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>Phase Inversion enabled helps to get rid of transients of the kick which might be still hearable in vocals in some cases.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Set Ensemble Algorithm: Min/Avg when you still hear bleeding.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If still the same, try Min/Max instead of Avg/Avg when doing an ensemble with Vocals/Instrumental output.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, you can resign from ensemble setting, and simply use only one clean model on the models list if the result is still not satisfactory.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Further explanations</span></p><p class="c1"><span class="c20"><br></span><span class="c0">Why not always go for Min-Max when you want the best acapella?</span></p><p class="c1"><span class="c0">Why not always go for Max-Min when you want the best Instrumental?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So far, I hear Max-Min on Instrumental sounds more &#39;muddy/muffled&#39; compared to Avg-Avg.</span></p><p class="c1"><span class="c0">I bet this will be the same for acapella, but it&#39;s less noticeable (I don&#39;t hear it).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Hence, I think the best approach would be always going with Avg-Avg.</span></p><p class="c1"><span class="c0">Then based on the outcome - after reviewing, tweak it based on your desired outcome,</span></p><p class="c1"><span class="c0">and process again with either Min-Max or Max-Min.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Min = less bleeding of the other side/stem (into this side/stem), but could get sound muddy/muffled</span></p><p class="c1"><span class="c0">Max = more full sound, but potential it will have more bleeding</span></p><p class="c1"><span class="c0">Avg = average, so a bit of all models combined</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Average/Average is currently the best for ensemble (the best SDR - compared with Min/Max, Max/Min, Max/Max).</span></p><p class="c1"><span class="c0">&ldquo;Ensemble is not the same as chopping/cutting off and stitching, it blends/removes frequencies. If song 1 has high vocals in the chorus, and song 2 has deep vocals in the chorus, max will mash them together, so the final song will have both high and deep vocals</span></p><p class="c1"><span class="c0">while min will remove both vocals&rdquo;</span></p><p class="c1"><span class="c0">&quot;If I ensembled with max, it would add a lot of noise and hiss, if I ensemble with min it would make the overall sound muted gsep.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Technical explanation on min/avg/max</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Max - keeps the frequencies that are the same and adds the different ones</span></p><p class="c1"><span class="c0">&ldquo;Max spec tends to give more artifacts as it&#39;s always selecting the loudest spectrogram frequency bins in each stft frames. So if one of the inputs have artifacts when it should be silent, and even if all other inputs are silent at the same instant, max spec will select the artifacts, as it&#39;s the max loud part of spectrogram here.&rdquo; jarredou </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Min - keeps the frequencies that are the same and removes any different ones</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;if the phases of the frequencies are not similar enough min spec and max spec algorithms for ensembles will create noisy artifacts (IDK how to explain them, it just kinda sounds washy), so it&#39;s often safer to go with average&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">by Vinctekan</span></p><p class="c1"><span class="c0">&quot;Min = Detects the common frequencies between outputs, and deletes the different ones, keeps the same ones.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Max = Detects the common frequencies between outputs, and adds the difference to them.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Now you would think that Max-Spec would be perfect since it should combine the all of the strengths of every model, therefore it&#39;s probably the best option</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">That would be the case if it wasn&#39;t for the fact that the algorithms that are used are not perfect, and I posted multiples tests to confirm this.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">However, it still gives probably the cleanest results, however, there are a few issues with said Max_Spec:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1. Lot of instrumentals are going to be left within the output</span></p><p class="c1"><span class="c0">2. If you are looking to measure quality by SDR, don&#39;t expect it to be better than avg/avg</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The average algorithm, basically, combine all the outputs and averages them. Like the average function in Excel.</span></p><p class="c1"><span class="c0">The reason why it works best is that it does not destroy the sound of any of the present outputs compared to Max_Spec and Min_Spec</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The 2 algorithms still have potential for testing, though.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">More on how the ensemble in UVR works</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Max takes the highest values between each separation to create the new one (fuller sounding, more bleed).</span></p><p class="c1"><span class="c0">Min takes the lowest values between each separation to create the new one (filtered sounding, less bleed).</span></p><p class="c1"><span class="c0">Avg is the average of each separation.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;[E.g.] HQ 1 would be better if the ensemble algorithm worked how I thought it did. </span></p><p class="c1"><span>It was explained to me that [ensemble algorithm] tries to find common frequencies across all the outputs and combines them into the result, which to me doesn&#39;t actually seem to happen when HQ1 manages to bring vocals to the mix in an 8 model ensemble, how is it not like &quot;okay A those are vocals, and B you&#39;re the only model bringing those frequencies to me trying to imply that they are not vocals&quot; and discard them. I mean I am running max/max, but I swear all avg/avg and min/min do is lower the volumes [see </span><span class="c4"><a class="c3" href="#h.oxd1weuo5i4j">enemble in DAW</a></span><span class="c0">], It&#39;s hard to know without days of testing&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;If u try avg/avg it will get quite muddy on instr result than max/max. But some song if you put kim vocal 1 will get vocal residue on the result&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.tb9spo3rgthx"><span class="c6">4-5 max ensemble models rule</span></h6><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.dg189uh59q2g"><span class="c0">Q: Why I shouldn&rsquo;t use more than 4-5 models for UVR ensemble (in most cases)</span></h6><p class="c1"><span class="c0">A: It&#39;s easier to get, when you separate the same song using some models. Get the best 4-5 models out of the most recommended currently, plus make some more separations, using some random ones. Then try to reflect avg spec from UVR by importing all of these results to your DAW.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You&#39;ll do it by decreasing volume by 3dB per one stem, so for a pair you need to decrease the volume of two stems by 6dB (possibly 6.02 as well). Decrease the volume by the same value further for more than a pair for all stems accordingly, so you&#39;ll get pretty much similar result like avg spec in UVR.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can also maybe apply a limiter on the master. In the second variant, manipulate the volume of all stems by your taste instead of keeping the same volume. By this process, you can observe that the more results imported above 4-5 results, the worse result you have when you don&#39;t decrease volume of worse results. When you have control over the volume of single results, you&#39;ll end up decreasing the volume of bad results (or deleting them completely). You don&#39;t have this opportunity in UVR using avg spec - so like in the first variant in your DAW when you set the same volume for all results. The only way to not deteriorate the final result further, is to delete such worse results from the bag entirely, to not worsen the final outcome when you have too many models ensembled. Without the possibility of decreasing volume of such a result when all volumes are equal, the more results you&#39;ll import to the bag of the 4-5 the best models, the worse final result you&#39;ll get. Because you cannot compensate for bad results in the bag by decreasing their volume like in avg spec - all tracks are equally loud in the bag of avg to the models with good results - hence, good models sound quieter if they are in minority and the final outcome is worse.</span></p><p class="c1"><span class="c0">The 4-5 max models ensemble rule is taken from long-conducted tests of SDR on MVSEP multisong leaderboard. When various ensembles were tested in UVR, most of these combinations didn&#39;t consist of more than 4-5 models, because above that, SDR was usually dropping. Usually due to all the reasons I mentioned. </span></p><p class="c1"><span class="c0">Even using clever methods of using only certain frequencies of specific models, like in ZFTurbo, jarredou and Captain FLAM code from MDX23 (don&#39;t confuse with MDX23C arch) and its derivations, which minimize the influence of &quot;diminishing returns&quot; when using too many models I think they never used more than 4-5 in their bags, and they conducted impressive amount of testing, and jarredou even focused on SDR during developing his fork (actually OG ZFTurbo code too).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____</span></p><p class="c1"><span><br></span><span class="c20">For vocal popping in instrumental issue, read about </span><span class="c4 c20"><a class="c3" href="#h.4t9vx74g45zt">chunks</a></span><span class="c20">&nbsp;or update UVR to use a better option used automatically (called batch mode) if you didn&#39;t update to 5.6/+ for a long time already, but the issue might still occur on GPUs with less than 11GB VRAM (and earlier patches doesn&rsquo;t have Roformers support). </span></p><p class="c1"><span class="c0">_______</span></p><h6 class="c1 c27 c7" id="h.lg65cu1q54j0"><span class="c6"></span></h6><h6 class="c1 c27" id="h.llty7xxxk0xi"><span class="c12">MDX v2 parameters</span><span class="c22">&nbsp;</span><span>(e.g. HQ_1-5, Kim inst, Inst 1-3, NET, Crowd)<br></span><span class="c42 c15 c36 c11 c30">(self.n_fft / &nbsp;dim_f / dim_t inference parameters later below)</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Segments 512 had better SDR than many higher values on various occasions (while 256 has lower SDR, and has almost the same separation time).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Segments 1024 and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/5129&amp;sa=D&amp;source=editors&amp;ust=1765035743394247&amp;usg=AOvVaw1ZeOAcZPtpUZUlNjsBKMjO">0.5</a></span><span class="c0">&nbsp;overlap are the last options before processing time increases very much.<br><br>Don&#39;t exceed an overlap of 0.93 for MDX models, it&#39;s getting tremendously long with not much of a difference.</span></p><p class="c1"><span class="c0">Overlap 0.7-0.8 might be a good choice as well. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Segments can also ditch the performance AF -</span></p><p class="c1"><span class="c0">segments 2560 and 2752 (for 6GB VRAM) might be still a high, but balanced value, although not fully justified SDR-wise, as 512 or 640 can be better than higher values for many songs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In UVR and Not Eddy&rsquo;s Colabs you can change segment size from 512 to 32 in order to possibly get better results with some older models like e.g. 438 (it tremendously increases separation time).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Overlap: 0.93-0.95 (0.7-0.8 seems to be the best compromise for ensembles, with the biggest measured SDR for 0.99)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Best measured SDR on MVSEP leaderboard have currently following settings (but it was measured on 1-minute songs, so it can be potentially different for your song):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Segment Size: 4096</span></p><p class="c1"><span class="c0">Overlap: 0.99</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">with 512/0.95 worse by a hair (0.001 SDR) and 0.9 overlap for as long, but still not tremendously long processing time (1h30m31s vs 0h46m22s for multisong dataset on GTX 1080 Ti).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, segments 12K performed worse than 4K SDR-wise (counterintuitively to what it is said, that higher means better result, but maybe diminishing returns at some point here, so too big values maybe cause SDR drop in some cases)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It seemed to be correlated with set overlap.</span></p><p class="c1"><span class="c0">For overlap 0.75, segments 512 was better than 1024, </span></p><p class="c1"><span class="c0">but for overlap 0.5, 1024 was better, but the best SDR out of these four results has 0.75/512 setting, although it&rsquo;s a bit slower than 1024, but for 0.99 overlap, 4096 segments were better than 512.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">SDR difference between overlap 0.95 and 0.99 for voc_ft in UVR is 0.02.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Segment size 4096 with overlap 0.99 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/4533&amp;sa=D&amp;source=editors&amp;ust=1765035743398072&amp;usg=AOvVaw16ICvEgT5v-8HS-xrXdGNb">here</a></span><span>) vs 512/0.95 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/5143&amp;sa=D&amp;source=editors&amp;ust=1765035743398191&amp;usg=AOvVaw2Xupgc9y0fHHKg5O2hQzSu">here</a></span><span class="c0">) showed only 0.001 SDR difference for voc_ft and vocals in favour of the first result.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Difference between segment size 512 with overlap 0.25 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/5122&amp;sa=D&amp;source=editors&amp;ust=1765035743398591&amp;usg=AOvVaw3XPxNMCbx0OUzzIvoiVXfi">here</a></span><span>) vs 0.95 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/5143&amp;sa=D&amp;source=editors&amp;ust=1765035743398696&amp;usg=AOvVaw14kGcg1bFIBDfncoqdA1u3">here</a></span><span class="c0">) is 0,1231 SDR for the latter.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>The difference between default segment size 256 with overlap 0.25 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/5116&amp;sa=D&amp;source=editors&amp;ust=1765035743399002&amp;usg=AOvVaw2Nzbsp17Bsjd93fGryvunZ">here</a></span><span>) vs 512/0.95 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/5126&amp;sa=D&amp;source=editors&amp;ust=1765035743399109&amp;usg=AOvVaw2RtDecrhubV1OZbzjSMyrS">here</a></span><span class="c0">) is 0,1948 SDR for vocals, and 0,1969 with denoiser on (standard, not model), and 0.95 is longer by triple.</span></p><p class="c1"><span class="c0">1024/0.25 vs 256 has not much longer processing time (7 vs 6 mins) than default settings, and better SDR by 0.0865</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For overlap </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/5124&amp;sa=D&amp;source=editors&amp;ust=1765035743399711&amp;usg=AOvVaw05wmvIBs0r-Fv5g28AozXt">0.75</a></span><span class="c0">, segments 512 were better than 1024 (at least on 1 minute audio).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Measurement is logarithmic, meaning that 1 SDR is 10x difference.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that increasing only overlap to e.g. 0.5 from default 0.25, when segments are still at default 256 will muddy the result a bit (might be more noticeable with denoise model enabled), while increasing segments (at least up to 480/512) suppose to add more clarity.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">At least on the second beta Roformer patch, max supported segment size on 4GB AMD/Intel GPUs is 480 (at least for 4:58 and HQ 1-3 can sometimes only work with lower 448 - higher overlap and segment size crashes). </span></p><p class="c1"><span class="c0">256/0.5 also works, at least with HQ 4 (but crashes with 480 segments)</span></p><p class="c1"><span class="c0">480/0.38 works too, but you can settle on e.g. 0.31 if it&rsquo;s too muddy.</span></p><p class="c1"><span class="c0">Try not to keep too many opened apps during separation, as drawing their interface also eats up VRAM on the GPU.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX-Net v2 max balanced settings: </span></p><p class="c1"><span class="c0">Segment Size: 2752 (1024 if it&rsquo;s taking too long as it&rsquo;s the last value before processing time increases really much; at least SDR-wise, 512 is better in every case than default 256 unless overlap is increased, and still gets good SDR results)</span></p><p class="c1"><span class="c0">Overlap: 0.7-/0.8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c40 c36 c33 c30">Denoising</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Denoise option used to increase SDR for MDX-Net v2, but instrumentals get a bit muddier (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/5141&amp;sa=D&amp;source=editors&amp;ust=1765035743402418&amp;usg=AOvVaw1TC6sgbI5-6v7MrBMC1KUC">result</a></span><span class="c0">).</span></p><p class="c1"><span>Denoise model has slightly lower SDR (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/5142&amp;sa=D&amp;source=editors&amp;ust=1765035743402603&amp;usg=AOvVaw1R0QU73oiNS0FyQVYa2MmO">result</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">For MDX23C models it somehow changed and using standard denoiser doesn&rsquo;t change SDR.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Spectral Inversion </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">On bigger dataset like Multisong Leaderboard decreases SDR, but sometimes you can avoid some e.g. instrumental residues using it - can be helpful when you hear instruments in silent parts of vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Explanation:</span></p><p class="c1"><span class="c0">&quot;When you turn on spectral inversion, the SDR algorithm is forced to invert the spectrum of the signal. This can cause the SDR to lose signal strength, because the inverse of a spectrum is not always a valid signal. The amount of signal loss depends on the quality of the signal and the algorithm used for spectral inversion.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In some cases, spectral inversion can actually improve the signal strength of the SDR. This is because the inverse of a spectrum can sometimes be a more accurate representation of the original signal than the original signal itself. However, this is not always the case, and it is important to experiment with different settings to find the best results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Here are some tips for improving the signal strength of the SDR when using spectral inversion:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">* Use a high-quality input. The better the quality of the signal, the less likely it is that the SDR will lose signal strength when the spectrum is inverted. (...)&quot;</span></p><p class="c1"><span class="c0">Further, there is also about picking a good inversion algorithm and experimenting with different ones, but UVR seems to have one to pick anyway.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Q: I noticed </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard2.php?id%3D2967&amp;sa=D&amp;source=editors&amp;ust=1765035743405465&amp;usg=AOvVaw0Bou91r_chAX7TLFQHz4OJ">https://mvsep.com/quality_checker/leaderboard2.php?id=2967</a></span></p><p class="c1"><span class="c0">has Spectral Inversion off for MDX but on for Demucs. The Spectral Inversion toggle seems to apply to both models, so should it be on or off?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: Good catch.</span></p><p class="c1"><span class="c0">Once u put it on for one or the other, both will be affected indeed.</span></p><p class="c1"><span class="c0">I&#39;ve enabled it (so for both, actually) [for this result].</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c12">MDX v3 parameters</span><span class="c6">&nbsp;(e.g. MDX23C-InstVoc HQ and 2 and MDX23C_D1581)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">(biggest measured SDR)</span></p><p class="c1"><span class="c0">Segment Size: 512</span></p><p class="c1"><span class="c0">Overlap: 16</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(default)</span></p><p class="c1"><span class="c0">Segment Size: 256</span></p><p class="c1"><span class="c0">Overlap: 8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The &ldquo;512/16 is slightly better for big cost of time&rdquo; vs the default 256/8.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- On a GPU with lots of VRAM (e.g. 24GB), you can run two instances of UVR, so the processing will be faster. You only need to use 4096 segmentation instead of 8192.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0"><br>It might be not fully correct to evaluate segment and overlap SDR-wise based on measurements done on multisong dataset, as every single file in the dataset is shorter than average normal track, and that might potentially lead to creating more segments and different overlaps than with normal tracks, so achieved results won&rsquo;t fully reflect normal separation use cases (if e.g. number of segments is dependent on input file). Potentially, the problem could be solved by increasing overlap and segments for a full length song to achieve the same SDR as with its fragment from multisong dataset.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Recommended balanced values for various archs</span></p><p class="c1"><span class="c0">between quality and time for 6GB graphic cards:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">VR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Window Size: 320 (best measured SDR)</span></p><p class="c1"><span class="c0">Faster value for slow PCs: 512</span></p><p class="c1"><span class="c0">Slower, might give more artefacts: 272</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Worse: 768, 1024</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Read more in </span><span class="c4"><a class="c3" href="#h.atxff7m4vp8n">VR settings</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>_____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Demucs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Segment: Default</span></p><p class="c1"><span class="c0">Shifts: 2 (def)</span></p><p class="c1"><span class="c0">Overlap: 0.5 </span></p><p class="c1"><span class="c0">(experimental: 0.75, </span></p><p class="c1"><span class="c0">default: 0.25)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The best SDR for the least time for Demucs (more a compromise, as it takes much longer than default settings ofc - &ldquo;best SDR is a hair more SDR and a sh*load of more time):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Segments: Default</span></p><p class="c1"><span class="c0">Shifts: 0</span></p><p class="c1"><span class="c0">Overlap: 0.99 (max can be 0.999 or even more, but it&rsquo;s getting tremendously long)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Best results for instrumentals as input (tested in Colab):</span></p><p class="c1"><span class="c0">Segments: Default</span></p><p class="c1"><span class="c0">Shifts: 10 (20 is max possible)</span></p><p class="c1"><span class="c0">Overlap: 0.1</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Overlap can reduce/remove artifacts at audio chunks/segments boundaries, and improve a little bit the results the same way the shift trick works (merging multiple passes with slightly different results, each with good and bad).</span></p><p class="c1"><span class="c0">But it can&#39;t fix the model flaws or change its characteristics&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In case of Voc_FT it&#39;s more nuanced... there it seems to make a substantial difference SDR-wise.</span></p><p class="c1"><span class="c0">The question is: how long do you wanna wait vs. quality (SDR-based quality, tho)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In UVR and Not Eddy&rsquo;s Colabs you can change segment size from 512 to 32 in order to possibly get better results with some older models like e.g. D1581 (but it tremendously increases separation time).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">For lack of spectrum above 14.7kHz</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">E.g. in such ensemble:</span></p><p class="c1"><span class="c0">5_HP-Karaoke-UVR, 6_HP-Karaoke-UVR, UVR-MDX-NET Karaoke, UVR-MDX-NET Karaoke 2 </span></p><p class="c1"><span class="c0">Set Max Spec/Max Spec instead of Min Spec/Min Spec, and also hi-end process (both need to be enabled for fuller spectrum).</span></p><p class="c1"><span class="c0">Karaoke models are not full band, even VR ones are 17.7kHz and MDX are 14.7kHz IRC. Setting Max Spec with hi-end process will give around 21kHz output in this case.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Cutoff with min spec in narrowband models is a feature introduced at some point in UVR5 GUI for even single MDX models in general, and doesn&#39;t exist in CLI version. It&#39;s to filter out some noise in e.g. instrumental from inversion. Cutoff then matches model training frequency (in CLI MDX, vocal model after inversion with mixture gives full band instrumental). Also, similar filtering/cutoff is done in ensemble with min spec.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">More settings explanation</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Leaving both shifts and overlap default vs shifts 10 decreases SDR by only 0.01 SDR in ensemble, but processing time is much faster - 1.7x for each shift. Also, 0.75 overlap increases SDR at least for a single model when even shift is set to 1)</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">It takes around 1 hour 36 minutes on a GTX 1080 Ti for 100 1-minute files.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;And 18 hours on i5-2410M @2.8 for 5:04 track.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Rating 1 Ensemble on a 7-min song to compare.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Time elapsed:</span></p><p class="c1"><span class="c0">1080Ti = 5m45s = 345s = 100%</span></p><p class="c1"><span class="c0">4070Ti = 4m49s = 289s = 83,8%</span></p><p class="c1"><span class="c0">4070Ti = ~16% faster</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1080Ti = ~&euro;250 (2nd hand)</span></p><p class="c1"><span class="c0">4070Ti = &euro;909 (new)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Conclusion: for every 1% gain in performance, u pay &euro;41 extra (&euro;659 extra in total).&rdquo; Bas</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">More min/max explanations moved to </span><span class="c4 c20"><a class="c3" href="#h.6q2m0obwin9u">MDX/Ensemble settings</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c44">Compensation values </span><span class="c0">for MDX v2<br>(no longer necessary since MDX23C)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Volume compensation compensates the audio of the primary stems to allow for a better secondary stem.&#39;&#39;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For the last Kim&#39;s ft other instrumental model, 1.03 or auto seems to do the best job.</span></p><p class="c1"><span class="c0">For Kim vocal 1 and NET-X (and probably other vocal models), 1.035 was the best, while 1.05 was once calculated to be the best for inst 3/464 model, but the values might slightly differ in the same branch (and compensation value in UVR5 only changes secondary stem - changing compensation value in at least UVR GUI for inst models doesn&#39;t change SDR of instruments metric)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c40 c36 c33 c30">self.n_fft / &nbsp;dim_f / dim_t parameters</span></p><p class="c1 c7"><span class="c40 c36 c33 c30"></span></p><p class="c1"><span class="c0">These parameters directly correspond with how models were trained. In most cases they shouldn&#39;t be changed, and automatic parameter detection should be enabled.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Fullband models:</span></p><p class="c1"><span class="c0">self.n_fft = 6144 dim_f = 3072 dim_t = 8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- kim vocal 1/2, kim ft other (inst), inst 1-3 (415-464), 406, 427:</span></p><p class="c1"><span class="c0">self.n_fft = 7680 dim_f = 3072 dim_t = 8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- 496, Karaoke, 9.X (NET-X)</span></p><p class="c1"><span class="c0">self.n_fft = 6144 dim_f = 2048 dim_t = 8 (and 9 kuielab_a_vocals only)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Karaoke 2</span></p><p class="c1"><span class="c0">self.n_fft = 5120 dim_f = 2048 dim_t = 8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- De-reverb by FoxyJoy</span></p><p class="c1"><span class="c0">self.n_fft = 7680 dim_f = 3072 dim_t = 9</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Roformers</span><span class="c0">&nbsp;(located in MDX-Net menu; </span></p><p class="c1"><span>only in UVR Roformer beta </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">patches</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">chunk_size</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;most of the time using higher chunk_size than the one used during training gives a bit better SDR score, until a peak value, and then quality degrades.</span></p><p class="c1"><span class="c0">For Roformers trained with 8 sec chunk_size, 11 sec is giving best SDR (then it degrades with higher chunk size)</span></p><p class="c1"><span class="c0">For MDX23C, when trained with ~6 sec chunks, iirc, peak SDR value was around 24 sec chunks (I think it was same for vit_large, you could make chunks 4 times longer)</span></p><p class="c1"><span class="c0">How much chunk_size can be extended during inference seems to be arch dependant.&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that increasing chunk_size consumes much more VRAM, and for 4GB VRAM AMD/Intel GPUs, the max supported will be chunk_size = 112455 (2,55s), sometimes chunk_size = 132300 (3s). CUDA has garbage collector which might make VRAM usage more efficient.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Conversion between dim_t and chunk_size [dim_t was used in the old Roformer beta 2 UVR patch] </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">dim_t = 801 is chunk_size = 352800 (8.00s) - maximum value working on AMD/Intel 8GB GPUs and 900MB, at least Mel models</span></p><p class="c1"><span class="c0">dim_t = 1101 is chunk_size = 485100 (11.00s)</span></p><p class="c1"><span class="c0">dim_t = 256 is chunk_size = 112455 (2,55s) - maximum value for AMD/Intel 4GB GPUs</span></p><p class="c1"><span class="c0">dim_t = 1333 is chunk_size = 587412 (13,32s)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The formula is: chunk_size = (dim_t - 1) * hop_length)&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unless you turn off Segment default in Options&gt;Advanced MDX-Net&gt;Multi Network Options, chunk_size is being read from the yaml of the model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Inference mode</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Can be found in the menu Multi Network Options menu above. Turning it off will fix the issue of silent separations on older GTX GPUs (iirc GTX 900 and older), but it might make separation slower for other, at least Nvidia GPUs.</span></p><p class="c1"><span class="c0">It was implemented in one of the latest beta Roformer patches, so if you noticed any slowdowns since updating UVR, try enabling it (now it&rsquo;s disabled by default).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">batch_size</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Inference Colab by jarredou forces 1 (clicks with that setting were fixed in MSST later), and using above 2 might increase VRAM usage. In newer patches, Anjok started to use MSST inference code for Roformers and MDX23C, hence it might have inherited its usage.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Technical explanation how it works near the </span><span class="c4"><a class="c3" href="#h.j14b9cv2s5d9">end</a></span><span>&nbsp;</span><span class="c0">of this document (scroll down a bit).</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.4o8e4hgykrim"><span class="c6">Overlap</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>4 is a balanced value in terms of speed/SDR according to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/KyCtncG&amp;sa=D&amp;source=editors&amp;ust=1765035743424385&amp;usg=AOvVaw3sgxhRqI_wSaQBukRJvm6m">measurements</a></span><span>&nbsp;(since the beta patch #3 or later used above, overlap 16 is now the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/JtxzRZD&amp;sa=D&amp;source=editors&amp;ust=1765035743424597&amp;usg=AOvVaw14AoxLCFNTg9kZD_-ax9Cz">slowest</a></span><span class="c0">&nbsp;(not overlap 2 anymore) and overlap 4 has a bigger SDR than overlap 2 now. <br>Some people still prefer using overlap 8, while for others it&rsquo;s already an overkill.<br>There&rsquo;s very little SDR improvement for overlap 32, and for 50 there&rsquo;s even a decrease to the level of overlap 4, and 999 was giving inferior results to overlap 16. <br><br>Compared to overlap 2, for 8 &ldquo;I noticed a bit more consistency on 8 compared to 2 (less cut parts in the spectrogram).&rdquo; <br>Instrumentals with overlap higher than 2 can get gradually muddier.</span></p><p class="c1"><span class="c0"><br>Calculations above were based on evaluations conducted on multisong dataset on MVSEP. Search for e.g. overlap 32 and overlap 16 below, and you will see the results to compare:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?algo_name_filter%3Dkim&amp;sa=D&amp;source=editors&amp;ust=1765035743426285&amp;usg=AOvVaw0nyImflkvECnRfz9b05Wqk">https://mvsep.com/quality_checker/multisong_leaderboard?algo_name_filter=kim</a></span></p><p class="c1"><span class="c0">&ldquo;overlap=1 means that the chunk will not overlap at all, so no crossfades are possible between them to alleviate the click at edges.&rdquo;<br>The setting in GUI overrides the one in model&rsquo;s yaml.<br></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Refer to UVR Roformer beta </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">patch</a></span><span>&nbsp;</span><span class="c0">section for more detailed information </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.929g1wjjaxz7"><span>[</span><span class="c42 c36 c51 c33 c24 c30">Tips to enhance separation results]</span></h5><p class="c1"><span class="c0">If you cannot achieve good separation, you can conduct the following experiments</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>1. </span><span class="c6">De-bass</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>Turn down all the bass to stabilize the voice frequencies of your input song (example EQ curves: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/1054893075056562236/1061276815391469639/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743427810&amp;usg=AOvVaw2MZQWJ8rUZY0ZyW48Pa1ak">1</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/1054893075056562236/1061276881103630366/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743427975&amp;usg=AOvVaw1TcOlMEEKRgSB8pNAjAqF6">2</a></span><span class="c0">). </span></p><p class="c1"><span class="c0">Male setting: cut all below 100Hz + cut all above 8kHz.</span></p><p class="c1"><span class="c0">Female setting: cut all below 350Hz + cut all above 17kHz.</span></p><p class="c1"><span class="c0">This works, because jitter is reduced a lot. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>2. </span><span class="c6">De-reverb</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>You can also test out the de-reverb e.g. in RX Advanced 8-10 on your input song. One or both combined in some cases may help you get rid of some synth leftovers in vocals. Alternatively (not tested for this purpose), you can also try out </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/1006301791354376233&amp;sa=D&amp;source=editors&amp;ust=1765035743429260&amp;usg=AOvVaw1LOliKM0KHjfFtln_KVcqN">this</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/872995262224818187/1062492523689418793&amp;sa=D&amp;source=editors&amp;ust=1765035743429397&amp;usg=AOvVaw1u4yL6vwaQ6l40ilwMztUd">this</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pixeldrain.com/u/UWn7d2iH&amp;sa=D&amp;source=editors&amp;ust=1765035743429487&amp;usg=AOvVaw2VMFho75zKtxyDdGULV8AC">dl</a></span><span>&nbsp;is in UVR&#39;s Download Center</span><span class="c0">) de-reverb model (decent results). Currently, the VR dereverb/de-echo model in UVR5 GUI seems to give the best results out of the available models (but RX or others described in the models list section at the top can be more aggressive and effective with more customizable settings).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>3. </span><span class="c20">Unmix drums</span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c6">(mainly tested on instrumentals)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Separate an input song using 4 stem model, then mix the result tracks together without drums and separate the result using strong ensemble or single vocal or instrumental model (doesn&#39;t always give better results).</span></p><p class="c1"><span class="c0">Alternatively, unmix bass as well. There&rsquo;s great bass+drums BS-Roformer model released for UVR (currently in beta)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>4. </span><span class="c6">Pitch it down/up</span></p><p class="c1"><span class="c6">(soprano/tenor voice trick + ensemble of both)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>- You can use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/JoeAllTrades/SpectraDownshift&amp;sa=D&amp;source=editors&amp;ust=1765035743431281&amp;usg=AOvVaw31jhF8Pj1ljywmAw2NoscR">https://github.com/JoeAllTrades/SpectraDownshift</a></span><span>&nbsp;for it<br>(it&rsquo;s based on scipy, it&rsquo;s lossless, so fully reversible and nulls), or:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Already implemented option in newer versions of UVR under &ldquo;Shift Conversion Pitch&rdquo; in Settings&gt;Choose Advanced Menu&gt;Advanced [Arch] Options&gt;</span></p><p class="c1"><span class="c0">And there are positive and negative values when you scroll up and down<br>(lossy, even more than soxr).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Negative value will slow down the track before separation, so e.g. model with cut-off will be compensated for its band lost a bit after speeding up again.</span></p><p class="c1"><span class="c0">If you slow down the input file, it may allow you to separate more elements in the &ldquo;other&rdquo; stem of 4-6 stems separations of Demucs or GSEP (when it&rsquo;s done manually).</span></p><p class="c1"><span class="c0">It works either when you need an improvement in such instruments like snaps, human claps, etc. The soprano feature on x-minus works similarly (or even the same), it&rsquo;s also good for high-pitched vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that low deep male vocals might not get separated while using this method (then use tenor voice trick instead - so pitch it up instead of pitching it down.</span></p><p class="c1"><span class="c0">Also, it serves the best for hard paned songs (e.g. 1970 and pre era, e.g. The Beatles, etc). Also, it works great for drums. While evaluation on multisong dataset on MVSEP, it decreases SDR by around 1.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Basically lossless speed conversion a.k.a. soprano voice trick done manually:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Do it in Audacity by changing sample rate of a track, and track only (track &gt; rate), it won&#39;t resample, so there won&#39;t be any loss of quality, just remember to calculate your numbers</span></p><p class="c1"><span class="c0">44100 &gt; 33075 &gt; 58800</span></p><p class="c1"><span class="c0">48000 &gt; 36000 &gt; 64000</span></p><p class="c1"><span class="c0">(both would result in x0.75 speed)</span></p><p class="c1"><span class="c0">etc.&quot; (by BubbleG)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Won&#39;t the result be sped up?</span></p><p class="c1"><span class="c0">A: &ldquo;No. Because when you first slow it down, after processing with said model it gets converted to 44100 again (only the sample rate, not the actual speed), so speeding it up brings the speed back to normal&rdquo; becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: I don&#39;t quite get what I&#39;m supposed to do though, just slow down the file to 0.75x and then export in 58800?</span></p><p class="c1"><span class="c0">A: &ldquo;change the sample rate to 33075 Hz,</span></p><p class="c1"><span class="c0">then export at whatever sample rate</span></p><p class="c1"><span class="c0">process then,</span></p><p class="c1"><span class="c0">change the sample rate of the processed file to 58800 Hz</span></p><p class="c1"><span class="c0">key word being change, not resample</span></p><p class="c1"><span>like </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/nC6BR2Z&amp;sa=D&amp;source=editors&amp;ust=1765035743435660&amp;usg=AOvVaw3-KuUtKOJxuBCDRyldfW6n">this</a></span><span class="c0">, click other and the pick the correct samplerate&rdquo; Dry Paint Dealer</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4b*. If you have a mix of soprano and baritone voices, you possibly can do:</span></p><p class="c1"><span class="c0">&quot;1. Soprano mode (slow down sample rate), then bring back to normal</span></p><p class="c1"><span class="c0">after that </span></p><p class="c1"><span class="c0">2. Tenor mode (speed up sample rate), then bring back to normal</span></p><p class="c1"><span class="c0">and finally combine the two with max algorithm&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Making an ensemble of such results can also increase the quality of separation.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>5. </span><span class="c20">Use 2 stem model result as input for better 4-6 stem separation</span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You may get better results in Demucs/GSEP/MDX23C Colab using previously separated good instrumental result from UVR5 or elsewhere (e.g. MDX HQ3 fullband or Kim inst narrowband in case of vocal residues, or BS-Roformer 1296)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>6. </span><span class="c6">Debleed</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>If you did your best, but you still get some bleeding here and there in instrumentals, check RX 10 Editor with its new De-bleed feature. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/nwyJJMiYGUI&amp;sa=D&amp;source=editors&amp;ust=1765035743437660&amp;usg=AOvVaw2P3BzHypWdqRvj2Fl7IzQH">Showcase</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="#h.tv0x7idkh1ua">More</a></span><span>&nbsp;methods of debleeding stems.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>7. </span><span class="c6">Vocal model&gt;karaoke model</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">You might want to separate the vocal result achieved with a vocal model with MDX B Karaoke afterwards to get different vocals (old model).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">8. The same goes for unsatisfactory result of instrumental model - you can use MDX-UVR Karaoke 2 model to clean up the result, or top ensemble or GSEP like for cleaning inverts (old models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>9. </span><span class="c20">Mixdown of 4 stems with vocal volume decreased for final separation</span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">An old trick of mine. Used in times of Spleeter to minimize vocal residues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Process mixture to 4 stems and then mix stems in a way that vocal is still there, but quieter, so lower their volume, and set drums louder, then send the mixture from it to one good isolation model/ensemble, so in result drums after separation will be less muddy, and possible vocal residues will be less persistent. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But it was in times when there wasn&#39;t even Demucs (4) ft or MDX-UVR instrumental models, where such issues are much less prevalent.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">10. If you use UVR5 GUI and 4GB, you may hear more vocal residues using GPU processing than e.g. while using 11GB GPU (tested on NVIDIA). In this case, use CPU processing instead.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>11. </span><span class="c6">Fake stereo trick</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Aufr33: &ldquo;process the left channel, then the right channel, then combine the two. [Hence] the backing vocals in the verses are removed&rdquo; (it still may be poor, but better). &ldquo;I&#39;m having to process as L / R mono files otherwise I get about 3-5% bleed into each channel from the other channel, but processing individually, totally fixes that&rdquo; -A5</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>On an example of Audacity: import your file, click on down arrow in track selection near its label, click </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1169618081178464336/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743441454&amp;usg=AOvVaw2XYeeRfTKaoQ92d9iQBwkP">Split Stereo Track</a></span><span>, go to Tracks&gt;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1169618081400754216/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743441632&amp;usg=AOvVaw1lBncnNEzvKD8n8TCi77tR">Add</a></span><span>&nbsp;New</span><span class="c0">&gt;Stereo Track.</span></p><p class="c1"><span class="c0">Mark the whole channel, copy and paste on one of the tracks you divided before. </span></p><p class="c1"><span class="c0">It will overlap the same mono track in stereo track, so the same across both channels.</span></p><p class="c1"><span class="c0">Do the same for both L and R separately. Then separate with some model both results separately. Then import both files and join their separate channels by method above. Don&rsquo;t confuse L and R channel while joining both.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>12. </span><span class="c20">Turn on Spectral Inversion in UVR</span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">it can be helpful when you hear instruments in silent parts of vocals, and sometimes also using denoiser might help for it (although both can make your results slightly muddier)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>13. </span><span class="c6">Chain separation</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For vocal residues in instrumental, you can experimentally separate it with e.g. Kim vocal (or inst 3) model first and then with instrumental model. You might want to perform additional steps to clean up the vocal from instrumental residues first, and invert it manually to get cleaner instrumental to separate with instrumental model to get rid of vocal residues. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/FBMOWcDDxIs&amp;sa=D&amp;source=editors&amp;ust=1765035743443760&amp;usg=AOvVaw0A6QGcyYkPMM6bIgygDE3S">Tutorial</a></span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>14. To not clean silences from instrumental residues in the vocal stem manually, you can use a noise gate in even Audacity. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/9vrVJov7OWo&amp;sa=D&amp;source=editors&amp;ust=1765035743444132&amp;usg=AOvVaw0e-LJSSYi_IRFjK2zCJ5dU">Video</a></span></p><p class="c1"><span>In some cases, using noise reduction tool and picking noise profile might be necessary. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/XiuNjkGl4iY&amp;sa=D&amp;source=editors&amp;ust=1765035743444409&amp;usg=AOvVaw1SaYpsdcDZ2Emdgo43fYkC">Video</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>15. </span><span class="c6">Choice of good models for ensemble</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Use only instrumental models for ensemble if you have some vocal residues (and possibly vice versa - use only vocal models for ensemble for vocals to get less instrumental residues) - mainly used in times when there was still strong division between vocal and instrumental models (before MDX23C release). Now it can narrow down to picking only models which doesn&rsquo;t have bleeding - listening all the separate models results carefully, and pick the best 2-5 results to make an ensemble.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>16. </span><span class="c6">For vocals with vocoder</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">You can use 5HP Karaoke (e.g. with aggression settings raised up) or Karaoke 2 model (UVR5 or Colabs). Try out separating the result as well (outdated models).</span></p><p class="c1"><span class="c0">&quot;If you have a track with 3 different vocal layers at different parts, it&#39;s better to only isolate the parts with &#39;two voices at once&#39; so to speak&quot;</span></p><p class="c1"><span class="c0">Be aware that BS-Roformer model ver. 2024.04 on MVSEP is better on vocoder than the viperx&rsquo; model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>17. </span><span class="c6">Find some leaked or official instrumental for inversion</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">To get better vocals</span></p><p class="c1"><span class="c0">If you&#39;re struggling hard getting some of the vocals:</span></p><p class="c1"><span class="c0">&quot;I used an instrumental that I don&#39;t remember where I found it (I&#39;m assuming most likely somewhere on YouTube) and inverted it and then used MDX (KAR v2) on x-minus and then RX 10 after.</span></p><p class="c1"><span class="c0">I Just tried the one-off Bandcamp and funnily enough it didn&#39;t work with an invert as good as the remake that I used from YouTube, but I don&#39;t remember which remake it was I downloaded because it was a while ago&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>18. </span><span class="c20">Fix for</span><span>&nbsp;</span><span class="c6">~&quot;ah ha hah ah&quot; vocal residues</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Try out some L/R inverting, try out to separate multiple times to get rid of some vocal pop-ins like this</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>19. </span><span class="c20">Center channel extraction method</span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c20">by BubbleG using Adobe Audition</span><span class="c0">:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;The idea is that you shift the track just enough where for example if you have a hip hop track, and the same instrumental tracks the drums will overlap again in rhythm, but they will be shifted in time so basically Center Extract will extract similar sounds. You can use that similarity to further invert/clean tracks... It works on tracks where samples are not necessarily the same, too&hellip;&rdquo;</span></p><p class="c1"><span class="c0">&gt;</span></p><p class="c1"><span class="c20">Step-by-step guide by Vinctekan</span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1136773448291602614/bandicam_2023-08-03_23-28-25-726.mp4&amp;sa=D&amp;source=editors&amp;ust=1765035743449372&amp;usg=AOvVaw1tQrhtHbuZcp4R5rsExj_r">video</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1. You take your desired audio file</span></p><p class="c1"><span class="c0">2. Open it in Audacity</span></p><p class="c1"><span class="c0">3. Split Stereo to Mono</span></p><p class="c1"><span class="c0">4. Click the left speaker channel (now mono), and duplicate it with Ctrl+D.</span></p><p class="c1"><span class="c0">*: If the original and duplicate is not beside eachother, move it so that it&#39;s next to eachother</span></p><p class="c1"><span class="c0">5: Select the original left speaker channel and it&#39;s duplicate, and click &quot;Make Stereo Track&quot;</span></p><p class="c1"><span class="c0">6: Solo it.</span></p><p class="c1"><span class="c0">7. Export it in Audacity, preferably in 44100hz since UVR doesn&#39;t output in higher frequencies. Format, and bit depth don&#39;t really matter, I prefer wav always.</span></p><p class="c1"><span class="c0">8: Do the same thing for the right speaker channel.</span></p><p class="c1"><span class="c0">9: Open UVR</span></p><p class="c1"><span class="c0">10: Navigate to Audio Tools&gt;Manual Ensemble.</span></p><p class="c1"><span class="c0">11: Make sure to choose Min Spec (since that function is supposed to isolate the common frequencies of 2 outputs)</span></p><p class="c1"><span class="c0">12: Select the 2 exported fake stereo files of both the left and right speaker channels.</span></p><p class="c1"><span class="c0">13: Hit process</span></p><p class="c1"><span class="c0">___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>20. </span><span class="c6">Q&amp;A for the above</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Q: For the right channel are you doing the same with the duplicate and moving the file next to the original or just duplicating and making that stereo?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: Those 2 steps go hand in hand. These reason I mentioned it is because if you try to make a Stereo Track with those 2 (the left/right channel speaker, and it&#39;s duplicate mono]) when there is a track between them, it doesn&#39;t work. Even if you select those 2 with Ctrl held down.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Take that 1 channel (left/right), Ctrl+C, Ctrl+V, now you have 2 of the exact same audio. Hold Ctrl select the 2, click &quot;Make Stereo Track&quot;. Finally, export.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>21. </span><span class="c6">Passing through lot of models one by one</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">&quot;I usually do ensemble to make an instrumental first, then demucs 4_ft&hellip; sometimes I do it once, then take that rendered file and pass it back through the algo a few more times, depends until it strips out artifacts.&quot; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It can be beneficial also in case of more vocal residues of MDX23 or Demucs ft model compared to current MDX models or their ensembles.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">22. If you still have instrumental bleeding in vocals using voc_ft, process the result further with Kim vocal 2</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>23. </span><span class="c6">Rearrange cleaner parts</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">When a verse starts, and you start having muddy drums and their pattern is consistent (e.g. some hip-hop), and you have cleaner drums from fragments before the verse starts, you can rearrange drums manually, using 4 stems model and paste that cleaner fragments throughout the track. Sometimes fade outs or intros can have clean loops without vocals, which can be rearranged without even the need of separation. Listen carefully to the track. Such moments can be even briefly in the middle of the song.</span></p><h5 class="c55 c27" id="h.vktvthhthrvh"><span class="c50">24. </span><span class="c6">arigato78 method for lead vocal acapella</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1) Try to make the best acapella (using mvsep.com site or using UVR GUI). I recommend the MDXB Voc FT model for this with an overlap setting set to at least 0.80 (I used 0.95 for this example). The overlap for this model at mvsep.com is set to 0.80. Speaking of the &quot;segment size&quot; parameter in UVR GUI - changing it from 320 to 1024 doesn&#39;t make much of a difference. It acts randomly, but we&#39;re working on a beta version of UVR GUI - remember that. (...)</span></p><p class="c1"><span class="c0">I noticed all the &quot;vocal-alike&quot; instruments still remaining on the acapella track, but wait...</span></p><p class="c1"><span class="c0">2) The second part is to process the acapella thru the mdx karaoke model (I did it using mvsep.com). I prefer the file with &quot;vocalsaggr&quot; in the name. It has more details than the file with &quot;vocals&quot; in it. The same goes to the background vocals in this case - I prefer the &quot;instrumentalaggr&quot; one.</span></p><p class="c1"><span class="c0">One important thing - all (maybe almost) of the residue instrumental sounds were taken by mdx karaoke model to the backing vocals stem, leaving the lead vocal almost studio quality (&quot;studio&quot;). But - it may be helpful for all you guys trying to make good acapellas. I was just playing with all the models and parameters and I accidentally came across this. Please, let me know what you think about it. I&#39;m gonna try this on some tracks with flutes, etc. And I realize that this method is not perfect - we get nice lead vocals, but the backing vocals are left with all that sh*tty residues.</span></p><p class="c1"><span class="c0">So the track is called &quot;Reward&quot; by Polish singer Basia Trzetrzelewska from her 1989 album &quot;London, Warsaw, New York&quot;.</span></p><p class="c1"><span class="c0">__</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>25. </span><span class="c6">Uneven quality of separated vocals</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">You can downmix your separated vocal result to mono and repeat the separation (works for e.g. BVE model on x-minus).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>26. </span><span class="c6">Experimental vocal debleed with AI for voice</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes for instrumental residues in vocals, AIs for voice recorded with home microphone can be used (e.g. Goyo [now paid Supertone Clear], or even Krisp, RTX Voice, AMD Noise Suppression, Adobe Podcast as a last resort) it all depends on the type of vocals and how destructive the AI can get.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>27. </span><span class="c6">Minimize vocal residues for very loud songs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For very loud tracks between -2.5 and -4 iLUFS, try to decrease volume of your track before separation. E.g. for Ripple, -3dB for loud tracks is a good choice. If your track you&rsquo;re trying to separate is already quiet and around -3dB, then the step is not necessary.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">27b. You could try out attenuate volume of the mixture before separation (-3/6 dB), but I can&#39;t remember whether current MSST uses normalization before anyway. UVR maybe not.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>28. </span><span class="c6">Brief (old) models summary</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">MDX-Net HQ_3 or 4 is a more aggressive model for instrumentals, with usually fewer amounts of residues vs MDX23C HQ models or sometimes even vs KaraFan or jarredou&rsquo;s MDX23 Colab v2.3. HQ_3 can give muddier results vs competition, though.</span></p><p class="c1"><span class="c0">The most aggressive are BS-Roformer models, but they can sound filtered and even muddier at times, but cleaner. It&rsquo;s good to use them with ensemble with e.g. MDX23C model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">voc_ft is pretty universal for vocals (with residues in instrumental, but not less muddy results), while people also liked Ripple/Capcut, although they give more artefacts (use the released BS-Roformer models now for vocals instead). Consider using MDX23C HQ model(s) as well, but they tend to have more instrumental residues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>29. </span><span class="c6">Cleaning up bleeding between mics in multitracks </span></p><p class="c1"><span class="c6">(by SeniorPositive)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Demucs bleed &quot;pro&quot; tip that I figured out now, and I didn&#39;t see mentioned, that I will probably try to use every time I hear some bleed between. (...) I was cleaning multitrack from bleed between microphones in conga track, and used demucs for separation drums/rest pair, and [the] other [stem] had some of those bongos still, very very low, but it existed, and I heard it just enough.</span></p><p class="c1"><span class="c0">- So I took rest signal, boosted it +20db (NOT NORMALISE! Other value but make note how much of it you boosted, go few dbs less to 0db threshold). If you do not boost it to sensible levels, the algorithm will skip it.</span></p><p class="c1"><span class="c0">- Do separation once again (this time I&#39;ve done it using spectralayers one, but it&#39;s also demucs)</span></p><p class="c1"><span class="c0">- lower result -20dB add this result to first separation result</span></p><p class="c1"><span class="c0">[The] result [is -] better separation, fewer data in other/bleed and with proper proportions. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It looks like AI is not yet perfect with low volume information and, as seen in ripple Bas Curtiz discovery, too hot content also.&quot;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1171218543258378370&amp;sa=D&amp;source=editors&amp;ust=1765035743464402&amp;usg=AOvVaw3y9iEJfFOd9VLZ5sebKZMZ">Showcase</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>30. </span><span class="c20">For clap leftovers in vocal stem</span></p><p class="c1"><span>Methods suggested in </span><span class="c4"><a class="c3" href="#h.tv0x7idkh1ua">debleeding</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>31. </span><span class="c6">(paraphrase of point 17) </span></p><p class="c1"><span class="c0">Use traditional phase inversion method and then feed them to the UVR models if you had a chance finding any official instrumental or vocal, but it doesn&rsquo;t invert perfectly. This way, the models will have less noisy data to work with. But it sometimes happens that the official instrumental and the vocal version of tracks have slightly different phasing. This makes isolating vocals via phase inversion difficult, or even sometimes impossible ~Ryan_TTC</span></p><p class="c1"><span class="c0">Sometimes only specific fragments of song will align, and in further parts of the track it will stop and require manual aligning. You may try to use Utagoe or possibly UVR with Aligning in Audio Tools as it shares some similar functionalities.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Why official stems don&rsquo;t invert?</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">&ldquo;Very rarely will the vocal or instrumental fully invert out of the master. This is because of master bus processing and non-linear nature of that processing. I.e. part of the masters sound is the processing reacting to the vocal and instrumental passing through the same chain.</span></p><p class="c1"><span class="c0">Sidechaining and many limiters are also looking ahead to the signal. Also, some processing is non-linear so even if you set it up identically re. settings, each bounce will be slightly different in nature. Stuff like saturation/distortion. Some reverbs, limiters and transient shapers etc are not outputting the same signal / samples every time you bounce, so instrumental bounce is not the same as the master bounce in terms of phase inversion.&rdquo; - Sam Hocking</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>32a. </span><span class="c6">Muddiness in instrumentals of some BS-Roformer models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Invert (at best lossless) mixture (original song - instrumental mixed with vocals) with vocal result of separation. It might increase vocal residues outside busy mix parts.</span></p><p class="c1"><span class="c0">Inverting vocals instead of mixture will result in less residues, but more artificial results in busy mix parts.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Similar trick might even increase SDR for MDX23C models irc.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>How to perform inversion is explained somewhere in this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1XIbyHwzTrbs6LbShEO-MeC36Z2scu-7qjLb-NiVt09I/edit&amp;sa=D&amp;source=editors&amp;ust=1765035743468676&amp;usg=AOvVaw0FSsu2YSCya136_mNDUE26">doc</a></span><span class="c0">&nbsp;by Bas Curtiz.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It might be unnecessary to use in UVR - it might use this trick for BS-Roformer models already, but for 2024.02 on MVSEP it was beneficial.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The trick is not necessary for 04.2024 BS-Roformer model (it sounds worse after inverting). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Furthermore, for some muddiness in this model, you can use the premium&rsquo;s feature - ensemble. The default output without intermediates should be enough (min_fft is very muddy, and max_fft very noisy). Strangely, the result from Roformer from intermediates might sound v. slightly better (maybe it was something random). The ensemble is kinda mimicked in jarredou&rsquo;s MDX23 v2.4 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.4/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743469968&amp;usg=AOvVaw0aMPpLPynSsm5btR2XtNj9">Colab</a></span><span class="c0">&nbsp;and to some extend it can be mimicked in UVR by using 1296+1297+MDX23 HQ ensemble (or copy of 1296 result via Manual ensemble instead, for faster processing).</span></p><p class="c1"><span class="c0">Now also x-minus has drums ensemble feature for Roformer models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>32b. Fixing </span><span class="c20">muddiness for MDX-Net</span><span>&nbsp;(on example of HQ_3 model) - </span><span class="c20">inverting trick</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s less muddy when mixture is inverted and mixed with separated vocals in louder parts, but vs the instrumental stem, it&#39;s worse in silent parts with less busy mix - then it has more vocal residues than the instrumental stem.</span></p><p class="c1"><span class="c0">When vocals were inverted instead of mixture, it was more muddy, but still more residues were present vs OG inst. stem, just a bit less. Can&#39;t tell how it&#39;s SDR-wise.</span></p><p class="c1"><span class="c0">So you can combine various fragments for the best results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>33. </span><span class="c6">Descriptions of models, pt. 2</span></p><p class="c1"><span class="c6">Muddiness of instrumentals in specific archs</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Beside changing min/avg/max spec for MDX ensembling (or in Colab for single models), plus aggression for VR models, or manipulating shifts and overlap for Demucs models, you need to know that some models or AIs sound usually less muddy than others. Like e.g. VR tends to have less muddiness vs MDX-Net v2 arch, but the first tends to have more vocal residues. Consider using HQ2/3/4/inst3/Kim inst for fewer residues than in VR arch or BS-Roformer.</span></p><p class="c1"><span class="c0">For less muddiness than in MDX-Net, consider using MDX23 Colab 2.0/2.1 or 2.2 (more residues) or KaraFan (e.g. preset 5).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">34. Muddiness of 4/+ stem results after mixdown</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">UVR5 supports even 64 bit output for Demucs, eventually you can use Colab or CML version for 32-bit float, but mvsep.com supports 32 bit output in MDX23 model when you choose WAV. It has better SDR vs Demucs, anyway, but sometimes more vocal residues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Then, on MVSEP beside 4 stems, you have also instrumental - ready mixture of the three for instrumental in 32 bit provided, which is not bad, but you can go to extreme, and download e.g. Cakewalk, and 3 stems separately, and now in Cakewalk:</span></p><p class="c1"><span class="c0">1) Don&#39;t use splash screen project creation tool, close it</span></p><p class="c1"><span class="c0">2) Go to new</span></p><p class="c1"><span class="c0">3) Pick 44100 and 64 bit</span></p><p class="c1"><span class="c0">4) Make sure that double 64 bit precision is enabled in options</span></p><p class="c1"><span class="c0">5) Import MDX23 3 stems (without vocals)</span></p><p class="c1"><span class="c0">6) Go to file&gt;Export</span></p><p class="c1"><span class="c0">7) Pick WAV 64</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Output files of 64 bit mixdown are huge, but that way you get the least amount of muddiness as possible. If only MDX23 model doesn&#39;t give you much more vocal residues vs MDX-UVR inst models or top ensemble which you wouldn&#39;t accept.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that 32-bit float vs 16 bit outputs can sound more muddy. Probably due to the fact that most sound cards/DACs don&rsquo;t have native 32-bit float output support in drivers and additional downsampling must be done in-fly during playback, probably even if some drivers allow using 32-bit output in Sound settings in Control Panel for the same device (while other version might not).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Spectrum-wise, instrumentals downloaded from MVSEP vs manual mixdowns are nearly identical. The only difference in one case I saw was in an instrumental intro in the song where the site&#39;s instrumental had more high end, maybe noise, but besides, spectrum looks identical at first glance without zooming it. Still, when I performed mixdown to anything lower than 64 bit, I didn&#39;t get comparable clarity to the site&#39;s instrumental. Maybe I&#39;d need to change some settings, e.g. change project bit depth to the same 32 bits as stems and later perform mixdown to 64 bit. Haven&#39;t tested it yet.</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.euyv55qdbx07"><span class="c6">35. Debleeding of drums in vocals by Sam Hocking</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For drums, I usually try and do some kind of sidechained denoise using the demixed Drum stem itself as the signal to invert with. If you shape &#39;shape&#39; the sidechained input using spectral tools/filters/transient tools etc, you can often null more of the drum out of the vocal. My favourite tool for this is Bitwig Spectral Split, but there&#39;s several FFT Spectral VSTs out there. The key is the tools has smoothing to extend the transients in time a bit so they null more.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Difficult to audibly hear on a video, but here&#39;s a vocal stem with a lot of residue i&#39;ve exaggerated in a passage without singing. I turn on a sidechain bass, drums and other stem to phase invert them out the vocal a bit via the spectral transient split in Bitwig. I then take a spectral noiseprint in Acon Digital of what&#39;s left and that works as a mild denoiser, but only after the inversion has done its thing. Don&#39;t take the noise print until you&#39;re happy everything else is inverting out as much as you can get it, and it&#39;s not noticeable.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">36. Manual MDX23 stems mixdown issues</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">It can happen that after importing three stems from MDX23 or other arch, into the same session, all combined they sound so loud that they clip on the master fader. I&rsquo;d rather suggest that, in many cases it can be ignored, as after mixdown it will be fine in most cases and better than with using limiter, but it also depends on a song loudness of how much clipping even the instrumental from single model will have:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>37. Q: </span><span class="c6">Why sometimes separated instrumentals have clipping?</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">A: &ldquo;Mixture doesn&#39;t clip, but instrumental is clipping. </span></p><p class="c1"><span class="c0">This is because where the instrumental is clipping in positive values, the vocals are in negative values, and so vocals are lowering instrumental peak value when mixed together.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you separate a song peaking at 0 with high loudness, the instrumental will probably clip because of this (and the more loudness, the more chances this clipping can happen, as waveform is brickwalled toward boundaries values). It&#39;s the laws of physics, as that&#39;s because of these laws that audio phase/polarity inversion works.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">That&#39;s why Demucs is using the &quot;clamp&quot; thing, or can also lower the volume of the separated stem to avoid that clipping.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Most of the time, lowering your input by 3dB solves that issue. &nbsp;</span></p><p class="c1"><span class="c0">- Saving your audio to float32 can be a solution, as &quot;clipped&quot; audio data is not lost in this case&rdquo; (jarredou)</span></p><p class="c1"><span class="c0">So theoretically in 32-bit float, the volume can be decreased after separation and still nothing is lost, and clipping should be fixed.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>38. </span><span class="c6">Separated audio using MDX-Net arch has noise when mixture has no audio and is silent</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Use denoise standard (or denoise model) in Options&gt;Choose Advanced Menu&gt;Advanced MDX-Net Options&gt;Denoise output</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>39. </span><span class="c6">MDX23C/BS-Roformer models ringing issue</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>&ldquo;It was reported that maybe DC offset can amplify it. Fixing it with RX before separation was said to alleviate the issue&rdquo; See the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/JKZfjUu.png&amp;sa=D&amp;source=editors&amp;ust=1765035743481895&amp;usg=AOvVaw2ledP14Aim1y9O3_AcqqEn">screenshot</a></span><span class="c0">&nbsp;how to do it,</span></p><p class="c1"><span class="c0">&ldquo;Don&#39;t forget to use &quot;mix&quot; pasting mode&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It serves to alleviate the issue of horizontal lines in specific frequencies across the whole track, cause most likely by bandsplitting neural network artifacts. Problem presented above.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Mine is 0.047% for the DC offset, so I would just do 0.047 or 0.04</span></p><p class="c1"><span class="c0">A: &ldquo;0.047% is kind of normal value, it&#39;s even a great one. No need to fix that.</span></p><p class="c1"><span class="c0">I don&#39;t know at what value it could be become problematic for source separation models.</span></p><p class="c1"><span class="c0">On some raw instrument recordings, I have seen 20%~30% DC offset sometimes, which can become a real issue for mixing then, as it&#39;s reducing headroom&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>40. </span><span class="c6">Ensemble of pitch shifted results (point 4 continues)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So you follow the point 4, and &ldquo;change sample rate before each separation and restore it after for each, then ensemble them all&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;on drums it was really working great, where sometimes you have sudden muffled snare because other [stem] masked it, the SRS ensemble [irc used in MDX23 2.x Colab and KaraFan] was helping a lot with that, making separation more coherent across the track.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>41. </span><span class="c6">A5 method for clean separations</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Consider the fake stereo trick fist from point 11, separate with BS-Roformer 1296, clean the residues in vocals manually, put the vocals back into mixture - so perform mixdown to have a mixture again, and then separate this mixture with demucs_ft (old models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>42. </span><span class="c6">Using surround versions of songs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes you can get vocals separated easier from center channel from surround version of the song. Perhaps you might also get different separations of instrumentals from such versions, also with possibility of manipulating the volume of specific tracks before mixdown to 2.0/stereo file. It might be necessary anyway, because otherwise you might run into some errors on an attempt of separation of 5.1 file or with more channels.</span></p><p class="c1"><span class="c6">Use Dolby Atmos/360 Reality Audio/5.1 version of the song</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>Multichannel mixes can give better results for separation. For more on Atmos </span><span class="c4"><a class="c3" href="#h.ueeiwv6i39ca">read</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that center may contain not only vocal, but also some effects. </span></p><p class="c1"><span class="c0">Consider separating every channel separately, or one pair of channels at the time (rear, front, center, sides separately) or only separate center channel separately and all the rest separately.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Visit </span><span class="c4"><a class="c3" href="#h.nspwy0bkpiec">this</a></span><span class="c0">&nbsp;section for more information.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>43. </span><span class="c20">Matchering as substitute of ensemble (UVR&gt;Audio Tools)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If the result of some separation is too noisy, but it preserved the mood and clarity of the instrumental much better than some cleaner, but muddy result, you can use that noisy result</span></p><p class="c1"><span class="c0">as the reference for more muddy target file. E.g. voc_ft used as reference for GSEP 2 stem instrumental output.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>44. </span><span class="c6">Retry separation 2&ndash;3 times</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">At least for MDX23C models it happened for someone, that every separation made in UVR differed in terms of muddiness and residues, and someone received satisfactory result after the second or third attempt of separating the same song. Consider turning on Test mode in UVR, so the few digits number will be added to the output file name, so the results won&rsquo;t be overwritten during the process, and you&rsquo;ll be able to listen and compare them.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>45. </span><span class="c6">Ensemble instrumental result with drums with max/max</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Can help to fix muddiness of vocal BS-Roformer models, but drums can sound too loud in the end. Consider decreasing their volume before ensemble if necessary.</span></p><p class="c1"><span class="c0">Drums can be obtained from e.g. demucs_ft (and mixture as input or from some less muddy model) or from MDX23 Colab/MVSEP (which already uses its own input from model ensemble for 4 stems)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>46. </span><span class="c6">Use EQ on your song before separation (e.g. for too weak &ldquo;s&rdquo; sounds in separated vocals)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">It&rsquo;s an old method used in times when models didn&rsquo;t give good quality yet, might be no longer necessary. You can use EQ on a mixture to stress vocals in the mix more, so the separation might turn out to be better.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>47. Bas Curtiz </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DUGvkpilXx3Q&amp;sa=D&amp;source=editors&amp;ust=1765035743490555&amp;usg=AOvVaw2NSHkWp2qbI_kYPsrjgqxD">video</a></span><span>&nbsp;tutorial for tips and tricks and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1XIbyHwzTrbs6LbShEO-MeC36Z2scu-7qjLb-NiVt09I/edit&amp;sa=D&amp;source=editors&amp;ust=1765035743490779&amp;usg=AOvVaw1yf4B6qaN_4ha2Qs_erzo5">document</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>48. </span><span class="c4"><a class="c3" href="#h.sv6j1ndk4oq5">Aufr33&rsquo;s demudder</a></span><span class="c0">&nbsp;(more for Roformers than HQ 4)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>49. </span><span class="c6">Volume compensation finetuning for MDX-Net models</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">It can slightly enhance the result, helping fighting muddiness a bit.</span></p><p class="c1"><span class="c0">It&rsquo;s no longer beneficial for MDX23C and Roformer models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Volume compensation generally differ for every song. E.g. for HQ_3 model, sometimes 1.035 can be the best, but sometimes 1.022. By default, it affects only vocals, but when you switch primary stem in model settings, so vocals are labelled as instrumentals and vice versa (so how MDX kae Colab works), it can be used also to fine tune instrumental stems.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>50. </span><span class="c6">Picking correct models for ensemble (by dca100fb8)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">&ldquo;I&#39;m seeing a certain pattern, if the Mel-Roformer model from x minus leaves faint vocals in the background during silent parts of the song, then it means MDX23 &amp; Demucs 4 htdemucs_ft models should not be used for ensemble because vocals can be heard in the background too using these models, while MDXv2 models will not leave those vocals. So it&#39;s either UVR Mel/BS-Roformer 1296 + 1297 + MDXv2 or MDX23 + Demucs + Mel-Roformer X Minus + BS-Roformer 1296 + 1297.</span></p><p class="c1"><span class="c0">I excluded VitLarge because it always leaves faint vocals&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>51. </span><span class="c20">Ensemble only extra higher frequencies</span><span class="c0">&nbsp;</span></p><p class="c1"><span>from e.g. HQ 3 model with narrowband inst 3 model - </span><span class="c4"><a class="c3" href="#h.h952n842ljfj">guide</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">52. Use some BV/Karaoke model first, to potentially get cleaner instrumental with dedicated model afterwards</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">53. Set vocals to center with stereo plugin (guide by Musicalman)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Trick [working] with the [now outdated] &nbsp;BS-Roformer karaoke model, though it may work on other karaoke models too (I suspect you might have some mileage with MDX for instance). Anyway, the trick has to do with separating one voice from other sounds. If the voice you want to separate is panned centrally, you&#39;re already in luck; the model should expertly separate it. If not, you can rotate the stereo field so that the voice is as close to the center as possible (I use the Reaper js stereo field manipulator plug in for this). Process the rotated sound with the karaoke model and the voice you&#39;re looking for will magically be separated, even from other voices! If you need the original stereo image back, simply perform the opposite rotation.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>54. </span><span class="c6">Method for cleaner vocals (by YAZKEN*)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Basically you do 2 vocal extractions, invert the polarity of one of them and render it, after that you invert the rendered audio and choose one of the extractions you&rsquo;ve made and listen what is cleaner&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">55. Spectral editing in Audacity explained (by CC Karaoke)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I typically use Audacity .. But [...] RX11 has some nice shiny toys, so maybe try that. I do things the hard way.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Here&#39;s a great basic example when using the (Roformer) Karaoke model. It can really sometimes struggle with the hard consonants.</span></p><p class="c1"><span class="c0">So for best results, you&#39;ll often need to isolate those in the main vocal stem by muting out all the surrounding sound, and then mixing them back in with the backing vocal stem. Of course by doing this the hard consonants will often be too loud, so you can de-amp the volume on them and then play back till you get a level that sounds like it blends properly. </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/dyc9olh&amp;sa=D&amp;source=editors&amp;ust=1765035743497358&amp;usg=AOvVaw2krJRT5YmjYVB1IcHKF30M">https://imgur.com/a/dyc9olh</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Slightly more complex example; Where the vocal lines are overlapping. I tried drawing green over one of the lines to show the difference. Might be a couple mistakes lol, as I haven&#39;t checked, but you get the idea. The previous sound is a carrying note, whereas the next line is a &#39;HA&#39; kinda hard hit punching words, so it has a different shape to it. This kind of more obvious difference is easier than say... reverb&hellip;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/BFGqN7P&amp;sa=D&amp;source=editors&amp;ust=1765035743498255&amp;usg=AOvVaw2fQQBMXWD-rIEBfarPS06p">https://imgur.com/a/BFGqN7P</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">jarredou&rsquo;s hint: That&#39;s a case where I would go SpectraLayers as while the 2 vocals are not on the same pitch, you can separate them manually (with harmonic selection tool). At least for that small part shown here.</span></p><p class="c1"><span class="c0">In SpectraLayers, you can change FFT resolution, higher value will give you more defined freq &quot;picture&quot;, and it can help when 2 parts are really close in pitch, like here.</span></p><p class="c1"><span class="c0">The downside is that with high FFT values, you lose time resolution. So to use SpectraLayers manual selection efficiently, you often need to switch that FFT resolution value depending on the elements you are targeting, like you would zoom/dezoom in photoshop while editing a picture. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>56. </span><span class="c6">Sequential stem separation (by dynamic64/isling)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">With single stem models, feel free to experiment with sequential stem separation -</span></p><p class="c1"><span class="c0">Instrumental model first, then drums or bass, piano or guitar, strings or horns. It depends on the song whether better results will give e.g. drums or bass when separated first, the same to piano vs guitar and strings vs horns first.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>57. </span><span class="c20">Advanced chain processing chart</span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://lh3.googleusercontent.com/pw/AP1GczNwiJ8BSJdjCWA4Z0D7CHevRfEbOqbf4uBFZSYFEWIxoSm3tUfJVUrlTMJOolR9wD_IxNZgzf7Efe7Nh58-nAuzrZmoAOwXE-FgDFWztWCmMZcJ0ResQZCjP4PMG26BpWSSMhQO4CEiM4XGplqKggoY_mVTqXaT14EBXpweZ95Dy8SJmI69Wf3usD4pyl0E2zJyMxyWZ5MYKs3uz6eenqpF98BYowhl0Qvq55xLZEqfeUsnbhouJPctM792NzghD81lLh1gxNU5sLpyS_c9y79ZOAvPSnXpHp1vFPoqrPbYhYQ1E70HtxuPb7UOSyptwB4pnQVfuJ_JRZzLWq_GDbdWa2uBHznGLFOLnwrtwlH6Kewd2hU8sE9oJzOhPCBhWoY52bDsLqjSFct7AVfFBWUpNAUQpitAMr4pEAYIjc6EaSMyYgR_Cf8Y05htRoNmOqxn08kynl7xlXtQ-5duX1VcZj6cPZ-QSbaH6W-CyBrbPjfCsDymb4V5Yl53W1oVY5ZRQWzfkfM3_KrmP1RQVimzvAq36Vwv9IwjqL_PR9AcS6HHYukQ88ZwtUzuSo7BnzuuslRFVPMM0NxzbwkPP-MWrNzlPGdMCm8VsLnmIcEcq8CRw9CRFvWzII8LsgLDUcpBeo00BBZxRQ8P0mMtQ3OjQ0opjqb4v7OJqoteW-rTPDaIuvcfgu6udWDDSUJgYuHBHOYB3n42ASD0lShDA3yORjfgPNvkQpDIJ5ZOqlbMOZz2dlOjhzq69glN8dmEx2Kn1z2h9NZo7nhrrt8QWaHnHpGT_OxroAwxHscd6lodzSQKtS86zExbCpW3PrmslkQCeXnKL-LMd9Mmr_xN5tO_zfeEuaVhCBTwzJmbxEqg5yxpgQ1klsIzxeCiqIRzJ96i1A5Tv_BjjTGeHlMjyBbOl_iCT7TSbtP9krhYs0BymO_02BE0q1r95rCOlFHyyj1Fbnh38Zt9hBHEPYOYqsTYHvwhJIjmb2M89xOr2KA9qyybrSa5vbZx4X1y91cSxQ03%3Dw1345-h941-s-no-gm?authuser%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035743501256&amp;usg=AOvVaw3AvFTyUFIrpzHW87J8czKY">image</a></span><span class="c0">)<br></span></p><p class="c1"><span>It&rsquo;s a method utilizing old models, and e.g. Kim Vocals 2 can be potentially replaced by unwa&rsquo;s BS/Mel-Roformer models in </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta UVR</a></span><span>&nbsp;(or other good method for </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">vocals</a></span><span class="c0">) or ensembles mentioned in this document. Check the best current methods for vocals in one stem to find what works the best for your song to get all vocals before splitting to other stems using this diagram.</span></p><p class="c1"><span>htdemucs v4 above can be replaced by htdemucs_ft, as it&#39;s the fine-tuned version of the model (or </span><span class="c4"><a class="c3" href="#h.jmb1yj7x3kj7">MDX23 Colab</a></span><span>). Even better, you can use some of the methods for </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">4 stems</a></span><span class="c0">&nbsp;in this GDoc (like drums on x-minus).</span></p><p class="c1"><span class="c0">De-echo and reverb models can be potentially replaced by some better paid plugins like:</span></p><p class="c1"><span>DeVerberate by Acon Digital, Accentize DeRoom Pro (more in the </span><span class="c4"><a class="c3" href="#h.5zlfuhnreff5">de-reverb</a></span><span class="c0">&nbsp;section).</span></p><p class="c1"><span>UVR Denoise can be potentially replaced by less aggressive Aufr33 model on x-minus.pro (used when aggressiveness is set to minimum), and there&rsquo;s also newer Mel-Roformer (read </span><span class="c4"><a class="c3" href="#h.5zlfuhnreff5">de-reverb</a></span><span class="c0">&nbsp;section).</span></p><p class="c1"><span>As for </span><span class="c4"><a class="c3" href="#h.h110k6ouf88c">Karaoke</a></span><span>&nbsp;models, there&#39;s e.g. a Mel-Roformer model on x-minus.pro for premium users or MVSEP/jarredeou inference </span><span class="c4"><a class="c3" href="#h.wbc0pja7faof">Colab</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;If the vocals don&#39;t contain harmonies, this model (Mel) is better. In other cases, it is better to use the MDX+UVR Chain ensemble for now.&quot;. It is possible to recreate to some extent this approach while not using BVE v2 models, by processing the output of main vocal model by one of Karaoke/BVE models in UVR (possibly VR model as the latter) using Settings&gt;Additional Settings&gt;Vocal Splitter Options, so it separates using one model, then it uses the result as input for the next model (see the Karaoke section).</span></p><p class="c1"><span class="c0">MedleyVox (not available in UVR) will be useful in the end in cases when everything else fails after you obtain all vocals in one stem, as it&#39;s very narrowband. But you can use AudioSR on it afterwards.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>58. See </span><span class="c4"><a class="c3" href="#h.tv0x7idkh1ua">here</a></span><span>&nbsp;for more on </span><span class="c6">cleaning/debleeding</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>59. </span><span class="c20">Reverse polarity and/or remove DC offset</span><span>&nbsp;of the input file<br><br>60. Find </span><span class="c20">fragments </span><span>of instrumentals in your song and </span><span class="c20">overlap them inverted across the whole song</span><span>&nbsp;before separation (heauxdontlast)<br><br>60. </span><span class="c20">Method for better quality of instrumental leaks on YT by theamogusguy<br><br></span><span class="c0">&ldquo;I did something really odd. (...) since you can only rip max 128kbps I did something really odd to get a higher quality instrumental:</span></p><p class="c1"><span class="c0">I inverted the 128kbps AAC YouTube rip into the original to get the acapella</span></p><p class="c1"><span class="c0">I took the subtracted acapella and ran it through AI (Mel-Roformer 2024.10) to reduce the compression artifacts</span></p><p class="c1"><span class="c0">I then inverted the isolated acapella and mixed it with the lossless to get an... unusual lossless instrumental file?<br>Also, the OPUS stream goes up to 20kHz, but I feel like the sample rate difference is going to cause issues, so I ended up ripping AAC (OPUS is 48khz while most music is 44.1kHz)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>61. </span><span class="c20">Join the best fragments from various models<br><br></span><span class="c0">E.g. unwa inst models might be noisy at times, so you might want to use specific fragments of v1e/v1/v2 fitting across the song, or e.g. beta 4 vocal model in certain fragments where it&rsquo;s not enough, though it is more muddy, but less noisy than unwa&rsquo;s inst models. In some cases, if it&rsquo;s still not enough, you might want to use BS-Roformer models like unwa&rsquo;s Large or e.g. 24.10 on MVSEP. Just find which model on the list in this document has the least amounts of residues and experiment with the rest starting from models listed at the top.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>62. </span><span class="c6">Lowpassing lossless file to 20kHz</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Sometimes it&rsquo;s a bit useful in getting rid of some constant faint noise/residues from vocals in instrumentals. It might muffle some unwanted parts of instrumental, but some more difficult fragments with more residues than usual might sound better that way. Tested on FLAC 16 compressed to mp3 320kbps, but it should work better with lowpassing using EQ instead of compressing. Other example values you might want to try out using are 19kHz (mp3 VBR V0 cutoff)/17.7kHz (cutoff of some narrowband models)/16kHz (cutoff of mp3 and AAC 128kbps)/14.7kHz (D1581 model cutoff).</span></p><p class="c1"><span class="c0">A possible explanation of why it might sometimes work is: sometimes, e.g. more oldschool hip-hop beats might have less higher tones, or even none above 16kHz, so most of the information in this area might come from vocals in a mixture. You can recognize it especially if vocals lose much more clarity than beat in the mixture once you compress it to e.g. mp3 VBR V0 (19kHz cutoff) or lower.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">63. Refrain from excessively stacking models (e.g. for RVC)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;Inst Voc, Kim Vocals, Denoise, ensemble mode, and so forth can introduce noises to your dataset as it rips away frequencies from your audio. This harms the model fidelity and quality.&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rentry.co/RVC-dataset-RX11/%23preparing-the-dataset-through-musicsfx-removal&amp;sa=D&amp;source=editors&amp;ust=1765035743509884&amp;usg=AOvVaw1cwAPSn9kW-Fo1Xf4lER7n">more</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>64. Get cleaner vocals with vocal and instrumental model mixdown (e.g. of Mel becruily models) by </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1324043432309817437&amp;sa=D&amp;source=editors&amp;ust=1765035743510264&amp;usg=AOvVaw0Isslr0xnBPfazaViZqegc">Havoc</a></span><span class="c0">/mrmason347<br><br>Separate with becruily Mel Vocal model and its instrumental model variant, then get vocals from the vocal model, and instrumental from instrumental model, import both stems for the DAW of your choice (can be Audacity) so you&rsquo;ll get a file sounding like original file, then export - perform a mixdown of both stems, then separate it with vocal model </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>65. Less vocal bleed with dim_t 256 or corresponding </span><span class="c4"><a class="c3" href="#h.c4nrb8x886ob">chunk_size</a></span><span class="c0">&nbsp;(cypha_sarin)</span></p><p class="c1"><span class="c0"><br>Small difference observed on 6GB NVIDIA GPU and Gabox instv5 model where &ldquo;one little vocal glitching sound from the song that only gets picked up when the segment size is lower [256]&rdquo; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">66. If you set 24-bit output in UVR&gt;Options&gt;Additional settings (or ev. 64-bit) for e.g. demudder, the results might be slightly less muddy</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>67. </span><span class="c6">Clean loop of the instrumental used for Matechering and full separation</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You can use well sounding fragment of single instrumental model separation with high fullness metric as a reference for Matchering in UVR for </span><span class="c4"><a class="c3" href="#h.j14b9cv2s5d9">phase-fixed</a></span><span class="c0">&nbsp;muddy result set as target. It will have less bleeding than models with low bleedless metric, but still fuller than phase-fixed results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">68. chunk_size 112455 and overlap 50</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>To have the best SDR for Roformers, use chunks not lower than 11s, which is usually training chunks value (rarely higher). Although, at times people get better results with 2,55s chunks (called chunk_size 112455 since UVR Roformer patch #3). But be aware that e.g. using becruily Karaoke model, using low 2,55s chunk will lead to crossbleeding. dim_t to chunk_size conversion is later </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">here</a></span><span class="c0">. Sometimes even go to extremes and use e.g. overlap 50 claiming that it was better with 112455 and becruily inst model (thx gustownis)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">69. If you want smoother vocals from e.g. Beta 5e, use negative values of Shift Pitch Conversion in UVR Advanced MDX-Net settings (explained more thoroughly above).</span></p><p class="c1"><span class="c0">&ldquo;tried it on a regular model (bigBeta5e) - the spectrogram looks a little more cut off at the high end than without the pitch adjust and overall the vocal sounds a little rounder and not quite as harsh (so the transients are not so nuclear)&rdquo; - cristouk</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>70. </span><span class="c6">Fixing missing sound after separation of multistem models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">With certain at least 4 stem models, you might find out that the inversion of a mixdown of those 4 stems vs original mixture is different. So you might get an additional 5th stem that way - your own &ldquo;other&rdquo;. It might be useful if some instruments got missed, or simply for remastering purposes where not having any missed bits of audio is critical for your work.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>71</span><span class="c6">. Start separation in a different place of the song</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Cut it manually. The result might resemble changing chunks setting a bit.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>72. </span><span class="c6">Use instrumental model result as pre-processor for vocal model</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">One of suggested RVC workflows<br><br>___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Get VIP models (optional donation)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035743516242&amp;usg=AOvVaw0Rz8TpFFPHBqtVDaONsWTo">https://www.buymeacoffee.com/uvr5/vip-model-download-instructions</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you still see some missing models in UVR5 GUI, which are mentioned in this document, get them from download center (or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.3.0/v5_model_expansion_pack.zip&amp;sa=D&amp;source=editors&amp;ust=1765035743516660&amp;usg=AOvVaw1e11I49MtZojxYURd91TLW">here</a></span><span class="c0">, expansion pack) and click refresh in model list if you don&#39;t see some models.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>_______________________________________________________</span></p><h5 class="c5" id="h.sc2lgq9t4p19"><span class="c42 c36 c51 c33 c24 c30">SDR leaderboard</span></h5><p class="c1"><span>Tested on multisong dataset<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard2.php?%26sort%3Dinstrum%26page%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035743517347&amp;usg=AOvVaw2xksBaWa2eObh24JcAuXg6">https://mvsep.com/quality_checker/leaderboard2.php?&amp;sort=instrum</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(some models/AIs/methods are not public, or only on MVSEP, all others you will find in UVR&#39;s and/or download center if you can&#39;t find some models, some only after using VIP code, or somewhere in this doc if it&rsquo;s public)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Older, &ldquo;synth&rdquo; dataset more of older models, a bit less reliable, no longer updated leaderboard by the results of new models</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard.php?sort%3Dinsrum&amp;sa=D&amp;source=editors&amp;ust=1765035743518237&amp;usg=AOvVaw1Qxs1xkJ0m8Cip5LQxIXLY">https://mvsep.com/quality_checker/leaderboard.php?sort=insrum</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>The biggest SDR doesn&#39;t automatically have to mean that your result will be the best for your song, and your use case (inst/voc/stem). Read the </span><span class="c4"><a class="c3" href="#h.rz0d5zk9ms4w">list</a></span><span class="c0">&nbsp;of all the best models and methods at the top, and experiment.<br>Apart from bleedless/fullness metric, models with bigger SDR than others might pick up instruments better (e.g. less wind instruments recognized as voice).</span></p><p class="c1"><span class="c0">Also, &ldquo;The way I see high SDR is it indicates the lower frequencies will be more accurate to the original stem, and be more free of distortion or noise. And I also see it sometimes indicates better quality of fundamental frequencies (closer to the original gain/phase, more consistent separation), but I don&rsquo;t know much beyond that lol&rdquo; - stephanie</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For specific songs, different ensemble configurations can give better results than for others.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;Since the SDR [on MVSEP&rsquo;s] synth dataset is flawed from the get-go due to the dataset being used isn&#39;t really music, but sample-based, don&#39;t get your hopes up too much.&quot;.</span></p><p class="c1"><span>But it generally reflects in greater extent differences between models, e.g. used in Demixing Challenge 2021, so it&#39;s not totally bad and multisong dataset might be even better (and still not perfect) - just be aware that different settings can give you better results for your particular song rather than average best combination of models on the SDR chart.<br>- Bas Curtiz conducted some tests with commercial music as evaluation dataset, and it turned out that only models already close in SDR switched ranks, and most models kept the same. So in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1304892082057646090&amp;sa=D&amp;source=editors&amp;ust=1765035743520922&amp;usg=AOvVaw15P9zZEq1lwAP79BdiuGlm">conclusion</a></span><span class="c0">, multisong dataset can be considered as still reliable (although bleedless and fullness metric is more suitable for our tasks now - more below).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">About SDR evaluation on MVSEP and how important factor is that to the final result &nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It still depends on the specific song, what bag of models/ensemble or what specific models will come out the best in specific scenarios. Suggesting by SDR of at least multisong dataset can be misleading. For example, the metric doesn&rsquo;t really reflect the differences between e.g. HQ_3 and MDX23C fullband model in case of bleeding in instrumentals occurring in lots of contemporary songs. Although, the bleeding issue doesn&rsquo;t always occur, and then, HQ_3 results can be more muffled, so in this case, SDR metric would be more accurate to human listening scenario where MDX23C models gets better metric, so it can be misleading, because SDR can vary very much from song to song. <br>&ldquo;The thing is that SDR evaluates at the same time how &quot;full&quot; the stem separation is and how much bleed there is in the separated stem. You can&#39;t know, only based on SDR score, which of &quot;fullness&quot; or &quot;bleedless&quot; is impacting the score the more&rdquo; - jarredou</span></p><p class="c1"><span class="c0">Also, according to some SDR evaluations conducted by Bas Curtiz, it turned out that permanent bleeding don&rsquo;t have more impact on SDR than occasional bursts of bleeding here and there.</span></p><p class="c1"><span class="c0">Still, in some scenarios SDR metric of multisong dataset on MVSEP can be a safe approach, giving you some reassurance that the result in a strict test scenario will be at least decent in some respects, although you can (or even should when some instruments are missing) still experiment trying to get a better result, but it doesn&#39;t have to be reflected in SDR. <br>To sum up, SDR evaluation is only kind of averaging toward a specific dataset of songs, and it&rsquo;s unpredictable based on just SDR how certain model will behave on specific song, plus its algorithm is limited vs human ears too. For example, if you could measure SDR for a specific song by its official, perfectly inverting instrumental, then it may not get the best result by the settings of the best ensemble combination measured by SDR for the time being. Suggesting by SDR means there&rsquo;s just higher chance to hit a good result in a certain spectrum of sonic changes - it&rsquo;s a good starting point to experiment further. </span></p><p class="c1"><span>Based on 9.7 NET 1 models, MVSEP synth dataset usually gives ~0.7 higher scores than on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021/leaderboards?challenge_leaderboard_extra_id%3D869%26challenge_round_id%3D886%26post_challenge%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035743525031&amp;usg=AOvVaw3SuKlj7nHIGvB7JMZ93FBk">Demixing Challange 2021 leaderboard</a></span><span class="c0">. Also, it favours Bas Curtiz FT model more than multisong dataset due to some characteristic features ZFTurbo pointed out.</span></p><p class="c1"><span class="c0">&ldquo;A calculation by a computer isn&#39;t a human ear&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Another way to at least sonically evaluate a model/ensemble, is to test it on a set of </span><span class="c4"><a class="c3" href="#h.37hhz9rnw7s8">AI killing tracks</a></span><span class="c0">&nbsp;which tend to have specific issues after separation with most if not all models, and to see how better or worse it got. Childish Gambino &ndash; Algorhythm is a good starting point to chase differences in vocal bleeding in instrumentals among various models, due to specific effects applied to vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">How does SDR even work in Python</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">def sdr(reference, estimate):</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; delta = 1e-7 &nbsp;# avoid numerical errors</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; num = np.sum(np.square(reference), axis=(1, 2))</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; den = np.sum(np.square(reference - estimate), axis=(1, 2))</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; num += delta</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; den += delta</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; return 10 * np.log10(num / den)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Is there a way to compare SDR between an official instrumental and the filtered instrumental </span></p><p class="c1"><span>A: Bas has shared an </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1i4xeKfNSUJumvcKjexu5lTjqKVJv9ZBI/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743527265&amp;usg=AOvVaw1W9k1OQi5MvTVo-nMzzi72">.exe</a></span><span>&nbsp;script to do that easily &#8288;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1235225091944480870&amp;sa=D&amp;source=editors&amp;ust=1765035743527449&amp;usg=AOvVaw3xT2rgo2a17ePayIXMECYE">uvr-general&#8288;</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">What you could do, but only if u have the original vocal or instrumental, is to check on SDR with this:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">usage:</span></p><p class="c1"><span class="c0">sdrcalc.exe &quot;c:\your-input-folder&quot; &quot;c:\your-output-folder&quot; </span></p><p class="c1"><span class="c0">make sure they have the exact same extension + filename</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;Here is an idea for multisong leaderboard V2, with the songs edited to have the loudness of real music. In this paper, they show that lots of models SDR value decrease when evaluated on real music </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2208.14355&amp;sa=D&amp;source=editors&amp;ust=1765035743528502&amp;usg=AOvVaw2Y093i8KNg9Oe4i6XN5UcX">https://arxiv.org/pdf/2208.14355</a></span><span class="c0">&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">After the community used SDR on synth, and later multisong dataset extensively, later</span></p><p class="c1"><span class="c0">jarredou invented a new method of automated evaluation of models:<br></span></p><h2 class="c71 c27" id="h.le80353knnv5"><span class="c4 c22 c33"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?algo_name_filter%3D%26sort%3Dinstrum%26ranking_metrics%3Dbleedless&amp;sa=D&amp;source=editors&amp;ust=1765035743529004&amp;usg=AOvVaw2LxcKwZl6GsapB_bgwCR6F">Bleedness</a></span><span class="c33">&nbsp;</span><span class="c22 c33">and </span><span class="c4 c22 c33"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/multisong_leaderboard?algo_name_filter%3D%26sort%3Dinstrum%26ranking_metrics%3Dfullness&amp;sa=D&amp;source=editors&amp;ust=1765035743529167&amp;usg=AOvVaw3hxwxY-8t4Kf4j0y-psTZv">fullness</a></span><span class="c33">&nbsp;</span><span class="c22 c33">leaderboard</span><span><br><br></span><span class="c33">Python evaluation </span><span class="c4 c33"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1n8CWiFYtr0_T1qR8WM8pOjYcA401epez/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743529379&amp;usg=AOvVaw3Z91dCUFwUysDI1VsG8t6r">script</a></span><span class="c33">&nbsp;by jarredou (prob. </span><span class="c4 c33"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1302786918244814930&amp;sa=D&amp;source=editors&amp;ust=1765035743529530&amp;usg=AOvVaw2GZ3GrpkN9TDOXP-SAPFdG">mirror</a></span><span class="c33">), </span><span class="c4 c33"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1MqSUnWgY_w-Io0GNXUyyA3_19Y9RVgLy/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743529666&amp;usg=AOvVaw0DpT11UQOC8jBtFQz-9S7j">Torch version</a></span><span class="c33">&nbsp;(with Bas Curtiz),<br>used on </span><span class="c4 c33"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/pl/quality_checker&amp;sa=D&amp;source=editors&amp;ust=1765035743529804&amp;usg=AOvVaw2etQIoNNcphZqwmo0K1Iai">Quality Checker</a></span></h2><p class="c1"><span class="c0">Librosa version added to ZFTurbo training repo.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">More detailed and reliable method of evaluation on multisong dataset than SDR.</span></p><p class="c1"><span><br>(old) Bas Curtiz&rsquo; evaluation chart with some Roformers tested with that method:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1pPEJpu4tZjTkjPh_F5YjtIyHq8v0SxLnBydfUBUNlbI/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743530626&amp;usg=AOvVaw2_wAStyRbX5HyWSdAH2Hxj">https://docs.google.com/spreadsheets/d/1pPEJpu4tZjTkjPh_F5YjtIyHq8v0SxLnBydfUBUNlbI/edit?usp=sharing</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/aJ0nNdc&amp;sa=D&amp;source=editors&amp;ust=1765035743530727&amp;usg=AOvVaw06JaBO6d9W25rh2CCdi-uX">shortened version</a></span><span>&nbsp;- it&rsquo;s outdated - all metrics are rewritten in the models sections </span><span class="c4"><a class="c3" href="#h.2vdz5zlpb27h">above</a></span><span class="c0">)</span></p><p class="c1"><span>For some newer models not on the list, you could search </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard2.php?sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035743531105&amp;usg=AOvVaw1YeRMEP0C5sX0xG8BG76Ph">here</a></span><span class="c0">&nbsp;for the model name, and bleedless/fullness metrics for new models are now provided in the evaluation description when you click on the result, but plenty of model evaluations have names not corresponding to final model names and were shared along with models on our Discord and later pasted to this document above.<br>Also, sorting by specific metric on MVSEP was added in June 2025, so you can track the exact evaluation by provided metrics in this document that way, or by searching Discord, but it can be difficult, as links to some older models&rsquo; evaluations were not indexed by the metrics bot, so once the evaluation was posted, the bot wasn&rsquo;t showing metrics from the beginning, and not all models were evaluated along with the model release.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Explanations on the metric</span></p><p class="c1"><span class="c20">Spectrogram difference showcase </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/EnD4Ljc&amp;sa=D&amp;source=editors&amp;ust=1765035743532554&amp;usg=AOvVaw37BVEb2Lf4stZ2hZ7vV-l_">diagram</a></span></p><p class="c1"><span class="c0">&ldquo;Blue is what is missing from separated stem (compared to clean source).</span></p><p class="c1"><span class="c0">Red is bleed in separated stem.</span></p><p class="c1"><span class="c0">White is perfect</span></p><p class="c1"><span class="c0">(dB scale on right seems wrong, I haven&#39;t checked, but it&#39;s not really important to see what is going on).<br></span></p><p class="c1"><span class="c0">Same formula [can] be used for a metric, which would theoretically measure bleedness and fullness of the evaluated models</span></p><p class="c1"><span class="c0">I think that for a metric, it&#39;s better to then separate negative values of diff array on one side, and keep positive values on other side, and average/scale each of them separately, so we get 2 scores, 1 for bleedness and 1 for fullness.</span></p><p class="c1"><span class="c0">It has to be experimented further (and with better stft, it&#39;s only working on single chunk currently)</span></p><p class="c1"><span class="c0">(Not sure that so high n_fft/mel_bins values are really needed, it was just nicer on the plot with that)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;bleedless/fullness metrics are stft magnitude-only based and as they are discarding the phase data, they have some kind of blind spots.&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Random noise added to results can increase fullness metric:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7709&amp;sa=D&amp;source=editors&amp;ust=1765035743534597&amp;usg=AOvVaw0yVrmICnSXOVX3u6hiWdxl">https://mvsep.com/quality_checker/entry/7709</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7708&amp;sa=D&amp;source=editors&amp;ust=1765035743534771&amp;usg=AOvVaw0WYhDy3dC4ijMTX8VF_VX5">https://mvsep.com/quality_checker/entry/7708</a></span></p><p class="c1"><span class="c0">&ldquo;l1 freq, the simplest way to explain it - it&rsquo;s a mix between fullness and bleedless but without the noise issue (in a sense it&rsquo;s the real fullness/bleedless metric) (...)<br>there&rsquo;s no universal metric still sadly, we have to rely on a combination of them (and our ears)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;-l1_freq = bleedless (higher is cleaner)</span></p><p class="c1"><span class="c0">-aura_mrstft = fullness (higher is fuller)</span></p><p class="c1"><span class="c0">they maybe don&rsquo;t have the issues fullness and bleedless have but I haven&rsquo;t played to check that&rdquo; becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Read for </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1299477079963992064&amp;sa=D&amp;source=editors&amp;ust=1765035743535799&amp;usg=AOvVaw32zHv1CPtIQRKx3Y3iLG5m">discussion</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">&ldquo;[The] problem with bleedless/fullness metric is that you can easily increase them by multiplying stem on constant.</span></p><p class="c1"><span class="c0">Multiply predictions by 0.97 - it increases fullness and reduces bleedless</span></p><p class="c1"><span>Multiply predictions by 1.03 - it greatly increases bleedless and reduces fullness&rdquo; - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1344980978556473437&amp;sa=D&amp;source=editors&amp;ust=1765035743536640&amp;usg=AOvVaw2QQ84DPlXqYDKXAl_v6L4A">ZFTurbo</a></span><span class="c6">&nbsp;(metrics/discussion)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Other metrics:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Log WMSE - good &ldquo;at least for drums or anything rich in low frequency content&rdquo; - jarredou</span></p><p class="c1"><span class="c0">&quot;It is a relatively new time-domain metric over SDR and SI-SDR that is not overly sensitive to low frequencies like SDR and can accurately evaluate silent intervals.</span></p><p class="c1"><span class="c0">In addition, time-domain metrics can be evaluated for both amplitude and phase.&quot; - Unwa</span></p><p class="c1"><span class="c0">Metrics ignore phase, so probably phase fixer won&#39;t affect fullness/bleeedless metric.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">For evaluating specific instrument stems, interesting read:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2507.06917v2&amp;sa=D&amp;source=editors&amp;ust=1765035743537961&amp;usg=AOvVaw31biDCX-WTJxLOFaLDASmX">https://arxiv.org/abs/2507.06917v2</a></span></p><p class="c1"><span class="c6">_____________________________</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Top metrics of publicly available Roformers for instrumentals available for download</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">(as for 18.06.25)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">Instrumental models sorted by instrumental </span><span class="c12">fullness </span><span class="c20">metric</span><span class="c20">:</span></p><p class="c1"><span class="c0">INSTV6N (41.68)&gt;inst_Fv4Noise (40.40)/INSTV7N (no metrics)/Inst V1e (38.87)&gt;Inst Fv3 (38.71).</span></p><p class="c1"><span>While V1e+ (37.89) might be already muddy in some cases</span><span class="c6"><br></span></p><h5 class="c5" id="h.6ypgpf4ku4d0"><span class="c20 c50">Instrumental models sorted by instrumental </span><span class="c12 c50">bleedless </span><span class="c6">metric:</span></h5><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">Gabox </span><span class="c20">inst_fv7b</span><span class="c6">&nbsp;</span></p><p class="c1"><span class="c6">Fullness: 27.07 (worse than most vocal Mel-Roformers later below)</span></p><p class="c1"><span class="c20">B</span><span class="c20">leedless: </span><span class="c6">47.49</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Inst_GaboxFv7z</span></p><p class="c1"><span class="c6">Fullness: 29.38 </span></p><p class="c1"><span class="c6">Bleedless: 44.95</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Unwa BS-Roformer-Inst-FNO </span></p><p class="c1"><span class="c6">Fullness: 32.03</span></p><p class="c1"><span class="c6">Bleedless: 42.87</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Unwa v2</span></p><p class="c1"><span class="c6">Fullness: 31.85</span></p><p class="c1"><span class="c6">Bleedless: 41.73</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Inst_gaboxBv3</span></p><p class="c1"><span class="c6">Fullness: 32.13 </span></p><p class="c1"><span class="c6">Bleedless: 41.69</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Inst_GaboxFv8 (its replaced v2 variant)</span></p><p class="c1"><span class="c6">Fullness: 33.22</span></p><p class="c1"><span class="c6">Bleedless: 40.71</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Becruily inst</span></p><p class="c1"><span class="c6">Fullness: 33.98</span></p><p class="c1"><span class="c6">Bleedless: 40.49</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Gabox instv7plus</span></p><p class="c1"><span class="c6">Fullness: 29.83</span></p><p class="c1"><span class="c6">Bleedless: 39.36</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Unwa HyperACE</span></p><p class="c1"><span class="c0">Fullness: 36.91</span></p><p class="c1"><span>Bleedless: 38.77</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Unwa v1</span></p><p class="c1"><span class="c0">Fullness: 35.69</span></p><p class="c1"><span class="c0">Bleedless: 37.59</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Gabox fv3</span></p><p class="c1"><span class="c6">Fullness: 38.71</span></p><p class="c1"><span class="c20">Bleedless: 35.62</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Unwa v1e</span></p><p class="c1"><span class="c6">Fullness: 38.87 </span></p><p class="c1"><span class="c6">Bleedless: 35.59</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Gabox fv5</span></p><p class="c1"><span class="c6">Fullness: 39.40 </span></p><p class="c1"><span class="c6">Bleedless: 33.49</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1 c7"><span class="c6"></span></p><h6 class="c1 c27" id="h.6f1v88my7hfk"><span>Vocal models/ensembles sorted by instrumental </span><span class="c22">bleedless </span><span class="c0">metric:<br>(more muddy; Gabox and Unwa&rsquo;s Revive models not evaluated yet):</span></h6><p class="c1"><span class="c4 c20"><a class="c3" href="#h.3mrz4632uifx">Descriptions</a></span><span class="c20">&nbsp;of the public models</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">MVSep BS-Roformer (2025.07.20) - the 2 previous versions got replaced on the site by it</span></p><p class="c1"><span class="c6">Inst. Fullness 27.83 </span></p><p class="c1"><span class="c6">Inst. Bleedless 49.12</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">MVSep Ensemble 11.50 (2024.12.20)</span></p><p class="c1"><span class="c6">Inst. Fullness 27.17 </span></p><p class="c1"><span class="c6">Inst. Bleedless 47.94</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">MVSep Ensemble (4 stem) 11.93 (2025.06.30)</span></p><p class="c1"><span class="c6">Inst. Fullness 28.70</span></p><p class="c1"><span class="c6">Inst. Bleedless 47.68</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">MVSep MelBand Roformer (2024.10)</span></p><p class="c1"><span class="c6">Inst. Fullness 27.73</span></p><p class="c1"><span class="c6">Inst. Bleedless 47.48</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">BS-RoFormer SW 6 stem (MVSEP/Colab/undef13 splifft)</span></p><p class="c1"><span class="c6">Inst. Fullness 27.45</span></p><p class="c1"><span class="c6">Inst. Bleedless 47.41</span></p><p class="c1"><span class="c6">(use inversion from vocals and not mixed stems for better instrumental metrics)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">MDX23 Colab fork v2.5 by jarredou</span></p><p class="c1"><span class="c6">Inst. Fullness 28.02</span></p><p class="c1"><span class="c6">Inst. Bleedless 47.24</span></p><p class="c1"><span class="c6">(more noticeable bleeding/noise than MVSep Ensemble above)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">voc_fv4</span></p><p class="c1"><span class="c6">xx</span></p><p class="c1"><span class="c6">xx</span></p><p class="c1"><span class="c6">(Good if you need less vocal residues than typical instrumental Roformers (even less than Mel Kim, FT2 Bleedless, or Beta 6X - makidanyee).</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">MelBand Roformer Kim</span></p><p class="c1"><span class="c6">Inst. Fullness 27.44</span></p><p class="c1"><span class="c6">Inst. Bleedless 46.56</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Kim | FT2 Bleedless (by Unwa)</span></p><p class="c1"><span class="c20">Inst. </span><span class="c0">Fullness 27.78</span></p><p class="c1"><span class="c20">Inst. </span><span class="c0">Bleedless 46.31</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Beta 5e (by unwa)</span></p><p class="c1"><span class="c6">Inst. Fullness 27.63 (bigger metric than Kim)</span></p><p class="c1"><span class="c6">Inst. Bleedless 45.90</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Kim | FT 2 (by unwa)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c1"><span class="c6">Inst. Fullness 28.36</span></p><p class="c1"><span class="c6">Inst. Bleedless 45.58</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Kim | FT (by unwa)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c1"><span class="c6">Inst. Fullness 29.18</span></p><p class="c1"><span class="c6">Inst. Bleedless 45.36</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">MVSEP BS Roformer (2025.06)</span></p><p class="c1"><span class="c6">Inst. fullness: 17.30</span></p><p class="c1"><span class="c6">Inst. bleedless: 37.83</span></p><p class="c1"><span class="c6">(can be still a good choice in case of some crossbleeding, vocal chops, or residues of reverbs or BGV)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">MVSEP Ensemble 11.93 (also contains 2025.06)</span></p><p class="c1"><span class="c6">Inst. fullness: 17.73</span></p><p class="c1"><span class="c6">Inst. bleedless: 36.30</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">___</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Outperformed vocal models for instrumental bleedless<br>(still metrics for instrumental stem, so after inversion if not duality)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">SYHFT V3 (by SYH99999)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c1"><span class="c6">Fullness 28.07</span></p><p class="c1"><span class="c6">Bleedless 45.15</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Duality v1 (by unwa)</span></p><p class="c1"><span class="c6">Fullness 29.08</span></p><p class="c1"><span class="c6">Bleedless 43.26</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Duality v2 (by unwa)</span></p><p class="c1"><span class="c6">Fullness 28.03</span></p><p class="c1"><span class="c6">Bleedless 44.16</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Mel Becruily vocal</span></p><p class="c1"><span class="c6">Fullness 28.25</span></p><p class="c1"><span class="c6">Bleedless 40.95</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">SYHFT V2.5 (by SYH99999)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c1"><span class="c6">Fullness 28.60</span></p><p class="c1"><span class="c6">Bleedless 40.34</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Big SYHFT V1 (by SYH99999)</span></p><p class="c1"><span class="c6">Fullness 28.48</span></p><p class="c1"><span class="c6">Bleedless 44.81</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Unwa beta 4</span></p><p class="c1"><span class="c6">Fullness 26.29</span></p><p class="c1"><span class="c6">Bleedless 44.71</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">SYHFT V4 and V5 were never publicly released</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">___</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">bleedless+fullness/2=avg</span></p><p class="c1"><span class="c6">experimental avg metric for vocals (favours bleedless metric)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Bas&#39; Edition - 27.72</span></p><p class="c1"><span class="c6">FT2 bleedless - 27,54 | 2,49</span></p><p class="c1"><span class="c6">24.10 - 27.44 | 2,21</span></p><p class="c1"><span class="c6">FT2 - 26.84 | 2,23</span></p><p class="c1"><span class="c6">FT - 26.58</span></p><p class="c1"><span class="c6">5e - 26.42 | 1,54</span></p><p class="c1"><span class="c6">voc_gabox - 26.38</span></p><p class="c1"><span class="c6">voc_fv2 - 26.36</span></p><p class="c1"><span class="c6">voc_fv3 - 26.06</span></p><p class="c1"><span class="c6">Becruily - 25.99</span></p><p class="c1"><span class="c6">beta 4 - 25.93</span></p><p class="c1"><span class="c6">FullnessVocalModel - 25.91</span></p><p class="c1"><span class="c6">voc_fv4 - 25.02</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.xya7mtyl0m39"><span>Other e</span><span class="c0">nsembles for UVR5</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Best newer ensembles on the list at the </span><span class="c4"><a class="c3" href="#h.2vdz5zlpb27h">top</a></span><span>&nbsp;of the doc</span><span class="c0">. Older configurations follow after the listed hidden results below.</span></p><p class="c1"><span>For reference, read MVSEP&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard2.php?%26sort%3Dinstrum%26page%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035743550709&amp;usg=AOvVaw2nr-sPAgLD7YDlx-1jDgTV">SDR evaluation chart</a></span><span>&nbsp;(UVR ensembles will appear later in the chart).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that some of the results on the chart above at the top are not from UVR5 or use different methods and code to achieve better results and might be not public/still WiP, e.g. the following:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Hidden leaderboard results (all SDR results provided for instrumentals,<br>Discord links below are dead, but at least some can be found by the search on Discord and by verifying the opened link address which initial URL hasn&rsquo;t changed): </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Bas&rsquo; unreleased fullband vocal model epoch 299 + voc_ft - SDR </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1127034811656196137/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743551920&amp;usg=AOvVaw184tw8M3KMB23WYPdk5Qt7">16.32)</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1126326776952520764/image.png?width%3D1440%26height%3D63&amp;sa=D&amp;source=editors&amp;ust=1765035743552108&amp;usg=AOvVaw2p_fr9Uuy8NACqx7_iQM29">this</a></span><span class="c0">&nbsp;older viperx&rsquo; unreleased custom weights code (newer one is up already), besides, &ldquo;instrumental vX&rdquo; entries are his ones (it rather utilizes public models with his own non-public weighted inference, and he gatekeeps it for more than since MDX23 results were published). </span></p><p class="c1"><span class="c0">BTW. ebright is probably the 2nd place in MDX23, at least the result appeared in similar time like ByteDance. 2nd place decided not to publish their work.</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/911050124661227542/1136370992369905775/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743552905&amp;usg=AOvVaw3II080IcxIH2QhemdGhsyE">32-bit</a></span><span class="c0">&nbsp;higher SDR result of original multisong dataset uploaded as output (opposed to the previous 16-bit currently on top). &ldquo;Multisong dataset | Original stems | bass/drums/other joined&rdquo; is not a model!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Bytedance v.0.2 - inst. SDR </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/911050124661227542/1126353744880210041/image.png?width%3D1440%26height%3D362&amp;sa=D&amp;source=editors&amp;ust=1765035743553506&amp;usg=AOvVaw3Olx_qzGQNLeaPSb59kzUQ">17.26</a></span><span>, now it&rsquo;s outperformed by v.0.3 and is </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://web.archive.org/web/20230806134030/https://mvsep.com/quality_checker/multisong_leaderboard?sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035743553788&amp;usg=AOvVaw1llC8qD1eRtwVoFY9k9h-S">17.28</a></span><span class="c0">, now called 1.0), </span></p><p class="c1"><span>-&quot;MSS&quot; - is probably ByteDance 2.0, not </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/gladia-research-group/multi-source-diffusion-models&amp;sa=D&amp;source=editors&amp;ust=1765035743554087&amp;usg=AOvVaw21j0Q0Q_iz3RSzd1ep5AtC">multi source stable diffusion</a></span><span>, as BD&#39;s test files which were published were starting with MSS name before, but the first doesn&#39;t necessarily contradict the latter, although they said to use novel arch - SDR </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1134276341697630329/MSS.png&amp;sa=D&amp;source=editors&amp;ust=1765035743554451&amp;usg=AOvVaw0e63yNtPtohhylzyKwlFq_">18.13</a></span><span>, and probably another one by ByteDance - SDR </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/767947630403387393/1136620057783455844/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743554644&amp;usg=AOvVaw2D5ixuoYaXUsODjU3rjqI9">18.75</a></span><span class="c0">, let&#39;s call it 2.1, but seeing inconsistent vocal result vs previous one here, we have some suspicions that the result was manipulated at least for vocals (or stems were given from different model). </span></p><p class="c1"><span class="c0">- Ripple app/SAMI-Bytedance on the chart is 16.59, also input files weren&#39;t lossless.</span></p><p class="c1"><span>- BS-Roformer results by viperx posted in </span><span class="c4"><a class="c3" href="#h.bg6u0y2kn4ui">Training</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">BTW. model_mel_band_roformer_ep_617_sdr_11.5882 is Bas Curtiz model trained purely on multisong dataset as an experiment, and won&rsquo;t give good results outside multisong dataset.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">mel_band_roformer_ep_125_sdr_11.2069 is Bas Curtiz fine-tune model trained from ZFTurbo checkpoint, and it was shared with him under condition it will remain non-public/MVSEP exclusive.</span></p><p class="c1"><span class="c0">____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Some of these models in the download center are visible after using the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035743556251&amp;usg=AOvVaw37ltVtcedwHJyP6uthJCHs">VIP code</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Older the best ensembles for UVR by SDR </span><span class="c0">:</span></p><p class="c1"><span class="c0">(some newer/better ones than these located at the top of the doc)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For 28.07.23</span></p><p class="c1"><span class="c0">Kim Vocal 2 + MDX23C_D1581 + Inst HQ3 + Voc FT | Avg/Avg</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For 28.07.23 (#4563)</span></p><p class="c1"><span class="c0">Kim Vocal 1 + Kim Vocal 2 + MDX23C_D1581 + Inst HQ3 + Voc FT + htdemucs_ft | Avg/Avg</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For 27.07.23 (#4561)</span></p><p class="c1"><span class="c0">Kim Vocal 1 + Kim Vocal 2 + Kim Inst + MDX23C_D1581 + Inst HQ3 + Voc FT + htdemucs_ft | Avg/Avg (beta UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For 24.06.23 (#3842) </span></p><p class="c1"><span>Kim Vocal 1 + 2 + Kim Inst + HQ3 + Voc FT + htdemucs_ft | Avg/Avg | Chunks: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1123703874847506532/image.png?width%3D343%26height%3D651&amp;sa=D&amp;source=editors&amp;ust=1765035743557698&amp;usg=AOvVaw30P3sXfd1UIYCFqk2Kzcny">ON</a></span></p><p class="c1"><span class="c0">(but for ensembles instead of single models it can score better with chunks disabled)</span></p><p class="c1"><span class="c0">[Consider using MDX23C_D1581 vocal model above as well, if ensemble in this arch works correctly, if not, perform manual ensemble, not sure here)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">As for the very big ensemble</span><span class="c0">&nbsp;from older synth leaderboard (2023-04-30):<br>MDX-Net: 292, 496, 406, 427, Kim Vocal 1, Kim Inst + Demucs ft</span></p><p class="c1"><span class="c0">Optionally, with later released models - voc_ft and Kim Vocal 2 -</span></p><p class="c1"><span class="c0">It doesn&#39;t score too good SDR-wise on newer synth dataset, since it uses older models which have better counterparts already. Synth dataset is not used for evaluations for a long time.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For 13.06.23 (#3322)</span></p><p class="c1"><span class="c0">Inst HQ2 + 427 + Inst Main + Kim Inst + Kim Vocal 1 + 2 + Demucs FT | Avg/Avg | Chunks Batch | Spectral inversion OFF</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Most probably you can safely replace Inst HQ2 with HQ3 and 4 (better SDR) getting a slightly better SDR in ensemble (it&rsquo;s just not tested in ensemble yet).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But be aware that &ldquo;The moment you introduce Instrumental models, there will be a bit of residue in the vocal output.</span></p><p class="c1"><span class="c0">However, the SDR scores higher.</span></p><p class="c1"><span class="c0">I&#39;d say go with Vocal models only, if you care about your vocal output.&rdquo;</span></p><p class="c1"><span class="c0">The same is vice versa for instrumentals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">- Older ensemble configurations or custom settings with lower SDR</span></p><p class="c1"><span class="c6">(but might be useful for some specific songs or genres if further info is given)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">From public models, the best SDR on 14.04.23:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ensemble | Kim vocal 1 + Inst HQ 2 + Main 427 + htdemucs_ft | Avg/Avg | Chunks Batch | Denoise Output ON | Spectral Inversion OFF | WAV</span></p><p class="c1"><span class="c0">For instrumentals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">And</span></p><p class="c1"><span class="c0">Ensemble | Kim vocal 1 + Inst 3 + Inst HQ 2 + Inst Main + htdemucs_ft | Avg/Avg | Chunks Batch | Denoise Output ON | Spectral Inversion OFF | WAV</span></p><p class="c1"><span>For vocals</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">As of 01.01.23 the best SDR for vocals/instrumentals has:</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>-UVR-MDX-NET INST MAIN + UVR-MDX-NET Inst 3` + `kim vocal model fine tuned (old)` + `Demucs: v4 | htdemucs_ft - Shifts: 2 - Ensemble Algorithm: Avg/Avg`, chunk margin: 44100 (better SDR compared to 22050), denoise output on (-||- off), spectral inversion off (-||- on)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX-Net: Kim vocal model fine-tuned (old) + UVR-MDX-NET_Main_427 + Demucs: v4 | htdemucs_ft - Ensemble Algorithm: Avg/Avg, Volume Compensation: Auto </span></p><p class="c1"><span class="c0">(it sets `1.035` - the best for Kim (old) model vs other options)</span></p><p class="c1"><span class="c0">Shifts: 10 - Overlap: 0.25 </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- a bit worse ensemble settings than both ensemble settings above SDR-wise:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR-MDX-NET Inst 3 (464) and &ldquo;UVR-MDX-NET_Main_438&rdquo; vocal model (main) and htdemucs_ft - Ensemble Algorithm: Average/Average</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Also good combo (for instrumentals, vocals in half of the cases):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX-Net: UVR-MDX-NET Inst Main</span></p><p class="c1"><span class="c0">VR Arc: 7_HP2_UVR</span></p><p class="c1"><span class="c0">Demucs: v4 | htdemucs_ft</span></p><p class="c1"><span class="c0">Max Spec/Max Spec</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- UVR-MDX-NET Inst 3 as a main model and 7_HP2-UVR as a secondary with the scale set to 75% </span></p><p class="c1"><span class="c0">(Anjok 21.12.22: Personally, I found that using [it] produces the cleanest instrumental.&quot;</span></p><p class="c1"><span class="c0">&ldquo;It means the final track will be 25% hp2 model and 75% inst 3 (similar to ensemble feature, but you have more control over how strong you want the secondary model to be)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX-NET inst3 model (464) with secondary model 9_HP2_UVR 71% (hendrysetiadi: seems to get the best results with e.g. disco songs).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Inst Main + 427 + Net 1 (CyPha-SaRin: was a pretty good combo. One big model, one medium, one small, pretty decent results across the board. If a song going to have problematic parts, it&#39;s going to have regardless of what combo you picked, it seems.)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- kim vocal 1 + instr 3 + full 403 + inst HQ 1 + full 292 + instr main with MAX/MAX (hendrysetiadi: i think that&#39;s the best combination of ensemble that i found)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For Rock/Metal - The MDX-Net/VR Architecture ensemble with the Noise Reduction set between 5-10 (depending on the track) and Aggression to 10.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For Pop - The MDX-Net/VR Architecture ensemble with the Noise Reduction set between 0-4 and Aggression to 10. (Anjok, 13.05.22)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Here is another ensemble that I have tried myself &quot;VR Arc: 1_HP-UVR x MDX-Net: &nbsp;Kim Vocal 1 x MDX-Net: UVR-MDX-NET: Inst HQ 1 x MDX-Net: UVR-MDX-NET: Inst HQ 2&quot; All with the average/average ensemble (Mikey/K-Pop Filters)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Inst HQ 1 &amp; Main 427 are best for India</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-VR: 7_HP2-UVR, MDX: Kim vocal 1, Inst 3, Inst Main, Main, htdemucs_ft</span></p><p class="c1"><span class="c0">Max/Max, main pair: vocals/instrumental </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Instrumentals sound so good using these settings also. I can&rsquo;t believe this is possible. What an amazing software. Thank you to whoever made this.&quot; StepsFan</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- I got an ensemble that works well for loud and crazy tracks (this instance it&#39;s dariacore lol) - by knock:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Models: Inst HQ 3, Main, Voc FT</span></p><p class="c1"><span class="c0">Ensemble Algorithm: Avg/Avg</span></p><p class="c1"><span class="c0">MDX-Net settings: </span></p><p class="c1"><span class="c0">Vol Comp: Auto</span></p><p class="c1"><span class="c0">Segment Size: 4096 (you can go up to 6144 if you want to wait longer, 4096 has seemed to be perfect for me)</span></p><p class="c1"><span class="c0">Overlap: Default (which I believe is 0.5)</span></p><p class="c1"><span class="c0">Shift Conversion Pitch: -6 (semitones)</span></p><p class="c1"><span class="c0">Match Freq Cut-off: Off</span></p><p class="c1"><span class="c0">Denoise Output: Yes</span></p><p class="c1"><span class="c0">Spectral Inversion: No</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.79cxg1a64b11"><span class="c0">Mateus Contini&#39;s methods</span></h6><h6 class="c2 c27 c7" id="h.5crknvonat1o"><span class="c0"></span></h6><h6 class="c1 c27" id="h.ynukuzsi11zf"><span class="c40 c36 c33 c30">&nbsp;#1 (old)</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-&ldquo;TIP! For busy songs: I was testing some ensembles trying to get Instrumental Stems with less volume variation (muddy), preserving guitar solos, pads the most and I had great results doing the following, for anyone interested: </span></p><p class="c1"><span class="c0">Ensemble (Demucs + 5_HP-Karaoke with Max for Instrumental stem) - The result will be the Instruments + Backing Vocals and this preserves most of the guitar solos, pads and things that MDX struggles.</span></p><p class="c1"><span class="c0">Instrumental Stem Output &gt; Demucs to remove the Backing Vocals from the track - This pass will remove the rest of the Vocals. In some cases will be some minor leftovers that you can clean later with other methods.</span></p><p class="c1"><span class="c0">I find the results better than Demucs alone/ MDX models or other ensembles for what I&#39;m looking for. I&#39;m not evaluating noise, but fuller instrumental Stems, trying to preserve most of it and also the cost (time) to do it.</span></p><p class="c1"><span class="c0">Since I&#39;m not interested, for this case, in doing manual work song by song and just use these stems to sing over it, I find the results great.&rdquo; - Mateus Contini</span></p><p class="c1"><span class="c0">Q: Do you mean that you process Demucs 2 times? Once for ensemble with VR then the result was processed using Demucs again?</span></p><p class="c1"><span class="c0">A: You can add other models with the ensemble, like Demucs, VR_5-Karaoke and HQ3 for an extra, before processing again with Demucs.</span></p><p class="c1"><span class="c0">Also, this method is very good for leave good backing vocals into the instrumentals (only the ensemble result). I find extracting bv from the Vocal Stem to be less effective, giving you less material (comparing if you would join the bv with instrumentals later)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c40 c36 c33 c30">M.Contini Method #2 (newer)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Well, I tried to improve the results of the method I posted, so here it is, for **anyone interested in get fuller Instrumentals**, with a bit of bleed in some songs, wielding great results overall.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I&#39;m doing this in the UVR-gui. The idea behind it is to scoop the vocals little by little, so the instrumentals is preserved the most. The proccess requires 3 extractions. Here are the Ensembles:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1. pass Ensemble: 5_HP-Karaoke-UVR + Inst HQ3 + htdemucs - Min/ Max</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;- If the song doesn&#39;t have BV, this will already give you good Instrumental Stem results. If you have Vocals bleeding into the Instr, continue to pass 2, but sometimes jumping straight to pass3 will produce better results.</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;- If the song have BV, this you keep a fuller **Instrumental Stem with BV** in it. If you want to keep the BV, but there is some Main Vocals bleeding through the Instr, continue to pass 2.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2. pass Ensemble: Kim Vocal 2 + Inst HQ3 + MDX Karaoke 2 - Min/Max</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;- This pass will try to preserve the BV in the Instrumental Stem while removing Main Vocal bleed. You can stop here if you want the **Instrumental Stem with BV**</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3. pass Ensemble: Kim Inst + Inst HQ3 + htdemucs - Min/Max</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;- This pass will try to remove BV from the instrumental Stem and other Main Vocal Bleed while keep the Instrumental fuller.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The idea behind it, is to have less volume variation where the vocals are extracted, leaving the Instrumental Stem less muddy. Since the extraction of the vocals is done little by little using the Min/Max, the Models will not be so aggressive. This is a great starting point if you want to improve further in a DAW or just sing over it. The Con is that, sometimes, the track will have tiny bleeds. If you try this method, please post the results here.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">#3</span></p><p class="c1"><span class="c0">- -try this ensemble: 9_HP (10 agression) + HQ3 (chunks on) + demucs_ft, Min/Max</span></p><p class="c1"><span class="c0">- it preserves most of the instruments.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c40 c36 c33 c30">M. Contini method #4 (new)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Another Ensemble suggestion for good instrumentals with minimized bleeding vocals and a bit of noise in some cases:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ensemble: 9_HP + HQ3 + Demucs_6s (secondary model 50%: full_292) - Algorithm [min/max]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Configs:</span></p><p class="c1"><span class="c0">9_HP Window[512], Agress[10], TTA[on], Post[off], High-End [off])</span></p><p class="c1"><span class="c0">HQ3 Chunks[on] [auto], Denoise[on], Spectral[off]</span></p><p class="c1"><span class="c0">Demucs_6s Chunks[on] [auto], Split[off], Combine[off], Spectral[off], Mixer[off], Secondary Model - Vocals/Instr [MDX-Inst_full_292] [50%]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Why Demucs_6s and not _ft - I compare them in some songs and 6s have less vocal bleed in the instrumental track.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Description:</span></p><p class="c1"><span class="c0">The idea is to take the good bits of the models using only one from each Group (VR, MDX and Demucs). The secondary model on Demucs is to minimize some vocal bleeding with sustained notes that was happening in some songs.</span></p><p class="c1"><span class="c0">Comparing the results from multiple models, I find that Chunks enabled on MDX and Demucs removes some bleeding vocals from the Instrumental track and gives better results overall. This ensemble in my machine completes in about 5 min per song (GTX 1070 8GB, 16GB RAM, Ryzen 1600x). [chunks have been replaced by newer method in newer UVR GUI versions]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">____________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;The best combo is the HQ instrument models ensemble average/average including HQ3/Main/Main Inst/Kim1/2/Kim Inst/demucs3 (mdx_extra)/htdemucs_ft/hdtdemucs6s&rdquo; (MohammedMehdiTBER)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Wow, I tried out the ensemble with all those models you said, and it actually sounds pretty good. There&#39;s a definitely more vocal bleed but in a saturated/detailed distortion type of way. I can&#39;t tell which one I like better, the ensemble sounds more full and has more detailed frequencies, but the vocal bleed is a lot more obvious. The HQ_3 by itself has almost no vocal bleed but sounds more thin and watery.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Kim instr + mdx net instr3 + HQ2 + HQ3 + voc ft max/max</span></p><p class="c1"><span class="c0">The result is so amazing&hellip; Now can hear more detail on instrumental result where before I cannot hear a bit of music parts. (Henry)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;I am very much enjoying making an ensemble of HQ3 and MDX23C_D1581, then inverting the vocals into the instrumental and running that through hq3 with 0.5 overlap&quot; (Ros&eacute;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">__________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Ensembles for specific genres</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Evaluation based on public models available at 23.04.23 and multisong dataset on MVSEP. The list might be outdated, as it doesn&rsquo;t take all the current models into account.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">SDR sorted by genre</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">By Bas Curtiz</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;If we remove **Kim vocal 2**, so only those that are available right now will be taken into account:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ensemble Rating 1 scores highest on average overall</span></p><p class="c1"><span class="c0">[Probably this one:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/974&amp;sa=D&amp;source=editors&amp;ust=1765035743580573&amp;usg=AOvVaw2WgUmvRzlfyY5J7kN0-tGn">Kim vocal 2 + Kim FT other + Inst Main + 406 + 427 + htdemucs_ft | Avg/Avg</a></span></p><p class="c1"><span class="c0">At least it was the best for the given date.</span></p><p class="c1"><span class="c0">But now we have ensembles which score better.]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Kim vocal 1 is best for Rock</span></p><p class="c1"><span class="c0">- Kim vocal 1 &amp; Ensemble Rating 1 are best for RnB/Latin/Soul/Funk</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX&#39;23 Best Model is best for Pop</span></p><p class="c1"><span class="c0">- Main 427 &amp; MDX&#39;23 Best Model are best for Other</span></p><p class="c1"><span class="c0">- Main 427 &amp; MDX&#39;23 Best Model are best for Blues/Country</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Main 427 &amp; Ensemble Rating 1 are best for Jazz</span></p><p class="c1"><span class="c0">- Main 427 &amp; Ensemble Rating 1 are best for Acoustic genres</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ensemble Rating 1 is best for Beats</span></p><p class="c1"><span class="c0">- Ensemble Rating 1 is best for Hip Hop</span></p><p class="c1"><span class="c0">- Ensemble Rating 1 is best for House</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sheet where **Kim vocal 2 **is removed:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1ceXA7XKmECwnsQvs7a0S81XZOUokIXUN8ndsUDcYRcc/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743582890&amp;usg=AOvVaw3fRvbQJfN0itkuOwvLiZeW">https://docs.google.com/spreadsheets/d/1ceXA7XKmECwnsQvs7a0S81XZOUokIXUN8ndsUDcYRcc/edit?usp=sharing</a></span><span>&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Further single MDX-UVR models descriptions</span></p><p class="c1"><span class="c0">E.g. used for ensembles above, but if a model has a cutoff, using ensemble with models/AIs without cutoff like Demucs 2-4 will fill the gap above. But it&#39;s still a good alternative for people without decent Nvidia GPUs or are force to use Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">UVR-MDX models naming scheme</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">All models called &quot;main&quot; are vocal models.</span></p><p class="c1"><span class="c0">All models called &quot;inst&quot; and &quot;inst main&quot; are instrumentals.</span></p><p class="c1"><span class="c0">NET-X [9.X/9.XXX in Colab] are vocal models</span></p><p class="c1"><span class="c0">Kim vocal 1/2 (self-explanatory)</span></p><p class="c1"><span class="c0">Inst main is 496</span></p><p class="c1"><span class="c0">Kim other ft is Kim inst</span></p><p class="c1"><span class="c0">Model labelled as just &lsquo;main&rsquo; is vocal, and was reported to have the same checksums as 427 and 423, but it doesn&#39;t seem to be true as 427 and main have different SDR (427 has better SDR than main, so apparently main is 423 [CRC32: E3C998A6]).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX HQ_1/2 models - excellent, vivid snares, no cutoff (22kHz) high quality, rarely worse results than narrowband inst1-3 models, HQ_2 might have slightly less loud snares, but can have fewer problems with removing some vocals from instrumentals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MDX-UVR Inst 3 model (464) - 17.7 cutoff (the same cutoff as for Inst 1, 2 inst main, but maybe not applicable for vocals after inversion in Colab), it was the third-best single model in our </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard.php&amp;sa=D&amp;source=editors&amp;ust=1765035743586098&amp;usg=AOvVaw3qG2mRJS7ItwH4XXTTe9_u">SDR chart</a></span><span>&nbsp;at the time, available in Colab </span><span class="c4"><a class="c3" href="#h.zaimpsi6j19a">update</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035743586359&amp;usg=AOvVaw1dMkRtIbrNFgp_emUKJH3r">UVR5 GUI</a></span><span>&nbsp;with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035743586514&amp;usg=AOvVaw05k0s6XY6N63wp6US3c7nT">VIP models package</a></span><span class="c0">&nbsp;- now available for free.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Forth-best single model for instrumentals back then was inst main (496, MDX 2.1), then inst 1 and inst2.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- There was some confusion about MDX 2.1 model (iirc on x-minus) being vocal 438 (even 411), but it&rsquo;s currently inst main.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Full band MDX-Net models without cutoff (better SDR than Demucs 4 ft)</span></p><p class="c1"><span>As for SDR, the epochs score is following: 292&lt;403&lt;386&lt;(inst 1)&lt;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/1tdgFTaJ%23AiiXwWWjmAuHb-Cebj5LpWezkXcJKWJsp8LHzFuNvho&amp;sa=D&amp;source=editors&amp;ust=1765035743587583&amp;usg=AOvVaw1cL5P_2nDlz0V-uiC9QGde">338</a></span><span class="c0">&lt;382&lt;309&lt;337</span></p><p class="c1"><span class="c0">&lt;450 (first final, HQ_1)&lt;498 (HQ_2)&lt;(inst3)&lt;(Kim inst)&lt;HQ_3&lt;HQ_4</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Epochs 292, 403 and 450 and newer are also in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kae0-0/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743588184&amp;usg=AOvVaw3Jns93ZmXLANni8aFz7NWT">Colab</a></span><span class="c0">&nbsp;(and in UVR5, older when VIP code is redeemed)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (currently the best, maybe not single model, but custom ensemble, as for vocals) MDX23 in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1086720481962496000&amp;sa=D&amp;source=editors&amp;ust=1765035743588761&amp;usg=AOvVaw2jY9lwxXSmY0T6Adyuk3Bx">MVSEP beta</a></span><span class="c0">, </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">and in UVR5 - Kim vocal model - </span></p><p class="c1"><span class="c0">It&#39;s a further trained MDX-UVR vocal model from their last epoch (probably UVR-MDX-NET Main). It&#39;s based on a higher n_fft scale which uses more resources.</span></p><p class="c1"><span class="c0">Not always gives that good results for instrumental as SDR may suggest, and also more people shares that opinion [both Colab and UVR users, so i&rsquo;ts not due to no cutoff in Colab]).</span></p><p class="c1"><span class="c0">In UVR5 generally for the best vocal result use vocal models, and for the best instrumental result use instrumental models or eventually 4 stem Demucs 4 ft.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&quot;[Kim_Vocal_1] is an older model (November), than Kim uploaded at 2022-12-04 to&quot; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard.php?sort%3Dinsrum%26ensemble%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035743590069&amp;usg=AOvVaw0GyRjwT4SDT6hPuq163WI2">https://mvsep.com/quality_checker/leaderboard.php?sort=insrum&amp;ensemble=0</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(steps below no longer necessary, the model is added to GUI and these are the same models)</span></p><p class="c1"><span>You can download her (so-called &ldquo;old&rdquo;) model from here (it still gets better results for vocals than inst 3 and main): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1exdP1CkpYHUuKsaz-gApS-0O1EtB0S82?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743590762&amp;usg=AOvVaw3rqesukNyIEhGcdvifov_U">https://drive.google.com/drive/folders/1exdP1CkpYHUuKsaz-gApS-0O1EtB0S82?usp=sharing</a></span></p><p class="c1"><span class="c0">When you copy/paste the model in `C:\Users\YOURUSERNAME\AppData\Local\Programs\Ultimate Vocal Remover\models\MDX_Net_Models` It asks you to configure, hit Yes.</span></p><p class="c1"><span class="c0">Then change `n_fft to 7680`.&quot;</span></p><p class="c1"><span class="c0">For instrumentals, it gets worse results, frequently with more bleeding, and UVR manually applies cutoff above training frequency to instrumentals after inversion, to avoid some noise and possibly bleeding. Colab version of Kim model doesn&rsquo;t have that cutoff, so instrumentals as a result of inversion have max 22kHz frequency (but UVR applies it to prevent some noise).</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">- (generally outperformed by models above) </span><span class="c4 c20"><a class="c3" href="#h.pv80l0nr97r5">MDX-UVR 9.7 vocal model</a></span><span>&nbsp;a.k.a. UVR-MDX-NET 1 (instrumental is done by inversion, older model)</span><span class="c20">&nbsp;</span><span>- available in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/189nHyAUfHIfTAXbm15Aj1Onlog2qcCp0?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743592223&amp;usg=AOvVaw29eIjSiEoUQAXzKez8cZ0G">Google Colab</a></span><span>/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com&amp;sa=D&amp;source=editors&amp;ust=1765035743592291&amp;usg=AOvVaw0LCjKxUazvwx5L39Vx6uGq">mvsep</a></span><span>&nbsp;(here 24 bit for instrumentals)/</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035743592429&amp;usg=AOvVaw3PbRjj2j73D7lHhohpx-bL">UVR5 GUI</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">Compared to 9.682 NET 2 model, it might have better results on vocals, where 9.682 NET might have better results for instrumentals, but everything might still depend on a song. Generally, 9.7 model got better SDR both in Sony Demixing Challenge and on MVSEP. Generally, 438 vocal, or 464 inst_3 should give better results for instrumentals. 427 vocal model tends to give worse results for instrumentals than even this older 9.7/NET1 model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">More about MDX-UVR models -</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If they don&#39;t have more vocal bleeding than GSEP, they&rsquo;re better in filtering more vocal leftovers which sometimes GSEP tend to leave (scratches, additional vocal sounding sounds, also so-called &ldquo;cuts&rdquo; [short multiple lo-fi vocal parts] which GSEP doesn&rsquo;t catch, but MDX-UVR does probably due to bigger dataset). But using single instrumental MDX-UVR models instead of ensemble will result in cut off of a training frequency (e.g. 17.7kHz or lower).</span></p><p class="c1"><span class="c0">Also, MDX-UVR like GSEP may not have this weird constant &quot;fuzz&quot; which VR models tend to leave as vocal leftovers (but in other cases, 9.7 model can leave very audible vocal residues, so test out everything on this list, till you get the best result).</span></p><p class="c1"><span class="c0">The 9.7 model (or currently newer models) is also good for cleaning inverts (e.g. when having lossy a cappella and regular song).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you tested all the alternatives, and you stick to the MDX-UVR 9.7 for some song, and it doesn&#39;t have (too much) bleeding, to fine-tune the results you can try out two 9.6 models to check whether it&#39;s better for you than 9.7 in this specific case (they&#39;re available at least in HV Colab and UVR5 GUI).</span></p><p class="c1"><span class="c0">Newer MDX-UVR 423 vocal model usually provides more audible leftovers than 9.7 model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To further experiment with MDX-UVR results, and you&rsquo;re stuck with Colab, you can enable Demucs 2 model on Colab to &quot;ensemble&quot; it with MDX-UVR model (although metrics say it slightly decreases SDR, I like what it does in hi-end - it was suspected at some point the SDR decreasing problems may come out from enabling chunking). </span></p><p class="c1"><span class="c0">________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.m9ndauawzs5f">Demucs 4</a></span><span class="c0">&nbsp;(htdemucs_ft) - no cutoff, it&rsquo;s 4 stem, but you can perform mixdown without vocals in Audacity for instrumental - sometimes it may give you louder snare than in GSEP, but usually muffled shakers compared to GSEP. Also, it will give you more vocal residues than GSEP and MDX-UVR 464 (Inst 3). 6 stem models gives more vocal residues than 4 stem model (ft is the best one and also outperformed mdx_extra model [better than mdx_extra_q - quantized) but in some cases that might be worth to check old mdx_extra model as well (but </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (outperformed in many cases when used at least as a single models) </span></p><p class="c1"><span class="c4 c20"><a class="c3" href="#h.rdfatusyntt1">VR-architecture models</a></span><span class="c0">&nbsp;(Colab, CLI or UVR5 GUI) sometimes provide cleaner and less muddy results for instrumentals than single narrowband models of MDX or even GSEP, only if they do not output too much vocal bleeding (which really happens for VR models frequently - especially for heavily processed vocals in contemporary music), but bleeding also depends on specific model:</span></p><p class="c1"><span>- E.g. </span><span class="c20">500m_1 (9_HP2-UVR) and MSB2 (7_HP2-UVR)</span><span class="c0">&nbsp;models are the most aggressive in filtering vocals among VR models, but other, less aggressive VR models may provide better sounding, less spoiled instrumentals (only if it is not paid for with worse vocal bleeding [BTW. I haven&rsquo;t heard the newest 2022 VR model yet (available at least in UVR5 GUI, maybe for Patreons, not sure]). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>All parameters and settings corresponding to specific models you&rsquo;ll find in &ldquo;</span><span class="c4"><a class="c3" href="#h.atxff7m4vp8n">VR architecture models settings</a></span><span class="c0">&rdquo; section.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">- </span><span class="c4 c20"><a class="c3" href="#h.rv7wwzcmuq3s">VR models-only ensemble settings</a></span><span class="c20">&nbsp;- </span><span class="c0">if your track doesn&rsquo;t have too many problems with bleeding using VR-models above, to fine-tune the results achieved with VR, and to get rid of some mud, and e.g. get better sounding drums in the mix, I generally recommend VR-architecture models ensemble with settings I described in the linked section above. </span></p><p class="c1"><span class="c0">I&#39;d say it&#39;s pretty universal, though the most time/resource-consuming method.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Also, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/1054893075056562236/1060720863361650728/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743599466&amp;usg=AOvVaw1JL9tI9nRpWEVqsx2Zzq5o">these</a></span><span class="c0">&nbsp;ensemble settings from the UVR HV Colab seem to make decent job for extracting vocals in some cases when above solutions failed (e.g. claps leftovers).</span></p><p class="c1"><span class="c0">Check also demucs_6s with 9 HP UVR and gsep in min-specs mode</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, UVR5 GUI has rewritten MDX, so it can use their Demucs-UVR models from Demucs 3 (I think mvsep doesn&#39;t provide ensembling for any MDX models):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (generally outperformed by MDX-UVR 4xx models) </span><span class="c20">Demucs-UVR models</span><span>&nbsp;- 1 and 2 models beside &quot;bag&quot; are worth trying out (mainly 1) on their own if the results achieved with above methods still provide too much bleeding - better results than e.g. bare MDX-UVR 9.7 or VR models or even GSEP in some specific cases (available on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com&amp;sa=D&amp;source=editors&amp;ust=1765035743600833&amp;usg=AOvVaw2KoOwK2zBYjYjEjHr-2_Ib">MVSEP</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035743601001&amp;usg=AOvVaw3uhWYi4L2htRZy5ctuabxZ">UVR5 GUI</a></span><span class="c0">). They&#39;re Demucs 3, 2 stem better trained models by UVR team. No cutoff - 22kHz.</span></p><p class="c1"><span class="c0">_______________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- As for extracting -</span></p><h4 class="c17" id="h.h110k6ouf88c"><span class="c22">Karaoke / </span><span class="c42 c22 c51 c58 c24 c30">Backing Vocals </span></h4><p class="c1"><span>(more up-to date, but less descriptive list at the </span><span class="c4"><a class="c3" href="#h.rz0d5zk9ms4w">top</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">check MDX-UVR Karokee 2 model (available on MVSEP, UVR 5 GUI)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">TL;DR - &quot;Usually MDX B Karaoke has really good lead vocals and UVR Karaoke has really good backing vox&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;There are 3 good karaoke models (the ones I&#39;m referring to are on mvsep.com [they seem to be no longer available there]). &quot;MDX B (Karaoke)&quot; seems to be the best at getting lead vocals from karaoke while &quot;karokee_4band_v2_sn&quot; (UVR) and &quot;HP_KAROKEE-MSB2-3BAND-3090&quot; (UVR) seem to be best for backing vocals. I recommend using a mix of the 3 to get as many layers as possible, and then use Melodyne to extract layers as best as possible. Then combine the filter results and Melodyne and you should have smthn that sounds pretty good&quot; karokee_4band_v2_sn model might be not compatible with Colab (check mvsep or UVR5 GUI)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Demix Pro may do a better job in B.V. than models on x-minus.</span></p><p class="c1"><span class="c0">Even than the new model on x-minus since 01.02.23, but might be worth trying out on some songs (the problem is probably bound to MDX architecture itself).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;MDX in its pure form is too aggressive and removes a lot of backing vocals. However, if we apply min_mag_k processing, the results become closer to Demix Pro&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Medley Vox</span></p><p class="c1"><span>(installation </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/VbM4qp0VP80&amp;sa=D&amp;source=editors&amp;ust=1765035743604301&amp;usg=AOvVaw2-RFGUb3eKHm6LbQII0axN">tutorial</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">For separating different voices, including harmonies or backing vocals check out this vocal separator, the demos sound quite good and Cyrus model has pretty similar results.</span></p><p class="c1"><span class="c0">It&#39;s for already separated or original acapellas. Sometimes it gives better results than BVE models. Output sample rate is 24kHz, but it can be easily upscaled by AudioSR well.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Org. repository</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jeonchangbin49/medleyvox&amp;sa=D&amp;source=editors&amp;ust=1765035743605315&amp;usg=AOvVaw2BDbqh76WTQ8skqXXSOHF9">https://github.com/jeonchangbin49/medleyvox</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Old info (dead link): </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/900904142669754399/1050444866464784384/Screenshot_81.jpg&amp;sa=D&amp;source=editors&amp;ust=1765035743605911&amp;usg=AOvVaw0hiTbPk0XA0RMSrBmztETV">https://media.discordapp.net/attachments/900904142669754399/1050444866464784384/Screenshot_81.jpg</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">How to get vocals stems by using specific models:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Song -&gt; vocal model -&gt; Voc &amp; Inst</span></p><p class="c1"><span class="c0">Vocal model -&gt; Karaoke model -&gt; Lead_Voc &amp; Backing_Voc</span></p><p class="c1"><span class="c0">Lead_Voc + Inst = Lead_Inst </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- How to get backing vocals using x-minus</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/page/bv-isolation?locale%3Den_US&amp;sa=D&amp;source=editors&amp;ust=1765035743607034&amp;usg=AOvVaw3tFtds4JUdcbbaG3Nxj8ZC">https://x-minus.pro/page/bv-isolation?locale=en_US</a></span></p><p class="c1"><span class="c0">&ldquo;Method two is terrible and I do not recommend it&rdquo; - Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-If you have x-minus subscription, you can use chain mode for Karaoke as it currently gives the best results</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">How it probably works under the hood?</span></p><p class="c1"><span>&quot;On sitting down and reading &nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/900904142669754399/1071599186350440540&amp;sa=D&amp;source=editors&amp;ust=1765035743607932&amp;usg=AOvVaw3d_OFO21fr33EHDogYEaso">https://discord.com/channels/708579735583588363/900904142669754399/1071599186350440540</a></span></p><p class="c1"><span class="c0">It&#39;s a multistep process where it mixes a little bit from MDX&#39;s split vocals and instruments.</span></p><p class="c1"><span class="c0">Then passes that mixture through the UVR v2 karaoke/backing vocals model.</span></p><p class="c1"><span>Then with those results, it inverts the separated lead vocal, and adds it to the instrumental result&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- As for </span><span class="c12">4 stem</span><span>&nbsp;</span><span class="c22">separation</span><span>, check GSEP or </span><span class="c4"><a class="c3" href="#h.m9ndauawzs5f">Demucs 4 </a></span><span>(now check better MDX23 Colab by jarredou)</span></p><p class="c1"><span class="c0">(other stem is usually the best in GSEP, bass in Demucs 4, rest depends also on a song, and as for drums, if you further process them in DAW using plugins, then Demucs 4 is usually better as it&#39;s lossless and supports up to 32-bit float output).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Demucs 4 has also experimental </span><span class="c22">6 stem</span><span class="c0">&nbsp;feature. Guitar (can give good results) and piano (it&#39;s bad and worse than GSEP).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- As for free </span><span class="c12">electric guitar </span><span class="c22">and</span><span class="c12">&nbsp;piano stems,</span><span class="c0">&nbsp;currently GSEP and MVSEP models are the best, but paid Audioshake provides better results than GSEP. Also in GSEP &quot;when the guitar model works (and it grabs the electric), the remaining &#39;other&#39; stem often is a great way to hear acoustic guitar layers that are otherwise hidden.&quot;. LALAL.AI also has piano model and is &ldquo;drastically&rdquo; better than Demucs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- From paid solutions for separating drums&#39; sections, there are </span><span class="c4"><a class="c3" href="#h.cz4j2d3uf48s">FactorSynth</a></span><span>, UnmixingStation, or free </span><span class="c4"><a class="c3" href="#h.2u19k7ty9b00">Drumsep</a></span><span>&nbsp;(but rather use MDX23C model)</span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- As for specific sounds separation, check </span><span class="c4"><a class="c3" href="#h.g37f4a6hnxm0">Zero Shot Audio</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">______</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Cutoffs examination with spectrograms for various models and AIs, available in UVR5 GUI, along with examined times needed for each model to process on CPU or GPU (1700x/1080 Ti) by Bas Curtiz (cutoffs examination not applicable for MDX Colab where there is none unlike in UVR [it&#39;s to prevent noise]):<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1R_pOURv8z9GmVkCt-x1wwApgAnplM9SHiPO_ViHWl1Q/edit%23gid%3D23473506&amp;sa=D&amp;source=editors&amp;ust=1765035743611947&amp;usg=AOvVaw0jB6Bfdf290IYopQZjkHxi">https://docs.google.com/spreadsheets/d/1R_pOURv8z9GmVkCt-x1wwApgAnplM9SHiPO_ViHWl1Q/edit#gid=23473506</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Spreadsheet of songs that use Vocals as a melody with snippets how they separate on various models/AIs</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://vocalisolationtesting.x10.mx/&amp;sa=D&amp;source=editors&amp;ust=1765035743612366&amp;usg=AOvVaw26fgxrG6hW_jnyohA5-n-k">http://vocalisolationtesting.x10.mx/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">___</span></p><p class="c1"><span>In below sections you&rsquo;ll find more details, links, Colabs, all tools/AIs listed, more information about specific models as alternatives to experiment further (mostly MDX-UVR instrumental and vocal models available in UVR5 GUI and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/ai&amp;sa=D&amp;source=editors&amp;ust=1765035743613038&amp;usg=AOvVaw3Tgt2mRp8_1CfYre8VMsdC">https://x-minus.pro/ai</a></span><span>&nbsp;and MVSEP)</span><span class="c0">. I also provide some technicalities/troubleshooting everywhere when necessary.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_________________________________________________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.sm5m61aib1vx"><span class="c18 c15">Table of content</span></h6><p class="c1"><span class="c20">(click on an entry to be redirected to a specific section; <br>the section is outdated - check it in document outline instead if you can)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.k3vca4e9ena8">Last updates and news&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.k3vca4e9ena8">1</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.2vw7f9wat3nv">General reading advice&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.2vw7f9wat3nv">30</a></span></p><p class="c13 c7"><span class="c18 c15"></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.sosams1g0zrm">Instrumental, vocal, stems separation &amp; mastering guide</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.rz0d5zk9ms4w">The best models</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.8o01ot6sjxel">for specific stems</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.2vdz5zlpb27h">for instrumentals&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.2vdz5zlpb27h">31</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.n8ac32fhltgg">for vocals&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.n8ac32fhltgg">34</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.p1fyricuv1j8">How to check whether a model in UVR5 GUI is vocal or instrumental?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.p1fyricuv1j8">39</a></span></p><p class="c13 c39"><span class="c15">for k</span><span class="c15"><a class="c3" href="#h.vg1wnx1dc4g0">araoke&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.vg1wnx1dc4g0">39</a></span></p><p class="c13 c39"><span class="c15">for</span><span class="c15"><a class="c3" href="#h.sjf0vefmplt">&nbsp;4-6 stems (drums, bass, others, vocals + opt. guitar, piano):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.sjf0vefmplt">43</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.owqo9q2d774z">SFX&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.owqo9q2d774z">45</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.5zlfuhnreff5">De-reverb&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.5zlfuhnreff5">46</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.hyzts95m298o">Vinyl noise/white noise (or simply noise)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.hyzts95m298o">50</a></span></p><p class="c13 c39"><span><a class="c3" href="#h.86cdyl2tgclm">Mixing and mastering</a></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>51</span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.kmvf6iw5hfvm">Audio upscalers list&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.kmvf6iw5hfvm">52</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.gdihug899mot">More descriptions of models&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.gdihug899mot">53</a></span></p><p class="c13 c61"><span class="c15">&nbsp; &nbsp; &nbsp; </span><span class="c15"><a class="c3" href="#h.6q2m0obwin9u">MDX settings in UVR5 explained&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.6q2m0obwin9u">57</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.929g1wjjaxz7">Tips to enhance separation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.929g1wjjaxz7">63</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.xya7mtyl0m39">Other ensembles in UVR5 - list&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.xya7mtyl0m39">71</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.n0f4tib5eipp">50 models sorted by SDR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.n0f4tib5eipp">87</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.ak53injalbkf">Separating speakers in recording&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.ak53injalbkf">93</a></span></p><p class="c13"><span class="c15">General section of </span><span class="c15"><a class="c3" href="#h.czix2y8eiuna">UVR5 GUI (MDX-Net, VR, Demucs 2-4, MDX23</a></span><span><a class="c3" href="#h.czix2y8eiuna">) &hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;. 95</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.ul5en196k909">GUI FAQ &amp; troubleshooting&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.ul5en196k909">96</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.4t9vx74g45zt">Chunks may alter separation results&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.4t9vx74g45zt">99</a></span></p><p class="c13"><span><a class="c3" href="#h.tb9spo3rgthx">Q: Why I shouldn&rsquo;t use more than 4-5 models for UVR ensemble (in most cases).............100</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.yx8u0ahol7ao">(older) UVR &amp; x-minus.pro updates&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.yx8u0ahol7ao">101</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.16gdep9n4hi3">MVSEP models from UVR5 GUI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.16gdep9n4hi3">107</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.surlvvp6mr8f">Manual ensemble Colab for various AI/models&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.surlvvp6mr8f">108</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.h952n842ljfj">Joining frequencies from two models&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.h952n842ljfj">109</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.oxd1weuo5i4j">DAW ensemble&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.oxd1weuo5i4j">110</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.wbhpqttnrw7b">Manual ensemble in UVR5 GUI of single models from e.g. Colabs&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.wbhpqttnrw7b">110</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.wjd2zth0azhs">UVR&rsquo;s VR architecture models </a></span><span><a class="c3" href="#h.7j2ewdqsy5qw">(settings and recommendations)</a></span><span class="c15"><a class="c3" href="#h.7j2ewdqsy5qw">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.7j2ewdqsy5qw">110</a></span></p><p class="c13"><span class="c15">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c15"><a class="c3" href="#h.rdfatusyntt1">VR Colab by HV&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.rdfatusyntt1">110</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.atxff7m4vp8n">VR settings&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.atxff7m4vp8n">111</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.1wojovpsoqy">VR models settings and list&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.1wojovpsoqy">113</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.rv7wwzcmuq3s">VR ensemble settings&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.rv7wwzcmuq3s">116</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.nj23a76dbn89">VR Colab troubleshooting&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.nj23a76dbn89">123</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.87ny11r7l9">First vocal models trained by UVR for MDX-Net arch:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.87ny11r7l9">125</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.zaimpsi6j19a">(the old) Google Colab by HV&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.zaimpsi6j19a">126</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.aa2xhwp434">Upd. by KoD &amp; DtN &amp; Crusty Crab &amp; jarredou, HV (12.06.23)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.aa2xhwp434">126</a></span></p><p class="c13 c8"><span class="c0">Other archs general section</span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.99i5nkp6p5v0">Demucs 3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.99i5nkp6p5v0">134</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.m9ndauawzs5f">Demucs 4 (+ Colab) (4, 6 stem)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.m9ndauawzs5f">135</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.yy2jex1n5sq">Gsep (2, 4, 5, 6 stem, karaoke)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.yy2jex1n5sq">139</a></span></p><p class="c13"><span class="c15 c22">D</span><span class="c15 c22"><a class="c3" href="#h.xdux18tet3x9">ango.ai&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.xdux18tet3x9">144</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.jmb1yj7x3kj7">MDX23 by ZFTurbo /w jarredou fork (2, 4 stems)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.jmb1yj7x3kj7">145</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.7kniy2i3s0qc">KaraFan by Captain FLAM (2 stems)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.7kniy2i3s0qc">149</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.f0orpif22rll">Ripple/SAMI-Bytedance/Volcengine/Capcut (Jianying)/BS-RoFormer (2-4 stem)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.f0orpif22rll">152</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.m55fp5i7rdpm">Single percussion instr</a></span><span class="c22"><a class="c3" href="#h.m55fp5i7rdpm">uments</a></span><span class="c15 c22"><a class="c3" href="#h.m55fp5i7rdpm">&nbsp;separation </a></span><span class="c22"><a class="c3" href="#h.m55fp5i7rdpm">(from drums stem)</a></span><span class="c15 c22"><a class="c3" href="#h.m55fp5i7rdpm">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.m55fp5i7rdpm">159</a></span></p><p class="c13 c26"><span class="c15 c22"><a class="c3" href="#h.jmjab44ryjjo">drumsep </a></span><span class="c15"><a class="c3" href="#h.jmjab44ryjjo">(free)</a></span><span class="c15"><a class="c3" href="#h.jmjab44ryjjo">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.jmjab44ryjjo">159</a></span></p><p class="c13 c26"><span class="c15"><a class="c3" href="#h.cz4j2d3uf48s">FactorSynth&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.cz4j2d3uf48s">160</a></span></p><p class="c13 c26"><span class="c15"><a class="c3" href="#h.buopqcmi0inj">Regroover&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.buopqcmi0inj">161</a></span></p><p class="c13 c26"><span class="c15"><a class="c3" href="#h.n8a91zv9lor0">UnMixingStation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.n8a91zv9lor0">161</a></span></p><p class="c13 c26"><span class="c15"><a class="c3" href="#h.ftdzxgety1hd">VirtualDJ 2023/Stems 2.0 (kick, hi-hat)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.ftdzxgety1hd">162</a></span></p><p class="c13 c26"><span class="c15"><a class="c3" href="#h.1bm9wmdv6hpf">RipX DeepAudio (-||-) (6 stems [piano, guitar])&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.1bm9wmdv6hpf">162</a></span></p><p class="c13 c26"><span class="c15"><a class="c3" href="#h.404qq7uhcrx5">Spectralayers 10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.404qq7uhcrx5">162</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.4svuy3bzvi1t">USS-Bytedance (any; esp. SFX)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.4svuy3bzvi1t">163</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.g37f4a6hnxm0">Zero Shot (any sample; esp. instruments)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.g37f4a6hnxm0">164</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.s4sjh68fo1sw">Medley Vox (different voices)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.s4sjh68fo1sw">165</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.t7yszids7p1p">About other services:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.t7yszids7p1p">167</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.eoh4mhmvzmrt">Spleeter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.eoh4mhmvzmrt">167</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.lmhpaip88xjn">Izotope RX-8/9/10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.lmhpaip88xjn">167</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.cbtg72bxj2sf">moises.ai (3 EU/month)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.cbtg72bxj2sf">167</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.colcze2vgkha">phonicmind&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.colcze2vgkha">167</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.wttisf5ujyf1">melody.ml&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.wttisf5ujyf1">167</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.76t56x1587z5">ByteDance&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.76t56x1587z5">167</a></span></p><p class="c13 c26"><span class="c15">R</span><span class="c15"><a class="c3" href="#h.z0rg2bewgfed">eal-time</a></span><span>&nbsp;separation</span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.920bb96xiyga">Serato&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.920bb96xiyga">167</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.ko20o19wn5vp">Stems 2.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.ko20o19wn5vp">168</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.mj9frri60cqr">Acon Digital Remix&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.mj9frri60cqr">168</a></span></p><p class="c13"><span>&nbsp; &nbsp; &nbsp; Misc</span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.oe4d2kewoelf">FL Studio (Demucs)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.oe4d2kewoelf">168</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.4r74hvaiyeik">Fadr.com from SongtoStems.com&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.4r74hvaiyeik">168</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.kbxqqeby51dw">Apple Music Sing&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.kbxqqeby51dw">168</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.zd7m35sh6zri">Music to MIDI transcribers/converters&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.zd7m35sh6zri">169</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.6xxrbp51to9n">Piano2Notes&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.6xxrbp51to9n">169</a></span></p><p class="c13 c8"><span class="c15 c22"><a class="c3" href="#h.tc4az79fufkn">Audioshake</a></span><span class="c15"><a class="c3" href="#h.tc4az79fufkn">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.tc4az79fufkn">169</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.51dyuze5xz9o">Lalal.ai&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.51dyuze5xz9o">170</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.4yn6zawn80la">DeMIX Pro V3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.4yn6zawn80la">171</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.bf9sv6h9xjaz">Hit&#39;n&#39;Mix RipX DeepAudio&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.bf9sv6h9xjaz">171</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.x7qk80tje220">Moises.ai&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.x7qk80tje220">172</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.krccq343z6z9">How to remove artefacts from an inverted acapella? (can be outdated)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.krccq343z6z9">174</a></span></p><p class="c13 c7"><span class="c0"></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.nspwy0bkpiec">Sources of FLACs for the best quality for separation process&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.nspwy0bkpiec">175</a></span></p><p class="c13 c26"><span class="c15"><a class="c3" href="#h.ueeiwv6i39ca">Dolby Atmos ripping&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.ueeiwv6i39ca">184</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.ki1wmwa90cgp">AI mastering services&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.ki1wmwa90cgp">186</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.tu3sw6pao8fp">How to </a></span><span><a class="c3" href="#h.tu3sw6pao8fp">g</a></span><span class="c15"><a class="c3" href="#h.tu3sw6pao8fp">et the </a></span><span><a class="c3" href="#h.tu3sw6pao8fp">b</a></span><span class="c15"><a class="c3" href="#h.tu3sw6pao8fp">est quality on YouTube for your audio uploads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.tu3sw6pao8fp">192</a></span></p><p class="c13"><span>How to get the b</span><span class="c15"><a class="c3" href="#h.6543hhocnmmy">est quality from YouTube and Soundcloud - squeeze out the most from the music taken from YT for separation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.6543hhocnmmy">193</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.nmqmya8t76oc">Custom UVR models&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.nmqmya8t76oc">195</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.40ggyvro35uu">Repository of other Colab notebooks&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.40ggyvro35uu">196</a></span></p><p class="c13 c39"><span class="c15"><a class="c3" href="#h.lc0zj8wttng0">Google Colab troubleshooting (old)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.lc0zj8wttng0">199</a></span></p><p class="c13 c7 c39"><span class="c0"></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.k3cm3bvgsf4j">Repository of stems/multitracks from music - for creating your own dataset&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.k3cm3bvgsf4j">200</a></span></p><p class="c13"><span class="c15"><a class="c3" href="#h.5haztbxg91rt">List of cloud services with a lot of space&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.5haztbxg91rt">205</a></span></p><p class="c13 c7"><span class="c18 c15"></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.37hhz9rnw7s8">AI killing tracks - difficult </a></span><span class="c22"><a class="c3" href="#h.37hhz9rnw7s8">songs </a></span><span class="c15 c22"><a class="c3" href="#h.37hhz9rnw7s8">to get instrumentals&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.37hhz9rnw7s8">211</a></span></p><p class="c13"><span class="c15 c22"><a class="c3" href="#h.bg6u0y2kn4ui">Training models guides&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span class="c22"><a class="c3" href="#h.bg6u0y2kn4ui">215</a></span></p><p class="c13"><span class="c15 c22">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c15"><a class="c3" href="#h.yhu13dizwjvi">Volume compensation for MDX models&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.yhu13dizwjvi">229</a></span></p><p class="c13"><span class="c15 c22">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c15"><a class="c3" href="#h.ntgu6se9g0u5">UVR hashes decoded by Bas Curtiz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.ntgu6se9g0u5">231</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.gzsz53bzhmzn">Local SDR testing script&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.gzsz53bzhmzn">233</a></span></p><p class="c13 c8"><span class="c15"><a class="c3" href="#h.dus2zjzbt7dg">Best ensemble finder for a song script&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a></span><span><a class="c3" href="#h.dus2zjzbt7dg">233</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_________________________________________________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Models master list</span></p><h3 class="c35 c27" id="h.n0f4tib5eipp"><span class="c19">50 models sorted by SDR</span></h3><p class="c1"><span class="c0">(from the public ones - so available to download and offline use)</span></p><p class="c1"><span class="c0">(07.10.2024)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c42 c15 c36 c58 c30">These are basically the top single models for now </span></p><p class="c1"><span class="c0">(conventionally after these, additional vocal residues kick in, especially if not a vocal model)</span></p><p class="c1"><span class="c0">Based on Multisong dataset evaluation on MVSEP chart with similar or the same parameters and inference if applicable.</span></p><p class="c1"><span class="c0"><br>Kim&rsquo;s Mel Roformer</span></p><p class="c1"><span class="c0">model_bs_roformer_ep_317_sdr_12.9755</span></p><p class="c1"><span class="c0">model_bs_roformer_ep_368_sdr_12.9628 (viperx/UVR beta)</span></p><p class="c1"><span class="c0">BS-Roformer_LargeV1 (unwa&rsquo;s ft)</span></p><p class="c1"><span class="c0">Unwa&#39;s Mel-Roformer Beta 3 (although for this day, SDR wasn&rsquo;t tested with the same parameters vs above, so it&rsquo;s based on assumption that unwa used the same parameters in synth dataset measurement)</span></p><p class="c1"><span class="c0">Unwa&#39;s Mel-Roformer Beta 4</span></p><p class="c1"><span class="c0">Unwa&#39;s Mel-Roformer Beta 5e</span></p><p class="c1"><span class="c0">0) InstVoc MDX23C HQ (fullband a.k.a. 1648, 8K FFT)</span></p><p class="c1"><span class="c0">0b) InstVoc MDX23C HQ 2 (fullband)</span></p><p class="c1"><span class="c0">1) voc_ft</span></p><p class="c1"><span class="c0">1b) UVR-MDX-NET HQ_4 (inst)</span></p><p class="c1"><span class="c0">2) MDX23C_D1581 (a.k.a. narrowband)</span></p><p class="c1"><span class="c0">3) Kim Vocal 2</span></p><p class="c1"><span class="c0">4) Kim Vocal 1</span></p><p class="c1"><span class="c0">5) UVR-MDX-NET_Main_427 (voc)</span></p><p class="c1"><span class="c0">6) UVR-MDX-NET_Main_406 (voc)</span></p><p class="c1"><span class="c0">7) UVR-MDX-NET HQ_5 (inst)</span></p><p class="c1"><span class="c0">7) UVR-MDX-NET HQ_3 (inst)</span></p><p class="c1"><span class="c0">8) UVR-MDX-NET_Main_438 (voc)</span></p><p class="c1"><span class="c0">9) UVR-MDX-NET_Main_390 (voc)</span></p><p class="c1"><span class="c0">10) Kim inst (a.k.a. other)</span></p><p class="c1"><span class="c0">11) UVR-MDX-NET_Main_340 (voc)</span></p><p class="c1"><span class="c0">12) Inst 3 (a.k.a. 464)</span></p><p class="c1"><span class="c0">13) UVR-MDX-NET HQ_2 (inst)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(for vocal models, here start those with more vocal residues in instrumentals - can be still handy for specific songs)</span></p><p class="c1"><span class="c0">+4 pos.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">9) Inst Main (496)</span></p><p class="c1"><span class="c0">10) Inst 2</span></p><p class="c1"><span class="c0">11) UVR-MDX-NET HQ1</span></p><p class="c1"><span class="c0">12) UVR-MDX-NET HQ 337 &gt;382&gt;338 epoch</span></p><p class="c1"><span class="c0">13) Inst 1</span></p><p class="c1"><span class="c0">14) HQ 386&gt;403&gt;292 epoch</span></p><p class="c1"><span class="c0">15) UVR-MDX-NET2&gt;NET3&gt;NET1&gt;9482 (NET3 a.k.a. 9.7)</span></p><p class="c1"><span class="c0">16) htdemucs_ft (4 stem) (S 10/O 0.95)</span></p><p class="c1"><span class="c0">17) hdemucs_mmi (4 stem)</span></p><p class="c1"><span class="c0">18) htdemucs_6s (6 stem)</span></p><p class="c1"><span class="c0">19) UVR-MDX-NET_Inst_82_beta</span></p><p class="c1"><span class="c0">20) Demucs3 Model B (4 stem)</span></p><p class="c1"><span class="c0">21) UVR-MDX-NET_Inst_187_beta</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(dango.ai, Audioshake, Bandlab not evaluated)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Somewhere here, trash begins (excluding GSEP)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">22) Moises.ai (probably before transition to newer Roformer models)</span></p><p class="c1"><span class="c0">23) DeMIX Pro 4.1.0</span></p><p class="c1"><span class="c0">24) Myxt (AudioShake 128kbps)</span></p><p class="c1"><span class="c0">25) UVR-MDX-NET_Inst_90_beta</span></p><p class="c1"><span class="c0">26) RipX DeepRemix 6.0.3</span></p><p class="c1"><span class="c0">27) kuielab_b (4 stem) (MDX Model B from 2021 MDX Challenge)</span></p><p class="c1"><span class="c0">28) kuielab_a (4 stem)</span></p><p class="c1"><span class="c0">29) LALAL.AI</span></p><p class="c1"><span class="c0">30) GSEP (6 stem) (although it sometimes gives much better results than its SDR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VR arch</span></p><p class="c1"><span class="c0">31) 7_HP2-UVR (a.k.a. HP2-MAIN-MSB2-3BAND-3090_arch-500m) </span></p><p class="c1"><span class="c0">32) 3_HP-Vocal-UVR</span></p><p class="c1"><span class="c0">33) 2_HP-UVR (HP-4BAND-V2_arch-124m)</span></p><p class="c1"><span class="c0">34) 9_HP2-UVR (HP2-4BAND-3090_4band_arch-500m_1)</span></p><p class="c1"><span class="c0">35) 1_HP-UVR (HP_4BAND_3090_arch-124m)</span></p><p class="c1"><span class="c0">36) 8_HP2-UVR (HP2-4BAND-3090_4band_arch-500m_2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">37) 14_SP-UVR-4B-44100-2 (4 band beta 2)</span></p><p class="c1"><span class="c0">38) &nbsp;4_HP-Vocal-UVR</span></p><p class="c1"><span class="c0">39) 13_SP-UVR-4B-44100-1 (4 band beta 1)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">39) 15_SP-UVR-MID-44100-1</span></p><p class="c1"><span class="c0">40) 16_SP-UVR-MID-44100-2</span></p><p class="c1"><span class="c0">41) 14_HP-Vocal-UVR</span></p><p class="c1"><span class="c0">42) VR | MGM_LOWEND_A_v4</span></p><p class="c1"><span class="c0">43) 12_SP-UVR-3B-44100</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">44) Demucs 2 (4 stem)</span></p><p class="c1"><span class="c0">(6 other old VR models proceeds)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">50) Spleeter 4 stems </span></p><p class="c1"><span class="c0">51) Spleeter 2 stems</span></p><p class="c1"><span class="c0">52) GSEP after mixdown from 4 stems separation</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c42 c15 c36 c20 c58">Only instrumental models listed (outdated)</span></p><p class="c1"><span class="c6">(4 stem and MDX23C models lies in all categories):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Tier 1</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX-Net models (trained by UVR team)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0) MDX23C HQ 1648 fullband</span></p><p class="c1"><span class="c0">1) MDX23C HQ 2 fullband</span></p><p class="c1"><span class="c0">1b) UVR-MDX-NET HQ_4 (inst)</span></p><p class="c1"><span class="c0">2) MDX23C_D1581 narrowband </span></p><p class="c1"><span class="c0">7) HQ3</span></p><p class="c1"><span class="c0">10) Kim inst (other)</span></p><p class="c1"><span class="c0">12) Inst 3</span></p><p class="c1"><span class="c0">13) HQ2</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Tier 2</span></p><p class="c1"><span class="c0">+4 pos.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">9) Inst Main (496)</span></p><p class="c1"><span class="c0">10) Inst 2</span></p><p class="c1"><span class="c0">11) HQ1</span></p><p class="c1"><span class="c0">12) HQ 337 &gt;382&gt;338 epoch</span></p><p class="c1"><span class="c0">13) Inst 1</span></p><p class="c1"><span class="c0">14) HQ 386&gt;403&gt;292 epoch</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Demucs 4</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">16) htdemucs_ft (S 10/O 0.95)</span></p><p class="c1"><span class="c0">17) hdemucs_mmi</span></p><p class="c1"><span class="c0">18) htdemucs_6s</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">20) Demucs 3 Model B (mdx_extra)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Tier 3</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(somewhere between place 9-20 might be dango.ai, Audioshake, later maybe Bandlab)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">22) Moises.ai </span></p><p class="c1"><span class="c0">23) DeMIX Pro 4.1.0</span></p><p class="c1"><span class="c0">24) Myxt (AudioShake 128kbps)</span></p><p class="c1"><span class="c0">26) RipX DeepRemix 6.0.3</span></p><p class="c1"><span class="c0">27) MDX-Net Model B from 2021 MDX Challenge (kuielab_b)</span></p><p class="c1"><span class="c0">28) kuielab_a</span></p><p class="c1"><span class="c0">29) LALAL.AI</span></p><p class="c1"><span class="c0">30) GSEP (although it sometimes gives much better results than its SDR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Tier 4</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VR arch</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">31) 7_HP2-UVR (a.k.a. HP2-MAIN-MSB2-3BAND-3090_arch-500m) </span></p><p class="c1"><span class="c0">33) 2_HP-UVR (HP-4BAND-V2_arch-124m)</span></p><p class="c1"><span class="c0">34) 9_HP2-UVR (HP2-4BAND-3090_4band_arch-500m_1)</span></p><p class="c1"><span class="c0">35) 1_HP-UVR (HP_4BAND_3090_arch-124m)</span></p><p class="c1"><span class="c0">36) 8_HP2-UVR (HP2-4BAND-3090_4band_arch-500m_2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Tier 5</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">37) 14_SP-UVR-4B-44100-2 (4 band beta 2)</span></p><p class="c1"><span class="c0">38) 13_SP-UVR-4B-44100-1 (4 band beta 1)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Tier 6</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">39) 15_SP-UVR-MID-44100-1</span></p><p class="c1"><span class="c0">40) 16_SP-UVR-MID-44100-2</span></p><p class="c1"><span class="c0">42) VR | MGM_LOWEND_A_v4</span></p><p class="c1"><span class="c0">43) 12_SP-UVR-3B-44100</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">44) Demucs 2</span></p><p class="c1"><span class="c0">(6 other old VR models proceeds)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Tier 7</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">50) Spleeter 4 stems </span></p><p class="c1"><span class="c0">51) Spleeter 2 stems</span></p><p class="c1"><span class="c0">52) GSEP after mixdown from 4 stems separation </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Differences by SDR divided for vocals and instrumentals are important to divide I think only in ensembles. In all other cases, if SDR is bigger for instrumentals in some model, it will be bigger for vocals vs the same model. At least only for ensembles there were so little differences that we had two top ensembles for both vocals and instrumentals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">__________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Hall of fame</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Great thanks to Anjok, Aufr33 (creators of UVR), KimberleyJSN a.k.a. Kim (model contributor and MDX/Roformers support), viperx (our former heavy user, supporter and now private models creator), tsurumeso (the creator of VR arch base code), BoskanDilan (creator of the old UVR GUI), IELab a.k.a Kuielab &amp; Woosung Choi (MDX-Net arch creators), ZFTurbo (creator of MVSEP, MDX23, and many models), GAudio (GSEP creators), Alexandre Deffosez a.k.a. Adefossez (Demucs creator), Bytedance with asriver (Roformer arch and Ripple app), lucidrains (for recreating the BS and Mel Roformer from released papers), jarredou (MDX23 fork, drumsep model, tons of support and work Colabs), Bas Curtiz (model trainer, insane amount of testing and UVR5 settings guidance, tutorials with SDR evaluating, models creator), Captain FLAM (KaraFan creator), unwa (for his Roformer fine-tunes and training advice), Gabox (-||-), becruily (model trainer, tons of advice), FoxyJoy (de-reverb, de-echo, denoise models), Not Eddy (UVR UI, Colabs, HF, KF fork), Sir Joseph (WebUI Colabs) - thanks to all of these people for the best freely available AI separation technologies and models so far, mesk (metal models and trianing guide).</span></p><p class="c1"><span class="c6">Special thanks for users of our Discord:</span></p><p class="c1"><span class="c20">HV (MDX and VR Colabs creator and UVR contributor), txmutt (Demucs Colab), CyberWaifu (lots of testing, some older Colabs), KoD/Mixmasher (first HV MDX Colab fork), dca100fb1 (a.k.a dca100fb8) (VR ppr bug, finding tons of UVR bugs and models testing and feedback), mesk (training guide and Roformers fine-tuning), </span><span>Isling (lot of testing and suggestions),</span><span class="c20">&nbsp;CyPha-SaRin (lots of models/UVR testing), BubbleG, &#5609;&#3619;&rho;&#3648;&#1108;&#1075;, Joe, santilli, RC, Matteoki (a.k.a. Albacore Tuna, our &ldquo;upscaling&rdquo; guru), Syrkov, ryrycd, Mikeyyyyy/K-Kop Filters, </span><span>Mr. Crusty </span><span class="c0">&#7580;&#691;&#7491;&#7495; (our mod; compensation values finding, MDX Colab mods and testing), knock (ZF&rsquo;s MDX23 fine-tuning), A5 (lots of feedback on existing models), Infisrael (MDX23 guide and model testing), Pashahlis/ai_characters (WhisperX guide and script), Sam Hocking (our most valuable pro sound engineer and industry insider), Kubinka (for his Colabs and coding help), Vinctekan (one of our most valuable sound engineers and tools creator), CC Karaoke, &ldquo;am able to use uvr with gpu&rdquo;/vernight (both lots of testing and advice), hendry.setiadi, raiboomdash (lots of model tests with vast descriptions), wancitte, essid64, makidanyee, </span></p><p class="c1"><span>&nbsp;- thanks </span><span class="c20">to</span><span class="c6">&nbsp;all of these people - for knowledge, help, testing and everyone whose advice, quotes and stuff appear in this doc. This guide wouldn&#39;t be created without you. If I forgot someone, forgive me.</span></p><p class="c1"><span class="c0">__________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can support UVR team by these links:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035743645907&amp;usg=AOvVaw3LDewPF7WKKomY5PTT_kSg">https://www.buymeacoffee.com/uvr5/vip-model-download-instructions</a></span></p><p class="c1"><span class="c0">and</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://boosty.to/uvr&amp;sa=D&amp;source=editors&amp;ust=1765035743646104&amp;usg=AOvVaw3T5HCZfVLHCRHvtoIAfCPb">https://boosty.to/uvr</a></span></p><p class="c1"><span>(subscription to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/ai&amp;sa=D&amp;source=editors&amp;ust=1765035743646274&amp;usg=AOvVaw0u15Gty-8EDHxyL8gA8Exq">https://x-minus.pro/ai</a></span><span class="c0">&nbsp;to process some VIP models there online)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you see duplicated models on the list in UVR5, click refresh.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">X-minus FAQ</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: how come level 1 will be eliminated? is it possible to leave it since i use this site very little and paying ( 2.79$ ) per month is too much and anyway 360 minutes of audio per week is a lot. i do 5/ 6 per week. it is a waste of minutes.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: If you renew your subscription several months in advance, you can use Level 1 even after removal. In addition, once your subscription Level 1 expires, you can use it for another month for free (after removing it in February).</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c59 c27" id="h.3c6n9m7vjxul"><span class="c42 c36 c51 c33 c24 c30">Similarity/Phantom Center/Mid channel Extractor</span></h5><p class="c1"><span class="c0">&ldquo;It extracts the phantom centre. I.e. what you hear as being in front of you in stereo audio&rdquo; &ldquo;very useful for older mixes. Like 60s songs with hard panning&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Dry Paint Dealer Undr (a.k.a. wesleyr36) released new Phantom Centre Models</span></p><p class="c1"><span class="c0">HTDemucs Similarity/Phantom Centre Extraction model:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/10PRuNxAc_VOcdZLHxawAfEdPCO6bYli3?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743648799&amp;usg=AOvVaw3tizxj7MIf-r67SLzYc-Tf">GDrive</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/jarredou/HTDemucs_Similarity_Extractor_by_wesleyr36/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035743648982&amp;usg=AOvVaw0Xkbo1G2cVmFTKZ-uJQUQu">HF</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743649181&amp;usg=AOvVaw3tr5qjSXUzaFYVoWDHULMr">Colab</a></span><span>&nbsp;</span><span class="c0">(it tends to be more &ldquo;correct&rdquo; in center extraction than the MDX23C model below)</span></p><p class="c1"><span class="c0">That Demucs model won&rsquo;t work with UVR giving bag_num error even with the yaml prepared in the same way as for Imagoy Drumsep and after renaming ckpt to th (it&rsquo;s probably because it needs ZFTurbo inference code it was trained with).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- SCNet Similarity/Phantom Centre Extraction model by Dry Paint Dealer:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1CM0uKDf60vhYyYOCg2G1Ft4aAiK1sLwZ?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743650224&amp;usg=AOvVaw3-qWmSF4qVA3UIfUcn9ygj">https://drive.google.com/drive/folders/1CM0uKDf60vhYyYOCg2G1Ft4aAiK1sLwZ?usp=sharing</a></span></p><p class="c1"><span class="c20"><br>VR6 models don&rsquo;t work in UVR</span><span><br><br>- iter41_l1_loss </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/12xKwmRpig-dGdHJoPLM2oV9LniWWC0MR/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743650479&amp;usg=AOvVaw2xhW-fcx8KPnvcU77HIxnc">model</a></span><span>&nbsp;for </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/tsurumeso/vocal-remover/releases&amp;sa=D&amp;source=editors&amp;ust=1765035743650587&amp;usg=AOvVaw1_kqyeZT83kfgWJolNJnyy">VR v6.0.0b4</a></span><span>&nbsp;- similarity/phantom centre extractor </span><span>by wesleyr36/drypaintdealerundr</span><span class="c0">, </span></p><p class="c1"><span class="c0">&ldquo;I think this arch makes for a much better similarity extractor</span></p><p class="c1"><span>(make sure to use the complex flag when running this model --complex or -X)&rdquo;<br><br>Compared to MDX23C models below, VR6 ones were trained on limited dataset, but they can still perform better.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- 4096 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1RMkUa6iMvJ0gW0LIMq_OofGiZDA5snKK?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743651433&amp;usg=AOvVaw2NczznFB3gGGD6PWM9xjb4">model</a></span><span>&nbsp;for </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/tsurumeso/vocal-remover/releases&amp;sa=D&amp;source=editors&amp;ust=1765035743651553&amp;usg=AOvVaw1kHawCyLSXv3ZQtD4uLuVU">VR v6.0.0b4</a></span><span class="c0">&nbsp;by wesleyr36/drypaintdealerundr (it should perform better than the MDX23C 2048 model below)</span></p><p class="c1"><span class="c0">&ldquo;must be run not only with -X or --complex but also --n_fft 4096 --hop_length 2048 or -f 4096 -H 2048&rdquo;</span></p><p class="c1"><span class="c0">VS 2048 - &ldquo;pros: less bleed</span></p><p class="c1"><span class="c0">cons: less complete results as a similarity extractor</span></p><p class="c1"><span class="c0">it seems to benefit from running the centre channel results back through the model for more complete results just like the original similarity extractor for more complete results although with the trade-off of more bleed</span></p><p class="c1"><span>you end up with overall more bleed than the other model but with even more complete results&rdquo;<br><br>Usage for </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/tsurumeso/vocal-remover/releases&amp;sa=D&amp;source=editors&amp;ust=1765035743652707&amp;usg=AOvVaw342SjjwY3uv8dUvhTm2RIi">VR v6.0.0b4</a></span><span class="c0">:</span></p><p class="c1"><span class="c36 c31 c77">python inference.py -i path/to/an/audio/file --gpu 0 -P path/to/model.pth -X -f 4096 -H 2048 -o folder/you/wish/to/save/to<br></span><span>you can just drag a file/folder into the terminal/CMD to get the path too if that&#39;s more convenient</span></p><p class="c1"><span>The command for Nvidia GPU, but CPU inferencing should be possible too.<br></span></p><p class="c1"><span>- 2048 MDX23C </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2417116936&amp;sa=D&amp;source=editors&amp;ust=1765035743653543&amp;usg=AOvVaw2W6vk0YlDdYaI6YNWOzlZr">model</a></span><span class="c0">&nbsp;by wesleyr36/drypaintdealerundr </span></p><p class="c1"><span>Can be used on MVSEP (in Experimental section) and x-minus.pro (option Extract backing vocals) or using ZFTurbo inference CML </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/&amp;sa=D&amp;source=editors&amp;ust=1765035743654089&amp;usg=AOvVaw39VDccoXA_Baw1hSWzqMlI">code</a></span><span>&nbsp;</span><span class="c0">(it doesn&rsquo;t work in the OG MDX23C inference code and in UVR).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;This model is similar to the Center Channel Extractor effect in Adobe Audition or Center Extract in iZotope RX [and Audacity/Bertom], but works better. </span></p><p class="c1"><span class="c0">Although it does not isolate vocals, it can be useful.&rdquo; Aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The main thing I trained it for was to be used in a similarity extractor, since the original also used an AI model</span></p><p class="c1"><span class="c0">The steps for that being:</span></p><p class="c1"><span class="c0">1. Take the L channel from Audio_1 and the L channel from Audio_2 and merge them into a stereo file.</span></p><p class="c1"><span class="c0">2. Run that through the model</span></p><p class="c1"><span class="c0">3. Repeat for R channels</span></p><p class="c1"><span>4. Merge the L and R channels back together, and you have the similarity, assuming the audio files were perfectly aligned.&rdquo;<br>It was trained in a period of 6 days on Quadro RTX 4000<br><br>&ldquo;Some bits were better on the model, others on [the] Audacity&#39;s [Vocal and Center Isolation feature]&rdquo;<br><br>- Melband Roformer Similarity/Phantom Centre Extraction </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1uJP5OQuChCQVY4CVB1Ju3nxBskE-dYzy?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743656227&amp;usg=AOvVaw1N-z7Qpo8FN3rVESLHofEr">model</a></span><span>&nbsp;</span><span class="c0">(beta) + lora<br>by wesleyr36/drypaintdealerundr</span></p><p class="c1"><span>&ldquo;results are relatively clean but sound a bit filtered at times, comes with 2 lora checkpoints for frazer&#39;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/fmac2000/Music-Source-Separation-Training-Models/tree/lora&amp;sa=D&amp;source=editors&amp;ust=1765035743656731&amp;usg=AOvVaw0SEe_RByqpYjixNQZEILwh">LoRA repo</a></span><span class="c0">&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Mel-Roformer de-reverb by anvuew (a.k.a. v2/19.1729 SDR) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/resolve/main/dereverb_mel_band_roformer_anvuew_sdr_19.1729.ckpt&amp;sa=D&amp;source=editors&amp;ust=1765035743657122&amp;usg=AOvVaw2ya-lsYLelsKY4sMNKIgkD">DL</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/anvuew/dereverb_mel_band_roformer/resolve/main/dereverb_mel_band_roformer_anvuew.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035743657288&amp;usg=AOvVaw2KvdfaxVn6pxereg9lZOGH">config</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743657498&amp;usg=AOvVaw2VqnzOlQHRsD0IHP9HKin_">Colab</a></span></p><p class="c1"><span class="c0">(it can serve also as a phantom center model, removing sides)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">- Older VR model by HV Colab (Colab fixed 16.02.24)</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1WP5IjduTcc-RRsvfaFFIhnZadRhw-8ig?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743658096&amp;usg=AOvVaw2lKTznPMO4hi3GnKaOp0Xx">https://colab.research.google.com/drive/1WP5IjduTcc-RRsvfaFFIhnZadRhw-8ig?usp=sharing</a></span></p><p class="c2"><span class="c0">Don&rsquo;t forget to click cell with dependencies after mounting</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span>If you want to use the repo locally, use just this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1PUYK2QDT8moe6EOugDu0kROV11XlZjnx?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743658500&amp;usg=AOvVaw2VNiVjpNgmkwDABRA3eB0t">fix</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">&quot;If you have two language track it&#39;ll remove the vocals, but not its adlibs&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">&quot;It works like invert but instead of mixing the inverts together, it removes the difference and leaves the ones that sound the same&quot;</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">It uses a specifically trained model on 100 pairs.</span></p><p class="c2 c7"><span class="c0"></span></p><ul class="c9 lst-kix_eiskzjj27gc6-0 start"><li class="c2 c25 c8 li-bullet-0"><span class="c0">Sadly, &ldquo;It&#39;s like a downgrade of Audacity Vocal and Center Isolation feature&rdquo; - it&rsquo;s muddier</span></li></ul><p class="c2"><span class="c0">Audacity can be used in browser at:</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://wavacity.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743659490&amp;usg=AOvVaw0P1H6bREjx1w44TK5LZlit">https://wavacity.com/</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">The option in version prior 3.5.0 is located in:</span></p><p class="c2"><span class="c0">Effect&gt;Special&gt;Vocal Reduction and isolation</span></p><p class="c2"><span class="c0">on 2.x: Effect&gt;Vocal Reduction and isolation (at the very bottom)</span></p><p class="c2"><span>3.5.0 or later: downloadable as Nyquist plugin from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://plugins.audacityteam.org/nyquist-plugins/effect-plugins/filters-and-eq%23vocal-reduction-and-isolation&amp;sa=D&amp;source=editors&amp;ust=1765035743660227&amp;usg=AOvVaw12sPLoG30oWFbaUX3S80y6">here</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">&ldquo;Adobe Audition works a similar, but you can actually tweak a lot of settings. But the difference is pretty much non-existent. Or any better for that matter. Similar way. Even with Audacity, Adobe Audition, and PEEL [3d Audio Visualize], we are still not quite there yet.</span></p><p class="c2"><span class="c0">Currently, Audacity, and maybe Waves Stereo Center plugin have the best capabilities, but they are still aren&#39;t perfect.&rdquo; Vinctekan</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sadly, it turns out that all the three solutions can sound worse than current models for the use case of getting rid of dubbing in movies.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">It can be used with window size 768 on CPU as well. Probably the lowest supported for GPU is 272 (352 was set, and 320 is possible too), but probably it won&#39;t change here much.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">One of the use cases of Audacity method to get lead vocals (in 2021) was by obtaining e.g. main vocals from vocal or BVE model, and processing that stem with these settings:</span></p><p class="c1"><span class="c0">Audacity&gt;Effect&gt;Vocal reduction and isolation&gt;</span></p><p class="c1"><span class="c0">on action, make it Isolate Center</span></p><p class="c1"><span class="c0">Strength: 1.1 or 1.6</span></p><p class="c1"><span class="c0">Then click OK. That effect must go on vocal part. If you use center isolation, low/high cut will be ignored </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Q: wouldn&rsquo;t it be possible to extract anything that is panned to a specific point yk like extract anything that is panned 100% exactly, or anything that is panned 80% or 50% etc, would that not be possible? </span></p><p class="c1"><span class="c0">A: Mashtactic does that since almost 20 years now (coupled with dynamics and EQ filtering)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D0lDAY0va4VE&amp;sa=D&amp;source=editors&amp;ust=1765035743663362&amp;usg=AOvVaw18d0xHj9hhS7pwDoVsX-de">https://www.youtube.com/watch?v=0lDAY0va4VE</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- zplane has released a clone recently, but it doesn&#39;t have the transient/sustain filtering iirc&rdquo; (isling/jarredou)</span></p><p class="c1"><span class="c0">- Also, you can use AudioSourceRE RePAN for center extraction as well (IncT)</span></p><p class="c1"><span class="c0">- Or less complex free/paid Bertom Phantom Center (sometimes it&rsquo;s better, sometimes worse than MDX23C model).<br>&ldquo;Bertom Audio claim to not use basic mid/side processing to extract the center so probably uses decorrelation on the sides instead of mid/side processing which by its nature negatively correlates them. The net result of Bertom is the sides are decorrelated from the center and so are maintained more strongly in the stereo field.&rdquo; Sam Hocking</span></p><p class="c1"><span>- </span><span class="c58 c56 c38">&nbsp;</span><span class="c4 c38"><a class="c3" href="https://www.google.com/url?q=https://aom-factory.jp/products/stereo-imager-d/&amp;sa=D&amp;source=editors&amp;ust=1765035743664722&amp;usg=AOvVaw0VR4N34KxU5uc_Va2rOopz">AOM Stereo Imager D</a></span><span class="c31">&nbsp;</span><span>&ldquo;turn off auto-gain &amp; turn down center&rdquo;</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/junh1024/junh1024-Documents/blob/master/Audio/How%2520to%2520extract%2520Backing%2520Vocals.md%23fft-imaging-extract-out-of-phase&amp;sa=D&amp;source=editors&amp;ust=1765035743665080&amp;usg=AOvVaw1dhkP2GQSiEjn5bc2tzweK">Reaper guide</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Hints on using similarity models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &ldquo;Hi there! I have a question regarding audio separation in movies. I have an old movie with a stereo track in English, and a mono (!) track in French. I couldn&#39;t for the life of me find anything better than mono for my native language, which is a shame (even a source with supposedly stereo French is actually mono, you hear it right away).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So I&#39;m willing to try and use the English track to reinject some stereo in the background, to widen the music and sfx at least (the voices being centered don&#39;t bother me). i.e. I could separate the voices from the rest in both languages, then mix the French voices with the English sfx and music. Whatever artifacts remaining could blend enough that it wouldn&#39;t be noticeable... Maybe...</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">How would you guys go about it? I&#39;ve used UVR in the past but only on music, not movies &ndash; and it was months ago. Also my GPU is old (Nvidia GTX 970 with 4 GB VRAM) so this might be a limitation. Thanks for any advice you can give me!&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: &ldquo;If the French rip is a downmix between stereo channels, then you don&#39;t have to separate dialogue in the French rip. &nbsp;Only separate the vocals in the English version, encode it to mid/side, replace the mid channel with the French rip, decode back to stereo, and you&#39;re done. English vocal separation will get rid of the stereo bits from the side channel, so you won&#39;t be hearing both languages at once. Obv you have to align the sources too, which can be tricky if there are any changes in timing between the versions. If the French rip is only a single channel from source stereo, then do your way of isolating both languages.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Instead of using your own GPU you can send your audio file to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743668627&amp;usg=AOvVaw0IMHofdW1QyeCz8i6l5I4v">Colab </a></span><span class="c0">and use smth like melroformer v1e with default settings.&rdquo; (introC)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What difference do you mean with &quot;a downmix between stereo channels&quot; and &quot;a single channel from source stereo&quot;? It seems the same thing to me but I may be missing sth obvious.</span></p><p class="c1"><span class="c0">A: A single channel is either left or right, downmix is an average of left and right</span></p><p class="c1"><span class="c0">Q: Then I guess what I have is a downmix?</span></p><p class="c1"><span class="c0">A: Not sure, you need to check. I can check if you want, sent the English and mono audio. But basically, align the tracks, downmix the English track and check for null when mixing with the French mono track. If it isn&#39;t null, then it&#39;s not a downmix (or the audio tracks have other differences)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/12siscZBrM9SwxITGipAvSobVtQ8t2Pus?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743670081&amp;usg=AOvVaw2ja-cFEylqDnDiF4vfvI4s">OG</a></span><span class="c0">&nbsp;VR broken Colab by HV fixing history</span></p><p class="c1"><span class="c0">It was fixed by adding these lines to it: </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">!apt-get install python3.8</span></p><p class="c1"><span class="c0">!apt-get install python3.8-distutils</span></p><p class="c1"><span class="c0">!apt-get install python3.8 pip</span></p><p class="c1"><span class="c0">!python3.8 -m pip install librosa==0.9.1</span></p><p class="c1"><span class="c0">!python3.8 -m pip install numpy==1.19.5</span></p><p class="c1"><span class="c0">!python3.8 -m pip install numba==0.55.0</span></p><p class="c1"><span class="c0">!python3.8 -m pip install tqdm</span></p><p class="c1"><span class="c0">!python3.8 -m pip install torch==1.13.1</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">and renamed inference Colab line to python3.8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(not necessary)</span></p><p class="c1"><span class="c0">! pip install soundfile=0.11.0</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">distutils was necessary to fix numpy wheel error, but regular 3.8 installed before was necessary for Colab to recognize !python3.8 commands. Because 3.8 was bare, it needed pip installed separately for this 3.8 installation. Then the rest of the necessary packages are installed for 3.8 - the old librosa fix, numpy for 3.8, and broken dependencies numba and tqdm. Then, the last torch working in HV Colabs was 1.13.1, 1.4 didn&#39;t work though it&#39;s compatible with 3.8. Maybe CUDA or generally upgraded Ubuntu problem. Can&#39;t tell. It was necessary anyway because Torch wasn&#39;t installed for 3.8.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Additionally, to fix the regular VR Colab, this line was necessary:</span></p><p class="c1"><span class="c0">!python3.8 -m pip install opencv-python</span></p><p class="c1"><span class="c0">And for some reason, I needed to install these with normal pip like below, and with python 3.8, so basically twice, otherwise it gave module not found</span></p><p class="c1"><span class="c0">! pip install pathvalidate</span></p><p class="c1"><span class="c0">! pip install yt_dlp</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">That all hassle with Python 3.8 is necessary because numpy on Colab got newer version, and newer ones no longer supports function used in HV Colabs, as they got deprecated.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.ak53injalbkf"><span>Separating people </span><span class="c21">in recording</span></h4><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">Guide and script for </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://github.com/m-bain/whisperX&amp;sa=D&amp;source=editors&amp;ust=1765035743673666&amp;usg=AOvVaw2aH-SSjX00L9En0feFBa3o">WhisperX</a></span><span class="c6">&nbsp;by Pashahlis/ai_characters </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;A script on the AI hub discord for automatically separating specific voices from an audio file, like separating a main character&#39;s voice from an anime episode.</span></p><p class="c1"><span class="c0">I massively updated this script now, and I am also posting it here now, since this discord is literally about that kinda stuff.</span></p><p class="c1"><span class="c0">Script to automatically isolate specific voices from audio files</span></p><p class="c1"><span class="c0">(e.g. isolating the main character&#39;s voice from an anime episode where many different characters are speaking).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">After literal hours of work directing ChatGPT, fixing errors, etc, there is now a heavily updated and upgraded script available:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I encountered some transcription errors (musical notes, missing speaker or start and end times) that would result in the entire script failing to work. So the updated script now skips such audio. That is not a problem, however, as for a 22-min file it skipped only 16s of audio and the errored audio is just music or silence anyway.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It now also automatically merges all your audio files into one if you provide multiple, so that the speaker diarization remains consistent. This increases diarization time by quite a lot, but is necessary. The merged file will be temporarily saved as a .flac file, as .wav files have a maximum file size of 4gb. The resulting speaker files at the end of the script are created as .wav again, though, as it is unlikely they will reach 4gb in size.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I also added helpful messages that tell you at which state of the script it currently is at and which audio files it is processing at the start with the total length of audio being processed.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I also made sure that it saves the speaker files in the original stereo or mono and 16 bit or 32 bit format.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">At the end of the script execution, it also lists all the speakers that were identified in order of and with the audio length for each speaker. It also lists the total amount of audio length that had to be skipped due to processing errors, as well as the total time it took to execute the script.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Last but not least, I ran this script on a vast.ai rented Ubuntu based VM with a 4090 GPU and it worked. I did this to test Linux as well as because I was processing over 4h of audio, so I wanted this to be fast. Keep in mind that if you are running this script on your home PC with a bad GPU and are processing a lot of audio, it can take quite a while to complete.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Script is attached.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/13iY2knyABBU-MOaMN5_zNAoDHFMZY6SD/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743678760&amp;usg=AOvVaw2AKd0ypu8tjXirJ6nWvP6Q">https://drive.google.com/file/d/13iY2knyABBU-MOaMN5_zNAoDHFMZY6SD/view?usp=sharing</a></span></p><p class="c1"><span class="c0">example console output and example speaker output:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1132503652033114192&amp;sa=D&amp;source=editors&amp;ust=1765035743679231&amp;usg=AOvVaw1j4wcfsgTlwRWP52al-xta">https://discord.com/channels/708579735583588363/708579735583588366/1132503652033114192</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Usage instructions:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>install whisperx and its additional dependencies such as FFmpeg as per the instructions on the GitHub page </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/m-bain/whisperX&amp;sa=D&amp;source=editors&amp;ust=1765035743679705&amp;usg=AOvVaw1cM4xvqH8wdFGY_MLLPeFp">https://github.com/m-bain/whisperX</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Additionally, install pydub (and any other dependencies you might be missing if the script gives an error message indicating you are missing a dependency)</span></p><p class="c1"><span class="c0">install ffmpeg-python, make sure to use the following command instead of pip install if you&#39;re running this in a conda environment, otherwise it won&#39;t work: conda install -c conda-forge ffmpeg-python</span></p><p class="c1"><span class="c0">edit the script to include your huggingface token and path to the folder containing the audio files you want to process</span></p><p class="c1"><span class="c0">run the script simply by python your_filename_here.py</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Results are quite good for what it is, but you&#39;ll definitely need to do some additional editing in audacity and ultimate vocal remover or whatever afterwards to cut out music, noise, and other speakers that were wrongfully included. It definitely works best with speakers that appear a lot in the audio file, like main characters. It does a very good job at separating those.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I won&#39;t provide tech support beyond this, as I am no programmer and did this all by just directing ChatGPT.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Or check </span><span class="c4"><a class="c3" href="#h.ea9fj444mg3m">alternatives</a></span></p><p class="c2 c7"><span class="c0"></span></p><h3 class="c27 c67" id="h.czix2y8eiuna"><span class="c46">UVR5 GUI</span><span class="c19">&nbsp;(MDX, VR, Demucs 2-4 and UVR team models)</span></h3><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">GUI provides more functionalities and models/AIs compared to Colabs, incl. custom model import:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases&amp;sa=D&amp;source=editors&amp;ust=1765035743682362&amp;usg=AOvVaw25c51-KX5B95HAlolBYjPS">https://github.com/Anjok07/ultimatevocalremovergui/releases</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Official app Win 11 installation tutorial:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/u8faZW7mzYs&amp;sa=D&amp;source=editors&amp;ust=1765035743682635&amp;usg=AOvVaw0Sdr7qsR_OJCGPS70EURZ7">https://youtu.be/u8faZW7mzYs</a></span></p><p class="c1"><span class="c0">MacOS build:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/tag/v5.6&amp;sa=D&amp;source=editors&amp;ust=1765035743682916&amp;usg=AOvVaw3BcP5K4x_JI4B1E4VK5tsB">https://github.com/Anjok07/ultimatevocalremovergui/releases/tag/v5.6</a></span><span>&nbsp;(or </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">MacOS Catalina tutorial (outdated at this point):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Du8faZW7mzYs&amp;sa=D&amp;source=editors&amp;ust=1765035743683235&amp;usg=AOvVaw0KyIGEslqD36iVuDUJgmD9">https://www.youtube.com/watch?v=u8faZW7mzYs</a></span></p><p class="c1"><span class="c0">(you better don&rsquo;t run Windows build in W10 VM or you will get like 3 hours processing time)</span></p><p class="c1"><span class="c0">Windows 7 users:</span></p><p class="c1"><span class="c0">&quot;To use the newest python 3.8+ with Windows 7 install VxKex API extensions and in case of problems select Windows 10 compatibility in EXE installer properties.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Here you can find a searchable PDF guide by the devs for UVR5 GUI describing functions and parameters (can be outdated):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1RtMRj8FpSpMHlK1XxaBrKoWQlmMfCSmy/view?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035743684220&amp;usg=AOvVaw32vT9rIaSopPyuq87An48J">https://drive.google.com/file/d/1RtMRj8FpSpMHlK1XxaBrKoWQlmMfCSmy/view?usp=drive_link</a></span></p><p class="c1"><span class="c0">Video guide:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/jQE3oHXfc7g&amp;sa=D&amp;source=editors&amp;ust=1765035743684418&amp;usg=AOvVaw20wT9X5qMGXCXrkEVu3elh">https://youtu.be/jQE3oHXfc7g</a></span></p><p class="c1"><span class="c0">Online guide:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://multimedia.easeus.com/ai-article/how-to-use-ultimate-vocal-remover.html&amp;sa=D&amp;source=editors&amp;ust=1765035743684732&amp;usg=AOvVaw2P2V5DWXMwuJC1eoqTmPu9">https://multimedia.easeus.com/ai-article/how-to-use-ultimate-vocal-remover.html</a></span></p><p class="c1"><span class="c0">(their instructions for installing and using stable version seems to be fine, despite the fact they recommend to clone repo for Macs. It&#39;s already available as appropriate binaries for M1 and Intel CPUs (/wo Roformer beta patch at the moment) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Some of</span><span class="c0">&nbsp;UVR5 GUI models described in this guide can be downloaded via the expansion pack:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.3.0/v5_model_expansion_pack.zip&amp;sa=D&amp;source=editors&amp;ust=1765035743685656&amp;usg=AOvVaw05Aiz_da3bltz8QQF8bNK0">https://github.com/Anjok07/ultimatevocalremovergui/releases/download/v5.3.0/v5_model_expansion_pack.zip</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VIP models</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.buymeacoffee.com/uvr5/vip-model-download-instructions&amp;sa=D&amp;source=editors&amp;ust=1765035743685982&amp;usg=AOvVaw3LdjUBGe5XJ1MRWwvmE-ze">https://www.buymeacoffee.com/uvr5/vip-model-download-instructions</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(some older) settings for the GUI:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://photos.app.goo.gl/EUNMxm1XwnjMHKmW6&amp;sa=D&amp;source=editors&amp;ust=1765035743686302&amp;usg=AOvVaw1hqObG4xdb858g8NtiNUvT">https://photos.app.goo.gl/EUNMxm1XwnjMHKmW6</a></span></p><p class="c1"><span class="c0">(though it&#39;s mostly outdated).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(no longer necessary as UVR now has separate DirectML branch and executable:)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Optional fork of UVR GUI for AMD and Intel cards, currently supporting only VR Architecture and MDX using DirectML (Demucs currently not supported). If you have Nvidia card, then use official app above since CUDA is supposed to be faster.</span></p><p class="c1"><span class="c0">&ldquo;A four minute and 20 second audio takes about 30 seconds (including saving) using 1_HP-UVR on an Intel Arc A770 16GB. It takes up approximately 6GB of VRAM.&rdquo;</span></p><p class="c1"><span class="c0">If you only use MDX models, in most cases it won&#39;t be faster than processing with CPU - i5 4460 has similar performance to RX 6700 XT here, so better stick to official app.</span></p><p class="c1"><span class="c0">Compared to Roformer beta #8, it&rsquo;s still much faster at least for VR models, but you might get some issues with MDX-Net models though.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Aloereed/ultimatevocalremovergui-directml&amp;sa=D&amp;source=editors&amp;ust=1765035743688054&amp;usg=AOvVaw3iKXk8ZCj2fm_7aiOdh3dV">https://github.com/Aloereed/ultimatevocalremovergui-directml</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Python command line fork of UVR 5 with current models support:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/karaokenerds/python-audio-separator&amp;sa=D&amp;source=editors&amp;ust=1765035743688429&amp;usg=AOvVaw2Xnt01oxThqkQW0bHzLe3l">https://github.com/karaokenerds/python-audio-separator</a></span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c27 c85" id="h.ul5en196k909"><span class="c21">GUI FAQ &amp; troubleshooting for UVR</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Start with reading information about </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">Roformer patch</a></span><span class="c22">&nbsp;</span><span>and its common issues section</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;If you enable the &quot;enable help hints&quot; setting&rdquo; &ldquo;you can hover parameters with the mouse, [and] you&#39;ll get [settings] info hints (...) if [it&rsquo;s] not activated by default)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- See the section </span><span class="c4"><a class="c3" href="#h.czix2y8eiuna">above</a></span><span>&nbsp;</span><span class="c0">for UVR installation and usage guides</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- It&#39;s not guaranteed to run on older versions of Windows than 10, so do it at your own risk.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;3.8.10 is the last [Python] official installer that works on Win7, however I was able to find an unofficial [Python] installer from GitHub for 3.10.13 on Win7 and that seemed to do the trick! No more error on load of UVR&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You may encounter &ldquo;Encoding failed. ffmpeg/avlib returned error code: 3221225477&rdquo; while using Manual ensemble and output set to mp3 on Windows 7<br>&ldquo;Think I&#39;ve found my problem. I used a full build of FFMPEG instead of the essentials one.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;If anyone needs the solution to running it on [MacOS] Mojave+ go to the Releases page on GitHub scroll down to 5.5, under assets grab UVR 5.5 x86_64_9_29.dmg. Confirmed working now on my Mojave machine. Thanks to @ambresakura on GH&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Installing the GUI outside the default location on C:\ drive, esp. with older versions may result in e.g. startup issues (although they seem to be fixed in 5.6 and Roformer patches). If you lack space on C: drive, create your folders using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/amd989/Symlinker&amp;sa=D&amp;source=editors&amp;ust=1765035743691460&amp;usg=AOvVaw0ksPpmxT-NVHOA0_CswTQo">Symlink Creator</a></span><span class="c0">&nbsp;to redirect the content to some other disk, keeping the C:\ location in the Windows file system logic.</span></p><p class="c1"><span class="c0">Or else, copying only Ultimate Vocal Remover\gui_data folder to the C:\ drive while keeping the GUI installation on another drive might work as well. Although there seem to be no issues with the latest stable 5.6 opened from a different location than default, and standalone Roformer patch installed in a different location.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- There&rsquo;s no way to bypass the 3 GB free disk space requirement on C: drive, even for using AudioTools. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/issues/285%23issuecomment-1244606111&amp;sa=D&amp;source=editors&amp;ust=1765035743692595&amp;usg=AOvVaw36JJsIYuWfyNDD6TTnlzUy">Here</a></span><span>&nbsp;someone set UVR to L: drive, and it read free space from that letter, but I&rsquo;m not sure if they just installed UVR in that location, and whether it&rsquo;s still possible using the latest UVR versions (even when UVR was uninstalled previously) or whether it&rsquo;s enough to copy UVR elsewhere and/or change something in the registry about installation path.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;UVR GUI will only process files with English characters (might be fixed, although some complicated names/paths still give &ldquo;System error&rdquo; during separation)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">E.g. for RuntimeError: &quot;Error opening &#39;F:/Fl studio files/ACAPELLAS\1y2mate.com - 2 AM Full Video Karan Aujla &nbsp;Roach Killa &nbsp;Rupan Bal &nbsp;Latest Punjabi Songs 2019(Vocals).wav&#39;: System error.&quot; your file path/file name is too long or contains some unsupported charts. You need to shorten/simplify it and/or copy the file to a different location.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Be aware that your system may occasionally become unresponsive on slow 2 and 4 core configurations with GPU Conversion disabled while separation is progressing (although, you can set all the priorities in Process Lasso to Idle, and it will be saved for future use).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The provided directory is not writable or read only</span></p><p class="c1"><span>Run UVR as admin, or potentially changing privileges to the output/input folders to everyone might help too (alternatively use &ldquo;Context Menu&rdquo; for it described </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.makeuseof.com/windows-10-11-own-folder/&amp;sa=D&amp;source=editors&amp;ust=1765035743695073&amp;usg=AOvVaw1L5G8pxW6EB4HdKw1g-L-B">here</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Why Vocal Dereverb Options are greyed out. I can&#39;t select more, only &quot;main vocals&quot;</span></p><p class="c1"><span class="c0">A: This option removes reverb from a vocal stem.</span></p><p class="c1"><span class="c0">You must have the &quot;UVR-DeEcho-DeReverb&quot; VR Arch model installed to use this option.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Matchering doesn&rsquo;t work correctly with Opus files (error occurs)<br><br>- Matchering doesn&rsquo;t work correctly with mp3 files on Mac (at least x86, error occurs)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Matchering input audio file length limit before error occur is 14:44 or 15 minutes</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Matchering and Manual Ensemble use only CPU and are fast</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;Download speed of models via Download center was really slow for no apparent reason, like some users have already reported.</span></p><p class="c1"><span class="c0">I&#39;ve reduced [the] UVR[&rsquo;s] window while the download was ongoing and the download speed fastly improved instantly.</span></p><p class="c1"><span class="c0">I&#39;ve restored the window, download speed was again instantly slowed down. Re-reduce UVR window, download speed back to normal again&hellip;&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Official UVR requirements from GH page:</span></p><p class="c1"><span class="c0">Nvidia RTX 1060 6GB is the minimum requirement for GPU conversions.</span></p><p class="c1"><span class="c0">Nvidia GPUs with at least 8GBs of VRAM are recommended.</span></p><p class="c1"><span class="c0">Intel Pentium might be unsupported, but AVX or SSE4.2 instructions are not required, so even newer C2Q like Q9650 with SSE4.1 will suffice. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- 2GB VRAM GPUs had some issues even on CPU, maybe it&#39;s fixed already</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;Official minimum RAM requirement is 8GB, although it works correctly on 6GB RAM too. With 4GB RAM you can run out of memory on longer tracks (probably fixed in many cases in the v 5.5 and newer - you&rsquo;re able to separate Roformers on GPU on 4GB VRAm with 2,5s chunks).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- As from new Nvidia GPUs, something like RTX 3050 (8GB) is a good, cheap choice for even the heaviest processing and is (theoretically) equivalent to Colab&#39;s Tesla T4 for CUDA computing power (but it&#39;s not really enough for training, of course, and in Colab slower like 3 times). But watch out for smaller 4GB laptop variants, as they can be more problematic.<br>But if you separate a lot using Rofomers, definitely consider something better (look for as menu CUDA cores as possible)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sometimes 32/64 bit float output set can trigger &ldquo;FileNotFoundError: &quot;[WinError 2] The system cannot find the file specified&quot;&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">(troubleshooting continues later beneath)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">CPU/GPU performance in UVR</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">- The higher the total amount of CUDA cores for Nvidia GPU, the faster separation in UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- AMD and Intel ARC GPUs using OpenCL are slower in this separation task than CUDA used in Nvidia GPUs. So it&rsquo;s safe to say that Nvidia GPUs from the same performance segment will be most likely faster for separation.</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">- Min. 4GB VRAM GPUs tested (with some yaml tweaking for Roformers described below), On AMD, 16GB VRAM recommended (so no modifications are required). <br>Min. NVIDIA Maxwell/900 series GPUs/compute compatibility 5 is the minimum requirement (at least NVIDIA GT 700 series and older are unsupported returning CUDNN_STATUS_NOT_INITIALIZED).<br>For AMD, at least RX 4GB models tested (not sure about R9 200 4GB GPUs - either if on newer modded Radeon-ID drivers and/or with downgraded DirectML.dll attached with your drivers, copied to UVR\torch_directml folder)</span></p><p class="c1"><span class="c0">Intel was confirmed to work with ARC GPUs, and Xe integrated graphics (e.g. Tiger Lake 2021) with MDX-Net HQ (v2) models.</span></p><p class="c1"><span class="c0">RTX 5090 is not yet supported in official UVR packages, you can use OpenCL (DirectML) in options instead (slower). </span></p><p class="c1"><span>2GB cards will probably cause issues, and 4GB VRAM too - at least on certain Roformer models and settings (unless dim_t equivalent of chunk_size is set to 301/201, but 201 might have a bit of audible audio skipping at times - see </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">here</a></span><span class="c0">&nbsp;later below for dim_t&gt;chunks_size conversion) &nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Not meeting these requirements, you&rsquo;re forced using CPU processing, which is very slow - even Ryzen 5950X is slower than 1050 Ti in this application, and 1700X is slower by double than even 940M. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Since the last updates you can also use AMD/Intel GPU, with separate installer with OpenCL support (most likely min. requirement is GCN or Polaris architectures and up - HD 7XXX and RX 4XX, but even 4GB variants may crash on certain settings). <br><br>- Old drivers for GCN GPUs might fail using GPU Conversion option. Consider using Radeon.ID drivers or using DirectML.dll copied from your Windows installation into Ultimate Vocal Remover\torch_directml</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You can also use Mac M1 for GPU acceleration (MPS GPU support in separate installer), but also Radeons acceleration on Intel Macs is supported</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- GTX 1660 Ti (6GB) is slow for separation using Roformer models. A better choice is RTX 3050 despite similar performance in games, 3050 has the same amount of CUDA cores as Tesla T4 on Colab, but with less VRAM. Avoid the laptop variant of 3050 which has only 4GB of VRAM, and not 8GB like the desktop variant.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you want a fast 2nd hand GPU with more VRAM, consider 1080 Ti or 2080 Ti or even 3080 Ti (16GB). Pretty fast ones for separations.</span></p><p class="c1"><span class="c0">1080 Ti is much faster in this task than 3060 12GB.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/767947630403387393/1133164474749169864/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743705355&amp;usg=AOvVaw2Y1gdwZWS9c55E3fn9BWqT">https://media.discordapp.net/attachments/767947630403387393/1133164474749169864/image.png</a></span><span class="c0">&nbsp;(dead)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: My AMD/Intel GPU have sudden spikes of usage, or just 30% is being utilized. Is that a CPU bottleneck?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: Nope. It&#39;s just how inefficiently DirectML behaves. It&#39;s normal and happens for all people, even on some ancient 4 cores.</span></p><p class="c1"><span class="c0">We&rsquo;ve tested various DirectML.dll libraries major versions since 1.9 (and besides 1.12 and 1.14), up to 1.15.4, and the one attached with UVR (1.10.1.0) was the fastest (1.5.1.0 didn&rsquo;t work).</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.6uak70lspqhf"><span class="c22">Separation times chart by Bas Curtiz </span><span class="c0">(various CPUs and GPUs, model cut-off examination)</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1R_pOURv8z9GmVkCt-x1wwApgAnplM9SHiPO_ViHWl1Q/edit?gid%3D460807774%23gid%3D460807774&amp;sa=D&amp;source=editors&amp;ust=1765035743706919&amp;usg=AOvVaw1hrThoIFMbZP0hC6VH857Y">https://docs.google.com/spreadsheets/d/1R_pOURv8z9GmVkCt-x1wwApgAnplM9SHiPO_ViHWl1Q/edit?gid=460807774#gid=460807774</a></span></p><p class="c1"><span class="c0">(probably the results made with old UVR Roformer patch when lower overlap means longer processing time, so the opposite to what&#39;s in patches newer than #2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In addition to the above -</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">for CPU-only:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX-Net HQ_3 in UVR with CPU takes 2 minutes with Ryzen 5 3600 (some regular song time)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- HQ_4 takes ~13 minutes on C2Q @3.6 DDR2 on CPU, 6GB RAM with default settings </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- HQ_3 for 4:19 track takes 20 minutes and 22 seconds (</span><span class="c4"><a class="c3" href="#h.6q2m0obwin9u">default</a></span><span class="c0">&nbsp;overlap and 256 segments, iirc default too) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- HQ_4 is much faster on the same CPU</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- On AMD A6-9225 Dual-Core CPU (2/2), 4GB RAM three models ensemble (MDX, MDX, Demucs 4) it took almost 17 hours.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- On i3 3xxx it took around 8 hours (not sure about song elapsed time). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The main burden in this ensemble on such configuration is Demucs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX23C and Demucs ht/ft cannot be processed under ~5-17 hours without GPU acceleration with CPU-only using C2Q. Probably the same for Roformers.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;MDX-Net HQ_3/4 models and VR models with 512 window size are fine on the same configuration</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX-Net HQ_3 in UVR with CPU takes 2 minutes with Ryzen 5 3600 - for unknown regular song between 2-4 minutes)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- HQ_4 takes ~13 minutes on C2Q @3.6 DDR2 with default settings (and it&rsquo;s faster than HQ_3) - for uknown regular song between 2-4 minutes)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">for GPU Conversion:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- It will take 39m 28s for 3:28 song using 1296 model on RX 470 4GB and C2Q @3.6 DDR2 and beta 2 patch (GPU OC doesn&#39;t really matter here, so the same will be for RX 570 which is basically the same chip after OC/different BIOS) and 18 minutes for Kim Mel-Roformer and 3:01 song, and 45 minutes for unwa v2 and 3:52 song. It&rsquo;s pretty possible that we have a huge CPU bottleneck in that case, as CPU still takes crucial part in separation, even for GPU separation.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- iGPU Intel Iris Xe Tiger Lake 11th Gen i7 on LG Gram notebook from 2021 (newer UVR patch)</span></p><p class="c1"><span class="c0">I used Unwa&#39;s duality v2, chunk size: 2s<br>&ldquo;I separated a 6 minute long song, it was a flac file, it took 38 minutes. </span></p><p class="c1"><span class="c0">- With CPU processing it took around and an hour and twenty minutes iirc</span></p><p class="c1"><span class="c0">keep in mind, I had stuff like VSCode, librewolf, Firefox etc in the background hogging up memory and CPU as well, during both those instances&rdquo; 12/16GB RAM recommended - it uses RAM as VRAM and you will clog almost whole 16GB RAM fast when using apps in background </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Using HQ_4 is much faster than real-time using default settings, but even longer than accelerated Roformer, when on CPU only using old Core 2 Quad @3.6 DDR2 800MHz.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- On Mac M1 using dedicated Roformer patch:<br>- it takes 9 minutes to process a 3-minute song using BS-Roformer 12xx viper model (dim_t 1101, batch size 2, overlap 8) with &ldquo;constant throttling&rdquo;.</span></p><p class="c1"><span class="c0">- below 4 minutes for Kim Mel-Roformer (overlap 1, dim 801)</span></p><p class="c1"><span class="c0">and 11:12 for MDX23C-InstVoc HQ for 04:11 track with default settings<br><br>- On 6800 XT it takes one hour for 5 minute song using overlap 5 and unwa&rsquo;s inst v2 Mel-Roformer model (newer UVR patch)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- RTX 3060 Ti allows 3x realtime using BS-Roformer SW 6 stems:<br>3 minutes of audio takes a minute to process (newer UVR patch)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Some separation times above could have changed a bit in newer UVR beta Roformer patches than #2</span></p><p class="c1"><span class="c0">_______</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">(FAQ continues)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Vocal chops using MDX models are more likely to appear on 4GB VRAM cards (use CPU processing with e.g. 12GB of RAM to get rid of the issue). MDX HQ_1 (or later) model can cause errors on some 4GB VRAM laptop GPUs at least with wrong parameters (you might want to use CPU processing instead, then min. 8GB RAM recommended). We&rsquo;re talking about the newer Batchmode (you cannot choose Chunk mode anymore in newer versions).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (no longer needed) 4GB VRAM cards should be supported out of the box with chunks set to auto (6GB may be required for longer tracks for auto setting or batch processing for chunks higher than at least 10).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(probably fixed) 4GB GPUs will sometimes force you to reopen UVR after each separation to free up VRAM or else separation might be unsuccessful (setting chunks in old versions of UVR to 10 or lower might alleviate the issue). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- UVR5 GUI instead of old CML &ldquo;mirroring&rdquo; has now &ldquo;hi-end process&rdquo; for VR models which is actual mirroring (no mirroring2, not sure about possible automatic bypass from CML while using ensemble of VR models) but don&rsquo;t confuse it with old &ldquo;hi-end process&rdquo; from CML version which was dedicated for 16kHz models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: If you run a single model with default configuration, it is okay with success. The problem is when ensemble 2 models, it does not have enough resources to complete the process. Unless using a manual ensemble. It also has an error if the chunk size was changed, even with a single model. Seems there is not enough VRAM for processing the song.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: I had the same issue the other day running ensemble 4 models.</span></p><p class="c1"><span class="c0">Turned out - as the error msg showed, the chunk size was too big...</span></p><p class="c1"><span class="c0">I prolly must have changed it by accident to `Full` - when I set it back to `Auto` - it was able to process.</span></p><p class="c1"><span class="c0">U can find this setting under Settings &gt; Advanced MDX Options.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (probably fixed) For 4GB VRAM GPU and VR 3090 models (e g. 1,2,9_HP-UVR) you may need to split e.g. 2:34 song into two parts (I recommend lossless-cut) or eventually use chunks option if you encounter run out of memory CUDA error. Lossless-cut will do chunking, so it won&rsquo;t be necessary to set chunks in UVR in case of some problems (not in all cases on 4GB VRAM).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (fixed in the latest Roformer patch iirc) &nbsp;&quot;When choosing to save either vocals or instrumentals only, the app saves the exact opposite (if I want to save vocals only, it will save instrumental, and vice versa)&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;A value of 10 for aggressiveness in VR models is equivalent to 0.1 (10/100=0.1) in Colab</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;Hidden feature of the GUI:</span></p><p class="c1"><span class="c0">&quot;All the old v5 beta models that weren&#39;t part of the main package are compatible as well. Only thing is, you need to append the name of the model parameter to the end of the model name&quot;</span></p><p class="c1"><span class="c0">Also, V4 models are compatible using this method.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The GUI also has all 4-6 stem models from Demucs 4 implemented. For 4 stem, simply pick up _ft model since it&#39;s the best for 4 stems. Demucs-UVR 2 stem model trained on Demucs 3 gets worse results than newer Demucs 4 ft model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You might consider using Nvidia Studio Drivers for UVR5. Versus Game Ready normal drivers, they can be more stable, but less often updated. You can check your current type of drivers in GeForce Experience (but if you don&rsquo;t know which ones you have, they&rsquo;re probably Game Ready)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Is there a way I can remove models I already have downloaded?</span></p><p class="c1"><span class="c0">I want to remove all the HP models, but I don&#39;t want to delete them from the directory, I want to be able to get them back if I need them</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: Check the current Download center and if all the models you want are there, then you can delete them and redownload from there later</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1. Delete the models from the directory, or</span></p><p class="c1"><span class="c0">2. Move the models to a separate folder out of the directory</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- At least since introduction of Batch mode (now default and the only option in 5.6/Roformer patch), stability of the app on lower VRAM GPUs got improved, but you can see more vocal residues processing on 4GB GPU vs on CPU, while 11GB GPU doesn&#39;t really have that problem.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Maybe something changed since batch mode was introduced, but some vocal pop-ups could be fixed only with chunks set to 50-60 (11 and 16GB VRAM cards only) in the older UVR versions and CML code.</span></p><p class="c1"><span class="c0">Some low values were still culprits of vocal pop-ups in chunks mode (at least before the patch).</span></p><p class="c1"><span class="c0">I&rsquo;m not sure if the way of handling chunks has changed since the integration of inference code with MSST repo in for MDX-Net menu models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Chart showing separation times for various MDX models and different chunks settings on desktop GTX 960 4GB - &nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/767947630403387393/1061182654621429811/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743721770&amp;usg=AOvVaw2nTD2-XCw1aNMOgcmY9Fqg">click</a></span><span class="c0">&nbsp;(dead)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- More in-depth - Settings per model SDR vs Time elapsed -||- (incl. dim_t and overlap evaluation for Roformers) - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1XNjAyKwA2RkyOA_agmaV_6Xp2xXOHjJV09t-ho0nngk/edit?gid%3D1530726921%23gid%3D1530726921&amp;sa=D&amp;source=editors&amp;ust=1765035743722209&amp;usg=AOvVaw2dhWJBqUo3_UzGiNA5BjqR">click</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/KBYHdNK&amp;sa=D&amp;source=editors&amp;ust=1765035743722298&amp;usg=AOvVaw0v0lBsiz0V0__Van62M7D3">conclusion</a></span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Linked above frequency cutoff + Time elapsed per model (GPU vs. CPU) - chart by Bas Curtiz - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1R_pOURv8z9GmVkCt-x1wwApgAnplM9SHiPO_ViHWl1Q/edit%23gid%3D23473506&amp;sa=D&amp;source=editors&amp;ust=1765035743722622&amp;usg=AOvVaw3XJ_pGB64MtNfiboq6IdU0">click</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (no chunks in 5.6 anymore) On 4GB VRAM cards, you can encounter crashes with the newest instrumental and Kim vocal model while using batch processing. Lowering chunks to at least 10 (but better lower, sometimes still crashes) should help</span></p><p class="c1"><span class="c0">___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There&rsquo;s no way to bypass 3GB free disk space requirement on C: drive, even for AudioTools</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If your disk space in not freed after separation, check in PowerShell if you have Memory Compression and Page Combining enabled, by typing:</span></p><p class="c1"><span>MMAgent. If not 1) Type: Get-MMAgent 2) Then: Enable-MMAgent -mc (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1LGVnJgivysKkXOkc2IfZAoF58f9MMJXt/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743723806&amp;usg=AOvVaw38gY6vyx6doY7HwQvHUGkI">video tutorial</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">More typical ways to get more space on C:\</span></p><p class="c1"><span class="c0">- &nbsp;If something is suddenly eating your disk space on the system disk, check: C:\Users\User\AppData\Local\CrashDumps because UVR can create even a few gigabyte crash dumps. Consider turning on compression in properties for that folder.</span></p><p class="c1"><span class="c0">Also, you can simply search for *.dmp and delete all the existing crash dumps on C: drive.</span></p><p class="c1"><span class="c0">- You should have around 20GB of free space on C: drive after UVR installation on 12GB RAM configurations for separating top ensemble settings (it uses a lot of pagefile) and at least 10GB for 24GB RAM for long songs on 4GB VRAM cards. You can enable pagefile on another drive as well if you run out of space on the system drive (better if it was an SSD as well). </span></p><p class="c1"><span class="c0">- Go to Safe Mode and delete your GPU drivers with DDU - it will delete all remain remnants from older versions of drivers</span></p><p class="c1"><span class="c0">- Delete all restore points besides the newest</span></p><p class="c1"><span class="c0">- Delete cache taking the biggest amounts of space in your browser if you don&#39;t want to clear browser data entirely (e.g. the old-fashioned cookie cleaning). </span></p><p class="c1"><span class="c0">E.g. in Chrome you can do it here:</span></p><p class="c1"><span class="c0">chrome://settings/content/all?sort=data-stored</span></p><p class="c1"><span class="c0">- Consider using CompactGUI for using a better compression algorithm for system compression than built-in context menu. Some programs compress excellent. E.g. Office.</span></p><p class="c1"><span class="c0">- Use old-fashioned disk cleaning feature in context menu of disk in Computer, and click on the next menu to see more entries (but cleaning up temp in appdata and Windows folder will do similar trick)</span></p><p class="c1"><span class="c0">- Consider using TreeSize Free in order to investigate the biggest files and folders on your partition</span></p><p class="c1"><span class="c0">- Sometimes Windows Update leaves lots of unused files after updates are installed - they can be cleaned up too by some methods.</span></p><p class="c1"><span class="c0">This command helped me free some disk space in the past. Iirc, precisely for WU cache in C:\Windows\SoftwareDistribution</span></p><p class="c1"><span class="c0">start %systemroot%\system32\rundll32.exe advapi32.dll,ProcessIdleTasks (it will take up to 15 minutes, leave PC for some time, and observe how some processes suddenly use CPU or disk, and suddenly stop, then it&#39;s done, eventually maybe after restart the space is freed)</span></p><p class="c1"><span class="c0">- You can shrink the pagefile to min. 500MB on C: drive and use other partition for pagefile</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mcci.com/support/guides/how-to-change-the-windows-pagefile-size/&amp;sa=D&amp;source=editors&amp;ust=1765035743727930&amp;usg=AOvVaw2kB7Nzvd3nO_Zq5JXNvWKk">https://mcci.com/support/guides/how-to-change-the-windows-pagefile-size/</a></span></p><p class="c1"><span class="c0">__</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &nbsp;Q: When ensembling and having settings test mode enabled, UVR keeps all the different outputs before ensembling in a folder. If you&#39;re not careful, these quickly can stack up.</span></p><p class="c1"><span class="c0">[Is it] Possible to have a feature where UVR automatically deletes those after ensembling?</span></p><p class="c1"><span class="c0">A: Disable &#39;*Save all outputs*&#39; in *Ensemble Customization Options* &gt; *Advanced Option Menu* is what you ask for.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Performance of GPU per dollar in training and interference (running a model): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://timdettmers.com/wp-content/uploads/2023/01/GPUs_Ada_performance_per_dollar6.png&amp;sa=D&amp;source=editors&amp;ust=1765035743729068&amp;usg=AOvVaw19JOY3FJeMNmM5nA7nQ12j">click</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- How to check whether the model is instrumental or vocal?</span></p><p class="c1"><span class="c0">Q: Are VR Arc models also grouped between instrumentals/vocal models, or it&#39;s just MDX-Net models?</span></p><p class="c1"><span class="c0">A: The moment you see Instrumental on top (and Vocal below) in the list where GPU conversion is mentioned, you know it&#39;s an instrumental model.</span></p><p class="c1"><span class="c0">When it flips the sequence, so Vocal on top, you know it&#39;s a vocal model. </span></p><p class="c1"><span class="c0">Same happens for MDX and VR archs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: [How to] have UVR automatically deleting the ensemble result folder after processing a song.</span></p><p class="c1"><span class="c0">A: Go to settings, ensemble options, uncheck &quot;Save all outputs&quot;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You can perform the Manual ensemble on your own already separated files (e.g. from Colab) in UVR5 under &quot;Audio Tools&rdquo;. Just ensure that files are aligned (begin in the same place). Sometimes using lossy files can mess with offset and file alignment.</span></p><p class="c1"><span class="c0">- Furthermore, you can use Matchering in Audio Tools, e.g. to fit muddy results without residues, to the separation with more clarity, but containing residues you want to get rid of. Just use file without residues as target,</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you have crashes on &ldquo;saving stem&rdquo; uninstall odrive</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Q: An option to add the model&#39;s name to the output files (this existed in a previous version of UVR but now it&#39;s gone) it was really useful when you needed to test multiple models on the same song</span></p><p class="c1"><span class="c0">A: It&#39;s still there under additional settings &quot;Model Test Mode&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Q: I want to separate an audio from a video (input is still empty when I choose a file)</span></p><p class="c1"><span class="c0">A: Go to General Process Settings&gt;Accept Any Input</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Q: First time trying the ensemble mode and I used the VR Models: &quot;De-Echo-Aggresive, De-Echo-Normal, DeEcho-DeReverb, DeNoise&quot; now the outputs confuse me. In the folder called &quot;Ensembled-Outputs&quot; there are many files which are from each of the models. Outside that directory are 2 wav files, one says Echo the other No Echo. Isn&#39;t the ensemble mode basically a wav file that goes through each model and saves a final wav file after it went through all the models listed?</span></p><p class="c1"><span class="c0">A: The two files outside the ensemble folder are the final ensembled files.</span></p><p class="c1"><span class="c0">The folder is all the separate outputs from each model (you&#39;ve enabled that in settings)</span></p><p class="c1"><span class="c0">Q: Those files are final after they went through all the models, right? Not just the DeEcho model.</span></p><p class="c1"><span class="c0">A: Yes</span></p><p class="c1"><span class="c0">Q: I am just suspicious of the naming, I see at the time, and it makes sense that the files outside the directory are the final version although are they after all the models or just 1 model.</span></p><p class="c1"><span class="c0">A: The naming is just whatever stem is assigned to the models, in your case all the models output echo and no echo file</span></p><p class="c1"><span class="c0">so the final ensemble files will have that in the name</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Q: What is this &quot;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/900904142669754399/1193600744377552987/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743734621&amp;usg=AOvVaw3da-wX9wo6-GEweBb0sV1K">band</a></span><span class="c0">&quot; that I keep seeing in the spectrograph of tracks that I&#39;ve isolated with x-minus?</span></p><p class="c1"><span class="c0">A: MDX noise - a noise it produces no matter what. In UVR you can use denoise standard/model in options&gt;Advanced MDX-Net it will do exactly what the below describes:</span></p><p class="c1"><span class="c0">You can either use UVR De-noise model or isolate the track twice. Once normal one and already inverted,</span></p><p class="c1"><span class="c0">then you add the results of normal-inst, inverted-inst, reinvert the inverted-inst, merge both normal and reinverted-inst.</span></p><p class="c1"><span class="c0">The merged will be without noise, but 6 dBs higher - so lower the gain accordingly, and you&#39;ll get the same, just no noise. Repeat that for vocals obviously.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Q: voc_ft doesn&rsquo;t have any spectrum above 17.7kHz. How to restore it, and have e.g. 48kHz or 96kHz output like the input file has?</span></p><p class="c1"><span class="c0">A: Turn off &ldquo;Match Freq Cut-off&rdquo; but it copies the remaining frequencies from the original, leading to possibly more noise.</span></p><p class="c1"><span class="c0">&ldquo;if you want true 96 kHz you need to manually lower the rate for 44100 Hz or less since the models themselves are 44100 Hz&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- It can happen that VR models using 512 window size can crash on 4GB cards, but 272 will be fine, although it will take more time</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &ldquo;I have tried everything and also googled a lot, but UVR with MDX-Net is producing me this type of noise in every sample I have tried, that was not in the recording before. Anybody have an idea what can cause it?&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: &ldquo;It&rsquo;s just part of the architecture. Either run it through a denoise model or run it through it twice with the second time the sound being phase-inverted&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Enabling Denoise Output should do the trick. I use the Denoise Model option, seems to work quite well, to my ears, at least&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &ldquo;Is there any way to fix the uvr bve model saying &quot;vocals&quot; on the bgv and &quot;instrumental&quot; on the lead vocal file? It&#39;s unbelievably annoying&rdquo;</span></p><p class="c1"><span>A: Change primary stem from whatever it is set to the opposite in model options (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/875539590373572648/1204228165506039898/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743738204&amp;usg=AOvVaw1bqa_-hmzMW5FtAQKdVqCJ">screenshot</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Matchering gives errors with long files.</span></p><p class="c1"><span class="c0">A: 14:44 input length limit for both target and reference audio is set, and sth slightly above it caused error (probably a bit above 15 mins, so maybe 15 minutes is a limit).</span></p><p class="c1"><span class="c0">If you see the error log, it will specify whether the reference or target file is too long, but the limit is the same for both.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &ldquo;Is there any way to batch-process multiple different models on the same file?</span></p><p class="c1"><span class="c0">A: Yeah, ensemble, turn individual outputs on [in options], you&#39;ll have the same song over and over, each with a different model name attached, all saved before the final min/max/avg mix&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you drag and drop many files at the same time into the input field and save intermediate files in options, you don&#39;t have to do manually start separation for every song. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The feature to save intermediate files is probably enabled by default in options&gt;Choose Advanced&gt;Ensemble&gt;Save all outputs</span></p><p class="c1"><span class="c0">IDK if &quot;Model test mode&quot; in Options&gt;Additional is necessary for it (Settings Test Mode can be additionally enabled too, just in case something gets overwritten by accident if you change settings).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So you can simply use Ensemble to pick all models you want to batch process, and using drag and drop, to separate all songs you want, using all models you picked in the Ensemble, and probably intermediate files (so from the models) will be saved rather intact, no matter what ensemble algorithm you&#39;ll use. You can make a manual ensemble with any algorithm with existing intermediate files later.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;Invalid buffer size: 17.34 GB&quot; (Mac ARM) when using demucs_ft</span></p><p class="c1"><span class="c0">Try to uninstall and make a clean installation of UVR.</span></p><p class="c1"><span>Consider also using the latest Roformer </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">patch</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(4-5 max ensemble explained moved to MDX settings)</span></p><h4 class="c17" id="h.4t9vx74g45zt"><span class="c21">- Chunks may alter separation results </span></h4><p class="c1"><span class="c0">(update: chunks are now replaced with batch mode on even 4GB cards, feature was introduced in one of beta patches and is available in v. 5.6, and you cannot use chunks experimentally in this version if batch mode gives you some vocal pop-ups vs 11GB GPUs which is a pretty common issue in 5.6; the old text for old UVR pre 5.6 code with chunks available follows). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">E.g. a bigger chunk value will less likely cause instruments disappearing.</span></p><p class="c1"><span class="c0">Chunks 1 is not the same as chunks full (disabled). Also, chunks may cause distorting briefly some vocals in the middle when split is being made. Chunks &ldquo;auto&rdquo; is calculated individually for your VRAM and RAM configuration (also song length), so the result will differ among various users for the same song. Maximum chunks value differ for various MDX models (e.g. NET 1 will allow for bigger values than newer Inst models with higher training frequency). You can test what is the maximum supported chunk size for your computer specs till you encounter crash (e.g. for 5:11 song and inst main 496 - chunks 15 (20 for 30 s song) for 4GB desktop card, 38 for 6GB laptop card (50 for NET 1 model), and around 50 for 11GB). Sweet spot for 3:39 track is chunks 55 (works at least on 16GB VRAM) - more than that gives worse results. Also on some GPUs/configuration you may notice some variations in very short vocal bleeding not (fully) associated with chunks which don&rsquo;t happen on e.g. x-minus or other configurations (1660 Ti vs 1080 Ti and 960 (we don&rsquo;t know what causes it). In this case, you can only alleviate the issue by changing chunks. Be aware that low maximum chunks on 4GB cards beside more sudden vocal residues and cuts in the result, may cause also specific artefacts like e.g. beeping not existing on e.g. 11GB card (the issue happen in Kim vocal model).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.yx8u0ahol7ao"><span>(older) </span><span class="c42 c36 c51 c33 c24 c30">UVR &amp; x-minus.pro updates/news (2021-2023)</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What is the segment size/overlap for VOC FT processing for uve bve models on x-minus, aufr33?</span></p><p class="c1"><span class="c0">A: --segments_mdx 384</span></p><p class="c1"><span class="c0">--overlap_mdx 0.1</span></p><p class="c1"><span class="c0">uvr bve v1</span></p><p class="c1"><span class="c0">-0.2, -0.05 and 0.15</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Average aggressiveness is 0.0 (for v2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Anjok (UVR5) &ldquo;I made a few more fixes to batch mode for MDX-Net before I release it publicly to GitHub later this week. This install also includes a new full band model that will be included in this week&#39;s public patch. Please let me know if you run into any bugs or issues.&rdquo;</span></p><p class="c1"><span class="c0">Link (not needed anymore):&rdquo;</span></p><p class="c1"><span class="c0">(the model is called UVR-MDX-NET-Inst_HQ_1 - it&rsquo;s epoch 450, better SDR than 337 and 403 models, only sometimes worse than narrowband inst3 [464])</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Anjok: &quot;I decided to make a public beta for everyone here who wants to try the new patch with **batch mode for MDX-Net** before I release it publicly to GitHub next week. This install also includes a **new full band beta model**! [full_403] Please let me know if you run into any bugs or issues.&rdquo; Patch download link</span></p><p class="c1"><span class="c0">If you don&#39;t have the new model on the list, make sure you have &quot;Download more models&quot; on your list.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The beta patches are currently only for Windows (but just the fb 403/450 models can be used in the older UVR version, and it works correctly - the patch itself is an exe installer which has the model inside and doesn&#39;t check for current UVR installation)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Update 14.02.23</span></p><p class="c1"><span class="c0">&quot;I found a bug in the MDX-NET.</span></p><p class="c1"><span class="c0">If the input song contains a DC offset,</span></p><p class="c1"><span class="c0">there will be a lot of noise in the output!</span></p><p class="c1"><span class="c0">It has already been fixed on the XM.</span></p><p class="c1"><span>It will also be fixed soon in the next UVR GUI update.&quot; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/900904142669754399/1075014031326330991&amp;sa=D&amp;source=editors&amp;ust=1765035743749868&amp;usg=AOvVaw3WbBVQ7rYb0PClKG-Vk4kl">Examples</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Update 11/12.02.23</span></p><p class="c1"><span class="c0">&quot;I will soon add a new setting to fine tune the Karokee / B.V. model. This will help remove **even wide stereo lead vocals**.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;You can now specify the placement of the lead vocal. The percentages are approximate vocal wideness.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/900904142669754399/1073823800161996931&amp;sa=D&amp;source=editors&amp;ust=1765035743750623&amp;usg=AOvVaw1glsidlJj6k9iMXU1p9eZX">Here</a></span><span class="c0">&nbsp;is the current result. As you can hear, the lead vocals are hardly removed [in the old setting].&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;this is super cool, if you invert the 2 results you can actually get the stereo width vocals isolated</span></p><p class="c1"><span class="c0">1 step closer to more than just 1 track bgvox separation&quot;</span></p><p class="c1"><span class="c0">&quot;Ooo that&#39;s very interesting, stereo lead vocals always get confused for background ones&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Update 4.02.23</span></p><p class="c1"><span class="c0">New chain ensemble mode for B.V. models available on x-minus</span></p><p class="c1"><span class="c0">&quot;the chain is the best bg vox filtering I&#39;ve ever heard&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It mixes MDX lead vocal and a little bit of instruments. The resulting mix is then processed by the UVR (b.v.) v2 model and the cleaned lead vocal is inverted with the input mix (song).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unlike min_mag and other methods, when using chain, processing is sequential. One model processes the result of another model. That&#39;s why I called it a &quot;chain&quot;.&quot; Aufr33 </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Update 31.01.23</span></p><p class="c1"><span class="c0">&quot;**The new MDX Karokee model is ready and will be added to [x-minus.com] tomorrow!***&quot; aufr33</span></p><p class="c1"><span class="c0">New Demucs 4 (probably instrumental) model is in training. edit. training stopped due to technical issues and full band MDX models were trained instead.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Throwing a Demix Pro karaoke model for comparison... I think the bgv parts still sound better for this song, but demix has more noise on the lead parts</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Demix keeps more backing [backround] (and somehow the lead vocals are also better most of the time, with fuller sound)&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;MDX in its pure form is too aggressive and removes a lot of backing vocals. However, if we apply min_mag_k processing, the results become closer to Demix Pro.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;In the future, we will create a [b.v.] model for Demucs V4. The MDX-NET is not really well suited for such a purpose.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Update 24.12.22</span></p><p class="c1"><span class="c0">Wind instruments model (saxophone, trumpet, etc.) added to x-minus for premium users (since March now also in UVR5).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I tested. Maximum aggressiveness extracts the most amount of instrument, while minimum the least. The model is not bad at all, but has hiccups often (maybe it needs a much larger dataset)&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Maximum aggressiveness &quot;gives you more wind&quot;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Update 20/19.12.22</span></p><p class="c1"><span class="c0">New UVR5 GUI 5.5.0 rewrite was released. Lots of changes and faster processing.</span></p><p class="c1"><span class="c0">MDX 2.1 model added as inst main (inst main 496) in UVR5 GUI. </span></p><p class="c1"><span class="c0">- There was some confusion about MDX 2.1 model being vocal 438, but it&rsquo;s inst main.</span></p><p class="c1"><span class="c0">MacOS native build available on GitHub.</span></p><p class="c1"><span class="c0">VIP models are now available for free with a donation option.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">More changes:</span></p><p class="c1"><span class="c0">&quot;Pre-process mode for Demucs is actually very useful. Basically, you can choose a solid mdx-net or VR model to do the heavy lifting in removing vocals and Demucs can get the rest with far less vocal bleed&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Secondary Models are a massive expansion of the old &quot;Demucs Model&quot; check button MDX-Net used to have. You&#39;ll want to play around with those to find what works for the tracks your processing.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There was also Spectral Inversion added, but it seems to decrease SDR slightly.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There was an additional cutoff to MDX models introduced - &ldquo;Just a heads up, for mdx-net, the secondary stem frequencies have the same cut-off as the primary stems now </span></p><p class="c1"><span class="c0">There were complaints about lingering vocals (or instrumentals depending on the model) in the upper frequencies that was audible and very bothersome&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Update 04.12.2022</span></p><p class="c1"><span class="c0">&quot;**A new MDX model has been added!**</span></p><p class="c1"><span class="c0">This model uses non-standard FFT settings optimized for high temporal resolution: 2048 / 5210</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035743757898&amp;usg=AOvVaw3JG39Jng1PVm_2hoAMSIbR">https://x-minus.pro/ai?hp&amp;test</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">[results are very promising]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">edit. 19.12. Final main model sometimes leaves more vocal leftovers.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Update 16.11.2022</span></p><p class="c1"><span class="c0">&quot;Due to anti-Russian sanctions, I will no longer be able to receive your donations from December 9th. All available withdrawal methods are no longer available to me. I will try to solve this issue, and probably move to another country such as Kazakhstan or Uzbekistan, but it will take some time, and servers must be paid for monthly.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>As a temporary solution, I will use Boosty. I ask everyone who is subscribed to Patreon to cancel your subscription and subscribe to Boosty: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://boosty.to/uvr&amp;sa=D&amp;source=editors&amp;ust=1765035743759189&amp;usg=AOvVaw2H70CcGXD66KmddeFySZOu">https://boosty.to/uvr</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">**Just a reminder that I&#39;m switching from Patreon to Boosty.** </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you want to renew your subscription but don&#39;t want to mess with Boosty, I&#39;ve found an alternative for *European* users!</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.profee.com&amp;sa=D&amp;source=editors&amp;ust=1765035743759718&amp;usg=AOvVaw3w0B0ySbB9sV0Wuy67WuOv">https://www.profee.com</a></span><span class="c0">&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you have any questions, DM aufr33 on Discord.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Update September 2022</span></p><p class="c1"><span class="c0">New VR model added to UVR5 GUI for patreons.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Update 31.10.22</span></p><p class="c1"><span class="c0">The release of the new instrumental models for patreons - </span></p><p class="c1"><span class="c0">optimised for better hi-end (lower FFT parameter), not so big cutoff during training and possibly better results for hip-hop (and possibly more genres).</span></p><p class="c1"><span class="c34">https://www.patreon.com/uvr</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_1 is Epoch 415</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_2 is Epoch 418</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_3 is Epoch 464</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The last one is the best model (at least out of these three) so far, although -</span></p><p class="c1"><span class="c0">&ldquo;I like it 50/50. In some cases it does a really good job, but on others it&#39;s worse than 418.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;New models are great! I&#39;m having a little issue on higher frequencies hanging in the vocals, but I found I can remove that by processing again&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Anyone else still uses inst 464? I&#39;ve been testing it and my conclusion is that it&#39;s a great model alongside 418</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">the pros of it are that it sounds fuller and doesn&#39;t have a lot of vocal residues, but it falls short when picking up some vocals, there might be occasions where it misses some bits, or you can hear some very low or very high-pitched vocals (though this is mostly fixed by using other models)&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I&#39;ve only tested one track so far, with 468 (My usual first test; Rush - The Pass). First off, it&#39;s the cleanest vocal removal of the track yet. First model to really deal with the reverb/echo and faint residuals ... but also the first model to trap a ton of instrumentation in the vocal stem. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Fascinatingly again, the UVR Karaokee model was able to almost perfectly remove the trapped instrumentation from the vocal line, creating a much more perfect result. I don&#39;t know if the new models were trained with this in mind, but the Karaokee model has proven to be extremely effective at this. The two almost work as a necessary pair.&quot;</span></p><p class="c1"><span class="c0">(UVR Karaoke model should be available on MVSEP or maybe also x-minus, and of course UVR5 GUI and it&#39;s free and public)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">September update</span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">of MDX vocal models added only for premium users (more models available in GUI, to be redeemed with code). They&#39;re available online exclusively for our Discord server via this link:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/ai?hp%26test-mdx&amp;sa=D&amp;source=editors&amp;ust=1765035743764205&amp;usg=AOvVaw0YDHphhW3bWiyd5mpVmJdK">https://x-minus.pro/ai?hp&amp;test-mdx</a></span></p><p class="c1"><span class="c0">(probably not needed or working anymore as training is finished and final models are already released from this training period, but I&#39;ll leave it just in case).</span></p><p class="c1"><span class="c6">edit. Be aware that models below are outdated and newer above supposed to outperform already them</span></p><p class="c1"><span class="c6">(outdated, as some old models got deleted from x-minus)</span></p><p class="c1"><span class="c0">mdx v2 (inst) = 418 epoch (inst model)</span></p><p class="c1"><span class="c0">mdx v2 (voc) = 340 epoch (voc model)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Description for new </span><span class="c22">MDX </span><span>VIP vocal ones (instrumental based on inversion) and instrumental models (vocal models 9.7 (NET 1) and 423 available</span><span class="c22">&nbsp;</span><span class="c0">on MVSEP under MDX-B option): </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Vocal models:</span></p><p class="c1"><span class="c0">- beta 340 is better for vocals, while -</span></p><p class="c1"><span class="c0">- 390 has better quality for instrumentals, though it has more vocal residues.</span></p><p class="c1"><span class="c0">- &quot;423 is really nice for extracting vocals, but is not good for instrumentals</span></p><p class="c1"><span class="c0">- 427 is not good for me.&quot; </span></p><p class="c1"><span class="c0">- &ldquo;In the last 438 vocals are really nice, also backing vocals. Unfortunately, we can hear more music noises, but voices are amazing&rdquo; (it&#39;s good for cleaning artifacts from inverts). &ldquo;(no longer available, at least on x-minus). </span></p><p class="c1"><span class="c0">- Beta 390 is better than 340. Instruments are cleaner but have more vocal disturbances.</span></p><p class="c1"><span class="c0">- I&#39;ve tried a combination of MDX 390 - UVR min_mag_k. Not really bad at all&rdquo;.</span></p><p class="c1"><span class="c0">- &quot;406 keeps most of these trumpets/saxes or other similar instruments, and ensembling with max_mag means it combines it with UVR instrumental which already keeps such instruments, so you get best of both worlds&quot;.</span></p><p class="c1"><span class="c0">Instrumental models:</span></p><p class="c1"><span class="c0">- 430 or 418 are worth checking. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Update 17.11.2021</span><span>&nbsp;- older public UVR 9.6 and 9.7 vocal models (but still decent) for MDX are described in &quot;</span><span class="c4"><a class="c3" href="#h.pv80l0nr97r5">MDX-Net with UVR team</a></span><span class="c0">&quot; section.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Upcoming UVR5 updates (outdated)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Since the training of MDX September models is completed, some older beta models might not be available anymore.</span></p><p class="c1"><span class="c0">As of the middle of September a new VR model was in training, but cancelled due to not &quot;conclusive&quot; results, although later a new VR model was released.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;these models will be next:</span></p><p class="c1"><span class="c0">1. Saxophone model for UVR.</span></p><p class="c1"><span class="c0">2. &quot;Karokee&quot; model for MDX v2.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, completely rewritten UVR5 GUI version. </span></p><p class="c1"><span class="c0">Among many new features - new denoiser for MDX models available and new Demucs 4 models (SDR 9).</span></p><hr style="page-break-before:always;display:none;"><h5 class="c5 c7" id="h.gayylnl910g1"><span class="c42 c36 c51 c33 c24 c30"></span></h5><h5 class="c5" id="h.wbc0pja7faof"><span class="c42 c12 c15 c33">Online sites and Colabs for separation - the best quality freebies you can currently get</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c42 c15 c36 c20 c37">Refrain from using lossy audio files for separation (e.g. downloaded from YouTube) for the best results.</span></p><p class="c1"><span class="c20 c37">See </span><span class="c4 c20 c37"><a class="c3" href="#h.ataywcoviqx0">here</a></span><span class="c20 c37">&nbsp;</span><span class="c42 c15 c36 c20 c37">for ripping lossless music from Tidal, Qobuz, Deezer, Apple Music or Amazon. </span></p><p class="c1 c7"><span class="c42 c15 c36 c20 c37"></span></p><p class="c1"><span class="c0">If you don&#39;t have a computer, or decent CPU/GPU and separation is too slow on your machine using UVR 5 GUI, or it doesn&rsquo;t work correctly for you, you can use these online sites to separate for free:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://mvsep.com&amp;sa=D&amp;source=editors&amp;ust=1765035743771962&amp;usg=AOvVaw2Z_f3RsBdo4qd--oDI57KJ">mvsep.com</a></span><span class="c0">&nbsp;(lots of the best UVR 5 GUI models incl. various Roformers, and some exclusive models not available in UVR, and ensemble of these for paid users)</span></p><p class="c1"><span class="c0">The page by MDX23 code/Colab original author and models&rsquo; creator - ZFTurbo.</span></p><p class="c1"><span class="c34 c42 c36 c33 c30 c50">If you register an account on MVSep, you can output in .flac and .wav 32-bit float.</span></p><p class="c1"><span class="c0">Since 28.07.25, now 32-bit float for WAV will be used only if gain level fall outside 1.0 range, otherwise 16 bit PCM will be used.</span></p><p class="c1"><span class="c0">Also, now FLAC uses 16-bit instead of 24-bit.</span></p><p class="c1"><span class="c0">If you have troubles with nulling due to the new changes in free version, consider decreasing volume of your mixtures by e.g. 5dB, and you won&rsquo;t be affected, although it might slightly affect separation results.</span></p><p class="c1"><span>I</span><span class="c0">f your credits are higher than 0, you have shorter queue (also users using the mobile app have &ldquo;a bit higher priority&rdquo;), 100 MB max file size/10 minutes (up to 10 concurrent separations in premium and 1GB/100MB in premium). You can disable using credits for non-ensembles in settings, for the cost of a longer queue again. Shorter queues seem to be currently around mornings of GMT +2/CEST (9 a.m.) or even early afternoon or late at night, depends - sometimes the queue goes crazy long randomly, but if you don&rsquo;t care, you can just set your jobs and download it the next day.</span></p><p class="c1"><span class="c0">Selecting &ldquo;Extract from vocals part&rdquo; uses the best BS-Roformer models as preprocessor for the chosen model (currently the ver. 2024.08 - subject to change).<br>For Mel Band Kar dim_t 801 and overlap 2 is used, and for Mel Becruily inst/voc, Mel 2024.10, Mel Rofo Decrowd: 1101 and 2.</span></p><p class="c1"><span class="c0">If downloading from the site is too slow try out e.g. Free Download Manager (Win) or ADM (Android) and/or VPN, or if you have premium you can use your credits to pack to zip the separation after your separation is done. </span></p><p class="c1"><span>Batch processing with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/MVSep-API-Examples&amp;sa=D&amp;source=editors&amp;ust=1765035743775389&amp;usg=AOvVaw3ZkS-nGSe0pi-zYXk8wkkw">API</a></span><span>&nbsp;</span><span>and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/MVSep-API-Examples/tree/main/python_example4_gui&amp;sa=D&amp;source=editors&amp;ust=1765035743775558&amp;usg=AOvVaw20mYjQkDPeejFRi9m4Iqkv">GUI</a></span><span>&nbsp;- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1335760269598523433&amp;sa=D&amp;source=editors&amp;ust=1765035743775681&amp;usg=AOvVaw08efs80s4jla3p4ICldrg9">click</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/septcoco/macvsep/&amp;sa=D&amp;source=editors&amp;ust=1765035743775758&amp;usg=AOvVaw2uwDbcqtIaaMLg0COOlJo4">Mac</a></span><span>)</span><span class="c0">. You can use MVSEP download links as remote URL in order to further separate the result (e.g. MVSEP Drums&gt;drumsep for more stems).</span></p><p class="c1"><span class="c0">Q: Is there a way to turn off the normalization when using FLAC?</span></p><p class="c1"><span class="c0">It&#39;s annoying when you have to combine the outputs later</span></p><p class="c1"><span class="c0">A: &ldquo;No, if you turn off normalization, FLAC will cut all above 1.0</span></p><p class="c1"><span class="c0">And if it was normalized, it means you had these values.&rdquo;</span></p><p class="c1"><span class="c0">FLAC doesn&rsquo;t support 32-bit float, it&rsquo;s 32 int, so normalization is still needed.&rdquo;</span></p><p class="c1"><span class="c0">So if your stems don&rsquo;t invert correctly, just use WAV.</span></p><p class="c1"><span>Q: How multichannel is handled by MVSEP:<br>A: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1143136052547178516&amp;sa=D&amp;source=editors&amp;ust=1765035743776927&amp;usg=AOvVaw1uCSJ613mwuIuCXtspx28d">librosa script</a></span><span class="c0">&nbsp;which performs stereo downmixing (for 5.1 or 7.1 inputs)</span></p><p class="c1"><span class="c0">Q: I convert a song using v1e+ and use phase fix, then do another conversion using for example Gabox V7 and use phase fix, if I go back to upload the same song using v1e+ it gives the stems instantly but if I use phase fix it will process again, in the past it would remember</span></p><p class="c1"><span class="c0">A: This may be a temporary issue. Sometimes that server may be unavailable, then processing will start on another server.</span></p><p class="c1"><span class="c0">Q: What&rsquo;s &ldquo;include results from independent models&rdquo;?</span></p><p class="c1"><span class="c0">A: &ldquo;When you use an ensemble, you will also get results from each model of the ensemble and not only the ensemble final result.&rdquo;</span></p><p class="c1"><span class="c0">Q: What means &ldquo;Disown Expired Separations&rdquo; option</span></p><p class="c1"><span class="c0">A: &ldquo;we do not delete expired separation data (they are needed for analytics), but just remove your ownership from expired separations</span></p><p class="c1"><span class="c0">We could have written delete expired separations, but wanted to be more clear about your data&rdquo;</span></p><p class="c1"><span class="c0">Q: &ldquo;So I understand, all the uploads are kept, regardless of &#39;disowning&#39; or not. So what is the distinction between disowning and not disowning? Is there one?&rdquo; </span></p><p class="c1"><span class="c0">A: no uploads are kept, just settings. If you disown, you won&#39;t see your expired separations </span></p><p class="c1"><span class="c0">Q: I will need a refresher in terms. Separations are created from (audio) uploads. Separations are also not kept? Only the settings used, i.e. kuielab_a_drums, aufr33-jarredou_DrumSep_model_mdx23c_ep_141_sdr_10.8059, and whatever segment, aggression, vocal only, etc are selected at the point of hitting &#39;do it&#39;.. in a manner of speaking..</span></p><p class="c1"><span class="c0">A: separation is when you choose settings and upload file, we just save the settings and delete file.</span></p><p class="c1"><span class="c0">Q: How to use the same file over and over for different models in order to test them, but without reuploading the same file over and over</span></p><p class="c1"><span>A: &ldquo;You can use remote upload for this. Just use link on file from previous separation. So you will not need to upload anything. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/remote&amp;sa=D&amp;source=editors&amp;ust=1765035743780328&amp;usg=AOvVaw06grErXm6UCXkQO_we99K6">https://mvsep.com/remote</a></span><span>&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://x-minus.pro&amp;sa=D&amp;source=editors&amp;ust=1765035743780513&amp;usg=AOvVaw3pBSdjBVU3xb_C28SS582P">x-minus.pro</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronlione.app&amp;sa=D&amp;source=editors&amp;ust=1765035743780598&amp;usg=AOvVaw20yOJdJXYqO9r1nvMD5-gF">uvronlione.app</a></span><span>&nbsp;</span><span class="c0">(-||-, 10 minute daily limit for free, very fast, mp3 192kbps output for free (lossless for premium), some exclusive models for paid users, Roformers will be back for free around 31 December 2024)</span></p><p class="c1"><span class="c0">The site is made by one of the UVR creators and models creator - Aufr33 with dedicated </span></p><p class="c1"><span class="c0">Overlap 2 used for Roformers. At subscription level standard and above, song limit for Roformers is 20 minutes. For Mel Karaoke model, dim_t 256 and overlap 2 is being used</span></p><p class="c1"><span>&ldquo;Mel-RoFormer by Kim &amp; unwa ft3 and some other models are hidden. As before, you can find them here: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?hp%26test&amp;sa=D&amp;source=editors&amp;ust=1765035743781592&amp;usg=AOvVaw2WI_qLT1t_OCWsKgf9-dru">https://uvronline.app/ai?hp&amp;test</a></span><span>&rdquo;</span><span>&nbsp;- Aufr33 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai?discordtest&amp;sa=D&amp;source=editors&amp;ust=1765035743781710&amp;usg=AOvVaw378L4ZbmFPs53OXBTNtb-0">link</a></span><span class="c0">&nbsp;for free users)</span></p><p class="c1"><span class="c0">Model used for phase fixer/swapper/correction on the site is Mel-Roformer Becruily Vocal</span></p><p class="c1"><span class="c0">___</span></p><p class="c1"><span class="c0">Alternatively, you can use Google Colab notebooks for free (with time limits), which are virtual runtime environments configured to use specific architectures and models or ensembles</span></p><p class="c1"><span class="c0">(see dedicated sections in the document outline for more information on specific Colabs).</span></p><p class="c1"><span class="c0">If downloading from the site is too slow, go to settings and turn on &ldquo;Use CDN&hellip;&rdquo; or try out e.g. Free Download Manager and/or VPN.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743783059&amp;usg=AOvVaw2MeHZbgBehUOP1dg-WKZz_">Music Source Separation Colab by jarredou</a></span></p><p class="c1"><span class="c0">Single models inference kept upd to date - new MDX23C Drumsep model, most if not all Roformers (now also /w 1053, and unwa/Gabo models), plus VitLarge, and Bandid model support for SFX and MelBand Decrowd, plus experimental SCNet, and both MDX23C and Mel-Roformer dereverb. <br>Based on ZFTurbo inference repo (optimized dependencies and frozen commit to avoid issues).</span></p><p class="c1"><span class="c0">No BigShifts here, and fixed overlap issues with Roformers from UVR.</span></p><p class="c1"><span class="c0">Use drumsep on already separated drums from already good sounding instrumental.</span></p><p class="c1"><span>Use 4 stem models at best on already well separated instrumental with a single model.<br>Detailed instruction how to use the Colab:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rentry.org/msst-colab&amp;sa=D&amp;source=editors&amp;ust=1765035743784619&amp;usg=AOvVaw1j4B4ZbIKbmtzVsB2j82q4">https://rentry.org/msst-colab</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What is TTA option?</span></p><p class="c1"><span class="c0">A: &ldquo;It means &quot;test time augmentation&quot;, with ZFTurbo&#39;s script, it will do 3 passes on the audio file instead of 1. 1 pass with be with original audio. 1 will be with inverted stereo (L becomes R, R become L). 1 will be with phase inverted and then results are averaged for final output. It gives a little better SDR score, but hard to tell if it&#39;s really audible in most cases&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;overlap: This helps improve separation quality slightly. Higher overlap might give better results at the cost of slower processing speeds.&rdquo; I&#39;ll go for 8. For instrumentals, oeverlap higher than</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;chunk_size: Just leave it default unless the model uses higher chunk_size in yaml (the Colab overrides the parameter).<br></span></p><p class="c1"><span class="c0">Sometimes it might fail to detect files uploaded on GDrive after mounting on Colab was done. Then open file manager in the Colab and show your input folder, so your file will appear and start working. Sometimes adding a new code field with:<br>drive.mount(&quot;/content/drive&quot;, force_remount=True)</span></p><p class="c1"><span class="c0">will be necessary (it forces remounting).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Colab instruction for newbies</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0. If you plan to use your GDrive for input files, go there now, and create a folder called &ldquo;input&rdquo; and upload your files there. Create also &quot;output&quot; folder in the root GDrive directory (not sure if the Colab creates both already). That way you may decrease the time till timeout, when the Colab is initialized (esp. for people with slower connection), and also you will avoid an occasional bug when files uploaded on GDrive appear with some delay in the Colab.</span></p><p class="c1"><span class="c0">The Colab is case aware - e.g. call your folder &quot;input&quot; not &quot;Input&quot; to match what is written in the Colab</span></p><p class="c1"><span class="c0">1. Now open the Colab link in your browser</span></p><p class="c1"><span class="c0">2. Click the &ldquo;play&rdquo; button on the &quot;GDrive connection&quot; cell. Grant all the privileges (otherwise there will be an error). </span></p><p class="c1"><span class="c0">Don&#39;t use any other account than you&#39;re already logged in in the right top corner (otherwise it will error out).</span></p><p class="c1"><span class="c0">3. Click the &ldquo;play&rdquo; button on the &quot;Install&quot; cell, and wait patiently til it&#39;s finished (it should show a green checkmark on the side afterwards) - be aware that rarely it can take a longer time than in most cases.</span></p><p class="c1"><span class="c0">4. Now pick your model in &quot;Separation&quot; cell.</span></p><p class="c1"><span class="c0">5. Click the &ldquo;play&rdquo; button on the &quot;Separation&quot; cell.</span></p><p class="c1"><span class="c0">Don&#39;t provide any filenames in input_folder path there. It will batch process all the files inside the input folder.</span></p><p class="c1"><span class="c0">Default settings are already balanced in terms of SDR, and not too resource-intensive (increasing overlap might muddy instrumentals a bit, 8 might have a bit more information on spectrogram iirc in vocals).</span></p><p class="c1"><span class="c0">TTA increases SDR a bit. I&#39;d leave it turned on, although it will separate 3 times.</span></p><p class="c1"><span class="c0">Chunk_size should be left default, as it&#39;s the value used by most models, but iirc beta 6 uses higher chunks. Refer to the yaml of the model, as the Colab will override yaml setting.</span></p><p class="c1"><span class="c0">6. After it&#39;s done, it will output the stems in the output.</span></p><p class="c1"><span class="c0">7. Before closing, go to Environment and delete the environment manually, so you won&#39;t exceed your free Colab credits (so you&rsquo;ll be able to use it e.g. next day).</span></p><p class="c1"><span class="c0">You should be able to use the Colab for 3,5h+ per day (I think 4h in at least not one single separation job started).</span></p><p class="c1"><span class="c0">If your GPU gets disconnected, change the Google account in the right top corner of the Colab and use the same account to mount GDrive.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Colab_Inference_BSRofo_SW_fp16.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743790930&amp;usg=AOvVaw3g2gNc1djJYw6kPcTHY4X7">Colab of 6 stem undef13 splifft</a></span><span>&nbsp;- SW BS-Roformer model, but in FP16 (almost identical metrics, but faster)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference)_CustomModel.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743791396&amp;usg=AOvVaw27m-0qQ949k4v2K0t8MMVd">Custom Model Import</a></span><span class="c0">&nbsp;Version of the inference Colab by jarredou. <br>You can use it if we don&rsquo;t add any new model to the main Colab on time, or you test your own models.<br><br>Just make sure you &ldquo;you have downloaded the webpage presenting the model instead of the model itself.&rdquo;</span></p><p class="c1"><span class="c0">E.g. for yamls from GH, use e.g.:<br>https://raw.githubusercontent.com/ZFTurbo/Music-Source-Separation-Training/main/configs/config_vocals_mdx23c.yaml&#39;</span></p><p class="c1"><span class="c0">Instead of:<br>https://github.com/ZFTurbo/Music-Source-Separation-Training/main/configs/config_vocals_mdx23c.yaml&#39;<br>And for HF, follow the pattern presented in the Colab example (so with the resolve in the address)<br>&ldquo;If you don&#39;t delete the failed yaml/ckpts downloads you&#39;ve made before [e.g. wrong link pasted], the Colab will continue to use them.&rdquo; so delete the files manually from file manager or restart environment while still getting errors.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/lucassantillifuck2fa/Music-Source-Separation-Training/blob/main/Phase_Fixer.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743792994&amp;usg=AOvVaw0_JU31TMNDAZ5fbYizESqf">Phase fixer Colab</a></span><span>&nbsp;by santilli_ using Kim model phase for unwa&rsquo;s v1e/v1/v2 and other models to get rid of some noise </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/13qM3HaQB6nh-OzCEH5RBzTVzTb4829oY?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743793269&amp;usg=AOvVaw2ern9nI_lbcE7x72edoVf3">(older outdated</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1uDXiZAHYk7dQajOLtaq8QmYXL1VtybM2&amp;sa=D&amp;source=editors&amp;ust=1765035743793391&amp;usg=AOvVaw0FXpdZ3yLy5_TQ0t8gtVPm">newer</a></span><span class="c0">) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/TheStinger/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035743793662&amp;usg=AOvVaw2CfWWa-bS48NFBXqYOT2Xp">UVR5 UI HuggingFace</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/qtzmusic/UVR5_UI&amp;sa=D&amp;source=editors&amp;ust=1765035743793788&amp;usg=AOvVaw20hXtvy7eL9TNgJrqgnB69">mirror</a></span><span>) maintained by NotEddy and hosted by their friend -</span><span class="c0">&nbsp;running on Zero GPU (A100 cluster), it has most models from the inference Colab. Might be faster.</span></p><p class="c1"><span>(HF has a quota ~12 min of usage each 2 hours, and it doesn&rsquo;t have TTA). Some </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1263877979696664669&amp;sa=D&amp;source=editors&amp;ust=1765035743794295&amp;usg=AOvVaw1PHC4Pm_Pcgz1hF8ms0epd">advice</a></span><span class="c0">&nbsp;to make it work on PC.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CH2JWd6YculmKSug9zpzuxvM6mSYysdB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743794668&amp;usg=AOvVaw2uycfooGqYo0R9kWgZlr83">SESA Colab by yusuf v3</a></span><span>&nbsp;</span><span class="c0">- WebUI for the same ZFTurbo inference code (might differ in available models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1IC6Q1hLF55_tK6mhky0SWYKGVF9T5WsY?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035743795211&amp;usg=AOvVaw1bGpPey6Fz5Q7hoj1Qiw6R">Extended inference Colab</a></span><span>&nbsp;by </span><span class="c41">makidanyee</span><span>&nbsp;</span><span class="c0">(also based on jarredou&rsquo;s) containing phase fixer as a separate cell to work on ready separations, zip/unzip cell, manual ensemble (all in one)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Eddycrack864/UVR5-NO-UI/blob/main/UVR5_NO_UI.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743795823&amp;usg=AOvVaw39_emZgTlwu-CfIdM5rzwj">Multi-arch Colab by Not Eddy</a></span></p><p class="c1"><span class="c0">Archs: MDX-Net, MDX23C, Roformers (incl. 1053), Demucs, and all VR models (incl. e.g. de-echo not supported in VR HV Colab) with YouTube support and batch separation. </span></p><p class="c1"><span class="c0">If you encounter increased separation time (like 5 hours) using some high parameters for MDX-Net models (e.g. 512 segment size and 0.95 overlap) use another Google account. You could&rsquo;ve reached free daily limit.</span></p><p class="c1"><span class="c0">Plus, be aware that the Colab uses broken overlap from OG beta UVR core for Roformers, so the same fix for the issue applies:</span></p><p class="c1"><span class="c0">Don&#39;t set overlap higher than 10 for 1101 segments, and overlap 8 for 801. Best SDR is dim_t=1101 and overlap 2.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Eddycrack864/UVR5-UI/blob/main/UVR_UI.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743797185&amp;usg=AOvVaw1P83BXY_RZ6_wwWH_zB-66">Not Eddy&rsquo;s multi-arch Colab</a></span><span class="c0">&nbsp;in form of UI (like in e.g. KaraFan)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In case of &ldquo;FileNotFoundError: [Errno 2]&rdquo; try other location than &ldquo;input&rdquo;, or other Google account in case of ERROR - mdxc_separator (helps for both errors).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or use the Colab below for Roformers instead:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743797967&amp;usg=AOvVaw0VB8wM6c1JrReDLc5EDlPO">MVSEP MDX23 jarredou fork Colab v.2.5</a></span><span class="c0">&nbsp;(2-4 stems)</span></p><p class="c1"><span class="c0">It has adjustable ensemble of BS-Roformer Viperx, Kim Mel-Roformer, UVR MDX-Net HQ_4, MDX23C HQ 1, VitLarge, voc_ft and has optional output to 4 stems using ensemble of various 4 stem demucs models. Original 1.0 code made by ZFTurbo (MVSEP).</span></p><p class="c1"><span class="c0">Consider using already well separated instrumental as input from the above Colabs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can manipulate with weights there to have more of a specific model in the final result.</span></p><p class="c1"><span class="c0">Default settings can be a good start. </span></p><p class="c1"><span class="c0">Sometimes you might want to disable VitLarge.</span></p><p class="c1"><span class="c0">Also, some people like to increase BigShifts to 20 or even 30 with all other default settings (some songs might be less muddy that way), </span></p><p class="c1"><span>but default 3 is already a balanced value, although exceeding 5 or 7 may not give a noticeable difference, while increasing separation time severely over default settings. </span><span class="c4"><a class="c3" href="#h.jmb1yj7x3kj7">Read</a></span><span class="c0">&nbsp;for more.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Eddycrack864/KaraFan/blob/master/KaraFan_Improved_Version.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743799799&amp;usg=AOvVaw10kVj6gRJTWCz4AaVoMDn7">KaraFan by Captain FLAM</a></span></p><p class="c1"><span class="c0">It allows using currently all notable UVR instrumental and vocal models besides BS-Roformer, also in ensemble (with suggested ensemble presets - start with P5 for instrumentals and P4 for vocals), but with further tweaks and tricks in order to get the best quality of instrumentals and vocals sonically, but without overfocusing on SDR only, but on the overall sound. Usually more vocal residues than instrumental Roformers.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1GwMEjhczFzdS0Ld7eZzMcZgEmz6Jgv6m&amp;sa=D&amp;source=editors&amp;ust=1765035743800685&amp;usg=AOvVaw0B5Nj_4aWz38yBcpcrMz6V">MDX-Net Colab by HV</a></span></p><p class="c1"><span class="c0">All older notable UVR-MDX models are in this fork, including HQ_5 (don&#39;t confuse with MDX23C arch) - very fast once the Colab initializes, but more vocal residues than instrumental Roformers.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kae0-0/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743801236&amp;usg=AOvVaw3zQMCm1ynPagfo0BUryJnL">MDX-Net alternative kae Colab</a></span><span class="c0">&nbsp;(fork of one earlier HV Colab version, not sure if it still works)</span></p><p class="c1"><span class="c0">In comparison to the above, it has the old min/avg/max mag mixing algorithms and optional Demucs 2 ensemble for only vocal models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl&amp;sa=D&amp;source=editors&amp;ust=1765035743801771&amp;usg=AOvVaw130aAN_2weP0AoxAEOePvJ">VR HV Colab</a></span><span class="c0">&nbsp;(even older archs with even more residues, no de-echo model - it&rsquo;s included in Not Eddy&rsquo;s HF/Colabs above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/117SWWC0k9N2MBj7biagHjkRZpmd_ozu1&amp;sa=D&amp;source=editors&amp;ust=1765035743802186&amp;usg=AOvVaw3B8OoVO_-6sEob0xVqdAKp">Demucs 4 - for 4 stems</a></span><span class="c0">&nbsp;(lower SDR than MDX23 Colab)</span></p><p class="c1"><span class="c0">You might want to use here already well separated instrumental with the methods above</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1KTkiBI21-07JTYcTdhlj_muSh_p7dP1d?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743802600&amp;usg=AOvVaw3-CO0Uwg6GPXPxopVP682Z">Batch separation for Demucs</a></span><span>&nbsp;by jarredou</span><span class="c0">&nbsp;(less friendly GUI, but should be usable too)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>older </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1wws3Qm3I1HfMr-3gAyW6lYzUHXG_kuyz&amp;sa=D&amp;source=editors&amp;ust=1765035743802925&amp;usg=AOvVaw298oS8x-eFthSrskcHCJ-r">Drumsep</a></span><span class="c0">&nbsp;by Imagoy (newer model above in Music Source Separation Colab) - kick, snare, hi-hat, toms (based on Demucs v3) - also use on already separated drums from already good sounding instrumental</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/larsnet-colab/blob/main/LarsNet_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743803407&amp;usg=AOvVaw3ny-f5_sWU42tcEb4iQ83J">LarsNet</a></span><span class="c0">&nbsp;- kick, snare, hihats, toms and also cymbals separation (can be worse than the old Imagoy&rsquo;s based on Demucs at times, but has more stems)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/r3gm/Ultimate-Vocal-Remover-WebUI&amp;sa=D&amp;source=editors&amp;ust=1765035743803800&amp;usg=AOvVaw3kpYDcarZnRki4mklgglxF">UVR on hugging_space</a></span><span class="c0">&nbsp;(incorporates VR de-echo not available in HV Colab,</span></p><p class="c1"><span class="c0">it&rsquo;s slower than Multi-arch Colab above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Bandit Plus, Mel-Roformer by jazzpear SFX separation - Colab by joowon</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1efoJFKeRNOulk6F4rKXkjg63RBUm0AnJ&amp;sa=D&amp;source=editors&amp;ust=1765035743804460&amp;usg=AOvVaw1sNU9Qe1NV3-Te26x7zvRI">https://colab.research.google.com/drive/1efoJFKeRNOulk6F4rKXkjg63RBUm0AnJ</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="#h.4svuy3bzvi1t">ByteDance-USS</a></span><span class="c0">&nbsp;(SFX separation based on audio sample, March 2024 update)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1f2qUITs5RR6Fr3MKfQeYaaj9ciTz93B2&amp;sa=D&amp;source=editors&amp;ust=1765035743804925&amp;usg=AOvVaw1KxYRwJaTQPZmkNzO1NuD4">https://colab.research.google.com/drive/1f2qUITs5RR6Fr3MKfQeYaaj9ciTz93B2</a></span></p><p class="c1"><span class="c0">Colab by jazzpear94</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/10x8mkZmpqiu-oKAd8oBv_GSnZNKfa8r2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743805229&amp;usg=AOvVaw1JLQgf0basBICJ2RTjQUfb">MedleyVox Colab</a></span><span class="c0">&nbsp;by Cyrus (can be used on MVSEP too)</span></p><p class="c1"><span class="c0">with chunking introduced</span></p><p class="c1"><span>Use already separated vocals as input (e.g. by </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">these</a></span><span>&nbsp;</span><span class="c0">models).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Collabs for upscalers (AudioSR, FlashSR, Apollo and more) - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.i7mm2bj53u07&amp;sa=D&amp;source=editors&amp;ust=1765035743805954&amp;usg=AOvVaw1SoQ17gvL8kRECIho4Uiil">here</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Other Colabs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MVSEP-MDX23 v2</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/main/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743806538&amp;usg=AOvVaw1vHZLRBvsoDyTOmXGp9WM-">https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/main/MVSep-MDX23-Colab.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MVSEP-MDX23 v2.1</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/deton24/MVSEP-MDX23-Colab_v2.1/blob/main/MVSep_MDX23_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743806958&amp;usg=AOvVaw2DSxVYae27ot_j-nhB_9sY">https://colab.research.google.com/github/deton24/MVSEP-MDX23-Colab_v2.1/blob/main/MVSep_MDX23_Colab.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MVSEP-MDX23 v2.2</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743807372&amp;usg=AOvVaw23XoFjj6y-qoz1Z_A4PBJj">https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MVSEP-MDX23 v2.3 </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.3/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743807840&amp;usg=AOvVaw34VTykyuZY7rKJW9c8Om2T">https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.3/MVSep-MDX23-Colab.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Not sure if all of these older versions has the following fix for slow separations:</span></p><p class="c1"><span class="c0">!python -m pip -q install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">jazzpear&#39;s soon to be 17-stem separation Colab (probably doesn&rsquo;t work anymore)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1jrw-cAi-JqZpBi6wyT3YIp3x-XHhDm1W&amp;sa=D&amp;source=editors&amp;ust=1765035743808802&amp;usg=AOvVaw2cs3BU0-n0l3Wm0zm_UVf3">https://colab.research.google.com/drive/1jrw-cAi-JqZpBi6wyT3YIp3x-XHhDm1W</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Similarity Extractor</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1WP5IjduTcc-RRsvfaFFIhnZadRhw-8ig&amp;sa=D&amp;source=editors&amp;ust=1765035743809185&amp;usg=AOvVaw2A_viNwCdsf4lIc_GrkgVD">https://colab.research.google.com/drive/1WP5IjduTcc-RRsvfaFFIhnZadRhw-8ig</a></span></p><p class="c1"><span class="c0">But Audacity&#39;s center extraction which can be used also online works better:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://wavacity.com&amp;sa=D&amp;source=editors&amp;ust=1765035743809468&amp;usg=AOvVaw0qUCK1n9AcFW3U5wvkEbo1">wavacity.com</a></span></p><p class="c1"><span>There was also MDX23C model for the same purpose released:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2417116936&amp;sa=D&amp;source=editors&amp;ust=1765035743809900&amp;usg=AOvVaw05cC3tokkocyZj4Abf161d">https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1#issuecomment-2417116936</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Useful repositories</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Python command line fork of UVR 5 with current models support</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/karaokenerds/python-audio-separator&amp;sa=D&amp;source=editors&amp;ust=1765035743810372&amp;usg=AOvVaw2s16QT4avLQCYc3UMtdKvv">https://github.com/karaokenerds/python-audio-separator</a></span></p><p class="c1"><span>(it used to have the same broken overlaps from UVR for Roformers)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">OG repo on which jarredou&rsquo;s single models Colab separation is made</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035743810906&amp;usg=AOvVaw0jDrSdraGSItvhPF0aC95f">https://github.com/ZFTurbo/Music-Source-Separation-Training</a></span></p><p class="c1"><span class="c0">(can be used locally both for inference [separation] and training)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It has other GUI too:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/AliceNavigator/Music-Source-Separation-Training-GUI&amp;sa=D&amp;source=editors&amp;ust=1765035743811390&amp;usg=AOvVaw3ZQeO4IdQVdwkhq85_sbE6">https://github.com/AliceNavigator/Music-Source-Separation-Training-GUI</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Using only CPU in the GUI might be fixed by changing line 149 to </span></p><p class="c1"><span class="c0">device = &#39;cuda&#39;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/AliceNavigator/Music-Source-Separation-Training-GUI/blob/66ada053a623a20865cac7b9d26a02615204d178/inference.py%23L148&amp;sa=D&amp;source=editors&amp;ust=1765035743812009&amp;usg=AOvVaw0bjp0fgpqRygI6psluoR5F">https://github.com/AliceNavigator/Music-Source-Separation-Training-GUI/blob/66ada053a623a20865cac7b9d26a02615204d178/inference.py#L148</a></span><span class="c0">&nbsp;~frazer</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">WebUI:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/SUC-DriverOld/MSST-WebUI&amp;sa=D&amp;source=editors&amp;ust=1765035743812289&amp;usg=AOvVaw2uCLdyD9fpbQaGn5gG6LWi">https://github.com/SUC-DriverOld/MSST-WebUI</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Other GUI for UVR</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TheStingerX/Ilaria-UVR&amp;sa=D&amp;source=editors&amp;ust=1765035743812561&amp;usg=AOvVaw3t9vGqjWx7awJmeRDUAMYn">https://github.com/TheStingerX/Ilaria-UVR</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Good paid sites:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://dango.ai&amp;sa=D&amp;source=editors&amp;ust=1765035743812870&amp;usg=AOvVaw0jdwCOZKcyoTa4Sx2NCNBS">dango.ai</a></span><span class="c0">&nbsp;(expensive, one of the best results for instrumentals)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://moises.ai&amp;sa=D&amp;source=editors&amp;ust=1765035743813056&amp;usg=AOvVaw0lxqzMJEKkF1yWrc1cuVMC">moises.ai</a></span><span class="c0">&nbsp;(probably in-house BS-Roformer models)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://studio.gaudiolab.io&amp;sa=D&amp;source=editors&amp;ust=1765035743813259&amp;usg=AOvVaw2v7iHMj19vMYoGUpew4xnP">studio.gaudiolab.io</a></span><span class="c0">&nbsp;(a.k.a. GSEP, still good for specific cases)</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://music.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035743813438&amp;usg=AOvVaw1wK1qsdADy6yCj0Cb8pn5g">Music AI</a></span><span>&nbsp;- better results than those on Moises (same team). $25 per month or pay as you go, pricing chart, no free trial, Good </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1206684280625963018/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743813719&amp;usg=AOvVaw0oqcICDcnbu4WLZcAnsbtD">selection </a></span><span>of models and interesting </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1206353306767728752/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035743813887&amp;usg=AOvVaw14Cftsk0BvUXA2TZLCmYfT">module stacking</a></span><span class="c0">&nbsp;feature. To upload files instead of using URLs &ldquo;you make the workflow, and you start a job from the main page using that custom workflow&rdquo; by [~ D I O ~].</span></p><p class="c1"><span class="c0">&ldquo;Bass was a fair bit better than Demucs HT, Drums about the same. Guitars were very good though. Vocal was almost the same as my cleaned up work. (...) I&#39;d say a little clearer than mvsep 4 ensemble. It seems to get the instrument bleed out quite well, (...) An engineer I&#39;ve worked with demixed to almost the same results, it took me a few hours and achieve it [in] 39 seconds&rdquo; by Sam Hocking</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="#h.tc4az79fufkn">Audioshake </a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://myxt.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743814938&amp;usg=AOvVaw2xZ5qbgCU033RiMC-2IBph">Myxt</a></span><span>&nbsp;- 3 stem model, u</span><span class="c0">nfortunately, it has/had WAVs with 16kHz cutoff which Audioshake normally doesn&#39;t have. No other stem. Results, maybe slightly better than Demucs. Might be good for vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Thanks to Mr. &#119810;&#119825;&#119828;&#119826;&#119827;&#119832; &#7580;&#691;&#7491;&#7495; for gathering lots of the links.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">More online site descriptions</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743815730&amp;usg=AOvVaw35XvSYo-PpNDzhOz2G3ptd">https://mvsep.com/</a></span><span class="c0">&nbsp;(FLAC, WAV 24 bit/32 bit for MDX instrumentals and Demucs, Roformers, 100MB per file limit, MP3 320kbps available, 512 window size for VR models (all UVR 5 GUI models including WiP piano [it&#39;s better than Spleeter worse than GSEP]), /wo HQ_4, big choice of various architectures and models.</span></p><p class="c1"><span class="c0">Good instrumental models: MDX23C 16.66, MDX B&gt;HQ_3, BS-Roformer 17.55</span></p><p class="c1"><span class="c0">Good vocal models: MDX B&gt;voc_ft, MDX23C 16.66 (more bleeding, better quality</span></p><p class="c1"><span class="c0">Ensemble for paid users (instrumentals have fewer residues than 2.4 Jarredou Colab, but are muddier)</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span>(old) In </span><span class="c22">Demucs 3-UVR</span><span class="c0">&nbsp;instrumental models - model 1 is less aggressive, model 2 is more destructive (sometimes it happens the opposite, though), the &ldquo;bag&rdquo; leaks even more, </span></p><p class="c1"><span class="c0">also, regular 4 stem model B - mdx_extra from Demucs 3 and also HT Demucs 4 (better ft model). For UVR-MDX models choose MDX model B, and the new field will appear. Biggest queue in the evenings till around 10 PM CEST, close to none around 15:00 (working days).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/ai&amp;sa=D&amp;source=editors&amp;ust=1765035743817539&amp;usg=AOvVaw1xi8Kie4Agu3qNSDweEDzj">https://x-minus.pro/ai</a></span><span class="c0">&nbsp;(10 minutes daily limit for free users - it can exceed like 1 minute on the last song)</span></p><p class="c1"><span class="c0">Currently, more models are available for free (like MDX and Roformer models), but some more resource hungry methods like drums max mag are behind paywall.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Good methods:</span></p><p class="c1"><span class="c0">Models ensembled - available only for premium users:</span></p><p class="c1"><span class="c0">- demudder (used on Mel-Roformer)</span></p><p class="c1"><span class="c0">- Mel-Roformer + MDX23C</span></p><p class="c1"><span class="c0">- drums ensemble max_mag with Roformer</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(old) Previously for free users only one UVR model without parameters for &quot;lo-fi&quot; option was available (unreleased model, mp3, 17kHz cutoff) and Demucs 3 (2 stem) (or 6 stems?) for registered users (site by of the authors) and Demucs 4 (4 stem) for premium users (and its better htdemucs_ft model for songs shorter than 5 minutes [better equivalent of previous demucs_extra model which wasn&#39;t quantized) and 7-8 minutes in the future (not sure if it also got replaced by 6s model for premium users as well).</span></p><p class="c1"><span class="c0">Besides WAV, paid users get exclusive unreleased VR model when aggressiveness is set to minimum.</span></p><p class="c1"><span class="c0">As the site development dynamically progresses, some info above can be outdated.</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.2y2nycmmf53"><span class="c42 c36 c24 c30 c47">MSST / MSST-GUI by ZFTurbo</span></h5><p class="c1"><span>Repository of MVSEP creator and model trainer: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035743820071&amp;usg=AOvVaw0DjX8NcH4D6rRuqeeDMZpn">https://github.com/ZFTurbo/Music-Source-Separation-Training</a></span></p><p class="c1"><span class="c0">It can be used either for training or also inference (separation using models).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>MSST-</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035743820452&amp;usg=AOvVaw0rZ3Z558IV-a1aioONlmh4">GUI</a></span><span class="c0">&nbsp;by Bas Curtiz (default list of models can get outdated, but you can provide file paths manually there too) other GUIs linked at the bottom. The GUI has screen reader compatibility.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(If you have a hard time setting your local Python environment with the above, you could try out portable installation of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/MSST-WebUI/tree/main/1.7.0&amp;sa=D&amp;source=editors&amp;ust=1765035743821056&amp;usg=AOvVaw0cTLxgjg-u-ZT_zf9bDnrp">Sucial&rsquo;s WebUI</a></span><span class="c0">&nbsp;fork, but I cannot guarantee the compatibility with all the latest models - the 1.7.0 code derives from April 2025)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>1. If you deal with dequantization error while occurring on e.g. crowd model on 1 hour mp3 file, use this repo instead:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training/tree/colab-inference&amp;sa=D&amp;source=editors&amp;ust=1765035743821734&amp;usg=AOvVaw2TMDFdqm5VKOo5beIR576f">https://github.com/jarredou/Music-Source-Separation-Training/tree/colab-inference</a></span></p><p class="c1"><span class="c0">&ldquo;It&rsquo;s the one used in Colabs&rdquo; - jarredou. Sometimes MSST updates might break things, while here a certain older checked commit is used.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2. &ldquo;For some reason when I use unwa models it just like gives back a really quiet resampled version of whatever I put in.&rdquo;</span></p><p class="c1"><span class="c0">A: &ldquo;Check that you are using up-to-date version of the repo, iirc, an edit made some months ago to Roformers code was creating weird issues similar to this for some people and was removed later&rdquo;</span></p><p class="c1"><span class="c0">Q: &ldquo;Works now&rdquo;</span></p><p class="c1"><span>Hint: Requirements just for inference might be faster to install like presented in the Installation cell in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743823146&amp;usg=AOvVaw3cYbxakQ8k0TBmfGJa-SSQ">this</a></span><span class="c0">&nbsp;Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3. For state_dict error using existing MSST installation, update MSST to the last repo version with:</span></p><p class="c1"><span class="c0">!rm -rf /content/Music-Source-Separation-Training</span></p><p class="c1"><span class="c0">!git clone https://github.com/ZFTurbo/Music-Source-Separation-Training</span></p><p class="c1"><span class="c0">&ldquo;and you must reinstall the main branch&#39;s requirement.txt. (before it, edit requirements.txt to remove wxpython)&rdquo; - Essid</span></p><p class="c1"><span class="c0">wxpython is for GUI.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MSST works on CPU or NVIDIA GPUs (by default it uses GPU if it&rsquo;s properly configured), and separates up to 3 times faster than UVR on 8GB GPUs (on 4GB it might be even slower). It was also tested on Linux and ROCm 6 and 7 on AMD GPU.<br></span></p><p class="c1"><span class="c0">- Unlike in UVR, MDX-Net v2 and VR archs are unsupported here.</span></p><p class="c1"><span><br>- Officially </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html&amp;sa=D&amp;source=editors&amp;ust=1765035743824721&amp;usg=AOvVaw1JOSrFvJ5iK6WcJmigD0wu">supported</a></span><span class="c0">&nbsp;AMD consumer GPUs for ROCm on Linux are: <br>RX 7900 XTX, RX 7900 XT, RX 7900 GRE and AMD Radeon VII on Ubuntu 24.04 LTS using Pytorch 2.6 for ROCm 6.3.3, but also RX 9070 and RX 9070 XT and RX 6700 XT should be manageable to work, and probably 5700 XT with older ROCm version.</span></p><p class="c1"><span class="c0">- For RX 7900 XTX &ldquo;No special editing of the code was necessary. All we had to do was install a ROCm-compatible version of the OS, install the AMD driver, create a venv, and install ROCm-compatible PyTorch, Torchaudio, and other dependencies on it.&rdquo; - unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- ROCm 7 officially working with Instinct MI350 CDNA 4 was released, providing 3-7x performance gains over 6.0 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.techpowerup.com/341074/amd-launches-rocm-7-0-up-to-3-8x-performance-uplift-over-rocm-6-0&amp;sa=D&amp;source=editors&amp;ust=1765035743826063&amp;usg=AOvVaw3-cr-oLqBre1jf9L7Tvf5k">more</a></span><span class="c0">). You can try your lack with it on other GPUs by e.g:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm7.0</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Since then also ROCm 6.4.4 allowing using PyTorch natively on Linux and Windows on RX 7000 and 9000 was released (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.techpowerup.com/341329/amd-enables-pytorch-on-radeon-rx-7000-9000-gpus-with-windows-and-linux-preview&amp;sa=D&amp;source=editors&amp;ust=1765035743826865&amp;usg=AOvVaw3xBZw1U-38S7umDdZlUWPU">more</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- &ldquo;I managed to make</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/SUC-DriverOld/MSST-WebUI&amp;sa=D&amp;source=editors&amp;ust=1765035743827094&amp;usg=AOvVaw0GAnFQBAa0xOMzWZ8uUBRE">&nbsp;MSST-WebUI</a></span><span class="c0">&nbsp;work [on Linux] with: </span></p><p class="c1"><span class="c6">Torch 2.10.0.dev20251110+rocm7.0 </span></p><p class="c1"><span class="c0">on RX 7600</span></p><p class="c1"><span class="c0">(...) it seems like ROCm 7.0 is about a second faster [than 6.x]&rdquo; <br>(probably by adding just pip install before it)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">turns out that if you do:</span></p><p class="c1"><span class="c6">export TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1</span></p><p class="c1"><span class="c0">it uses waay less VRAM and processes even faster</span></p><p class="c1"><span class="c0">inst_V1e_plus batch_size=2 overlap=3 chunk_size= 485100, 51.78s/it &nbsp;[3:50 of audio in 61 seconds]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For ROCm 6.x (a tad slower, might work on more GPUs):</span></p><p class="c1"><span class="c6">torch 2.9.0+rocm6.3 torchvision0.24.0+rocm6.3 [--index-url https://download.pytorch.org/whl/rocm6.3]</span></p><p class="c1"><span class="c0">Thanks, fr4z49.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Official support for PyTorch on RX 400/500 (a.k.a. Polaris/GCN 4/GFX803) GPUs was dropped, but you can follow </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/robertrosenbusch/gfx803_rocm&amp;sa=D&amp;source=editors&amp;ust=1765035743828989&amp;usg=AOvVaw1bU-CRgxSR6LVX5HfVhxqG">this</a></span><span class="c0">&nbsp;Ubuntu guide for unofficial ROCm 6 support (it might even potentially work from Windows using WSL with almost no GPU performance overhead).</span></p><p class="c1"><span>Or for ROCm 5, read </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nikos230/Run-Pytorch-with-AMD-Radeon-GPU&amp;sa=D&amp;source=editors&amp;ust=1765035743829367&amp;usg=AOvVaw1wb5oboAyhLQd6JPHngvS3">this</a></span><span class="c0">&nbsp;Ubuntu guide.</span></p><p class="c1"><span>Also, there seems to be some Arch Linux community package to install Pytorch still compatible for these GPUs (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs%23install-on-amd-and-arch-linux&amp;sa=D&amp;source=editors&amp;ust=1765035743829797&amp;usg=AOvVaw2PXMYiVhrWqlNJagm7MFA9">click</a></span><span class="c0">).</span></p><p class="c1"><span class="c0"><br>Or optionally also might be potentially supported with some other specific versions of ROC, e.g. 5.7.2 and also described above:</span></p><p class="c1"><span class="c20">export ROC_ENABLE_PRE_VEGA=1 </span><span class="c0">(deprecated in ROCm 6; might help for lacking dependencies or wheel building issues). Or also check out this:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/10435%23issuecomment-1555399844&amp;sa=D&amp;source=editors&amp;ust=1765035743830707&amp;usg=AOvVaw1dnjFx0qohINvbjyc60_uP">https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/10435#issuecomment-1555399844</a></span><span class="c0">, or alternatively follow below instructions:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pytorch.org/get-started/locally/&amp;sa=D&amp;source=editors&amp;ust=1765035743830976&amp;usg=AOvVaw0ukF4WUhHobxHX4j0qrl9F">https://pytorch.org/get-started/locally/</a></span><span class="c0">&nbsp;and then execute:</span></p><p class="c1"><span class="c20">pip3 install torch torchvision torchaudio --index-url </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://download.pytorch.org/whl/rocm5.4.2&amp;sa=D&amp;source=editors&amp;ust=1765035743831305&amp;usg=AOvVaw21oViEG94lkCxF5FF61onn">https://download.pytorch.org/whl/rocm5.4.2</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4. If you have SageAttention error, you need an arch corresponding to e.g.: RTX 5000, 4000, 3000, H100, H200 (Ada Lovelace, Hopper, Ampere, Blackwell) which will probably work out of the box. Otherwise, it will probably fall back to CPU. To fix it, make sure you have installed CUDA/Torch/Torchvision/Torchaudio compatible with your GPU</span></p><p class="c1"><span class="c0">(probably it will work down to Maxwell GPUs (not sure about Kepler):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;For the [GTX] 1660 the minimum [CUDA] version is 10&rdquo; E.g. minimum compatible CUDA version requirement for GTX 1660 is 10 (on GTX 1060, Torch 2.5.1+cu121 can be used), but pip doesn&rsquo;t find such a package of Torch (and usually it fixes issues when CPU is only used on those GPUs).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Check out index-url method described later below:</span></p><p class="c1"><span class="c0">pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span class="c0">pip install torch==2.3.0+cu118 torchvision torchaudio &mdash;-extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span class="c0">pip install torch==2.3.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">and</span></p><p class="c1"><span class="c0">pip install torchaudio==2.3.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">Replacing cu118 with newer cu121 seems to give a proper working URL too. </span></p><p class="c1"><span class="c0">Maybe replacing 2.3.0 with 2.3.1 will work too. cu126 is the latest supported for GTX 1080, while cu128 isn&rsquo;t (but supports RTX 5000 series), although it works with torch 2.7.0 which can cause unpickling errors with some models:<br>&quot;pip install torch==2.7.0 torchvision --upgrade --index-url https://download.pytorch.org/whl/cu126&quot;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>JFYI, the official PyTorch page: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pytorch.org/get-started/previous-versions/&amp;sa=D&amp;source=editors&amp;ust=1765035743834730&amp;usg=AOvVaw0VBsZfs5Ex2xRMTYu-2Z1O">https://pytorch.org/get-started/previous-versions/</a></span></p><p class="c1"><span class="c0">lacks links for CUDA 10 compatible versions for older GPUs other than v1.12.1 (which is pretty old, and might be a bit slower if even compatible at all), so the only way to install newer versions for CUDA 10 is --extra-index-url trick, as executing normally &ldquo;pip install torch==2.3.0+cu118&rdquo; will end up with the version not found error.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Alternatively, you might also try out installing it from wheels from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://download.pytorch.org/whl/torch_stable.html&amp;sa=D&amp;source=editors&amp;ust=1765035743835620&amp;usg=AOvVaw0AZdidJTNJV2F5BPiGRr0C">here</a></span><span class="c0">&nbsp;by the following command:</span></p><p class="c1"><span class="c0">&ldquo;pip install SomePackage-1.0-py2.py3-none-any.whl&rdquo; - providing a full path with the file name should do the trick. Just for the location with spaces, you also need &quot; &quot;. On GTX 1660 and Turing GPUs, you might seek for e.g. cu121/torch-2.3.1&quot; and those various CP wheels (there are no newer versions). But the -extra-index-url trick above should be enough.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3. After performing all of these, you might still have SageAttention not found error on GPUs up to Turing arch. Then perform the following:</span></p><p class="c1"><span class="c0">&ldquo;Had to replace cufft64_10.dll from C:\Users\user\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\lib </span></p><p class="c1"><span class="c0">by the one from C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin&rdquo;</span></p><p class="c1"><span class="c0">It is even compatible with the newest Torch 2.8.0 (if you followed the instruction to fix the dict issue above) if you grab that apparently &ldquo; fixed version of cufft64_10.dll from CUDA v10.0&rdquo; - dca</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4. If you write Python in CMD, and it wasn&#39;t found, start with method 2 described here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.liquidweb.com/help-docs/server-administration/windows/adding-python-path-to-windows-10-or-11-path-environment-variable/&amp;sa=D&amp;source=editors&amp;ust=1765035743837833&amp;usg=AOvVaw3x3EypLrpDlw2s917JB8nT">https://www.liquidweb.com/help-docs/server-administration/windows/adding-python-path-to-windows-10-or-11-path-environment-variable/</a></span></p><p class="c1"><span class="c0">Or make sure you&#39;ve checked &nbsp;the option to add path environmental variable during Python installation.</span></p><p class="c1"><span class="c0">Also, you can try out &ldquo;disabling the python executable in app execution aliases.&rdquo; - neoculture</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5. For state_dict = torch_load/unpickling_error</span></p><p class="c1"><span class="c0">&ldquo;add the following line above torch.load (at utils/model_utils.py line 479):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">with torch.serialization.safe_globals([torch._C._nn.gelu]):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">[So, the code like the following:]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; else:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; with torch.serialization.safe_globals([torch._C._nn.gelu]):</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state_dict = torch.load(args.start_check_point, map_location=device, weights_only=True)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; model.load_state_dict(state_dict, strict=False)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;(~unwa)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">*. For &ldquo;np.complex&rdquo; error with incompatible Numpy (Python 12) execute:</span></p><p class="c1"><span class="c0">pip install numpy==1.26.4</span></p><p class="c1"><span class="c0">pip install -U librosa audiomentations</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>6. For: &ldquo;failed to build diffq pesq&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708595418400817162/1430693276272300052&amp;sa=D&amp;source=editors&amp;ust=1765035743840134&amp;usg=AOvVaw0BXKRC66kIN0KnEpvfVOZ0">click</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">More notes:</span><span><br><br>- 4GB VRAM GPUs will give out of memory errors on for Roformers. You can use CPU instead, or potentially decreasing chunk_size as described </span><span class="c4"><a class="c3" href="#h.c4nrb8x886ob">here</a></span><span class="c0">&nbsp;might help too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Leave the checkbox &ldquo;extract instrumental&rdquo; disabled for duality or potentially other models with more than one stem target (it will have worse quality than dedicated stem output)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">CML guide by mesk (working on RTX 3070 Mobile):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;0 &ndash; You need Python:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.python.org/downloads/&amp;sa=D&amp;source=editors&amp;ust=1765035743841463&amp;usg=AOvVaw39LHC1MVO8RehtfVQD-1Im">https://www.python.org/downloads/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0a &ndash; I would also recommend installing Pytorch too from here: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pytorch.org/get-started/locally/&amp;sa=D&amp;source=editors&amp;ust=1765035743841787&amp;usg=AOvVaw17P6v-UDG46w1q60vyJmQq">https://pytorch.org/get-started/locally/</a></span></p><p class="c1"><span class="c0">(grab the command and enter it into the command prompt)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0b &ndash; But then you can just also double-click on guiwx.py on the repo, and it is much easier.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">That&#39;s the harder method with the command prompt</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>1 &ndash; Go there: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035743842756&amp;usg=AOvVaw2wn5TCYU4yPVJ8RUw0WtCR">https://github.com/ZFTurbo/Music-Source-Separation-Training</a></span></p><p class="c1"><span class="c0">and clone the repository (click on Code =&gt; Download as zip)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2 &ndash; Go to the repo folder, create 3 new folders: results, input and separation_results. <br>Place your tracks in the input folder. Place the checkpoint in results and leave the yaml at the root of the repo (where inference.py and requirements.txt are)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3 &ndash; Open command prompt, type in cd C://Users/[YOURUSERNAME]/Desktop/Music-Source-Separation-Training-main <br>(changes directory to the repo folder on your desktop)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4 &ndash; Type in: python install -r requirements.txt</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5 &ndash; Let it install the requirements</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">6 &ndash; Type in: python inference.py --model_type mel_band_roformer --config_path [NAME OF YAML] --start_check_point results/[NAME OF CHECKPOINT] --input_folder input/ --store_dir separation_results/ --extract_instrumental</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">7 &ndash; Make sure to replace the stuff in brackets with the actual stuff you need&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you have decent Nvidia GPU, and no GPU acceleration, maybe &ldquo;Check these commands to install torch version that handle CUDA&rdquo;:</span></p><p class="c1"><span class="c0">pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span class="c0">pip install torch==2.3.0+cu118 torchvision torchaudio &mdash;-extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span class="c0">pip install torch==2.3.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1"><span class="c0">or</span></p><p class="c1"><span>pip install torchaudio==2.3.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">[various GPU archs will have different CUDA requirements for different Torch versions, refer to documentation]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">FAQ</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &ldquo;When running inference, I am getting tired of it creating a folder for each input file and putting individual stems inside that folder. Especially since most of the time I&#39;m running single stem models and I only need the primary stem. I remember on a much older version, it wouldn&#39;t create folders, it would just copy the original filename and put the stem name at the end of it. So I was wondering what I could modify in newer versions to restore that behavior. I&#39;m guessing that would be in inference.py, but don&#39;t exactly know where to look.&rdquo; - Musicalman</span></p><p class="c1"><span>A: &ldquo;You can download the &quot;old&quot; version from my forked repo&#39;s &quot;colab-inference&quot; branch, with old behaviour for results and folders. It&#39;s the version used in my colab notebooks, it should be preselected with that link:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training/tree/colab-inference&amp;sa=D&amp;source=editors&amp;ust=1765035743847542&amp;usg=AOvVaw3J0_QbJcZiHg1LDkB4R4fU">https://github.com/jarredou/Music-Source-Separation-Training/tree/colab-inference</a></span><span class="c0">&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- torch.load and load_state_dict, errors</span></p><p class="c1"><span class="c0">A: &ldquo;PyTorch 2.6 and later have improved security when loading checkpoints, which causes the problem. torch._C_.nn.gelu must be set to exception&rdquo; or &ldquo;add the following line above torch.load (at utils/model_utils.py line 479)</span></p><p class="c1"><span class="c0">with torch.serialization.safe_globals([torch._C._nn.gelu]):</span></p><p class="c1"><span class="c0">&ldquo;don&#39;t forget to align the indentation since it&#39;s Python code.&rdquo;- unwa</span></p><p class="c1"><span class="c0">Also in the case of the unwa&rsquo;s FNO model: &ldquo;edit the model file</span></p><p class="c1"><span class="c0">As I mentioned in the model card, you need to change the MaskEstimator&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &ldquo;I&#39;ve been using a really old version of msst for a while and finally decided to update it today. I noticed that the gui-wx.py file was moved to the gui folder (it used to be in the root). So now when I try to launch the gui, I get file not found errors. Gui still works at least for screen reader users like myself, but these errors should definitely be fixed.</span></p><p class="c1"><span class="c0">I&#39;m wondering if I should be trying to launch the gui from the main msst folder, or if I should be launching it from the gui folder. Either way I get errors. I could fix them by modifying paths in gui-wx.py, just need to know which folder I should be starting from lol&rdquo; - Musicalman</span></p><p class="c1"><span class="c0">A: &ldquo;You can use python gui/gui-wx.py and replace (130-131 strings) right now:</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">font_path = &quot;gui/Poppins Regular 400.ttf&quot;</span></p><p class="c1"><span class="c0">bold_font_path = &quot;gui/Poppins Bold 700.ttf&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>I will fix it at next pull-request&rdquo; Kisel</span></p><h5 class="c5" id="h.16gdep9n4hi3"><span class="c42 c36 c51 c33 c24 c30">MVSEP models from UVR5 GUI explained</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Ensemble option - further developed custom code of the original MDX23 </span><span>(not available in UVR) - custom tech, consisting of various models from UVR and in-house, non-public models unavailable in UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Demucs 4 ft - (settings might be shifts 1 and overlap 0.75 as he tested once) - same as in Colabs or UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX B (not sure about whether min, avg, max is set) - the option has MDX arch models:</span></p><p class="c1"><span class="c0">- Newest MDX models added - Kimberley - Kim inst (ft other), Kim Vocal 1 &amp; 2, HQ_2, 3</span></p><p class="c1"><span>- 8.62 2022.01.01 - is NET 1 (9.7) with Demucs 2, this one has a new name now. It had slightly bigger SDR in the same </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard2.php?%26sort%3Dinstrum%26page%3D40&amp;sa=D&amp;source=editors&amp;ust=1765035743852085&amp;usg=AOvVaw1MqqTJ_WVk9CbqVhGlduo0">multisong</a></span><span class="c0">&nbsp;dataset as the newer model below - discrepancy vs UVR5 SDR results might be on the server side (e.g. different chunks), so it might be still the same. The dates can only relate to date of adding the model to the site and nothing more, not sure here, but it might be it - NET 1 is older model than below indeed. Looks like that the model is used with Demucs 2 enabled (at least he said it was configured like this at some point)</span></p><p class="c1"><span class="c0">- 8.51 2022.07.25 - might be vocal 423 a.k.a main, not sure if with Demucs 2 (judging how instrumental from inversion in 423 looked like - cannot be any inst model yet, since they were released in the end of 2022 - epoch 418 in September to be precise) - it was tested in multisong dataset on page 2 as MDX B (UVR 2022.07.250 - the date is the same as before, so nothing new here), can&#39;t say now if Demucs 2 is used here. In times of 9.7/NET 1 it was decreasing SDR a bit on I don&#39;t know which dataset, but instrumentals usually sounded kinda richer with this enabled. Now it&#39;s better to use other models to ensemble.</span></p><p class="c1"><span class="c0">The change in MDX-B models scheme was probably to unify SDR metrics to multisong dataset.</span></p><p class="c1"><span class="c0">- Demucs 3 Model B - mdx_extra (and rather not mdx_extra_q as ZFTurbo said it&#39;s &quot;original&quot; and used mdx_extra name on the channel referring to this model; in most cases the one below should be better)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Ultimate Vocal Remover HQ - the option has VR architecture models</span></p><p class="c1"><span class="c0">Window size used - 512</span></p><p class="c1"><span class="c4"><a class="c3" href="#h.1wojovpsoqy">Here</a></span><span class="c0">&nbsp;are all VR arch model names</span></p><p class="c1"><span class="c0">- UVRv5 Demucs - rather the same names</span></p><p class="c1"><span class="c0">- MVSEp models - unavailable in UVR5</span></p><p class="c1"><span class="c0">- MDX B Karaoke - Possibly MDX-UVR Karokee or MDX-UVR Karokee 2 (karokee_4band_v2_sn irc), maybe the latter</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The rest below on the MVSEP&rsquo;s list is outdated and not really recommended to use anymore </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Issues using MVSEP</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- NaN error during upload is usually cause by unstable internet connection, and it usually happens on mobile connections when you already upload more than one file elsewhere.</span></p><p class="c1"><span class="c0">If you have NaN error, just retry uploading your file.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Rarely it can happen after upload that error about not uploaded file occurs - you need to upload your file again.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1"><span class="c0">- If you finished separation and click back, model list can disappear till you won&rsquo;t click on other algorithm and pick yours again. But if you click separate instead, it will process with the first model which was previously on the list (at least if it was also your previous choice).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Slow download issues. Separation was complete, and I was listening to the preview when playback on the preview page simply stopped, and couldn&#39;t be started. Main page didn&#39;t load (other site worked).</span></p><p class="c1"><span class="c0">Also, I couldn&#39;t download anything. It showed 0b/s during attempt of downloading.</span></p><p class="c1"><span class="c0">Two solutions:</span></p><p class="c1"><span class="c0">- close all MVSEP tabs completely and reopen</span></p><p class="c1"><span class="c0">- Connect to VPN, preview some track, but after a short time, the same can happen and nothing is playing or buffering. Then fire up Free Download Manager, and simply copy the download link there, and it will start downloading. Later, the browser can also start downloading something you clicked a moment a go. Crazy.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&mdash;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Comparing to MDX with 14.7 cutoff, depending on a track, VR models only (not MDX/Demucs) might leave or cut more instruments or leave more constant vocal residues, but in general VR is trained model at 20kHz with possible mirroring covering 20-22kHz, generally less aggressive vocal removing (with exceptions) but most importantly, comparing to MDX, VR tends to leave some specific noise in a form of leftover artifacts of vocal bleeding, but from the other hand MDX, especially models with cutoff, can be more muddy and recall original track mastering less.</span></p><p class="c1"><span class="c0">______</span></p><h4 class="c17" id="h.surlvvp6mr8f"><span class="c21">Manual ensemble Colab</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You can perform manual ensemble on your own files in UVR5 under &quot;Audio Tools&quot; or beside </span><span class="c4"><a class="c3" href="#h.oxd1weuo5i4j">DAW method</a></span><span>, you can also use:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Ensemble Colab for various AI/models </span></p><p class="c1"><span class="c0">If you want to combine ready result files from various MDX and Roformer models or different archs/AIs from external sources using Google Colab, here&rsquo;s a notebook for you:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Manual_Ensemble_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743861103&amp;usg=AOvVaw1STDQjc0rPS5f6p8Q4dxi8">https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Manual_Ensemble_Colab.ipynb</a></span></p><p class="c1"><span class="c6">(implementation of ZFTurbo code with drop-down menus plus manual weights and various ensemble algorithms by jarredou)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>Once you mount GDrive, open file manager on the left, right click&gt;copy path&gt;paste in the first input field, then for the second file in the second field and so on and so forth. Then you can change type from max to e.g. avg or set weights manually - so to have the specified amount of one model in the result file (you could listen to the imported stems altogether in DAW to actually know what you&rsquo;re doing).</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Possible fixes for the errors</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Don&rsquo;t use spaces in output file name</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;AttributeError: module &#39;numpy&#39; has no attribute &#39;float&#39; </span></p><p class="c1"><span class="c0">np.float was a deprecated alias for the builtin float.&rdquo;</span></p><p class="c1"><span class="c0"><br>&gt; &ldquo;Try to rerun the install cell, this issue is because of a problem with numpy version</span></p><p class="c1"><span class="c0">if it doesn&#39;t work you can force numpy upgrade by creating a new code cell with:</span></p><p class="c1"><span class="c0">!pip install -U numpy</span></p><p class="c1"><span class="c0">Sometimes install cell ask you to restart runtime because of numpy version too, if you don&#39;t say yes, you have to restart runtime by yourself to make it work&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;Try forcing librosa update too:</span></p><p class="c1"><span class="c0">!pip install -U librosa</span></p><p class="c1"><span class="c0">Have you tried to delete runtime and restart it from scratch ?</span></p><p class="c1"><span class="c0">It&#39;s weird that these issues happen again, they were lots of these with old colab, but for recent ones, not much&rdquo; </span></p><p class="c1"><span class="c0">&ldquo;If you face this error again, you can update the 2 libs at the same time with:</span></p><p class="c1"><span class="c0">!pip install -U numpy librosa&rdquo; -jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 2) + inhomogeneous part.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt; In some specific cases (not always) converting your file to 32-bit float WAV might help. </span></p><p class="c1"><span class="c0">Not sure if exactly the same length is necessary. But you can check it if above fails.</span></p><p class="c1"><span>Also, lossy files will not align with lossless, and also files with different sample rate.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">&gt; For one person helped converting files to 320kbps mp3 for the ValueError</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- ValueError: Homogenous shape</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt;? anything from the above</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">____</span></p><p class="c1"><span class="c6">(Old not working Colab by ZFTurbo</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1fmLUYC5P1hPcycI00F_TFYuh9-R2d_ap?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743866166&amp;usg=AOvVaw1I47FGCw0fSQrG0EvQZo0M">https://colab.research.google.com/drive/1fmLUYC5P1hPcycI00F_TFYuh9-R2d_ap?usp=sharing</a></span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708912741980569691/1102706707207032833/Copy_of_Ensemble.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743866483&amp;usg=AOvVaw2vpfsw0Q0E2fukXxyIifG5">https://cdn.discordapp.com/attachments/708912741980569691/1102706707207032833/Copy_of_Ensemble.ipynb</a></span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Last backup</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1k1jD_sOWKLish2T3_pZoYpeE1DGwGfG3/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743866835&amp;usg=AOvVaw23pyD9xr8NtDa_ydpCieLP">https://drive.google.com/file/d/1k1jD_sOWKLish2T3_pZoYpeE1DGwGfG3/view?usp=sharing</a></span></p><p class="c1"><span class="c0">We got two reports that it throws out some errors now, and could stop working due to some changes Google made into Colabs this year) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You should be able to modify it to use with three models and different weights like 3, 2, 2 in example of Ensemble MDX-B (ONNX) + MVSep Vocal Model + Demucs4 HT on the old SDR chart (so it does not work like avg/avg in GUI).</span></p><p class="c1"><span class="c0">___</span></p><h4 class="c17" id="h.h952n842ljfj"><span class="c21">Joining frequencies from two models</span></h4><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Sometimes it may happen that a regular ensemble even with min spec doesn&#39;t give you complete freedom over what you want to achieve, having one cleaner narrowband model result with fullband model result with more vocal residues, but you still want to have a full spectrum.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instead of using ensemble Colab, you can also mix in some DAW, MDX-UVR 464/inst3 or Kim inst model result which have 17.7Hz cutoff, with HQ_1-5 or Demucs 4 result, which has full 22kHz training frequency model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>First, import both tracks. Now rather the most correct attitude to avoid any noise or frequency overlapping is to use</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/5PpmmfI.png&amp;sa=D&amp;source=editors&amp;ust=1765035743868874&amp;usg=AOvVaw0rl90YtX3YGcisVeja35e8">&nbsp;brickwall highpass</a></span><span class="c0">&nbsp;in EQ at 17680Hz everywhere on Demucs 4 stems, and leave MDX untouched, and just it. You can use GSEP instead of Demucs 4 (possibly less vocal residues).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you want to experiment further, as for a cut-off, once I ended up with 17725.00 flat high pass with -12dB slope for &quot;drums&quot; in Izotope Elements EQ Analog and I left MDX untouched. &ldquo;Bass&rdquo; stem set to 17680.00 in mono and &quot;other&quot; in stereo at 17680.00 with Maximiser with IRC 1 -0.2, -2, th. 1.55, st. 0, te 0. But it might produce hissy hi-hat in places with less busy mix or when hi-hat is very fast, so tweak it to your liking.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For free EQ you can use e.g. TDR Nova - click LP and set 17.7 and slope -72dB.</span></p><p class="c1"><span class="c0">As a free DAW you can use free Audacity (new versions support VST) or Cakewalk, Pro Tools Intro, or Ableton Lite.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The result of above will probably cause a small hole in a spectrum, and a bit lack of clarity. Alternatively, you can apply resonant high pass instead of brickwall, so the whole will be filled without overlapping frequencies.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instead, you can also consider using linear phase EQ/mode like in free Qrange and its high pass to potentially cause less problems in phase.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Similar method to this can also be used for </span><span class="c20">joining YT Opus frequencies above 15750Hz with AAC</span><span>&nbsp;(m4a) files, which gives more clarity compared to normal Opus on YT. Read </span><span class="c4"><a class="c3" href="#h.6543hhocnmmy">this</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.oxd1weuo5i4j"><span class="c21">DAW ensemble</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Averaging</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>The counterpart of avg ensemble from UVR (</span><span class="c4"><a class="c3" href="#h.lczfb0e870z9">more</a></span><span class="c0">) can also be made in a DAW (Audacity/Cakewalk/Reaper etc.). When you drag and align all stems you want to ensemble in your DAW, you simply need to lower the volume of stems according to the number of imported stems to ensemble.</span></p><p class="c1"><span class="c0">It&#39;s -3 dB per one stem for replicating avg spec, so for a pair you need to decrease the volume of two stems by 6 dB (possibly by 6.02 as well).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So, when you add another stem (so for 3 models ensemble), you need to decrease the volume of all stems by 9dB, and so on.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The other way round, it&#39;s 3dB decrease for all stems every time you import a new track.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Weighting manually (more precise)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can change volume of stems to your liking, just to not cause clipping having too loud output on master fader once you play. You can circumvent the problem to some extent using a limiter on the sum, but it might be not necessary.<br><br>Also, you can use different volume automation of stems towards specific verses and choruses, or just different volume relation of stems whenever a new verse or chorus appear.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Note: You won&rsquo;t be able to use that method if one stem had phase rotated or flipped.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I&#39;ve made some tests by simply overlaying each audio above each other and reducing their volume proportionally of the number of audio overlays (like you would do in a DAW), it scores like ~0.0002 better SDR than UVR&#39;s average.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can use Audacity online at wavacity.com, although it might crash occasionally while using on at least smartphone.</span></p><p class="c1"><span>Bandlab is more stable while using as app: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.bandlab.com/explore/home&amp;sa=D&amp;source=editors&amp;ust=1765035743874620&amp;usg=AOvVaw2iO_HEohGClJh45wCGYhYT">https://www.bandlab.com/explore/home</a></span></p><p class="c1"><span class="c0">but also crashes when used in PC mode online.</span></p><p class="c1"><span>The app at least vertically doesn&rsquo;t show master fader, so you cannot control the output volume meter. Probably the same in horizontal view. Plus, the app doesn&#39;t give the possibility to adjust the gain precisely, e.g. to 9dB instead of -9,5dB, so to use single files with found gain values in Wavacity, to mix them without crashes, you can use the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Manual_Ensemble_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743875443&amp;usg=AOvVaw1WZKjOX7VLl9htXzSnpkrd">manual ensemble Colab</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you want to just listen to stems offline, change their volume, panning, solo, mute, you can download </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1fgBW5gqPz7J3u-u772Cab88IEVv8TvyX/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743875775&amp;usg=AOvVaw2295JmHGKPB9171kO9jR16">this</a></span><span class="c0">&nbsp;html (by cypha_sarin) and run it locally in your browser.</span></p><h4 class="c17" id="h.wbhpqttnrw7b"><span>Manual e</span><span class="c21">nsemble in UVR5 GUI from single models (e.g. from inference Colabs or online sites)</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;You can use Colabs to make individual model separations and then use the manual ensemble tool from UVR5 GUI to merge them together (you don&#39;t need special CPU/GPU to use that tool and it&#39;s fast! 15-year-old computers can handle it).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In UVR GUI &gt; process method = Audio Tools, then choose &quot;Manual Ensemble&quot; and the desired ensembling method.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Combine input is even more aggressive than Max Spec.</span></p><p class="c1"><span class="c0">E.g. it takes two -15 ilufs songs, and makes pretty loud -10 ilufs result.</span></p><p class="c1"><span class="c0">To potentially deal with harshness of such output, you can set quality in options to 64 bit (sic!), or possibly manually decrease volume of ensembled files before passing through UVR Combine Inputs.</span></p><p class="c1"><span class="c0">Combine input was good for ensembling KaraFan results of preset with the least amounts of residues, and preset 5 for more clarity, but a bit more residues. The instrumental result was fuller sound, better snares and clarity.</span></p><p class="c1"><span class="c0">The downside is, you cannot control gain of ensembled stems precisely like in DAW, or using Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.900rfc8gjynn"><span class="c21">Model fusion</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You can perform fusion of models using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/18E5uTSVJV6rn8gTsOc0RC1m12lJFJGmP/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743878317&amp;usg=AOvVaw1LGIx6d75NnLebMLlpocZW">ZFTurbo script</a></span><span class="c28">(</span><span class="c4 c28"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1220364005034561628/1386610707042271243&amp;sa=D&amp;source=editors&amp;ust=1765035743878484&amp;usg=AOvVaw3YlUJ0rTq9JtmE5pFFKACI">src</a></span><span class="c28">)</span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Sucial/Dereverb-Echo_Mel_Band_Roformer/blob/main/scripts/model_fusion.py&amp;sa=D&amp;source=editors&amp;ust=1765035743878644&amp;usg=AOvVaw3ge8vKGZTOv985VPb3mOW_">Sucial script</a></span><span class="c0">&nbsp;(they&rsquo;re similar if not the same). &ldquo;I think the models need to have at least the same dim and depth, but I&#39;m not sure about that&rdquo; - mesk.</span></p><p class="c1"><span class="c0">They allow creating one model out of weighted models with specified parameters, so only one model is needed to inference instead of two or more.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">How to separate in UVR using multiple models in batch to compare the results for the best manual ensemble?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Simply use </span><span class="c22">Ensemble Mode</span><span>, but before, go to Settings&gt;Additional Settings and enable &ldquo;</span><span class="c22">Settings Test Mode</span><span>&rdquo; (adds 10-digits to every separation file name, so you won&rsquo;t overwrite the result of the same models with different settings) and &ldquo;</span><span class="c22">Model Test Mode</span><span>&rdquo; (adds model name to every output file name, so the file won&rsquo;t get overwritten by any other model separation) and now go to Settings&gt;Settings Guide&gt;Choose Advanced Menu&gt;</span><span class="c22">Ensemble Customization Options</span><span>&nbsp;and enable &ldquo;</span><span class="c22">Save All Outputs</span><span>&rdquo; (now when you choose models to separate in Ensemble, intermediate files won&rsquo;t be deleted, so not only min/max/avg mag ensemble result file will be left, but also result of separation from single models which you can use later to check the result manually for </span><span class="c4"><a class="c3" href="#h.oxd1weuo5i4j">manual weighted ensemble</a></span><span>&nbsp;e.g. in DAW or in </span><span class="c4"><a class="c3" href="#h.surlvvp6mr8f">Colab</a></span><span class="c0">).</span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.wjd2zth0azhs"><span class="c18 c15">UVR&rsquo;s VR architecture models</span></h2><h6 class="c2 c27" id="h.7j2ewdqsy5qw"><span>(settings and recommendations;<br></span><span class="c20">mostly outdated arch for all vocals and instrumental models</span><span class="c0">)</span></h6><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.rdfatusyntt1"><span class="c42 c36 c51 c33 c24 c30">VR Colab by HV</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(old) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/blob/main/Vocal%2520Remover%25205_arch.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743881816&amp;usg=AOvVaw0TJFxb6ymKXaOR45aF1mCT">https://colab.research.google.com/github/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/blob/main/Vocal%20Remover%205_arch.ipynb</a></span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743882034&amp;usg=AOvVaw1vVDmAKixuBTCJeZSIQBwm">this</a></span><span class="c0">&nbsp;fixed notebook for now (04.04.23)</span></p><p class="c1"><span class="c0">Sometimes Google Colab might break itself (e.g. error: No module named &#39;pathvalidate&#39;), and then you can simply try to go to Environment and delete it entirely and start over, and then it might start working.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(since 17.03.23 the official link above for HV Colab stopped working (librosa, and later pysound related issues with again YT links, but somehow fixed)</span><span class="c22">&nbsp;</span><span class="c0">&ldquo;!pip install librosa==0.9.1&rdquo; in OG Colab fixes the issue and is only necessary for both YT and local files and clean installation works too.)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- HV also made a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1VnqwFkpjPLjMwUPmgjoZJQR1S8hd6CBJ&amp;sa=D&amp;source=editors&amp;ust=1765035743883624&amp;usg=AOvVaw3J3xaDoYa--72hlC2wDj0l">new</a></span><span class="c0">&nbsp;VR Colab which irc, now don&rsquo;t clutter all your GDrive, but only downloads models which you use (but without VR ensemble) and probably might work without GDrive mounting.</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">(Google Colab in general allows separating on free virtual machine with decent Nvidia GPUs - it&#39;s for all those who don&#39;t want to use their personal computer for such GPU/CPU-intensive tasks, or don&rsquo;t have Nvidia GPU or decent CPU, or you don&rsquo;t want to use online services - e.g. frequently wait in queues, etc.)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Video tutorial how to use the VR Colab (it&rsquo;s very easy to use): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/channel/UC0NiSV1jLMH-9E09wiDVFYw&amp;sa=D&amp;source=editors&amp;ust=1765035743885152&amp;usg=AOvVaw2zGNQXblmmkRMvfKN969BL">https://www.youtube.com/channel/UC0NiSV1jLMH-9E09wiDVFYw</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can use VR models in UVR5 GUI or</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To use the above tool locally (old command line branch for VR models only):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/tree/v5-beta-cml&amp;sa=D&amp;source=editors&amp;ust=1765035743885698&amp;usg=AOvVaw2ziUM2hEfQdb4iO5RpTxL0">https://github.com/Anjok07/ultimatevocalremovergui/tree/v5-beta-cml</a></span></p><p class="c1"><span>Installation tutorial: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dps7GRvI1X80&amp;sa=D&amp;source=editors&amp;ust=1765035743885919&amp;usg=AOvVaw1yPP2kRWztS8ssJOuieg_a">https://www.youtube.com/watch?v=ps7GRvI1X80</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In case of CUDA out memory error due to too long files, use Lossless-cut to divide your song into two parts,</span></p><p class="c1"><span class="c0">or use this Colab which includes chunks option turned on by default (no ensemble feature here):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1UA1aEw8flXJ_JqGalgzkwNIGw4I0gFmV?usp%3Dsharing%23scrollTo%3DI4B1u_fLuzXE&amp;sa=D&amp;source=editors&amp;ust=1765035743886650&amp;usg=AOvVaw0vFeXV1IHjj5MkSzMH3S2x">https://colab.research.google.com/drive/1UA1aEw8flXJ_JqGalgzkwNIGw4I0gFmV?usp=sharing#scrollTo=I4B1u_fLuzXE</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Below, I&#39;ll explain Ultimate Vocal Remover 5 (VR architecture) models only (fork of vocal remover by tsurumeso).</span></p><p class="c1"><span class="c18 c15">For more information on VR arch, see here for official documentation and settings:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/tree/v5-beta-cml&amp;sa=D&amp;source=editors&amp;ust=1765035743887485&amp;usg=AOvVaw00PnM2YkUVfZQfqQdm8zY0">https://github.com/Anjok07/ultimatevocalremovergui/tree/v5-beta-cml</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035743887680&amp;usg=AOvVaw2Y-xjGYBl7FvV6miZJGEC_">https://github.com/Anjok07/ultimatevocalremovergui</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c75"><span class="c18 c15">The best </span></p><h4 class="c17" id="h.atxff7m4vp8n"><span class="c21">VR settings</span></h4><p class="c1"><span>E</span><span class="c0">xplained in detail</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Settings available in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743888232&amp;usg=AOvVaw0US5S6xyBzyqbIxfpZvHX0">Colab</a></span><span>&nbsp;</span><span class="c0">and in CLI branch, and also UVR 5 GUI (but without at least mirroring2. mirroring in UVR5 GUI for VR arch got replaced entirely by High End Process (works as mirroring now, and not like original High End Process which was originally dedicated for very old 16kHz VR models only).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>These VR models can be used in this 1) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/blob/main/Vocal%2520Remover%25205_arch.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743889052&amp;usg=AOvVaw2uL1S37F1jSNiuevkH1vXT">Colab</a></span><span>&nbsp;</span><span>or in 2) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui&amp;sa=D&amp;source=editors&amp;ust=1765035743889187&amp;usg=AOvVaw3diBeDSGlJs3tY0vYQKM7S">UVR5 GUI</a></span><span>&nbsp;or on 3) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://mvsep.com&amp;sa=D&amp;source=editors&amp;ust=1765035743889278&amp;usg=AOvVaw0qd0ufuZH_ZTBEtUlmO0Kz">mvsep.com</a></span><span class="c0">&nbsp;(uses 512 windows size, aggressiveness option, various models) 4) x-minus.pro/uvronline.app (for free one UVR (unreleased) model without parameters (&quot;lo-fi&quot; option, mp3, 17,7 kHz cutoff) [Demucs 4 for registered users iirc (site by Aufr33 - one of the authors of UVR5)]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I had at least one report that results for just VR models are better using Colab above/old CLI branch instead of the newest UVR5 GUI, so be aware (besides both mirroring settings - only mirroring is working under high-end process - no mirroring2 [272 window size is added back as user input] all settings should be available in GUI). Interestingly, I received similar report for MDX models in UVR5 GUI comparing to Colab (be aware just in case). The problems might be also bound to VRAM, and don&#39;t exist on 11GB GPPUs and up or in CPU mode.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Before we start -</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Issue with additional vocal residues when postprocess is enabled</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- &ldquo;</span><span class="c20">postprocess</span><span>&nbsp;option masks instrumental part based on the vocals volume to improve the separation quality.&quot; (from: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/tsurumeso/vocal-remover&amp;sa=D&amp;source=editors&amp;ust=1765035743891431&amp;usg=AOvVaw3b5-BWOvREwvBh22hOfHkJ">https://github.com/tsurumeso/vocal-remover</a></span><span>)</span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">where in HV Colab it says: &ldquo;Mute low volume vocals&rdquo;. So, if it enhances separation quality, then maybe it should cancel some vocals residues (&quot;low volume vocals&quot;) so that&#39;s maybe not too bad explanation. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But that setting enabled in at least Colab may leave some vocal residues:<br><br>(it&rsquo;s fixed in UVR GUI &quot;the very end bits of vocals don&#39;t bleed anymore no matter which threshold value is used&quot;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Customizable postprocess settings (threshold, min range and fade size) in HV&#39;s Colab were deleted, and were last time available in this revision:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/blob/b072ad7418f6b1825d3dcff7cef70c5b0985d540/Vocal%2520Remover%25205_arch.ipynb%23scrollTo%3DCT8TuXWLBrXF&amp;sa=D&amp;source=editors&amp;ust=1765035743892970&amp;usg=AOvVaw3v7-KQ0HbyPN_yAOXnLa7b">https://colab.research.google.com/github/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/blob/b072ad7418f6b1825d3dcff7cef70c5b0985d540/Vocal%20Remover%205_arch.ipynb#scrollTo=CT8TuXWLBrXF</a></span></p><p class="c1"><span class="c0">So change default 0.3 or 0.2 threshold value (depending on revision) and set it to 0.01 if you have the issue when using postprocess.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>The </span><span class="c20">threshold </span><span class="c0">parameter set to 0.01 fixes the issue (so quiet the opposite thing happened using default settings than this option should serve to, I believe).</span></p><p class="c1"><span class="c0">Also, default threshold values for postprocess changed from 0.3 to 0.2 in later revisions of the Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c20">Window size</span><span class="c0">&nbsp;option set to anything other than 512 somehow decrease SDR, although most people like lower values (at least 320, me even 272; 352 is also possible, but anything above changes the tone of sound more noticeably) - we don&rsquo;t know yet why lower window sizes mess with SDR (similar situation like with GSEP) - 512 might be a good setting for ensemble with other models than VR ones or for further mastering. Sometimes compared to 512 windows size, 272 can lead to a bit more noticeable vocal residues. You might find bigger window sizes less noisy in general, but also more blurry for some people.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c20">Aggressiveness/Aggression</span><span class="c0">&nbsp;- &ldquo;A value of 10 is equivalent to 0.1 (10/100=0.1) in Colab&rdquo;.</span></p><p class="c1"><span class="c0">Strangely, the best SDR for aggressiveness using MSB2 instrumental model turned out to be 100 in GUI, 10 in Colab, while we usually used 0.3 for this model and 500m_x as well, while HP models usually behaves the best with lower values than HP2 models (0.09/10 in GUI).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Mirroring turned out to enhance SDR. It adds to the spectrum e.g. above 20kHz for a base training frequency of VR model (all 4 bands).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; none - No processing (default)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; bypass - This copies the missing frequencies from the input.</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; mirroring - This algorithm is more advanced than correlation. It uses the high frequencies from the input and mirrored instrumental&#39;s frequencies. More aggressive.</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; mirroring2 - This version of mirroring is optimized for better performance.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>--</span><span class="c20">high_end_process</span><span class="c0">&nbsp;- In the old CLI VR, this argument restored the high frequencies of the output audio. It was intended for models with a narrow bandwidth - 16 kHz and below (the oldest &ldquo;lowend&rdquo; and &ldquo;32000&rdquo; ones, none more). But now in UVR5 GUI, High-end process is counterpart of mirroring.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(current 500MB models don&rsquo;t have full 22kHz coverage, but 20kHz, so consider using mirroring instead or none if you want fuller spectrum)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Be aware, that even for VR arch, the same rule for GPUs with less than 8GB VRAM applies (inb4 - Colab T4 has 15GB) - separations on 6GB VRAM have worse quality with the same parameters. In order to work around the issue, you can split your audio into specific parts (e.g. for all chorus, verses etc).</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.1wojovpsoqy"><span class="c21">VR models settings and list</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For VR architecture models, you can start with these two fast models:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Model: </span><span class="c22">HP_4BAND_3090_arch-124m</span><span class="c0">&nbsp;(1_HP-UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1) Fast and reliable. V2 below has more &ldquo;polished&rdquo; drums, while here they&rsquo;re more aggressive and louder. Sometimes V2 might be safer and can fit in more cases where it&rsquo;s not hip-hop and music is not drum oriented, but that one rarely harms some instruments more in certain cases with more busy mix with e.g. repeatable synth. You may want to isolate using these two models and pick the best results on even the same album. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Windows size: 272</span></p><p class="c1"><span class="c0">Aggressiveness: 0.09 (9 in GUI)</span></p><p class="c1"><span class="c0">TTA: ON (OFF if snare is too harsh)</span></p><p class="c1"><span class="c0">Post-processing: OFF (at least for this model - it can get muffle instruments in background beside drums of the track in some cases, e.g. guitar)</span></p><p class="c1"><span class="c0">&quot;Mirroring&quot; (Hi-end process in GUI) (rarely &quot;Mirroring2&quot; here, since the model itself is less smooth and usually have better drums, but it sometimes leads to overkill - in that case check mirroring2 in CLI or V2 model above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Better yet, to increase the quality of the separation (when drums in e.g. hip-hop can be frequently damaged too much during the process) go now straight to the Demucs section and read the &quot;Anjok&#39;s tip&quot;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you have too many vocal residues vs 500m_1 model, increase aggressiveness from 0.09 to 0.2 or even 0.3, but it&rsquo;s destructive for some instruments (at least without Demucs trick above).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Model: </span><span class="c22">HP-4BAND-V2_arch-124m</span><span class="c0">&nbsp;(2_HP-UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">!) Fast and nice model, but sometimes gives lots of vocal residues comparing to above, but thanks to this, it may sometimes harm snare less in some cases (still 4 times faster than 500m_1) it&rsquo;s ~55/45 which model is better and depends on the album even on the same genre:</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">Window size: 272 (the lowest possible; in some very rare cases it can spoil the result on 4 band models, then check 320)</span></p><p class="c1"><span class="c0">Aggressiveness: 0.09 (9 in GUI)</span></p><p class="c1"><span class="c0">TTA: ON (instr. separation of a better quality)</span></p><p class="c1"><span class="c0">Postprocess: (sometimes on, it rather compliments to the sound of this model especially when the result sounds a bit too harsh, but it also can spoil drums in some places when e.g. strong synths suddenly appear in mix for short, probably misidentifying them as vocals, so be aware)</span></p><p class="c1"><span class="c0">Mirroring (it fits pretty well to this model in comparison to mirroring2 which is not &ldquo;aggressive&rdquo; enough here) [mirroring doesn&rsquo;t seem to be present in GUI so be aware)</span></p><p class="c1"><span class="c0">Processing time for this model is 10 minutes using the weakest GPU in Colab (but currently you should be getting better Tesla T4).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(for users of x-minus) &ldquo;slightly different models [than in GUI] are used for minimum aggressiveness. When we train models, we get many epochs. Some of these models differ in that they better preserve instruments such as the saxophone. These versions of the models don&#39;t get into the release, but are used exclusively on the XM website.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Model: </span><span class="c22">HP2-4BAND-3090_4band_arch-500m_1</span><span class="c0">&nbsp;(9_HP2-UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3) Older good model, but resource heavy - check it if you get too many vocal residues, or in other cases - when your drums are too muffled - rarely there might be more bleeding and generally more spoiled other instruments in comparison to those above, it depends on a track. In some cases it bleeds vocal less than HP_4BAND_3090_arch-124m</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Window size: 272</span></p><p class="c1"><span class="c0">Aggressiveness: 0.3-0.32 (30-32 in GUI)</span></p><p class="c1"><span class="c0">TTA: ON</span></p><p class="c1"><span class="c0">Postprocess: (turned ON in most cases with exceptions (it&rsquo;s polishing high-end), and the problem with muffling instruments using ppr doesn&rsquo;t seem to exist in this model)</span></p><p class="c1"><span class="c0">Mirroring2 (I find mirroring[1] too aggressive for this model, but with exceptions)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">! Be aware these settings are very slow (40 minutes per track in Colab on the former default K80 GPU, but it&#39;s faster now) so just in case, you might want to experiment with 320/384, or at worse even 512 window size if you want to increase processing speed in cost of isolation precision.</span></p><p class="c1"><span class="c0">Colab&rsquo;s former default Tesla K80 processes slower than even GTX 1050 Ti, so if you have a decent Nvidia GPU, consider using UVR locally. Since May 2022 there is faster Tesla T4 available as default, so there shouldn&#39;t be any problem.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">HP2-4BAND-3090_4band_arch-500m_2 (8_HP2-UVR) </span></p><p class="c1"><span class="c0">was worse in I think every case I tested, but it&rsquo;s good for a pair for ensemble (more about ensemble in section below).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Model: HP2-MAIN-MSB2-3BAND-3090_arch-500m (7_HP2-UVR.pth)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4) Last resort, e.g. when you have a lot of artifacts (heavily filtered vocal residues) some instruments spoiled, and no equal sound across the track. Last resort, because it&rsquo;s 3 band, instead of 4 band, and it lacks some hi-end/clarity, but if your track is very demanding to filter out vocal residues, then it&rsquo;s good choice. The best SDR among VR-arch models.</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">Window size: 272</span></p><p class="c1"><span class="c0">Aggressiveness: 0.3</span></p><p class="c1"><span class="c0">TTA: ON</span></p><p class="c1"><span class="c0">Postprocess: ON</span></p><p class="c1"><span class="c0">Mirroring</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&rsquo;s similarly nightmarishly slow in Colab just like 500m_1/2 using these settings (1 hour for a track on K80) when you got accidentally slower Tesla K80 assigned in Colab instead of Tesla T4.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">HighPrecison_4band_arch-124m_1</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">*)</span></p><p class="c1"><span class="c0">May sometimes harm instruments less than HP_4BAND_3090_arch-124m, but may leak vocals more in many cases, but generally instrumentals lacks some clarity, but it sounds more neutral vs 500m_1 with mirroring (not always an upside). It&rsquo;s not available in GUI by default due to its not fully satisfactory results vs models above.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Window size: 272</span></p><p class="c1"><span class="c0">Aggressiveness: 0.2</span></p><p class="c1"><span class="c0">TTA: ON</span></p><p class="c1"><span class="c0">Postprocess: off</span></p><p class="c1"><span class="c0">mirroring</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">SP in the GUI models stands for &quot;Standard Precision&quot;. Those models use the least amount of computing resources of any other models in the application. HP on the other hand &nbsp;stands for &quot;Higher Precision&quot; those models use more resources but have better performance.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So, what&#39;s the best VR arch model?</span></p><p class="c1"><span>I&#39;d stick to </span><span class="c22">HP_4BAND_3090_arch-124m</span><span class="c0">&nbsp;(1_HP-UVR) if it only gives good result for your song (e.g. hip-hop). If you&#39;re forced to use any other VR model for a specific song due to unsatisfactory results with this model, then probably current MDX models will achieve better results.</span></p><p class="c1"><span class="c0">Second most usable model for me was 500_m1(9_HP2), and then HP-4BAND-V2_arch-124m (2_HP-UVR) or something in between, but compared to MDX-UVR models, it might be not worth to use it anymore due to possibility of more vocal residues.</span></p><p class="c1"><span class="c0"><br>- 13/14_SP models (called 4-band beta 1/2 in the Colab) - less aggressive than above</span></p><p class="c1"><span class="c0">(these are older UVR5 models by UVR team - less aggressive, give more vocal residues frequently&rsquo; the mid ones have less clarity, but might be less noisy - but they&rsquo;re surpassed by MDX models)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- v4 models -</span></p><p class="c1"><span class="c0">Even older models from times of previous VR codebase<br>&quot;All the old v5 beta models that weren&#39;t part of the main package are compatible [with UVR] as well. Only thing is, you need to append the name of the model parameter to the end of the model name&quot;</span></p><p class="c1"><span class="c0">Also, V4 models are still compatible with UVR using this method.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Main Models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MGM_MAIN_v4_sr44100_hl512_nf2048.pth - </span></p><p class="c1"><span class="c0">This is the main model that does an excellent job removing vocals from most tracks.</span></p><p class="c1"><span class="c0">MGM_LOWEND_A_v4_sr32000_hl512_nf2048.pth - </span></p><p class="c1"><span class="c0">This model focuses a bit more on removing vocals from lower frequencies.</span></p><p class="c1"><span class="c0">MGM_LOWEND_B_v4_sr33075_hl384_nf2048.pth - </span></p><p class="c1"><span class="c0">This is also a model that focuses on lower end frequencies, but trained with different parameters.</span></p><p class="c1"><span class="c0">MGM_LOWEND_C_v4_sr16000_hl512_nf2048.pth - </span></p><p class="c1"><span class="c0">This is also a model that focuses on lower end frequencies, but trained on a very low sample rate.</span></p><p class="c1"><span class="c0">MGM_HIGHEND_v4_sr44100_hl1024_nf2048.pth - </span></p><p class="c1"><span class="c0">This model slightly focuses a bit more on higher end frequencies.</span></p><p class="c1"><span class="c0">MODEL_BVKARAOKE_by_aufr33_v4_sr33075_hl384_nf1536.pth - </span></p><p class="c1"><span class="c0">This is a beta model that removes main vocals while leaving background vocals intact.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Stacked Models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">StackedMGM_MM_v4_sr44100_hl512_nf2048.pth - </span></p><p class="c1"><span class="c0">This is a strong vocal artifact removal model. This model was made to run with MGM_MAIN_v4_sr44100_hl512_nf2048.pth -</span></p><p class="c1"><span class="c0">However, any combination may yield a desired result.</span></p><p class="c1"><span class="c0">StackedMGM_MLA_v4_sr32000_hl512_nf2048.pth - </span></p><p class="c1"><span class="c0">This is a strong vocal artifact removal model. This model was made to run with MGM_MAIN_v4_sr44100_hl512_nf2048.pth - </span></p><p class="c1"><span class="c0">However, any combination may yield a desired result.</span></p><p class="c1"><span class="c0">StackedMGM_LL_v4_sr32000_hl512_nf2048.pth - </span></p><p class="c1"><span class="c0">This is a strong vocal artifact removal model. This model was made to run with MGM_LOWEND_A_v4_sr32000_hl512_nf2048.pth - </span></p><p class="c1"><span class="c0">However, any combination may yield a desired result.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.rv7wwzcmuq3s"><span class="c21">VR ensemble settings</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>As for VR architecture, ensemble</span><span>&nbsp;is the most universal and versatile solution for lots of tracks. </span><span class="c0">It delivers, when results achieved with single models fail - e.g. when snare is too muffled or distorted along with some instruments, but sometimes a single model can still provide more clarity, so it&rsquo;s not universal for every track. </span></p><p class="c1"><span class="c0">In most cases, ensemble of only VR models is dedicated for the tracks when in the most prevailing moments of busy mix in the track, you don&rsquo;t have major bleeding using single VR model(s) because it rarely removes that well vocal residues from instrumentals better than current MDX models, or with high aggressiveness it becomes too destructive.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Order of models is crucial (at least in the Colab)! Set the model with the best results as the first one. Usually, using more than 4 models has a negative impact on the quality. Be aware that you cannot use postprocess in HV Colab in this mode, otherwise you&rsquo;ll encounter an error. </span><span class="c20">Please note that now UVR 5 GUI allows an ensemble of UVR and MDX models in the app exclusively, so feel free to check it too. </span><span>Here you will find settings for &ldquo;only&rdquo; UVR models ensemble only.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- HP2-4BAND-3090_4band_arch-500m_1.pth (9_HP2-UVR)</span></p><p class="c1"><span class="c0">- **HP2-4BAND-3090_4band_arch-500m_2.pth (8_HP2-UVR)</span></p><p class="c1"><span>- HighPrecison_4band_arch-124m_1.pth (probably deleted from GUI, and you&rsquo;d need to copy this model from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/13Tm0AveW5yKEmxaTnkRWXxjshIXi415c/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743917113&amp;usg=AOvVaw34MJsAnZFwVVBuOeU_ERc7">here</a></span><span>&nbsp;</span><span class="c0">to your GUI folder manually - if it will only work)</span></p><p class="c1"><span class="c0">- HP_4BAND_3090_arch-124m.pth (1_HP-UVR)</span></p><p class="c1"><span class="c0">(order in Colab is important, keep it that way!)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or for less bleeding, but a bit more muffled snare, use this one instead:</span></p><p class="c1"><span class="c0">HP-4BAND-V2_arch-124m.pth (model available only in Colab, recommended </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">*on slower Tesla K80 you can run out of time due to runtime disconnection, but you should get faster Tesla T4 by default on first Colab connection on the account in 24h.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Aggressiveness</span><span class="c0">: 0.1 (pretty universal in most cases, 0.09 rarely fits). </span></p><p class="c1"><span class="c0">Or for more vivid snare if bleeding won&rsquo;t kick in too much: 0.01 (in cases when it&rsquo;s more singing than rapping - for the latter it can result in more unpleasant bleeding (or just in some parts of the track). Suggested very low aggressiveness here doesn&rsquo;t leak as much as it could using the same settings on a single model, but it leaks more in general vs single models&rsquo; suggested settings).</span></p><p class="c1"><span class="c0">0.05 is not good enough for anything AFAIK.</span></p><p class="c1"><span class="c20">high_end_process</span><span class="c0">: mirroring2 (just ON in GUI)</span></p><p class="c1"><span class="c0">(for less vivid snare check &ldquo;bypass&rdquo;, (not &ldquo;mirroring&rdquo; for ensemble - for some reason both make the sound more muffled), be aware that bypass on ensemble results with less vocal leftovers)</span></p><p class="c1"><span class="c20">ensembling_parameter</span><span class="c0">: 4band_44100.json</span></p><p class="c1"><span class="c20">TTA</span><span class="c0">: ON</span></p><p class="c1"><span class="c20">Window size</span><span class="c0">: 272</span></p><p class="c1"><span class="c20">FlipVocalModels</span><span class="c0">: ON<br>Ensemble algorithm: default on Colab (min_mag for instrumentals)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Other ensemble settings </span></p><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_kzw7lb63578w-0 start"><li class="c1 c25 c8 li-bullet-0"><span>For clap leftovers in vocal stem, check out </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/BmvcUEt.png&amp;sa=D&amp;source=editors&amp;ust=1765035743920704&amp;usg=AOvVaw2MPANz31JfCfJog_jaYJWe">this</a></span><span>&nbsp;</span><span class="c0">ensemble settings.</span></li><li class="c1 c25 c8 li-bullet-0"><span>For creaking sounds, process your separation output more than once till you get there with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/jDYlYFk.jpeg&amp;sa=D&amp;source=editors&amp;ust=1765035743921152&amp;usg=AOvVaw06AyU79VQtTfGDE2X1u6it">this</a></span><span class="c0">&nbsp;setting</span></li><li class="c1 c25 c8 li-bullet-0"><span>Also reported clean instrumentals with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/iaHdw5M.png&amp;sa=D&amp;source=editors&amp;ust=1765035743921345&amp;usg=AOvVaw1NzwFnFRKoQZm9Y1TwT_TC">this</a></span><span>&nbsp;setting</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Make sure you checked separated file after the process and file length agrees with original file. Occasionally, the result file can be cut in the middle, and you&rsquo;ll need to start isolation again. Also, you can accidentally start isolation before uploading of source file is finished. In that case, it will be cut as well.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It takes 45 minutes using Tesla T4 (~RTX 3050 in CUDA benchmarks) for these 4 models settings. Change your songs for processing after finishing the task FAST, otherwise you&rsquo;ll be disconnected from runtime when the notebook is idle for some time (it can even freeze in the middle).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In reality, Tesla T4 maybe has much more memory, but what takes 30 minutes on a real RTX 3050, here might take even more than 2 hours and sometimes slower or sometimes slightly faster (usually slower). So you&#39;re warned.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">**Be aware that these 4 model ensemble setting with both 500m models in most cases won&rsquo;t suffice for the slowest (and no longer available in 2023) Tesla K80 due to its time and performance limit to finish such a long operation which exceeds 2 hours (it takes around 02:25h). Certain tasks too much above 2 hours ends up with runtime disconnection, so you&#39;re warned.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also be aware that the working icon of Colab on the opened tab sometimes doesn&rsquo;t refresh when operation is done.</span></p><p class="c1"><span class="c0">Furthermore, it can happen that the Colab will hang near 01:45-02:17h time of executing the operation. To proceed, you can click F5 and press cancel on prompt to whether to refresh. Now the site will be functional again, but the process will stop without any notice. It is most likely the same case when you suddenly stop connection to the internet, and the process will still run virtually till you reconnect to the session. But here, you just don&rsquo;t have to click the reconnect button on the right top. Most likely you have very limited time to reestablish the connection till the process will stop permanently if you don&#39;t connect on connection lost (or eventually if progress tracker/Colab will stop responding). So in the worst case, you need to observe if the process is still working between 01:45-02:17h of processing. If you see that your GPU has 0.84GB instead of ~2GB, you&rsquo;re too late and your process is permanently interrupted, and the result is gone. It&rsquo;s harder to track how long it processes when you already used the workaround once, and the timer stopped, so you don&#39;t know how long it is separating already.</span></p><p class="c1"><span class="c0">Limit for faster Tesla T4 is between 1:45 and 2:00h/+ (sometimes 2:25, but can disconnect sooner, so try not to exceed two hours) of constant batch operation, which suffice for 2 tracks being isolated using ensemble settings above with both 500m models (rarely 3 tracks).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">HP2-4BAND-3090_4band_arch-500m_1 (9_HP2-UVR) - I think it tends to give the most consistent results for various songs (at least for songs when vocal residues are not too prevalent here)</span></p><p class="c1"><span class="c0">HP-4BAND-V2_arch-124m (2_HP-UVR) - much faster and can give crisp results, but with too many vocal residues for some songs (like VR arch generally tends to)</span></p><p class="c1"><span class="c0">HP_4BAND_3090_arch-124m (1_HP-UVR) - something between the two above, and can give the best results for some song too (out of other VR models)</span></p><p class="c1"><span class="c0">HP2-MAIN-MSB2-3BAND-3090_arch-500m (7_HP2-UVR.pth) - tends to have the least vocal residues out of the VR models listed above, but in cost of instrumentals not sounding so &quot;full&quot;</span></p><p class="c1"><span class="c0">HighPrecison_4band_arch-124m_1 (I think not available in UVR, you&#39;d need to install it manually) - can be a good companion if you only have VR models for ensemble</span></p><p class="c1"><span class="c0">HP2-4BAND-3090_4band_arch-500m_2 (9_HP2-UVR) - the same situation, I think it rarely gives any better results than 500m_1 (if in even any case) but it&#39;s good for purely VR ensemble</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">_______VR algorithms of ensemble _______</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">by &#12469;&#12490;(Hv#3868)</span></p><p class="c1"><span class="c0">&ldquo;np_min takes the highest value out, np_max does vice versa</span></p><p class="c1"><span class="c0">it&#39;s also similar to min_mag and max_mag</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So the min_mag is better for instrumental as you could remove artefacts.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">comb_norm simply mixes and normalizes the tracks. I use this for acapella as you won&#39;t lose any data this way&rdquo;</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Batch conversion on UVR Colab</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">There&rsquo;s a &ldquo;ConvertAll&rdquo; batch option available in Colab. You can search for &ldquo;idle check&rdquo; in this document to prevent disconnections on long Colab sessions, but at least if you get the slowest K80 GPU, the limit is currently 2 hours of constant work, and it simply terminates the session with GPU limit error. The limit is enough for 5 tracks - 22 minutes with ~+/-3m17s overhead (HP_4BAND_3090_arch-124m/TTA/272ws/noppr/~2it/s) so better execute bigger operations in smaller instances using various accounts and/or after 3-5 attempts you can also finally hit on better GPU than K80. </span></p><p class="c1"><span class="c0">To get faster GPU simply go to Runtime&gt;Manage session&gt;Close and connect and execute Colab till you get faster Tesla T4 (up to 5 times). But be aware, that 5 reconnections will reach the limit on your account, and you will need to change it. It&rsquo;s easier to get T4 and not reach the limit reconnecting, around 12:00 CET in working days. 14:30 o&rsquo;clock it was impossible to get T4, but probably it depended on a situation when I already used T4 this day since I received it immediately on another account.</span></p><p class="c1"><span class="c0">For single files isolation instead of batch convert I think it took me 6-7 hours till the GPU limit was reached, and I processed 19 tracks using 272 ws in that session.</span></p><p class="c1"><span class="c0">JFI: Even 5800X is slower than the slowest Colab GPU.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Shared UVR installation folder among various Google accounts</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>Since we no longer can use old Gdrive mounting method allowing mounting the same drive across various Colab sessions - t</span><span class="c0">o not clutter all of your accounts by UVR installation, simply share a folder with editing privileges and create a shortcut from it to your new account. Sadly the trick will work for one session at a time. </span></p><p class="c1"><span>Firstly - sometimes you can have problems with opening the shared folder on proper account despite changing it after opening the link (it may leave you on old account anyway). In that case, you need to manually insert id of your account where you want to open your link to. E.g. https://drive.google.com/drive</span><span class="c22">/u/9/</span><span class="c0">folders/xxxxxxxx (where 9 is an example of your account ID which shows right after you switch your account on main Google Drive page).</span></p><p class="c1"><span class="c0">After you opened the shared UVR link on your desired account, you need to add the shortcut to your disk (arrow near folder&rsquo;s name) and when it&rsquo;s done, create &ldquo;track&rdquo; and &ldquo;separated&rdquo; folder on your own - so delete/rename shared &ldquo;tracks&rdquo; and &ldquo;separated&rdquo; folder and create it manually, otherwise you will get error during separation. If you still get an error anyway, refresh file browser in the left of Colab and/or retry running separation three times till error disappears (from now on it shows error occasionally, and you need to retry from time to time and/or click refresh button in file manager view in the left or even navigate manually to tracks folder in order to refresh), Colab gets changes like moving files and folders on your disk with certain delay. And be aware that most likely such way of installing UVR will prevent you from any further updates from such account with shared UVR files, and on the account you shared the UVR files from, you need to repeat folder operations if you will use it back again on Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Comparing 500m_1 and arch_124m above, in some cases you can notice that the snare is louder in the first, but you can easily make it up using mirroring instead of mirroring2. Downside of normal mirroring might be more pronounced vocal residues due to higher output frequency. </span></p><p class="c1"><span class="c0">Also, in 500m_1 more instruments are damaged or muffled, though more aggressiveness in the default setting of 500m_1 sometimes makes an impression that more vocal residues are cancelled.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/870722720546041856&amp;sa=D&amp;source=editors&amp;ust=1765035743938356&amp;usg=AOvVaw3zSg0gkf6C4RsW8uz80Hwa">evaluation tests</a></span><span class="c0">&nbsp;window size 272 vs 320 -</span></p><p class="c1"><span class="c0">it&rsquo;s much slower, doesn&rsquo;t give noticeable difference on all sound systems, 272 got slightly worse score, but based on my personal experience I insist on using 272 anyway)</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/868770117205520434&amp;sa=D&amp;source=editors&amp;ust=1765035743938885&amp;usg=AOvVaw3Gp0BCj6CN9Q-5FX5fdyd-">evaluation tests</a></span><span class="c0">&nbsp;aggressiveness 0.3 vs 0.275 -</span></p><p class="c1"><span class="c0">doesn&rsquo;t apply for all models - e.g. MGM - 0.09)</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/868594718915829841&amp;sa=D&amp;source=editors&amp;ust=1765035743939222&amp;usg=AOvVaw1KHnGLoTqzh1pRk1Pe9XE2">evaluation tests</a></span><span class="c0">&nbsp;TTA ON vs OFF -</span></p><p class="c1"><span class="c0">in some cases, people disable it)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5a) (haven&rsquo;t tested thoroughly these aggressiveness parameters yet)</span></p><p class="c1"><span class="c0">HP2-4BAND-3090_4band_arch-500m_1.pth </span></p><p class="c1"><span class="c0">w 272 ag 0.01, TTA, Mirroring</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5c)</span></p><p class="c1"><span class="c0">HP2-4BAND-3090_4band_arch-500m_1.pth </span></p><p class="c1"><span class="c0">w 272, ag 0.0, TTA, Mirroring 2</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Low or 0.0 aggressiveness leaves more noise, sometimes it makes instrumental cleaner, if you don&rsquo;t care for more vocal bleeding (it depends also on your sound system how you are able to catch them. E.g. whether you listen on headphones or speakers).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But be aware that:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;A 272 window size in v5 isn&#39;t recommended [in all cases]. Because of the differing bands. In some cases it can make conversions slightly worse. 272 is better for single band models (v4 models) and even then the difference is tiny&rdquo; Anjok (developer)</span></p><p class="c1"><span class="c0">(so on some tracks it might be better to use 320 and not below 352, but personally I haven&rsquo;t found such case yet)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">DeepExtraction is very destructive, and I wouldn&rsquo;t recommend it with current good models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Karokee V2 model for UVR v5 (MDX arch)</span></p><p class="c1"><span class="c0">(leaves backing vocals, 4band, not in Colab yet, but available on MVSep)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Model:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/yJIBXKxR%2310vw6lRJmHRe3CMnab2-w6gAk-Htk1kEhIp_qQGCG3Y&amp;sa=D&amp;source=editors&amp;ust=1765035743941953&amp;usg=AOvVaw0fa9Mh9pyx3a3cqzcBR5rp">https://mega.nz/file/yJIBXKxR#10vw6lRJmHRe3CMnab2-w6gAk-Htk1kEhIp_qQGCG3Y</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be sure to update your scripts (if you use older command line version instead of GUI): </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/tree/v5-beta-cml&amp;sa=D&amp;source=editors&amp;ust=1765035743942418&amp;usg=AOvVaw00Xk9KCOXC7cqzUJ-YgXd0">https://github.com/Anjok07/ultimatevocalremovergui/tree/v5-beta-cml</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Run:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">python inference.py -g 0 -m modelparams\4band_v2_sn.json -P models\karokee_4band_v2_sn.pth -i &lt;input&gt;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5d) Web version for UVR/MDX/Demucs (alternative, no window size parameter for better quality):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743943119&amp;usg=AOvVaw3W4gMlV8bIfMJLRz4Q-iim">https://mvsep.com/</a></span></p><p class="c1"><span class="c0">How to use this free online stem splitter with a variety of quality algorithms -</span></p><p class="c1"><span class="c0">1. Put your audio file in.</span></p><p class="c1"><span class="c0">2. Choose an algorithm. Usually, you really only need to choose one of two algorithms:</span></p><p class="c1"><span class="c0">- The best algorithm for getting clean vocals/instrumental is selecting Ultimate Vocal Remover. Once you selected Ultimate Vocal Remover, select HP-4BAND-V2 as the &quot;Model type&quot;.</span></p><p class="c1"><span class="c0">- The best algorithm for getting clean separate instrument tracks, like bass, drums and other, is Demucs 3 Model B.</span></p><p class="c1"><span class="c0">3. Hit Separate, and mvsep will load it for you. This means you can do everything yourself, no need to ask for other people&#39;s isolations if you can&#39;t find them.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">6) VR 3 band model (gives better results on some songs like K Pop)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/2MpjGIoQ%23rUz2_AzTqISYTm7Yy8YTnoTmWqAhq3JlLbhwor4rYiI&amp;sa=D&amp;source=editors&amp;ust=1765035743944671&amp;usg=AOvVaw0c5AcnvAbakBavfLBftPu3">HP2-MAIN-MSB2-3BAND-3090</a></span></p><p class="c1"><span class="c0">(I think default aggresiveness was 0.3)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">7) deprecated - in many cases lot of bleeding (not every time) but in some cases it hurts some instruments less than all above models (e.g. quiet claps).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MGM-v5-4Band-44100-BETA2/</span></p><p class="c1"><span class="c0">(MGM-v5-4Band-44100-_arch-default-BETA2) </span></p><p class="c1"><span class="c0">/BETA1</span></p><p class="c1"><span class="c0">Agg 0.9, TTA, WS: 272</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes I use Lossless-Cut to merge beta1 and beta2 certain fragments.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Models from point 4 surpasses ensemble of both BETA1 and BETA2 models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c36 c33 c30 c40">(!) Interesting results (back in 2021)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Whoever wants to know the HP1, HP2 plus v4 STACKED model method, I have a [...] group explaining it&quot;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/PHbVxrV4yS&amp;sa=D&amp;source=editors&amp;ust=1765035743946338&amp;usg=AOvVaw1FksR2IWVK89fNRa_9fAFO">https://discord.gg/PHbVxrV4yS</a></span></p><p class="c1"><span class="c0">Long story short - you need to ensemble HP1 and HP2 models, then on top of it, apply stacked model from v4.</span></p><p class="c1"><span class="c0">Be aware that ensemble with postprocessing in Colab doesn&#39;t work.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instruction:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1 Open this link</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/189nHyAUfHIfTAXbm15Aj1Onlog2qcCp0?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743947150&amp;usg=AOvVaw2sHLImPcyGap53PRT9oXiu">https://colab.research.google.com/drive/189nHyAUfHIfTAXbm15Aj1Onlog2qcCp0?usp=sharing</a></span></p><p class="c1"><span class="c0">2. Proceed all the steps</span></p><p class="c1"><span class="c0">3. After mounting GDrive upload your, at best, lossless song to GDrive\MDX\tracks</span></p><p class="c1"><span class="c0">4. Uncheck download as MP3, begin isolation step</span></p><p class="c1"><span class="c0">5. Download the track from &quot;separated&quot; folder on your GDrive. You can use GDrive preview on the left.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>1*. Alternatively, if you have a paid account here, upload your song to: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/ai?hp&amp;sa=D&amp;source=editors&amp;ust=1765035743948020&amp;usg=AOvVaw04eYsEWg6f1HYQkY6wIlrp">https://x-minus.pro/ai?hp</a></span></p><p class="c1"><span class="c0">Make sure you have &quot;mdx&quot; selected for the AI Model option. Wait for it to finish processing.</span></p><p class="c1"><span class="c0">2*. Set the download format to &quot;wav&quot; then click &quot;DL Music.&quot; Store the resulting file in the ROOT of your UVR installation.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">6. Use a combination of UVR models to remove the vocals. Experiment to see what works with what. Here&#39;s a good starting point:</span></p><p class="c1"><span class="c0">HP2-4BAND-3090_4band_arch-500m_1.pth</span></p><p class="c1"><span class="c0">HP2-4BAND-3090_4band_arch-500m_2.pth</span></p><p class="c1"><span class="c0">HP_4BAND_3090_arch-124m.pth &nbsp; &nbsp;</span></p><p class="c1"><span class="c0">HP-4BAND-V2_arch-124m.pth</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">7. Store the resulting file in the ROOT of your UVR installation alongside your MDX result.</span></p><p class="c1"><span class="c0">8. Finally, ensemble the two outputs together. cd into the root of your UVR installation and invoke spec_utils.py like so:</span></p><p class="c1"><span class="c0">$ python lib/spec_utils.py -a crossover &lt;input1&gt; &lt;input2&gt;</span></p><p class="c1"><span class="c0">the output will be stored in the ensembled folder</span></p><p class="c1"><span class="c0">9* (optional). Ensemble the output from spec_utils with the output from UVR 4 stacked models using the same algorithm</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ensemble</span></p><p class="c1"><span class="c0">spec_utils.py allowing ensemble is standalone, and doesn&#39;t require UVR installed in order to work. It accepts any of the audio files </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">mul - multiplies two spectrograms</span></p><p class="c1"><span class="c0">crossover - mixes the high frequencies of one spectrogram with the low frequencies of another spectrogram</span></p><p class="c1"><span class="c0">Default usage from aufr33:</span></p><p class="c63"><span class="c36 c51 c31 c30 c73">python lib/spec_utils.py -o inst_co -a crossover UVR_inst.wav MDX_inst.wav</span></p><p class="c63 c7"><span class="c36 c51 c31 c30 c69"></span></p><p class="c63 c7"><span class="c69 c36 c51 c31 c30"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/blob/v5-beta-cml/lib/spec_utils.py&amp;sa=D&amp;source=editors&amp;ust=1765035743951339&amp;usg=AOvVaw35pfZW6efotXRDWCG_n7RE">https://github.com/Anjok07/ultimatevocalremovergui/blob/v5-beta-cml/lib/spec_utils.py</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Custom UVR Piano Model:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1_GEEhvZj1qyIod1d1MX2lM6u65CTpbml/view?usp%3Ds&amp;sa=D&amp;source=editors&amp;ust=1765035743951797&amp;usg=AOvVaw216r9XtdPn3EUh2_4CtLDM">https://drive.google.com/file/d/1_GEEhvZj1qyIod1d1MX2lM6u65CTpbml/view?usp=s</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">______________</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.nj23a76dbn89"><span class="c21">VR Colab troubleshooting</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you somehow can&#39;t mount GDrive in the VR Colab because you have errors or your separation fails:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Use the same account for Colab and for mounting GDrive (or you&rsquo;ll get an error)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you&rsquo;re on mobile, you might be unable to use Colab without PC mode checked in your browser settings (although now it works without it in Chrome Android)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- In some cases, you won&rsquo;t be able to write &ldquo;Y&rdquo; in empty box to continue on first mounting on some Google account. In that case, e.g. change browser to Chrome and check PC mode.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- In some cases, you won&rsquo;t be able to paste text from clipboard into Colab if necessary, when being in PC mode on Android, if some opened on-screen applications will prevent the access - you&rsquo;ll need to close them, or use mobile mode (PC mode unchecked)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (probably fixed) If you started having problems with logging into Colabs.</span></p><p class="c1"><span class="c0">&gt; Actually, it doesn&#39;t show that you&#39;re logged in while the button says to log in.</span></p><p class="c1"><span class="c0">So, it should respect redirections in Colab links to specific accounts, but if you&#39;re mounting to GDrive, and it fails with Colab error, simply click the button in the top right corner to log in. It will. Just won&#39;t show that you did that. Then Colab will start working.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Don&#39;t use postprocess in ensemble, or you&#39;ll encounter error</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You can try checking force update in case of errors</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Go to runtime&gt;manage sessions&gt;terminate session and then try again with Trigger force update checked (ForceUpdate may not work before terminating session after Colab was launched already).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Make sure you got 4.5GB free space on GDrive and mounting method is set to &quot;new&quot;. You can try out &quot;old&quot; but it shouldn&#39;t work.</span></p><p class="c1"><span class="c0">Try out a few times.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If still nothing, delete VocalRemover5-COLAB_arch folder from GDrive, and retry without Trigger update. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">On fresh installation, make sure you still have 4.5GB space on GDrive (empty recycle bin - automatic successful models installation will leave separate files there as well, so you can run out of space on cluttered GDrive easily)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If still nothing (e.g. when models can&rsquo;t be found on separation attempt), then download that thing, and extract that folder to the root (main) directory of Gdrive, so it looks like following: Gdrive\VocalRemover5-COLAB_arch and files are inside, like in the following link:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1UnjwPlX1uc9yrqE-L64ofJ5EP_a8X407?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743957055&amp;usg=AOvVaw054_n2UXI_m-HRajklmikx">https://drive.google.com/drive/folders/1UnjwPlX1uc9yrqE-L64ofJ5EP_a8X407?usp=sharing</a></span></p><p class="c1"><span class="c0">and then try again running the Colab:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl&amp;sa=D&amp;source=editors&amp;ust=1765035743957423&amp;usg=AOvVaw0Nw-5V2jLgeFvHo4rbUaHv">https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- if you cannot connect with GPU anymore and/or you exceeded your GPU limit</span></p><p class="c1"><span class="c0">try to log into another Google account.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Try not to exceed 1 hour when processing one file or one batch of files, otherwise you&#39;ll get disconnected. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Always close the environment in Environment before you close the tab with the Colab.</span></p><p class="c1"><span class="c0">That way, you will be able to connect to the Colab again after some time, even if you previously connected to the runtime and stopped using it. Not shutting down the runtime before exit, makes it wait in idle, and hitting timeout. Then the error of limit reached will appear after you&#39;ll try to connect to Colab again if it wasn&#39;t closed before. Then you&#39;ll need to wait up to 24h, or switch Colab account, while using the same Google account as for Colab in the mounting cell (otherwise, it will end up with error when you&#39;ll use different account for Colab and different for GDrive mounting).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New layer models may not work with 272 window size causing following error:</span></p><p class="c1"><span class="c0">&ldquo;raise ValueError(&#39;h1_shape[3] must be greater than h2_shape[3]&#39;)</span></p><p class="c1"><span class="c0">ValueError: h1_shape[3] must be greater than h2_shape[3]&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (fixed) Sometimes on running mounting cell you can have short &ldquo;~from Google Colab error&rdquo; on startup. It will happen if you didn&rsquo;t log into any account in the top right corner of the Colab. Sometimes it will show a blue &ldquo;log in&rdquo; button, but actually it&rsquo;s logged in, and Colab will work.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c6">A network error occurred, and the request could not be completed.</span></p><p class="c1 c8"><span class="c6">GapiError: A network error occurred and the request could not be completed. </span></p><p class="c1"><span class="c0">In order to fix these error in Colabs, go to hosts file in your c:\Windows\System32\Drivers\etc\hosts and check if you don&rsquo;t have any lines looking like:</span></p><p class="c1"><span class="c0">127.0.0.1 clients.google.com</span></p><p class="c1"><span class="c0">127.0.0.1 clients1.google.com etc.</span></p><p class="c1"><span class="c0">It can be introduced by RipX Pro DAW.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Various Colabs might occasionally get unstable, and the environment disk might get unmounted, or you might get weird errors. In that case, simply kill the current environment and start over</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- These are all the lines which fix problems in our VR Colabs since the beginning of the year when new versions of these dependencies became incompatible (but usually one Colab linked is forked when told and up-to-date with these necessary fixes applied already)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">!pip install soundfile==0.11.0</span></p><p class="c1"><span class="c0">!pip install librosa==0.9.1</span></p><p class="c1"><span class="c0">!pip install torch==1.13.1</span></p><p class="c1"><span class="c0">!pip install yt-dlp=2022.11.11</span></p><p class="c1"><span class="c0">!pip install git+https://github.com/ytdl-org/ytdl-nightly.git@2023.08.07</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Later in February 2024 we needed to switch to older Python 3.8 in order to make numpy work correctly with used deprecated functions. More details on these fixes and used lines below </span><span class="c4"><a class="c3" href="#h.3c6n9m7vjxul">Similarity Extractor</a></span><span class="c0">&nbsp;section (all those fixes should be already applied in the latest fixed Colab at the top).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7 c8"><span class="c0"></span></p><h6 class="c2 c27" id="h.pv80l0nr97r5"><span class="c33">MDX-Net </span><span class="c4 c33"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743963174&amp;usg=AOvVaw09dc8JxcZOSLmdHPxinrhF">Colab </a></span><span class="c33">by HV</span><span>&nbsp;(March 2025)<br>Models </span><span class="c58">trained by UVR team models </span><span class="c42 c15 c36 c58 c30">(aufr33 &amp; Anjok) </span></h6><h2 class="c29 c27" id="h.87ny11r7l9"><span class="c42 c15 c36 c20 c58">First vocal models trained by UVR for MDX-Net arch:</span></h2><h2 class="c29 c27" id="h.6v62cmednwjl"><span class="c42 c15 c36 c20 c58">9.703 model is UVR-MDX-NET 1, UVR-MDX-NET 2 is UVR_MDXNET_2_9682, NET 3 is 9662, all trained at 14.7kHz</span></h2><p class="c2"><span class="c0">(instrumental based on processed phase inversion)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">List of all (newer) available MDX models at the very top.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I think main was 438 in UVR 5 GUI at some point. At least now it&#39;s simply main_438 (if it wasn&#39;t from the beginning, but it was easy to confuse it with simply main model or even inst main)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(use MDX is a way to go now over VR) Generally use MDX when the results achieved with VR architecture are not satisfactory - e.g. too much vocal bleeding (e.g. in deep and low voices) or damaged instruments. If you only want acappella - it&rsquo;s currently the best solution. Actually the best in most cases now.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX-UVR models are also great for cleaning artifacts from inverts (e.g. mixture (regular track) minus official instrumental or acappella).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(outdated) 9.682 might be better for instrumentals and inversion in some cases, while 9.7 for vocals, but better check already also newer models like 464 from KoD update (should be better in most cases) and also check Kim Model in GUI.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Generally on MVSEP&#39;s multisong dataset, these models received different SDR than on MDX21 dataset back in the days.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">On MVSEP there&rsquo;s 9.7 (NET 1) model, and it doesn&#39;t have any cutoff above training frequency for inverted instrumentals like currently GUI has. For (new) model it&rsquo;s vocal 423 model and possibly with Demucs 2 enabled like in Colab, but it doesn&rsquo;t have a specific jaggy spectrum above MDX training frequency which is specific to inverted vocal 4XX models from that period including Kim&rsquo;s model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Non-onnx version of voc_ft model in pth by MusicMan - 20x faster on MPS devices:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/887455924845944873/1204148534790852608&amp;sa=D&amp;source=editors&amp;ust=1765035743966827&amp;usg=AOvVaw2LIfb7kypjYvL9oD__hWem">https://discord.com/channels/708579735583588363/887455924845944873/1204148534790852608</a></span><span>&nbsp;(roughly the same model size)</span></p><p class="c1"><span>It won&rsquo;t work in UVR. Inference code mirror: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1aSe0bwgIWhR7vvF1aoHQlCHpj39Kd-YK/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743967289&amp;usg=AOvVaw00dl2wQHQWqPnZeW5yMeU3">https://drive.google.com/file/d/1aSe0bwgIWhR7vvF1aoHQlCHpj39Kd-YK/view?usp=sharing</a></span></p><p class="c1"><span class="c0">Mirror:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/16QbwuCBT0_w9nmNDg22m1niq0odtaZUP?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743967620&amp;usg=AOvVaw3_A7Z3gyjbCm8UDn2YboFY">https://drive.google.com/drive/folders/16QbwuCBT0_w9nmNDg22m1niq0odtaZUP?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">And the rest of MDX-Net v2 models: HQ_1-5, inst3, Kim inst, Kim Vocal 1-2, and older narrowband vocal and instrumental ones and Karaoke models.</span></p><h4 class="c17" id="h.zaimpsi6j19a"><span class="c42 c22 c51 c58 c24 c30">(the old) Google Colab by HV</span></h4><p class="c1"><span>(with OG demucs 2 ensembling for vocal models)</span><span class="c22"><br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/189nHyAUfHIfTAXbm15Aj1Onlog2qcCp0?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743968377&amp;usg=AOvVaw03ZlQnRx2JkzOhoX3hPpr8">https://colab.research.google.com/drive/189nHyAUfHIfTAXbm15Aj1Onlog2qcCp0?usp=sharing</a></span></p><p class="c1"><span class="c0">Add separate cell as following, or else it won&rsquo;t work</span></p><p class="c1"><span class="c0">!pip install torch=1.13.1 (probably numpy 1.25 for this old Torch)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you&#39;re still getting errors, delete whole MDX_Colab folder, terminate your session, make clean installation afterward, and don&#39;t forget to have this torch line executed after mounting (that might happen in case you manually replaced model.py with some of the ones below, and didn&#39;t restore the correct old one).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(The Colab to use MDX easily in Google&rsquo;s cloud. Newer models not included, and it gives error if you add other models manually - custom models.py necessary, only 9.7 [NET 1-3] and karaoke models included above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(In case of &ldquo;RuntimeError: Error opening &#39;separated/(trackname)/vocals.wav&#39;: System error.&rdquo; simply retry)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">More MDX models explained in UVR section in the beginning of the document since they&#39;re a part of UVR GUI now.</span></p><p class="c1"><span>Optionally, 423 model can be downloaded separately </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://1.filedit.ch/1/wIfYtOBtLvIIsKKbHPK.rar&amp;sa=D&amp;source=editors&amp;ust=1765035743970245&amp;usg=AOvVaw1Holam3SU3jvkl13KVQk6O">here</a></span><span class="c0">&nbsp;(just in case, it&rsquo;s main). It is on MVSEP as well.</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.aa2xhwp434"><span>(defunt) U</span><span>pd. by KoD &amp; DtN &amp; Crusty Crab &amp; jarredou, HV (12.06.23)<br></span><span class="c42 c15 c36 c58 c30">(probably now requires !pip install numpy==1.26 and restarting env)<br>It might have more models than above (e.g. some beta HQ ones)</span></h4><p class="c1"><span class="c0">____________________________________________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The newest MDX Colabs - now with automatic models downloading (no more manual GDrive models installation as in older updates). Consider everything in the divided section later below as unnecessary.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kae0-0/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743971513&amp;usg=AOvVaw0W1jAG90CFrlDea1j6EWXO">https://colab.research.google.com/github/kae0-0/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb</a></span><span class="c0">&nbsp;(stable, lacks voc_ft batch process + also manual parameters loading per model like in the two above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743972092&amp;usg=AOvVaw2_-c3yN9yYxLiNqG83OCt_">https://colab.research.google.com/github/jarredou/Colab-for-MDX_B/blob/main/MDX_Colab.ipynb</a></span><span class="c0">&nbsp;(Beta. Might lack HQ_3 and voc_ft. It supports batch processing. Works with a folder as input and will process all files in it.</span></p><p class="c1"><span class="c0">In &quot;tracks_path&quot; must be a folder containing (only) audio files (not the direct link to a file).</span></p><p class="c1"><span>But the below might still work.)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1CO3KRvcFc1EuRh7YJea6DtMM6Tj8NHoB?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743972943&amp;usg=AOvVaw0q5yqz798YUuhhLnpiXby6">https://colab.research.google.com/drive/1CO3KRvcFc1EuRh7YJea6DtMM6Tj8NHoB?usp=sharing</a></span><span class="c0">&nbsp;(older revision with also auto models downloader, but with manual n_fft dim_f dim_t parameters setting like HV added)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">and working one by HV linked at the top:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035743973553&amp;usg=AOvVaw1KjkmTbB0kBkwCFIJgDJ9v">https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb</a></span></p><p class="c1"><span>(new one by HV with community edits - 2025)</span></p><p class="c1"><span class="c0">____________________________________________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Old update from before model downloader implementation (May which year?)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1MssLvN06i4gUC-N6QiEgeRdq5IyBiyem&amp;sa=D&amp;source=editors&amp;ust=1765035743974249&amp;usg=AOvVaw19UIMkuZ-o7WQCC6VVA8cC">MDX Colab</a></span><span>&nbsp;with separate input for 3 models parameters, so you don&rsquo;t need to change models.py every time you switch to some other model. Settings for all models listed in Colab. From now on, it uses</span><span>&nbsp;</span><span class="c0">reworked main.py and models.py downloaded automatically (made by jarredou). Don&rsquo;t replace models.py from below packages with models from now on. Now denoiser also optionally added.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">___________________________</span></p><p class="c1"><span class="c0">(older Colab instruction)</span></p><p class="c1"><span class="c0">To use more recent MDX-UVR models in Google Colab:</span></p><ol class="c9 lst-kix_incqcf2p39ls-0 start" start="1"><li class="c1 c25 c8 li-bullet-0"><span>Use and install this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1NV6Ewjn9CLSrKFGCZGFFgd5nG45_Ow7T?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743975277&amp;usg=AOvVaw3UPvtspmOJjkPBkj7qjhUt">Colab</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1MssLvN06i4gUC-N6QiEgeRdq5IyBiyem&amp;sa=D&amp;source=editors&amp;ust=1765035743975397&amp;usg=AOvVaw2UEHfH3r_k69A_gJAuTihx">new</a></span><span class="c0">) to GDrive at least once, run all the cells, nothing more - if you used MDX HV Colab (the one in the section above) on your specific Google Drive account before, ignore this step. </span></li><li class="c1 c25 c8 li-bullet-0"><span>Copy these files to onnx folder in MDX_Colab on your GDrive (inst1-3, 427) (down) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/13SsV7b_kC6SqkICeX5wKhx-Z05uC8dLl&amp;sa=D&amp;source=editors&amp;ust=1765035743976020&amp;usg=AOvVaw0pNZJMfrwVAErAknhKKs-e">https://drive.google.com/drive/folders/13SsV7b_kC6SqkICeX5wKhx-Z05uC8dLl</a></span><span class="c0">&nbsp;(down)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Overwrite models.py in MDX_Colab folder by provided below (not for new Colab)</span></li></ol><p class="c1 c8"><span class="c0">(compatible with inst1-3, 427, Kim vocal and other)</span></p><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/945913897033023559/1036947933536473159/models.py&amp;sa=D&amp;source=editors&amp;ust=1765035743976614&amp;usg=AOvVaw04ux8qWmqyC4Og5yeeoZR3">https://cdn.discordapp.com/attachments/945913897033023559/1036947933536473159/models.py</a></span><span class="c0">&nbsp;(completely different one with self.n_fft set to 7680 - incompatible with NET-1/9.x and 496 models)</span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="4"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Use this notebook with added models </span></li></ol><p class="c1 c8"><span class="c0">(the same as the link in point 1):</span></p><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1zx7DQM-W9i7MJuEu6VTYz1xRG6lKRKVL?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743977302&amp;usg=AOvVaw06DXoBewT6DooKwborh5pX">https://colab.research.google.com/drive/1zx7DQM-W9i7MJuEu6VTYz1xRG6lKRKVL?usp=sharing</a></span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="5"><li class="c1 c25 c8 li-bullet-0"><span class="c0">For Kims vocal model (poor instrumentals on Colab and no cutoff after inversion) copy vocals.onnx</span></li></ol><p class="c1 c8"><span>(use the same models.py from point 3): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1exdP1CkpYHUuKsaz-gApS-0O1EtB0S82?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743977862&amp;usg=AOvVaw0watUUeu5MEmI_endg8qoi">https://drive.google.com/drive/folders/1exdP1CkpYHUuKsaz-gApS-0O1EtB0S82?usp=sharing</a></span></p><p class="c1 c8"><span>to onnx subfolder named </span><span class="c36 c51 c41 c30 c65">&quot;MDX-UVR-Kim Vocal Model (old)&quot; </span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="6"><li class="c1 c25 c8 li-bullet-0"><span>For 496 inst model (inst main/MDX 2.1) go to the link below and put the model to onnx subfolder named &ldquo;</span><span class="c20">MDX-UVR Ins Model 496 - inst main-MDX 2.1</span><span class="c0">&rdquo; but you must replace attached models.py in the link in your GDrive (it&rsquo;s from the OG HV Colab), and it is incompatible with the rest of the models in this new Colab - make a copy/rename the previous models.py in order to go back to it </span></li></ol><p class="c1 c8"><span>(496 model is not as effective as 464/inst3 leaving more vocal residues in some cases, but might work well in specific scenarios). 496 is the only model requiring the old models.py from 9.7/NET1-3 models (attached below). </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1iI_Zvc506xUv_58_GPHfVKpxmCIDfGhx?usp%3Dshare_link&amp;sa=D&amp;source=editors&amp;ust=1765035743979384&amp;usg=AOvVaw1ssFIbs_6HS7xhmihSdVq5">https://drive.google.com/drive/folders/1iI_Zvc506xUv_58_GPHfVKpxmCIDfGhx?usp=share_link</a></span><span>&nbsp;(if you place model in the wrong place, you&rsquo;ll get missing vocals.onnx error [e.g. wrong folder structure or name] or &ldquo;Got invalid dimensions for input: input for the following indices index: 2 Got: 3072 Expected: 2048.&rdquo; [when having wrong models.py])</span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="7"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Demucs turned on works only with default mixing algorithm and vocal models (or else you&rsquo;ll get &ldquo;ValueError: operands could not be broadcast together with shapes (8886272,2) (8886528,2)&rdquo;). Also, chunks might have to be decreased.</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Be aware that after following these steps if you launch the old HV Colab above, it may overwrite models.py by the old one in point 6, which is compatible only with inst main/496 or full band models, so you&#39;ll need to repeat step 3 or 10 in case of invalid dimensions error or cutoff of full band model.</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">In case of runtime error, to use Kim model decrease chunks from 55 to 50, and for Demucs on, decrease it to 40 (or respectively even lower)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">(beta) Full band beta 292 model (with new, only working for that model, models.py file with self.n_fft changed to 6144). </span></li></ol><p class="c1 c8"><span class="c0">Go to the link below, copy model file to onnx subfolder called &ldquo;MDX-UVR Ins Model Full Band 292&rdquo; as in the link, and replace models.py (ideally make a backup/rename the old one in order to use previous models)</span></p><p class="c1 c8"><span class="c0">Thanks for help to Kim </span></p><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1CTJ6ctldr_avwudua1qJJMPAd7OrS2yO?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743982027&amp;usg=AOvVaw3rafyk6tBu68QbFgaO0_FP">https://drive.google.com/drive/folders/1CTJ6ctldr_avwudua1qJJMPAd7OrS2yO?usp=sharing</a></span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="11"><li class="c1 c25 c8 li-bullet-0"><span class="c0">(beta) Full band beta 403 model (with the same modified models.py for these two models)</span></li></ol><p class="c1 c8"><span class="c0">Copy model file to:</span></p><p class="c1 c8"><span class="c0">Gdrive\MDX_Colab\onnx\MDX-UVR Ins Model Full Band 403\&rdquo; as in the link below, and replace models.py in Gdrive\MDX_Colab</span></p><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1UXPxQMVAocpyDVb3agXu0Ho_vqFowHpA?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743982836&amp;usg=AOvVaw1Jkq64gnOCUiILrrOSAr4z">https://drive.google.com/drive/folders/1UXPxQMVAocpyDVb3agXu0Ho_vqFowHpA?usp=sharing</a></span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="12"><li class="c1 c25 c8 li-bullet-0"><span class="c0">(final) Full band 450/HQ_1 model (with the same modified models.py for the full band models)</span></li></ol><p class="c1 c8"><span class="c0">Copy model file to:</span></p><p class="c1 c8"><span class="c0">Gdrive\MDX_Colab\onnx\MDX-UVR Ins Model Full Band 450 (HQ_1)\&rdquo; as in the link below, and replace models.py in Gdrive\MDX_Colab (if you didn&rsquo;t already for full band models)</span></p><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/126ErYgKw7DwCl07WprAXWPD_uX6hUz-e?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743983699&amp;usg=AOvVaw2iK9cbY0A6FprcKU_naitY">https://drive.google.com/drive/folders/126ErYgKw7DwCl07WprAXWPD_uX6hUz-e?usp=sharing</a></span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="13"><li class="c1 c25 c8 li-bullet-0"><span class="c0">From now on, you&rsquo;re forced to run separately newly added torch cell to fix PyTorch issues</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Newer full band 498/HQ_2 model (with the same modified models.py for the full band models)</span></li></ol><p class="c1 c8"><span class="c0">Copy model file to:</span></p><p class="c1 c8"><span class="c0">Gdrive\MDX_Colab\onnx\MDX-UVR Ins Model Full Band 498 (HQ_2)\&rdquo; as in the link below, and replace models.py in Gdrive\MDX_Colab (if you didn&rsquo;t already for full band models)</span></p><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1O5b-uBbRTn_A9B2QkefklCT41YR9voMq?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743984655&amp;usg=AOvVaw1ne34LsX9JnneN_WLQi92_">https://drive.google.com/drive/folders/1O5b-uBbRTn_A9B2QkefklCT41YR9voMq?usp=sharing</a></span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="15"><li class="c1 c25 c8 li-bullet-0"><span class="c0">For full band models, use only modified models.py attached above, or you&rsquo;ll get cutoff at 14.7kHz instead of 22kHz in spectrograms while using 427 models.py file.</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">For Kim other FT instrumental model with cutoff but the highest SDR (even than inst3)</span></li></ol><p class="c1 c8"><span class="c0">Copy both (vocals and other) model files to:</span></p><p class="c1 c8"><span class="c0">Gdrive\MDX_Colab\onnx\Kim ft other instrumental model\&rdquo; as in the link below, and replace models.py in Gdrive\MDX_Colab (if you didn&rsquo;t already for full band models)</span></p><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1v2Hy4AgFOJ9KysebGuOgn0rIveu510j6?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743985769&amp;usg=AOvVaw28fpbZ8UM2TTmLmBY8Ca8S">https://drive.google.com/drive/folders/1v2Hy4AgFOJ9KysebGuOgn0rIveu510j6?usp=sharing</a></span><span class="c0">&nbsp;(it will give only 1 stem output, models duplicated fixes errors in Colab, models.py is from inst3 model)</span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="17"><li class="c1 c25 c8 li-bullet-0"><span class="c0">If you use models.py from fullband model, it will output fullband for ft other model, but giving much more vocal residues (but it still might be even better in some busy mix parts than VR models, while having still less vocal residues only in those busy parts like chorus) - definitely use min_mag here.</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">To fix the following error, make sure both vocals and invert vocals are always checked:</span></li></ol><p class="c1 c8"><span class="c6">shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory</span></p><p class="c1 c8"><span class="c20">Intel MKL FATAL ERROR: Cannot load </span><span class="c0">/usr/local/lib/python3.9/dist-packages/torch/lib/libtorch_cpu.so.</span></p><p class="c1 c8"><span class="c0">Above error can also mean you need to terminate your session and start over. It randomly happens after using the Colab:</span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="19"><li class="c1 c25 c8 li-bullet-0"><span>I&#39;ve reverted old &quot;Karokee&quot; and &quot;Karokee_AGGR&quot; models to use with the oldest HV&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1102627615803723817/models.py&amp;sa=D&amp;source=editors&amp;ust=1765035743987510&amp;usg=AOvVaw3IbSU1cn4XXXQmLgeUOHIN">models.py</a></span><span>&nbsp;file, but these are old models (maybe they will do the trick, though).</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c6">ModuleNotFoundError: No module named &#39;models&#39;</span></li></ol><p class="c1 c8"><span class="c0">Sometimes switching models.py doesn&rsquo;t work correctly (especially during working on previously shared Colab folder with editing privileges) in that case, check Colab&rsquo;s file manager if models.py is actually present after you&rsquo;ve made a change on GDrive. If not, rename it to models.py (it might have been renamed to something else).</span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="21"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Collection of all three models.py for all models for your comfort:</span></li></ol><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1J35h9RYhPFk8dH-vShSW_AUharXY1YsN?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035743988693&amp;usg=AOvVaw1HSDoyxfctLYDnN0NiPLOE">https://drive.google.com/drive/folders/1J35h9RYhPFk8dH-vShSW_AUharXY1YsN?usp=sharing</a></span></p><ol class="c9 lst-kix_incqcf2p39ls-0" start="22"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Main_406 vocal model</span></li></ol><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/dcREzKTR%23PYKk3s1NPicC3mBBYH8ejC2rK_Im3sAj0p9xcOi1cpE&amp;sa=D&amp;source=editors&amp;ust=1765035743989020&amp;usg=AOvVaw0bRUK3E9Vr5DIIYHFD3rYJ">https://mega.nz/file/dcREzKTR#PYKk3s1NPicC3mBBYH8ejC2rK_Im3sAj0p9xcOi1cpE</a></span></p><p class="c1 c8"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &quot;compensate&quot;: 1.075,</span></p><p class="c1 c8"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &quot;mdx_dim_f_set&quot;: 3072,</span></p><p class="c1 c8"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &quot;mdx_dim_t_set&quot;: 8,</span></p><p class="c1 c8"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &quot;mdx_n_fft_scale_set&quot;: 7680,</span></p><p class="c1 c8"><span>&nbsp; &nbsp;</span></p><p class="c1 c7"><span class="c65 c36 c51 c41 c30"></span></p><p class="c1"><span class="c0">Models include here only: baseline, instrumental models: 415 (inst_1), 418 (inst_2), 464 (inst_3) trained on 17.7kHz, and vocal model 427, and Kim&rsquo;s vocal model (old) (instrumental should be automatically made by inversion option, but it&rsquo;s not a very good one for it) and 292 and 403 full band. If you want to use older 9.7 models, use old HV Colab above.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">464/inst 3 should be the best in most cases for instrumentals and vocals than previous 9.x models, but depending, even in half of the cases, 418 can achieve better results, while full band 403 might give better results than inst3/464 in half of the cases.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Settings </span></p><p class="c1"><span class="c0">max_mag is for vocals</span></p><p class="c1"><span class="c0">min_mag for instrumentals</span></p><p class="c1"><span class="c0">default</span></p><p class="c1"><span class="c0">(deleted from the new HV Colab, still in Kae Colab above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But &quot;min mag solve some unwanted vocal soundings, but instrumental [is] more muffled and less detailed.&quot;</span></p><p class="c1"><span class="c0">Also check out &ldquo;default&rdquo; setting (whatever is that, compare checksums if not one of these).</span></p><p class="c1"><span class="c0">Chunks </span></p><p class="c1"><span class="c0">As low as possible, or disabled.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Equivalent of min_mag in UVR is min_spec.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that UVR5, opposed to MDX Google Colab, applies cutoff to inverted output, matching the frequency of training frequency e.g. 17.7kHz for inst 1 and 3 models. It was to avoid some noise and vocal leftovers. You might have to apply it manually.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, you can uncomment visibility of compensation value in Colab, and change it to e.g. 1.08 to experiment.</span></p><p class="c1"><span class="c0">Compensation value for 464 MDX-UVR inst. model is 1.0568175092136585</span></p><p class="c1"><span class="c0">Default 1.03597672895 is for 9.7 model, and it also does the trick with at least Kim (old) model in GUI (where 1.08 had worse SDR).</span></p><p class="c1"><span class="c0">Or check + 3.07 in DAW (it worked on Karokee model).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In Collab above, I also enabled visibility of max_mag for vocals and min_mag for instrumentals settings (mixing_algoritm).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, if you want to use Demucs option (ensemble) in Kae Colab, it uses stock Demucs 2, which in UVR5 was rewritten to use Demucs-UVR models with Demucs 3 or even currently better Demucs 4.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">According to MVSEP SDR measurements, for ensemble Max Spec/Min Spec was better than Min Spec/Max Spec, but Avg/Avg was still better than these both.</span></p><p class="c1"><span class="c0">Also for ensemble, Avg/Avg is better compared to e.g. Max Spec/Max Spec - it&#39;s 10.84 v 10.56 SDR in other result.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">How denoiser work</span></p><p class="c1"><span class="c0">It&#39;s not frequency based, it processes &ldquo;the audio in 2 passes, one pass with inverted phase, then after processing the phase is restored on that pass, and both passes mixed together with gain * 0.5. So only the MDX noise is phase cancelling itself.&rdquo;</span></p><p class="c1"><span class="c0">Or the other way round:</span></p><p class="c1"><span class="c0">&ldquo;it&#39;s only processing the input 2 times, one time normal and one time phase inverted, then phased restored after separation, so when both passes are mixed back together only the noise in attenuated. There&#39;s no other processing involved&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Denoise serves to fix so called MDX noise existing in all inst/voc MDX-NET (v2) models.</span></p><p class="c1"><span>______</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Web version (32 bit float WAV as output for instrumentals, just use MDX-B for single MDX-Net models.</span></p><p class="c1"><span class="c0">It was 9.682 MDX-UVR model in 2021, but in the end of 2022 it&#39;s probably inst 1 judging by SDR (not sure, as results are not exactly the same), then more models were added (e.g. HQ_3):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035743995923&amp;usg=AOvVaw090ihN24eGIarHn9tipFCr">https://mvsep.com/</a></span></p><p class="c1"><span class="c0">Web version (paid for MDX, lossless):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035743996173&amp;usg=AOvVaw3NUMKCohrDDbftDDf9P1F2">https://x-minus.pro/</a></span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In kae Colab, you can keep the option Demucs: off (ONNX only), it may provide better results in some cases even with the old MDX narrowband models (non-HQ). </span></p><p class="c1"><span class="c0">In Colab you can change chunks to 10 if your track is below 5:00 minutes. It will take a bit more time, but the quality will be a bit cleaner, but more vocal residues can kick in (esp. short sudden ones).</span></p><p class="c1"><span class="c0">Be aware that MDX Colabs for single models have 16 bit output. </span></p><p class="c1"><span class="c0">And also noise cancellation implementation for MDX models in kae and HV Colab can differ a bit, plus there is also separate denoise method available as separate model. </span></p><p class="c1"><span>Code for denoise method in HV Colab </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/887455924845944873/1021652469320781834&amp;sa=D&amp;source=editors&amp;ust=1765035743997406&amp;usg=AOvVaw0IxxLF66tSmrgynYvi014I">here</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">As for any other settings, just use defaults since they&#39;re the best and updated.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Just for a vocal it&rsquo;s one of the best free solutions on the market, very close to the result of paid and (partly) closed Audioshake service (#1 AI in a Sony separation contest; SDRs are from the contest evaluation based on private dataset). Very effective, high quality instrumental isolation </span><span class="c20">AI </span><span>and custom model</span><span class="c20">&nbsp;</span><span>(but the old models are trained at 14.7 kHz [NET-X a.k.a. 9.x] in comparison to VR models, and 17.7kHz in newer models like inst X and kim inst).</span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">In most cases MDX-UVR inverted models give less bleeding than VR (especially on bassy voice), while occasionally the result can be worse comparing to VR above, especially in terms of hi-end frequencies quality, but in general, MDX with UVR team models behaves the best for vocals and instrumentals. </span></p><p class="c1"><span class="c0">Even instrumental from inverted vocals from vocal models gets less impaired than in VR, since vocal filtering is less aggressive, but with even more bleeding in some cases. Depends on a song.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You can support the creators of UVR and the newest MDX model is also available on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.patreon.com/uvr&amp;sa=D&amp;source=editors&amp;ust=1765035743999504&amp;usg=AOvVaw2eEz_KxgvP3f3BoQDomfXB">https://www.patreon.com/uvr</a></span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://boosty.to/uvr&amp;sa=D&amp;source=editors&amp;ust=1765035743999603&amp;usg=AOvVaw1B5596YY2L0skS1G_GIUWB">https://boosty.to/uvr</a></span><span>&nbsp;to visit </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://x-minus.pro/&amp;sa=D&amp;source=editors&amp;ust=1765035743999712&amp;usg=AOvVaw0rJCATiWrE9Wy4WmyjMdEE">https://x-minus.pro/</a></span><span class="c0">&nbsp;to get an online version of MDX there as well (with exclusive paid models). </span></p><p class="c1"><span class="c0">At least paid x-minus subscription allows you to use MDX HQ_2 498 (or HQ_3 already) instrumental model and for VR arch - 2_HP-UVR (HP-4BAND-V2_arch-124m), and Demucs 6s on their website. Feel free to listen and download lots of uploaded instrumentals on x-minus already. Dozens of instrumentals available.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Outdated</span></p><p class="c1"><span class="c0">Alternatively you can experiment with 9662 model and ensemble it with the latest UVR 5&#39;s 4 band V2 with -a min_mag as Anjok suggested (but it was when new models weren&#39;t released yet).</span></p><p class="c1"><span class="c0">Remotely I only know about old Colab which ensembles any two audio files, but it uses old algorithm if I&#39;m not mistaken, so it is not as good (better use the ensemble Colab linked at the very top of the document):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1eK4h-13SmbjwYPecW2-PdMoEbJcpqzDt?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744001453&amp;usg=AOvVaw1JvOEYD41bWad22NRyhaNI">https://colab.research.google.com/drive/1eK4h-13SmbjwYPecW2-PdMoEbJcpqzDt?usp=sharing</a></span></p><p class="c1"><span class="c0">_____</span></p><p class="c1"><span class="c0">Note</span></p><p class="c1"><span class="c0">Don&rsquo;t disable invert_vocals in Colab even if you only need vocal instead of instrumental, otherwise the Colab will end up with error.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">MDX noise</span></p><p class="c1"><span class="c0">There is a noise using all MDX-UVR inst/vocal models, and it&rsquo;s model dependent (irc 4 stems don&rsquo;t have it). It&#39;s fixed in Colabs using denoiser &quot;however by using my method, conversions will be 2x slower as it needs to predict twice.</span></p><p class="c1"><span class="c0">I see no quality degradation at all, and I can&#39;t believe it actually worked rofl&quot; -HV</span></p><p class="c1"><span class="c0">Also, UVR 5 GUI has the same noise filtering implemented (if not better, also with alternative model).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Current MDX Colab has normalization feature &ldquo;normalizes all input at first and then changes the wave peak back to original. This makes the separation process better, also less noise. IDK if you guys have tried this, but if you split a quiet track, and normalize it after MDX inference the noise sounds more audible than normalizing it and changing the peak back to original.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you want to experiment with MDX sound, the Colab from before that change is below:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1EXlh--o34-rzAFNEKn8dAkqYqBvhVDsH?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744003768&amp;usg=AOvVaw0KA0oJmmJfyI1_bb5ch9pB">https://colab.research.google.com/drive/1EXlh--o34-rzAFNEKn8dAkqYqBvhVDsH?usp=sharing</a></span><span class="c0">&nbsp;(might no longer work due to changes made by Google to Colab environment, the last maintained are kae and HV (new) Colabs)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Furthermore, you can also try manually mixing vocal with original track using phase inversion and add specific gain on vocal track (+1.03597672895 or +3.07) for 9.7 model (or other ones with different values), using both this and below Colab and save result as 32 bit float (but this might have more bleeding, but it uses 32 bit while chunking):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1R32s9M50tn_TRUGIkfnjNPYdbUvQOcfh?usp%3Dsharing%23scrollTo%3DlkTLtOvyBuxc&amp;sa=D&amp;source=editors&amp;ust=1765035744004861&amp;usg=AOvVaw05GtCXnHP-ax8twUEWTHO3">https://colab.research.google.com/drive/1R32s9M50tn_TRUGIkfnjNPYdbUvQOcfh?usp=sharing#scrollTo=lkTLtOvyBuxc</a></span></p><p class="c1"><span class="c0">(for e.g. the best compensation value for 464 MDX-UVR inst. model is 1.0568175092136585</span></p><p class="c1"><span class="c0">and it&#39;s not constant)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also be aware that MVSEP uses 32 bit for MDX-UVR models for ready inversion of any model too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you look for eliminating the noise from MDX-UVR instrumentals, also the method described in Zero Shot below might work.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I just run the MDX vocals thru UVR to remove any remaining buzz noises and synths, it works great so far&quot; (probably meant one of VR models)</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1"><span class="c0">Average track in Colab is being processed in 1:00-1:30 minute using slower Tesla K80 (much faster than even UVR&rsquo;s HP-4BAND-V2_arch-124m model).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you want to get rid of some artifacts, you can further process output vocal track from MDX through Demucs 3.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Options in the old HV MDX Colab/or kae fork Colab (from the very top)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Demucs model in the older MDX-Net Colab</span></p><p class="c1"><span class="c0">When it&#39;s enabled, it sounds better to me, used with the old narrowband 9.X and newer vocal models, as Demucs 2 model is fullband, but opinions on superiority of this option are divided, and MVSEP dev made some SDR calculation where it achieved worse results with Demucs enabled. But be aware, that inverted results from narrowband are still fullband despite the narrowband training frequency, as there&rsquo;s no cutoff matching present in Colab, as it&rsquo;s implemented in UVR GUI as a separate option. Using such cutoff matching training frequency (which can be observed in non-inverted stem) might lead to less noise and residues in the results. Demucs model will work correctly only with vocal models in Colabs (we didn&rsquo;t have any MDX instrumental models back then, so naming scheme is reversed for these models, hence Demucs model with instrumental model produces distorted sound, it mixes vocals with instrumental in a weird way).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The --shifts=SHIFTS performs multiple predictions with random shifts (a.k.a. the shift trick) of the input and average them. This makes prediction SHIFTS times slower but improves the accuracy of Demucs by 0.2 points of SDR. It has limited impact on Conv-Tasnet as the model is by nature almost time equivariant. The value of 10 was used on the original paper, although 5 yields mostly the same gain. It is deactivated by default, but it does make vocals a bit smoother.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The --overlap option controls the amount of overlap between prediction windows (for Demucs one window is 10 seconds). Default is 0.25 (i.e. 25%) which is probably fine.&rdquo;</span></p><p class="c1"><span class="c0">You can even try out 0.1, but for Demucs 4 it decreases SDR in ensemble if you&rsquo;re trying to separate a track containing vocals. If it&rsquo;s instrumental, then 0.1 is the best (e.g. for drums).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(outdated/for offline use/added to Colab) </span></p><p class="c1"><span>Here&#39;s the new MDX-B Karokee model! </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/iZgiURwL%23jDKiAkGyG1Ru6sn21MkIwF90C-fGD0o-Ws58Mn3O7y8&amp;sa=D&amp;source=editors&amp;ust=1765035744009989&amp;usg=AOvVaw1fUWUh_A5PKOVL7ltllyUP">https://mega.nz/file/iZgiURwL#jDKiAkGyG1Ru6sn21MkIwF90C-fGD0o-Ws58Mn3O7y8</a></span></p><p class="c1"><span class="c0">The archive contains two versions: normal and aggressive. The second removes the lead vocals more. The model was trained using a dataset that I completely created from scratch. There are 610 songs in total. We ask that you please credit us if you decide to use these models in your projects (Anjok, aufr33). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c42 c36 c51 c30 c54">__________________________________________________________________</span></p><p class="c1 c7"><span class="c40 c36 c33 c30"></span></p><h2 class="c29 c27" id="h.99i5nkp6p5v0"><span class="c22 c58">Demucs 3</span><span class="c42 c15 c22 c46 c30">&nbsp;</span></h2><p class="c2"><span class="c40 c36 c33 c30">for 4 stems</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">(SDR 7.7 for 4 stems, it&rsquo;s better than Spleeter (which is SDR 6.5-7), or better than MDX 4 stem. In most cases, it&rsquo;s even better than Audioshake - at least on tracks without leading guitar)</span></p><p class="c2"><span class="c0">Accompanied by MDX-UVR 9.7 vocal model, it gives very good 4 stem separation results</span></p><p class="c2"><span class="c0">(For Demucs 4 a.k.a &quot;htdemucs&quot; check below)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1yyEe0m8t5b3i9FQkCl_iy6c9maF2brGx?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744013078&amp;usg=AOvVaw1c-Oay4VU-mxVPddbMKwl2">https://colab.research.google.com/drive/1yyEe0m8t5b3i9FQkCl_iy6c9maF2brGx?usp=sharing</a></span><span>&nbsp;(by txmutt), alternatively with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1Q-mD-ypAoaaTzmt52nMiml10Wz0NgOMT?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744013376&amp;usg=AOvVaw2Fn7TBVag1fm5pTlcagjMN">float32</a></span><span class="c0">&nbsp;here</span></p><p class="c1"><span>Or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/akhaliq/demucs&amp;sa=D&amp;source=editors&amp;ust=1765035744013711&amp;usg=AOvVaw1QdWAAt6mGzh0lCLdyB4ci">https://huggingface.co/spaces/akhaliq/demucs</a></span></p><p class="c1"><span>Or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744013920&amp;usg=AOvVaw2S181vAIvcopuMt2VksEDm">https://mvsep.com/</a></span></p><p class="c1"><span class="c0">Pick up from the list Demucs Model B there.</span></p><p class="c1"><span class="c0">You can export result files in MP3 320kbps, WAV and FLAC. File limit is 100MB and has a 10 minute audio length limit.</span></p><p class="c1"><span>To use Demucs 3 locally: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/777727772008251433/909145349426384917&amp;sa=D&amp;source=editors&amp;ust=1765035744014917&amp;usg=AOvVaw0EsUFbhcvlhuAVqwjzRADl">https://discord.com/channels/708579735583588363/777727772008251433/909145349426384917</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Currently, all the code uses now main branch which is Demucs 4 (previously HT) but these Colabs use old mdx_extra model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Demucs 3 UVR models 2 stem only available on MVSEP.com or in UVR5 GUI (nice results in cases when you suffer vocal bleeding i regular UVR5, GSEP, MDX 9.7 - model 1 less aggressive, model 2 more destructive, model bag has more bleeding of all three).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>In Colab, j</span><span class="c0">udging by quality of drums track, I prefer using overlap 0.1 (only for instrumentals), but default set by the author is 0.25 and is better for sound of instrumental as a whole.</span></p><p class="c1"><span class="c0">But it still provides decent results with instrumentals.</span></p><p class="c1"><span class="c0">Also, HV had overall better separation quality results using shifts=10, but it increases separation time (it&#39;s also reflected by MVSEP&#39;s SDR calculations). Later we found out it can be further increased to 20.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, I have a report that you may get better results in Demucs using previously separated instrumental from e.g. UVR.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Anjok&rsquo;s tip for better instrumentals: &ldquo;I recommend removing the drums with the Demucs, then removing the vocals and then mixing the drums back in&rdquo;. Yields much better results than simple ensemble.</span></p><p class="c1"><span class="c0">It works the best in cases when drums get muffled after isolation, e.g. in hip-hop. You need to ensure that tracks are aligned correctly. E.g. if you isolate drumless UVR track, isolate also regular track to align drumless UVR track easier with drums track from Demucs, otherwise there will be hard to find the same peaks. Then simply align drumless UVR the same as regular track is aligned and mute/delete UVR regular (instrumental) track.</span></p><p class="c1"><span class="c0">Be aware! This is not a universal solution for the best isolation in every case. E.g. in tracks with busy mix like Eminem - Almost Famous, the guitar in the background can get impaired, and so even drums (UVR tends to impair guitars in general, but on drumless track it was even more prevalent - in that case normal UVR separation did better job).</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c22">Also</span><span class="c0">, if you slow down the input file, it may allow you to separate more elements in the &ldquo;other&rdquo; stem.</span></p><p class="c1"><span class="c0">It works either when you need an improvement in such instruments like snaps, human claps, etc. </span></p><p class="c1"><span class="c0">Normally, the instrumental sounds choppy when you revert it to normal speed. The trick is - &quot;do it in Audacity by changing sample rate of a track, and track only (track menu &gt; rate), it won&#39;t resample, so there won&#39;t be any loss of quality, just remember to calculate your numbers</span></p><p class="c1"><span class="c0">44100 &gt; 33075 &gt; 58800</span></p><p class="c1"><span class="c0">48000 &gt; 36000 &gt; &nbsp;64000</span></p><p class="c1"><span class="c0">(both would result in x 0.75 speed)</span></p><p class="c1"><span class="c0">etc.&quot;.</span></p><p class="c1"><span class="c0">Also, there&#39;s dithering enabled in Audacity by default. Might be worth disabling it in some cases. Maybe not, but still, worth trying out. There should be less noise.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">BTW. If you have some remains of drums in acapella using UVR or MDX, simply use Demucs, and invert drums track.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The output will be a wave file encoded as int16. You can save as float32 wav files with --float32, or 24 bits integer wav with --int24&rdquo; it doesn&rsquo;t seem to work in Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.m9ndauawzs5f"><span class="c42 c15 c22 c46 c30">Demucs 4 (+ Colab) (4, 6 stem)</span></h2><p class="c2"><span class="c0">4 stem, SDR 9 for vocals on MUSDB HQ test, and SDR 9 for mixdowned instrumentals (5, 6 stem - experimental piano [bad] and guitar)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/demucs&amp;sa=D&amp;source=editors&amp;ust=1765035744022813&amp;usg=AOvVaw2yNZTuyDoixkhrUT59CrKO">https://github.com/facebookresearch/demucs</a></span><span>&nbsp;(all these models available in UVR 5 GUI or MVSEP [just x-minus doesn&rsquo;t have ft model for at least free users, it was mmi model at some point, but then got replace by MDX-B which &ldquo; turned out to be not only higher quality, but also faster&rdquo;])</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Google Colab (all 4-6 stem models available, 16-32 bit output)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/117SWWC0k9N2MBj7biagHjkRZpmd_ozu1&amp;sa=D&amp;source=editors&amp;ust=1765035744023763&amp;usg=AOvVaw3rXeuPBAuiDE1rbAh9eZ92">https://colab.research.google.com/drive/117SWWC0k9N2MBj7biagHjkRZpmd_ozu1</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">or Colab with upload script without Google Drive necessity:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1dC9nVxk3V_VPjUADsnFu8EiT-xnU1tGH?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744024286&amp;usg=AOvVaw3-X0pWZrI3XsDUtsMaACb-">https://colab.research.google.com/drive/1dC9nVxk3V_VPjUADsnFu8EiT-xnU1tGH?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">or Colab by Bezio with batch processing, (only mp3 output and no overlap/shifts parameters beside model choice - choose demucs_ft for 4 stems):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/15IscSKj8u6OrooR-B5GHxIvKE5YXyG_5?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744024853&amp;usg=AOvVaw09T2LdKQ-RDAcV4ydIlWam">https://colab.research.google.com/drive/15IscSKj8u6OrooR-B5GHxIvKE5YXyG_5?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">or Colab with batch processing by jarredou (less friendly GUI, but should be usable too, lossless):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1KTkiBI21-07JTYcTdhlj_muSh_p7dP1d?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744025373&amp;usg=AOvVaw0cfwTDfMUwLwOJ4lwU6czN">https://colab.research.google.com/drive/1KTkiBI21-07JTYcTdhlj_muSh_p7dP1d?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I&#39;d recommend using the &ldquo;htdemucs_ft&rdquo; model over normal &ldquo;htdemucs&rdquo; since IMHO it&#39;s a bit better&quot;, also SDR measurements confirm that. 6s might have more vocal residues than both, but will be a good choice in some cases (possibly songs with guitar).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">All the best stock models:<br>- htdemucs_ft (f7e0c4bc-ba3fe64a.th, d12395a8-e57c48e6.th, 92cfc3b6-ef3bcb9c.th, 04573f0d-f3cf25b2.th [drums, bass, other, vocals])</span></p><p class="c1"><span class="c0">&nbsp;&ldquo;fine-tuned version of htdemucs, separation will take 4 times more time but might be a bit better. Same training set as htdemucs&rdquo;.</span></p><p class="c1"><span class="c0">Can be obtained with UVR5 in download center (04573f0d-f3cf25b2.th, 04573f0d-f3cf25b2.th, d12395a8-e57c48e6.th, f7e0c4bc-ba3fe64a.th; not in order)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- htdemucs - &ldquo;first version of Hybrid Transformer Demucs. Trained on MusDB + 800 songs.&rdquo;</span></p><p class="c1"><span class="c0">Default Demucs model in e.g. UVR5 (955717e8-8726e21a.th)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- htdemucs_mmi = Hybrid Demucs v3, retrained on MusDB + 800 songs</span></p><p class="c1"><span class="c0">htdemucs_6s = &nbsp;6 sources version of htdemucs, with piano and guitar being added as sources. Note that the piano source is not working great at the moment.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;nowhere near Logic Pro&rdquo; from May 2025 update.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- mdx_extra: The best Demucs 3 model from MDX 2021 challenge. Trained with extra training data (including MusDB test set), ranked 2nd on the track B of the MDX 2021 challenge.</span></p><p class="c1"><span class="c0">- mdx_extra_q: a bit worse quantized version of the above (a bit faster)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that also UVR team and also ZFTurbo [available on MVSEP and GitHub] trained their own Demucs models (respectively instrumental and vocal ones), but there are some issues with ZFTurbo model using inference other than provided on his GitHub (so it&rsquo;s so far not compatible with e.g. UVR giving &ldquo;KeyError: &quot;&#39;models&#39;&quot; for ckpt Demucs models insteat of th).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To use the best Demucs 4 model in the official Colab (the 2nd link) rename model to e.g. &ldquo;htdemucs_ft&rdquo;. It can behave better than 6 stems if you don&rsquo;t need extra stems.</span></p><p class="c1"><span class="c0">In other cases, extra stems will sound better in the mix, although using 6s model, vocal residues are usually louder than in ft model (but that might depend on a song or genre).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Despite the fact that 6s is an electric guitar model, it can also pick up acoustic guitar very well in some songs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The problem with 6s models is that &ldquo;when a song has a piano because not only the piano model is not the best, but it also makes the sound itself worse</span></p><p class="c1"><span class="c0">rather than just very filtered piano, it sounds like distorted filtered piano&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometime Gsep can be &ldquo;still better because each stem has its dedicated model&quot; but it depends on a song (other stem in GSep can be better more frequently, but now MDX23 jarredou fork or Ensemble models on MVSEP returns good other stems as well)</span></p><p class="c1"><span class="c0">Gsep instead of inverting the whole result among stems like Demucs, won&rsquo;t preserve all the instruments occasionally.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;htdemucs (demucs 4) comes a bit closer [vs Gsep], most of the time the bass is better and there are few instances where demucs picks up drums better&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;From my experience and testing: If you decide to process an isolated track through Demucs, it has no trouble identifying what is bass guitar and what isn&#39;t bass guitar [does not matter if it&#39;s finger/pick/slap, it works on all of them for me, except distorted wah-wah bass]. The leftover noise [the part&#39;s that demucs did not pick up, and left it in the (No Bass) stem] is usually lower than minus 40 - 45 DB, and it&#39;s either noise, or hisses usually.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The problem comes when there are instruments besides the bass guitar that are playing beside it [a.k.a. music], since these are separation models, not identification models. It starts having trouble grabbing all the upper harmonics [which is the multiple of the root note frequency], and the transients, potentially starts mis-detecting, or in extreme cases, it does not pick up the bass at all.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;When used with &quot;--shifts&quot; &gt; 0, demucs gives slightly different results each time you use it, that can also explain some little score differences&rdquo; </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/demucs/issues/381%23issuecomment-1262848601&amp;sa=D&amp;source=editors&amp;ust=1765035744033110&amp;usg=AOvVaw2yV08Rr_paBRNc7OE0GYeI">https://github.com/facebookresearch/demucs/issues/381#issuecomment-1262848601</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Initially, Shifts 10 was considered as max, but it turned out 20 can be used. </span></p><p class="c1"><span class="c0">Overlap 0.75 is max before it gets very slow (and 0.95 when it becomes overkill).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">While we also thought overlap 0.99 is max, it turned out you can use 0.99999 in UVR, and 0.999999 in CLI mode, but both make separations tremendously long, even 0.999 much longer than 0.99.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">On GTX 1080 Ti on 1 minute song:</span></p><p class="c1"><span class="c0">`0.99` &nbsp;= Time Elapsed: `00:09:45`</span></p><p class="c1"><span class="c0">`0.999` = Time Elapsed: `01:36:45`</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, shifts can be set to 0.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">With htdemucs_ft, shifts doesn&#39;t matter nearly as much as overlap, I recommend keeping (shifts) at 2 [for weaker GPUs].</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The drum SDR with 1 and 10 shifts difference is about 0.005</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So overlap impacts SDR a bit more than shifts.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The best way to judge optimum settings is to take a 10-second sample of a vocal extraction where there&#39;s evident bleeding and just keep trying higher overlaps etc until you&#39;re happy, or you lose patience, then you&#39;ll arrive at what I call the &#39;Patience Ratio&#39;. For me, it&#39;s 2x song length.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Installation of only Demucs for Windows</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Use UVR, or:</span></p><p class="c1"><span class="c0">Download the git repo, extract it, then open PowerShell and write </span></p><p class="c1"><span class="c0">&quot;pip install *insert the directory of the extracted repo here*&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/demucs%23egg%3Ddemucs&amp;sa=D&amp;source=editors&amp;ust=1765035744036195&amp;usg=AOvVaw1qIu6WuBg23x2Ypeu47KL2">https://github.com/facebookresearch/demucs#egg=demucs</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Alternatively, execute this command:</span></p><p class="c1"><span>pip install git+</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/demucs%23egg%3Ddemucs&amp;sa=D&amp;source=editors&amp;ust=1765035744036625&amp;usg=AOvVaw3X87rJSTyJi2CUgyqj0uVn">https://github.com/facebookresearch/demucs#egg=demucs</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">or download the git repo first and then </span></p><p class="c1"><span class="c0">&quot;pip install *insert the directory of the extracted repo here*&quot;</span></p><p class="c1"><span class="c0">In case of &ldquo;norm_first_ error run this line or update torch to 1.13.1</span></p><p class="c1"><span class="c0">python.exe pip install -U torch torchaudio </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In Colab, judging by quality of drums track, I prefer using overlap 0.1 (better only for instrumentals) with shifts 10 (actually can be set to even 20), but default set by the author is 0.25 and is better for sound of instrumental as a whole.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, we have overall better separation quality results using shifts=10, but it increases separation time (it&#39;s also reflected by MVSEP&#39;s SDR calculations). Overlaps also increase general separation quality for instrumentals/vocals, at least up to 0.75, but everything above starts being tremendously slow (few hours for 0.99 max setting).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you use particularly high overlap like 0.96 for a full length song, you can run out of Colab time limit if it&rsquo;s not your first file being processed during this session (for cases when processing takes more than 1 hour). If you exceed the limit, you can change Google account in the right top (don&rsquo;t use other account during mounting, or you&rsquo;ll end up with error). The limit is reset after 12 hours (maybe sooner). It&rsquo;s capable of processing one file for two hours, at least only if it&rsquo;s the first file being processed for a longer time during this day. Also, rarely, it can happen that your file is being processed faster than usual despite the same T4 GPU. </span></p><p class="c1"><span>If you have </span><span class="c20">&ldquo;something has gone terribly wrong</span><span class="c0">&rdquo; error right on the separation start, simply retry. If in the end of long separation - ignore it, and don&rsquo;t retry - your result is in the folder.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- *clipclamp* - uncheck it to disable hard limiter, but it may cause separation artifacts on some loud input files or will change volume proportions of the stems. I like it enabled somehow.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Q: How to stop Demucs from rescaling the volume of stems after they&#39;re extracted (without adjusting the volume of the input mixture and passing --clip-mode=clamp)?</span></p><p class="c1"><span class="c0">A: Set &ldquo;&rdquo;--clip-mode none argument coupled with export to --float32&rdquo; (jarredou)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/0VxJdz4&amp;sa=D&amp;source=editors&amp;ust=1765035744040688&amp;usg=AOvVaw1HpLwpybuBBTa77MvNLXRE">Picture</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Demucs parameters explained by jarredou </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;Overlap is the percentage of the audio chunk that will be overlapped by the next audio chunk. So it&#39;s basically merging and averaging different audio chunk that have different start (&amp; end) points.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For example, if audio chunk is `|---|` with overlap=0.5, each audio chunk will be half overlapped by next audio chunk:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">```</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; |---|</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; |---|</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; |---| etc...</span></p><p class="c1"><span class="c0">&nbsp; |---| (2nd audio chunk half overlapping previous one)</span></p><p class="c1"><span class="c0">|---| (1st audio chunk)</span></p><p class="c1"><span class="c0">```</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-shifts is a random value between 0 and 0.5 seconds that will be used to pad the full audio track, changing its start(&amp;end) point. When all &quot;shifts&quot; are processed, they are merged and average. (...)</span></p><p class="c1"><span class="c0">It&#39;s to pad the full song with a silent of a random length between 0 and 0.5 sec. Each shift add a pass with a different random length of silence added before the song. When all shifts are done (and silences removed), the results are merged and averaged.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Shifts is performing lower than overlap because it is limited to that 0.5 seconds max value of shifting, when overlap is shifting progressively across the whole song. Both works because they are shifting the starting point of the separations. (Don&#39;t ask me why that works!)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But overlap with high values is kinda biased towards the end of the audio, it&#39;s caricatural here but first (chunk - overlap) will be 1 pass, 2nd (chunk - overlap) will be 2 passes, 3rd (chunk - overlap) will be 3 passes, etc&hellip;&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So Overlap has more impact on the results than shift.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Side-note: Demucs overlap and MVSEP-MDX23 by ZFTurbo overlap features are not working in the same way. (...)</span></p><p class="c1"><span class="c0">Demucs is kinda crossfading the chunks in their overlapping regions, while MVSep-MDX23 is doing avg/avg to mix them together&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Why is overlapping advantageous?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Because changing the starting point of the separation give slightly different results (I can&#39;t explain why!). The more you move the starting point, the more different the results are. That&#39;s why overlap performs better than shifts limited to 0-0.5sec range, like I said before.</span></p><p class="c1"><span class="c0">Overlap in Demucs (and now UVR) is also crossfading overlapping chunks, that is probably also reducing the artifacts at audio chunks/segments boundaries.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">[So technically, if you could load the entire track in at once, you wouldn&#39;t need overlap]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Shifts=10 vs 2 gives +0.2 SDR with overlap=0.25 (the setting they&#39;ve used in their original paper), if you use higher value for overlap, the gain will be lower, as they both rely on the same &quot;trick&quot; to work.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Shifts=X can give little extra SDR as it&#39;s doing multiple passes, but will not degrade &quot;baseline&quot; quality (even with shifts=0)</span></p><p class="c1"><span class="c0">Lower than recommanded values for segment will degrade &quot;baseline&quot; quality.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So in theory, you can equally set shifts to 0 and max out overlap.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Segments optimum (in UVR beta/new) is 256.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.yy2jex1n5sq"><span>Gsep </span><span class="c36">(</span><span class="c0">2, 4, 5, 6 stem, karaoke)</span></h2><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://studio.gaudiolab.io/&amp;sa=D&amp;source=editors&amp;ust=1765035744046857&amp;usg=AOvVaw2Sk_ayERnzCod07Imna-lZ">https://studio.gaudiolab.io/</a></span></p><p class="c2"><span class="c0">Paid (20 minutes free in mp3 - no credit card required)</span></p><p class="c2"><span class="c0">7$/60 minutes </span></p><p class="c2"><span class="c0">16$/240 minutes </span></p><p class="c2"><span>50$/1200 minutes</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span>E</span><span class="c0">lectric guitar (occasionally bad), good piano, output: mp3 320kbps (20kHz cutoff), wav only for paid users, accepted input: wav 16-32, flac 16, mp3, m4a, mp4, don&rsquo;t upload files over 100MB (and also 11 minutes may fail on some devices with Chrome &quot;aw snap&quot; error), capable of isolating crowd in some cases, and sound effects. Ideally, upload 44kHz files with min. 320kbps bitrate to have always maximum mp3 320kbps output for free.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">2025 metrics for 2 stems</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9095&amp;sa=D&amp;source=editors&amp;ust=1765035744048334&amp;usg=AOvVaw3_LqIMMQDR6lg1IX8rkrMc">https://mvsep.com/quality_checker/entry/9095</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c6">(outdated) About its SDR</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://gaudiolab.com/ai_source_separation_technology/&amp;sa=D&amp;source=editors&amp;ust=1765035744048600&amp;usg=AOvVaw3ZMFHqYWhSuEKndlbpl-oI">10.02 SDR</a></span><span>&nbsp;for vocal model (vs Byte Dance 8.079) on seemingly MDX21 chart, but non-SDR rated newer model(s) were available from 09.06.22, and later by the end of July, and now new model is released since 6 September (there were 4 or 5 different vocal/instrumental models in total so far, the last introduced somewhere in September and no models update was performed with later UI update). </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard.php?sort%3Dinsrum&amp;sa=D&amp;source=editors&amp;ust=1765035744049306&amp;usg=AOvVaw2blEzj45ZCRxNtYBpGtX3t">MVSEP SDR comparison</a></span><span>&nbsp;chart on their dataset, shows it&#39;s currently around SDR 9 for both instrumental and vocals, but I think evaluation done on </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021/leaderboards?challenge_leaderboard_extra_id%3D869%26challenge_round_id%3D886%26post_challenge%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035744049663&amp;usg=AOvVaw1TE4ZlyFgpsxguSCGvJnjo">demixing challenge</a></span><span class="c0">&nbsp;(first model) was more precise. Be aware that GSEP causes issue of cancelling different sounds which cannot be found in any stem.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Since May 2024 update there was an average of 0.13 SDR increase for mp3 output and first 19 songs from multisong dataset evaluation, but judging by no audible difference for most people, they could simply change some parameters of inference. Actually, it&rsquo;s more muddy now, but in some songs there are a bit less of vocal residues, and in other songs, noticeably more. Inverting the mixture with vocals in WAV will muffle the sound in overall, e.g. snares, esp. in places of these residues, but the residues will disappear as well.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Uncheck vocals to download WAV file if WAV download doesn&#39;t work,</span></p><p class="c2"><span class="c0">and uncheck instrumental to download vocals in WAV -</span></p><p class="c2"><span class="c0">don&#39;t check all stems if you can&#39;t download WAV at all and download window simply disappears.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">If you still can&rsquo;t download your WAV files, go to Chrome DevTools&gt;Network before starting downloading, and press CTR+R, now start download. Now both stems should be shown in DevTools&gt;Network, starting with input file name, e.g. instrumental with ending name &ldquo;result_accom.wav&rdquo; (usually marked as &ldquo;fail&rdquo; in State column and xhr as type), click the entry with right mouse button and choose Open in new tab. </span></p><p class="c2"><span class="c0">The download may fail frequently, forcing you to resume the download multiple times in browser manually, or wait a bit on the attempt to download the file at the start.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Free option of separating has been removed since the May 2024 update. There&#39;s only a 20-minute free trial with mp3 output.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Vocals and all other stems (including instrumentals/others) are paid, and length for each stem is taken from your account separately for each model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">No credit is not required for the trial. </span></p><p class="c1"><span class="c0">For free, only mp3 output and 10 minutes input limit.</span></p><p class="c1"><span class="c0">For paid users there&#39;s a 20 minutes limit, and mp3/wav output, plus paid users have faster queue, shareable links, and long term results storage.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Seems like there weren&#39;t any changes in the model</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DOGWaoBOkiMg&amp;sa=D&amp;source=editors&amp;ust=1765035744053503&amp;usg=AOvVaw2_iJruDs0A6qF9JeDZzgt0">https://www.youtube.com/watch?v=OGWaoBOkiMg</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The old files from previous separations on your account didn&#39;t get deleted so far if you have premium.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://studio.gaudiolab.io/pricing&amp;sa=D&amp;source=editors&amp;ust=1765035744053978&amp;usg=AOvVaw2jMy83xbjpD_ohsomR2aRz">https://studio.gaudiolab.io/pricing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There was also added a new option for vocals called &ldquo;Vocal remover&rdquo; - good &quot;for conservative vocals, it&#39;s fine it even has 15 best scoring on SDR.&quot; and 10.85 in vocals on multisong dataset.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c6">Instruction</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Log in, and re-enter into the link above if you feel lost on the landing page.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For instrumental with vocals, simply uncheck drums, choose vocal, and two stems will be available for download.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>As for using 4/5 stem option for instrumental after mixing if you save the tracks mixed in 24 bit in DAW like Audacity, it currently produces less voice leftovers, but the instrumental have worse quality and spectrum probably due to noise cancellation (which is a possible cause of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://vimeo.com/776925082&amp;sa=D&amp;source=editors&amp;ust=1765035744055425&amp;usg=AOvVaw11rtfeC-vZe0ad0ciKsi3G">missing sounds</a></span><span class="c0">&nbsp;in other stem). Use 5 stem, but cut silence in places when there is no guitar in the stem to get comparable quality to 4 stem in such places.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For 3-6 stem, you better don&rsquo;t use dedicated stems mixing option - yes, it respects muting stems to get instrumental as well, but the output is always mp3 128kbps while you can perform mixdown from mp3s to even lossless 64 bit in free DAWs like Audacity or Cakewalk.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In some very specific cases you can get a bit better results for some songs by converting your input FLAC/WAV 16 to WAV 32 in e.g. Foobar2000.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Troubleshooting</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (fixed for me) Sometimes very long &quot;</span><span class="c22">Waiting</span><span>&quot; or recently </span><span class="c22">&ldquo;Waiting&rdquo;</span><span class="c0">&nbsp;- can disappear after refreshing the site after some time (July 2023) - e.g. if you see &ldquo;SSG complete&rdquo; message, you can refresh the site to change from waiting to waveform view immediately. I had that on a fresh account once when uploading the very first file on that account, and then it stopped happening (later it happened for me on an old account as well).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (might be fixed too) </span><span class="c22">If you don&rsquo;t see all stems after separation</span><span class="c0">&nbsp;(e.g. while choosing 2 stems, only vocals or only instrumental is shown) and only one stem can be downloaded (can&rsquo;t be done on mobile browser) - workaround:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;Aw snap&quot; error on mobile Chrome can happen on regular FLACs as well as an attempt to download a song. Simply go back to the main page and try to load the song again and download it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If nothing happens when you press download button on PC, also go to Chrome DevTools&gt;Network&gt;All and click download again. Then new files will appear on the list. Right click and open mp3 file in a new tab to begin download. Alternatively, log into your account in incognito mode.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you have &quot;An error has occurred. Please reload the page and try again.&quot; try deleting Chrome on mobile (cleaning cache wasn&#39;t enough in one case).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- (rather fixed) If you have &ldquo;</span><span class="c12">no audio</span><span class="c0">&rdquo; error all the time when separation is done, or preview loading is infinite, or you have only one stem, also -</span></p><p class="c1"><span>In PC Chrome go to DevTools&gt;Network&gt;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1123682568399749271/image.png?width%3D1222%26height%3D634&amp;sa=D&amp;source=editors&amp;ust=1765035744059434&amp;usg=AOvVaw1TOddVu0LAY5zlwr_XIm8j">All</a></span><span class="c0">&nbsp;and refresh this audio preview site, and new entries will show up on the right, which among others will list filenames with your input file name with stems names e.g. &quot;rest of targets&quot; in the end.</span></p><p class="c1"><span class="c0">Double click it or click RBM on it and press open on new tab, and download will start.</span></p><p class="c1"><span class="c0">If no filenames to download appear on the list, press CTRL+R to refresh the site, and now they should appear.</span></p><p class="c1"><span class="c0">In specific cases, files in the list won&rsquo;t show up, and you will be forced to log in to GSEP using incognito mode (the same account and result can be used). Also, make sure you have enough of disk space on C:.</span></p><p class="c1"><span class="c0">Alternatively, clean site/browser cache (but the latter didn&#39;t help me at some point in the past, don&#39;t know how now).</span></p><p class="c1"><span class="c0">If still the same, use VPN and/or new account (all three at the same time only in very specific cases when everything fails). You can also use different browser.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- When you see loop of redirections when you just logged, and you see Sign In (?~go to main page) simply enter the main link </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://studio.gaudiolab.io/gsep&amp;sa=D&amp;source=editors&amp;ust=1765035744061326&amp;usg=AOvVaw2vktxxdmrw85VTuETGgJyj">https://studio.gaudiolab.io/gsep</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- If you&rsquo;re getting mp3 with </span><span class="c22">bitrate lower than 320kbps</span><span class="c0">&nbsp;which is base maximum quality in this service (but you get 112/128/224 output mp3 instead) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt; Probably your input file is lossy 48kHz or/and in lower bitrate than 320kbps &gt; your file must be at least mp3 320kbps 44kHz (and not 48kHz). The same issue exists for URL option and for Opus file downloaded from YouTube when you rename it to m4a to process it in GSEP. To sum up - GSEP will always match bitrate of the input file to the output file if it&rsquo;s lower than 320kbps. To avoid this, use lossless 44kHz file or if you can&rsquo;t, convert your lossy file to WAV 32 bit (resample Opus to 44kHz as well - it&rsquo;s always 48kHz, for YT files, don&rsquo;t download AAC/m4a files - they have cutoff at 16kHz while Opus at 20kHz). Now you should get 320kbps mp3 as usual without any worse cutoff than 20kHz for mp3 320kbps. </span></p><p class="c1"><span class="c0">If you still not get 320kbps, try using incognito mode/VPN/new account (at best all three at the same time). </span></p><p class="c1"><span class="c0">You can use Foobar2000 for resampling e.g. Opus file (RBM on file in playlist&gt;convert&gt;processing&gt;resampler&gt;44100. And in output file format&gt;WAV&gt;32 bit). Don&rsquo;t download from YT in any other audio than Opus, otherwise it will have 16kHz cutoff and separation result will be worse.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (fixed) Also on mobile, the file may not appear on your list after upload, and you need to refresh the site.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If FLAC persists to be stuck in the &quot;Uploading&quot; screen, try converting it to WAV (32-bit float at best)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Check </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://vimeo.com/776925082&amp;sa=D&amp;source=editors&amp;ust=1765035744064033&amp;usg=AOvVaw2JxWiimf6C6NV9SDaQbLCx">this</a></span><span class="c0">&nbsp;video for fixing issues in missing sounds in stems (known issue with GSEP)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- GSEP separation results don&#39;t begin at the same time signature like UVR results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&gt; In order to fix it, convert mp3 to WAV or align stems manually if you need it for some comparisons or manual ensemble. Also some DAWs can correct it automatically on import.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Eventually hit their </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/tMcqmhu79Y&amp;sa=D&amp;source=editors&amp;ust=1765035744064881&amp;usg=AOvVaw0u_NoQKtFYEWoqEhCLQNw8">Discord</a></span><span class="c0">&nbsp;server and report any issues (but they&rsquo;re pretty much inactive lately).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Remarks about quality of separation</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The main difference (vs old model) is the vocals. I can&#39;t say for sure if they&#39;re better than before, but there is a difference, the &quot;others&quot; and &quot;bass&quot; are also different. Only the drums remain the same. Generally better, but the difference is not massive, depends on the song&rdquo; (becruily)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">GSEP is generally good for tracks where using all the previous methods you had bleeding (e.g. low-pitched hip-hop vocals) or got flute sounds removed, although it struggles with &ldquo;cuts&rdquo; and heavily processed vocals in e.g. choruses. Though, it has more bleeding in some cases when the very first model didn&#39;t, so new MDX-UVR models can achieve generally better results now.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;GSEP is good at piano extraction, but it still lacks in vocal separation, in many times the instruments come out together with the voices, this is annoying sometimes.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Electric guitar model got worse in the last update in some cases. Also, bass &amp; drums also not so loud since the first release of gsep.</span></p><p class="c1"><span class="c0">&quot;Electric guitar model barely picks up guitars, it doesn&#39;t compare to Demix/lalal/Audioshake&quot;.</span></p><p class="c1"><span class="c0">&ldquo;I kinda like it. When it works (that&#39;s maybe 50-60% of time), it&#39;s got merit.&rdquo;<br>The issue happens (also?) when you process (GSEP) instrumental via 5 stems. If you process a regular song with vocals - it picks up guitar correctly. It happens only in a place where previously was vocal removed by GSEP 2 stem.</span></p><p class="c1"><span class="c0">I only tested GSEP instrumental so far, I don&rsquo;t know whether it happens on official instrumentals too (maybe not).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The cool thing is that when the guitar model works (and it grabs the electric), the remaining &#39;other&#39; stem often is a great way to hear acoustic guitar layers that are otherwise hidden. </span></p><p class="c1"><span class="c0">The biggest thing I&#39;d like to see work done on is the bass training. At present, it can&#39;t detect the higher notes played up high... whereas Demucs3/B can do it extremely well.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It has &ldquo;much superior&rdquo; other stem than Demucs or even better than Audioshake. It has changed since 6 September 2022, but probably got updated since then and is probably fine. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">As for 14.10.22 piano model sounds &ldquo;very impressive&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">As for the first version of the model comparable vocal stem to MDX-UVR 9.7, but with current limitation to mp3 320kbps and worse drums and bass than Demucs (not in all cases). Usually less bleeding in instrumentals than VR architecture models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Gsep sounds like a mix between Demucs 3 and Spleeter/lalal, because the drums are kind of muffled, but it&#39;s so confident when removing vocals, there aren&#39;t as many noticeable dips like other filtered instrumentals, and it picks up drums more robustly than Demucs. [it can be better in isolating hihats then Demucs 4 ft model too]</span></p><p class="c1"><span class="c0">It removes vocals more steadily and takes away some song&#39;s atmospheres, rather than UVR approach which tries to preserve the atmosphere, but [in UVR] you end up with vocal artefacts&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">As for tracks with more complicated drums sections: &ldquo;GSEP sounds much fuller, Demucs 3 still has this &quot;issue&quot; with not preserving complex drums&#39; dynamics&rdquo; it refers to e.g. not cancelling some hi-hats even in instrumentals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It happens that some instruments can be deleted from all stems. &ldquo;From what I&#39;ve heard, [it] gets the results by separating each stem individually (rather than subtractive / inverting etc.), but this means some sounds get lost in between the cracks you can get those bits by inverting the gsep stems and lining up with the original source, you should then be left with all the stuff gsep didn&#39;t catch&rdquo;.</span></p><p class="c1"><span class="c0">Also, I&#39;d experiment with the result achieved with Demucs ft model, and apply inversion for just the specific stem you have your sounds missing. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">As for June 2023 gsep is still the best in most cases for stems, not anywhere close to being dead</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">gsep loves to show off with loud synths and orchestra elements, every other mdx/demucs model fail with those types of things</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Processing </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">After your track is uploaded (when 5 moving bars disappear) it&rsquo;s very fast, and it takes 3-4 minutes for one track to be separated using 2 stem option (processing takes around 20 seconds). If 5 bars are moving longer than expected track upload time, and you see that nothing uses your internet upload, simply press CTRL+R and retry, if still the same, log off and log in again. It can rarely happen that the upload stuck (e.g. when you minimize the browser on mobile or switch tabs).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Generally it&rsquo;s very fast and long after the very first GSEP days, I needed to wait briefly in queue twice at 6-9 PM CEST, and I think once on Sunday in weekend of adding new model once in my whole life I waited around 7 minutes. Usually you wait in a queue longer than processing takes, so it&rsquo;s bloody fast.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">___</span></p><p class="c1"><span class="c6">(outdated) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If your stems can&rsquo;t be downloaded after you click the download button, go to Tools for Developers in your browser and open the console and retry. Now you should see an error with file address and your file name in it. You can simply copy the address to the address bar and start downloading it.</span></p><p class="c1"><span class="c0">(Outdated - 3rd model changes) The quality of hi-hats is enhanced, sometimes at the cost of less vivid snare in less busy mix, while it&rsquo;s usually better in busy mix now, but it sometimes confuses snare in tracks when it sounds similar to hi hat making it worse than it was. So a trap with lots of repetitive hi-hats and also tracks with a busy mix should sound better now.</span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.xdux18tet3x9"><span class="c42 c15 c22 c30 c46">dango.ai</span></h2><p class="c2"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://dango.ai/vocal-remover&amp;sa=D&amp;source=editors&amp;ust=1765035744075690&amp;usg=AOvVaw3PlPDE-Js-pirp_bK41Ptt">2</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://dango.ai/stem-separator&amp;sa=D&amp;source=editors&amp;ust=1765035744075820&amp;usg=AOvVaw2thiUs_909ca8xDo9bhx5d">more</a></span><span>&nbsp;</span><span class="c0">[up to 6+] stems, paid only, 30 seconds free preview of mp3 320 output, 20kHz cutoff)</span></p><p class="c2"><span class="c0">drums, vocal, bass guitar, electric guitar, acoustic guitar, violin, erhu</span></p><p class="c2"><span class="c0">&ldquo;10 tracks = &euro;6.33 + needs Alipay or WeChat Pay&rdquo;</span></p><p class="c2"><span class="c0">max 12 minutes input files allowed</span></p><p class="c2"><span class="c0">Now the site has English interface</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Currently, one of the best instrumental results (if not the best). Not so good vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(for older models) The combination of 3 different aggression settings (mostly the most aggressive in busy mix parts) gives the best results for Childish Gambino - Algorithm vs our top ensemble settings so far. But it&#39;s still far from ideal (and [not only] the most aggressive one makes instruments very muffled [but vocals are better cancelled too], although our separation makes it even a bit worse in more busy mix fragment). </span></p><p class="c1"><span class="c0">As for drums - better than GSEP, worse than Demucs 4 ft 32, although a bit better hihat. Not too easy track and already shows some diffrences between just GSEP and Demucs when the latter has more muffled hi-hats, but better snare, and it rather happens a lot of times</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(old) Samples: </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1070546464322883664&amp;sa=D&amp;source=editors&amp;ust=1765035744078168&amp;usg=AOvVaw3UG31JjlKX0Tr7AlobyDin">Instrumental</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1RSKoci8gPd4w2fRNb2rsJdrjPhaIfFxm?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744078381&amp;usg=AOvVaw0fqjhJDupO15UsCin8zmcm">Drums</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, it automatically picks the first fragment for preview when vocal appears, so it is difficult to write something like AS Tool for that (probably manipulations by manual mixing of fake vocals would be needed). Actually, smudge wrote one.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Very promising results even for earlier version.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">They wrote once somewhere about limited previews for stem mode (for more than 2 mode) and free credits, but haven&rsquo;t encountered it yet.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">They&rsquo;re accused by aufr33 to use some of UVR models for 2 stems in the past, without crediting the source (and taking money for that).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Now new, better models are released. Better instrumentals than in UVR/MVSep, and not the same models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It used to be possible to get free 30 seconds samples on dango.ai, but recently 5 samples are available for free (?also) here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tuanziai.com/vocal-remover/upload&amp;sa=D&amp;source=editors&amp;ust=1765035744080486&amp;usg=AOvVaw1bKK_wThZDFw4-G1uYAvjS">https://tuanziai.com/vocal-remover/upload</a></span></p><p class="c1"><span class="c0">You must use the built-in site translate option in e.g. Google Chrome, because it&#39;s Chinese only. You are able to pay for it using Alipay outside China.</span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.69k3dgps61mc"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://music.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035744080943&amp;usg=AOvVaw2Nh5Z4wDBmFkFaQPsD8q1Q">music.ai</a></span></h2><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span>Paid - $25 per month or pay as you go (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://music.ai/pricing/&amp;sa=D&amp;source=editors&amp;ust=1765035744081215&amp;usg=AOvVaw0rZmdoul-1tk9kQ0gbrA-L">pricing chart</a></span><span class="c0">). In fact, no free trial. </span></p><p class="c2"><span>Good </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/ssjEI79.png&amp;sa=D&amp;source=editors&amp;ust=1765035744081405&amp;usg=AOvVaw1a5DTzvoeQqi1flYquDibn">selection</a></span><span>&nbsp;</span><span>of models and interesting </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/h3u7Vuw.png&amp;sa=D&amp;source=editors&amp;ust=1765035744081574&amp;usg=AOvVaw0vGu0Ffj7dYMXlTpBAen1k">module stacking</a></span><span class="c0">&nbsp;feature. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To upload files instead of using URLs &ldquo;you make the workflow, and you start a job from the main page using that custom workflow&rdquo; [~ D I O ~].</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Allegedly it&rsquo;s made by Moises team, but the results seem to be better than those on Moises.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Bass was a fair bit better than Demucs HT, Drums about the same. Guitars were very good though. Vocal was almost the same as my cleaned up work. (...) An engineer I&#39;ve worked with demixed to almost the same results, it took me a few hours and achieve it 39 seconds&rdquo; (...) I&#39;d say a little clearer than MVSEP 4 Ensemble. It seems to get the instrument bleed out quite well,&rdquo; </span></p><p class="c1"><span class="c0">&ldquo;Beware, I&#39;ve experienced some very weird phase issues with music.ai. I use if for bass, but vocals are too filtered / denoised imo and you can&#39;t choose to not filter it all so heavily.&rdquo;</span></p><p class="c1"><span class="c0">Sam Hocking</span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.jmb1yj7x3kj7"><span class="c42 c15 c22 c46 c30">MDX23 by ZFTurbo (jarredou fork) - 2, 4 stems</span></h2><p class="c2"><span class="c0">(2-4 stems, max 32-bit float output)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c20">As of October 2025, the following Colabs are defunct due to Google&rsquo;s runtime changes &nbsp;(possible </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training-Colab-Inference/issues/5%23issuecomment-3478451287&amp;sa=D&amp;source=editors&amp;ust=1765035744084103&amp;usg=AOvVaw2fv1p47S5Iwvwu4dDwYk6u">fix</a></span><span class="c6">).</span></p><p class="c2 c7"><span class="c6"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744084348&amp;usg=AOvVaw11x0v_qvJHv5T8nx5fZIIn">v2.5</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1v-a7qcdmUOaXLJd9QUpUBnac9Atxb3dd?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744084493&amp;usg=AOvVaw0YGBNQU5PT6CAeyFXUa7D4">v2.5 /w HQ_5</a></span><span>&nbsp;(experimental - muddiness, residues - set HQ_5 weight to 2.5 or lower)</span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/deton24/MVSEP-MDX23-Colab_v2.1/blob/2.7/MVSep_MDX23_Colab_2_7_Version_Updated.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744084878&amp;usg=AOvVaw15edL8ckmL4Q9TSGpitYt8">/w SCNet XL</a></span><span>&nbsp;(weights not measured), </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.4/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744085066&amp;usg=AOvVaw0otGFoCPkOU_XkS6lXivJe">2.4</a></span><span>&nbsp;(added BS-Roformer model),</span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kubinka0505/colab-notebooks/blob/master/Notebooks/AI/Audio/Separate/MDX23C.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744085270&amp;usg=AOvVaw0N065XrarsDbPVE6s_8Xgz">2.3</a></span><span>&nbsp;(Kubinka fork of jarredou&rsquo;s Colab /w FLAC conversion, ZIP unpacking, new fullband preservation), </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/deton24/MVSEP-MDX23-Colab_v2.1/blob/main/MVSep_MDX23_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744085600&amp;usg=AOvVaw1dwLKutSJDgnUPXImT9YIY">2.1</a></span><span>&nbsp;(voc_ft instead of Kim Vocal 2, a bit better SDR over 2.0 in overall)</span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744085864&amp;usg=AOvVaw2J0LseeVoxJmrTfj5e02I2">2.2</a></span><span>&nbsp;(with MDX23C model, may have more vocal residues vs 2.1), org. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.3/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744086089&amp;usg=AOvVaw0QOjxlNe7ueoqB6QXn-RAI">2.3</a></span><span>&nbsp;(with VitLarge model instead instr-HQ3), </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/MVSEP-MDX23-music-separation-model/releases&amp;sa=D&amp;source=editors&amp;ust=1765035744086258&amp;usg=AOvVaw2vOlsIy6dROmuQJ5CMRcYz">GUI/CML</a></span><span class="c0">&nbsp;(GUI only for older original 1.x release by ZFTurbo), instructions for local installation at the button</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The ZFTurbo 1.0 Colab further modified by jarredou to alleviate vocal residues. It adds better models and volume compensation, fullband trick for narowband vocal models, higher frequency bleeding fix and much more. Currently, it achieves not much worse SDR as current &ldquo;Ensemble 4 models&rdquo; on MVSEP utilizing some newer private models available only on MVSEP already. Initially released 1.x code by ZFTurbo received 3rd place in the latest MDX 2023 challenge.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I have successfully processed a ~30min track with vocals_instru_only mode [on Colab] while I was working on that 2.3 version, but it was probably with minimal settings.</span></p><p class="c1"><span class="c0">[Errors/freezes are] already happening during Demucs separation when you do 4-stem separation with files longer than ~10-15 min&rdquo; jarredou</span></p><p class="c1"><span class="c0">With v. 2.4, 30 minute file was too long, and the Colab hung on Roformer model separation.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The Colab combines results of then the best public models of different architectures using custom weights for every model (like a manually set volume for every stem, then mixed with others together), instead of usual methods of ensembling as in UVR, which in e.g. &ldquo;avg&rdquo; averages results of all models (so there the same volume is used for every stem). More tricks in the Colab explained further below.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">As of v. 2.5 &ldquo;Baseline ensemble is made with Kim Melband Rofo, InstVocHQ and selected 1296 or 1297 BS Rofo&rdquo; (so Kim Rofo was added, and VitLarge is no longer default).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">~&ldquo;Free Google Colab gives you 3h per day, then you need to wait 24h, and next day it gives you 2 free hours, after 24h wait you&#39;ll get only 1h, and 24h later, 2h of free credits, the day after 1h of free credits, etc... and once in that pattern, you have to wait 48h to recover the 3h back.&rdquo; You can just change Google account when GPU limit is reached, but remember to use the same new account during mounting GDrive, otherwise you may get an error.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;I&#39;ve opened a donation account for those who would want to support me: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ko-fi.com/jarredou&amp;sa=D&amp;source=editors&amp;ust=1765035744090403&amp;usg=AOvVaw16OohTKbnhs9HZ8R8W5NvK">https://ko-fi.com/jarredou</a></span><span class="c0">&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Troubleshooting</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;PytorchStreamReader error&rdquo;</span></p><p class="c1"><span class="c0">simply restart the environment, it&rsquo;s a random issue occurring in the Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;usage: inference.py [-h] --input_audio INPUT_AUDIO [INPUT_AUDIO ...] --output_folder&rdquo;</span></p><p class="c1"><span class="c0">(and the whole list of arguments is shown below)</span></p><p class="c1"><span class="c0">launch mount to GDrive cell (it&rsquo;s not being done automatically) or change file input and output path</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;ValueError: Mountpoint must not already contain files&rdquo;</span></p><p class="c1"><span class="c0">(on attempt of mounting GDrive), go to file manager on the left, and you probably have GDrive folder with empty folders you need to delete from there first, and retry (might happen when you use GDrive on this account while it&rsquo;s nto mounted yet, but Colab works).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;no such file&quot; </span></p><p class="c1"><span class="c0">(error in v2.3 while batch processing)</span></p><p class="c1"><span class="c0">&ldquo;it&#39;s square brackets [ ] </span></p><p class="c1"><span class="c0">when it sees a [ in the filename, it then thinks there&#39;s two additional [ ] in the name </span></p><p class="c1"><span class="c0">changing to regular parentheses does work&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;If I input more than a single song it just starts building up on model data without clearing the old one, so it slowly starts running out of VRAM and then gets stuck&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Experimenting with settings </span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">- Default settings of the Colab are a good starting point in general</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Some people like to increase BigShifts to 20 or even 30 with all other default settings (some songs might be less muddy that way), but default 3 is already balanced value, but exceeding 5 or 7 may not give a noticeable difference, while increasing separation time severely.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Switching from 1296 to 1297 model produces more muddy/worse instrumentals in this Colab (more sudden jumps of dynamics from residues). Similar situation with decreasing BigShifts to 1.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- voc_ft enabled might give less muddy results, but with more residues in instrumentals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- In 2.5 you can try out the following settings by mesk:</span></p><p class="c1"><span class="c0">&ldquo;Set the weights of BS-RoFormer &amp; MDX23C to 0, enable VitLarge, and set the weights of Mel-RoFormer &amp; VitLarge to 8 &amp; 3 respectively. </span></p><p class="c1"><span class="c0">You can set BigShifts to whatever you&#39;d like, I think 5 or 7 is optimal&rdquo; but mesk uses even 9.</span></p><p class="c1"><span class="c0">VitLarge overlap can no longer be changed in v2.5 of the Colab, probably only in CLI version.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Or you can test ensemble of only Kim weight 10 + Vit weight 5, BigShifts e.g. 9</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Or BS-Roformer with MDX23C</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Experimentally set &ldquo;Separation_mode:&rdquo; to 4 stems (slower) and &quot;filename_instrum2&quot; will be the sum of the Drums + Bass + Other stems that are obtained by processing &quot;instrum&quot; with multiple Demucs models. It might have a bit less vocal residues or be a bit muddier. Vs 2.1 denoiser is less aggressive as its disabled for some stems to save on VRAM.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Increasing overlap might give muddier results, but potentially better if you hear some vocal residues</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- In e.g. older v. 2.4 you might want to disable VitLarge to experiment (it&rsquo;s disabled in 2.5) - the model increases some noise at times</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Older versions than 2.4 have very clean results for instrumentals, although it can rarely fail in getting rid of some vocals in quiet fragments of a track, but it has bigger SDR than the best ensembles in UVR. Versions 2.4 and newer started to utilize BS-Roformer arch, which is pretty muddy itself, but deprived of the majority of vocal residues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For instrumentals, I&rsquo;d rather stick to instrum2 results (so sum of all 3 stems instead of inversion with e.g. inst only enabled) but some fragments can sound better in instrum and it also slightly better SDR, so e.g. instrum can give louder snares at times, while instrum2 is muddier but sometimes less noisy/harsh. It can all depend on a song. Most people can&rsquo;t tell a difference between both.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you stuffer from some vocal residues in v. 2.2.2, try out these settings</span></p><p class="c1"><span class="c0">BigShifts_MDX: 0</span></p><p class="c1"><span class="c0">overlap_MDX: 0.65</span></p><p class="c1"><span class="c0">overlap_MDXv3: 10</span></p><p class="c1"><span class="c0">overlap demucs: 0.96</span></p><p class="c1"><span class="c0">output_format: float</span></p><p class="c1"><span class="c0">vocals_instru_only: disabled (it will additionally give instrum2 output file for less vocal residues in some cases)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You can manipulate with weights.</span></p><p class="c1"><span class="c0">E.g. different weight balance, in 2.2 with less MDXv3 and more VOC-FT.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- For vocals in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744100913&amp;usg=AOvVaw0pGckCphxfocig7TE3OYm2">2.2</a></span><span>&nbsp;you can test out </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1191316113166958622/image.webp&amp;sa=D&amp;source=editors&amp;ust=1765035744101120&amp;usg=AOvVaw3-4-zPtnBkpNn-ZeULg_ZA">these</a></span><span class="c0">&nbsp;(dead link) settings (21, 0, 20, 6, 5, 2, 0.8)</span></p><p class="c1"><span class="c0">- In older versions of the Colab Overlap large and small control overlap of song during processing. The larger value, the slower processing but better quality (for both), but bad setting will crash your separation at least on certain songs.</span></p><p class="c1"><span class="c0">Q: is it possible to use v.2.5 for Melband inference without the need to run the BS model?</span></p><p class="c1"><span class="c0">A: You can comment out the model(s) you don&#39;t want to disable them L621-627 in inference.py [in the line called &ldquo;vocals_model_names&rdquo;</span></p><p class="c1"><span class="c0">Probably, you could also set BS weight to 0, but it might trigger separation of that model anyway, making it slower.]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- To experiment with parameters for just 4 stems separation, you can use:</span></p><ol class="c9 lst-kix_ypd5gkkarijk-0 start" start="1"><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;overlap_demucs&quot; in the Colab (not sure how in this Colab, but for demucs_ft, shifts 10 and overlap 0.1 worked the best for original instrumentals as input)</span></li><li class="c1 c25 c8 li-bullet-0"><span>shifts for demucs are in line probably 511 (formerly 618 in some other versions iirc): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/inference.py&amp;sa=D&amp;source=editors&amp;ust=1765035744103081&amp;usg=AOvVaw2YNpctkxONGS9GZc_TkPK6">https://github.com/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/inference.py</a></span></li></ol><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- In order to bypass models for 2 stem separation to use just instrumentals as input for 4 stem separation, &ldquo;comment out/delete the name of the models you want to bypass&rdquo; in the line 621 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/g3mrQTb&amp;sa=D&amp;source=editors&amp;ust=1765035744103543&amp;usg=AOvVaw2MC0C0_D0ouiXJbmS6-atJ">screen</a></span><span class="c0">). &ldquo;If you want to use only VOCFT, you have to activate InstVoc too, else it will crash (as it&#39;s using InstVoc to fill the spectrum part that is missing because of VOCFT cutoff)&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Using other models not included in the Colab</span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/inference.py&amp;sa=D&amp;source=editors&amp;ust=1765035744104289&amp;usg=AOvVaw1k_ObCEv8QCuAF2CZIXGqe">https://github.com/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.5/inference.py</a></span></p><p class="c1"><span class="c0">E.g. in line 452 you can replace Kim model by any other vocal model, and replace that edited in file manager once Colab has executed initialization cell or fork the repo. As for using instrumental Roformer models instead of vocal models, I can&#39;t guarantee it will work correctly.</span></p><p class="c1"><span>- &ldquo;Easiest way [to replace MDX HQ model] should be to replace Inst-HQ4 link with HQ5 link line 480 </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/MVSEP-MDX23-Colab_v2/blob/36909309efd4a75dab9f1d093a112785a8f560fb/inference.py%23L480&amp;sa=D&amp;source=editors&amp;ust=1765035744105318&amp;usg=AOvVaw2ZIp_Ch3v24xNS_pjIFCX4">https://github.com/jarredou/MVSEP-MDX23-Colab_v2/blob/36909309efd4a75dab9f1d093a112785a8f560fb/inference.py#L480</a></span></p><p class="c1"><span class="c0">If models parameters are same (iirc they are), drop-in replacement should work (and then you control HQ5 with HQ4 settings in colab GUI)&rdquo;</span></p><p class="c1"><span class="c0">- Change the args awaited by inference.py accordingly to the ones you&#39;ve changed in the Colab notebook [if you decide to change models names in he Colab], it&#39;s at bottom of inference.py (line 874 and so on)</span></p><p class="c1"><span class="c0">- Adding e.g. SCNet is not that easy task, it will also require to really add SCNet arch to the script, not only words (add its core files to &quot;modules&quot; folder, import them in main script, check if that work with existing &quot;demix&quot; functions, etc... else it can&#39;t work).</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/tree/main/models/scnet&amp;sa=D&amp;source=editors&amp;ust=1765035744106843&amp;usg=AOvVaw09QYbtbkN7MQKbWOAxpV2E">https://github.com/ZFTurbo/Music-Source-Separation-Training/tree/main/models/scnet</a></span></p><p class="c1"><span class="c0">You can study how ZFTurbo is doing it with his script and then try to adapt it to MDX23 Colab. ~jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- What weight you should use for your custom model?</span></p><p class="c1"><span>&ldquo;You must process an evaluation dataset with each model individually, download the separated audio and then use my &quot;weight finder&quot; script (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/773763762887852072/1273057160670089236&amp;sa=D&amp;source=editors&amp;ust=1765035744107593&amp;usg=AOvVaw3TB_7yPM3Qu0DXEUequew9">here</a></span><span>&nbsp;[</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1Hn5rFYaUGxRkdrwUCiOwOES06PPghAwu&amp;sa=D&amp;source=editors&amp;ust=1765035744107713&amp;usg=AOvVaw3NZgd-mPl18OHvirIqigze">mirrored</a></span><span class="c0">]) with all the separated audios from each model. It will try many different weights until it find the best ones for the given model inputs.</span></p><p class="c1"><span>Else you can set &quot;random&quot; weights, process the multisong dataset from MVSEP and upload the separated audios to the quality checker to get the evaluation scores </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/en/quality_checker&amp;sa=D&amp;source=editors&amp;ust=1765035744108304&amp;usg=AOvVaw37FzlVDwgHWrozsyy63cOq">https://mvsep.com/en/quality_checker</a></span><span class="c0">&nbsp;(and repeat until you&#39;re satisfied)</span></p><p class="c1"><span class="c0">Download the mutlisong eval dataset provided on the quality checker link I&#39;ve shared above. Process the 100 tracks with the model/ensemble you want to evaluate. Download the separated audio.</span></p><p class="c1"><span class="c0">Rename the files accordingly to guidelines provided in quality checker link, zip them, upload them and wait for the results</span></p><p class="c1"><span class="c0">All in same folder, and named:</span></p><p class="c1"><span class="c0">song_000_instrum.wav</span></p><p class="c1"><span class="c0">song_000_vocals.wav</span></p><p class="c1"><span class="c0">song_001_instrum.wav</span></p><p class="c1"><span class="c0">song_001_vocals.wav</span></p><p class="c1"><span class="c0">song_002_instrum.wav</span></p><p class="c1"><span class="c0">song_002_vocals.wav</span></p><p class="c1"><span class="c0">etc...</span></p><p class="c1"><span>Software like </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.advancedrenamer.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744110172&amp;usg=AOvVaw3CcQuhU2admUZcO52mI5ql">https://www.advancedrenamer.com/</a></span><span class="c0">&nbsp;can be useful for this&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">About</span></p><p class="c1"><span class="c0">The Colab produces one of the best SDR scores for 4 stems (maybe with slightly better implementation on MVSEP as &ldquo;Ensemble&rdquo; 4/5 or more models, although it could be 24 or 32 bit output used for that evaluation which increases SDR (jarredou&rsquo;s v2.3 evaluation was made using 16 bit).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In version 2.4, for 2 stems, UVR/ZFTurbo/Viperx following models are used: </span></p><p class="c1"><span class="c0">MDX23C Inst Voc HQ/MDX-Net HQ_4 and voc_ft (optionally)/VitLarge/BS-Roformer</span></p><p class="c1"><span class="c0">and for 4 stems: </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">How MDX23 Colab works under the hood in 2.3 iirc (more or less)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- MDX models vocal outputs (so inversion of one inst model there) + Demucs only vocals&gt;inversion of these to get instrumental&gt;demucs_ft+demucs 6s+demucs+mmi to get remaining 3 stems (weighted) to get remaining 3 stems (all steps weighted). Something in this recipe could be changed since then.</span></p><p class="c1"><span class="c0">Or differently - &ldquo;The process is:</span></p><p class="c1"><span class="c0">1. Separate vocals independently with InstVocHQ, VitLarge (and VOC-FT as opt)</span></p><p class="c1"><span class="c0">2. Mix the vocals stems together as a weighted ensemble to create final vocals stem</span></p><p class="c1"><span class="c0">3. Create instrumental by inverting vocals stem against source</span></p><p class="c1"><span class="c0">4. Save vocals &amp; instrumental stems</span></p><p class="c1"><span class="c0">5 (if 5). Take the instrumental to create the 3 others stems with the multiple demucs models weighted ensembles + phase inversion trick and save them.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Modified inference will probably work locally too, e.g. if you use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/deton24/MVSEP-MDX23-Colab_v2.1&amp;sa=D&amp;source=editors&amp;ust=1765035744113110&amp;usg=AOvVaw1nIA2Ek4Eo3NFK-aiLeaKP">that</a></span><span>&nbsp;2.1 </span><span class="c0">repo locally (and probably newer too), but the modified inferences from jarredou crashes the GUI, so you can only use CML version locally in that case.</span></p><p class="c1"><span class="c0">Usage:</span></p><p class="c1"><span>python inference.py --input_audio mixture1.wav mixture2.wav --output_folder ./results/</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To separate locally, it generally requires a 8GB VRAM Nvidia card. 6GB VRAM is rather not enough but lowering overlaps (e.g. 500000 instead of 1000000) or chunking track manually might be necessary in this case. Also, now you can control everything from options: so you can set chunk_size 200000 and single ONNX. It can possibly work with 6GB VRAM that way.</span></p><p class="c1"><span class="c0">If you have fail to allocate memory error, use --large_gpu parameter.</span></p><p class="c1"><span class="c0">Chunks option have been deleted from newer Colab options.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Jarredou made some fixes in 2.2.2.x version in order to handle memory better with MDX23C fullband model.</span></p><p class="c1"><span class="c0">&ldquo;I&#39;ve only removed the denoise double pass for demucs_6s, it&#39;s activated for other demucs models.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">jarredou:</span></p><p class="c1"><span>&ldquo;you can use a workaround to have MDX23C InstVoc-HQ results only with (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/767947630403387393/1162948305152655390/image.png?ex%3D653dcb02%26is%3D652b5602%26hm%3D307fa02087648792bc7a598cab1fd21af1d1d066903cd6619758b1f0930dabf6%26%3D%26width%3D953%26height%3D646&amp;sa=D&amp;source=editors&amp;ust=1765035744115378&amp;usg=AOvVaw3LZNRBxeasHP67KJObUtb6">dead</a></span><span>) </span><span class="c0">settings:</span></p><p class="c1"><span class="c0">(all weights beside MDXv3 set to 0, BigShifts_MDX set to min. of 1, and demucs overlap 0 [at least for vocal_instru_only)</span></p><p class="c1"><span class="c0">You can use a higher &quot;overlap_MDXv3&quot; value than in the screenshot to get slightly better results.</span></p><p class="c1"><span class="c0">(and also, as it&#39;s only a workaround, it will still process the audio with other models, but they will not be used for final result as their weights = 0)</span></p><p class="c1"><span class="c0">(MDX23C InstVoc-HQ = MDXv3 here)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can also use the defaults settings &amp; weights, as it scores a bit higher SDR than InstVoc alone &rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Be aware that </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/2.0/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744117335&amp;usg=AOvVaw1m9-yQf9jTn_0WT6JdXO7F">2.0</a></span><span class="c0">&nbsp;version wasn&rsquo;t updated with:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">!python -m pip install ort-nightly-gpu --index-url=https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or in case of credential issues, you can try out this instead:</span></p><p class="c1"><span class="c0">!python -m pip -q install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Hence, it&rsquo;s slow (so use 2.1-2.3 instead as they work as intended or add the line at the end of the first cell yourself)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Explanations on features added in </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.2/MVSep-MDX23-Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744118933&amp;usg=AOvVaw23wiEYdDH798IHzhsElVIe">2.2 Colab</a></span><span class="c20">&nbsp;(2.2 might have more residues vs 2.1) by jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">What are BigShifts?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s based on Demucs&#39; shift trick, but for Demucs it is limited to 0.5 second shifting max (with a randomly chosen value).</span></p><p class="c1"><span class="c0">Each BigShifts here shifts the audio by 1 second, no more random shfiting.</span></p><p class="c1"><span class="c0">f.e. bigshifts=2, it will do 1 pass with 0 shifting, and a second pass with 1 second shifting, then merge the results</span></p><p class="c1"><span class="c0">bigshifts=3 means 1 pass with 0 shifting + 1 pass with 1 sec shift + 1 pass with 2 sec shift, etc...</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Overlap is doing almost the same thing but at audio chunks level, instead of full audio, and the way overlap is implemented (in MVSEP-MDX23), f.e. with overlap=0.99, first audio chunk will have 1 pass, 2nd audio chunk will have 2 passes, etc... until 99th audio chunk and following ones will have 99 passes. With BigShifts, the whole audio is processed with the same number of passes.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So BigShifts shifts the audio forward one second each time.</span></p><p class="c1"><span class="c0">Overlap computing is different between MDXv2 models and the other ones in the fork:</span></p><p class="c1"><span class="c0">For MDXv2 models (like VOC-FT), it uses the new code from UVR and goes from 0 to 0.99.</span></p><p class="c1"><span>For MDXv3 (InstVoc) &amp; VitLarge models [introduced in v2.3] it uses code from ZFTurbo (based on MDXv3 code from KUIELab, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2306.09382&amp;sa=D&amp;source=editors&amp;ust=1765035744121873&amp;usg=AOvVaw37Wk0nTGBvrBDZfn-AMzPk">https://arxiv.org/abs/2306.09382</a></span><span>)</span><span class="c0">&nbsp;and it goes from 1 to whatever.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>I&#39;m using low overlap values in the fork because it&#39;s kinda redundant with the BigShifts experimental feature I&#39;ve added and which is based on Demucs&#39; &quot;shift trick&quot; (described here </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/1911.13254.pdf&amp;sa=D&amp;source=editors&amp;ust=1765035744122480&amp;usg=AOvVaw1jPxQC9VCdwU_eBQp_NMdv">https://arxiv.org/pdf/1911.13254.pdf</a></span><span>,</span><span class="c0">&nbsp;chapter 4.4). But instead of doing shifts between 0 and 0.5 sec like Demucs by adding silence before input, BigShifts are much larger (and related &nbsp;to input length). Having larger time shifting gives more amplitude in possible results.</span></p><p class="c1"><span class="c0">Instead of adding silence before input to shift it, which would be a waste of time &amp; resources as BigShifts can be above 30s or 1 min of shifting, instead, it changes the shifted part position in audio input (like move the 1st minutes of audio at the end of the file before processing and restores it after processing).</span></p><p class="c1"><span class="c0">Then like Demucs original trick all shifted &amp; restored results are merged together and averaged.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">From my tests, it can influence results from -2 SDR to +2 SDR for each shifted results, depending on input and BigShifts value. It&#39;s not linear!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Using BigShifts=1 (disabled) and high overlap value probably gives more stable results, in the other end, but maybe not always as high and/or fast as what BigShifts can give.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Weights have been indeed evaluated on MVSep&#39;s multisong dataset. I haven&#39;t tried every possible settings, but default values should be not far away from optimal settings, if not optimal [already]. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Wasn&#39;t the BigShifts trick in the MDX23 Colab relying on a slowed-down and sped-up separation ensembling?</span></p><p class="c1"><span class="c0">I think increasing the parameter too much rather tends to increase bleeding.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: It&#39;s unrelated to bigshifts, but it was doing that for MDX2 models with a cutoff around 16-17khz (to get fullband results from them) but since it&#39;s using only fullband models, I&#39;ve removed that part (in v2.2 iirc)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There are a few other &quot;tricks&quot; used in the fork:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The phase inversion denoise trick (was already in original code from ZFTurbo, also used in UVR):</span></p><p class="c1"><span class="c0">Some archs (MDXv2 mostly, so VOC-FT here) are adding noise to output signals. So to attenuate it, we process the input 2 times, including one time with phase polarity inverted before processing, and restored after processing. So, only the model noise is phase cancelled when the 2 passes are mixed together. (It doesn&#39;t cancel 100%, but it&#39;s attenuated). This is also applied to Demucs processing (since original code).</span></p><p class="c1"><span class="c0">MDXv3 &amp; VitLarge don&#39;t seem to add noise (or at insignificant volume) so this trick is not used with these models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Segment_size (dim_t) original model value is doubled since v2.3 of the fork.</span></p><p class="c1"><span>Some benchmarks done by Bas Curtiz showed that it gives a little bit better results (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1158057984727973948&amp;sa=D&amp;source=editors&amp;ust=1765035744127303&amp;usg=AOvVaw0hutfw2S04kgBcMSzhPT2S">here</a></span><span>&nbsp;with VOC-FT, there&#39;s the same benchmark with InstVocHQ model </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1156687062439821422&amp;sa=D&amp;source=editors&amp;ust=1765035744127570&amp;usg=AOvVaw0L1Kuj1SLXkeLu6RYicSJP">here</a></span><span class="c0">).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Multiband ensembling:</span></p><p class="c1"><span class="c0">I&#39;m using a 2-band ensemble, with different ensemble in frequencies below 10 kHz and above. This is a workaround to get fullband final results even when not fullband models are part of the ensemble (like VOC-FT). Without it, the instrumental stem, obtained by vocals phase inversion against the input audio would have small permanent vocals bleeding above VOC-FT&#39;s cutoff, as phase cancellation would be biased there.</span></p><p class="c1"><span class="c0">It was a really more essential feature in previous versions when most of the models were not fullband.</span></p><p class="c1"><span class="c0">VitLarge is not used too in high freq band, but it&#39;s a more personal taste (so in the end there&#39;s only InstVoc model results above the crossover region)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>In fact, alternatively you could separate your instrumental with Demucs single models used by the Colab (demucs_ft, demucs 6s, demucs, mmi) and use SCNet XL and BS-Roformer models from </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">here</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">As, along with demucs_ft, they have the best overall SDR for 4 stems separation (actually MDX23C model1 can give interesting results too compared to demucs_ft).</span></p><p class="c1"><span class="c0">And then perform manual weighted ensemble in DAW by setting volume of the stems manually to your liking after importing and aligning lossless stems. </span></p><p class="c1"><span class="c0">Because rarely ensembling of more than 4 stems gives good results, IG you could get rid of some demucs models with lower SDR for it (I think the mmi has the lowest SDR, and then 6s).</span></p><p class="c1"><span class="c0">If it&#39;s too much of a hassle, you could change the volume of the stems from a specific model by the same volume.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Guide how to use Colab v 2.5</span></p><p class="c1"><span class="c0">(reworked Infisrael text)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0. If you plan to use your GDrive for input files, go there now, and create folder called &ldquo;input&rdquo; and upload your files there. Create also output folder (not sure if the Colab creates both already). That way you may decrease the time till timeout when the Colab is initialized (esp. for people with slower connection).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Now open the Colab</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1. Click the &ldquo;play&rdquo; button on the Installation cell and wait until it&#39;s finished (should show a green checkmark on the side)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2. Click the &ldquo;play&rdquo; button on the GDrive cell.</span></p><p class="c1"><span class="c0">It will ask you for permission for this notebook to access your Google Drive files, you can either accept or deny it (it is recommended to accept it if you want to use Google Drive as i/o for your files).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">After you&#39;ve done installing it, go to the Separation section below.</span></p><p class="c1"><span class="c0">Default settings are already balanced in terms of SDR, and too resource-intensive.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3. Click on the play button to start the Separation, **make sure** you uploaded the audio file in the `folder_path`.</span></p><p class="c1"><span class="c0">After it&#39;s done, it will output the stems in the `output_folder`.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also note, &quot;`filename_instrum`&quot; is the inversion of the separated vocals stems against the original audio.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;`filename_instrum2`&quot; when &ldquo;Separation_mode:&rdquo; is set to 4 stems (slower) is the sum of the Drums + Bass + Other stems that are obtained by processing &quot;`instrum`&quot; with multiple Demucs models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So &quot;`instrum`&quot; is the most untouched and &quot;`instrum2`&quot; can have fewer vocals residues or sound a bit muddier.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Experimenting on settings you can set BigShifts to 5 or 7, although it may not give a noticeable difference vs default 3, while increasing separation time severely, but some people use 20 or even 30.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c42 c12 c15 c33">Comparisons of MDX23 (probably v. 2.0) vs single demucs_ft model by A5</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c40 c36 c33 c30">The Beatles - She Loves You - 2009 Remaster (24-bit - 44.1kHz)</span></p><p class="c1"><span class="c0">So I tried out the MDX23 Colab with She Loves You, which is easily the most ratty sounding of all the Beatles recordings, as it is pure mono and the current master was derived from a clean vinyl copy of the single circa 1980. So if it can handle that, it can handle anything. And well, MDX23 is very nice, certainly on par with htdemucs_ft, and maybe even better. I&#39;m surprised. You can hear the air around the drums. Something that is relatively rare with demucs. And the bass is solid, some bleed but the tone and the air, the plucking etc is all there. Plus, the vocals are nicer, less drift into the &#39;other&#39; stem.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c40 c36 c33 c30">John Lennon - Now and Then (Demo) - Source unknown (16-bit - 44.1kHz)</span></p><p class="c1"><span class="c0">OK, another test, this time on a John Lennon demo, Now and Then. The vocals are solid, MDX23 at 0.95 overlap is catching vocals that were previously in htdemucs_ft being lost to the piano. So, yeah, it&#39;s pretty good. MDX23 is now my favored model. In fact, upon listening to the vocals, it&#39;s picking up, from a demo, from a poor recording, on a compact cassette, lip smacks, breathing and other little non-singing quirks. It&#39;s like literally going back and having John record in multitrack.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c40 c36 c33 c30">Queen - Innuendo - CD Edition TOCP-6480 (16-bit 44.1kHz)</span></p><p class="c1"><span class="c0">Every single model fell down with Freddie Mercury&#39;s vocals, not anymore. (...) I&#39;ve heard true vocal stems from his vocals and the MDX23 separation sounds essentially like that. We&#39;re now approaching the &#39;transparent&#39; era of audio extraction.</span></p><p class="c1"><span class="c0">NOTE: [voc_ft not tested] for Innuendo, will be tested by 07/07/2023</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Colab instruction by Infisrael for old versions</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Install it, click on the play button and wait until it&#39;s finished (should show a green checkmark in the side).</span></p><p class="c1"><span class="c0">It will ask you for permission for this notebook to access your Google Drive files, you can either accept or deny it (it is recommended to accept it if you want to use Google Drive as i/o for your files).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">After you&#39;ve done installing it, go to the configuration, it&#39;s below the &#39;Separation&#39; tab.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/qD9jsYG.png&amp;sa=D&amp;source=editors&amp;ust=1765035744138702&amp;usg=AOvVaw07N2EMjzkCQgyQqOqvLQGi">https://i.imgur.com/qD9jsYG.png</a></span><span>&nbsp;(dead)</span></p><p class="c1"><span class="c0">(Recommended settings)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Input &quot;`overlap_large`&quot; &amp; &quot;`overlap_slow`&quot; with what you desire, at the highest (1.0), it will process slower but will give you a better quality. The default values for large are (0.6), and for small (0.5) [with 0.8 still being balanced in terms of speed and quality].</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Input &quot;`folder_path`&quot; with the folder destination where you have uploaded the audio file you&#39;d like to separate </span></p><p class="c1"><span class="c0">Input &quot;`output_folder`&quot; with the folder you&#39;d like the stems to be separated</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Change your desired path after `/content/drive/MyDrive/`, so for example: </span></p><p class="c1"><span class="c0">&gt; `folder_path: /content/drive/MyDrive/input`</span></p><p class="c1"><span class="c0">&gt; `output_folder: /content/drive/MyDrive/output`</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can also make a use of &quot;`chunk_size`&quot; and put it in a higher value &nbsp;by a little, but if you experience memory issues, lower it, default value for it is 500000.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Afterwards, click on the play button to start the separation, **make sure** you uploaded the audio file in the `folder_path` you provided.</span></p><p class="c1"><span class="c0">After it&#39;s done, it will output the stems in the `output_folder`.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also note, &quot;`filename_instrum`&quot; is the inversion of the separated vocals stems against the original audio.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;`filename_instrum2`&quot; is the sum of the Drums + Bass + Other stems that are obtained by processing &quot;`instrum`&quot; with multiple Demucs models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So &quot;`instrum`&quot; is the most untouched and &quot;`instrum2`&quot; can have fewer vocals residues.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Installing the Colab locally</span></p><p class="c1"><span class="c0">NVIDIA 12GB VRAM GPU recommended</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">&quot;I think it&#39;s possible to use Colab notebook .ipynb files locally with anaconda and jupyter, but I&#39;ve never tried. [Or:]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can git clone the repo, install requirements and use the inference.py script, but the command line can be really long to type manually (on Colab it&#39;s managed with the GUI):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">python inference.py \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --input_audio &quot;{file_path}&quot; \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --large_gpu \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --BSRoformer_model {BSRoformer_model} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --weight_BSRoformer {weight_BSRoformer} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --weight_Kim_MelRoformer {weight_Kim_MelRoformer} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --weight_InstVoc {weight_InstVoc} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --weight_InstHQ4 {weight_InstHQ4} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --weight_VOCFT {weight_VOCFT} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --weight_VitLarge {weight_VitLarge} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --overlap_demucs {overlap_demucs} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --overlap_VOCFT {overlap_VOCFT} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --overlap_InstHQ4 {overlap_InstHQ4} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --output_format {output_format} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --BigShifts {BigShifts} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --output_folder &quot;{output_folder}&quot; \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; --input_gain {input_gain} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; {filter_vocals} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; {restore_gain} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; {vocals_only} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; {use_VitLarge_} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; {use_VOCFT_} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; {use_InstHQ4_} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; {use_InstVoc_} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; {use_BSRoformer_} \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; {use_Kim_MelRoformer_}</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">Q: How do you use the example {useVitLarge}</span></p><p class="c1"><span class="c0">like the other stuff ik how to use</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: These last arguments are boolean based, there are generated before the command line and depending on the option selected in the GUI with:</span></p><p class="c1"><span class="c0">use_InstVoc_ = &#39;--use_InstVoc&#39; #forced use</span></p><p class="c1"><span class="c0">use_BSRoformer_ = &nbsp;&#39;--use_BSRoformer&#39; #forced use</span></p><p class="c1"><span class="c0">use_Kim_MelRoformer_ = &nbsp;&#39;--use_Kim_MelRoformer&#39; #forced use</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">use_VOCFT_ = &#39;--use_VOCFT&#39; if use_VOCFT is True else &#39;&#39;</span></p><p class="c1"><span class="c0">use_VitLarge_ = &#39;--use_VitLarge&#39; if use_VitLarge is True else &#39;&#39;</span></p><p class="c1"><span class="c0">use_InstHQ4_ = &#39;--use_InstHQ4&#39; if use_InstHQ4 is True else &#39;&#39;</span></p><p class="c1"><span class="c0">restore_gain = &#39;--restore_gain&#39; if restore_gain_after_separation is True else &#39;&#39;</span></p><p class="c1"><span class="c0">vocals_only = &#39;--vocals_only&#39; if Separation_mode == &#39;Vocals/Instrumental&#39; else &#39;&#39;</span></p><p class="c1"><span class="c0">filter_vocals = &#39;--filter_vocals&#39; if filter_vocals_below_50hz is True else &#39;&#39; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: So you don&#39;t need to use them?</span></p><p class="c1"><span class="c0">Only using the ones with the two -- before right</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: For example, if you want to activate vocals filtering below 50hz, you add &nbsp;&quot;--filter_vocals&quot; to the command line</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: How do you do this</span></p><p class="c1"><span>A: (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1CI6dwZ7tPUvbolckwjicTl6s1tbfAly-/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744148061&amp;usg=AOvVaw10A3Oo1vzeHZVmUfNMRxBz">click</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">Q: oh yeah I just have to change the default number then right</span></p><p class="c1"><span>It works </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1272994209732755500&amp;sa=D&amp;source=editors&amp;ust=1765035744148448&amp;usg=AOvVaw0bk6kvXti19ne-doHHGpfv">#&#8288;general&#8288;</a></span></p><p class="c1"><span class="c0">A: If you have multiple GPUs and the CUDA one is not labelled device &quot;0&quot;, maybe that can be the cause too, it&#39;s hardcoded for Colab, but you can change it in first lines of inference.py file gpu_use = &quot;0&quot; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If your GPU is not detected in Anaconda, use Python (can be 3.12). If it&#39;s the same:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pytorch.org/get-started/locally/%23start-locally&amp;sa=D&amp;source=editors&amp;ust=1765035744149283&amp;usg=AOvVaw3BfsQO2FPH4o8uw-SKaHXF">https://pytorch.org/get-started/locally/#start-locally</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Where it says &quot;run this command&quot; I basically uninstalled the modules it had in there</span></p><p class="c1"><span class="c0">so I did pip uninstall torch torchvision torchaudio</span></p><p class="c1"><span class="c0">then ran that command to install it</span></p><p class="c1"><span class="c0">and it fucking fixed it (knock)<br><br>1.0 original code used kim vocal 1 (later 2), kim inst and (at least for 4 stems) Demucs models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.7kniy2i3s0qc"><span class="c42 c15 c22 c46 c30">KaraFan by Captain FLAM</span></h2><p class="c2"><span class="c0">(2 stems)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Eddycrack864/KaraFan/blob/master/KaraFan_Improved_Version.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744150407&amp;usg=AOvVaw1qgYHCIW9rMNT1Q-OqjXYv">Colab</a></span><span>&nbsp;w/ more models (AI Hub fork, also fixed)</span><span>, fixed org. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1HwCKsVMGotBvkHe1bfR8Q5POZsrRx-iu&amp;sa=D&amp;source=editors&amp;ust=1765035744150660&amp;usg=AOvVaw3-6RZ92W_gMJ14ZUJtJlrs">Colab</a></span><span>, org. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/Captain-FLAM/KaraFan/blob/master/KaraFan.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744150801&amp;usg=AOvVaw0FDA4FwXQo3EFNQFnJWani">Colab</a></span><span>&nbsp;(slow), </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Captain-FLAM/KaraFan/releases&amp;sa=D&amp;source=editors&amp;ust=1765035744150904&amp;usg=AOvVaw0Wvm756gk9K0yrJ5PfonHp">GUI</a></span><span>, GH </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Captain-FLAM/KaraFan/wiki/&amp;sa=D&amp;source=editors&amp;ust=1765035744151012&amp;usg=AOvVaw0e72uq4kgzT3ysb7bl0Rim">documentation</a></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DuWJvMzu5EyA&amp;sa=D&amp;source=editors&amp;ust=1765035744151132&amp;usg=AOvVaw13uaR6Eu7Z6mDPx5IKIwCn">How</a></span><span>&nbsp;to install it locally (advanced), alt. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DBM5bF_bcYoE&amp;sa=D&amp;source=editors&amp;ust=1765035744151286&amp;usg=AOvVaw01luWzAqAGefmW_0eiPyYo">tutorial</a></span><span class="c0">,</span></p><p class="c2"><span>or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Captain-FLAM/KaraFan/wiki/%25F0%259F%259A%2580-Install-PC-users&amp;sa=D&amp;source=editors&amp;ust=1765035744151443&amp;usg=AOvVaw1jcDPrJHEg3N6iHeSyhYc-">easy</a></span><span class="c0">&nbsp;instruction</span></p><p class="c2"><span class="c0">Should work on Mac with Silicon or AMD GPU (although not for everyone)</span></p><p class="c2"><span class="c0">&amp; Linux with Nvidia or AMD GPU</span></p><p class="c2"><span class="c0">&amp; Windows probably with at least Nvidia GPU, or with CPU (v. slow)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For Colab users - create &ldquo;Music&rdquo; in the main GDrive directory and upload your files for separation there (the code won&rsquo;t create the folder on the first launch).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sometimes you&rsquo;ll encounter soundfile errors during separation. Just retry, and it will work</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">KaraFan (don&rsquo;t confuse with KaraFun) is a direct derivative of ZFTurbo&rsquo;s MDX23 code forked by jarredou, but with further tweaks and tricks in order to get the best quality of instrumentals and vocals sonically, but without overfocusing on SDR only, but the overall sound. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Its aim is to not increase vocal residues without making instrumentals too muddy like e.g. sometimes HQ_3 model does, but without having so many vocal residues as MDX23C fullband model (but it depends on chosen preset). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Since v. 4.4 and 5.x you have five presets to test out. </span></p><p class="c2"><span class="c0">Presets 3 and 4 are more aggressive in canceling vocal residues (P4 can be good for vocals). </span></p><p class="c2"><span class="c0">Preset 5 (takes 12 minutes+ on the slowest setting for 3:25 track on T4) has more clarity of instrumentals over presets 3 and 4, but also more vocal residues (although less than P1 and P2 (takes 8 minutes for 3:24 track on the slowest setting).</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span>On 23.11.24 &ldquo;Preset 5 was corrected to be less aggressive as possible&rdquo;. All the below Preset 5 descriptions refer to the old P5. The original preset 5 is </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/dJqnFnX.png&amp;sa=D&amp;source=editors&amp;ust=1765035744154529&amp;usg=AOvVaw06u4C8lVxTu8-J59KOXmXD">here</a></span><span class="c0">, and is less muddy, but has more vocal residues (at least the original preset contains more models and is slower). </span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Speed and chunks affect quality. The slower, the muddier, but also slightly less vocal residues, although they&rsquo;ll be still there (just slightly quieter). I&rsquo;d recommend the &ldquo;fastest&rdquo; Speed setting and 400K chunks for the current P5 (tested on 4:07 song, may not work for longer tracks). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">- If you replace Inst Voc HQ1 model by HQ2 using AI Hub fork in current P5, the instrumental will be muddier.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span>- To preserve instruments which are counted as vocals by other MDXv2 models, use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/coxj6Zs.png&amp;sa=D&amp;source=editors&amp;ust=1765035744155736&amp;usg=AOvVaw2Y-yA_SlLKm3uCLKyXrIY-">these</a></span><span class="c0">&nbsp;preset&rsquo;s 5 modified settings - they have more clarity than P5 and preserve hi-hats better. But to preserve the same processing time as in P5, but setting &ldquo;Speed&rdquo; slider to medium, in this case will result in more constant vocal residues vs P5 with the slowest setting (too much at times, but it might serve well for specific song fragments). It will take 12 minutes+ for 3:24 track on medium. Debug and God mode on the screenshot are unrelated and optional.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span>- To fix issues with saxophone in P5 use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/GeMeBJx.png&amp;sa=D&amp;source=editors&amp;ust=1765035744156830&amp;usg=AOvVaw2RX4TCuM4NIME_EiV21JKB">these</a></span><span class="c0">&nbsp;settings. They even have more clarity than the one above, but also more hearable vocal residues. It helps to preserve instruments better than the setting from the above. It can be better than P2 - less hearable consistent vocal residues, but in similar amount, while on other artists sax preset even gives more vocal residues than P2. Sax setting is worse in preserving piano than the setting above.</span></p><p class="c2"><span class="c0">- Using the slowest setting here in sax fix preset will result in disconnection of runtime with free T4 after 28 minutes of processing, but it should succeed anyway (result files might be uploaded on GDrive after some time anyway). </span></p><p class="c2"><span class="c0">Vs medium, the slowest setting gives more muffled sound, but not always less vocal residues. It can be heard the best in short parts with only vocals. 18 minutes for 4:07 track on Fast setting (God Mode and Debug Mode are disabled in KaraFan by default). </span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">After 3-4 ~18 minutes separations (in this case not made in batch, but with manually changed parameters in the middle), when you terminate and delete environment, you might be not able to connect with GPUs again as the limit will be reached unless you switch Colab account (mount the same GDrive account as Colab to avoid errors)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">- Preset 5 provides more muffled results than the two settings above, but with good balance of clarity and vocal residues. Sometimes this one has less vocal residues, sometimes 16.66 MDX23C model on MVSEP (or possibly a bit older HQ_1 model in UVR), it can even depend on a song fragment. &nbsp;Using newer MDX23C HQ 2 in P5 instead of MDX23C HQ doesn&rsquo;t seem to produce better results</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">After 5th separation (not in batch) you must start your next separation very fast because or you&rsquo;ll run out of Colab free limit when GUI is in idle state. In such case, switch Colab account, and use the same account to mount GDrive (or you might encounter error).</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Comparisons above made with normalization disabled and 32-bit float setting</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span>The code handles mono and 48kHz files too, 6:16 (preset 3) tracks, and possibly 9 minutes tracks too (but can&rsquo;t tell if with all presets). It stores models on GDrive, which takes 0,8-1,1GB (depending on how many models you&rsquo;ll use). One 4:07 song in 32-bit float with debug mode enabled (all intermediate files will be kept) will take 1,1GB on GDrive. Instrumentals will be stored in files marked as Final (in the end), Music Sub (can sound a bit cleaner at times, but with more residues), and Music Extract (from specific models).</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older 1.3 version Colab fork by Kubinka was deleted.</span></p><p class="c1"><span class="c0">Colab fork made by AI HUB server members also includes MDX23C Inst Voc HQ 2 and HQ_4 models, and contains slow separation fix from the &ldquo;fixed Colab&rdquo;. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">KaraFan used to have lots of versions which differ in these aspects with an aim to have the best result in the recent Colab/GUI version. E.g. v.3.1 used to have more vocal residues than in 1.3 version and even more than in HQ_3 model on its own, and it got partially fixed in 3.2 (if not entirely). But 1.3 irc, had some overlapped frequency issue with SRS disabled, which makes the instrumentals brighter, but it got fixed later. The current version at the time of writing this excerpt is 4.2, with pretty good opinions for v.4.1 shortly before.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Colab troubleshooting</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>- (no longer necessary in the fixed </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1HwCKsVMGotBvkHe1bfR8Q5POZsrRx-iu&amp;sa=D&amp;source=editors&amp;ust=1765035744163416&amp;usg=AOvVaw2ZOz0bzVG3GYPT8qxhDpnp">Colab</a></span><span class="c0">) If you suffer from very slow or unfinishable separations in the Colab using non-MDX23C models (e.g. stuck on voc_ft without any progress), use fixed Colab (the onnxruntime-gpu line added in the end of the first cell)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Contrary to every other Colab in this document, KaraFan uses a GUI which launches after executing inference cell. It triggers Google&rsquo;s timeout security checks frequently esp. in free Colab users, because Google behaves like the separation is not being executed where you do it in GUI, and it&rsquo;s generally against their policies to execute such code instead pasting commands to execute in Colab cells directly. The same way many RVC Colabs got blocked by Google, but this one is generally not directly for voice cloning, and is not very popular yet, so it wasn&rsquo;t targeted by Google yet.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Once you start separation, it can get you disconnected from runtime quickly, especially if you miss some multiple captcha prompts (in 2024 captchas stopped appearing at all, so the user inactivity during separation process seems to be no longer checked). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- After runtime disconnection error, output folder on e.g. GDrive can be still constantly populated with new files, while progress bar is not being refreshed after clicking close or even after closing your tab with Colab opened. At certain point it can interrupt the process, leaving you with not all output files. Be aware that final files always have &ldquo;Final&rdquo; in their names.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- It can consume free &quot;credits&quot; till you click Environment&gt;Terminate session. It happens even if you close the Colab tab. You can check &ldquo;This is the end&rdquo; option so the GUI will terminate the session after separation is done to not drain your free limit.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- (rather fixed) As for 4.2 version, session crashes for free Colab users can occur, due to running out of memory. You can try out shorter files.</span></p><p class="c1"><span class="c0">Currently, if you rename your output folder with separation, and retry separation, it will look for the old folder with separation to delete, and return the error, and running the GUI cell again may cause disappearing of GUI elements.</span></p><p class="c1"><span class="c0">it&#39;s a default behavior of Colab and IPython core : Sync of files the Colab sees is not real time</span></p><p class="c1"><span class="c0">Two possible solutions:</span></p><ul class="c9 lst-kix_qij6192l4p0g-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">wait until sync with Google Drive is done</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">restart &amp; run Colab</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Sometimes shutting down your environment in Environment options and starting over might do the trick if something doesn&#39;t work. E.g. (if it wasn&#39;t fixed), when you manipulate input files on GDrive when GUI is still opened, and you just finished separation, you might run into an error when you start separating another file with input folder content changed. </span></p><p class="c1"><span class="c0">In order to avoid it, you need to run the GUI cell again after you&#39;ve changed the input folder content (IRC it&#39;s &quot;Music&quot; folder by default). Maybe too low chunks (below 500k for too long tracks if something hasn&#39;t changed in the code). Also, check with some other input file you used before and worked before first.</span></p><p class="c1"><span class="c0">Also, be more specific about what doesn&#39;t work. Provide screenshot and/or paste the error.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You can be logged to a maximum of 10 Google accounts at the same time. You can&rsquo;t log out of any of these single accounts on PC in browser. The only way is to do it on your Android phone, but it might not fix the problem, as it will tell &ldquo;logged out&rdquo; on that account on PC, and logging into other one might not work and the limit will be still exceeded. At this situation you can only logged out from all accounts (but it will break accounts order, so any authorizations set to specific accounts in your bookmarked links will be messed up - e.g. those to Colab, GDrive, Gmail, etc. I mean: /u/0 and in Colab authuser= in links. Easier way to access to extra Google account will be to log into it from Incognito mode.</span></p><p class="c1"><span class="c0">If you possess lots of accounts and you don&rsquo;t log for some for 2 years, Google can delete it. To avoid it, create YT channel on it, and upload at least one video, and the account won&rsquo;t be deleted.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Tests of four presets of KF 4.4 vs MDX-UVR HQ_3 and MDX23C HQ (1648)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">(noise gate enabled a.k.a. &ldquo;Silent&rdquo; option)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Not really demanding case, so without modern vocal chain in the mix, but probably enough to present the general idea of how different presets sound here. So, more forgiving song to MDX23C model this time, and less aggressive models with more clarity.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Genre: (older rap) Title: (O.S.T.R. - Tabasko [2002])</span></p><p class="c1"><span class="c0">BEST Preset : 3</span></p><p class="c1"><span class="c0">Music : </span></p><p class="c1"><span class="c0">Versus P4, hi-hats are preserved better in P3. </span></p><p class="c1"><span class="c0">Snare in P3 is not so muffled like in P4. </span></p><p class="c1"><span class="c0">HQ_3 has even more muffled snares than in P4. </span></p><p class="c1"><span class="c0">P3 still had less vocal residues than MDX23C HQ 1648 model, although the whole P3 result was more muffled, but residues are smartly muffled too. </span></p><p class="c1"><span class="c0">MDX23C had like more faithfully sounding snares than P3, to the extent that they can be perceived brighter (but vocal residues, even on a more forgiving song like this, are more persistent in MDX23C than in P3). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes it depended on specific fragment where P4 and where P3 has more vocal residues in that specific case, so P3 turned out being pretty much balanced, although P4 had less consistent vocal residues, although still not so few like HQ_3, but it&#39;s not that much of a problem (HQ_3 is really muffled). If it was 4 stems, then I&#39;d describe P3/4 as having very good &quot;other&quot; stem but drums too as I mentioned.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">WORST Preset (in that case) : 1</span></p><p class="c1"><span class="c0">Music : Too much consistent vocal residues</span></p><p class="c1"><span class="c0">There&#39;s a similar situation in P2, but at least P2 has brighter snares than even MDX23C. </span></p><p class="c1"><span class="c0">In other songs, P1 can be better than P2, leaving less vocal residues in specific fragments for a specific artist, but noticeably more for others.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Preset 4 with setting slow (but not the slowest) takes 16 minutes for 5 minutes song on T4 in free Colab (performance of ~GTX 3050). For 3:30 track, it takes 13:30 for the slowest setting. In KF 5.1 with default chunks 500K and slowest setting, for 4:50 song and preset 2 it took &lt;10 minutes, preset 3, 12 minutes.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>VS preset 3, the one from the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/1162265179271200820/1173570485733302312/karafan.PNG&amp;sa=D&amp;source=editors&amp;ust=1765035744175306&amp;usg=AOvVaw1Td4upy2j8KOZxzApoYV8S">screenshot</a></span><span>&nbsp;(now added as preset 5) </span><span class="c0">is more noisy and has more vocal residues, mainly in quiet places or when there is no instrumental. Processing time for 6:16 track on medium setting is 22:19 minutes. But it definitely has more clarity over preset 3. And there is still less vocal residues than in Preset 1 and 2, which have more clarity, but tend to have too many vocal residues in some tracks. Hence, preset 5 is the most universal for now.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For future: &ldquo;To add or remove some models u need to edit the .csv file </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Eddycrack864/KaraFan/blob/master/Data/Models.csv&amp;sa=D&amp;source=editors&amp;ust=1765035744176373&amp;usg=AOvVaw0JwI4Pje5y5Lab8DTLOxUf">https://github.com/Eddycrack864/KaraFan/blob/master/Data/Models.csv</a></span></p><p class="c1"><span>with the model info (Only MDX23C or MDX-NET) u can found the model info on the model_data_new.json: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/model_data_new.json&amp;sa=D&amp;source=editors&amp;ust=1765035744176946&amp;usg=AOvVaw1tT7N3sW1ZMOVAd_NOoPeD">https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/model_data_new.json</a></span><span class="c0">&nbsp;u need to find the hash of the model. And.... that&#39;s it! (Not Eddie)</span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.f0orpif22rll"><span>Ripple/Capcut/SAMI-Bytedance/Volcengine/BS-RoFormer </span><span class="c42 c15 c36 c46 c30">(2-4 stem)</span></h2><p class="c2"><span class="c0">Output quality in Ripple is: 256kbps M4A (320kbps max) and lossless (introduced later). 50MB upload limit, 4 stems</span></p><p class="c2"><span class="c0">Min. iOS version: 14.1</span></p><p class="c2"><span class="c0">Ripple is only for US region (which you can change, more below)</span></p><p class="c2"><span class="c22">Ripple no longer separates stems </span><span class="c0">(there&#39;s an error &quot;couldn&#39;t complete processing please try again&quot;)</span></p><p class="c2"><span>Ripple for iOS: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://apps.apple.com/us/app/ripple-music-creation-tool/id6447522624&amp;sa=D&amp;source=editors&amp;ust=1765035744178728&amp;usg=AOvVaw3jNcvNKYZ_roGobls6yjKG">https://apps.apple.com/us/app/ripple-music-creation-tool/id6447522624</a></span></p><p class="c2"><span>Capcut for Android: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://play.google.com/store/apps/details?id%3Dcom.lemon.lvoverseas&amp;sa=D&amp;source=editors&amp;ust=1765035744179122&amp;usg=AOvVaw0CwES9h6CSevOGwqAK425o">https://play.google.com/store/apps/details?id=com.lemon.lvoverseas</a></span></p><p class="c2"><span class="c0">(separation only for Pro, Indian users sometimes via VPN)</span></p><p class="c2"><span class="c0">Capcut a.k.a. Jianying (2 stems) works also on Windows (only in Jianying Pro, separation option is available)</span></p><p class="c2"><span class="c0">Can be used instead of Ripple if you&#39;re on unsupported iOS below 14.1 or don&rsquo;t have iOS. To get Ripple you can also use a virtual machine remotely instead (instructions below). Ripple can also be run on your M1 Mac using app sideloading (instructions below). </span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Ripple = better quality than CapCut as of now (and fullband)</span></p><p class="c2"><span class="c0">with fixed the click/artifacts using cross-fade technique between the chunks.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Capcut = &ldquo;the results are really low quality but if you export the instrumental and invert it with the lossless track, you will get the vocals with the noise which is easy to remove with mdx voc ft for example, then you can invert the lossless processed vocals with the original and have it in better quality. </span></p><p class="c2"><span class="c0">The vocals are very clean from cap cut, almost no drum bleed&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ripple and Capcut uses SAMI-Bytadance arch (later known as BS-Roformer), but it&rsquo;s a different model with worse SDR than on the leaderboard. It was developed by Bytedance (owner of TikTok) for MDX23 competition, and holds the top of our MVSEP leaderboard. It was published on iOS and for the US region as &ldquo;Ripple - Music Creation Tool&rdquo; app. Furthermore, it&#39;s a multifunctional app for audio editing, which also contains a 4 stem separation model. Similar situation with Capcut (which is 2 stems only IRC). The model itself is not the same as for MDX23 competition (SAMI ByteDance v1.0), as they said, models for apps were trained on 128kbps mp3 files to avoid copyright issues, but it&rsquo;s the same arch, just scores a bit lower (even when exported losslessly for evaluation). SDR for Ripple is naturally better than for Capcut.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Seems like there is no other Pro variant for Capcut Android app, so you need to unlock regular version to Pro.</span></p><p class="c1"><span class="c0">At least the unlocked version on apklite.me have a link to the regular version, so it doesn&#39;t seem to be Pro app behind any regional block. But -</span></p><p class="c1"><span class="c0">&quot;Indian users - Use VPN for Pro&quot; as they say, so similar situation like we had on PC Capcut before. Can&#39;t guarantee that unlocked version on apklite.me is clean. I&#39;ve never downloaded anything from there.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Bleeding</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Bas Curtiz found out that decreasing volume of mixtures for Ripple by -3dB (sometimes -4dB) eliminates problems with vocal residues in instrumentals in Ripple. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1165647205600854118/Ripple_vs_-6db_example_2.mp4&amp;sa=D&amp;source=editors&amp;ust=1765035744184563&amp;usg=AOvVaw1Qh4qsU-Iig4vxtwVjAxgJ">Video</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">This is the most balanced value, which still doesn&#39;t take too many details out of the song due to volume attenuation.</span></p><p class="c1"><span class="c0">Other good values purely SDR-wise are -20dB&gt;-8dB&gt;-30dB&gt;-6dB&gt;-4dB&gt; /wo vol. decr. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The method might be potentially beneficial for other models, and probably work best for the loudest tracks with brickwalled waveforms.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The other stem is gathered from inversion to speed up the separation process. The consequence is bleeding in instrumentals.</span></p><p class="c1"><span class="c0">- If you suffer from bleeding in other stem of 4 stems Ripple, beside decreasing volume by e.g. 3/4dB also &ldquo;when u throw the &#39;other stem&#39; back into ripple 4 track split a second time, it works pretty well [to cancel the bleeding]&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The forte of the Ripple is currently vocals - the algo is very good at differentiating what is vocals and what is not, although they can sound &ldquo;filtered&rdquo; at times.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Currently, the best SDR for public model/AI, but it gives the best results for vocals in general. For instrumentals, it rather doesn&rsquo;t beat paid Dango.ai (and rather not KaraFan and HQ_3 or 1648/MDX23C fullband too).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s good for vocals, also for cleaning vocal inverts, and surprisingly good for e.g. Christmas songs, (it handled hip-hop, e.g. Drake pretty well). It&#39;s better for vocals than instrumentals due to residues in other stem - bass is very good, drums also decent, kicks even one if not the best out of all models, as they said some fine-tuning was applied to drums stem. Vocals can be used for inversion to get instrumentals, and it may sound clean, but rather not as good as what 2 stem option or 3 stem mixdown gives as output is lossy.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Capcut </span><span class="c0">(2 stems only)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.capcut.cn/&amp;sa=D&amp;source=editors&amp;ust=1765035744189748&amp;usg=AOvVaw1GfU7MQ4_2pHOkmZcALQyc">https://www.capcut.cn/</a></span></p><p class="c1"><span class="c0">It is a new Windows and Android app which contains the same arch as Ripple inst/vocal, but lower quality model, and without an option of exporting 4 stems.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It normalizes the input, so you cannot use Bas&rsquo; trick to decrease volume by -3dB to workaround the issue of bleeding like in Ripple (unless you trick out the CapCut, possibly by adding some loud sound in the song with decreased volume).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;At the moment the separation is only available in Chinese version of Windows app which is jianyingpro, download available at capcut.cn [probably here - it&rsquo;s where you&rsquo;re redirected after you click &ldquo;Alternate download link&rdquo; on the main page, where download might not work at all]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Some people cannot find the settings on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/875539590373572648/1163477679736102932/image.png?ex%3D653fb807%26is%3D652d4307%26hm%3D567a1806a464224601faa2e16b43ba2ff856d8a70355e3926d116869cefb1360&amp;sa=D&amp;source=editors&amp;ust=1765035744192146&amp;usg=AOvVaw3YokjW0RQCaJ-TxL9FH_8a">this</a></span><span>&nbsp;</span><span class="c0">screen in order to separate.</span></p><p class="c1"><span class="c0">Separation doesn&#39;t require sign up/login, but exporting does, and requires VIP, which is paid depending on whether you&rsquo;re from rich or poor country, then it&rsquo;s free.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- There&rsquo;s a workaround for people not able to split using Capcut for Windows in various regions. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Bas Curtiz&#39; new video on how to install and use Capcut for separation incl. exporting:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dppfyl91bJIw&amp;sa=D&amp;source=editors&amp;ust=1765035744193620&amp;usg=AOvVaw1iejw3Qj1tq3VHDJgWTJRF">https://www.youtube.com/watch?v=ppfyl91bJIw</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It&#39;s a bit of a hassle to set it up, but do realize:</span></p><p class="c1"><span class="c0">- This is the only way (besides Ripple on iOS) to run ByteDance&#39;s model (best based on SDR).</span></p><p class="c1"><span class="c0">- Only the Chinese version has these VIP features; now u will have it in English</span></p><p class="c1"><span class="c0">- Exporting is a paid feature (normally); now u get it for free</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The instructions displayed in the video are also in the YouTube description.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- mitmproxy </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1167458847963746364/mitmproxy_script.py&amp;sa=D&amp;source=editors&amp;ust=1765035744195113&amp;usg=AOvVaw1eVCI2FrlGQIjmLT5jBn-_">script</a></span><span>&nbsp;</span><span>allowing to save to FLAC instead of AAC (although it just reencodes from AAC 113kbps with 15.6kHz lowpass filter). It&rsquo;s a bit more than script. See the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DgEQFzj6-5pk&amp;sa=D&amp;source=editors&amp;ust=1765035744195474&amp;usg=AOvVaw1Xr_hdB2B-GgkHMQF2vyMZ">full</a></span><span class="c0">&nbsp;tutorial.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For some people using mitmproxy scripts for Capcut (but not everyone), they &ldquo;changed their security to reject all incoming packet which was run through mitmproxy. I saw the mitmproxy log said the certificate for TLS not allowed to connect to their site to get their API. And there are some errors on mitmproxy such as events.py or bla bla bla... and Capcut always warning unstable network, then processing stop to 60% without finish.&rdquo; ~hendry.setiadi</span></p><p class="c1"><span class="c0">&ldquo;At 60% it looks like the progress isn&#39;t going up, but give it idk, 1 min tops, and it splits fine.&rdquo; - Bas</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;in order to install pydub within mitmproxy, you additionally need to:</span></p><p class="c1"><span class="c0">open up CMD</span></p><p class="c1"><span class="c0">pip install mitmproxy</span></p><p class="c1"><span class="c0">pip install pydub&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- IntroC created a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/12m1qrRNpsTrCxfioG9xzcZUYTV0Gl8Ap&amp;sa=D&amp;source=editors&amp;ust=1765035744197154&amp;usg=AOvVaw2tfFi028ihaORPJ3iDQfrr">script</a></span><span>&nbsp;</span><span>for mitmproxy for Capcut allowing fullband output, by slowing down the track. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D-34Q5rJ68pI&amp;sa=D&amp;source=editors&amp;ust=1765035744197416&amp;usg=AOvVaw3QfJfhEXIBbJMv1_E8XaYD">Video</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older Capcut instruction:</span></p><p class="c1"><span>The </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1166823721831501834/Testing_CapCut_workaround.mp4&amp;sa=D&amp;source=editors&amp;ust=1765035744197757&amp;usg=AOvVaw0139-DheIParOjLEVIggOV">video</a></span><span>&nbsp;</span><span class="c0">demonstration of below:</span></p><p class="c1"><span class="c0">0. Go offline.</span></p><p class="c1"><span>1. Install the Chinese version from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.capcut.cn/&amp;sa=D&amp;source=editors&amp;ust=1765035744198050&amp;usg=AOvVaw0HbFsxZmikG2ZtqEf0Hprp">capcut.cn</a></span></p><p class="c1"><span>2. Use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://wetransfer.com/downloads/301dd839f2b7af2a0bcfdaf3188ff1a420231025163008/049ffb&amp;sa=D&amp;source=editors&amp;ust=1765035744198216&amp;usg=AOvVaw2febh4zDFTvLicrreZQ9tC">these</a></span><span>&nbsp;</span><span class="c0">files copied over your current Chinese installation in:</span></p><p class="c1"><span class="c0">C:\Users\(your account)\AppData\Local\JianyingPro </span></p><p class="c1"><span class="c0">Don&rsquo;t use English patch provided below (or the separation option will be gone)</span></p><p class="c1"><span class="c0">3. Now open CapCut, go online after closing welcome screen, happy converting!</span></p><p class="c1"><span class="c0">4. Before you close the app, go offline again (or the separation option will be gone later). </span></p><p class="c1"><span class="c0">! Before reopening the app, go offline again, open the app, close welcome screen, go online, separate, go offline, close. If you happen to missed that step, you need to start from the beginning of the instruction. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(no longer works after 4.6 to 4.7 update, as it freezes the app) The only thing that seems to enable vocal separation without requiring replacing everything, is to replace that </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1167169672580440195/SettingsSDK.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744199899&amp;usg=AOvVaw1NkaRz5Um73AEi9s1u0k5E">SettingsSDK</a></span><span>&nbsp;</span><span class="c0">folder contents inside User Data. It&#39;s probably the settings_json file inside responsible for that.</span></p><p class="c1"><span class="c0">FYI - the app doesn&rsquo;t separate files locally.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The quality of separation vs Capcut is not exactly the same as Ripple. Seeing by spectrograms, there is a bit more information in vocals in Capcut, while Ripple has a bit more information in spectrum in instrumentals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Separated vocal file is encrypted and located in C:\Users\yourusername\AppData\Local\JianyingPro\User Data\Cache\audioWave&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The unencrypted audio file in AAC format is located at \JianyingPro Drafts\yourprojectname\Resources\audioAlg (ends with download.aac)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;To get the full playable audio in mp3 format, a trick that you can do is drag and drop the download.aac file into Capcut and then go to export and select mp3. It will output the original file without randomisation or skipping parts&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(although it resulted in VIP option disappearing but Bas somehow managed to integrate it in his new video tutorial, and it started to work, English translation isn&#39;t the culprit of the problem, but if you use both language pack and SettingsSDK folder from above)</span></p><p class="c1"><span>You can replace the zh-Hans.po file with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/875539590373572648/1163902105006903347/zh-Hans.po&amp;sa=D&amp;source=editors&amp;ust=1765035744202693&amp;usg=AOvVaw17kh8--ML2GRBv30i3d5Bg">English one</a></span><span class="c0">&nbsp;to have English language on Chinese version of the app possessing separation feature in:</span></p><p class="c1"><span class="c0">jianyingpro/4.6.1.10576/Resources/po </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">While you can&rsquo;t use that language pack, you can always use Google Translate to transform Chinese into your own language on a screen of your smartphone.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://encrypted-tbn0.gstatic.com/images?q%3Dtbn:ANd9GcQwk_qynMHMwquSfQZFrrn30F355Ihta_GHQNo7vhnPUhfjj-kUiqSRBiLQbPlgmB5Gqro%26usqp%3DCAU&amp;sa=D&amp;source=editors&amp;ust=1765035744203689&amp;usg=AOvVaw1Iv824Gn3223xs17g3rHE_">https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQwk_qynMHMwquSfQZFrrn30F355Ihta_GHQNo7vhnPUhfjj-kUiqSRBiLQbPlgmB5Gqro&amp;usqp=CAU</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://support.google.com/translate/answer/6142483?hl%3Den%26co%3DGENIE.Platform%253DDesktop&amp;sa=D&amp;source=editors&amp;ust=1765035744204091&amp;usg=AOvVaw2J8rdGNxyi3S5TIHgW7n1I">https://support.google.com/translate/answer/6142483?hl=en&amp;co=GENIE.Platform%3DDesktop</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Trying out capcut, the quality seems the same as the Ripple app (low bitrate mp3 quality)</span></p><p class="c1"><span class="c0">at least the voice leftover bug is fixed, lol&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Random vocal pops from Ripple are fixed here.</span></p><p class="c1"><span class="c0">Also, it still has the same clicks every 25 seconds as before in Ripple.</span></p><p class="c1"><span class="c0">Capcut adds 1024 extra samples at the beginning, and 16 extra samples at the end of the file.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">How to change region to US </span></p><p class="c1"><span class="c18 c15">in order to make Ripple work on iOS</span></p><p class="c1"><span class="c0">in Apple App Store to make &quot;Ripple - Music Creation Tool&quot; (SAMI-Bytedance) work.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://support.apple.com/en-gb/HT201389&amp;sa=D&amp;source=editors&amp;ust=1765035744205822&amp;usg=AOvVaw0GRvKSkqwMWZ2AniVxPz9j">https://support.apple.com/en-gb/HT201389</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Bas&#39; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708595418400817162/1146727313963237406/Ripple_iOS_iPad_mini_2_-_demo.mp4&amp;sa=D&amp;source=editors&amp;ust=1765035744206068&amp;usg=AOvVaw3HDWc0BgfmaI30WtvJXZkP">guide</a></span><span class="c0">&nbsp;to change region to US for Ripple on iOS</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.bestrandoms.com/random-address-in-us&amp;sa=D&amp;source=editors&amp;ust=1765035744206362&amp;usg=AOvVaw2OCpp0KZBQ4KTzeU9hRuow">https://www.bestrandoms.com/random-address-in-us</a></span></p><p class="c1"><span class="c0">Or use this Walmart address in Texas, the number belongs to an airport.</span></p><p class="c1"><span class="c0">Do it in App Store (where you have the person-icon in top right).</span></p><p class="c1"><span class="c0">You don&#39;t have to fill credit cards details, when you are rejected,</span></p><p class="c1"><span class="c0">reboot, check region/country... and it can be set to the US already.</span></p><p class="c1"><span class="c0">Although, it can happen for some users that it won&#39;t let you download anything forcing your real country.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I got an error because the zip code was wrong (I did enter random numbers) and it got stuck even after changing it.</span></p><p class="c1"><span class="c0">So I started from the beginning, typed in all the correct info, and voil&agrave;&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If &#39;&#39;you have a store credit balance; you must spend your balance before you can change stores&#39;&#39;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It needs (an old?) a simcard to log your old account out if necessary</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.ntkyxgfg0tro"><span class="c21">Ripple on Windows or MacOS</span></h4><p class="c1"><span>- Another way to use </span><span class="c22">Ripple</span><span class="c0">&nbsp;without Apple device -</span></p><p class="c1"><span class="c18 c15">virtual machine</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">Sideloading of this mobile iOS app is possible on at least M1 Macs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Saucelabs</span></p><p class="c1"><span>Sign up at </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://saucelabs.com/sign-up&amp;sa=D&amp;source=editors&amp;ust=1765035744208984&amp;usg=AOvVaw1hDp5aYYrAqTk5c_R3Fn9k">https://saucelabs.com/sign-up</a></span></p><p class="c1"><span>Verify your email, upload this as the IPA: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://decrypt.day/app/id6447522624/dl/cllm55sbo01nfoj7yjfiyucaa&amp;sa=D&amp;source=editors&amp;ust=1765035744209313&amp;usg=AOvVaw1E7NK7Y7upXJLgajCXhmB8">https://decrypt.day/app/id6447522624/dl/cllm55sbo01nfoj7yjfiyucaa</a></span></p><p class="c1"><span class="c0">Rotating puzzle captcha for TikTok account can be tasking due to low framerate. Some people can do it after two tries, others will sooner run out of credits, or completely unable to do it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mobiledevice.cloud/&amp;sa=D&amp;source=editors&amp;ust=1765035744209809&amp;usg=AOvVaw3hseNwmOs4BGO6OrAqIaJT">https://mobiledevice.cloud/</a></span></p><p class="c1"><span class="c0">Mobile device cloud</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Scaleway</span></p><p class="c1"><span>&quot;if you&#39;re desperate you can rent an M1 Mac on scaleway and run the app through that for $0.11 an hour using this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/PlayCover/PlayCover&amp;sa=D&amp;source=editors&amp;ust=1765035744210302&amp;usg=AOvVaw3U9XLb_UunYKx4YYDPMde3">https://github.com/PlayCover/PlayCover</a></span><span>&rdquo;</span></p><p class="c1"><span class="c0">IPA file:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.dropbox.com/s/z766tfysix5gt04/com.ripple.ios.appstore_1.9.1_und3fined.ipa?dl%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035744210672&amp;usg=AOvVaw0n7x444EtUsjrlakbvYA3R">https://www.dropbox.com/s/z766tfysix5gt04/com.ripple.ios.appstore_1.9.1_und3fined.ipa?dl=0</a></span></p><p class="c1"><span class="c0">&quot;been working like a dream for me on an M1 Pro&hellip; I&#39;ve separated 20+ songs in the last hour&quot;</span></p><p class="c1"><span class="c0">More info:</span></p><p class="c1"><span>-</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1146136170342920302/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035744211220&amp;usg=AOvVaw2UJJm1-RikS9vqjvBt-xY3">https://cdn.discordapp.com/attachments/708579735583588366/1146136170342920302/image.png</a></span></p><p class="c1"><span class="c0">- &ldquo;keep in mind that the vm has to be up for 24 hours before you can remove it, so it&#39;ll be a couple bucks in total to use it&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Fixing chunking artefacts </span><span class="c0">(probably fixed)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Every 8 seconds there is an artifact of chunking in Ripple. Heal feature in Adobe Audition works really well for it:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DQqd8Wjqtx-8&amp;sa=D&amp;source=editors&amp;ust=1765035744212108&amp;usg=AOvVaw3Hzv8R8k7k3hRuUP8YPi-l">https://www.youtube.com/watch?v=Qqd8Wjqtx-8</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-The same explained on RX10 example and its Declick feature:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DpD3D7f3ungk&amp;sa=D&amp;source=editors&amp;ust=1765035744212501&amp;usg=AOvVaw3_tbpQaxtoCjgEw0fLwwJ1">https://www.youtube.com/watch?v=pD3D7f3ungk</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Volcengine </span><span class="c0">(a.k.a. The sami-api-bs-4track - 10.8696 SDR Vocals)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.volcengine.com/docs/6489/72011&amp;sa=D&amp;source=editors&amp;ust=1765035744213074&amp;usg=AOvVaw08jHkq9F5WDEjZLtWdMrvD">https://www.volcengine.com/docs/6489/72011</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ripple/SAMI Bytedance&#39;s API was found. If you&#39;re Chinese, you can go through it easier -</span></p><p class="c1"><span class="c0">you need to pass the Volcengine facial/document recognition, apparently only available to Chinese people</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>We already evaluated its </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/4750&amp;sa=D&amp;source=editors&amp;ust=1765035744213750&amp;usg=AOvVaw1TDUgnjwZZ-W8Rx2tVYZwZ">SDR</a></span><span class="c0">, and it even scored a bit better than Ripple itself.</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c0">&quot;API from volcengine only return 1 stem result from 1 request, and it offers vocal+inst only, other stems not provided. So making a quality checker result on vocal + instrument will cost 2x of its API charging.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Something good is that volcengine API offers 100 min free for new users&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">API is paid 0.2 CNY per minute.</span></p><p class="c1"><span class="c0">It takes around 30 seconds for one song.</span></p><p class="c1"><span class="c0">It was 1.272 USD for separating 1 stem out MVSEP&#39;s multisong dataset (100 tracks x 1 minute).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;My only thought is trying an iOS Emulator, but every single free one I&#39;ve tried isn&#39;t far-fetched where you can actually download apps, or import files that is&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So far, Ripple didn&#39;t beat voc_ft (although there might be cases when it&#39;s better) and Dango. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Samples we got months ago are very similar to those from the app, also *.models files have SAMI header and MSS in model files (which use their own encryption), although processing is probably fully reliable on external servers as the app doesn&#39;t work offline (also model files are suspiciously small - few megabytes, although it&#39;s specific for mobilenet models). It&#39;s probably not the final iteration of their model, as they allegedly told someone they were afraid that their model will leak, but better than the first iteration judging by SDR with even lossy input files.</span></p><p class="c1"><span class="c0">Later they told that it&rsquo;s different model than the one they previously evaluated, and that time it was trained with lossy 128kbps files due to some &ldquo;copyright issues&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;One thing you will notice is that in the Strings &amp; Other stem there is a good chunk of residue/bleed from the other stems, the drum/vocal/bass stems all have very little to no residue/bleed&quot; doesn&#39;t exist in all songs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s fully server-based, so they may be afraid of heavy traffic publishing Ripple worldwide, and it&#39;s not certain whether it will happen.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Thanks to Jorashii, Chris, Cyclcrclicly, anvuew and Bas, Sahlofolina.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Press information:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://twitter.com/AppAdsai/status/1675692821603549187/photo/1&amp;sa=D&amp;source=editors&amp;ust=1765035744218242&amp;usg=AOvVaw2MIzEp3Vyzb9A8o7gxaPzh">https://twitter.com/AppAdsai/status/1675692821603549187/photo/1</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://techcrunch.com/2023/06/30/tiktok-parent-bytedance-launches-music-creation-audio-editing-app/&amp;sa=D&amp;source=editors&amp;ust=1765035744218677&amp;usg=AOvVaw0QybB6AP9kkY2EZXv3DAnN">https://techcrunch.com/2023/06/30/tiktok-parent-bytedance-launches-music-creation-audio-editing-app/</a></span></p><p class="c1"><span class="c0">Site:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.ripple.club/&amp;sa=D&amp;source=editors&amp;ust=1765035744218901&amp;usg=AOvVaw2XTn9lOQOQ5JJII6P-ZFUe">https://www.ripple.club/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">BS-RoFormer </span></p><p class="c1"><span>Used architecture in Capcut/Ripple (now defunct). </span><span>Their paper was published and later reimplemented by lucidrains for training and inferencing:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lucidrains/BS-RoFormer&amp;sa=D&amp;source=editors&amp;ust=1765035744219449&amp;usg=AOvVaw1lT2FuFE_8pJVzUHA3tH5M">https://github.com/lucidrains/BS-RoFormer</a></span></p><p class="c1"><span>Later, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lucidrains/BS-RoFormer/blob/main/bs_roformer/mel_band_roformer.py&amp;sa=D&amp;source=editors&amp;ust=1765035744219639&amp;usg=AOvVaw1Fb6MEr0i8Qao0Oo7_kH8Q">Mel-Band RoFormer</a></span><span class="c0">&nbsp;based on band split was released, which is faster, but doesn&#39;t provide such high SDR as BS. Mel variant might require some revision of the code, and its paper might lack some features need to keep up SDR-wise with extremely slow BS original variant. On paper, it should be better than BS-Roformer, but for some reason, models trained with Mel have worse results than with BS-Roformer (so probably problem with reimplementation from paper). Kim reworked her config, so the results with Mel models improved, but still are a tad lower than BS-Roformer. ZFTurbo includes training and inference of Roformers in his repository on GitHub.</span></p><p class="c1"><span>For more information, check the </span><span class="c4"><a class="c3" href="#h.bg6u0y2kn4ui">training</a></span><span class="c0">&nbsp;section.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">About ByteDance </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Winners of MDX23 competition. They said at the beginning, that it utilizes novel arch (so no weighting/ensembling of existing models). In times of v.0.1 seemingly the best vocals, not so good instrumentals, as it was once said by someone who heard samples, but they came a long way lately. It&#39;s all about their politics. It&#39;s a Chinese company responsible for TikTok, famous for d**k moves outside China - manipulating their algorithms - encourage of stupidity outside China, and greedy, wellness-centered attitudes for users in China (the app is currently banned in China), manipulating their algorithms to promote only black-white relationships in western countries, spying on users copying their clipboard, spying even on journalists to find their sources of information about the company, unauthorized remote access to TikTok user data from China, and also, a subject to ban in US and other countries for bad influence on children, data infringement by storing non-China users data directly on their servers which is against the law of many countries (there were some actions taken on it later). </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://twitter.com/d1rtydan/status/1277081198624337920?ref_src%3Dtwsrc%255Etfw%257Ctwcamp%255Etweetembed%257Ctwterm%255E1278204068175818752%257Ctwgr%255E%26ref_url%3Dhttps%253A%252F%252Fwww.wirtualnemedia.pl%252Fartykul%252Fhakerzy-anonymous-usuncie-tiktoka-to-aplikacja-do-szpiegowania-internautow-dlaczego-tiktok-jak-zainstalowac-jak-korzystac-z-aplikacji&amp;sa=D&amp;source=editors&amp;ust=1765035744223102&amp;usg=AOvVaw3Z3wMR7de_xs7VTOzfxzuh">Decompiling TikTok analysis</a></span><span class="c0">&nbsp;(tons of spying improper behavior of the app). Currently, Bytedance is only around 40% owned by founders, Chinese investors, and their employees and the rest (60%) state global investors (incl. lots of American) and is pushed to sale more stakes to US risking US ban on the app.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">They said, the CEO, told them to hold this ByteDance arch for two years for themselves. Initially they had plans to release it in some kind of app, firstly at the end of June, later something was planned at the end of year, later they said something about two years (maybe more about open sourcing, but we can&#39;t have our hopes high). Previously, they said the case of open sourcing/releasing was stuck in their legal department. Later they told they used MUSDBHQ+500 songs for their dataset. These 500 songs could have been obtained illegally for training (although everyone does it), but they might be extremely cautious about it (or it&#39;s just an excuse). Eventually, they released Ripple and Capcut. Then they released the paper for the Bs/Mel archs, and it was implemented and coded by Lucidrains, so later could be used for training.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Later, they seemingly spread information among users privately, that despite the similarities in SDR, the 18.75 score is a result of a trolling, someone other than ByteDance. Some people favoring ByteDance were rumored for disruptive, trolling behavior on our server too, harassing other users, or just being unkind to others etc. Besides, the same person responsible, was also the most informed about ByteDance next moves, and was also changing nicknames or accounts frequently. Also possessed great ML knowledge. Many coincidences. In the end, the same user, zmis (if you see the details of the account above), was behind a lot of newly created, accounts, which were banned on our server. </span></p><p class="c1"><span class="c0">The same day or in very similar period, a new account was created, conducting the same behavior, when previous was banned.</span></p><p class="c1"><span class="c0">The main core of their activities, was spreading misinformation about SDR metrics, telling that is the most important thing in the world, because their own arch is good at it, hence the narration.</span></p><p class="c1"><span class="c0">So don&#39;t bother, and do your good job not feeding troll from other company. They don&#39;t like competition, doing their own moves behind backdrops and become better.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&rsquo;s not impossible to fake SDR results in the MVSEP leaderboard. For current public archs, you&rsquo;d need to feed your dataset both by the songs in the evaluation dataset, keeping your regular big dataset in place, so you simply lose evaluation factor of this leaderboard, or you can simply mix your result stems with original stems. &ldquo;SDR focuses more on lower frequencies, it can easily be fooled into giving a higher score if the lower frequencies are louder, Bas tested this theory and confirmed it&rdquo;. you can boost the bass, and it will score +1 or +2 sdr higher or something, that&#39;s why It&#39;s not always reliable&rdquo; - becruily<br><br>Those results, which are not faked, are at least those, which were uploaded by various users evaluating the same public, available for offline use models, but usually uploaded with various parameters which affects SDR (so usually the better parameters, the higher SDR, but not always), remain consistent among various users evaluations with similar parameters and inference code, so scalability is correct and preserved, thus the results weren&rsquo;t faked, and can be reproduced with similar SDR. For the other scores from unpublic inferences/models/methods, we simply trust ZFTurbo and rather viperx too, as they&rsquo;re/were our trusted users for years. Also, the leaderboard in the current multisong dataset tends to give better SDR to the results with more residues on different occasions before, so the chart is simply not fully reliable for that, but rather not manipulated in its core either. It&rsquo;s more a nature of SDR measurement and/or used dataset. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">ViperX trained the first community BS-Roformer model similar to SAMI v1.0 model, although 2 stems (and lower scoring Mel at the time). His BS model sounds similar to Ripple (although it&#39;s only 2 stem, while 4 stem Ripple variant scores a bit higher than the 2 stem variant, but still lower than ViperX and v1.0). Then there were a lot of community trained models like private one by ZFTurbo, and fine-tunes by various users (Kim, Unwa, Bas, ZFTurbo)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Bas tried to train a model purely on multisong dataset only, but failed to surpass the SDR score of a 1.1 Bytedance&rsquo;s model anyway. v1.1 has new arch enhancements to the arch, and will be presented on ISMIR2024 (white paper is already out; link in the </span><span class="c4"><a class="c3" href="#h.9i8359eysaoe">Training </a></span><span class="c0">section).</span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.m55fp5i7rdpm"><span class="c42 c15 c22 c46 c30">Drumsep - single percussion instruments separation</span></h2><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you want to further separate single instruments from drums stem separated with e.g. MDX23 Colab, Mel-Roformer drums on x-minus.pro premium, MVSEP, or Demucs_ft (not necessarily BS-Roformer SW) into: hihat, cymbals, kick, snare and more, you might want to check below solutions. Sampling from such separated stems might be not the best idea due to the quality (see </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://raredsp.com/drumclone&amp;sa=D&amp;source=editors&amp;ust=1765035744231374&amp;usg=AOvVaw3UsdyyS6_C0mXypaGRn7wp">here</a></span><span>&nbsp;for free Drumclone plugin allowing even different types of synthesised kicks from mixture; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DNbDo9DwNtuI&amp;sa=D&amp;source=editors&amp;ust=1765035744231619&amp;usg=AOvVaw35qzztjjEPorQxMKWiDWRG">video</a></span><span class="c0">). But e.g. it serves well for purposes of conducting new mixes/remasters of the same songs or separated instrumentals, e.g. when it&#39;s overlapped with better quality, previously separated drums stem. It might give interesting results when aligned with the original drums, and rebalanced with effects (drums stem might end up louder in the mix than separated percussion, as most likely it will still have better quality). Check out these drum replacers.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To potentially increase drumsep models separation quality, &ldquo;try using a small pitch shift up or down, like +/- 1 or 2 semitones (...) can sometimes help bring out the lows or highs if they seem weak.&rdquo; (CZ-84)</span></p><p class="c1"><span class="c0">Also, consider using good instrumental model before using 4 stem model for drums (if it&#39;s not instrumental already), to enhance drums stem, and then to enhance drumsep result.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Some drumsep models might have a bug where &ldquo;a small, but relevant portion of audio is being lost when the [drumsep] model is being used&rdquo; </span></p><p class="c1"><span class="c6">&ldquo;The solution is to invert the phase on all the drum stems into the original file and save that as its own file, making your own &quot;other&quot; file&rdquo;. It has been fixed on MVSEP.</span></p><h3 class="c35 c27" id="h.aowhgo4swnk4"><span class="c19">Mel-Roformer MVSEP drumsep models</span></h3><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>1)</span><span class="c0">&nbsp;4 stems v2 (kick, snare, toms, cymbals) - &ldquo;It gives the best metrics with a big gap for kick, snare and cymbals.&rdquo; - ZFTurbo. The old v1 below was removed.</span></p><p class="c1"><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/h924uBF&amp;sa=D&amp;source=editors&amp;ust=1765035744234141&amp;usg=AOvVaw2IXzHMYWDIfMFlR6LpGmP6">metrics</a></span><span class="c0">; only toms are worse SDR-wise vs previous SCNet Drumsep models below)</span></p><p class="c1"><span class="c34">1) 4 stems v1</span><span class="c0">&nbsp;removed (kick, snare, toms, cymbals) - average SDR of hihat ride, crash is 11,52 (but in one stem) and so far it&rsquo;s the best SDR out of all models (even vs the previous ensemble consisting of three MDX23C and SCNet models). </span></p><p class="c1"><span class="c0">2) 6 stems (kick, snare, toms, hihat, ride, crash) - average SDR of hihat ride, crash is 8.18 (but from separated stems), while </span></p><p class="c1"><span class="c0">The snare in 1) has the best SDR out of all available models.<br>Kick and toms are still the best SDR-wise in the previous 3x MDX23C and SCNet ensemble (new ensemble with these new Mel-Roformers so far)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The new models &ldquo;are very great for ride/crash/hh. And overall, they have the best metrics for almost all stems.&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/n9WMkSY&amp;sa=D&amp;source=editors&amp;ust=1765035744235646&amp;usg=AOvVaw0-5jrvlfQnf3rO-cJspWEa">SDR/L1 Freq/bleedless/fullness chart</a></span><span class="c0">&nbsp;of all models</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/vEVYTcJ&amp;sa=D&amp;source=editors&amp;ust=1765035744235817&amp;usg=AOvVaw1FyPh9-UtwRHEK1BsmW4nX">Evaluations on new dataset</a></span><span class="c0">&nbsp;(esp. check Log WMSE Results with &ldquo;&quot;bypass_filter&quot; with torch_log_wms, ([good] at least for drums or anything rich in low frequency content)&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes the newer jarredou&rsquo;s drumsep 6 stems model below can serve to clean up &ldquo;upper frequency range of snare hits&rdquo; in the cymbals stems in &ldquo;either MelRoFormer or SCNet-XL four-or-six stem DrumSep models&rdquo; - Dyslexicon</span></p><p class="c1"><span class="c0">&ldquo;The core problem is that the main MVSep Drums model which is used by everything- including the Drumsep models- is not purely drums, it&#39;s mixed with other percussion which taints things.&rdquo; - godzfire</span></p><h3 class="c35 c27" id="h.ofipsjc35vaq"><span class="c19">SCNet MVSEP drumsep models</span></h3><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Better SDR than MDX23C and Demucs models above</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- MVSEP 8 stems ensemble of all the 4 drumsep models below (along with MDX23C model, and besides Demucs model by Imagoy) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/sR5pNP3.png&amp;sa=D&amp;source=editors&amp;ust=1765035744237287&amp;usg=AOvVaw0zEuKJxMuxvj3hrDGpM_ec">metrics</a></span></p><p class="c1"><span class="c0">- MVSEP&rsquo;s SCNet 4 stem (kick, snare, toms, cymbals) out of following models, the best SDR for kick and similar to 6 stem below for toms - only -0.01 SDR difference) </span></p><p class="c1"><span class="c0">- MVSEP&rsquo;s SCNet 5 stem (cymbals, hi-hat, kick, snare, toms)</span></p><p class="c1"><span class="c0">- MVSEP&rsquo;s SCNet 6 stem model (ride, crash, hi-hat, kick, snare, toms) worse snare SDR</span></p><h3 class="c35 c27" id="h.67bx3lypshg7"><span class="c19">(newer) MDX23C 5 stem drumsep by jarredou</span></h3><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/models/releases/tag/DrumSep&amp;sa=D&amp;source=editors&amp;ust=1765035744238153&amp;usg=AOvVaw2v3BOCx38k65ONFJ-ato4b">Download</a></span><span class="c0">. All SDR metrics are better than the previous 6 stem model below:</span></p><p class="c1"><span>SDR: kick: 16.66, snare: 11.54, toms 12.34, hihat: 4.04, cymbals: 6.36 (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8460&amp;sa=D&amp;source=editors&amp;ust=1765035744238484&amp;usg=AOvVaw2IK2vYOWMpXcwE442cgv-I">all metrics</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">Metric fullness for snare: 25.0361, bleedless for hh: 12.3470, log_wmse for snare: 13.8959</span></p><p class="c1"><span class="c0">&ldquo;it&#39;s more on the fullness side than bleedless&rdquo; - from all the metrics, only bleedless for snare is worse than in the previous model: </span></p><p class="c1"><span class="c0">26.8420 vs 30.4149</span></p><p class="c1"><span class="c0">&ldquo;Quite cleaner than the previous [6 stem] one&rdquo;, &ldquo;a lot noisier than other drumpsep models, but that&#39;s not necessarily a bad thing.&rdquo;</span></p><p class="c1"><span class="c0">Possible &ldquo;UnpicklingError: &quot;invalid load key, &#39;\x0a&#39;.&quot;&rdquo; issue in UVR if you use the old 6 stem yaml.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Maybe if we separate just snare with the old MDX23C model below from an already separated drums stem, and mix/invert to get the rest, then pass it through the new model, the bleed would be gone.</span></p><p class="c1"><span><br>For comparison, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8195&amp;sa=D&amp;source=editors&amp;ust=1765035744239910&amp;usg=AOvVaw3miHbvEFW4Y_bHtKZRJFO4">metrics</a></span><span class="c0">&nbsp;of the old 6 stem jarredou/Aufr33 MDX23C model </span></p><p class="c1"><span class="c0">(which has cymbals divided into ride and crash which are not in the evaluation dataset):</span></p><p class="c1"><span class="c0">SDR: kick: 14.55, snare: 9.79, toms: 10.64, hihat: 3.20, cymbals: 6.08</span></p><p class="c1"><span class="c0">Metric fullness for snare: 25.0361, bleedless for hh: 10.2765, log_wmse for snare: 12.4258</span></p><p class="c1"><span class="c0">The model was trained with a lightweight config to train on a subpar T4 GPU on free Colabs and 10 accounts. The metrics do not surpass exclusive drumsep Mel-Roformer and SCNet models on MVSEP, but at least you can use this one locally.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Depending on the quality tier of input source material, it can sometimes yield more accurate stem-to-stem separations than either MelRoFormer or SCNet-XL four-or-six stem DrumSep models. (...) </span></p><p class="c1"><span class="c0">For example, I often find that MelRoFormer DrumSep can leave the upper frequency range of Snare hits and mis-assign them to the Cymbals stem. This is a common issue I have encountered with separating AUD recordings with MelRoFormer DrumSep.</span></p><p class="c1"><span class="c0">MDX23c 5-stem drumsep is trained in such a way that it separates these snare remainders out of the Cymbals stem, which is extremely useful. &quot; Dyslexicon&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h3 class="c35 c27" id="h.2u19k7ty9b00"><span>(older) </span><span>MDX23C 6 stem d</span><span>rumsep by jarredou/Aufr33</span></h3><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Use it on already separated </span><span class="c4"><a class="c3" href="#h.sjf0vefmplt">drums</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Download </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/models/releases/tag/aufr33-jarredou_MDX23C_DrumSep_model_v0.1&amp;sa=D&amp;source=editors&amp;ust=1765035744242693&amp;usg=AOvVaw1V-b4NMS_btGfUFPAPx5qX">https://github.com/jarredou/models/releases/tag/aufr33-jarredou_MDX23C_DrumSep_model_v0.1</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Use on Colab: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training-Colab-Inference/&amp;sa=D&amp;source=editors&amp;ust=1765035744243026&amp;usg=AOvVaw3xfxyN9ypxFj5aI1B-IS4h">https://github.com/jarredou/Music-Source-Separation-Training-Colab-Inference/</a></span></p><p class="c1"><span>&ldquo;. Added on MVSEP and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uvronline.app/ai&amp;sa=D&amp;source=editors&amp;ust=1765035744243196&amp;usg=AOvVaw1bXNnUPX30sG5wy68cBBKb">uvronline</a></span><span class="c0">&nbsp;too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(jarredou) &ldquo;Drums Separation model trained by aufr33</span></p><p class="c1"><span class="c0">(on my not-that-clean drums dataset)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Stems:</span></p><p class="c1"><span class="c0">kick, snare, toms, hh, ride, crash</span></p><p class="c1"><span class="c0">MVSEP dataset evaluation:</span></p><p class="c1"><span class="c0">SDR: kick: 14.55, snare: 9.79, toms: 10.64, hihat: 3.20, cymbals: 6.08, hihat &amp; cymbals: 6.77</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8195&amp;sa=D&amp;source=editors&amp;ust=1765035744243985&amp;usg=AOvVaw2j5OEYhvS3R1yIj62Rytt6">More metrics</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To get potentially better results with the model &ldquo;try using a small pitch shift up or down, like +/- 1 or 2 semitones, in the settings you use to extract the drum stem from the instrumental stem. (...) can sometimes help bring out the lows or highs if they seem weak.&rdquo; (CZ-84)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It can already be used, but training is not fully finished yet.</span></p><p class="c1"><span class="c0">The config allows training on not so big GPUs [n_fft 2048 instead of 8096], it&#39;s open to anyone to resume/fine-tune it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For now, it&#39;s struggling a bit to differentiate ride/hh/crash correctly, kick/snare/toms are more clean.</span></p><p class="c1"><span class="c0">[&ldquo;and has the usual issues with mdx23 models, but it&rsquo;s an improvement over drumsep I think&rdquo; - Dry Paint Dealer Undr]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you got an error while using jarredou&rsquo;s Drumsep Colab (object is not subscriptable):</span></p><p class="c1"><span class="c0">change to this on line 144 in inference.py:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; if type(args.device_ids) != int:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; model = nn.DataParallel(model, device_ids = args.device_ids)</span></p><p class="c1"><span class="c0">(thx DJ NUO)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It works in UVR too. All models should be located in the following folder:</span></p><p class="c1"><span class="c0">Ultimate Vocal Remover\models\MDX_Net_Models </span></p><p class="c1"><span class="c0">Don&#39;t forget about copying the config file to: model_data\mdx_c_configs.</span></p><p class="c1"><span class="c0">Once the model is detected, select the config in a new window, and that&rsquo;s all.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The model achieved much better SDR on private jarredou&#39;s small evaluation dataset compared to the previous drumsep model by Inagoy which was based on a worse dataset and older Demucs 3 arch.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>The dataset for further training is available in the drums section of </span><span class="c4"><a class="c3" href="#h.k3cm3bvgsf4j">Repository of stems/multitracks</a></span><span class="c0">&nbsp; - you can potentially clean it further and/or expand the dataset so the results might be better after resuming the training from checkpoint. Using the current dataset, the SDR might stall for quite some amount of epochs or even decrease, but it usually increases later, so potentially training it further to 300-500-1000 epochs might be beneficial.</span></p><p class="c1"><span>Attached config also includes necessary training parameters for training further using ZFTurbo </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035744247997&amp;usg=AOvVaw18nbi_jlM6lU5Jpd08YVpW">repo</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Current model metrics (not MVSEP evaluation dataset):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Instr SDR kick: 18.4312</span></p><p class="c1"><span class="c0">Instr SDR snare: 13.6083</span></p><p class="c1"><span class="c0">Instr SDR toms: 13.2693</span></p><p class="c1"><span class="c0">Instr SDR hh: 6.6887</span></p><p class="c1"><span class="c0">Instr SDR ride: 5.3227</span></p><p class="c1"><span class="c0">Instr SDR crash: 7.5152</span></p><p class="c1"><span class="c0">SDR Avg: 10.8059&rdquo; Aufr33 </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">And if evaluation dataset hasn&#39;t changed since then, the old Drumsep SDR:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;kick &nbsp;: 13.9216</span></p><p class="c1"><span class="c0">snare : &nbsp;8.2344</span></p><p class="c1"><span class="c0">toms &nbsp;: &nbsp;5.4471</span></p><p class="c1"><span class="c0">(I can&#39;t compare cymbals score as it&#39;s different stem types)&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">After initial jarredou&rsquo;s training in Colab, Aufr33 decided to train the model for additional 7 days, to at least above epoch 113 (perhaps around 150, it wasn&#39;t said precisely), while using the same config, but on a faster GPU (rented 2x RTX 4090). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Even epoch 5 trained on jarredou&#39;s dataset casually in slow and troublesome free Colab (which uses Tesla T4 15GB with performance of RTX 3050, but with more VRAM) with multiple Colab accounts and very light and fast training settings, already achieved better SDR than Drumsep using smaller dataset and older architecture. Colab epochs metrics:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;epoch 5:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instr SDR kick: 13.9763</span></p><p class="c1"><span class="c0">Instr SDR snare: 8.4376</span></p><p class="c1"><span class="c0">Instr SDR toms: 6.7399</span></p><p class="c1"><span class="c0">Instr SDR hh: 0.7277</span></p><p class="c1"><span class="c0">Instr SDR ride: 0.8014</span></p><p class="c1"><span class="c0">Instr SDR crash: 4.4053</span></p><p class="c1"><span class="c0">SDR Avg: 5.8480</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">epoch 15:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instr SDR kick: 15.3523</span></p><p class="c1"><span class="c0">Instr SDR snare: 10.8604</span></p><p class="c1"><span class="c0">Instr SDR toms: 10.3834</span></p><p class="c1"><span class="c0">Instr SDR hh: 4.0184</span></p><p class="c1"><span class="c0">Instr SDR ride: 2.7248</span></p><p class="c1"><span class="c0">Instr SDR crash: 6.1663</span></p><p class="c1"><span class="c0">SDR Avg: 8.2509&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Don&#39;t forget to use already well separated drums (e.g. from Mel-Roformer for premium users on x-minus or MVSEP Drums ensemble) from well separated instrumental as input for that model, or jarredou&rsquo;s MDX23 Colab fork v. 2.5 or also for all stems - MVSEP 4/+ ensemble (premium).</span></p><p class="c1"><span class="c0">Purely for drums separation from even instrumentals, the model might not give good results, hence it needs separated drums first. It was trained just on percussion sounds and not vocals or anything else.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, e.g. the kick and toms might have a bit weird looking spectrograms. It&rsquo;s due to:</span></p><p class="c1"><span>&ldquo;mdx23c subbands splitting + unfinished training, these artifacts are [normally] reduced/removed along [further] training.&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/900904142669754399/1258441408109613209&amp;sa=D&amp;source=editors&amp;ust=1765035744252992&amp;usg=AOvVaw1ZLZGYPlIgrkkDrE4wZCjH">Examples</a></span></p><p class="c1 c7"><span class="c0"></span></p><h3 class="c35 c27" id="h.jmjab44ryjjo"><span>Older </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/inagoy/drumsep&amp;sa=D&amp;source=editors&amp;ust=1765035744253194&amp;usg=AOvVaw1NR3cSVj5-pEQVocBkK4Mg">drumsep</a></span><span class="c19">&nbsp;by Inagoy</span></h3><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Demucs 3 model. Just remember to use drums in one stem (e.g. with demucs_ft) from already good sounding instrumental or ensemble on MVSEP or MDX23 v. 2.4 Colab first, as use it as input (both are better for instrumental in most cases than just Demucs 4 - you can use various settings for ensembles to get better instrumentals, the better drums, the better results from drumsep) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1wws3Qm3I1HfMr-3gAyW6lYzUHXG_kuyz?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744254097&amp;usg=AOvVaw1IX6gczBIvfK-jwvEK8WaL">Fixed Colab</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span>- or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kubinka0505/colab-notebooks/blob/master/Notebooks/AI/Audio/Separate/Drumsep.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744254312&amp;usg=AOvVaw34Kp5OD6Ev_sMLv_6oDJIS">Kubinka Colab</a></span><span class="c0">&nbsp;(you can provide direct links there)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Available on MVSEP.com (but you can use more intensive parameters in Colab for a bit better quality)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(Use these solutions instead of GitHub Colab as the model&#39;s GDrive link from OG GitHub Colab is currently deleted, so drumsep won&rsquo;t work correctly, unless you replace GDrive link with model to the .th model reupload:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1S79T3XlPFosbhXgVO8h3GeBJSu43Sk-O/view&amp;sa=D&amp;source=editors&amp;ust=1765035744255341&amp;usg=AOvVaw1NKMDhhOykViH6UBlaomBA">https://drive.google.com/file/d/1S79T3XlPFosbhXgVO8h3GeBJSu43Sk-O/view</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Windows installation - execute the following:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">demucs --repo &quot;PATH_TO_DrumSep_MODEL_FOLDER&quot; -n modelo_final &quot;INPUT_FILE_PATH&quot; -o &quot;OUTPUT_FOLDER_PATH&quot; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You can also use drumsep in UVR 5 GUI</span></p><p class="c1"><span class="c0">(so beside using fixed Colab or in CML):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Go to UVR settings and open application directory.</span></p><p class="c1"><span class="c0">Find the folder &quot;models&quot; and go to &quot;demucs models&quot; then &quot;v3_v4&quot;</span></p><p class="c1"><span>Copy and paste both the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1S79T3XlPFosbhXgVO8h3GeBJSu43Sk-O/view&amp;sa=D&amp;source=editors&amp;ust=1765035744256518&amp;usg=AOvVaw2wbQYzOZsLthVSR3bzngMo">.th</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1LJ_C4h-hXAJEMaP7lbPTpcrVH-i_VKjm/view?usp%3Ddrivesdk&amp;sa=D&amp;source=editors&amp;ust=1765035744256648&amp;usg=AOvVaw2rJA0DtlhnBc2aax-Zd7Zo">.yaml</a></span><span class="c0">&nbsp;files, and it&#39;s good to go.</span></p><p class="c1"><span class="c0">Be aware that stems will be labelled wrong in the GUI using drumsep.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s much more sensitive to shifts than overlap, where above 0.6-0.7 it can become placebo. Consider testing it with shifts 20.</span></p><p class="c1"><span class="c0">But some people find using shifts 10 and overlap 0.99 better than shifts 20 and overlap 0.75.</span></p><p class="c1"><span class="c0">Just be aware, that if you&rsquo;re willing to wait, you can further increase shifts to 20 if you want the best of both worlds.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, consider testing it with -6 semitones e.g. in UVR 5.6/+, or with 31183Hz sample rate with changed (decreased) tempo and pitch.</span></p><p class="c1"><span class="c0">-12 semitones from 44100Hz is 22050 and should be rather less usable in most cases, the same for tempo preservation, it should be off.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that sometimes it can &ldquo;consistently put hi hats in snare stem&rdquo; and can contain some artefacts, and results might not null with the source.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;From what I&#39;ve tested (on drums already extracted with demucs4_ft from a live band recording from the output of the soundboard... so shitty sounding!), It is quite good at separating cymbals from shells, and kick from snare, but there are parts of kick or snare sounds that can go into the toms stem (...it&#39;s easy to fix manually in a DAW)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Ok I did test it.</span></p><p class="c1"><span class="c0">- You&#39;re right, Drumsep is good if shifts are applied, this makes a HUGE difference, first time i did test it with 0 or 1 shift and results were meh. &nbsp;Shifts (from about 5/6/10 depending on source) clean it nicely.</span></p><p class="c1"><span class="c0">Minuses: only 4 outputs. Not enough for a lot of drumtracks (but hey you can Regroove results, and this is what i will be doing probably from now) - It takes a long time with a lot of shifts, - it doesnt null with original tracks</span></p><p class="c1"><span class="c0">- Regroove allows me more separations, especially when used multiple times, so as a producer it allows me to remove parts of kicks, parts of snares etc, noises etc. More deep control. Plus it nulls easily (it always adds the same space in front) so I can work more transparently. </span></p><p class="c1"><span class="c0">But you&#39;re right, I will use drumsep in the Colab with a lot of shifts as a starting point in most cases now.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It&#39;s trained with 7 hours of drum tracks that I made using sample-based drum software like Adictive Drums, trying to get as many different-sounding drums as I could. As everything was controlled with MIDI, I could export the isolated bodies: kick, snare, toms (all on one track), and cymbals (including hi-hat). So every dataset example is composed of kick, snare, toms, cymbals, and the mixture (the sum of all of them).&quot; - said the author - Inagoy</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>From paid solutions for separating drums&#39; sections there is mainly a paid </span><span class="c4"><a class="c3" href="#h.cz4j2d3uf48s">FactorSynth</a></span><span class="c0">&nbsp;and other alternatives are more problematic or less perfect.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Use free zero shot for separating single other instruments from e.g. others stem from Demucs or GSEP.</span></p><p class="c1 c7"><span class="c0"></span></p><h3 class="c35 c27" id="h.p1lb0lkwo8dk"><span class="c19">Moises.ai drumsep</span></h3><p class="c1"><span class="c0">(only for Pro)</span></p><p class="c1"><span class="c0"><br>- Kick, snare, toms, hi-hat, cymbals, other</span></p><p class="c1"><span class="c0">It&rsquo;s not well documented on their promotional materials, but the option is available after dragging your input file on the site, and then under drums button.</span></p><p class="c1 c7"><span class="c0"></span></p><h3 class="c35 c27" id="h.cz4j2d3uf48s"><span class="c19">FactorSynth</span></h3><p class="c1"><span class="c0">Since version 3 available in a form of plugin for most DAWs. Demo runs for 20 minutes at a time. Exporting and component editing are disabled.</span></p><p class="c1"><span class="c0">Till v. 2 it was Ableton-only compatible add-on. And (probably) could be used on free Ableton Live. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, not for separating drums from a full mix, but for separating your already separated drums into further layers like kick, snare, transients, cymbals, etc. from Demucs or GSEP (the latter usually has better shakers and at least hi-hats when they&#39;re in fast tempo).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">[till v2 demo version limit was 8 seconds and no limit for full version]&rdquo; &ldquo;it&rsquo;s amazing&rdquo;. </span></p><p class="c1"><span class="c0">It works the same way as Regroover VST (which may have some problems with creating a trial account).</span></p><p class="c1"><span class="c0">It&rsquo;s comparable or better quality (both better than zero shot for at least drums).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Factorsynth has more granularity, but drumsep is easier to work with and gets less confused between toms and kicks.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There&rsquo;s a freeware prototype 0.4-0.1 versions from 2017 for Mac available to download:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.jjburred.com/software/factorsynth/proto.html&amp;sa=D&amp;source=editors&amp;ust=1765035744264736&amp;usg=AOvVaw3rfjcL_ujCpjoUNQyPNXCb">https://www.jjburred.com/software/factorsynth/proto.html</a></span></p><p class="c1 c7"><span class="c0"></span></p><h3 class="c35 c27" id="h.buopqcmi0inj"><span class="c19">Regroover</span></h3><p class="c1"><span class="c0">Regroover is only for 30 seconds chunks, and they require manual align due to phasing issues - additional silence is added in the beginning and ending. </span></p><p class="c1"><span class="c0">&ldquo;Get your 30-second drum clip, then drag and drop it into Regroover.</span></p><p class="c1"><span class="c0">Make sure to de-select the Sync option, as it will time stretch it by default.</span></p><p class="c1"><span class="c0">On the right-hand side, I recommend changing the split to 6 layers instead of 4, simply for flexibility.</span></p><p class="c1"><span class="c0">Once it has processed that, you can choose export -&gt; layers.&quot; </span></p><p class="c1"><span class="c0">There was a report that probably newer versions might not be feasible for this task anymore.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In other words:</span></p><p class="c1"><span class="c0">It&rsquo;s much more hassle to use it than drumsep, but it&rsquo;s very good &ldquo;if you need particular sound and not about pattern etc.</span></p><p class="c1"><span class="c0">1. separate drums from whole track (demucs)</span></p><p class="c1"><span class="c0">2. Cut drum track into max 30 second cuts [regroover limits] and ideally &nbsp; cut right on transient, some space before kick helps,</span></p><p class="c1"><span class="c0">2. You use regroover for the first time and for example try to separate to 4 tracks, just so overall separation.</span></p><p class="c1"><span class="c0">3. Those separation sums exactly to that is given, sometimes it just need to be realigned few ms.</span></p><p class="c1"><span class="c0">4. And if for example kick still has some not needed parts, you just regroove it once again.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If are looking overall fast and for patterns, drumsep. Regroover for painfull but precise job. Also in most cases hihats are trash, but snare&#39;s and kicks you often can find perfetclu usable ones. I&#39;m not sure about metal but overall.&rdquo;</span></p><h3 class="c35 c27" id="h.n8a91zv9lor0"><span class="c19">UnMixingStation </span></h3><p class="c1"><span>&quot;Very, very old and almost impossible to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.magesypro.com/audionamix-unmixingstation-v0-90-115-8730-assign/&amp;sa=D&amp;source=editors&amp;ust=1765035744267840&amp;usg=AOvVaw0s0PL1qvrcJdPbQKkAKbj1">find</a></span><span class="c0">, but the separations are 95% close to Regroover&quot;. The software is 13 years old, and their site is down, and the tool doesn&rsquo;t seem to be available to buy anywhere.</span></p><p class="c1 c7"><span class="c0"></span></p><h3 class="c35 c27" id="h.f067glwjzyi4"><span class="c19">LarsNet </span></h3><p class="c1"><span>Adden on MVSep. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/larsnet-colab&amp;sa=D&amp;source=editors&amp;ust=1765035744268350&amp;usg=AOvVaw2brF1E5JXStq7d-zxSczBP">Colab</a></span><span>. Source: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/polimi-ispl/larsnet&amp;sa=D&amp;source=editors&amp;ust=1765035744268539&amp;usg=AOvVaw0qWbQY4TOG2OI1EChiG5bP">https://github.com/polimi-ispl/larsnet</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It separates previously separated drums into 5 stems: kick, snare, cymbals, toms, hihat. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&rsquo;s worse than Drumsep as it uses Spleeter-like architecture, but &ldquo;at least they have an extra output, so they separate hihats and cymbals.&rdquo;. Colab</span></p><p class="c1"><span class="c0">&ldquo;Baseline models don&#39;t seem better quality than drumsep, but the provided checkpoints are trained with oly 22 epochs, it doesn&#39;t seem much. (and STEMGMD dataset was limited by the only 10 drumkits), so it could probably be better with better dataset &amp; training&rdquo;</span></p><p class="c1"><span class="c0">Similar situation as with Drumsep - you should provide drums separated from e.g. Demucs model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There&rsquo;s also Zynaptiq Unmix Drums, but it&rsquo;s not exactly a separation tool, but to &ldquo;Boost Or Attenuate Drums In Mixed Music&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For only kick and hi hat separation now free -</span></p><h3 class="c35 c27" id="h.ftdzxgety1hd"><span class="c19">VirtualDJ 2023/Stems 2.0 (kick, hi-hat)</span></h3><p class="c1"><span class="c0">Probably using drums from Demucs 4 or GSEP first, will give better results but, it&#39;s not perfect. In many cases it may leave bleeding of snare a little bit, in both hi-hat and kick track. Sadly it sometimes confuses these elements of a mix.</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">&quot;If you are not using it professionally, and do not use any professional equipment like a DJ controller, or a DJ mixer, then VirtualDJ is (now) FREE&quot;.</span></p><h3 class="c35 c27" id="h.1bm9wmdv6hpf"><span class="c19">RipX DeepAudio (-||-) (6 stems [piano, guitar])</span></h3><p class="c1"><span>Popular tool. Decent</span><span class="c0">&nbsp;results for specific drums&#39; sections separation (but as for vocal/instrumental/4 stems separation, all the tools mentioned in at the very top of the document outperforms RipX, so use it only for specific drums&rsquo; section separation only, at best using Demucs 4 or GSEP for drums stem). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It can separate a file into a buncha things into a lot more types of instruments than just the basic 4 stems (with varying degrees of success ofc).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Might be a case that old cracked versions of RipX don&#39;t allow separating drums sections well, or just the opposite - check both the newest version and Hit&#39;n&#39;Mix RipX DeepAudio v5.2.6, but probably the latter doesn&#39;t support separating single drums yet. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&rsquo;s basically UVR but with their custom models + SFX single stem </span></p><p class="c1"><span class="c0">It&#39;s good for guitar, but not in all cases (possibly Demucs for 4 stems).</span></p><p class="c1"><span class="c0">Piano and guitar models were added recently (somewhere in the January 2023)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Hit &#39;n&#39; Mix RipX DAW Pro 7 released. For GPU acceleration, min. requirement is 8GB VRAM and 10XX card or newer (mentioned by the official document are: 1070, 1080, 2070, 2080, 3070, 3080, 3090, 40XX). Additionally, for GPU acceleration to work, exactly Nvidia CUDA Toolkit v.11.0 is necessary. Occasionally during transition from some older versions, separation quality of harmonies can increase. Separation time with GPU acceleration can decrease from even 40 minutes on CPU to 2 minutes on decent GPU.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">They say it uses Demucs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">We have reports about crashes, at least on certain audio files. There are various RipX versions uploaded on archive.org, maybe one will work, but some keys work only on versions from 2 and up.</span></p><h3 class="c35 c27" id="h.404qq7uhcrx5"><span class="c19">Spectralayers 10</span></h3><p class="c1"><span>Received an update of an AI, and they no longer use Spleeter, but Demucs 4 (6s), and they now also good kick, snare, cymbals separation too. Good opinions so far. Compared to drumsep sometimes it&#39;s better, sometimes it&#39;s not. Versus MDX23 Colab V2, instrumentals sometimes sound much worse, so rather don&rsquo;t bother for instrumentals.</span></p><h2 class="c29 c27" id="h.4svuy3bzvi1t"><span>USS-Bytedance </span><span class="c42 c15 c36 c46 c30">(any; esp. SFX)</span></h2><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/bytedance/uss&amp;sa=D&amp;source=editors&amp;ust=1765035744275200&amp;usg=AOvVaw0rF3zFCrcXHoAtyXXCmtSX">https://github.com/bytedance/uss</a></span></p><p class="c2"><span>(COMMAND: &quot;conda install -c intel icc_rt&quot; SOLVES the LLVM ERROR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You provide e.g. a sample of any instrument or SFX, and the AI separates it solo from a song or movie fragment you choose to separate.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It works in mono. You need to process right and left channel separately.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Update 29.04.25 (Python No such file or directory fix; thx epiphery)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1rfl0YJt7cwxdT_pQlgobJNuX3fANyYmx?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744276304&amp;usg=AOvVaw3X-ysDsoDQMz8DCHnPEPtf">https://colab.research.google.com/drive/1rfl0YJt7cwxdT_pQlgobJNuX3fANyYmx?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(old) </span><span class="c0">ByteDance USS with Colab by jazzpear94</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1lRjlsqeBhO9B3dvW4jSWanjFLd6tuEO9?usp%3Dshare_link&amp;sa=D&amp;source=editors&amp;ust=1765035744276764&amp;usg=AOvVaw0so_2jyf4Pn2mZxAulpVNN">https://colab.research.google.com/drive/1lRjlsqeBhO9B3dvW4jSWanjFLd6tuEO9?usp=share_link</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(old) Probably mirror (fixed March 2024):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1f2qUITs5RR6Fr3MKfQeYaaj9ciTz93B2&amp;sa=D&amp;source=editors&amp;ust=1765035744277152&amp;usg=AOvVaw1zP1srDrLRcUj0dVTaMcte">https://colab.research.google.com/drive/1f2qUITs5RR6Fr3MKfQeYaaj9ciTz93B2</a></span><span class="c0"><br>errors out with:</span></p><p class="c1"><span class="c0">&ldquo;sed: can&#39;t read /usr/local/lib/python3.10/dist-packages/uss/config.py: No such file or directory&rdquo;) (2025)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It works (much) better than zero-shot (not only &ldquo;user-friendly wise&rdquo;).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Better results, and It divides them into many </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1106629812119941341/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035744277841&amp;usg=AOvVaw06WeRSCiSBm3EbzFkIQvnR">categories</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Great for isolating SFX&#39;, worse for vocals than current vocal models. Even providing acapella didn&#39;t give better results than current instrumental models. It just serves well for other purposes.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Queries [so exemplary samples] for ByteDance USS taken from the DNR dataset. Just download and put these on your drive to use them in the Colab as queries [as similarly sounding sounds from your songs to separate].&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.dropbox.com/sh/fel3hunq4eb83rs/AAA1WoK3d85W4S4N5HObxhQGa?dl%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035744278978&amp;usg=AOvVaw2Zf7TQSTucHDmJuO4hFxBQ">https://www.dropbox.com/sh/fel3hunq4eb83rs/AAA1WoK3d85W4S4N5HObxhQGa?dl=0</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, grab some crowd samples from here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/-FLgShtdxQ8&amp;sa=D&amp;source=editors&amp;ust=1765035744279273&amp;usg=AOvVaw2U2rP3IBu9robXrPeh1y-9">https://youtu.be/-FLgShtdxQ8</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/IKB3Qiglyro&amp;sa=D&amp;source=editors&amp;ust=1765035744279418&amp;usg=AOvVaw3ZSea1A2lxbN2MxQ3fqaGO">https://youtu.be/IKB3Qiglyro</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/Hheg88LKVDs&amp;sa=D&amp;source=editors&amp;ust=1765035744279557&amp;usg=AOvVaw2lV8eT6SCHnhQTvqMeFE8L">https://youtu.be/Hheg88LKVDs</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q&amp;A by Bas Curtis and jazzpear</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What is the difference between running with and without the usage of reference query audio?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: Query audio lets you input audio for it to reference and extract similar songs based upon (like zeroshot but way better) whereas without a query auto splits many stems of all kinds without needing to feed it a query.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Let&#39;s say there is this annoying flute you wanna get rid off...</span></p><p class="c1"><span class="c0">and keep the vocals only....</span></p><p class="c1"><span class="c0">You feed a snippet of the flute as reference, so it tries to ditch it from the input?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: Quite the reverse. It extracts the flute only which ig you could use to invert and get rid of it</span></p><h2 class="c27 c29" id="h.g37f4a6hnxm0"><span>Zero Shot </span><span class="c36">(any sample; esp. instruments)</span></h2><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/RetroCirce/Zero_Shot_Audio_Source_Separation&amp;sa=D&amp;source=editors&amp;ust=1765035744281428&amp;usg=AOvVaw3N2PSb2dwQwTtuOEMl3ais">https://github.com/RetroCirce/Zero_Shot_Audio_Source_Separation</a></span><span><br>(as </span><span class="c4"><a class="c3" href="#h.4svuy3bzvi1t">USS Bytedance</a></span><span class="c0">&nbsp;came out now, zero shot can be regarded as obsolete now, although zero-shot might is rather better for single instruments than for SFX)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">You provide e.g. sample of any trumpet or any other instrument, and AI returns it from a song you choose to separate.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/947867283752108122/947867478271340556&amp;sa=D&amp;source=editors&amp;ust=1765035744282145&amp;usg=AOvVaw2Rda_fq4siw8jHNotz1Yui">Guide and troubleshooting</a></span><span class="c0">&nbsp;for local installation (get Discord invitation in footer first if necessary).</span></p><p class="c1"><span>Google Colab </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/947867283752108122/950263276514725898&amp;sa=D&amp;source=editors&amp;ust=1765035744282447&amp;usg=AOvVaw1Xz1tst3KAjxnnrvIzVkm_">troubleshooting</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1kUj5DQe6HzkPo4WyWYTVfHZg14FyTgZY?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744282580&amp;usg=AOvVaw3hH6G5PV3trVOvWkAeFkqh">notebook</a></span><span class="c0">&nbsp;(though it may not work at times when GDrive link resources are out of download limit, also it returns some torch issues after Colab updates in 2023).</span></p><p class="c1"><span class="c0">Check out also this Colab alternative:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://replicate.com/retrocirce/zero_shot_audio_source_separation&amp;sa=D&amp;source=editors&amp;ust=1765035744283113&amp;usg=AOvVaw0pbdvKOFZ2VWY3mxE410sk">https://replicate.com/retrocirce/zero_shot_audio_source_separation</a></span></p><p class="c1"><span class="c0">It&#39;s faster (mono input required).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Also available on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744283418&amp;usg=AOvVaw2HGjWl5TppAP7cW4qgJH3x">https://mvsep.com/</a></span><span class="c0">&nbsp;in a form of 4 stems without custom queries, and it&rsquo;s not better than Demucs in this form.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Zero shot isn&#39;t meant to be used as a general model, that&#39;s why it accelerates on a specific class of sounds with some limitations in mind.... It mostly works the best when samples match the original input mixture, of course there are limitations&quot;</span></p><p class="c1"><span class="c0">&quot;You don&rsquo;t have to train any fancy models to get decent results [...] And it&rsquo;s good at not destroying music&quot;. But it usually lefts some vocal bleeding, so process the result using MDX to get rid of these low volume vocals. Zero-shot is also capable of removing crowd from recordings pretty well.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">As for drums separation, like for snares, it&rsquo;s not so good as drumsep/FactorSynth/RipX, and it has cutoff.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I did zero shot tests a week or two ago, and it was killing it, pulling harmonica down to -40dB, synth lines gone, guitars, anything. And the input sources were literally a few seconds of audio.</span></p><p class="c1"><span class="c0">I&#39;ve been pulling out whole synths and whistles and all sorts.</span></p><p class="c1"><span class="c0">Knocks the wind model into the wind, zero shot with the right sample to form the model backbone works really well</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The key is to give it about 10 seconds of a sample with a lot of variation, full scales, that kinda thing&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Dango.ai</span></p><p class="c1"><span class="c0">Custom stem separation feature (paid, 10 seconds for free)</span></p><p class="c1"><span class="c0">Expensive</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Special method of separation by viperx (ACERVO DOS PLAYBACK) edited by CyberWaifu</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Process music with Demucs to get drums and bass.</span></p><p class="c1"><span class="c0">Process music with MDX to get vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Separate left and right channels of vocals.</span></p><p class="c1"><span class="c0">Process vocal channels through Zero-Shot with a noise sample from that channel.</span></p><p class="c1"><span class="c0">Phase invert Zero-Shot&#39;s output to the channel to remove the noise.</span></p><p class="c1"><span class="c0">Join the channels back together to get processed vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Invert the processed vocals to music to get the instrumental.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Separate left and right channels of instrumental.</span></p><p class="c1"><span class="c0">Process instrumental channels through Zero-Shot with a noise sample from that channel.</span></p><p class="c1"><span class="c0">Phase invert Zero-Shot&#39;s output to the channel to remove the noise.</span></p><p class="c1"><span class="c0">Join the channels back together to get processed instrumental.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Process instrumental with Demucs to get other.</span></p><p class="c1"><span class="c0">Combine other with drums and bass to get better instrumental.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So it sounds like Zero-Shot is being used for noise removal.</span></p><p class="c1"><span class="c0">As for how Zero-Shot and the noise sample works&hellip;</span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.p3wngakyrk0n"><span class="c42 c15 c22 c46 c30">AudioSep</span></h2><p class="c1"><span>&ldquo;I decided to try AudioSep: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Audio-AGI/AudioSep&amp;sa=D&amp;source=editors&amp;ust=1765035744288561&amp;usg=AOvVaw1Iq_URJCwZB39C9yaJLrcj">https://github.com/Audio-AGI/AudioSep</a></span><span class="c0">&nbsp;on MultiSong Dataset. </span></p><p class="c1"><span class="c0">I used prompt &#39;vocals&#39;. I was sure it would be bad, but I didn&#39;t think it&#39;s so bad.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/8408&amp;sa=D&amp;source=editors&amp;ust=1765035744288942&amp;usg=AOvVaw0_5JONaXPQIPiK_129O25w">https://mvsep.com/quality_checker/entry/8408</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I also tried it on the Guitar dataset - it&#39;s even worse - negative SDR. Maybe I&#39;m doing something wrong. But I tried the example with cat from the demo page, and it worked the same as in there. So I think I have no errors.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">sdr: 0.33</span></p><p class="c1"><span class="c0">si_sdr: -2.39</span></p><p class="c1"><span class="c0">l1_freq: 17.62</span></p><p class="c1"><span class="c0">log_wmse: 6.72</span></p><p class="c1"><span class="c0">aura_stft: 3.66</span></p><p class="c1"><span class="c0">aura_mrstft: 5.55</span></p><p class="c1"><span class="c0">bleedless: 9.29</span></p><p class="c1"><span class="c0">fullness: 16.58</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Colab on GH probably gives unpickiling issue. You might be able to fix it be executing:</span></p><p class="c1"><span class="c0">!pip install torch==2.5.0</span></p><p class="c1"><span class="c0">After you execute all the installation-related cells.</span></p><p class="c1"><span>Since then, probably something more about dependencies is also needed, like it &lsquo;s coded now in the inference Colab.</span></p><p class="c1 c7"><span class="c0"></span></p><h3 class="c67 c27" id="h.s4sjh68fo1sw"><span class="c19">Medley Vox (different voices)</span></h3><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Use already separated </span><span class="c4"><a class="c3" href="#h.n8ac32fhltgg">vocals</a></span><span>&nbsp;</span><span class="c0">as input (e.g. by Roformers, vox_ft or MDX23C fullband a.k.a. 1648 in UVR or 1666 on MVSEP).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Local installation video tutorial by Bas Curtiz:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/VbM4qp0VP80&amp;sa=D&amp;source=editors&amp;ust=1765035744291223&amp;usg=AOvVaw25zFen9B0xeR5i2ljF8tiJ">https://youtu.be/VbM4qp0VP8</a></span><span class="c0"><br>(NVIDIA GPU acceleration supported, or perhaps CPU - might be slow)</span></p><p class="c1 c7"><span class="c4 c42 c36 c33 c30"></span></p><p class="c1"><span class="c0">Cyrus version of MedleyVox Colab with chunking introduced, so you don&#39;t need to do chunking manually:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/10x8mkZmpqiu-oKAd8oBv_GSnZNKfa8r2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744291905&amp;usg=AOvVaw1uR-Ke57Lr_1znTJvyGf7y">https://colab.research.google.com/drive/10x8mkZmpqiu-oKAd8oBv_GSnZNKfa8r2?usp=sharing</a></span><span>&nbsp;(07.02.25 fork with fairseq fix and GDrive integration)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Currently, we have a duet/unison model 238 (default in Colab),</span></p><p class="c1"><span class="c0">and main/rest 138 to uncomment in Colab.</span></p><p class="c1"><span>Recommended model is </span><span>located in </span><span class="c0">vocals 238 folder (non ISR-net one).</span></p><p class="c1"><span class="c0">While:</span></p><p class="c1"><span class="c0">&ldquo;The ISR_net is basically just a different type of model that attempts to make audio super resolution and then separate it. I only trained it because that&#39;s what the paper&#39;s author did, but it gives worse results than just the normal fine-tuned.&rdquo;<br><br>MedleyVox is also available on MVSEP, but it has more bleeding and &ldquo;doesn&#39;t work as well as the Colab iteration with duets&rdquo;. (Isling/Ryanz)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The &quot;duet/unison model 238&quot; will be used by default.</span></p><p class="c1"><span class="c20">``and main/rest 138 to uncomment in Colab`` </span><span class="c0">if you need it.</span></p><p class="c1"><span>Then </span><span class="c0">go to the first cell again. To &quot;uncomment&quot; means to delete the &quot;#&quot; from the beginning of the line before the &quot;!wget&quot; so the line will be used to download the model files. </span></p><p class="c1"><span class="c0">Do it for both pth and json lines</span></p><p class="c1"><span class="c0">(you might be asked whether to replace existing pth and json files by the alternative model you just downloaded in the place of the previous one)</span></p><p class="c1"><span class="c6">``Recommended model is located in vocals 238 folder (non ISR-net one).``</span></p><p class="c1"><span class="c0">That&#39;s the model used in the Colab by default. You can ignore that information. It&#39;s for users using the MV on their own machine.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The output for 238 model is 24kHz sample rate (so 12kHz model in Spek).</span></p><p class="c1"><span>You might want to upscale the results using e.g. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.i7mm2bj53u07&amp;sa=D&amp;source=editors&amp;ust=1765035744294957&amp;usg=AOvVaw2ndZ3O2-9l-21w1JvpTG3d">AudioSR</a></span><span class="c0">&nbsp;or maybe even Lew&rsquo;s vocal enhancer location further below the linked section.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The output is mono.</span></p><p class="c1"><span class="c0">You might want to create a &quot;fake stereo&quot; as input by copying the same channel over the two, then do the same with another channel, and then create the stereo result from both channels processed separately in dual mono with MV.</span></p><p class="c1"><span class="c0">The AI will create a downmix from both input channels instead of processing channels separately.</span></p><p class="c1"><span>Be aware that &ldquo;dual mono processing with AI can often create incoherencies in stereo image (like the voice will be recognized in some part only in left channel and not the other, as they are processed independently)&rdquo; jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;The demos sound quite good (separating different voices, including harmonies or background [backing] vocals)&quot;</span></p><p class="c1"><span class="c0">It&#39;s for already separated or original acapellas.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The model is trained by Cyrus. The problem is, it was trained with 12kHz cutoff&hellip; &ldquo;audiosr does almost perfect job [with upscaling it] already, but the hugging page doesn&rsquo;t work with full songs, it runs out of memory pretty fast&rdquo;.</span></p><p class="c1"><span class="c0">It was possible at some point that later stages of the training, looking like over fitting were responsible for higher frequency output.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&rsquo;s sometimes already better than BVE models, and the model has already similar to demo results on their site.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sadly, the training code is extremely messy and broken, but a fork by Cyrus with instructions is planned, with releasing datasets including the one behind geo-lock. Datasets are huge and heavy.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Original repo (Vinctekan fixed it - the video at the top contains it)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jeonchangbin49/medleyvox&amp;sa=D&amp;source=editors&amp;ust=1765035744298069&amp;usg=AOvVaw3di1qRi7smZl8XbLL9CC8Z">https://github.com/jeonchangbin49/medleyvox</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">____</span></p><p class="c1"><span class="c6">Outdated</span></p><p class="c1"><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1StFd0QVZcv3Kn4V-DXeppMk8Zcbr5u5s?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744298577&amp;usg=AOvVaw3iEWa3orWrWBCHPnU2m75t">https://colab.research.google.com/drive/1StFd0QVZcv3Kn4V-DXeppMk8Zcbr5u5s?usp=sharing</a></span><span class="c0">&nbsp;(pip issues fixed 29.08.24, defunct as of 06.02.25)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(outdated instructions, current Colab explains everything)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;Run the 1st cell, upload song to folder infer_file, run the 2nd cell, get results from folder results = profit&rdquo;<br><br>Further explanations how to use the Colab:<br></span><span class="c6">``Run the 1st cell``</span></p><p class="c1"><span class="c0">So press the first &quot;play&quot; button then you load the Colab</span></p><p class="c1"><span class="c6">``upload song to folder infer_file``</span></p><p class="c1"><span class="c0">Looks like the folder for the input file has changed from infer_file to input in newer Colabs.</span></p><p class="c1"><span class="c0">So, once you started the first cell, and it finished, open Colab file manager (folder icon on the left) and go to /content/MedleyVox/input\</span></p><p class="c1"><span class="c0">Now paste your song there and wait till it&#39;s done.</span></p><p class="c1"><span class="c6">``run the 2nd cell``</span></p><p class="c1"><span class="c0">So the next play button below the first one once you scroll down a bit. Now it will start separation</span></p><p class="c1"><span class="c6">``get results from folder results``</span></p><p class="c1"><span class="c0">Go to file manager again and find /content/MedleyVox/results</span></p><p class="c1"><span class="c0">right-click on the result file and download it. Wait till it&#39;s done.</span></p><p class="c1"><span class="c6">``Currently, we have a duet/unison model 238 (default in Colab)``</span></p><p class="c1"><span class="c0">So you don&#39;t have to change anything in the Colab to separate using it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Old info</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/900904142669754399/1050444866464784384/Screenshot_81.jpg&amp;sa=D&amp;source=editors&amp;ust=1765035744301264&amp;usg=AOvVaw2ZoQx0kThq5QWabQtmE6a7">https://media.discordapp.net/attachments/900904142669754399/1050444866464784384/Screenshot_81.jpg</a></span><span class="c0">&nbsp;(dead)</span></p><p class="c1"><span class="c0">Colab old</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/17G3BPOPBPcwQdXwFiJGo0pKrz-kZ4SdU&amp;sa=D&amp;source=editors&amp;ust=1765035744301590&amp;usg=AOvVaw0FQM5tFgZmPFGB53si4QMW">https://colab.research.google.com/drive/17G3BPOPBPcwQdXwFiJGo0pKrz-kZ4SdU</a></span></p><p class="c1"><span class="c0">Older Colab</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1EHJFBSDd5QJH1FQV7z0pbDRvz8yXQvhk&amp;sa=D&amp;source=editors&amp;ust=1765035744301905&amp;usg=AOvVaw0LsSCIOxHfqyiUx-90AeRe">https://colab.research.google.com/drive/1EHJFBSDd5QJH1FQV7z0pbDRvz8yXQvhk</a></span></p><p class="c1"><span class="c0">(The same one, but here you need to change the .ckpt, .json and .pth files there from Cyrus [more details in the video above].)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">____________________________________________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.t7yszids7p1p"><span class="c18 c15">About other services:</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Check </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1-UTexxQpvZpxliGjcmRUDcnKSY-nikkNCqVDcq_0ROE/edit%23gid%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035744302701&amp;usg=AOvVaw23iG3tDlUxqXm0w06cK2eR">this</a></span><span class="c0">&nbsp;chart by Bas Curtiz to check what AIs use various (also online) services, plus their pricing.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">At this point everything mentioned above this link for at least instrumentals, vocals, 4-6 stems is better than below, (with exceptions for some single stems described at the top) commonly known services: &nbsp;</span></p><h6 class="c2 c27" id="h.eoh4mhmvzmrt"><span class="c0">Spleeter </span></h6><p class="c1"><span class="c6">and its implementation in: </span></p><h6 class="c2 c27" id="h.lmhpaip88xjn"><span class="c0">Izotope RX-8/9/10 </span></h6><p class="c1"><span class="c6">which just uses 22kHz models instead of 16kHz in the original Spleeter. There is no point in using these anymore. The same goes to most AIs described below (or only for specific stems):</span></p><p class="c2"><span class="c6">voiceremover.org, lalal.ai, </span></p><h6 class="c2 c27" id="h.colcze2vgkha"><span class="c0">phonicmind</span></h6><h6 class="c2 c27" id="h.wttisf5ujyf1"><span class="c0">melody.ml</span></h6><p class="c2"><span class="c6">RipX, Demix, </span></p><h6 class="c2 c27" id="h.76t56x1587z5"><span class="c0">ByteDance Ripple/CapCut</span></h6><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://beatstorapon.com/ai-stem-splitter&amp;sa=D&amp;source=editors&amp;ust=1765035744304408&amp;usg=AOvVaw0WJjGOpwZwpgf-rgpXCQUO">beatstorapon</a></span></p><h6 class="c2 c27 c7" id="h.fajb76bqeukr"><span class="c0"></span></h6><p class="c1"><span>For reference, you can check a </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/leaderboard.php?sort%3Dinsrum&amp;sa=D&amp;source=editors&amp;ust=1765035744304677&amp;usg=AOvVaw0Idu7WQRXIHnXaGhoqmppS">comparison</a></span><span class="c0">&nbsp;chart on MVSEP.com, </span></p><p class="c1"><span>or results of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021/leaderboards?challenge_leaderboard_extra_id%3D869%26challenge_round_id%3D886%26post_challenge%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035744304967&amp;usg=AOvVaw0DDCg6VFHYDX2BvGWuYgEH">demixing challenge</a></span><span class="c0">&nbsp;from Sony (kimberley_jensen there is 9.7 MDX-UVR model for vocals - 2nd best on the time) </span></p><p class="c1"><span>and watch </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/gl5AKCgMSSc&amp;sa=D&amp;source=editors&amp;ust=1765035744305221&amp;usg=AOvVaw2PRsXIuQe0SvxxQYAqy_AD">this</a></span><span class="c0">&nbsp;comparison. </span></p><p class="c1"><span>To hear 4 stems models comparison samples you can watch </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/gl5AKCgMSSc&amp;sa=D&amp;source=editors&amp;ust=1765035744305425&amp;usg=AOvVaw3-yF8kVaMn8fRtUNDq3djU">this</a></span><span class="c0">&nbsp;video comparison (December 2022).</span></p><p class="c1"><span class="c0">It all also refers to new:</span></p><h3 class="c27 c35" id="h.z0rg2bewgfed"><span class="c19">real-time </span></h3><p class="c1"><span class="c0">AI separation tools like </span></p><h6 class="c2 c27" id="h.920bb96xiyga"><span class="c0">Serato </span></h6><p class="c1"><span class="c0">and </span></p><h6 class="c2 c27" id="h.ko20o19wn5vp"><span class="c0">Stems 2.0 </span></h6><p class="c1"><span class="c0">tensorflow model (which can be found in newer Virtual DJ 2023 versions, now free for home users - better than Serato and Spleeter implementations) - they do not perform better than the best offline solutions at the very top of the document. But &ldquo;Esp. since it&#39;s on-the-fly [...] results are more than decent (compared to others).&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.mj9frri60cqr"><span class="c0">Acon Digital Remix</span></h6><p class="c2"><span class="c0">(Vocals, Piano, Bass, Drums, and Other)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Just listened to the demo, not great [as for realtime] but still&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Others</span></p><h5 class="c59 c27" id="h.oe4d2kewoelf"><span class="c42 c36 c51 c33 c24 c30">FL Studio (Demucs)</span></h5><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span>It&rsquo;s actually not realtime. It takes some time to process tracks first (hence maybe it&rsquo;s the best out of the three).</span></p><p class="c1"><span class="c0">It&#39;s Demucs 4, but maybe not ft model and/or with low parameters applied or/and it&#39;s their own model.</span></p><p class="c1"><span class="c0">&quot;Nothing spectacular, but not bad.&quot;</span></p><p class="c1"><span class="c0">&quot;- FL Studio bleeds beats, just like Demucs 4 FT</span></p><p class="c1"><span class="c0">- FL Studio sounds worse than Demucs 4 FT</span></p><p class="c1"><span class="c0">- Ripple clearly wins&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c27 c59" id="h.nwn5kvxpih0v"><span class="c42 c36 c51 c33 c24 c30">djay Pro 5.x </span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;very good realtime stems with low CPU&rdquo; Allegedly &ldquo;faster and better than Demucs, similar&rdquo; although &ldquo;They are not realtime, they are buffered and cached.&rdquo; but it&rsquo;s very fast anyway. It uses AudioShake. It can be better for instrumentals than UVR at times.</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.c3if8ih1yxff"><span class="c42 c36 c51 c33 c24 c30">Neutone VST </span></h5><p class="c1"><span>Has</span><span class="c0">&nbsp;Demucs model to use in realtime in a DAW</span></p><p class="c1"><span class="c0">(it uses light &ldquo;retrained, smaller version&rdquo; version of Demucs_mmi)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://neutone.space/&amp;sa=D&amp;source=editors&amp;ust=1765035744308913&amp;usg=AOvVaw0jfHgHdAfaOtoKpoQyNByr">https://neutone.space/</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://neutone.space/models/1a36cd599cd0c44ec7ccb63e77fe8efc/&amp;sa=D&amp;source=editors&amp;ust=1765035744309151&amp;usg=AOvVaw09fK4kq1srk_CFcUKPLJjG">https://neutone.space/models/1a36cd599cd0c44ec7ccb63e77fe8efc/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It doesn&#39;t use GPU, and it&#39;s configured to be fast with very low parameters, also the model is not the best on its own. It doesn&#39;t give decent results, so it&#39;s better to stick to other real-time alternatives. It won&rsquo;t work correctly on low-end CPU, breaking audio in the middle and giving inconsistent audio stream with breaks.</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.xromiy6cs60w"><span>Peel Stems</span></h5><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://products.zplane.de/products/peelstems/&amp;sa=D&amp;source=editors&amp;ust=1765035744310090&amp;usg=AOvVaw2q0HSIMkgvMJlzKvDeBzyJ">https://products.zplane.de/products/peelstems/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VST for real time source separation (probably same models like in MPC stems)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D0Js5bWQWY7M&amp;sa=D&amp;source=editors&amp;ust=1765035744310613&amp;usg=AOvVaw3CYLvCHo56MVwdej8RYDGf">https://www.youtube.com/watch?v=0Js5bWQWY7M</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Service rebranded to </span></p><h4 class="c17" id="h.4r74hvaiyeik"><span class="c21">Fadr.com from SongtoStems.com</span></h4><p class="c1"><span class="c0">is just Demucs 4 HT, but paid.</span></p><p class="c1"><span class="c0">&quot;My assumption, Fadr uses Gain Normalize [for instrumentals] was right [...].</span></p><p class="c1"><span class="c0">Demucs 4 HT seems to get a cleaner result. The rest = practically identical.&quot; And someone even said that vocals in VirtualDJ with Stems 2.0 had less artifacts on vocals.</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.kbxqqeby51dw"><span class="c21">Apple Music Sing</span></h4><p class="c1"><span class="c0">&ldquo;I heard a few snippets, and what stood out is, whether intentional or not, the vocals remained in the background just enough to actually hear them.</span></p><p class="c1"><span class="c0">Now that could be great for Karaoke, so u have a kind of lead to go on.&rdquo; but as for just instrumentals, it&rsquo;s bad.</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.pjbty7b7dg1h"><span class="c21">Voxless</span></h4><p class="c1"><span class="c0">VST &ldquo;uses AI to separate vocals and instrumental in real time. Now it is designed to be used in a DAW, but you can also run it in soundsource [on Mac, or probably SAVIHost (VST2/3) or Equalizer APO (VST3) or JBridge on Windows] so you can use it on your system audio live. It has low latency and doesn&#39;t use CPU a lot. The software has a very simple interface, just two knobs to increase/ decrease the instrumental or vocals or a mute/solo button for each. As for the quality it sounds like the first ever days of audio separation with AI like Demucs v1 or Spleeter in 2019 - 2020 but a little worse somehow, since it is very low latency not CPU heavy, but it does the job. Voxless has a trial of 7 days if you wanna check it but the license costs 100$ which I think is quite a lot for a software that separates vocals with barely first gen quality.&rdquo; midol</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.y7vtqnie350l"><span class="c21">Ozone 11 Master Rebalance</span></h4><p class="c1"><span class="c0">&ldquo;I select vocals and have them dialed down to max using an EQ inside of it (may sound complicated, so you gotta watch a tutorial to see how ozone works). However, the results were far from voxless quality. It leaves so much bleed and whenever vocals are quite loud you can barely hear anything from the way it&#39;s fighting it, so it sounds like a complete mess. Both from the master rebalance and the main AI interface&rdquo; midol</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(x) BL-Rebalance</span></p><p class="c1"><span class="c0">&ldquo;The most important thing which is the separation quality, is horrible unfortunately, dialing the vocals all the way down to -120db the max, barely picks up vocals to cancel, the song sounds like it&#39;s just playing normally with vocals being suppressed in a very horrible way, it&#39;s muddy, and it leaves a lot of bleed, also again, when vocals are quite loud, you barely hear anything else because it&#39;s fighting hard.&rdquo; midol</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">algoriddim djay</span></p><p class="c1"><span class="c0">App for Windows, Android, Mac.</span></p><p class="c1"><span>Judging by strings in stemseparation.dll, they seem to use &ldquo;bytesep&rdquo; which is a package name of this repository: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/bytedance/music_source_separation&amp;sa=D&amp;source=editors&amp;ust=1765035744316057&amp;usg=AOvVaw2ELgJnEt8bcyDFLpytRPUN">bytedance/music_source_separation</a></span><span>.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">____________________________________________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c27 c57" id="h.zd7m35sh6zri"><span class="c21">Music to MIDI transcribers/converters</span></h4><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/magenta/mt3&amp;sa=D&amp;source=editors&amp;ust=1765035744316770&amp;usg=AOvVaw1BaV6xx2ckdKlKTbdjCHKs">https://github.com/magenta/mt3</a></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/magenta/mt3/blob/main/mt3/colab/music_transcription_with_transformers.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744317124&amp;usg=AOvVaw3hN9zs7DZQQkD9qpI2AQ_T">https://colab.research.google.com/github/magenta/mt3/blob/main/mt3/colab/music_transcription_with_transformers.ipynb</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://basicpitch.spotify.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744317367&amp;usg=AOvVaw2vTxTTGqkSyu9qd6iEzNtL">https://basicpitch.spotify.com/</a></span></p><p class="c2"><span class="c0">&ldquo;Tried Basic-Pitch and It is way worse than MT3 as It produces midi tracks without an identifier.&rdquo;</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span>Good results for piano:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/notebooks/magenta/onsets_frames_transcription/onsets_frames_transcription.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744318039&amp;usg=AOvVaw060FQm2U9oPitf7DmkRJxE">https://colab.research.google.com/notebooks/magenta/onsets_frames_transcription/onsets_frames_transcription.ipynb</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">If you have notes:</span></p><p class="c2"><span class="c0">musescore</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Yujia-Yan/Transkun&amp;sa=D&amp;source=editors&amp;ust=1765035744318348&amp;usg=AOvVaw0rF_vKrzxhxC00AADJ6PuB">transkun</a></span><span class="c0">&nbsp;transcriber <br>&ldquo;it&#39;s the most accurate piano transcription algorithm ever trained and is unequalled in accuracy and absolute indifference to literally *any audio quality*</span></p><p class="c2"><span class="c0">as long as the piano being transcribed is at A440 it&#39;ll spit out a 95 percent accurate transcription from virtually any recording no matter how absolute garbage it is&rdquo;</span></p><p class="c2 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.6xxrbp51to9n"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://klang.io/piano2notes/&amp;sa=D&amp;source=editors&amp;ust=1765035744319216&amp;usg=AOvVaw1Jhjx1sSwW0N5nPIeYIocF">Piano2Notes</a></span></h4><p class="c2"><span class="c0">(notes and midi output, paid, 30 seconds for free, very good results)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c22">Harmonic mixing </span><span class="c0">(find the song key)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Since mixed in key change from 10 to 11 the software has several failures especially when overwriting the file name and an error that base 84 error, and you are left without the analysis of the file thing. Which is essential when doing remixes and having a clarity of the tone and bpm. Someone knows of an alternative that does not make a mistake&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.reddit.com/r/DJs/comments/n5byah/key_detection_comparison_mixed_in_key_10_vs_85/&amp;sa=D&amp;source=editors&amp;ust=1765035744320608&amp;usg=AOvVaw1kssY8LA0CZKYNajX3uhqq">https://www.reddit.com/r/DJs/comments/n5byah/key_detection_comparison_mixed_in_key_10_vs_85/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">__________</span></p><p class="c2"><span class="c0">Older separation services</span></p><p class="c2 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.tc4az79fufkn"><span class="c21">Audioshake</span></h4><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Paid, $16 per wav stem, 2 or 5 stems (6? (guitar and piano) or 4 stems for preview (Indie creators)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Better piano model than GSEP.</span></p><p class="c2"><span class="c0">&quot;gsep piano model is very clean but sometimes fails in bigger mix, when there are a lot of instruments&quot;</span></p><p class="c2"><span class="c0">And also guitar stem </span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Instead of Audioshake you can use: </span></p><p class="c2"><span class="c0">- myxt.com (also paid, 3 stem model, prob. 16kHz cutoff which Audioshake normally doesn&#39;t have. No other stem. Results, maybe slightly better than Demucs)</span></p><p class="c2"><span class="c0">- Algoriddim djay pro </span></p><p class="c2"><span>- &nbsp;Neural Mix Pro (part of Algoriddim, also uses Audioshake), but it&rsquo;s only for MacOS<br>- LANDR Stems (cheaper, also </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.audioshake.ai/press-releases/landr-introduces-landr-stems-plugin-powered-by-audioshakes-award-winning-ai-technology&amp;sa=D&amp;source=editors&amp;ust=1765035744322417&amp;usg=AOvVaw3sWR6F8Fwu71vyM28cXkpO">uses</a></span><span>&nbsp;Audioshake; plugin, probably doesn&rsquo;t work locally, free access won&rsquo;t give you access to stems; &ldquo;LANDR Stems is only included in Studio Standard + Studio Pro&rdquo; it&rsquo;s not included in trial; SDR: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7603&amp;sa=D&amp;source=editors&amp;ust=1765035744322822&amp;usg=AOvVaw3AS8M3EuHCzpKlOy2idP_S">1</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/7602&amp;sa=D&amp;source=editors&amp;ust=1765035744322943&amp;usg=AOvVaw1tTv19_YiSsj0AxEVOiG2u">2</a></span><span class="c0">)</span></p><p class="c2"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://twoshot.app/model/289&amp;sa=D&amp;source=editors&amp;ust=1765035744323128&amp;usg=AOvVaw1qERYFv_dLW8bictky9fpS">https://twoshot.app/model/289</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Audioshake is suspected that it is just MDX with expanded dataset, but there&rsquo;s no evidence at the moment. Comparing to UVR/MDX-UVR NET 1 model, vocal stem is 9.793 vs 9.702 in free MDX-UVR, so they&rsquo;re close as for vocals.</span></p><p class="c2"><span class="c0">Their researcher said they were training UMXHQ model at this period of time of 2020 Demixing Challenge.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span>Free Demucs 3 has a much better SDR for drums and bass than Audioshake, however the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708912656370630717/952035316754174002/unknown.png&amp;sa=D&amp;source=editors&amp;ust=1765035744324250&amp;usg=AOvVaw1lFiIhmShzxQC9Zh9OB03H">SDR</a></span><span class="c0">&nbsp;for vocals and others is worse.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It accepts only non-copyrighted music for separations, but you can slow it down to circumvent it (some music like K-Pop BTS is not detected) but changing speed to 110% yields better results, even vs reversing the track.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Upload limit is one minute, so theoretically you can cut and merge chunks, but AS will fade out each chunk, so you need to find specific overhead to begin every next chunk with, to merge chunks seamlessly (I don&rsquo;t remember if it solves the problem of AS watermark, though).</span></p><p class="c1"><span class="c0">Then, you can download preview (chunk) for free using similar method like described in allflac section (Chrome Dev Tools -&gt; Network -&gt; Set filter to amazon) but result file is unfortunately only 128kbps mp3.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">They are now limiting how many audio files you can upload to preview, but that can easily be mitigated by just using a temporary email provider or adding &ldquo;+1&rdquo; or &ldquo;+2&rdquo; or &ldquo;.&rdquo; to your gmail address, so you will still receive your email e.g. y.o.u.r.m.a.i.l.@gmail.com is the same for Google as yourmail@gmail.com.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">You can also ping Smudge, Baul Plart or Bas Curtiz in #request-separation to isolate some song to make this all easily just for you (edit. 09.02.2023 - at least the Bas&rsquo; tool stopped working, so the rest like AS Tool might be dead too - at least in terms of API access, not sure).</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.51dyuze5xz9o"><span class="c21">Lalal.ai</span></h4><p class="c2"><span class="c0">7 stem</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Acoustic and electric guitar models, piano, bass, drums and vocal with instrumental (for 2 stem UVR/MDX should do the job better)</span></p><p class="c1"><span class="c0">Online service with 10 minutes/50MB per file limitation per free user.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Now they have some voc/inst models sounding like some ensemble of public Roformers, but still not as good, but close. Some specific models are worth trying out, e.g. lead guitars - the model got better by the time or piano model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Older notes:</span></p><p class="c1"><span class="c0">&ldquo;I love Demucs 3, although for some specific songs (with a lot of percussion and loops) I still find lalal better.</span></p><p class="c1"><span class="c0">Demucs is great at keeping punchy drums, for example hip-hop, rap, house etc songs&rdquo; </span></p><p class="c1"><span class="c0">&ldquo;lalal is[n&rsquo;t] worth it anymore, most of their models like strings or synths are crap and don&#39;t work at all&rdquo; ~becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">How to&hellip; abuse it. Doesn&#39;t always work for everyone, and sometimes you&#39;ll receive only 19 seconds snippets.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Go to the signin/register screen and use a temp email from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tempail.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744328956&amp;usg=AOvVaw1Z9c8mdMDgYaNpfcOQwklG">https://tempail.com/</a></span></p><p class="c1"><span class="c0">When you are in, make sure you use the settings with a P icon, P meaning Pheonix, which seems to be some hybrid mvsep lalal shit they made</span></p><p class="c1"><span class="c0">I&#39;d recommend making the processesing level normal, although you can play around with the settings to see what sounds better</span></p><p class="c1"><span class="c0">They will later process it and since lalal has shorter queues, you get them faster. It took me like 10 seconds to get a preview for a song and 20 seconds for full which is wild.</span></p><p class="c1"><span class="c0">You will get a sample and if you like it, you can submit it and get your stems!&quot;</span></p><p class="c1"><span class="c0">You can also use dots in Gmail addresses, instead of +1 (and more) at the end, which is unsupported in lalal. You&#39;ll receive your email with dots in its username anyway, and it will be treated as a separate email by their system.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Their app uploads input files to separate on external servers.</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.4yn6zawn80la"><span class="c21">DeMIX Pro V3</span></h4><p class="c2"><span class="c0">Paid, 6 stem model, trial</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Official site:</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.audiosourcere.com/demix-pro-audio-separation-software/&amp;sa=D&amp;source=editors&amp;ust=1765035744331198&amp;usg=AOvVaw3W2l_YBwX8XSok-H1aSZA7">https://www.audiosourcere.com/demix-pro-audio-separation-software/</a></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.demixer.com/?utm_source%3Daudiosourcere%26utm_medium%3Dpop%26utm_campaign%3Dexit%26utm_term%3Dasre-exit-pop&amp;sa=D&amp;source=editors&amp;ust=1765035744331528&amp;usg=AOvVaw2EpyeeC7UA4ETky1_zwf9m">https://www.demixer.com/?utm_source=audiosourcere&amp;utm_medium=pop&amp;utm_campaign=exit&amp;utm_term=asre-exit-pop</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">paid 33$/month, or x10 for year, or x2,5 permanent license, 7 days trial available</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.audiosourcere.com/demix-pro-audio-separation-software/&amp;sa=D&amp;source=editors&amp;ust=1765035744332041&amp;usg=AOvVaw1lbIeFPRod9buFmuFyP_3o">https://www.audiosourcere.com/demix-pro-audio-separation-software/</a></span></p><p class="c2"><span class="c0">Vocal, Lead Vocal, Drum, Bass &amp; Electric Guitar </span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.demixer.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744332331&amp;usg=AOvVaw1ogWv_d4ZLy-o34shSbZij">https://www.demixer.com/</a></span><span>&nbsp;has the same models implemented, though they don&rsquo;t currently even describe that guitar model is available, but when you log in, it&rsquo;s </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/p6WCzoD&amp;sa=D&amp;source=editors&amp;ust=1765035744332640&amp;usg=AOvVaw0tad8a3Wx_5h13HLzZO04R">there</a></span><span class="c0">. Guitar might be a bit worse than RipX (not confirmed)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">&ldquo;audioshake [had] the best guitar model [at some point] (its combined [paid only]), second place is deemix pro (electric guitar)&rdquo;</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">&quot;Demix launched a new v4 beta, and it can now process songs locally + new piano and strings models</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">the piano model is not bad at all, it sounds a bit thin/weak, but it detects almost all notes</span></p><p class="c2"><span class="c0">hadn&#39;t found good songs to test the strings model yet, but it might be good too&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.bf9sv6h9xjaz"><span class="c4"><a class="c3" href="#h.1bm9wmdv6hpf">Hit&#39;n&#39;Mix RipX DeepAudio</a></span></h4><p class="c2 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.x7qk80tje220"><span class="c21">Moises.ai</span></h4><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://moises.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035744334205&amp;usg=AOvVaw2CnpG0h0ShMC9Sm71QdtB_">https://moises.ai/</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Not really a good models before introduing BS-Roformer ones, no previews for premium features.</span></p><p class="c2"><span class="c0">You can use apk when it allows previewing for free without downloading, but isling found some workaround googling for &ldquo;moises premium free apk&rdquo;.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Some information here might be outdated.</span></p><p class="c1"><span class="c0">&ldquo;also has a guitar and a b.v. model, and a new strings model, but it&#39;s not that good, in my opinion it is not worth buying a premium account.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4-STEM model is something like demucs v2 or demixer.</span></p><p class="c1"><span class="c0">B.V. model is worse than the old UVR b.v..</span></p><p class="c1"><span class="c0">GUITAR model is not really good, it&#39;s probably MDX, it has a weird noise, and it tries to take the &quot;guitar&quot; where is not at all. It takes acoustic and electric guitar together.</span></p><p class="c1"><span class="c0">PIANO model is just splitter, maybe better at some songs.</span></p><p class="c1"><span class="c0">STRINGS model is interesting, It&#39;s good for songs with orchestra, but still not that clean</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Their service is very interesting, and the appearance of their site is clear and simple, but the models have better competitors.&rdquo; thx, sahlofolina.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Byte Dance</span></p><p class="c2"><span>available on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744336496&amp;usg=AOvVaw1LGWx-vyKQGexSeiAXIW3V">https://mvsep.com/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">&ldquo;This algorithm took second place in the vocals category on Leaderboard A in the Sony Music Demixing Challenge. It&#39;s trained only on the MUSDB18HQ data and has potential in the future if more training data is added.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Quality metrics are available here (SDR evaluated by his authorship non-aircrowd method):</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality.php&amp;sa=D&amp;source=editors&amp;ust=1765035744337321&amp;usg=AOvVaw3Qhak0B4c9zpzcMk-pHSA2">https://mvsep.com/quality.php</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span>Demos for Byte Dance: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/demo.php?algo%3D16&amp;sa=D&amp;source=editors&amp;ust=1765035744337583&amp;usg=AOvVaw2kdOzzl_SEZgGnhA8d2kpZ">https://mvsep.com/demo.php?algo=16</a></span><span class="c0">&nbsp;&ldquo;</span></p><p class="c2"><span class="c0">(8.08 SDR aicrowd for vocal)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">MDX-UVR SDR vocal models (kimberley_jensen a.k.a. KimberleyJSN) were evaluated by the same dataset as ByteDance above (aircrowd):</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021/leaderboards?challenge_round_id%3D886%26challenge_leaderboard_extra_id%3D869%26post_challenge%3Dtrue&amp;sa=D&amp;source=editors&amp;ust=1765035744338429&amp;usg=AOvVaw0mNXWACRJhP-QG0oJ_v_S8">https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021/leaderboards?challenge_round_id=886&amp;challenge_leaderboard_extra_id=869&amp;post_challenge=true</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/887455924845944873/910677893489770536&amp;sa=D&amp;source=editors&amp;ust=1765035744338803&amp;usg=AOvVaw2La_HF6G8f2hMJsRvtkOXT">https://discord.com/channels/708579735583588363/887455924845944873/910677893489770536</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c0">and presumably the same goes to GSEP and their very first vocal model (10 SDR) since their chart showed the same ByteDance SDR score like in aircrowd.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.ia9bwo45sm2l"><span class="c0">___UVR settings for ensemble (section deprecated, see the section above)__</span></h6><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ensemble can provide different results from one current main model, but not especially better in all cases, so it&rsquo;s also a matter of taste and conscious evaluation.</span></p><p class="c2 c7"><span class="c0"></span></p><ul class="c9 lst-kix_7vaamq35f1cc-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Aggressiveness shouldn&rsquo;t be set to more than 0.1</span></li></ul><p class="c1 c8"><span class="c0">(also check 0.01)</span></p><ul class="c9 lst-kix_7vaamq35f1cc-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">high_end_process: bypass (official recommendation) or mirroring 2 (in some cases)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">In most cases, you shouldn&rsquo;t use more than 4 models to not decrease the quality (developer recommendation)</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Don&#39;t use postprocessing in HV Colab for ensemble (doesn&#39;t work).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Other recommended models for ensemble: </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">HP2-4BAND-3090_4band_arch-500m_1.pth, </span></p><p class="c1"><span class="c0">HP2-4BAND-3090_4band_arch-500m_2.pth</span></p><p class="c1"><span class="c0">(+new 3 band?)</span></p><p class="c1"><span class="c0">as they currently the best (15.08.21) but feel free to experiment with more (I also used old MGM beta 1 and 2 with two above, </span></p><p class="c1"><span class="c0">some people used also vocal models as well, and later there was also HP2-MAIN-MSB2-3BAND-3090_arch-500m model released, which gives good results solo).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.jcnv77e62k2s"><span class="c0">___Good UVR accapella models______</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In general, it&rsquo;s better to use MDX-UVR models for clean acappellas, but for UVR, these are going to be your best bet:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Vocal_HP_4BAND_3090 - This model with come out with less instrumental bleed.</span></p><p class="c1"><span class="c0">- Vocal_HP_4BAND_3090_AGG - This is a more aggressive version of the vocal model above. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;If you wanna removes the vocals but keeping the backing vocals, you can use the latest BV model&rdquo; </span></p><p class="c1"><span class="c0">HP-KAROKEE-MSB2-3BAND-3090.pth</span></p><p class="c1"><span class="c0">(HV)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For clean vocal, you can also use ensemble with following models:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/767947630403387393/897512785536241735/unknown.png&amp;sa=D&amp;source=editors&amp;ust=1765035744343506&amp;usg=AOvVaw3NY3ZEDjJJB4edFG4v2Myg">https://cdn.discordapp.com/attachments/767947630403387393/897512785536241735/unknown.png</a></span></p><p class="c1"><span>(REUim2005)</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.krccq343z6z9"><span class="c0">__How to remove artefacts from an inverted acapella?_____</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>This section is old, and &ldquo;cleaning inverts&rdquo; in </span><span class="c4"><a class="c3" href="#h.rz0d5zk9ms4w">current models</a></span><span class="c0">&nbsp;section can provide more up-to date solutions.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; 0) Currently, GSEP is said to be the best in cleaning inverts. But at least for vocal you can use some MDX model like Kim, or even better MDX23 from MVSEP beta.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><ol class="c9 lst-kix_d1gy3hy5r3qj-0 start" start="1"><li class="c1 c25 c8 li-bullet-0"><span class="c0">by charm</span></li></ol><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(rather outdated) Use Vocal_HP_4BAND_3090_arch-124m.pth at 0.5 aggressiveness, tta enabled</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">then use any model u like with Vocal_HP_4BAND_3090_arch-124m.pth instrumental results to filter out any vocals that weren&#39;t detected as vocals with Vocal_HP_4BAND_3090_arch-124m.pth model</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">combine the two results</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">then use model ensemble with whatever models u like (i used HP2 4BAND 1 and 2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">drag both vocal hp 4band+another model and ensemble results into audacity</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">use the amplify effect on both tracks and set it to -6.03</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">render</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">then use StackedMGM_MM_v4_1band_arch-default.pth</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">tbh vocal models even at 0 aggressiveness really help inverts</span></p><p class="c1"><span class="c0">Or 0.3</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I mostly use acapellas for mashups and remixes, so the little bit of bleed i get at 0.0 aggressiveness is fine</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">drums-4BAND-3090_4band.pth</span></p><p class="c1"><span class="c0">0.5 optionally (less metallic sound)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2) </span></p><h6 class="c2 c27" id="h.8vosdwb10mjo"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1_QabafcnbEUOSbmL6J3JDtNS7Da9V06m/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744346962&amp;usg=AOvVaw1gCnD-adho7FZEosF-1onZ">Utagoe</a></span><span class="c0">&nbsp;(English version with guide and error messages translated by Anjok) - if the invert isn&#39;t good, then try utagoe, but it&rsquo;s not the best.</span></h6><p class="c1 c62 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Settings for Utagoe by HV:</span></p><p class="c1"><span class="c0">&ldquo;if your tracks don&#39;t invert perfectly&rdquo; (even when aligned)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/uuuJ7Ws&amp;sa=D&amp;source=editors&amp;ust=1765035744347645&amp;usg=AOvVaw2_GgsVp9N_qZBmv5GV4duE">https://imgur.com/a/ZC14xlE</a></span></p><p class="c1"><span class="c0">&ldquo;if it&#39;s perfectly inverting&rdquo;:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/Qb4pKeX&amp;sa=D&amp;source=editors&amp;ust=1765035744347875&amp;usg=AOvVaw0o9j2KwVmB1Y2lHyTVeNnT">https://imgur.com/a/Qb4pKeX</a></span></p><p class="c1"><span class="c0">Some other settings:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/fvQwbMO&amp;sa=D&amp;source=editors&amp;ust=1765035744348118&amp;usg=AOvVaw1cDernYX_NZ7pxUr-GgHK4">https://imgur.com/a/fvQwbMO</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;It has a weird issue sometimes tho, even when everything is perfectly aligned and inverts perfectly, utagoe misses some places, and it won&rsquo;t insert for a second or so&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">by Mixmasher00</span></p><p class="c1"><span class="c0">&ldquo;There is no actually settings depending on songs, but that is what I use, which is the default one. </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/kSDrTAB&amp;sa=D&amp;source=editors&amp;ust=1765035744348869&amp;usg=AOvVaw3nz1QUptb1qaHpniXUC8Mu">https://imgur.com/a/kSDrTAB</a></span></p><p class="c1"><span class="c0">Going higher than 1.3 [of extractable level] imo won&#39;t do good at cleaning. Additional tip too, if you want to do just an &quot;invert&quot; and &quot;keep the original vocal volume&quot; just choose &quot;by waveform&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I have been using Utagoe for inversions recently because it keeps the original volume of the vocals, and then I ran it on UVR or MDX. If the chunks are soft, I prefer using UVR but if there are chunks are that heavy like drums, I&#39;d use MDX.</span></p><p class="c1"><span class="c0">Also, I find it better to clean an invert via UVR or MDX than Utagoe because it&#39;s better and cleaner without destroying the vocals&ldquo; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;When using Utagoe, or UVR5, for aligning inputs, and inverting them, I get this really strange cracking noise, that not even doing a vocal separation with AI later can get rid of. Anyone know what could possibly be causing this?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So, I actually found a solution to this, for anyone running into a similar issue.</span></p><p class="c1"><span class="c0">With inversions like this, you&#39;re already gonna have to use AI to get rid of the left over noise, since it&#39;s not gonna be a perfect inversion. So, the solution isn&#39;t to get a perfect one, it&#39;s simply to get rid of the noise that the AI cannot recognize, right?</span></p><p class="c1"><span class="c0">With this particular inversion, I originally was using really compressed MP3s from around 2007 for the instrumentals, because the lossless versions of the instrumentals were lost media, up until a few months ago.</span></p><p class="c1"><span class="c0">I thought it was odd, because i don&#39;t remember this noise being an issue with the MP3s, and that&#39;s when it hit me, MP3s cut off the noise, with compression, and added just a small bit more of that noise you get with imperfect inversions. </span></p><p class="c1"><span class="c0">So I converted the lossless instrumentals to an MP3 with Foobar, and it was better, but still had that damned drum crackling! So i kept trying. I used OPUS, OGG, different bitrates of MP3, even AAC. </span></p><p class="c1"><span class="c0">I have found that OPUS is the best at removing the drum overlap, I cannot hear any in fact, with OPUS.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So, my final guide is, </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you are getting cracking/crackling/overlap on drum hits in your inversions, then:</span></p><p class="c1 c7"><span class="c0"></span></p><ol class="c9 lst-kix_xktbtduo53bq-0 start" start="1"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Convert the instrumental to OPUS (128 Kbps) with Foobar2000.</span></li></ol><p class="c1 c7"><span class="c0"></span></p><ol class="c9 lst-kix_xktbtduo53bq-0" start="2"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Use a software like Audacity to amplify it to a peak amplitude zero DB (since apparently OPUS auto declips to floating levels?) </span></li></ol><p class="c1 c7"><span class="c0"></span></p><ol class="c9 lst-kix_xktbtduo53bq-0" start="3"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Export it as a WAV at the original sample rate (since OPUS only supports 48 kHz, I actually tried resampling the instrumental, and original to 48 kHz before converting to OPUS, but found that results in a WORST output.) </span></li></ol><p class="c1 c7"><span class="c0"></span></p><ol class="c9 lst-kix_xktbtduo53bq-0" start="4"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Do your inversion (hopefully in Utagoe) </span></li></ol><p class="c1 c7"><span class="c0"></span></p><ol class="c9 lst-kix_xktbtduo53bq-0" start="5"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Use whichever vocal model you like the output for best for cleanup.&rdquo; - sausum</span></li></ol><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">PS. Once, I&#39;ve runned into similar issue. And I fixed it, actually similarly. I think I was trying to invert with mp3 VBR, and the other file was lossless, so I converted it to the same codec and bitrate/V preset.</span></p><p class="c1"><span class="c0">Yes, it wasn&#39;t perfect, but better.</span></p><p class="c1"><span class="c0">I wonder if simply applying cutoff at 20kHz wouldn&#39;t be a better solution. That&#39;s what Opus more or less does, plus upsampling to 48kHz. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Despite the fact that separation is in 32 bit float, align inputs option in UVR uses something lower internally, hence the clipping may occur.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- As better alternative to Utagoe and UVR&rsquo;s Align feature, you can use paid Auto Align Post 2 (maybe even cheaper MAutoAlign).</span></p><h6 class="c2 c27 c7" id="h.qgxgl8e0ybyj"><span class="c0"></span></h6><h2 class="c29 c27" id="h.nspwy0bkpiec"><span class="c42 c15 c22 c46 c30">__Sources of FLACs for the best quality for separation process__</span></h2><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Introduction</span></p><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_tvu7bmfefz32-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Don&rsquo;t use YouTube or mp3 as input files for separation. Compression decreases the quality of the output</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">If you&#39;re forced to use YT, download audio, preferably as Opus if it&#39;s available for your video, and it exceeds 16kHz on spectrogram (AAC might be better up to 16kHz).</span></li><li class="c1 c25 c8 li-bullet-0"><span>To enhance results from YT by combining Opus and AAC </span><span class="c4"><a class="c3" href="#h.6543hhocnmmy">read</a></span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">If you want to verify if your input file is really lossless: </span></li></ul><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://fakinthefunk.net/en&amp;sa=D&amp;source=editors&amp;ust=1765035744357234&amp;usg=AOvVaw2ksMnyIKK9u18cCrD5phwh">https://fakinthefunk.net/en</a></span><span class="c0">&nbsp;(sometimes streaming services share bad/lossy versions)</span></p><ul class="c9 lst-kix_kp4gb6sd08f1-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">If you want to check the real bit depth of the file, check:</span></li></ul><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.stillwellaudio.com/plugins/bitter/&amp;sa=D&amp;source=editors&amp;ust=1765035744357683&amp;usg=AOvVaw1HqF-opVQnOgOljbIPDyxS">https://www.stillwellaudio.com/plugins/bitter/</a></span></p><ul class="c9 lst-kix_pxpm44v9ngyu-0 start"><li class="c1 c25 c8 li-bullet-0"><span>For output files, you can untick exporting as mp3 in </span><span class="c4"><a class="c3" href="#h.wbc0pja7faof">Colab</a></span><span class="c4"><a class="c3" href="#h.wbc0pja7faof">s</a></span><span>&nbsp;</span><span class="c0">(export your separations as WAV/FLAC)</span></li></ul><ul class="c9 lst-kix_tvu7bmfefz32-0"><li class="c1 c25 c8 li-bullet-0"><span>To upload your output file losslessly on YT </span><span class="c4"><a class="c3" href="#h.tu3sw6pao8fp">read</a></span></li></ul><p class="c1 c7"><span class="c73 c22 c51 c33 c30 c38"></span></p><h6 class="c1 c27" id="h.q2yh9cwh3mmt"><span class="c6">Various versions of the same song</span></h6><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.pjvi1qowv8cq"><span class="c0">Sometimes the same track you may try to isolate can exist in few versions: e.g. </span></h6><p class="c1"><span class="c0">0) album version <br>- on streaming services - sometimes both explicit and non-explicit album versions are available, plus sometimes both in 44kHz 16-24 bit or 48-192kHz - they might give a bit of different results (if your old player app struggles with playing these files, download the latest MKVToolnix, drag and drop the file and begin multiplexing. It doesn&rsquo;t reencode/recompress the audio stream)</span></p><p class="c1"><span class="c0">- on CD - sometimes these are two different masters - if total time and track gain of lossless files scanned by F2K is different by e.g. 1dB or iLufs reading is different, it&rsquo;s a different master. </span></p><p class="c1"><span class="c0">~ Sometimes recent masters of older music are louder on CDs than on streaming services providing fewer dynamics, and in most cases such CD should be worse for AI separation when mastered to -9 ilufs vs -14 ilufs for streaming, although it can be totally opposite for some releases too</span></p><p class="c1"><span class="c0">~ Regional CD version - certain albums in the past used to have different releases for some countries, e.g. Japan, different track order, even slightly different mastering</span></p><p class="c1"><span class="c0">- on DSD - if available, they are different masters and might be worth to check for separation too</span></p><p class="c1"><span class="c0">- on SACD - -||-</span></p><p class="c1"><span class="c0">- on vinyl (so-called &ldquo;vinyl rip&rdquo;) - might give you a bit of different results for problematic tracks</span></p><p class="c1"><span class="c0">- on DVD-Audio (sometimes also 2.0 releases) if AC3 was used, it can be lossy - used bit depth or sample rate might depend on a release and it can be a different master</span></p><p class="c1"><span>in separation - usually vinyls are different masters with bass more/mostly in mono</span></p><h6 class="c1 c27" id="h.sh3jeu6radnq"><span class="c0">1) single version - in the old days, single versions contained official instrumentals or accapella which not always invert with original mixture to get instrumental if it wasn&rsquo;t available (but if it inverts at least partially it might give you better result - always try lossless files - lossy might not invert well)</span></h6><h6 class="c1 c27" id="h.6tsiff5t9xtr"><span class="c0">- on CD - sometimes contain different track list than on vinyl, extra tracks, remixes, etc.</span></h6><h6 class="c1 c27" id="h.35pcm6mmklj4"><span class="c0">(rarely available on streamings in this form now) - always refer to Discogz to find all releases of your interest</span></h6><p class="c1"><span>- on vinyl - -||- (won&rsquo;t invert correctly due to constant playback speed fluctuations)</span></p><h6 class="c1 c27" id="h.p3strfbd6g31"><span class="c0">2) deluxe edition/reissue/remastered (sometimes separated instrumentals from remastered versions can be crispier than leaked multitracks which are rarely even mastered; also, different remasters might be available on streaming platforms or fan-made ones on YT or on the internet)</span></h6><p class="c1"><span class="c0">3) Video released for the song - although lossy, it can be completely different mix or master giving different results for separation</span></p><p class="c1"><span class="c0">4) Official remix - sometimes it might be easier to separate vocals from such version</span></p><p class="c1"><span class="c0">5) Leaks of earlier version of the song (might have different mixing, lyrics, even instrumental) - YT (often a subject to be taken down), fan-made Discord servers, internet</span></p><p class="c1"><span class="c0">6) Leaks of multitracks or stems of the song - usually it&rsquo;s a different master than the final song, but you might experiment with Matchering and using it mixdown without vocals a target, and well sounding separation as input for Matchering to make it more similar to the final song</span></p><p class="c1"><span>7) Leak of instrumental/vocals - it can be lossy or slightly different from the final song, e.g. close to final stage or sometimes might have even dry vocals without any effects</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Surround versions</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">8) 5.1 - &nbsp;e.g. DTS on DVD Audio/Blu-ray or SACD (you can search Discogz to look for multichannel versions released on disks, e.g. whole DTS Entertainment label)</span></p><p class="c1"><span class="c0">9) 360 Reality or Atmos (7.1 or more) - e.g. on Tidal, Apple Music (how to download is described below).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes in surround releases, vocals can be there simply in the center channel, but it&#39;s not always the case - still, it can be a better source, e.g. when you manipulate with volume of specific channels, or for vocals - when you get only center channel with very little instrumentalization which may turn out easier to separate by AI (for instrumental you might possibly invert result of vocal model and center channel to receive the remain instrumentalization in center).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;For me, I convert left and right together then center alone then LS+Rs+LFE together then I have 3 audio filles process them then remix into 5.1 again.</span></p><p class="c1"><span class="c0">The 2 are in stereo and one mono which is center:.</span></p><p class="c1"><span class="c0">- killdubo</span></p><p class="c1"><span class="c0">&ldquo;I do the same, except that I don&#39;t process LFE. Only the other 5.&rdquo; - </span></p><p class="c1"><span class="c0">- santilli_/Michael</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">E.g. &quot;With the Dolby Atmos release of Random Access Memories, some vocals and instrumentals can be separated almost like stems&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or alternatively, you can simply downmix everything to stereo and then separate (just to check the outcome vs regular 2.0 versions).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Tape</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">10) Cassette tape - wouldn&rsquo;t recommend it as a source (maybe unless it sounds superb, or you have a great deck at disposal to rip the recording) - even though the cassette tapes might be still released occasionally, contemporary music usually sound worse on them than it used to in the past, and potentially to compensate for it, they might contain different masters (cassette tape won&rsquo;t invert due to speed fluctuations either)</span></p><p class="c1"><span class="c0">11) Reel to reel tape (better quality, mostly old music, also, usually in the past, the base medium for archival original stems of the recording before final mix and master, but degrading along the time, sometimes can change the sound after some time even when in the period of the song production)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">General</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>As for good quality music on streaming services you can get FLAC 16 bit and 24 bit on Qobuz/Amazon) or on Tidal (now also up to 24 bit FLACs for Master quality - formerly MQA 24 bit (in the past most of Max (formerly Master) quality on Tidal was 16 bit MQA, while High (formerly Hi-Fi) is and was always FLAC 16 bit; MQA was lossy (but less than all other formats), but 24 bit MQA file could have given better results than 16 bit FLAC). MQA was gradually transitioned to FLAC on Tidal, but seems like old uploads in 24 bit MQA are not 24 bit anymore but just 16 bit FLACs, so you might want to use Qobuz to find some of these 24 bit files if they aren&rsquo;t available on Tidal like they used to be.</span></p><h6 class="c1 c27" id="h.8mlwgk6tbmt7"><span class="c0">Most importantly -</span></h6><h6 class="c1 c27" id="h.e1omx3l6uawl"><span class="c0">Feel free to experiment with different versions and find the best result with a specific version of your song, although 24 bit FLAC should be the best (although not everyone might notice the difference). </span></h6><h6 class="c1 c27 c7" id="h.7q7isrwwu4t2"><span class="c0"></span></h6><h6 class="c1 c27" id="h.eh7ezi7rouy4"><span class="c0">If you have seemingly the same FLAC Audio CD rip from before streaming services times (~&lt;2013), it can happen that a lossless file taken from a streaming service may be slightly different in most cases (same length but slight changes in Spek across the whole track which normally don&rsquo;t exist when comparing FLACs from various streaming services which have the same Audio MD5 checksums - also sometimes track finishes in slightly different place). Sometimes it can sound better, sometimes worse </span></h6><h6 class="c1 c27" id="h.tzetoh38au4n"><span>([</span><span class="c20">outdated - there are no longer MQA files on Tidal] </span><span class="c0">and we&rsquo;re talking about situation that it&rsquo;s not MQA 16 bit like &quot;Master&quot; quality files on Tidal [but lots are 24 bit as well, though it&#39;s better to get them from e.g. Qobuz if 24 bit for some track is available, or at least compare both, because it can give slightly different results]). </span></h6><h6 class="c1 c27" id="h.t5gdyub6p1t9"><span class="c0">Also, it can happen that 24 bit MQA on Tidal will sound better for whatever reason than seemingly better FLAC on Qobuz - it might be possibly due to different files sent to streaming services by the provider/labe.</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">How to notice difference on spectrogram in e.g. Spek between MQA and FLAC is frequencies from 18kHz (only in certain places) but in all cases - frequencies from 21kHz - press alt-tab between the two windows&rsquo; - don&rsquo;t hover your mouse between preview of both windows&rsquo; - use alt-tab - you&rsquo;ll notice the changes easier. That way, you&rsquo;ll notice CD rip vs streaming differences if there are any.</span></p><p class="c1"><span>Generally, MQA is the least of lossy codecs - you might consider picking it where its 24 bit variant is available over regular 16 bit FLAC (separate the track using the two, and you should notice any differences easier if you already can&rsquo;t hear them on mixtures/original songs).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Comparisons of various versions of the FLAC files on streaming services</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Use Audio MD5 in Foobar &gt;properties of the file (or download </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/moisespr123/AudioMD5Checker/releases/&amp;sa=D&amp;source=editors&amp;ust=1765035744373500&amp;usg=AOvVaw35aVivX_glzO6y1kHcLSi8">AudioMD5Checker</a></span><span class="c0">) to not run in circles looking for various versions of the same track with the same length. Some FLAC files don&rsquo;t have MD5 checksums in F2K shown, so you&rsquo;ll need to download AudioMD5Checker.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>E.g. on Tidal Recovery by Eminem returns the same MD5 for Deluxe and regular album, but using </span><span class="c68"><a class="c3" href="https://www.google.com/url?q=https://free-mp3-download.net&amp;sa=D&amp;source=editors&amp;ust=1765035744374201&amp;usg=AOvVaw0yvXA6AXBzmWDObG3Y-9Su">https://free-mp3-download.net</a></span><span class="c0">&nbsp;(Deezer), checksums are different for both (to differentiate - albums on the net site have various release dates), but Deluxe on Tidal with regular on (Deezer) have the same MD5. And when Audio MD5 checksums were different, there were different results after separation. In this case of one unique vs 3 same MD5, the unique resulted in worse separation (but it can depend on more factors in other cases). Be aware of non-explicit versions which will naturally have different checksum.</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.ataywcoviqx0"><span class="c18 c15">Sites and rippers</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">List of a ways to get lossless files for separation process</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Various music is scattered across various streaming services nowadays. If you can&rsquo;t find your track on one service, or its ripper currently doesn&rsquo;t work (it constantly changes) check other streaming service or the net (more below). </span></p><p class="c1"><span class="c0">List of all lossless streaming services with rippers below:<br>Tidal, Qobuz, Apple Music, Amazon Music (they support hi-res), Deezer (16/48 FLAC).</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c34">0</span><span>) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://us.deezer.squid.wtf/&amp;sa=D&amp;source=editors&amp;ust=1765035744376264&amp;usg=AOvVaw3kjwPbrfR2Zo8sL2FAWSNK">us.deezer.squid.wtf</a></span><span>&nbsp;| (out of order for now, Deezer only; search didn&rsquo;t respond before) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://eu.deezer.squid.wtf/&amp;sa=D&amp;source=editors&amp;ust=1765035744376500&amp;usg=AOvVaw3k68gUvajPV_FF6HQYgtvV">eu.deezer.squid.wtf/</a></span><span>&nbsp;</span><span class="c0">(also offline) - works for queries, not URLs, single songs or albums, if you don&rsquo;t check the &ldquo;Save songs on download&rdquo; (supported on Chrome) you need to press download button manually after ripping finishes (so once you&rsquo;re notified), sometimes ripping can be progressing very slow, but consequently when you zoom the progress bar. Also, sometimes downloading in your browser might get interrupted in the middle (press resume in your browser download queue if necessary).<br>Some users (e.g. French) are unable to reach the site (e.g. 403 error) then use VPN.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c34">0)</span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://us.qobuz.squid.wtf/&amp;sa=D&amp;source=editors&amp;ust=1765035744377606&amp;usg=AOvVaw11XJtzcTgr4RGewa2dJcmV">https://us.qobuz.squid.wtf/</a></span><span>&nbsp;(went offline)</span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://eu.qobuz.squid.wtf/&amp;sa=D&amp;source=editors&amp;ust=1765035744377790&amp;usg=AOvVaw0NE1RXqUm2ZPGloL1fGPKu">https://eu.qobuz.squid.wtf/</a></span><span class="c0">&nbsp;(back offline; Qobuz only) - -||- It can happen that using search on Qobuz won&rsquo;t give you the desired results, while the search in the link will be successful.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">0) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://lucida.to/&amp;sa=D&amp;source=editors&amp;ust=1765035744378213&amp;usg=AOvVaw2AV5cncI6qJL52Or_GlAGq">lucida.to</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://lucida.su/&amp;sa=D&amp;source=editors&amp;ust=1765035744378292&amp;usg=AOvVaw0QAXnD9ZCjgpk3F5z25eq8">lucida.su</a></span><span class="c0">&nbsp;(sometimes works, sometimes redirects to doubledouble.top)</span></p><p class="c1"><span class="c20">(Qobuz, Deezer [may not work], Tidal [icl. 24/96kHz FLAC stereo], Amazon Music, Beatport, lossy: Spotify, Yandex Music, Soundcloud). </span><span class="c0">Various subscription regions, for now there&rsquo;s no Apple Music) - for URLs generated from share option on these services<br>- Send your request again if you got site unreachable browser error during download<br>- Sometimes it might fail generating download in the first place<br>- It frequently shows that it&rsquo;s down, simply retry entering<br>- &ldquo;if a track has a status code 404, it means it is unavailable (region locked or completely unavailable) you have to try with another country/account under &#39;advanced&hellip;&#39;&rdquo;<br>- Downloading more than EP (7-10 songs) at a time works clunky - it&rsquo;s slow (at least from Tidal), plus during downloading track ~10 it might give an error, so you need to click retry, sometimes a few times, and then the whole album ripping will be completed. It might occur more than once for one album</span></p><p class="c1"><span class="c0">- Clicking retry while downloading whole albums from e.g. might end up with loops of &ldquo;An error occurred. Track #1 error: Max retries attempted.&rdquo; errors, after long wait on &ldquo;Sending request for item 1&rdquo; or series of interrupted downloads, while downloading single songs will work fine<br>- You cannot download Dolby Atmos versions of songs from e.g. Tidal<br>- For &quot;An error occurred. Unexpected token &#39;&lt;&#39;, &quot;&lt;html&gt; &lt;h&quot;... is not valid JSON.&quot; just retry the task, or uncheck add metadata option.</span></p><p class="c1"><span class="c0">- All linking schemes like: </span></p><p class="c1"><span class="c0">1) https://www.deezer.com/xx/track/XXXXXXXXXXXX?host=XXXXXXX&amp;utm_campaign=clipboard-generic&amp;utm_source=user_sharing&amp;utm_content=track-XXXXXXXXXXXX&amp;deferredFl=1&amp;universal_link=1&rdquo; </span></p><p class="c1"><span class="c0">2) Later converted by lucida automatically to: https://www.deezer.com/xxx/track/XXXXXXX or</span></p><p class="c1"><span class="c0">3) https://link.deezer.com/s/xXxXXxxXxxxXxxXX</span></p><p class="c1"><span>can can give &ldquo;uh-oh!&rdquo; error - if </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://lucida.to/stats&amp;sa=D&amp;source=editors&amp;ust=1765035744381652&amp;usg=AOvVaw2TW4TUVLYS2jlotCmKiRLq">stats</a></span><span class="c0">&nbsp;page shows 0 downloads for Deezer (or any other service), it just doesn&rsquo;t work</span></p><p class="c1"><span>- Sometimes Tidal links will work after retrying the pasting link request, or if you cut everything which follows </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tidal.com/track/xxxxxxxx/&amp;sa=D&amp;source=editors&amp;ust=1765035744382413&amp;usg=AOvVaw1nz9gc3xsHVdKhwuLzJlY4">https://tidal.com/track/xxxxxxxx/</a></span><span class="c0">&nbsp;so the &ldquo;u&rdquo; (not sure which one).</span></p><p class="c1"><span class="c0">- In Amazon linking scheme, referral number appears in the middle, not at the end of the link, so you can debloat the following to restrict the tracker: https://music.amazon.com/albums/B073JR1FBD?marketplaceId=A3K6Y4MI8GDYMT&amp;musicTerritory=PL&amp;ref=dm_sh_xxxxxxxxxxxxxxxxxxxxxxx&amp;trackAsin=B073RRBQR5<br>By the following:</span></p><p class="c1"><span class="c0">https://music.amazon.com/albums/B073JR1FBD?marketplaceId=A3K6Y4MI8GDYMT&amp;musicTerritory=PL&amp;trackAsin=B073RRBQR5<br>When you use shared Amazon links, sometimes they must be deprived of some information after &ldquo;&amp;&rdquo; mark, in order to not return error on the site, but because they contain an &ldquo;album&rdquo; string, you might end up with the whole album downloaded instead of a single song if you did it wrong.</span></p><p class="c1"><span class="c0">The region string should be rather US instead of whatever your shared links have (it seems the accounts have US region), but other regions in the links might work too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://doubledouble.top/&amp;sa=D&amp;source=editors&amp;ust=1765035744385165&amp;usg=AOvVaw1WoIy3R7jAKv5nheqNPjn1">doubledouble.top</a></span><span class="c0">&nbsp;(currently Qobuz, Tidal doesn&rsquo;t seem to work for EU region for now or for US rarely] and Soundcloud only work) Sometimes works, sometimes redirects to Lucida. For URLs, it supported Apple Music unlike Lucida (but later it stopped working too or work rarely or with specific music, then lucida started support it), and currently from Deezer it returns only mp3 128kbps (check current services status at the bottom). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In specific cases, some streaming service might not have FLAC for your song, then use other streaming service.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>*) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://qqdl.site/&amp;sa=D&amp;source=editors&amp;ust=1765035744386807&amp;usg=AOvVaw2sK0t4ve5GDUyT2gjoh4hx">https://qqdl.site/</a></span><span class="c0">&nbsp;- Qobuz, some smartphones might run out of memory running this, a new site by Lucida stuff, but seems to currently redirect to doubledouble.top</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://deezmate.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744387445&amp;usg=AOvVaw3dNFSmCiPPdtpOtOKt59Tj">https://deezmate.com</a></span><span class="c0">&nbsp;- mp3 or FLACs from Deezer, working with links</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tidal.qqdl.site&amp;sa=D&amp;source=editors&amp;ust=1765035744387852&amp;usg=AOvVaw1HdV_mqqAQHyBaEd_8nyTS">https://tidal.qqdl.site</a></span><span class="c0">&nbsp;- TIDAL</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Telegram ripping bots</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To use Telegram in browser:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://web.telegram.org/&amp;sa=D&amp;source=editors&amp;ust=1765035744388724&amp;usg=AOvVaw3_4M3HltMZqJ5b1gFkbzE9">https://web.telegram.org/</a></span></p><p class="c1"><span class="c0">You need the app installed and account registered on your phone, then QR code from there is needed.</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">1a) Bot </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/onlydonuts&amp;sa=D&amp;source=editors&amp;ust=1765035744389399&amp;usg=AOvVaw3SAP4BUHgi6qIR4M2ese4z">https://t.me/onlydonuts</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1b) Amazon bot (up to 24/96 FLAC)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/GlomaticoAmazonMusicBot&amp;sa=D&amp;source=editors&amp;ust=1765035744389881&amp;usg=AOvVaw2lWN15Gy6KpXU8yx5rbV3X">https://t.me/GlomaticoAmazonMusicBot</a></span><span class="c0">&nbsp;<br>Q: &ldquo;I hit start bot, but nothing happens&rdquo;<br>A: &ldquo;Once you start the bot you must type /codec and send, then it will show a menu where you pick the format you want (mp3, flac, atmos)</span></p><p class="c1"><span class="c0">After selecting a codec, you simply need to send a link to a track or album.</span></p><p class="c1"><span class="c0">The bot will download all the tracks in the format you pick, but if the track is not available in Atmos it will be ignored&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>1c) Apple Music Bot<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/GlomaticoAppleMusicBot&amp;sa=D&amp;source=editors&amp;ust=1765035744391337&amp;usg=AOvVaw3hteA1Qftbi7n70WusPyVg">https://t.me/GlomaticoAppleMusicBot</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/bayapplemusicbot&amp;sa=D&amp;source=editors&amp;ust=1765035744391596&amp;usg=AOvVaw3G_AD3fcOgbriw4zQNQ7yr">https://t.me/bayapplemusicbot</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1d) Deezer Telegram Bot </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/deezload2bot&amp;sa=D&amp;source=editors&amp;ust=1765035744392001&amp;usg=AOvVaw1J1JbcY_-Qypg4Xu_2GEvT">https://t.me/deezload2bot</a></span><span>&nbsp;- for ARLs </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rentry.org/firehawk52%23deezer-arls&amp;sa=D&amp;source=editors&amp;ust=1765035744392163&amp;usg=AOvVaw2Q_U-jcELi5ZShligNF0S1">see</a></span><span class="c0">&nbsp;(but those public get taken down often)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1e) Spotify / Deezer / Tidal / Yandex / VK / FLAC / 25 Daily bot</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/BeatSpotBot&amp;sa=D&amp;source=editors&amp;ust=1765035744392772&amp;usg=AOvVaw1iS_oS8N2FDXvig9SnMDkr">https://t.me/BeatSpotBot</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1f) Deezer mp3/FLAC bot</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/DeezerMusicBot&amp;sa=D&amp;source=editors&amp;ust=1765035744393203&amp;usg=AOvVaw1tX_cJXd3q1bskejJ5BA51">https://t.me/DeezerMusicBot</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>1e) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/vkmsaverbot&amp;sa=D&amp;source=editors&amp;ust=1765035744393466&amp;usg=AOvVaw1uBAzBjyQY7joDPpzaznbd">VK Bot</a></span><span>, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/vkmusbot&amp;sa=D&amp;source=editors&amp;ust=1765035744393596&amp;usg=AOvVaw2huNd39cOmLYjqF9E_gUZ9">vkmusbot</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/mephbot&amp;sa=D&amp;source=editors&amp;ust=1765035744393727&amp;usg=AOvVaw3t9P8U_MWm06shKLsU0lIY">Meph Bot</a></span><span class="c0">&nbsp;- VK / 320kbps MP3</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">Rippers</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">2) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://telegra.ph/murglar-en-05-12&amp;sa=D&amp;source=editors&amp;ust=1765035744394282&amp;usg=AOvVaw0cMbgs95OIHK-ydnoPIojz">Murglar</a></span><span>&nbsp;app - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/badmannersteam/murglar-downloads/releases/tag/murglar_2.1.3_279_stable&amp;sa=D&amp;source=editors&amp;ust=1765035744394503&amp;usg=AOvVaw2K5I7r37Lvj0xRp5eyAb-a">apk</a></span><span>&nbsp;for Android</span><span class="c6">&nbsp;- player and downloader working with Deezer, SoundCloud, VKontakte and Yandex Music (alternatively you can use it in Android virtual machine)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">3) Apple Music ALAC/Atmos downloader</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/adoalin/apple-music-alac-downloader&amp;sa=D&amp;source=editors&amp;ust=1765035744395494&amp;usg=AOvVaw0qehgL39iVNOlk3k9yKQyA">https://github.com/adoalin/apple-music-alac-downloader</a></span><span>&nbsp;(</span><span class="c20">valid subscription required, you can&rsquo;t use an account that&rsquo;s on a family sharing plan</span><span>, more about installation below in </span><span class="c4"><a class="c3" href="#h.ueeiwv6i39ca">Dolby Atmos</a></span><span class="c0">&nbsp;section)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Might be less comfy to install for beginners. It requires Android (rooted at best and in Android Studio w/o Google APIs) and installing specific Frida server version (for not rooted devices it might be more complicated) and specific version of Apple Music app. </span></p><p class="c1"><span class="c0">Refer to GitHub link above and Frida website for further instructions.</span></p><p class="c1"><span class="c6">(the section continues later below)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>4) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/zhaarey/apple-music-downloader&amp;sa=D&amp;source=editors&amp;ust=1765035744397556&amp;usg=AOvVaw33wNn5MgoeN2xYUfpXiYVL">https://github.com/zhaarey/apple-music-downloader</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rentry.co/zhaareywrapper&amp;sa=D&amp;source=editors&amp;ust=1765035744397759&amp;usg=AOvVaw3YQWa103FH_8cI4r1APw42">Instruction</a></span></p><p class="c1"><span class="c0">&ldquo;and additional note if that does not work </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">replace Part 2 Line 2</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Download and extract the NDK needed to build the wrapper.</span></p><p class="c1"><span class="c0">wget https://dl.google.com/android/repository/android-ndk-r23b-linux.zip &amp;&amp; unzip android-ndk-r23b-linux.zip -d ~</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">with </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Download and extract the NDK needed to build the wrapper.</span></p><p class="c1"><span class="c0">wget https://dl.google.com/android/repository/android-ndk-r27c-linux.zip &amp;&amp; unzip android-ndk-r27c-linux.zip -d ~</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">the change is the Android NDK version from 23b to 27c&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Bas Curtiz tutorial:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DeJ7a3W8qy5o&amp;sa=D&amp;source=editors&amp;ust=1765035744400225&amp;usg=AOvVaw0OTrdpsjy8i9qUXrsMaPAm">https://www.youtube.com/watch?v=eJ7a3W8qy5o</a></span></p><p class="c1"><span class="c0">__</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">General bots usage instructions</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Go to proper dl request channel and write</span></p><p class="c1"><span class="c0">!dl</span></p><p class="c1"><span class="c0">and after !dl (on Discord $dl), paste a link to your album or song from the desired streaming service and send the message, e.g.</span></p><p class="c1"><span class="c0">!dl https://www.deezer.com/en/track/XXXXXX</span></p><p class="c1"><span class="c0">Follow this link pattern. Sometimes the sharing option on the site changes the link pattern, so you need to open the changed link, and then it will redirect to the one similarly looking like above.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To open the Deezer player to search for files without active subscription, log-in and just go to:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.deezer.com/search/rjd2%2520deadringer&amp;sa=D&amp;source=editors&amp;ust=1765035744402590&amp;usg=AOvVaw2Y-gOIRz1lsPotCdIwYb1a">https://www.deezer.com/search/rjd2%20deadringer</a></span></p><p class="c1"><span class="c0">And replace the search query with yours after opening the link.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If the bot doesn&rsquo;t respond in an instant, it probably means the track/album is regional-blocked, and you should use a link from another service or another channel (UK and NZ alternative servers available). It&#39;s capable of printing out unavailability errors as well.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Some bots rip tracks or whole albums from Qobuz, Deezer, Tidal - all losslessly, while:</span></p><p class="c1"><span class="c0">Spotify, Soundcloud Go+, YouTube Music, JioSaavn are lossy. &nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Providing valid links for bot</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For your comfort, you should register and log into every streaming service and share links for specific tracks or albums from these services (e.g. instead of pasting full album links if you want), when you can&rsquo;t simply find a specific single track in Google for this service, or share the link only for it comfortably. So basically go to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://play.qobuz.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744405545&amp;usg=AOvVaw2NVaFxUWHNjdvGvtgu3omF">https://play.qobuz.com/</a></span><span>,</span></p><p class="c1"><span class="c0">and you can share single tracks to paste for bot to download - available only after logging into free account and only in the link above instead of regular Qobuz file search you can find in Google - there you cannot share single songs to download using bot later. It can happen that you&rsquo;ll see an error that Qobuz is not available in your country. It&rsquo;s fine - you won&rsquo;t have to buy a subscription at this step in order to use their search. It&rsquo;s enough to log-in using specific link and not the main page, use this one:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://play.qobuz.com/search/tracks&amp;sa=D&amp;source=editors&amp;ust=1765035744407194&amp;usg=AOvVaw3EELFUm3zbUvJ-zwUFK5nK">https://play.qobuz.com/search/tracks</a></span></p><p class="c1"><span class="c0">And it will allow you to log in.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Because the bot rips from Qobuz, it&rsquo;s the best source of 24 bit files which I recommend if only available (either 44, 48 or 96kHz) as it delivers FLACs for end users, instead of partly lossy MQA on Tidal when some album/song uses Master quality which is compulsory for 24 bit (44/48) there, but MQA 16 bit and Master is also possible for some albums (and you should avoid 16 bit MQA). Of course there might be some exceptions where 24 bit MQA on Tidal will sound better than FLAC 24 bit on Qobuz as I mentioned above - the example is Eminem - Music To Be Murdered By (Deluxe Edition) - Volume 1 (the newer Side B, track - Book of Rhymes).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For using Deezer links with bot, you need to find a song/album, use option to share a link to track or album, then open the shared link so it will be redirected, and then rename the link to this form for a single song (otherwise bot will return &ldquo;processing&rdquo; instead of ripping or even possible error):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.deezer.com/en/track/XXXXXXX&amp;sa=D&amp;source=editors&amp;ust=1765035744410190&amp;usg=AOvVaw3ScpS7yRopkGbyWWrA1t5p">https://www.deezer.com/en/track/XXXXXXX</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(ARLs trick doesn&rsquo;t work anymore) Hint: There&#39;s also something like ARL, which is a cookie&#39;s session identifier which can be shared, so everyone can log into the premium account and download FLACs with ARLs of different regions and regional locks. Might be useful for some specific tracks. ARLs are frequently shared online, though harder to find nowadays (Reddit censorship).</span></p><p class="c1"><span class="c0">IRC, Deemix might use ARLs beside regular account log in process.</span></p><p class="c1"><span class="c0">___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>5) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/yaronzz/Tidal-Media-Downloader-PRO/releases&amp;sa=D&amp;source=editors&amp;ust=1765035744412041&amp;usg=AOvVaw3DI7LSONPjEPZbnZSbalrL">Tidal Downloader Pro</a></span><span class="c0">&nbsp;(the fastest method for batch and local downloading) in GUI.</span></p><p class="c1"><span class="c0">HiFi Plus subscription is no longer necessary, just valid Hi-Fi subscription (for at least Hi-Fi albums, the two are merged in one for the price of the cheaper now).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You won&rsquo;t be able to download with better quality than 24 bit/48kHz and in Atmos with this downloader (then use </span><span class="c4"><a class="c3" href="#h.2myqsboh95hp">orpheusdl_tidal</a></span><span>&nbsp;instead, or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/exislow/tidal-dl-ng&amp;sa=D&amp;source=editors&amp;ust=1765035744413369&amp;usg=AOvVaw0o0pF8I8mbPNNypZgjWNzB">tidal-dl-ng</a></span><span class="c0">&nbsp;- but for that one I&rsquo;m not sure if it downloads Atmos files)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Install Tidal app on Windows and log in, then open the downloader and click log, copy and paste the given code in the opened browser tab and voila.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Or if that GUI temporarily doesn&rsquo;t work, go to: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/yaronzz/Tidal-Media-Downloader/releases&amp;sa=D&amp;source=editors&amp;ust=1765035744414599&amp;usg=AOvVaw0yZzlFvJ1MIGPN3q3chTOB">https://github.com/yaronzz/Tidal-Media-Downloader/releases</a></span><span class="c0">&nbsp;and download the newest source code. It contains CMD version for downloading, located in: Tidal-Media-Downloader-202x.xx.xx.x\TIDALDL-PY\exe</span></p><p class="c1"><span>Documentation: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://doc.yaronzz.com/post/tidal_dl_installation/&amp;sa=D&amp;source=editors&amp;ust=1765035744415336&amp;usg=AOvVaw0kK1wbzTgL_1veAjMJzRcn">https://doc.yaronzz.com/post/tidal_dl_installation/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you have problems with running the app and people also write in GitHub issues that the current version is not working, keep tracking new versions, or read all the issues about this version, it may happen that someone else will update the app before.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Versions &ldquo;2022.01.21.1&rdquo; and &rdquo;1.2.1.9&rdquo; need to be updated to newer versions, they stopped working entirely. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(not needed anymore, as current should still work)</span></p><p class="c1"><span>You can alternatively grab this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://na01.safelinks.protection.outlook.com/?url%3Dhttps%253A%252F%252Fmega.nz%252Ffolder%252FDR1k1CCa%2523Opt5RbSvXZVMMsq_QabAvA%26data%3D04%257C01%257C%257C7a3ae2ea93da4c74678c08d9e99f4da0%257C84df9e7fe9f640afb435aaaaaaaaaaaa%257C1%257C0%257C637797692673323048%257CUnknown%257CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%253D%257C3000%26sdata%3DtJ7ZlRYX5SDVc5MsMWZLau3FHcDkYq0g5l3QFJXrv4A%253D%26reserved%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035744417355&amp;usg=AOvVaw3edd7brBHwHWRDaWIs2TgD">recompiled </a></span><span class="c0">version by another user.</span></p><p class="c1"><span class="c0">By these downloaders you can easily download whole albums including hi-res and in GUI (PRO), and also queue for single tracks to download automatically is available (Pro). </span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">There are cases when certain songs are behind regional block, and won&rsquo;t be downloaded by any Divolt or Discord bot resulting in error. </span></p><p class="c1"><span>In such a case, you&rsquo;ll need the above downloader used locally, along with a Hi-Fi Plus subscription bought for your localization. Accounts bought from elsewhere, or paid with foreign currency, will most likely have regional block for some other country, so after you log into the service, certain songs won&rsquo;t show in search, so the only way to show them without proper account (at least for your region) is to log out from regional locked account, start new account, and visit: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://listen.tidal.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744419077&amp;usg=AOvVaw30JgQBVDn0n7R4sRRDHbQ-">https://listen.tidal.com/</a></span><span>&nbsp;(you don&rsquo;t need to have a valid subscription to search for songs on Tidal).</span></p><p class="c1 c7"><span class="c6"></span></p><h6 class="c1 c27" id="h.89rwiestpg95"><span>Besides trial, you can go for Tidal Hi-Fi cheap subscription to: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.hotukdeals.com/search?q%3DTidal&amp;sa=D&amp;source=editors&amp;ust=1765035744419548&amp;usg=AOvVaw2iVnQp-aFzhzHNqluLAe6Z">https://www.hotukdeals.com/vouchers/tidal.com</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.pepper.pl/search?q%3Dtidal&amp;sa=D&amp;source=editors&amp;ust=1765035744419662&amp;usg=AOvVaw1BJHiEaqzpQwRr1JsGHMgJ">pepper.pl</a></span><span>&nbsp;or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://mydealz.de&amp;sa=D&amp;source=editors&amp;ust=1765035744419787&amp;usg=AOvVaw3rx3bGFwbcqpZ_bDq37uAA">mydealz.de</a></span><span class="c0">&nbsp;which always have some free or almost free giveaways (linked to a ready search). Then install the desktop Tidal app and log in and open the downloader. It might automate the login process in the downloader</span></h6><p class="c1"><span class="c0">(if you need to switch an account, you better delete Tidal-GUI folder from your documents folder in case of any problems). Monthly Argentinian subscription is the most reliable solution now if you don&rsquo;t want to change your account every month or two searching for new offers.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Tidal over some other streaming services has some tracks in master quality which is 24 bit, and it gives better results for separation as the dynamics are usually better. But check if your downloaded file is really a 24 bit and your downloader is configured properly (read the documentation in case of any issues).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>But, on Tidal there </span><span class="c34">are</span><span class="c0">&nbsp;were some fake master files in the past, which in reality were 16 bits, and they&rsquo;re MQA to save space on their servers or mislead people, so there is no benefit from using them vs Audio CD 16 bit rip, since MQA alters quality in higher frequencies (only) and it will have an influence on separation process. So to verify if your downloader is set up properly, check whether you can download any track from Music To be Murdered By, by Eminem in 24 bit. If you can, you have properly installed and authorized the downloader, so it can download 24 bit files or in higher sample rate than 44kHz if available. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can paste links from Tidal into the GUI browser to find that track. Just delete &ldquo;?u&rdquo; in the end of the shared link.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5b) Colab for downloading from Tidal and Qobuz using your own valid account (based on streamrip, active subscription required):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://colab.research.google.com/github/r-piratedgames/rip/blob/master/rip.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744423690&amp;usg=AOvVaw2u8acczTw7Dlj0rDKs-B3V">colab.research.google.com/github/r-piratedgames/rip/blob/master/rip.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>6) For Deezer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://archive.org/details/deemix&amp;sa=D&amp;source=editors&amp;ust=1765035744423987&amp;usg=AOvVaw3tkB4O04pGXnEOz2FQS8Fs">https://archive.org/details/deemix</a></span><span>&nbsp;</span><span class="c0">- it allows you to download mp3 320 and FLAC files for premium Deezer accounts, and only mp3 128kbps for free Deezer accounts.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that deemix.pro site is unofficial, and the PC 2020 version linked there is not functional. The last 2022 is on the archive.org linked above from reddit. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Qobuz or Deezer might give better results since Tidal is recently deleting FLAC support for 16 bit files on some albums, making all the files 16 bit MQA, which is not fully lossless file format, but close (of course Tidal Downloader converts the same MQA to FLAC). It also provides some high resolution files, but most likely less of them than on Tidal.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that using some streaming services downloaders or even official Deezer/Tidal/Spotify apps, you might not be able to find or even play there some specific tracks or albums due to:</span></p><p class="c1"><span class="c0">a) premium lock (it won&#39;t be played for free users) </span></p><p class="c1"><span class="c0">b) regional lock (search will come up empty [the same applies to Tidal here])</span></p><p class="c1"><span class="c0">Example: Spyair - Imagination instrumental - it shows up in search probably in Japan, though it cannot be downloaded using 2) https://free-mp3-download.net, but deemix with premium Deezer subscription did the job in downloading the song (not sure if it was Japan account).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">PS. You can cancel your trial subscription of Deezer or Tidal immediately to avoid being charged in the future, but also keeping the access to premium till the previous charge date at the same time.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>7) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/yarrm80s/orpheusdl&amp;sa=D&amp;source=editors&amp;ust=1765035744427246&amp;usg=AOvVaw0bvPBIZMT7RJ9-h5SwVJK_">https://github.com/yarrm80s/orpheusdl</a></span></p><p class="c1"><span>Supports Qobuz, Tidal (with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Dniel97/orpheusdl-tidal&amp;sa=D&amp;source=editors&amp;ust=1765035744427451&amp;usg=AOvVaw2LHgtSK8cLzngXI1K9S6fQ">this</a></span><span class="c0">&nbsp;module, and unlike tidal-dl, also downloads files greater than 24/48 and Atmos) and probably more</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>7a) Bas Curtiz </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DRAXsW67SjGU&amp;sa=D&amp;source=editors&amp;ust=1765035744427797&amp;usg=AOvVaw37b8uZ7x6ajI1-LLctdySS">GUI</a></span><span>&nbsp;</span><span class="c0">for Orpheus (still needs working subscription)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>7b)</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rentry.org/firehawk52%23qobuzdownloaderx-mod&amp;sa=D&amp;source=editors&amp;ust=1765035744428102&amp;usg=AOvVaw3CcfcZm4vXTIgLLxDDcbr-">&nbsp;QobuzDownloaderX-MOD</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(*May not work anymore)</span></p><p class="c1"><span>7*) If you have a Qobuz subscription, you can just use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/vitiko98/qobuz-dl&amp;sa=D&amp;source=editors&amp;ust=1765035744428542&amp;usg=AOvVaw2UNDnVowdV55lLMSBNBji6">qobuz-dl</a></span><span class="c0">&nbsp;(last updated a year ago, probably no longer works, but not sure, there might be some alternative already). </span></p><p class="c1"><span class="c0">Alternatively check:<br>Qobuz Downloader X </span></p><p class="c1"><span class="c0">or Allavsoft (both requires subscription)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.qobuz-dl.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744429108&amp;usg=AOvVaw0bdnEiCR1y3bG-CVLzDaP0">https://www.qobuz-dl.com/</a></span><span>&nbsp;(takendown frontend browser client for downloading music for Qobuz. The code for hosting on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/QobuzDL/Qobuz-DL&amp;sa=D&amp;source=editors&amp;ust=1765035744429316&amp;usg=AOvVaw1lOC4Cazskh4R8uftwoK7l">GH</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>7b) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nathom/streamrip&amp;sa=D&amp;source=editors&amp;ust=1765035744429535&amp;usg=AOvVaw1pv-E6u255WwwZamCzCT6a">https://github.com/nathom/streamrip</a></span></p><p class="c1"><span class="c0">A scriptable stream downloader for Qobuz, Tidal, Deezer (active subscription required) and SoundCloud.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>8*) For Deezer you can use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://deezloader.site/&amp;sa=D&amp;source=editors&amp;ust=1765035744429934&amp;usg=AOvVaw3K-N-OR8lEZzDg6cHYkm1O">Deezloader</a></span><span class="c0">&nbsp;or Deezloader Remix - it doesn&rsquo;t require any subscription for mp3 128kbps, just register a Deezer account for free before, and use the account in the app. For free users it gives only mp3 128kbps with 16kHz, so it&#39;s worse than YT and Opus, so don&#39;t bother.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">9a) For Spotify, you can use Soggfy, or </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">9b) SpotiDown (premium subscription for 320kbps downloading and app compiling required)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>9c** Seemingly you can use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://spotiflyer.app/&amp;sa=D&amp;source=editors&amp;ust=1765035744430821&amp;usg=AOvVaw0X1CWKOXwZj6mmbU6MdISj">https://spotiflyer.app/</a></span></p><p class="c1"><span class="c0">but it &ldquo;doesn&#39;t download from Spotify, but from Saavn, in 128kbps/low-quality.</span></p><p class="c1"><span class="c0">Also, since it doesn&#39;t d/l from Spotify, you can&#39;t d/l exclusives released from there.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It doesn&#39;t require a valid subscription irc and also allows playing and sharing music inside the app.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">9d** The same sadly goes to this telegram bot downloader:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/Spotify_downloa_bot&amp;sa=D&amp;source=editors&amp;ust=1765035744431669&amp;usg=AOvVaw2kZAPjrZRSHg2Fc-vR7kzs">https://t.me/Spotify_downloa_bot</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>9e) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://spotify-downloader.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744431922&amp;usg=AOvVaw1FUeETuXqY0K_9zDucPPqW">https://spotify-downloader.com/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Other lists of rippers and sites: </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rentry.org/firehawk52&amp;sa=D&amp;source=editors&amp;ust=1765035744432307&amp;usg=AOvVaw1zE_Vl8SaVwbM55qnB_hNk">https://rentry.org/firehawk52</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ripped.guide/Audio/Music/&amp;sa=D&amp;source=editors&amp;ust=1765035744432461&amp;usg=AOvVaw38U3q9mIkbjIH8By1zxlZC">https://ripped.guide/Audio/Music/</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://fmhy.net/audiopiracyguide%23audio-ripping-sites&amp;sa=D&amp;source=editors&amp;ust=1765035744432672&amp;usg=AOvVaw2yxduVvtN92W-vdyk90RFH">https://fmhy.net/audiopiracyguide#audio-ripping-sites</a></span></p><p class="c1"><span class="c0">________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>10) Go to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://allflac.com&amp;sa=D&amp;source=editors&amp;ust=1765035744432949&amp;usg=AOvVaw2NwNMX0NPtkQlbSj7l-EsL">allflac.com</a></span><span class="c0">&nbsp;- it&rsquo;s paid, but they don&rsquo;t pay royalties to the artist and its labels, as I spoke with at least one. They don&rsquo;t keep up with the content with the streaming services, but they share stuff also not available on streaming services, even including vinyl rips as hi-res ones. Most if not all the files on the site are CD rips taken from around the net.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I&rsquo;ll explain to you how to download files for free from allflac and flacit:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">0. Log in</span></p><p class="c1"><span class="c0">1. Find desired album (don&#39;t press play yet!)</span></p><p class="c1"><span class="c0">2. Open the Chrome Menu in the upper-right-hand corner of the browser window and select More Tools &gt; Developer Tools&gt;navigate to &ldquo;Network&rdquo;</span></p><p class="c1"><span class="c0">3. Press CTRL+R as prompted</span></p><p class="c1"><span class="c0">4. Play audio file</span></p><p class="c1"><span class="c0">5. If it&#39;s 16/44 FLAC, go to media, sort by size, right-click on the entry and open in new tab to download (sometimes it appear after some time of playing and only in &ldquo;all&rdquo; instead of &ldquo;media&rdquo;)</span></p><p class="c1"><span class="c0">6*. On some 24 bit files, go to all, play the file and sort by size. You will find entry with increasing size with xhr type and flac name if it&rsquo;s not shown in media tab.</span></p><p class="c1"><span class="c0">7. Recently it happened once, that the point five stopped working and appearing FLAC link is red. Now you need to go to console and open a link with ERR_CERT_DATE_INVALID in new tab and open the site, clicking on advanced.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In case of 32 KB/s download, get Free Download Manager, and paste the download link there, and with 2 active connections in the downloader, it will speed up to 96KB/s occasionally (properly set JDownloader also allows increasing number of connections).<br>Haven&rsquo;t tried switching accounts to check if it will make the speeds back to normal (it wasn&rsquo;t like that before).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Some albums on allflac.com doesn&#39;t have tracks separated, but all the album is in track 1. </span></p><p class="c1"><span class="c0">If you want to physically divide the audio file -</span></p><p class="c1"><span>In such case, you can search for cue sheet here: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.regeert.nl/cuesheet/&amp;sa=D&amp;source=editors&amp;ust=1765035744436336&amp;usg=AOvVaw27uWoOM7ojqXzswUtg-Pcu">https://www.regeert.nl/cuesheet/</a></span></p><p class="c1"><span>Place it near the file, and eventually rename, and it&#39;s ready, but it&#39;s only for playing and playlist purposes. It doesn&#39;t separate the audio file physically. To cut the file losslesly you need lossless-cut </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/mifi/lossless-cut/releases/&amp;sa=D&amp;source=editors&amp;ust=1765035744436827&amp;usg=AOvVaw0eRqb5M146m74PAhKJFYhi">https://github.com/mifi/lossless-cut/releases/</a></span><span class="c0">&nbsp;- it allows importing cue sheet to cut the album. Now if you have all the files divided you can probably use MusicBrainz (probably Foobar2000 plugin is available) to tag the files (but not the filenames - for that, you need mp3tag and tagged files to copy tags to filenames with specific masks). I know that lossless-cut might be not precise, and it may create a problem with automatic content detection in MusicBrainz, but I know that tool or similar allowed to just search for the album you specifically searched for, and not by just mark files&gt;album detection in Foobar which may fail. So technically cutting and tagging the files should be possible, but time-consuming.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Looks like, unlike 24/48 files, all 24/96/192kHz ones are just vinyl rips taken from various torrents. If again there&rsquo;s only one or two files with the whole album, originally attached with cue, you should be able to find specific cue files simply searching in Google for its specific file name with quotes (file list is below track list there). Of course, you can also cut your album manually, or even make your own cue sheet to cut the album.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also be aware that sometimes you won&rsquo;t be able to download the file, and it won&rsquo;t appear as FLAC, if you do not press CTRL+R on Network before starting playing the file, otherwise you need to close and reopen the tab and press CTRL+R in Network again.</span></p><p class="c1"><span class="c0">And also, such file can reset during downloading near the end (maximum size of downloaded file cannot exceed 1GB, otherwise it gets reset for some reason). To prevent it, copy the download link from your browser, and paste it to some download accelerator. Even free BitComet will do the trick since it supports HTTP multiple connection downloading. If you&rsquo;re lazy, to prevent losing at least these 1GB, simply open the still downloaded file using MPC-HC and Chrome won&rsquo;t reset the file size after it starts to reset the whole download (because the file cannot be deleted now), wait for the reset of the download, now just make a copy of the file and rename file extension to FLAC from temporary extension added by e.g. Chrome during downloading. Now you can stop downloading in Chrome. The downside is - the moment the file gets reset is not when it ends, meaning it&rsquo;s not fully complete. But mostly. Of course, you can be lucky enough to find the original torrent with the files and simply finish downloading by verifying checksums of existing ones in P2P client (filenames must match to torrent files, simply replace them and find option to verify checksums).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>10b. All of the above applies to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.flacit.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744441688&amp;usg=AOvVaw1mNhAi_yCC6DqJRhlJ09fj">https://www.flacit.com/</a></span></p><p class="c1"><span class="c0">Looks like it has the same library taken from </span></p><p class="c1"><span class="c0">adamsfile.com </span></p><p class="c1"><span class="c0">which is warez also allowing playing files and downloading them using the method above.</span></p><p class="c1"><span>Y</span><span class="c0">ou also need to register before playing any file there (registration is free).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>11. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://flacmusicfinder.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744442436&amp;usg=AOvVaw3mGm6c2zGSVeoBWn7xIeqE">http://flacmusicfinder.com/</a></span></p><p class="c1"><span class="c0">But it has a small library.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>*. FLAC sites listed </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://fmhy.net/audiopiracyguide%23download-sites&amp;sa=D&amp;source=editors&amp;ust=1765035744442715&amp;usg=AOvVaw3OejERt-o4v2uc9r9Y8ZlG">here</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>12. Soulseek - but it&rsquo;s simply P2P based client, so carefully with that, and better use VPN (good one at best). GUI - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://nicotine-plus.org/&amp;sa=D&amp;source=editors&amp;ust=1765035744443184&amp;usg=AOvVaw1-5zVfXx2VWXoTOsAa5NGX">Nicotine+</a></span><span>&nbsp;and Seeker working on Android</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">13. Rutracker (the same advice as above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">14. Chomikuj.pl (use their search engine, eventually Yandex, Duckduckgo, Bing) - free 50MB per week for unlimited amounts of accounts, free transfer for points from files uploaded or shared from other people&rsquo;s profiles. People upload there separate tracks on loose as well, but they frequently get taken down, so search for rather full album titles in archives rather than single files. Mp3 files and those files which allow preview, can be downloaded for free with JDownloader, but occasionally some of such files might not work in JDownloader, and they&rsquo;ll have to be downloaded manually.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">15. Simply search for the track on Google, or even better - Yandex, Duckduckgo, eventually Bing, because Google frequently blacklists some sites or search entries. Also, your specific provider may cut connection to some sites, so you&#39;ll be forced to use VPN in that cases when a search engine shows up a result from a site you cannot open.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">16. YouTube Music - higher bitrate (256kbps) than max 128/160kbps on regular YT for Opus/webm (20kHz) and AAC/M4A 128kbps (16kHz). Similarly, like in Spotify - it can possess some exclusive files which are unavailable in lossless form on any other platform.</span></p><p class="c1"><span class="c0">If you have YouTube Premium you apparently can download files from it if you provide your token properly to yt-dl.</span></p><p class="c1"><span class="c0">Maybe logging into Google account with enabled premium in JDownloader 2 will do the trick as well.</span></p><p class="c1"><span class="c0">Anyway, Divolt bot will work too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">______</span></p><p class="c1"><span class="c0">Outdated/closed/defunct</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(it&#39;s been closed)</span></p><p class="c1"><span class="c0">0) Go to https://free-mp3-download.net (Deezer, FLAC, separate songs downloading)</span></p><p class="c1"><span class="c0">Here you can find (all?) mp3/flac files from Deezer. If the site doesn&#39;t work for you, use VPN. If the site doesn&#39;t search, mark &quot;use our VPN&quot;. Single files download and captcha. No tags for track numbers and file names, FLAC/MP3 16 bit only.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you see an error &ldquo;file not found on this server&rdquo; don&#39;t refresh, but go back and click download again.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- From time to time it happened that it didn&rsquo;t show up the FLAC option, and that it&#39;s &ldquo;unavailable&rdquo;, and sometimes it can show up after some period of time. The site started to have some problems, but it was fixed already.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">-Open every found track in a new tab, as back button won&#39;t allow you to see search results you looked for</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1 b) (doesn&rsquo;t work anymore for 07.02.24)</span></p><p class="c1"><span class="c0">Discord server with sharing bot (albums and songs)</span></p><p class="c1"><span class="c0">https://discord.gg/MmE4JnUVA</span></p><p class="c1"><span class="c0">-||-</span></p><p class="c1"><span class="c0">https://discord.gg/2HjATw6JF</span></p><p class="c1"><span class="c0">(another invite link valid till 12.11.13; needs to be renewed every month, probably current invitations will be on Divolt server here when the above will expire)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Later, they required writing to the bot via DM to access the welcome channel with requests. Once I couldn&#39;t access the channel, and I needed to update Discord or wait 10-15 minutes, so the input form appeared.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To download, in welcome channel, paste:</span></p><p class="c1"><span class="c0">$dl [link to the song or album on streaming service without brackets]</span></p><p class="c1"><span class="c0">More detailed instruction of usage below.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(Defunct)</span></p><p class="c1"><span class="c0">2) https://slavart.gamesdrive.net/tracks </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(sometimes used to work, but not too often) </span></p><p class="c1"><span class="c0">As of June 2023-March 2024 it is defunct, and throws: &ldquo;There was an error processing your request!&rdquo; on track download attempt, or in the past it was loading forever and nothing happens on multiple tries, before it worked after download button will stop being gray, and it&rsquo;s green again, so you should click it and download may start shortly, but it stopped, lately it was working, you only needed to wait a bit.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Similar search engine for FLACs. Files are sourced from Qobuz (including hi-res when available). Songs listed double are sometimes in higher bit depth/resolution (different versions of the same track). </span></p><p class="c1"><span class="c0">If you want to know what is the version you download, go to https://play.qobuz.com/ share track from there, and use download bots.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1 b) Join their Divolt server directly by this link (if the above stopped working):</span></p><p class="c1"><span class="c0">https://divolt.xyz/invite/Qxxstb7Q (currently the bot don&rsquo;t allow posting, containing only Discord invite, check it again later for valid link if necessary)</span></p><p class="c1"><span class="c0">Free registration required.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If this Divolt server is also down, go here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://slavart.gamesdrive.net/&amp;sa=D&amp;source=editors&amp;ust=1765035744451767&amp;usg=AOvVaw3e8ybilQJOMwipxWm1hB48">https://slavart.gamesdrive.net/</a></span><span class="c0">&nbsp;(defunct)</span></p><p class="c1"><span class="c0">to get a valid Divolt invite link (it might have changed). But it had the old link for the long time later.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>0) </span><span class="c68"><a class="c3" href="https://www.google.com/url?q=https://yams.tf/&amp;sa=D&amp;source=editors&amp;ust=1765035744452190&amp;usg=AOvVaw1DfoTMZH68hNr7ntpS2ocr">yams.tf</a></span><span class="c0">&nbsp;(offline) (Qobuz, Tidal, Deezer, Spotify, Apple Music [currently 320 kbps]) - for URLs, currently doesn&rsquo;t seem to work with even VPNs</span></p><h3 class="c67 c27" id="h.ueeiwv6i39ca"><span class="c19">Dolby Atmos ripping</span></h3><p class="c1"><span class="c0">&ldquo;Streamed Dolby Atmos is eac (5.1 Surround) and JOC (Joint Object coding) it&#39;s a hybrid file of channels and objects that decodes the 5.1 + joc to whatever your speakers are from 2.0 up to 9.1.6.</span></p><p class="c1"><span class="c0">It&#39;s not a multitrack, although clearly what some mixers do is put all the vocal in the center channel, so effectively you have an a cappella in center and then the instrumental in everything else, but many labels forbid engineers doing it and have policies that they must mix other sounds into center, so people don&#39;t rip the a cappella.</span></p><p class="c1"><span class="c0">[&ldquo;apparently Logic Pro does it automatically as well&rdquo; isling, src: ScrepTure]</span></p><p class="c1"><span>YouTube only supports FOA Ambisonics as spatial audio, but you can encode Dolby Atmos to Ambisonics. [by e.g. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mach1.tech/&amp;sa=D&amp;source=editors&amp;ust=1765035744453813&amp;usg=AOvVaw1GDLbUMkIhepid9IdUZUHK">https://www.mach1.tech/</a></span><span class="c0">]</span></p><p class="c1"><span class="c0">Apple Music has a larger amount [of Atmos songs] because Apple Pay the labels for exclusive Atmos deals.&rdquo; ~Sam Hocking</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Tidal only supports 5.1 or maybe 5.1.4, and Apple Music at least up to 7.1.4 (9.1.6 support could have been dropped since macOS Sonoma, not sure &ldquo;On latest MacOS you do now have the ability to decode directly to 7.1.4 pcm realtime from Apple Music.&rdquo;).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I tried using channels from an Atmos mix to get better instrumentals and very surprisingly it sounds a lot worse</span></p><p class="c1"><span class="c0">I rendered it into 7.1 and upmixed the channels into 3 separate stereo tracks, and processed each using unwa&#39;s v1e+</span></p><p class="c1"><span class="c0">It ended up sounding more muddy than using a lossless stereo mix&rdquo; - santilli_</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;sometimes rendering into 9.1.6 is good for some instruments yet everyone says it&rsquo;s really unnecessary</span></p><p class="c1"><span class="c0">which is kinda true</span></p><p class="c1"><span class="c0">like the 1-2 channel for 9.1.6 dolby is insanely clean on the songs i&rsquo;ve tried but some other stems sound a bit ehh&rdquo; - Isling</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c20">- from Tidal (via </span><span class="c34 c20">Tidal-Media-Downloader-PRO [Tidal-DL GUI]</span><span class="c6">)</span></p><p class="c1"><span class="c6">(doesn&rsquo;t work anymore for Atmos; see further below)</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span>Just get Tidal-dl with HiFi Plus </span><span class="c4"><a class="c3" href="#h.89rwiestpg95">subscription</a></span><span>&nbsp;</span><span class="c0">- now merged into one subscription (CLI version; for one user on our server it works for 13.10.22, but for some people strangely not).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For 30.04.24 with Tidal app installed on Windows and tidal-gui authorized by browser prompt/or automatically, Atmos files are not downloaded (checked all qualities in settings incl. 720/1080), at least on subscription automatically converted into higher plan due to recent changes (MQA files started to play since then, so it might be not subscription issue).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If having some problems, use tidal-dl (non-GUI) and tidal account with valid subscription and proper plan, set up to fire tv device api (option 5 iirc).</span></p><p class="c1"><span class="c0">But I cannot guarantee it will work for Atmos.</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.2myqsboh95hp"><span class="c22">&gt; from Tidal (with </span><span class="c4 c22"><a class="c3" href="https://www.google.com/url?q=https://github.com/Dniel97/orpheusdl-tidal&amp;sa=D&amp;source=editors&amp;ust=1765035744457555&amp;usg=AOvVaw1HWiUtcs34VUU66YOL9ynq">orpheus_dl_tidal</a></span><span class="c22">&nbsp;installed over </span><span class="c4 c22"><a class="c3" href="https://www.google.com/url?q=https://github.com/OrfiTeam/OrpheusDL&amp;sa=D&amp;source=editors&amp;ust=1765035744457698&amp;usg=AOvVaw0eWTgJC7VO42WihmskXL0I">orpheusDL</a></span><span class="c22">; max 5.1[.4?])</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Downloads </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tidal.com/browse/track/280733977&amp;sa=D&amp;source=editors&amp;ust=1765035744457969&amp;usg=AOvVaw3D-G5niLPrJrER-5HpNf_g">Atmos</a></span><span>&nbsp;</span><span>and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tidal.com/browse/track/200566143&amp;sa=D&amp;source=editors&amp;ust=1765035744458135&amp;usg=AOvVaw1O4Zt994r5c1vNLP9Oxm7t">high resolution</a></span><span>&nbsp;</span><span class="c0">files bigger than 24/48.</span></p><p class="c1"><span>It&rsquo;s only CLI app (valid </span><span class="c4"><a class="c3" href="#h.89rwiestpg95">subscription</a></span><span>&nbsp;</span><span class="c0">is still required).</span></p><p class="c1"><span class="c0">A bit convoluted installation. </span></p><p class="c1"><span>If you have problem with using git in the Windows command line, use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1V6ZwVgzYXjqc4QH9BGRoBqFZE-ZPNO16/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744458746&amp;usg=AOvVaw0HABnY-gFLN8ufZU_DagXO">this</a></span><span>&nbsp;ready OrpheusDL package (works for 30.04.24, later it can get outdated; it already has Tidal settings and Atmos enabled) </span><span class="c0">after you install python-3.9.13 or newer (works currently also on python-3.12.3-amd64). </span></p><p class="c1"><span class="c0">Or else, to install manually following GH instructions, to fix git issue, execute:</span></p><p class="c1"><span class="c0">pip install gitpython </span></p><p class="c1"><span>and/or install git from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://git-scm.com/download/win&amp;sa=D&amp;source=editors&amp;ust=1765035744459707&amp;usg=AOvVaw0Fi3EQVK1rkZvNt5UpztsF">here</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">(one or both of these should fix using git in CML when pip install git cannot find supported distribution and git command is not recognized).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Once Python and the OrpheusDL package is correctly installed, CML usage is:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">orpheus https://tidal.com/browse/track/280733977</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can place it as parameter for shortcut to orpheus.py on your desktop in Target (PPM on shortcut).</span></p><p class="c1"><span class="c0">E.g. &quot;C:\Program Files\OrpheusDL\orpheus.py&quot; https://tidal.com/browse/track/280733977</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or else, press Win+R&gt;cmd.exe, and if you&rsquo;re currently not at the same partition as Orpheus (e.g. C:\) press e.g. </span></p><p class="c1"><span class="c0">d:\</span></p><p class="c1"><span class="c0">and seek to the folder you have Orpheus installed, e.g. </span></p><p class="c1"><span class="c0">cd D:\Program Files\OrpheusDL\</span></p><p class="c1"><span class="c0">then execute</span></p><p class="c1"><span class="c0">orpheus https://tidal.com/browse/track/280733977</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Always delete &ldquo;?u&rdquo; at the end of the link copied from Tidal, or it won&rsquo;t work.</span></p><p class="c1"><span class="c0">Once you execute the command, it will ask you for login method (I tested the first one - TV) - now it will redirect to your browser to authorize.</span></p><p class="c1"><span class="c0">MQA is disabled by default (not used by Atmos), but you can enable it in config\settings\</span></p><p class="c1"><span class="c0">by editing &quot;proprietary_codecs&quot;: to false in line 21.</span></p><p class="c1"><span>Downloaded files are located in OrpheusDL\downloads folder</span></p><p class="c1"><span class="c20"><br>spatial_codecs</span><span class="c0">&nbsp;flag is enabled by default and supports Dolby Atmos and 360 Reality Audio.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Some of the 360 stuff is impossible to split right now. Not sure what is going on. Maybe some type of new encryption. I have the MP4 to David Bowie Heroes 22 channels, and it&#39;s a brick, useless&hellip;&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The output of downloaded Atmos files is m4a encoded in E-AC-3 JOC (Enhanced AC-3 with Joint Object) - &nbsp;Dolby Digital Plus with Dolby Atmos and possibly AC-4, and FLAC for hi-res</span></p><p class="c1"><span class="c0">Downloaded hi-res and Atmos files can be played in e.g. MPC-HC or VLC Media Player, but will fail on some old players like Foobar2000 1.3 and 1.6.</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.b33tzk42zlc"><span class="c22">&gt; from Tidal (with </span><span class="c4 c22"><a class="c3" href="https://www.google.com/url?q=https://github.com/exislow/tidal-dl-ng&amp;sa=D&amp;source=editors&amp;ust=1765035744464141&amp;usg=AOvVaw1w3arHi8bxFj0Zznc1HnKI">https://github.com/exislow/tidal-dl-ng</a></span><span class="c22">)</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c6">from Apple Music (Android, max 7.1[.4?])</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/adoalin/apple-music-alac-downloader&amp;sa=D&amp;source=editors&amp;ust=1765035744464629&amp;usg=AOvVaw3FQTdRStagYS1gmjqDpeNZ">https://github.com/adoalin/apple-music-alac-downloader</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Installation tutorial:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DblazHnCh6jQ&amp;sa=D&amp;source=editors&amp;ust=1765035744465043&amp;usg=AOvVaw38T9ODcp_ZZY373u4wmo-g">https://www.youtube.com/watch?v=blazHnCh6jQ</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Pre-Requisites:</span></p><p class="c1"><span class="c0">x86_64 bit device (Intel/AMD Only)</span></p><p class="c1"><span>Install Python: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.python.org/&amp;sa=D&amp;source=editors&amp;ust=1765035744465584&amp;usg=AOvVaw1n3PokczDmRAEWXn8iBBsZ">https://www.python.org/</a></span></p><p class="c1"><span>Install Go: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://go.dev/doc/install&amp;sa=D&amp;source=editors&amp;ust=1765035744465801&amp;usg=AOvVaw3JW4_R1K0FKqJgqCXtyP7Z">https://go.dev/doc/install</a></span></p><p class="c1"><span>Install Android Platform Tools: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://developer.android.com/tools/releases/platform-tools&amp;sa=D&amp;source=editors&amp;ust=1765035744466110&amp;usg=AOvVaw3FzQ96fvrk6YALjXgorCd7">https://developer.android.com/tools/releases/platform-tools</a></span></p><p class="c1"><span class="c0">and set it to environment variables / path</span></p><p class="c1"><span>Download and extract Frida Server - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/frida/frida/releases/download/16.2.1/frida-server-16.2.1-android-x86_64.xz&amp;sa=D&amp;source=editors&amp;ust=1765035744466576&amp;usg=AOvVaw1qQBqom33HU3SnH7Kan8Hu">https://github.com/frida/frida/releases/download/16.2.1/frida-server-16.2.1-android-x86_64.xz</a></span></p><p class="c1"><span>Download Apple Music ALAC Downloader - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/adoalin/apple-music-alac-downloader&amp;sa=D&amp;source=editors&amp;ust=1765035744466910&amp;usg=AOvVaw25GA5aaP0fuB479sDnK6Ra">https://github.com/adoalin/apple-music-alac-downloader</a></span></p><p class="c1"><span class="c0">Extract content to any folder.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1)</span></p><p class="c1"><span class="c0">Install Android Studio</span></p><p class="c1"><span class="c0">Create a virtual device on Android Studio with an image that doesn&#39;t have Google APIs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2)</span></p><p class="c1"><span>Install SAI - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Aefyr/SAI&amp;sa=D&amp;source=editors&amp;ust=1765035744467672&amp;usg=AOvVaw2L-Yq-4rzh24Cka9ZqTkVH">https://github.com/Aefyr/SAI</a></span></p><p class="c1"><span>Install Apple Music 3.6.0 beta 4 - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.apkmirror.com/apk/apple/apple-music/apple-music-3-6-0-beta-release/apple-music-3-6-0-beta-4-android-apk-download/&amp;sa=D&amp;source=editors&amp;ust=1765035744468176&amp;usg=AOvVaw2ii2OC4cTszQAdix715j4v">https://www.apkmirror.com/apk/apple/apple-music/apple-music-3-6-0-beta-release/apple-music-3-6-0-beta-4-android-apk-download/</a></span></p><p class="c1"><span class="c0">Launch Apple Music and sign in to your account. Subscription required.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3)</span></p><p class="c1"><span class="c0">Open Terminal</span></p><p class="c1"><span class="c0">adb forward tcp:10020 tcp:10020</span></p><p class="c1"><span class="c0">if u get a msg that there are more than 1 emulator/devices running, seek up NTKDaemonService in task manager/services and stop it</span></p><p class="c1"><span class="c0">adb root</span></p><p class="c1"><span class="c0">cd frida-server-16.2.1-android-x86_64</span></p><p class="c1"><span class="c0">adb push frida-server-16.2.1-android-x86_64 /data/local/tmp/</span></p><p class="c1"><span class="c0">adb shell &quot;chmod 755 /data/local/tmp/frida-server-16.2.1-android-x86_64&quot;</span></p><p class="c1"><span class="c0">adb shell &quot;/data/local/tmp/frida-server-16.2.1-android-x86_64 &amp;&quot;</span></p><p class="c1"><span class="c0">The steps above place Frida-server on your Android device and starts the Frida-server.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4)</span></p><p class="c1"><span class="c0">Open a new Terminal window</span></p><p class="c1"><span class="c0">Change directory to Apple Music ALAC Downloader folder location</span></p><p class="c1"><span class="c0">pip install frida-tools</span></p><p class="c1"><span class="c0">frida -U -l agent.js -f com.apple.android.music</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5)</span></p><p class="c1"><span class="c0">Open a new Terminal window</span></p><p class="c1"><span class="c0">Change directory to Apple Music ALAC Downloader folder location</span></p><p class="c1"><span class="c0">Start downloading some albums:</span></p><p class="c1"><span class="c0">go run main.go https://music.apple.com/us/album/beautiful-things-single/1724488123</span></p><p class="c1"><span class="c0">go run main_atmos.go &quot;https://music.apple.com/hk/album/&#21608;&#26480;&#20523;&#22320;&#34920;&#26368;&#24375;&#19990;&#30028;&#24033;&#36852;&#28436;&#21809;&#26371;/1721464851&quot; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">- from Apple Music (alternative tool)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rentry.co/AppleMusicDecrypt&amp;sa=D&amp;source=editors&amp;ust=1765035744471133&amp;usg=AOvVaw1gFPJ5YgyTy_Yof2dUXnOB">https://rentry.co/AppleMusicDecrypt</a></span></p><p class="c1"><span class="c0">(after March 5, 2025 get WSA from here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/MustardChef/WSABuilds&amp;sa=D&amp;source=editors&amp;ust=1765035744471501&amp;usg=AOvVaw0pGF57bNXrDabARIaN8_ba">https://github.com/MustardChef/WSABuilds</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">from Apple Music (MacOS, virtual soundcard recording)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>(Guide by Mikeyyyyy/K-Kop Filters, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/992461132755369984&amp;sa=D&amp;source=editors&amp;ust=1765035744472005&amp;usg=AOvVaw0maEoSZYA3tXTa2TXttJI_">source</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You will need a Mac to do this, this will only work for MacOS, you will need an Apple Music subscription, &quot;Blackhole 16ch&quot; and any DAW of your choice I prefer FL Studio (can be also Audacity),</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Step 1. Install Blackhole Audio driver (search for it in Google)</span></p><p class="c1"><span class="c0">Step 2. Download the song you want in Dolby Atmos (if you don&#39;t know how to do it, go to settings in Apple Music then to general then toggle download Dolby Atmos)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Step 3. Go to your desired DAW and in your mixed select input, and it will show your 16 outputs select 1, (Mono) for the first mixer, then number 2 mixer do the same but 2 and so on until you reached 6</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Step 4. Hit record and play the track in Dolby, and you&#39;re done!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://sharemania.us/threads/tutorial-how-to-rip-apple-musics-dolby-atmos-channels-7-1-4.209629/?__cf_chl_tk%3De.AYlwMiV9oW5skYALD286x_IM5QgjDS0GaB_FxH610-1682477648-0-gaNycGzNDFA&amp;sa=D&amp;source=editors&amp;ust=1765035744473624&amp;usg=AOvVaw3PTxH00tg9jbSXn6EWL-6_">Similar</a></span><span class="c0">&nbsp;tutorial based on Blackhole and Audacity on Mac (open the link in incognito in case of infinite captcha)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;On latest MacOS you do now have the ability to decode directly to 7.1.4 pcm realtime from Apple Music. If you use a loopback virtual audio driver you can record the 12 channels. Depending on how song was mixed might mean the C channel has even even clearer vocal.</span></p><p class="c1"><span class="c0">Probably worth mentioning Dolby Atmos is delivered as dd+ (Dolby Digital 5.1 Surround downmix) but JOC allows it to be decoded up to 9.1.6 16 channels. To do that you need either an AVR or Dolby Reference Player or Cavern/Cavernize.&rdquo; Sam</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You won&#39;t be able to do the same on Windows with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.nerds.de/en/loopbeaudio.html&amp;sa=D&amp;source=editors&amp;ust=1765035744474942&amp;usg=AOvVaw1kBD0yYanD5QlwsUrmNCsL">LoopBeAudio</a></span><span class="c0">&nbsp;instead (paid, but trial works for every 60 minutes after boot) because Apple Music on Windows (including the one in MS Store) doesn&#39;t provide Dolby Atmos (7.3.1) files at all (only stereo hi-res lossless) no matter what virtual soundcard you use, so you&#39;ll need Hackintosh or VMware.</span></p><p class="c1"><span class="c0">&quot;Vmware kinda lag</span></p><p class="c1"><span>and find own seri to fix login apple services&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ittiam-systems/libmpegh&amp;sa=D&amp;source=editors&amp;ust=1765035744475808&amp;usg=AOvVaw0XOIFwrp4fE-HKLNCdZ62S">ittiam-systems/libmpegh: MPEG-H 3D Audio Low Complexity Profile Decoder</a></span></p><p class="c1"><span class="c0">Using this program, you can extract the 12 channels of the Dolby Atmos tracks.</span></p><p class="c1"><span class="c0">&ldquo;MPEG-H is essentially Sony360, just Sony360 licenced decoders needed. Fraunhofer allow it to be used for free, though.</span></p><p class="c1"><span class="c0">ia_mpeghd_testbench.exe -ifile:&quot;FILENAME.mhm&quot; -ofile:track1.wav</span></p><p class="c1"><span class="c0">or:</span></p><p class="c1"><span class="c0">ia_mpeghd_testbench.exe -ifile:&quot;input file name.m4a&quot; -ofile:&quot;output file name.wav&quot; -cicp:13</span></p><p class="c1"><span class="c0">&ldquo;renders to 22.2 as well&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mpegh.lze-innovation.de/%23LZE&amp;sa=D&amp;source=editors&amp;ust=1765035744476749&amp;usg=AOvVaw2tjeqe5x-hGPbKmStahM3Z">https://mpegh.lze-innovation.de/#LZE</a></span></p><p class="c1"><span class="c0">But seems like you need to write them some message.</span></p><p class="c1"><span class="c0">Above it tells it&#39;s for professionals, but try your luck:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.iis.fraunhofer.de/en/ff/amm/broadcast-streaming/mpegh.html?source%3Dpost_page---------------------------&amp;sa=D&amp;source=editors&amp;ust=1765035744477288&amp;usg=AOvVaw34UcX-FMSgMIJ3AbWwiBPQ">https://www.iis.fraunhofer.de/en/ff/amm/broadcast-streaming/mpegh.html?source=post_page</a></span></p><p class="c1"><span class="c0">You should also have a success with extracting stems with MMH Atmos Helper &ldquo;includes a MPEG-H decoder built-in apparently&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.iis.fraunhofer.de/en/ff/amm/broadcast-streaming/mpegh.html?source%3Dpost_page---------------------------&amp;sa=D&amp;source=editors&amp;ust=1765035744477731&amp;usg=AOvVaw1Osu2tBTAQR_Opj-rSLZZD">---------------------------</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">All Dolby Atmos is encoded, so to play it, basically it has to be decoded to audio playback through a Dolby licensed decoder. There are ways to decode, though. Easiest is to use Cavern.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cavern.sbence.hu/cavern/&amp;sa=D&amp;source=editors&amp;ust=1765035744478253&amp;usg=AOvVaw0bHiBzi5rPxyrpX8ghhVWz">https://cavern.sbence.hu/cavern/</a></span></p><p class="c1"><span class="c0">Atmos is a lossy format. 768kbps across 6 channels so not the highest resolution, but to decode to multichannel .wav just download cavern and put your dd+joc file through Cavernize. Streamed Atmos [is lossy]. TrueHD Atmos isn&#39;t. Atmos Music is only distributed lossy, though.</span></p><p class="c1"><span>You can encode Dolby Atmos to Ambisonics by e.g. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mach1.tech/&amp;sa=D&amp;source=editors&amp;ust=1765035744478977&amp;usg=AOvVaw2meo109YT3okFyNEO8Xa1m">https://www.mach1.tech/</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Atmos files downloaded from Tidal with OrpheusDL are simply FLACs in m4a container, and can be read by MPC-HC, VLC, and Foobar 2.x.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>On the side, &ldquo;The process of making Atmos [</span><span class="c20">from an engineer standpoint</span><span class="c0">] is:</span></p><p class="c1"><span class="c0">DAW &gt; 128 channel ADM_BWF &gt; 7.1.4 &gt;5.1(joc). So basically those 128 channels are encoded to 6, but the object audio is still known where it should exist in the space and pulls that audio out of the 5.1 channels to make up to 9.1.6 (max supported for music)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">And authoring for Atmos is not available on Windows but:</span></p><p class="c1"><span class="c0">&ldquo;Traditionally it&#39;s not been unless you ordered a DELL from Dolby configured to use as a Rendering machine, but today both Dolby Atmos Renderer, DAWs like Cubase and Nuendo and 3rd party VST exist to do it on Windows now. I use Fiedler Atmos Composer on a stereo DAW called Bitwig to build demix projects for Atmos engineers to then master to Atmos from Stereo (sometimes all they have left to work with as multitrack tapes lost/destroyed/politics/easier)&rdquo; ~Sam Hocking</span></p><p class="c1 c7"><span class="c0"></span></p><h3 class="c67 c27" id="h.konra76mukwf"><span class="c19">360 Reality Audio FAQ</span></h3><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;A lot more stems in 360, and it has no bleeding or filtered sounding artifacts.</span></p><p class="c1"><span class="c0">A big problem with Dolby stems is artifacts, essentially none of that in 360.</span></p><p class="c1"><span class="c0">And if there is bleeding in 360 then the volume is completely balanced and doesn&rsquo;t change all the time&rdquo; - I.</span></p><p class="c1"><span class="c0">Q (isling): Is there a way to just listen to 360 files locally while still getting the immersive 3d effect?</span></p><p class="c1"><span class="c0">Decoding them and listening in DAWs don&#39;t sound like how they do on Amazon Music for example.</span></p><p class="c1"><span class="c0">Is there even a way to listen to them without decoding? I&#39;ve downloaded the MPEG-H software stuff.</span></p><p class="c1"><span class="c0">The MPEG-H format player doesn&#39;t read the decoded WAVs nor supports m4a which is what the original non-decoded files are.</span></p><p class="c1"><span class="c0">The 360 WalkMix player didn&#39;t work either.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ittiam-systems/libmpegh/releases&amp;sa=D&amp;source=editors&amp;ust=1765035744482678&amp;usg=AOvVaw0Xf1GS_hWgyipDm6Xfp9el">https://github.com/ittiam-systems/libmpegh/releases</a></span></p><p class="c1"><span class="c0">This one is the one I use, works great to use, but doesn&rsquo;t have the same 3D effect.</span></p><p class="c1"><span class="c0">I tried playing the decoded 360 Reality Audio stems in VLC as it has the best Dolby effect, but it didn&#39;t have all the channels playing.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>A (Sam Hocking): I&#39;ve worked it out, there&#39;s a free decoder. These are the main MPEG-H tools for both creating and playing MPEG-H 3D: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mpegh.lze-innovation.de/&amp;sa=D&amp;source=editors&amp;ust=1765035744483517&amp;usg=AOvVaw2X5pp0ZJcikVXNmSuxtLT_">https://mpegh.lze-innovation.de/</a></span></p><p class="c1"><span class="c0">All free. The plugin is really cool. Request the plugin from their site.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Dolby and Sony 360 are object based [not channel base like Ambisonics]. Sony 360 is just protected MPEG-H 3D.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">When you rip from Tidal, you can choose how you decode the file to channel-based audio. This is the point of object-based audio, you decode it to what number of speakers you have</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you use tidal-gui, enter an Android token from your Tidal app on the phone and download the file, then you can decode the Sony 360 / MPEG-H by the following:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp;Description in format Front/Surr.LFE</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 1: 1/0.0 &nbsp; &nbsp;- C</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 2: 2/0.0 &nbsp; &nbsp;- L, R</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 3: 3/0.0 &nbsp; &nbsp;- C, L, R</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 4: 3/1.0 &nbsp; &nbsp;- C, L, R, Cs</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 5: 3/2.0 &nbsp; &nbsp;- C, L, R, Ls, Rs</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 6: 3/2.1 &nbsp; &nbsp;- C, L, R, Ls, Rs, LFE</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 7: 5/2.1 &nbsp; &nbsp;- C, Lc, Rc, L, R, Ls, Rs, LFE</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 8: NA</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 9: 2/1.0 &nbsp; &nbsp;- L, R, Cs</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 10: 2/2.0 &nbsp; - L, R, Ls, Rs</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 11: 3/3.1 &nbsp; - C, L, R, Ls, Rs, Cs, LFE</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 12: 3/4.1 &nbsp; - C, L, R, Ls, Rs, Lsr, Rsr, LFE</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 13: 11/11.2 - C, Lc, Rc, L, R, Lss, Rss, Lsr, Rsr, Cs, LFE, LFE2, Cv, Lv, Rv,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Lvss, Rvss, Ts, Lvr, Rvr, Cvr, Cb, Lb, Rb</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 14: 5/2.1 &nbsp; - C, L, R, Ls, Rs, LFE, Lv, Rv</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 15: 5/5.2 &nbsp; - C, L, R, Lss, Rss, Ls, Rs, Lv, Rv, Cvr, LFE, LFE2</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 16: 5/4.1 &nbsp; - C, L, R, Ls, Rs, LFE, Lv, Rv, Lvs, Rvs</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 17: 6/5.1 &nbsp; - C, L, R, Ls, Rs, LFE, Lv, Rv, Cv, Lvs, Rvs, Ts</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 18: 6/7.1 &nbsp; - C, L, R, Ls, Rs, Lbs, Rbs, LFE, Lv, Rv, Cv, Lvs, Rvs, Ts</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 19: 5/6.1 &nbsp; - C, L, R, Lss, Rss, Lsr, Rsr, LFE, Lv, Rv, Lvr, Rvr</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; 20: 7/6.1 &nbsp; - C, Leos, Reos, L, R, Lss, Rss, Lsr, Rsr, LFE, Lv, Rv, Lvs, Rvs</span></p><p class="c1"><span class="c0">Note: CICP 13 is applicable for baseline profile streams with only object audio. </span></p><p class="c1"><span class="c0">But the delivery is all contained within 12 channels (7.1.4)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There are different levels of MPEG-H. For streaming, it&#39;s 7.1.4 which is level 3 IIRC.</span></p><p class="c1"><span class="c0">Q: 3rd order Ambisonics you mean? And 7.1.4 is literally just Dolby, right?</span></p><p class="c1"><span class="c0">A: No 7.1.4. You can consider it the same as Dolby Atmos.</span></p><p class="c1"><span class="c0">It&#39;s object-based audio, Ambisonics is channel based audio.</span></p><p class="c1"><span class="c0">Q: Isn&#39;t 360 RA Ambisonics though? Dolby is object based, right?</span></p><p class="c1"><span class="c0">A: Yep, Dolby and Sony 360 are object based. Sony 360 is just protected MPEG-H 3D </span></p><p class="c1"><span class="c0">Q: So Sony 360 is also object based? So it&#39;s not Ambisonics</span></p><p class="c1"><span class="c0">A: [Sony 360 7.1.4 &ldquo;decoded to normal channel-based audio&rdquo; looks like just 12 stems which can be imported into Audacity]</span></p><p class="c1"><span class="c0">Q: The one I got was from Amazon Music, not Tidal. Shouldn&#39;t make a difference?</span></p><p class="c1"><span class="c0">A: It&#39;s actually far more powerful than Dolby Atmos in this sense.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Music Media Helper can decode Sony 360. Last time i checked they are possible to rip from Tidal although iirc Tidal are dropping 360 support?</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.quadraphonicquad.com/forums/threads/music-media-helper-tools-for-multichannel-audio-music-videos.22693/&amp;sa=D&amp;source=editors&amp;ust=1765035744489456&amp;usg=AOvVaw0_hQO_l8u5sRZOWXZAXBw4">https://www.quadraphonicquad.com/forums/threads/music-media-helper-tools-for-multichannel-audio-music-videos.22693/</a></span><span class="c0">&nbsp;(Sam)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Alternatively, this paid plugin can handle 360RA downmix to binaural audio. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.perfectsurround.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744489794&amp;usg=AOvVaw240g9gk-Fm5mO9UJOgp90w">https://www.perfectsurround.com/</a></span><span class="c0">&nbsp;but you need an iLok ID even for the free trial (jarredou)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.ki1wmwa90cgp"><span class="c53">___</span><span class="c42 c47 c22 c30 c50">AI mastering services___</span></h2><p class="c2"><span class="c0">Might be useful even for enhancing quality of instrumentals after separation (or your own mixed music)</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that at least some advanced mixing beforehand may cheat the content ID detection system, so your song won&#39;t be detected. If some label prevents from uploading their stuff on YT by blocking it straight after uploading regular file, you may get a copyright strike after some time of uploading mastered instrumental as they also use search engine on YT too to find their tracks.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you don&#39;t find satisfying results with the services below, read </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?usp%3Ddrivesdk&amp;sa=D&amp;source=editors&amp;ust=1765035744491432&amp;usg=AOvVaw1dv85OWqIMAucrZ22WPwS0">that</a></span><span class="c0">.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Paid</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://emastered.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744491800&amp;usg=AOvVaw3ZAXlIQo394x5tjAUkxO87">https://emastered.com/</a></span><span class="c0">&nbsp;(unlimited free preview, 150$ per year)</span></p><p class="c1"><span class="c0">Preview is just mp3 320kbps @20kHz cutoff, which is claimed to have a watermark, but it cannot be heard or seen in Spek. The preview file can be downloaded by opening Developer Tools in browser, and playing preview, then in &quot;media&quot;, the proper file should appear on the list (don&#39;t confuse it with original file), now open the proper link in the new tab and open options of the media player and simply click download.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s the most advanced and better sounding service vs all free ones I tested (even if you have only access to mp3, but I also listened to max 24 bit WAVs on their site with a paid account). Also, it&#39;s one of those, which are potentially destructive if you apply wrong settings, but leaving everything in default state is a good starting point, and works decent for e.g. mixtures and even previously mastered music to some extent, at least which does not hit 0dB (but e.g. even -1dB, but it is claimed to work the best between -3dB and -6dB). Generally I recommend it. Worth trying out.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Note for paid users - be aware that preview files can be mp3 files as well. So what you hear during changing various parameters, is not exactly the same as final WAV output.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://distrokid.com/mixea/&amp;sa=D&amp;source=editors&amp;ust=1765035744494750&amp;usg=AOvVaw1VETGD8aJgxy2ohxCj_wIs">https://distrokid.com/mixea</a></span><span class="c0">&nbsp;(99$ per year/first master for free)</span></p><p class="c1"><span class="c0">&ldquo;[vs LANDR, BandLab and eMastered] I experienced that Mixea mastered with a much stronger sound and brighter (in a good way, the trebles are very clear) than the others.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.masteringbox.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744495268&amp;usg=AOvVaw2tOx_yl9RNnndq-OfriNTA">https://www.masteringbox.com</a></span><span class="c0">&nbsp;&gt;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.landr.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744495403&amp;usg=AOvVaw338RO4dGOOGgsvQnWdPEnU">https://www.landr.com/</a></span><span class="c0">&nbsp;(now also plugin available)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://masterchannel.ai&amp;sa=D&amp;source=editors&amp;ust=1765035744495619&amp;usg=AOvVaw2hEd05zcv7j5ECK6uvJSi3">https://masterchannel.ai</a></span><span class="c0">&nbsp;(15/20$ per month, only free previews, also can convert stereo to multichannel audio)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ariamastering.com/en/Pricing&amp;sa=D&amp;source=editors&amp;ust=1765035744495946&amp;usg=AOvVaw3OcyZX8BDDaV-wyYVPuHPF">https://ariamastering.com/en/Pricing</a></span><span class="c0">&nbsp;(from 50$ per month or 9.90$ per master, mastering based on fully analog gear and robotic arm to make adjustments in real time)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">VST plugins</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.izotope.com/en/shop/ozone-11-advanced/&amp;sa=D&amp;source=editors&amp;ust=1765035744496463&amp;usg=AOvVaw13o6XvcfDUTJCmCghmPkbl">iZotope Ozone Advanced</a></span><span class="c0">&nbsp;9 and up (paid)</span></p><p class="c1"><span class="c0">Version Advanced has a new AI mastering feature which automatically detects parameters which can be manually adjusted after the process. It works pretty well, and repairs lots of problems with muddy mixes (especially with manual adjustments - don&#39;t be afraid to experiment - AI is never perfect).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Mastering Assistant built-in the recent versions of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.apple.com/logic-pro/&amp;sa=D&amp;source=editors&amp;ust=1765035744497202&amp;usg=AOvVaw1575cUGSTh48V6hWdNQaDY">Logic Pro</a></span><span class="c0">&nbsp;DAW (MacOS only)</span></p><p class="c1"><span class="c0">It can give more natural results than Izotpe above </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.exonicuk.com/product-page/ai-master&amp;sa=D&amp;source=editors&amp;ust=1765035744497585&amp;usg=AOvVaw3-c3c2xoCh6KlPSjFpGwis">AI Master by Exonic UK</a></span><span class="c0">&nbsp;(paid)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://bedroomproducersblog.com/2023/03/05/master_me/&amp;sa=D&amp;source=editors&amp;ust=1765035744497773&amp;usg=AOvVaw1aDuwGR5MYFxOJMebN_3eX">master_me</a></span><span class="c0">&nbsp;(free)</span></p><p class="c1"><span class="c0">It contains a decent mastering chain which adjusts settings for you automatically for the song which can be changed later, and also you can change target ilufs value manually. By default, it&#39;s -14 ilufs and can be too quiet for songs already mastered louder, and it can become destructive while set that way for some songs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Free</span><span>&nbsp;</span><span class="c22">online services</span><span class="c22 c31">&nbsp;</span><span class="c0">(all below remarks apply when mastering AI separated instrumentals)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://aimastering.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744498778&amp;usg=AOvVaw36or0wwIAEM0yeOPjCVs3D">https://aimastering.com/</a></span><span>&nbsp;(redirects to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://bakuage.com/app/&amp;sa=D&amp;source=editors&amp;ust=1765035744498914&amp;usg=AOvVaw3SPRrkz_N0-R_E37jTBvQ6">https://bakuage.com/app/</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">wav, mp3, mp4 accepted, output: wav 16-32, mp3 320kbps, 44 or 48kHz</span></p><p class="c1"><span class="c0">You can optionally specify a reference audio file.</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">Tons of options but not comfortable preview during tweaking them. You can optionally specify the reference audio, uploading a file. Also, there&rsquo;s one completely automatic option. Generally it can be destructive to the sound, even using the most automatic setting - attenuation of bass, exaggerating of higher tones.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Preferred options while working with a bit muffled snare in the mix of 500m1 model for instrumental rap separation result </span></p><p class="c1"><span class="c0">(automatic (easy master) is (only) good for mixtures [vocal+instr]): </span></p><ul class="c9 lst-kix_tl77ogq6q7u-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">True Peak, Oversampling 2x, AM Level 0.3, WAV 32. SAO, 0/22000 (the rest untouched)</span></li></ul><p class="c1"><span class="c0">For still too muffled sound (e.g. when lost in lots of hi-hats): </span></p><ul class="c9 lst-kix_pv4jsz2h74wk-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">YouTube Loudness, OVS to 1x and AM Level 0.2 and 24 bit (+ true peak, SAO, 0/22000)</span></li></ul><p class="c1"><span class="c0">Alternative (good for mixtures and previously mastered music with a bit muddy snare):</span></p><ul class="c9 lst-kix_w21i9d12ynhg-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">YouTube Loudness, Target Loudness -8, Ceiling -0.2, OVS to 2x, True Peak and AM Level 0.3 and 32 bit, SAO, 0/22000</span></li></ul><p class="c1"><span class="c0">The most complicated tool, but the most capable amongst all free ones mentioned here so far. After two first files, it gets you into a short queue. Processing takes 2-3 minutes. Cannot upload more tracks than one at the same time. Great metrics, e.g. one measuring overall &quot;professionality&quot; of the result master. At this point, it can also start exaggerating vocal leftovers from the separation process. Equalize Loudness doesn&rsquo;t do anything when checked just before download (probably only after when you click remaster).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>They also have offline app: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ai-mastering/phaselimiter-gui/releases/tag/v0.1.1&amp;sa=D&amp;source=editors&amp;ust=1765035744503560&amp;usg=AOvVaw3f1Y6v4yciNKHj8IO0CvDm">https://github.com/ai-mastering/phaselimiter-gui/releases/</a></span></p><p class="c1"><span class="c0">with some features used on Bakuage/aimastering.com</span></p><p class="c1"><span class="c0">&ldquo;but most of the settings you want are on their site, their offline version is set and forget. (...) doesn&#39;t give you some specific settings to adjust.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://moises.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035744504214&amp;usg=AOvVaw22GQodLIFLWMr2d6p4n14q">https://moises.ai/</a></span></p><p class="c1"><span class="c0">16-32 bit WAV output (now WAV is only in premium), any input formats. They have bad separation tools, but great, neutral mastering AI. It works very good for vinyl rips. You can get more than 5 tracks per month for free (don&rsquo;t know how many - the 5 tracks limit is for separation, not for mastering feature, at least 30 worked in 2022).</span></p><p class="c1"><span class="c0">The mastering feature is only available in the web version, so if you&rsquo;re on the phone, run the site in PC mode.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">24 bit -9 iLUFS / or without limiter does the best job in most cases for e.g. GSEP (the latter is when you don&rsquo;t want to smooth out the sound). -8 tends to harm the dynamics of songs, but in some cases it might be useful to get your snare louder.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The interface has a bug when you need to pick your file to upload twice, otherwise you won&rsquo;t be able to change parameters and confirm the upload process (also on mobile parameters not always appear immediately after you pick your file/pasted link enlisting the options manually doesn&rsquo;t let you confirm the step to proceed to upload, and you need to retry picking the file, and now you can proceed).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes uploading is stuck for very, very long on 99% and if you leave your phone in sleep mode and return after 15 minutes, it will start some upload again on this 99%, but eventually it will return the error. You simply need to retry uploading the file (it will also stack at 99%, but it will still upload at that time). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, importing the same file via GDrive may not work.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Additionally, if you pick 32 bit output quality, when mastering is done, when you will want to download the file, in WAV it will show 24 bit, but the file will be 32 bit as you selected before.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&rsquo;s the most neutral in sound in comparison to the two below.</span></p><p class="c1"><span>If you plan to master your own music, read &ldquo;Preparing your tracks&rdquo; here: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://moises.ai/blog/how-to-master-a-song-home/&amp;sa=D&amp;source=editors&amp;ust=1765035744507619&amp;usg=AOvVaw1efo1R-jqWnvpGUBfwLyhg">https://moises.ai/blog/how-to-master-a-song-home/</a></span><span class="c0">&nbsp;I think these tips are pretty universal for all of these services.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mastering.studio/&amp;sa=D&amp;source=editors&amp;ust=1765035744507921&amp;usg=AOvVaw3k16z45d0MGqEAO2qLuwQs">https://www.mastering.studio/</a></span></p><p class="c1"><span class="c0">Four presets with live preview, only 16 bit WAV for free, only WAV as input accepted (for the best quality convert any mp3&rsquo;s to WAV 32-bit float (you can use Foobar2000), 64 bit WAV input unsupported).</span></p><p class="c1"><span class="c0">If you see &quot;upload failed&quot;, register and activate a new account in incognito mode and everything using VPN (probably a block for ISP which I had).</span></p><p class="c1"><span class="c0">Judging by only 16 bit output quality (which is unfair comparison to 24 bit on moises.ai) and for GSep 320kbps files, I found it worse, and even the London smooth preset is not so neutral like moises in overall, and it can be destructive to the sound quality. But, if you need to get something extra from the mix if it&rsquo;s blurry, that&rsquo;s a good choice (while some people can find emastered too pricy).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">BandLab Assistant mastering</span></p><p class="c1"><span class="c0">First, you need to download their assistant here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.bandlab.com/products/desktop/assistant&amp;sa=D&amp;source=editors&amp;ust=1765035744509562&amp;usg=AOvVaw3dekmor6hQg6vXknpJOs4U">https://www.bandlab.com/products/desktop/assistant</a></span></p><p class="c1"><span class="c0">Then insert the file, pick preset, listen, and then it is uploaded for further processing, and you&rsquo;re redirected to the download page.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">They write more about it below:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.bandlab.com/mastering&amp;sa=D&amp;source=editors&amp;ust=1765035744510063&amp;usg=AOvVaw3qJnRgMR53yHxBvXLErm-2">https://www.bandlab.com/mastering</a></span></p><p class="c1"><span class="c0">Four presets - CD, enhance, bass boost, max 16 bit WAV output only. In comparison to paid emastered, it&rsquo;s average. But in some cases it&rsquo;s better than free mastering.studio when you have a muffled snare in the instrumental. On GSEP only CD preset was usable. The sound is more crusty than even LA Punch - more saturated (less neutral) a bit too bassy and compressed, but it may work in some songs where you don&rsquo;t have a better choice and all above failed.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If your file doesn&rsquo;t start uploading (hangs on &ldquo;Preparing Master&rdquo;), make sure you don&#39;t have &ldquo;Set as a metered connection&rdquo; option enabled in W10/11. If yes, disable it, and restart the assistant.</span></p><p class="c1"><span class="c0">Straight after your file is done uploading, it is being processed, so don&rsquo;t bother going to BandLab site too fast - sometimes it&rsquo;s being processed even after download button appeared, where you start waiting in a queue even few minutes after you press the WAV button later, and you will not make this any faster.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">On the side. The audio you hear during preview is not exactly the same as in result downloaded from the site. Preview is a bit louder, and stresses vocal residues more, and snare is less present in the mix, although the file is more clear, sadly it&rsquo;s also 16 bit, in overall it doesn&rsquo;t seem to be better. Also, the file doesn&rsquo;t seem to be stored locally anywhere. But if you&rsquo;re desperate enough to get this preview, fasten your seatbelt. If you processed more files before, close the assistant, and open again, now process the file, so preview can be played, pause it.</span></p><p class="c1"><span class="c0">On Windows go to task manager, go to details, sort by CPU, RBM on BandLab Assistant.exe (the one with the most memory occupied)&gt;Create dump file. Open it in HXD (located in temp), write in bytes per row instead of &ldquo;16&rdquo;, &ldquo;4000&rdquo;, find string &ldquo;RIFF,&rdquo;. If you cannot find it, it&rsquo;s wrong process - make a dump of another assistant one (one of three most intensive). If you found the &ldquo;RIFF,&rdquo; delete everything above it (mark everything dragging the mouse to the top, with page up pressed and then keep shift pressed and left arrow to mark also the first row, then press delete), then save it as wav. The file can be played, but it&rsquo;s too big. To find the end, go to &ldquo;find&rdquo; (CTRL+F), hex and write FF 00 00 02 00 01 00, find (it shouldn&rsquo;t be at the beginning of the file - press F3 even more than once if necessary), mark everything dragging the mouse to the top with page up pressed and press copy (CTRL+C) and paste it into new file and save as wav.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You can also use </span><span class="c22">Matchering</span><span class="c0">. It works in a way that you provide a reference file, and it tries to match the sound of your audio to the reference you provided.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Reference file(s) to use </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Mastering The Mix&rdquo; (all-in-one collection of reference songs in one file):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1kqPmcVC3qvh_Mqd9vIssGUKpz3jTddPc/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744515203&amp;usg=AOvVaw1N4w_PyR8W3DjeTGW0YHrf">https://drive.google.com/file/d/1kqPmcVC3qvh_Mqd9vIssGUKpz3jTddPc/view?usp=sharing</a></span></p><p class="c1"><span class="c0">You need 7zip with WavPack plugin to extract it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Brown/Pink noise:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1wJHKRb2SIgJZIc-J8kEDD1k4OQj_OXzp/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744515708&amp;usg=AOvVaw0-mxmpDl-ZQM6-8dpMd4fj">https://drive.google.com/file/d/1wJHKRb2SIgJZIc-J8kEDD1k4OQj_OXzp/view?usp=sharing</a></span></p><p class="c1"><span class="c0">&ldquo;Try to use this as reference track in Matchering to get nice wide stereo and corrected high frequencies.&rdquo; zcooger</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But you can use a whole song of your choice, or its short fragment (e.g. instrumental part to get better result of separation)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- New Colab:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/kubinka0505/matchering-cli/blob/master/Documents/Matchering-CLI.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744516693&amp;usg=AOvVaw3Uwq6i367UgeuSh2TbRoal">https://colab.research.google.com/github/kubinka0505/matchering-cli/blob/master/Documents/Matchering-CLI.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Old Colab:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/814405660325969942/842132388217618442&amp;sa=D&amp;source=editors&amp;ust=1765035744517106&amp;usg=AOvVaw3mu2CphxGcwdxH8N2e4g-o">https://discord.com/channels/708579735583588363/814405660325969942/842132388217618442</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- UVR5 (in Audio Tools) - incorporates Matchering 2</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.songmastr.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744517474&amp;usg=AOvVaw3KqywOK-_KLJvivWAWNZUW">Songmastr</a></span><span class="c0">&nbsp;can be used online instead of Colab, uses Matchering 2 (7 free masters per week).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that there&rsquo;s a length limit in at least UVR5, and it&rsquo;s 14:44 (or possibly just 15 minutes). Instead of hit or miss by lots of reference files in one, you can also use simply one song you think will fit the most for your track. You can even further split it to a smaller fragment with e.g. lossless-cut in order to avoid reencoding. It can work even more efficiently that way.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sometimes I use Matchering for different master versions of the same song when I have a few masters I like certain things in them, but none good enough on their own.</span></p><p class="c1"><span class="c0">Usually, in the target file should be placed the file with the richest spectrum (but feel free to experiment).</span></p><p class="c1"><span class="c0">Can be a target file e.g. after a lot of spectral restoration, which e.g. lost some warm and fidelity, and you need something from the previous master version.</span></p><p class="c1"><span class="c0">You can also try to reprocess your result up to even 6 times, inputting a new file in target or reference each time, till you&rsquo;ll find the best result. But usually 2-3 should do the trick, sometimes while using target and reference interchangeably for different result files.</span></p><p class="c1"><span class="c0">For using Matchering in UVR5, necessarily check the option &ldquo;Settings Test Mode&rdquo; in additional settings. It will add a 10 digits number to each result, preventing you from overwriting your old files during multiple experiments conducted on your files. UVR doesn&rsquo;t ask before overwriting!</span></p><p class="c1"><span class="c0">Feel free to experiment with WAV output quality. Probably the further you&rsquo;ll go from 24 bit, the more different your result will be after converting back to 16 bit by some lossy codec like Opus on YT. But if you care mostly about the result file, then simply be aware that you can use output quality to your advantage, knowing in what way specific bit depth affects output results. E.g. the muddier results start with PCM_32 (non-float), 64 bit has it too, but additionally with some grittiness. 16 bit is usually good to glue well sounding audio together with loudly sounding snares already, but can be muddy frequently or harsher than e.g. 32 bit non-float. Usually your result will be not so good in most cases, hence I&rsquo;d encourage using higher bit depths than 16 bit here, but 24 bit can make your audio too bright at times, hence in such cases you can check 32 bit float and non-float. There&rsquo;s no simple setting working for every song, but the most universal setting I found so far is using non-float 32 bit and convert it to 16-bit manually. It&rsquo;s the most balanced setting across the whole song (might be slightly too muddy at times).</span></p><p class="c1"><span class="c0">Sometimes it can be good to have the richest file on a spectrogram as a target file, as it won&rsquo;t be lost after processing.</span></p><p class="c1"><span class="c0">Matchering can be generally useful when you have different versions of your masters, and you&rsquo;re running in circles finding the best one. Then you can use such different versions as target and reference (or in reverse), check what sounds the best, get the result, use in one of the fields, retry, and the same up to 4 times till it sounds the best. Then you could potentially master it further and/or separate into stems and bring the session back from this place.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you need more customizable settings for Matchering, e.g. controlling limiter intensity, or disabling it completely, consider using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/MuziekMagie/ComfyUI-Matchering&amp;sa=D&amp;source=editors&amp;ust=1765035744523454&amp;usg=AOvVaw0wideOpkZuUZHl27dhLlc2">ComfyUI-Matchering</a></span><span>&nbsp;(standalone/portable ComfyUI package for CPU or Nvidia: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/comfyanonymous/ComfyUI/releases/download/latest/new_ComfyUI_windows_portable_nvidia_cu124_or_cpu.7z&amp;sa=D&amp;source=editors&amp;ust=1765035744523786&amp;usg=AOvVaw0qe4UhJdGG5CSZ8P5pCSuM">new_ComfyUI_windows_portable_nvidia_cu124_or_cpu</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c18 c15">.masterknecht</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://masterknecht.klangknecht.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744524080&amp;usg=AOvVaw1Tlnu2485aeSUn4oNsiSp4">https://masterknecht.klangknecht.com/</a></span></p><p class="c1"><span class="c0">Web-based competitor of Matchering (it&rsquo;s not associated with Matchering). All the processing is done locally on your machine without uploading files to a server.</span></p><p class="c1"><span class="c0">The results using default settings usually sound a bit softer/warmer to those from Matchering, output is 48kHz, plus there&rsquo;s much more customizable settings.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.7re8afevk1p&amp;sa=D&amp;source=editors&amp;ust=1765035744524961&amp;usg=AOvVaw227LJ_DWIh9feMIT54keOx">EQ curve/master transfer</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Others</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Windows app</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.curioza.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744525394&amp;usg=AOvVaw257tXWXajBTrElzvOzXJdW">https://www.curioza.com/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Some newer AI:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/spaces/nateraw/deepafx-st&amp;sa=D&amp;source=editors&amp;ust=1765035744525703&amp;usg=AOvVaw0pPpAc7DqXSlyPP0RYsQOr">https://huggingface.co/spaces/nateraw/deepafx-st</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also try this one:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jhtonykoo/music_mixing_style_transfer&amp;sa=D&amp;source=editors&amp;ust=1765035744526028&amp;usg=AOvVaw0E8k-gYNcXj6jZEjjrOXlY">https://github.com/jhtonykoo/music_mixing_style_transfer</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/joaomauricio5/AssistedSpectralRebalancePlugin/releases/tag/v2.0&amp;sa=D&amp;source=editors&amp;ust=1765035744526426&amp;usg=AOvVaw07vHz58956cOLcbKY_MKWJ">https://github.com/joaomauricio5/AssistedSpectralRebalancePlugin</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">ChatGPT</span></p><p class="c1"><span class="c0">It can now master songs based on prompts and whatever you ask to make it sounds like. In the video below, the author wanted to make three instrumentals sound like Juice World. One result was decent, in the other one there was an issue with ovecrompressing/overlimiting, so the guitar was fading in/out once some other instrument was kicking in. Some prompts might fail to give you the result file, and he provided the examples.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D0kGJVgiyhAk&amp;sa=D&amp;source=editors&amp;ust=1765035744527482&amp;usg=AOvVaw2xQCwLjawihEJlSxtLKof_">https://www.youtube.com/watch?v=0kGJVgiyhAk</a></span></p><p class="c1"><span class="c0">&ldquo;GPT does a lot of things right now, but the biggest problem is that it can&#39;t get larger files (wav) into the buffer and thus can&#39;t process them. Compared to unstable work results, not working is more serious.&rdquo; - tat_evop1us</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://beatstorapon.com/ai-mastering&amp;sa=D&amp;source=editors&amp;ust=1765035744528107&amp;usg=AOvVaw0UfKviP3JocQCi36_C5WMS">https://beatstorapon.com/ai-mastering</a></span><span class="c0">&nbsp;(only mp3 192kbps for free)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For enhancing 4 stems separations from Demucs/GSEP:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/interactiveaudiolab/MSG&amp;sa=D&amp;source=editors&amp;ust=1765035744528546&amp;usg=AOvVaw2ZmUHm1kfeVZtx1oc0mc0r">https://github.com/interactiveaudiolab/MSG</a></span><span class="c0">&nbsp;(16kHz cutoff)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.platinumnotes.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744528791&amp;usg=AOvVaw2DRlo6zbzHANF65jyBGDoB">Platinum Notes</a></span></p><p class="c1"><span class="c0">(Windows/Mac paid software)</span></p><p class="c1"><span class="c0">&quot;corrects pitch, improves volume and makes every file ready to play anywhere (...) add warm&quot; and dynamics, remove clipping.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Mastering services I&#39;m yet to test: </span></p><p class="c1"><span class="c0">Landr, Aria, SoundCloud, Master Channel, Instant Mastering (iirc April fools joke), Bakuage, Mixea.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">AI mixing services</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://automix.roexaudio.com&amp;sa=D&amp;source=editors&amp;ust=1765035744529911&amp;usg=AOvVaw1vUNmqerW7CcxeROLXdIox">https://automix.roexaudio.com</a></span></p><p class="c1"><span class="c0">AI online auto-mixing service. Various instruments, genre settings, stem priority, pan priority. </span></p><p class="c1"><span class="c0">1 free mix per month. </span></p><p class="c1"><span class="c0">Might be useful for enhancing 4 stem separations.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I tried 2 songs with it. Wasn&#39;t really pleased with results&quot;</span></p><p class="c1"><span class="c0">&quot;The biggest problem I had [...] while I am trying to balance my vocals in instrumental like Hollywood style&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Other tool by Sony (open-source)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/sony/fxnorm-automix&amp;sa=D&amp;source=editors&amp;ust=1765035744531053&amp;usg=AOvVaw1EK50XpMr4zLyB_c9nMc6O">https://github.com/sony/fxnorm-automix</a></span></p><p class="c1"><span class="c0">You can also train your own models using wet music data.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A new free tool by Sony:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/SonyResearch/MEGAMI&amp;sa=D&amp;source=editors&amp;ust=1765035744531665&amp;usg=AOvVaw21egXmkab_BaWgbwuIqyCQ">https://github.com/SonyResearch/MEGAMI</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.arxiv.org/abs/2511.08040&amp;sa=D&amp;source=editors&amp;ust=1765035744531842&amp;usg=AOvVaw2JwnVZiQ7YemL-K4D1nxq-">https://www.arxiv.org/abs/2511.08040</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-based.md%23mixing-&amp;sa=D&amp;source=editors&amp;ust=1765035744532161&amp;usg=AOvVaw0hAUSrrP4vaAsTcy_Q8tWi">HyMPS list</a></span><span class="c0">&nbsp;of AI/CML tools</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">AI mixing plugins</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">iZotope Nectar</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">iZotope Neutron (Mix Assistant)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sonible Pure Bundle</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Creating mashups and also DJ sets (two options)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rave.dj/mix&amp;sa=D&amp;source=editors&amp;ust=1765035744533145&amp;usg=AOvVaw24PqlEtNYKkbp4rN5foeHj">https://rave.dj/mix</a></span></p><p class="c1"><span class="c0">It can give better results than manual mixes performed by some less experienced users (but I doubt it will work with more than 2 stems).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://apps.apple.com/us/app/ripple-music-creation-tool/id6447522624&amp;sa=D&amp;source=editors&amp;ust=1765035744533695&amp;usg=AOvVaw28uZseI8QhlXuIEcafVvaA">Ripple</a></span></p><p class="c1"><span class="c0">iOS only app (currently for US region only)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&quot;Ripple seems to be SpongeBand just translated into English, it was released last year: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pandaily.com/bytedance-launches-music-creation-tool-sponge-band/&amp;sa=D&amp;source=editors&amp;ust=1765035744534343&amp;usg=AOvVaw0JbLxxy7Nyzu4fiXeHCGde">https://pandaily.com/bytedance-launches-music-creation-tool-sponge-band/</a></span></p><p class="c1"><span class="c0">(more info about its capabilities)</span></p><p class="c1"><span class="c0">Back then, it only didn&#39;t have separation to 4 stems (but now the separation feature is defunct, anyway).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_______</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For enhancing vocal track you can use WSRGLOW, and better yet, process it through Izotope RX (7-9) spectral recovery tool (in RX 10 it&rsquo;s only in more expensive version irc), and then master it, or send it somewhere else above.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://replicate.com/lucataco/wsrglow&amp;sa=D&amp;source=editors&amp;ust=1765035744535327&amp;usg=AOvVaw2qvRtcAlTHtUQwiFvoOsEu">https://replicate.com/lucataco/wsrglow</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There are a lot of requests for music upscaling on our Discord. You can use online mastering services as well. Technically it&#39;s not upscaling in most cases, but the result can be satisfactory at times.</span></p><p class="c1"><span class="c0">If you try out all solutions, and learn how they work and sound, you can easily get any track in better quality in few minutes.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For very low resolution music (if you manage to run it):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">AudioSR - used more often then the below, lately (voc/inst)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Audio Super Resolution</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/olvrhhn/audio_super_resolution&amp;sa=D&amp;source=editors&amp;ust=1765035744536610&amp;usg=AOvVaw3ux8YfLuYwBatsjH90H5M_">https://github.com/olvrhhn/audio_super_resolution</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">hifi-gan-bwe</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/brentspell/hifi-gan-bwe/&amp;sa=D&amp;source=editors&amp;ust=1765035744536891&amp;usg=AOvVaw0SOG1eDnUXYD6PiNa-l6C2">https://github.com/brentspell/hifi-gan-bwe/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>More details and links, Colabs for these in the upscaler&rsquo;s full </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit%23heading%3Dh.i7mm2bj53u07&amp;sa=D&amp;source=editors&amp;ust=1765035744537244&amp;usg=AOvVaw1ZlBgdp36H9qAQxZIi6YzW">list</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you want to start making your own remasters (even if your file is in terrible quality, especially 22kHz):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?usp%3Ddrivesdk&amp;sa=D&amp;source=editors&amp;ust=1765035744537842&amp;usg=AOvVaw0wWmaQpdTzZ9cNvUTTZjbZ">https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?usp=drivesdk</a></span></p><p class="c1"><span class="c0">Might be useful also for low quality, crusty vocals, but it is also a guide for mixing music in overall but focused on audio restoration as well.</span></p><h3 class="c67 c27" id="h.tu3sw6pao8fp"><span class="c19">___Best quality on YouTube for your audio uploads____</span></h3><p class="c2 c7"><span class="c0"></span></p><ol class="c9 lst-kix_vgg0538grxk3-0 start" start="1"><li class="c1 c25 c8 li-bullet-0"><span class="c0">If you already have a ready video which is not just a one frame (e.g. a cover all over the video), download MKVToolnix and replace audio track with lossless one instead of rendered lossy track. You will avoid recompression or reencoding, unlike it is during rendering normal video. </span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">If you can, upscale the video to at least 1440p or greater. It will avoid deferred transitioning of your AAC (16kHz) audio stream to Opus (20kHz) when your video gets popular, or it&#39;s old enough (for current YT audio format, check statistics for nerds). QHD/+ makes your video play in better Opus codec from the beginning, and it will sound better than after deferred transition from AAC to Opus on FHD clip (Opus audio streams checksums differs in FHD and QHD videos despite the same video source file and most likely something is broken on YT side during the process, though both Opus files are 20kHz, so the file in FHD is not recompressed from AAC, perhaps from other audio file created during YT rendering, but not from the source video).</span></li><li class="c1 c25 c8 li-bullet-0"><span>Alternative - if you have just one image to make a video of it (e.g. cover), make sure it&rsquo;s at least 1440p or greater. If not, simply upscale it (e.g. XnView has some basic upscaling filters). Then place the image nearby this batch </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://disk.yandex.com/d/w7gmg_9mKSni2Q&amp;sa=D&amp;source=editors&amp;ust=1765035744540543&amp;usg=AOvVaw251unRWsAMPd8LhPKKmWHY">FFmpeg script</a></span><span class="c0">&nbsp;with your lossless audio files. It will render videos with the same audio streams like original files, but muxed into your output MKV files (you can check in Foobar2000 for Audio MD5 comparison or by using AudioMD5Checker, if MD5 checksum is not embedded when looking in F2K file properties) so it won&rsquo;t be recompressed on your end while making a video for upload on YT (yes, YT supports MKV!). It&rsquo;s faster than MKVToolnix and you can convert multiple files with the same image at the same time (it&#39;s very fast, incomparable to normal video rendering, and output is only 1 FPS, so it will buffer in YT also very fast).</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">You don&rsquo;t have to wait till YT stop processing your HD version for Opus to appear. It happens at a point when FHD resolution appears before QHD when processing is still in progress. So check it out from time to time before you hit the publish button.</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Because Opus is 16 bit, and your input audio file in Matroska container might have higher bit depth, it&rsquo;s good to compress your input file to Opus VBR 128kbps for testing purposes to check how it will sound on YT (of course don&rsquo;t use it later for MKV file). Downsampling performed by the encoder can occasionally introduce some unwanted changes to the sound. It&rsquo;s the most noticeable when audio input is 64 bit, but smaller can be still good enough.</span></li><li class="c1 c25 c8 li-bullet-0"><span>YouTube videos from early 2010 on archive.org have 192kbps AAC for 1080p (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://web.archive.org/web/20130116173108/https://www.youtube.com/watch?v%3DiD-NBs5kJqI&amp;sa=D&amp;source=editors&amp;ust=1765035744543093&amp;usg=AOvVaw1MbB8Qprs4ekNxhshuz5ZX">example</a></span><span class="c0">) (thx theamogusguy)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">If you deal with some harshness on your YT audio uploads with original 44kHz sample rate, consider resampling them manually to 48kHz before upload using e.g. Izotope RX (smooth) or e.g. dBpoweramp/SSRC (F2K plugin) and save the output as lossless format.</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Since now MVSEP supports batch API conversions, you can use Case Changing in Ant Renamer to reestablish uppercase letters to song titles for your YouTube uploads.</span></li></ol><p class="c1 c8"><span class="c0">So if you want to batch upload on YouTube the name will not appear as &quot;song artist song title&quot; but &quot;Song Artist Song Title&quot; (since YT removes dashes and commas etc.)</span></p><ol class="c9 lst-kix_vgg0538grxk3-0" start="9"><li class="c1 c25 c8 li-bullet-0"><span class="c0">It seems like 720p is now enough to get Opus after upload (thx dca100fb8 - 9. &amp; 8.)</span></li></ol><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7 c8"><span class="c0"></span></p><h2 class="c29 c27" id="h.6543hhocnmmy"><span class="c42 c15 c36 c46 c30">___Best quality from YouTube and Soundcloud - how to squeeze out the most from the music taken from YT for separation___</span></h2><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Sometimes a better source just doesn&rsquo;t exist, and only YouTube audio can be used for separation in some cases. </span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c6">Introduction</span></p><p class="c1 c8"><span class="c0">Audio on YT in most cases is available in two formats: </span></p><p class="c1 c8"><span class="c0">1) AAC (m4a) and Opus. As I mentioned, the latter appears for older or popular uploads, or videos uploaded in QHD or 4K. Most videos will have both formats available already. Currently only browsers without Opus support plau that audio stream (iirc Safari)</span></p><p class="c1 c8"><span class="c0">AAC on YT is @128kbps with 16kHz cutoff and 44kHz (that&rsquo;s not artificial cutoff - that&rsquo;s how the codec normally behaves when such bitrate is set).</span></p><p class="c1 c8"><span class="c0">2) Opus on YT is 96/128/152kbps with 20kHz cutoff (spectrum up to 24kHz for videos uploaded before ~2020+, but only with some aliasing above 20kHz, probably as a result of applied resampler) always 48kHz (44kHz audio is always upsampled with built-in resampler in Opus - that&rsquo;s how the Opus works - it has always 48Khz output).</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">1) and 2) can be downloaded, e.g. via JDownloader 2 (once you downloaded one file, you must delete the previously shown entry in link grabber and add the link once more, and now pick the Opus (m4a is default) for download).</span></p><p class="c1 c8"><span>You can also use online too </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cobalt.tools/&amp;sa=D&amp;source=editors&amp;ust=1765035744547151&amp;usg=AOvVaw0lnhfEE1RQQR9mtheXrQ3O">https://cobalt.tools/</a></span><span class="c0">&nbsp;which is probably just GUI for yt-dlp.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Opus files downloaded from JDownloader are different than Opus in webm files seeing by spectrum, but I can&rsquo;t compare it with Cobalt as Spek doesn&rsquo;t cooperate with its webm files in at least progressive mode which is &ldquo;direct vimeo stream&rdquo;. yt-dlp with -x argument might be free of the issue, but I haven&rsquo;t checked yet.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Don&#39;t download as Opus from JDownloader 2. The quality will be affected. </span></p><p class="c1 c8"><span class="c0">Download always as webm in any quality - all qualities will contain the same Opus audio stream in the same bitrate.<br>Be aware that sometimes JDownloader wrongly reports bitrate as 96kbps, while when you demux the webm file with MKVToolnix-GUI and then with MKVExtractGUI2 (compatible with MKVToolnix v 20), the result Opus file (add extension manually afterwards) will have average bitrate of not much below 128kbps (that&rsquo;s how VBR works).</span></p><p class="c1 c8"><span class="c0">Don&rsquo;t download in OGG from Cobalt. It&rsquo;s recompression from webm/Opus. OGG file is not on variants list in JDownloader (and probably the same would be in CML tools like yt-dlp, so it&rsquo;s simply not on YT).</span></p><p class="c1 c8"><span>However, it will have some additional information below 16kHz compared to Opus downloaded from JDownloader, probably because it was sourced from webm, and not JDownloader&#39;s Opus, but that&rsquo;s it. Recompression here will add some ringing issues and compression artefacts. Details and spectrograms </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1210343573388525619&amp;sa=D&amp;source=editors&amp;ust=1765035744549684&amp;usg=AOvVaw36178dt61rmDEaTQ-BPLBO">here</a></span><span class="c0">.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Sometimes it happens that m4a (AAC) sounds better than Opus. It all depends on a track. It is more likely to happen if both have the same cutoff in spectrogram due to how it was uploaded on YT.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c8"><span class="c6">What to do to improve the audio gathered from YT?</span></p><p class="c1 c7 c8"><span class="c6"></span></p><p class="c1 c8"><span class="c6">#1 Joining frequencies with EQ method </span></p><p class="c1 c7 c8"><span class="c6"></span></p><p class="c1 c8"><span class="c0">1) Download both M4A and Opus audio from YT (if Opus is available for your video) </span></p><p class="c1 c8"><span class="c0">2) Upsample M4A to 48kHz (or else you won&rsquo;t align the two files perfectly) with e.g. Resampler (PPHS) in Ultra mode in Foobar 1.3.20&gt;Convert&gt;...</span></p><p class="c1 c8"><span class="c0">3) To have frequencies above 16kHz from Opus and better sounding frequencies up to 16kHz from AAC, we will combine the best of the both worlds by:</span></p><p class="c1 c8"><span>a) applying </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i.imgur.com/QLwsGzK.png&amp;sa=D&amp;source=editors&amp;ust=1765035744551257&amp;usg=AOvVaw3n6qVuFDjBc--ZXLMFWIfu">resonant highpass</a></span><span class="c0">&nbsp;on Opus file at 15750Hz in e.g. Ozone 8/9 EQ</span></p><p class="c1 c8"><span class="c0">b) aligning the track to M4A audio file (converted to 48kHz WAV 32), so added as separate track in free DAWs like Audacity, Cakewalk, Ableton Lite, or Pro Tools Intro (or eventually Reaper with its infinite trial).</span></p><p class="c1 c8"><span class="c0">Export the mixdown as WAV24. It should be more than enough.</span></p><p class="c1 c8"><span class="c6">Using brickwall highpass instead will result in a hole in frequency in the result spectrogram (check it in Spek afterwards, and also whether there are no overlap frequencies in the crossover - consider checking also linear phase in e.g. free QRange EQ).</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c6">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #2 Manual ensemble in UVR</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1 c8"><span class="c20">Files ensemble with Max Spec</span><span class="c0">&nbsp;in UVR </span></p><p class="c1 c8"><span>Instead of EQ, you can use</span><span class="c20">&nbsp;</span><span class="c0">ensemble after manual upsampling of M4A file. You can have your files aligned in UVR.</span></p><p class="c1 c8"><span class="c0">Be aware that this method is not fully transparent, and produce files a little bit brighter, and still with cutoff, but not brickwall like in M4A.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span>Without upsampling step, you can use Max Spec method with great results also for </span><span class="c20">Soundcloud </span><span class="c0">which provides 64kbit/s opus and 128kbp/s mp3 and 256kbp/s aac.</span></p><p class="c1 c8"><span class="c0">You only need to amplify mp3 file by 3dB. Align step is also necessary here, but it can be performed in UVR.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">(fixed in UVR 5.6) Be aware that a bug in manual ensemble exist which forces 16 bit output despite choosing e.g. 32-bit float. To fix it, you need to execute regular separation of a song with any AI model with 32 bit set, and then you need to return to manual ensemble without changing any settings now, so from now on it will retain 32-bit float in manual ensemble.</span></p><p class="c1 c8"><span class="c0">You can fix this by changing the 510th line of lib_v5/spec_utils.py to:</span></p><p class="c1 c8"><span class="c0">&nbsp; &nbsp; sf.write(save_path, normalize(output.T, is_normalization), samplerate, subtype=&#39;FLOAT&#39;)</span></p><p class="c1 c8"><span class="c0">&nbsp;then restart the program (yo may not find that file if your UVR is not taken from source).</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">TBH, I didn&rsquo;t compare directly the first EQ vs the latter Max Spec method, but the latter sounds brighter for sure than opus, and m4a.</span></p><p class="c1 c8"><span class="c0">&ldquo;while it helps to make trebles more defined, it&#39;s a bit flawed, due ensembling 3 different compression methods, so 3 different compression flaws/errors and noises&rdquo;.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">PS. For YT I also tried downsampling Opus to 44 and to leave M4A intact, but it gave worse results (probably because of more frequencies affected by resampler in this case).</span></p><p class="c1 c7 c8"><span class="c6"></span></p><p class="c1 c8"><span class="c6">Explanation</span></p><p class="c1 c8"><span class="c0">Audio file sizes and bitrate are the same for both formats. Knowing that the cutoff in AAC is not artificial, but codec without a doubt efficiently compresses only audio up to 16kHz, leaving everything higher blank and untouched, we can come to the conclusion that frequencies up to 16kHz in AAC may sound better than in Opus, since the size and bitrate of both files is the same, and most likely bitrate in AAC is not used to frequencies above 16kHz, so full 128kbps bitrate is used only for frequencies up to 16kHz in AAC codec while in Opus for the whole spectrum up to 20 or even 24kHz in some old videos till around 2020, while keeping the same size, so that might be more harmful for frequencies up to 16kHz than in AAC. </span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span>PS. After some time, I receive explanation/reassurance on the purpose of this process </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/4qBnIx3&amp;sa=D&amp;source=editors&amp;ust=1765035744557375&amp;usg=AOvVaw1JHsj7wpheGRNvEzUgSXyM">here</a></span><span class="c0">, saying it&rsquo;s generally justified and Opus is actually better than AAC even above 9600Hz, so one more additional cutoff in AAC will be needed. Also, might be worthy to use phase linear EQ to get rid of some coloration of the result file.</span></p><p class="c1 c8"><span>Experimenting with it, make sure that you don&rsquo;t run into overlapping frequencies in area of bypassing (e.g. you can see it </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/1070055072706347061/1088074452824248481/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035744558146&amp;usg=AOvVaw0eWTryfq5pGO5cOY5pPWpg">here</a></span><span>&nbsp;as slightly brighter area above 9.6kHz up to 12kHz) to avoid it in e.g. in RX editor, one filtered signal needs to be 10Hz away from another one. I.e. if lowpass is 12000 Hz, then highpass is 12010 Hz. &ldquo;But there is a catch with iZotope RX. The 10Hz away I described is only applied to the Copy operation (when you basically select the frequency range, and just CTRL+C by copying it). But there is also Silence operation (when you select freq. range and press Delete, it eliminates the freq. in this range), and it is another way around: you need to get the other signal 10Hz inward, so they overlap. I.e.: 12000 Hz lowpass, 11990 Hz highpass. Here is the video demo: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://youtu.be/h5yE5cpqqMU&amp;sa=D&amp;source=editors&amp;ust=1765035744559228&amp;usg=AOvVaw0BLh87toeL3wvb8X5oGBwr">https://youtu.be/h5yE5cpqqMU</a></span><span class="c0">&rdquo;</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c6">#3 Bash script to automate the AAC/Opus quality combining from YT audio</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span>introC eventually wrote his bash script which makes an alignment (so trimming 1600 samples from m4a), performs cutoffs and joins frequencies of both files for you - without an overlap issue (tested with white noise). The script works for multiple m4a and webm files with the same name. Probably, MSYS2 (or cygwin) is required to run this script on Windows or for W10/11 use WSL (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.thewindowsclub.com/how-to-run-sh-or-shell-script-file-in-windows-10&amp;sa=D&amp;source=editors&amp;ust=1765035744560316&amp;usg=AOvVaw2uyhjhuqltpwDb9RolC6n6">read</a></span><span>)</span><span class="c0">. </span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span>He also took a more conservative approach here and changed cutoff frequency from 9600Hz to 1400Hz since AAC didn&rsquo;t perform better in one song, but below 1400Hz it will be rather in every case. What cutoff is actually the best might be sometimes depending on a song. The </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/16jarqz3gyFcjB4HEBS_24-i9eJ5iyP3D/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744560953&amp;usg=AOvVaw2fJvrWWQ84-ISs2KGXCsHB">script</a></span><span>&nbsp;is a subject to change.<br><br>#4 </span><span class="c20">Method for better quality of instrumental leaks on YT by theamogusguy<br><br></span><span class="c0">&ldquo;I did something really odd. (...) since you can only rip max 128kbps I did something really odd to get a higher quality instrumental:</span></p><p class="c1 c62"><span class="c0">I inverted the 128kbps AAC YouTube rip into the original to get the acapella</span></p><p class="c1 c8"><span class="c0">I took the subtracted acapella and ran it through AI (mel-roformer 2024.10) to reduce the compression artifacts</span></p><p class="c1 c8"><span class="c0">I then inverted the isolated acapella and mixed it with the lossless to get an... unusual lossless instrumental file?<br>also the OPUS stream goes up to 20khz but I feel like the sample rate difference is gonna cause issues, so I ended up ripping AAC (OPUS is 48khz while most music is 44.1khz)&rdquo;</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.nmqmya8t76oc"><span class="c0">_____Custom UVR models__________</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Mostly outdated models, see </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/1%23issuecomment-2156069553&amp;sa=D&amp;source=editors&amp;ust=1765035744562559&amp;usg=AOvVaw25wpkIkz5wBzcob7oL4HUX">here</a></span><span>&nbsp;</span><span class="c0">for more submissions from 2024</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; 0) &nbsp;BubbleG &mdash; 15.06.2021</span></p><p class="c1 c62"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708580573697933382/854421893166530609/drums-4BAND-3090_4band.pth&amp;sa=D&amp;source=editors&amp;ust=1765035744562981&amp;usg=AOvVaw3_IuonuRLbI1WVu1wsVl1m">Final drum model</a></span><span>&nbsp;(for UVR 5 and </span><span class="c42 c15 c36 c30 c58">4band_44100.json4band_44100.json)</span></p><p class="c1 c7"><span class="c42 c15 c36 c58 c30"></span></p><ol class="c9 lst-kix_hppu19i8fr2p-0 start" start="1"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Dry Paint Dealer Undr &mdash; 08.07.2021</span></li></ol><p class="c1 c8"><span>haring</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1_GEEhvZj1qyIod1d1MX2lM6u65CTpbml/view?usp%3Ds&amp;sa=D&amp;source=editors&amp;ust=1765035744563396&amp;usg=AOvVaw197zk1j8BuR4Bc8hmVZzFb">&nbsp;wip piano model</a></span><span class="c0">&nbsp;trained on almost 300 songs might continue to train might not, has an issue where it also removes bass guitar too</span></p><p class="c1 c7 c8"><span class="c0"></span></p><ol class="c9 lst-kix_hppu19i8fr2p-0" start="2"><li class="c1 c25 c8 li-bullet-0"><span class="c0">BubbleG &mdash; 16.06.2021</span></li></ol><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708580573697933382/854812714115268608/bass-4BAND-3090_4band.pth&amp;sa=D&amp;source=editors&amp;ust=1765035744563856&amp;usg=AOvVaw11m5XATxapo3jF_PPvjLnb">Temp. bass model.</a></span><span class="c0">&nbsp;Must use with 4band_44100.json</span></p><p class="c1 c7"><span class="c0"></span></p><ol class="c9 lst-kix_hppu19i8fr2p-0" start="3"><li class="c1 c25 c8 li-bullet-0"><span class="c0">viperx &mdash; 04.08.2021</span></li></ol><p class="c1 c80"><span>My</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Ra55Gb55Df-x9NrlJGCDcDlKSNECusMH/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744564216&amp;usg=AOvVaw1LIV35GAZSIOXtpTOptrqD">&nbsp;simple karaoke model</a></span><span class="c0">&nbsp;that I trained in month 5 until epoch 25/28 doesn&#39;t complete the training because I&#39;ve been busy with other projects, and I left this one aside, but this simple model removes the second voice, it can be useful in only some cases, it&#39;s bad but it&#39;s acceptable</span></p><p class="c1 c7"><span class="c0"></span></p><ol class="c9 lst-kix_hppu19i8fr2p-0" start="4"><li class="c1 c25 c8 li-bullet-0"><span class="c4 c58"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708580573697933382/874518732737765376/model_0_1.pth&amp;sa=D&amp;source=editors&amp;ust=1765035744564858&amp;usg=AOvVaw3XuYOhVA_7sTf4B1zg54VU">centre isolation model</a></span><span class="c58">&nbsp;epoch 0 inner epoch 1 - 150 pairs for UVR </span><span class="c4 c58"><a class="c3" href="https://www.google.com/url?q=https://github.com/tsurumeso/vocal-remover/tree/develop&amp;sa=D&amp;source=editors&amp;ust=1765035744565028&amp;usg=AOvVaw0hMoeGKGpaps_zKZE50QkH">4.0.1</a></span></li></ol><p class="c1 c7 c8"><span class="c0"></span></p><ol class="c9 lst-kix_hppu19i8fr2p-0" start="5"><li class="c1 c25 c8 li-bullet-0"><span class="c0">K-POP FILTERS &mdash; 02.07.2021</span></li></ol><p class="c1 c8"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/12kRtL6XfRLiOwUx1JF2vXKE_-8P2g5Wt/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744565356&amp;usg=AOvVaw1Koz2fkaaD_q2euXOkzSRV">model_0_0_1024_2048.pth</a></span></p><p class="c1 c8"><span class="c0">feedback will be appreciated</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1"><span>Check </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708580573697933382/874518735816368168&amp;sa=D&amp;source=editors&amp;ust=1765035744565741&amp;usg=AOvVaw1AKSOgRy3FomN_V7HiOsdB">#model-sharing </a></span><span class="c0">for current WiP models</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.40ggyvro35uu"><span class="c0">__Repository of old Colab notebooks__</span></h6><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span>UVR 5 (Colab by HV): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/blob/main/Vocal%2520Remover%25205_arch.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744566496&amp;usg=AOvVaw1hFefvF8ETXGihq_bapqad">https://colab.research.google.com/github/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/blob/main/Vocal%20Remover%205_arch.ipynb</a></span></p><p class="c1"><span class="c0">(On Mobile Chrome use PC mode)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Alternative UVR 5 notebook up to date (not HV&rsquo;s):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/lucassantilli/UVR-Colab-GUI/blob/main/UVR_v5.ipynb%23scrollTo%3D-KYA8iOZ8BKq&amp;sa=D&amp;source=editors&amp;ust=1765035744567234&amp;usg=AOvVaw0UAK-X5OqD_jIFhaJdVio9">https://colab.research.google.com/github/lucassantilli/UVR-Colab-GUI/blob/main/UVR_v5.ipynb#scrollTo=-KYA8iOZ8BKq</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX (Colab by CyberWaifu, 4 stem, cannot be used in Mobile Chrome even using PC mode - there&#39;s no GDrive mounting and track downloading is always 0%. Model A cleaner but with more bleeding; Audioshake is based on it, but with different model based on larger dataset iirc, UVR team consider training it on their own bigger dataset to get better results - it&rsquo;s based on phase unlike UVR, but tsumeruso works on adding phase, so then it might get rewritten to UVR)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1R32s9M50tn_TRUGIkfnjNPYdbUvQOcfh?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744568368&amp;usg=AOvVaw2wJAiLDimrLNY_aTi7269l">https://colab.research.google.com/drive/1R32s9M50tn_TRUGIkfnjNPYdbUvQOcfh?usp=sharing</a></span></p><p class="c1"><span>(wait patiently, it doesn&rsquo;t show the progress)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR 5 (old version by HV with any 2 files ensemble feature, put tracks in separated folder. As for x/z - similar results, but not the same. Put as first the one you want the result more similar to)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1eK4h-13SmbjwYPecW2-PdMoEbJcpqzDt?usp%3Dsharing%23scrollTo%3DCT8TuXWLBrXF&amp;sa=D&amp;source=editors&amp;ust=1765035744569143&amp;usg=AOvVaw0fyMH_9su-rsbEfgzF_MCh">https://colab.research.google.com/drive/1eK4h-13SmbjwYPecW2-PdMoEbJcpqzDt?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1C6i_6pBRjdbyueVw27FuRpXmEe442n4k?usp%3Dsharing%23scrollTo%3DCT8TuXWLBrXF&amp;sa=D&amp;source=editors&amp;ust=1765035744569516&amp;usg=AOvVaw2OtS8aQ91q3V785HEFwe3g">https://colab.research.google.com/drive/1C6i_6pBRjdbyueVw27FuRpXmEe442n4k?usp=sharing#scrollTo=CT8TuXWLBrXF</a></span><span class="c0">&nbsp;(+12 ens, no batch ens, deleted)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2021-ISMIR-MSS-Challenge-CWS-PResUNet (byteMSS) (if you run out of memory, split up the input file)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/17m08bvihZAov_F_6Rg3luNj030t6mtyk?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744570130&amp;usg=AOvVaw25u9T4rDOrYR4lv1lNkFzL">https://colab.research.google.com/drive/17m08bvihZAov_F_6Rg3luNj030t6mtyk?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Woosung Choi&#39;s ISMIR 2020 (Colab by CyberWaifu)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1jlwVgC9sRCGnZAKZTpqKgeSnzP3sIj8U&amp;sa=D&amp;source=editors&amp;ust=1765035744570611&amp;usg=AOvVaw1p81nxVOucGZ3rkmAd-Z72">https://colab.research.google.com/drive/1jlwVgC9sRCGnZAKZTpqKgeSnzP3sIj8U</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Vocal Remover 4:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1z0YBPfSexb4E7mhNz9LJP4Kfz3AvHf32&amp;sa=D&amp;source=editors&amp;ust=1765035744570985&amp;usg=AOvVaw3sZa_O-zTtu5xdIJYhzqU8">https://colab.research.google.com/drive/1z0YBPfSexb4E7mhNz9LJP4Kfz3AvHf32</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To fix librosa error, try adding the</span></p><p class="c1"><span class="c0">!pip install librosa==0.8.0</span></p><p class="c1"><span class="c0">or 0.9.? works as well</span></p><p class="c1"><span class="c0">line about librosa, and if still the same, about pysound as well:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/767947630403387393/1089518963253317652&amp;sa=D&amp;source=editors&amp;ust=1765035744571811&amp;usg=AOvVaw1CilDOJ4kRphHKp3fWbOyi">https://discord.com/channels/708579735583588363/767947630403387393/1089518963253317652</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/burntscarr/vocal-remover/blob/main/vocal_remover_burnt.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744572236&amp;usg=AOvVaw1NkmQbPRI4L3ByX09wJw9t">https://colab.research.google.com/github/burntscarr/vocal-remover/blob/main/vocal_remover_burnt.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(UVR4 + models description:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/tree/v4.0.1&amp;sa=D&amp;source=editors&amp;ust=1765035744572627&amp;usg=AOvVaw1WuxtsrcQH1EvM2qHJD3OL">https://github.com/Anjok07/ultimatevocalremovergui/tree/v4.0.1</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Search for:</span></p><p class="c1"><span class="c0">&quot;Models included&quot; at the bottom&quot;.)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR 2.20 (it achieved some good results for old 70&rsquo;s pop music for me where cymbals got muffled on current models, but prepare for more bleeding in some places vs VR4 and newer)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1gGtjAo3jK3nmHcMYTz0p8Qs8rZu8Lhb6?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744573454&amp;usg=AOvVaw3pc6OtCUfSfdv4M5y0kvdu">https://colab.research.google.com/drive/1gGtjAo3jK3nmHcMYTz0p8Qs8rZu8Lhb6?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Spleeter (11/16kHz, 2, 4, 5 stems, currently doesn&rsquo;t work): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1d-NKFQVRGCV5tvbd0GOy9spMMel6mrth?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744573878&amp;usg=AOvVaw1GM_tYOCjRF8TA8sCAXf4i">https://colab.research.google.com/drive/1d-NKFQVRGCV5tvbd0GOy9spMMel6mrth?usp=sharing</a></span></p><p class="c1"><span class="c0">According to my experience, if you don&rsquo;t need piano stem, 4 stem model makes better job than 5 stem (and even vs 2 stem, and it is also reflected in SDR results). Use 11kHz models only if your input files are sampled at 22kHz (it will provide better result in this and only in this case).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you can, use Izotope RX-8 for 22kHz 4 stem, as it provides better separation quality with aggressiveness option. It&rsquo;s Spleeter, but with better model (full band).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Demucs 3.0</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1yyEe0m8t5b3i9FQkCl_iy6c9maF2brGx?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744575089&amp;usg=AOvVaw2wZ-q6s7BLFqmMLtFHfEIt">https://colab.research.google.com/drive/1yyEe0m8t5b3i9FQkCl_iy6c9maF2brGx?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To install it locally (by britneyjbitch):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I cracked the Da Vinci code on how to install Demucs V3 sweat_smile For anybody who struggled (on Windows) - I got you!</span></p><p class="c1"><span class="c0">1. DL a zip folder of Demucs 3 from Github (link: https://github.com/facebookresearch/demucs) and extract it in a desired folder</span></p><p class="c1"><span class="c0">2. Inside the extracted folder run cmd</span></p><p class="c1"><span class="c0">3. If you want to simply separate tracks, run the following command:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; python.exe -m pip install --requirement requirements_minimal.txt</span></p><p class="c1"><span class="c0">4. If you want to be able to train models too, run the following command:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; python.exe -m pip install --requirement requirements.txt</span></p><p class="c1"><span class="c0">5. If a read error for incompatible versions of any of the modules appears (e.g. torch) run the following command:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pip install desired_module==version_of_desired_module</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.g. &nbsp;pip install torch==1.9.0</span></p><p class="c1"><span class="c0">6. Repeat step 5 for any incompatibilities that might occur</span></p><p class="c1"><span class="c0">7. Separating tracks:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; python.exe -m demucs &nbsp;-n &quot;desired_model_to_run_separation&quot; &quot;path_to_track&quot;</span></p><p class="c1"><span class="c0">8. If you want help finding all additional options (for example overlap or shifts), run:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; python.exe -m demucs --help</span></p><p class="c1"><span class="c0">At least that worked for me, feel free to let me know if this worked for others as well</span></p><p class="c1"><span class="c0">exclamation Oh, and I forgot - between step 6 or 7, don&#39;t pay attention to a potential red error &#39;&#39;torchvision 0.9.1+cu111 has requirement torch==1.8.1, but you&#39;ll have torch 1.9.0 which is incompatible.&#39;&#39;</span></p><p class="c1"><span class="c0">Do NOT change back to torch 1.8.0 cuz you won&#39;t be able to run demucs</span></p><p class="c1"><span class="c0">warning! If &#39;&#39;torchvision 0.9.1+cu111 has requirement torch==1.8.1, but you&#39;ll have torch 1.9.0 which is incompatible.&#39;&#39; is the only red error you&#39;re getting after executing the commands from step 3,4 and/or 5, you&#39;re good to go with separation!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Demucs (22khz, 4 stem):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1gRGRDhx9yA1KtafKhOaXZUpUoh2MuF_8?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744579031&amp;usg=AOvVaw3thPonPpKDdIebMpQ9tNxZ">https://colab.research.google.com/drive/1gRGRDhx9yA1KtafKhOaXZUpUoh2MuF8?usp=sharing</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/facebookresearch/demucs/blob/master/Demucs.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744579326&amp;usg=AOvVaw1hXB6U1de3o4ywkZUCHiOd">https://colab.research.google.com/github/facebookresearch/demucs/blob/master/Demucs.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1gRGRDhx9yA1KtafKhOaXZUpUoh2MuF_8?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744579643&amp;usg=AOvVaw2PB5tIR_7aYy1e4Ax58EDM">https://colab.research.google.com/drive/1gRGRDhx9yA1KtafKhOaXZUpUoh2MuF_8?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Other one(s):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>LaSAFT:<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1XIngzXDi2mF_y6WwDrLLx4XZtI8_1FAz?usp%3Dsharing%23scrollTo%3DZNfiadwPdWbK&amp;sa=D&amp;source=editors&amp;ust=1765035744580234&amp;usg=AOvVaw2KPXnZdym0Xwe2laC-6gI7">https://colab.research.google.com/drive/1XIngzXDi2mF_y6WwDrLLx4XZtI8_1FAz?usp=sharing</a></span></p><p class="c1"><span class="c0"><br>(original, cannot define model ATM)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ws-choi/Conditioned-Source-Separation-LaSAFT/blob/main/colab_demo/LaSAFT_with_GPoCM_(large)_Stella_Jang_Example.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744580748&amp;usg=AOvVaw3XrnidDIh58dQECsXfzY96">https://github.com/ws-choi/Conditioned-Source-Separation-LaSAFT/blob/main/colab_demo/LaSAFT_with_GPoCM_(large)_Stella_Jang_Example.ipynb</a></span></p><p class="c1"><span class="c0">If you cannot load the file, upload it manually to your Colab, or just wait patiently. Refresh Github page with CTRL+R if you can&rsquo;t see the code preview.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Check out also this laSAFT </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mediafire.com/file/j6hhuubmbb4m0po/lasaft2021.rar/file&amp;sa=D&amp;source=editors&amp;ust=1765035744581291&amp;usg=AOvVaw0VfOxugb2ha7aF7V72p2HS">download </a></span><span>with </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/819091933967679529&amp;sa=D&amp;source=editors&amp;ust=1765035744581454&amp;usg=AOvVaw3GuXi_f4aRb9yulZanvvzI">message</a></span><span class="c0">&nbsp;which says about superiority of 2020 model (said in march 2021).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Clone voice:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/RealTimeVoiceCloning.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744582056&amp;usg=AOvVaw2igpMOH-FHcttYwyOiEGei">https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/RealTimeVoiceCloning.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Matchering:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/814405660325969942/842133128851750952/MatcheringColabSimplified.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035744582497&amp;usg=AOvVaw0PS3WfJ34fT9twcAK4QVSj">https://cdn.discordapp.com/attachments/814405660325969942/842133128851750952/MatcheringColabSimplified.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For more Colabs search for colab.research.google.com on our Discord server</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.lc0zj8wttng0"><span class="c0">__Google Colab troubleshooting (old)_</span></h6><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_kxjfd2xlpmu-0 start"><li class="c1 c27 c25 c8 li-bullet-0"><h6 id="h.3bvk3ljw8ooa" style="display:inline"><span class="c6">Error of authorisation during mounting:</span></h6></li></ul><h6 class="c1 c27 c8" id="h.941p4v3b1iov"><span class="c0">TL:DR - you need to log into the same account in Colab you want to mount drive later, or just change your Colab account. </span></h6><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27 c8" id="h.i2w5n3ln3y4i"><span class="c0">It was introduced to Colab at some point. Once I tried to log into another account during mounting, it displayed a new window with only one account, where the wanted account didn&#39;t appear, and when I manually signed in to it, Colab showed an error on Colab, something about unsuccessful authorisation. When I changed account in the right corner this time for the same account I wanted to choose when mounting, everything went fine as it always used to be. Full list of accounts appeared. HV Colabs already have the new mount method implemented, so the old one doesn&rsquo;t cause error, but in UVR notebook you can choose between the new (default) and the old one (just in case Google changed something again).</span></h6><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_df6s37r8voak-0 start"><li class="c1 c25 c8 li-bullet-0"><span>T</span><span>ry to log into another Google account(s) if you cannot connect with GPU anymore and/or you </span><span class="c20">exceeded your GPU limit</span></li></ul><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_ksf6p4xm2w0d-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">(cannot really say if it&rsquo;s really helpful at this point) </span></li></ul><p class="c1 c8"><span class="c0">Paste this code to console (Chrome: CTRL+Shift+I or &hellip;&gt;more tools&gt;tools for developers&gt;console) to avoid disconnections from runtime environment or if you encounter problems while being AFK and if you run into issues of being unable to connect to GPU after reconnection after idle time or possibly after the code was executed, and you&rsquo;re AFK for too long. It won&rsquo;t prevent you from showing one captcha in the session.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">interval = setInterval(function() { </span></p><p class="c1"><span class="c0">&nbsp; &nbsp; console.log(&quot;working&quot;)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; var selector = &quot;#top-toolbar &gt; colab-connect-button&quot;</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; document.querySelector(selector).shadowRoot.querySelector(&quot;#connect&quot;).click()</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; setTimeout(function() {</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; document.querySelector(selector).shadowRoot.querySelector(&quot;#connect&quot;).click()</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; }, 1000)</span></p><p class="c1"><span class="c0">}, 60*1000)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It will constantly reclick one window to appear in Colab to prevent idle check.</span></p><p class="c1 c7"><span class="c0"></span></p><hr style="page-break-before:always;display:none;"><p class="c1 c7"><span class="c0"></span></p><h3 class="c35 c27" id="h.k3cm3bvgsf4j"><span class="c19">Repository of stems/multitracks from music to create your own dataset</span></h3><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Datasets search engine</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://datasetsearch.research.google.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744587389&amp;usg=AOvVaw1pBHr5nzDGT3ecZ8S2EPPt">https://datasetsearch.research.google.com/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Up-to-date list of datasets</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Yuan-ManX/ai-audio-datasets-list%23music&amp;sa=D&amp;source=editors&amp;ust=1765035744587722&amp;usg=AOvVaw2003CC9rNmHYXHmBLHnGkx">https://github.com/Yuan-ManX/ai-audio-datasets-list#music</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">33 datasets compilation list:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://sites.google.com/site/shinnosuketakamichi/publication/corpus&amp;sa=D&amp;source=editors&amp;ust=1765035744588071&amp;usg=AOvVaw2snkhtuJiVjVUZPxBmtwgW">https://sites.google.com/site/shinnosuketakamichi/publication/corpus</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>ZFTurbo&rsquo;s list (contains duplicates from below):<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/40&amp;sa=D&amp;source=editors&amp;ust=1765035744588418&amp;usg=AOvVaw0AD7EBMCTjIIMUn74JYlse">https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/40</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Check out also:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/773763762887852072&amp;sa=D&amp;source=editors&amp;ust=1765035744588661&amp;usg=AOvVaw3tPVCnB_3KWkRr1Jic5q7X">#resources</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1286052299931652106&amp;sa=D&amp;source=editors&amp;ust=1765035744588775&amp;usg=AOvVaw12xyBivgWMzNoOv4n48gn5">#datasets</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/ZPtAU5R6rP&amp;sa=D&amp;source=editors&amp;ust=1765035744588919&amp;usg=AOvVaw1TyJesNRehp_TaAkFY-Pr6">invite</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">musdb18-h</span><span class="c22">q </span><span>(for described errors in the repo </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://sigsep.github.io/datasets/musdb.html%23errata&amp;sa=D&amp;source=editors&amp;ust=1765035744589248&amp;usg=AOvVaw1jDmYQ3pohgG7EwJblfHyB">read</a></span><span class="c0">)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1ieGcVPPfgWg__BTDlIGi1TpntdOWwwdn/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744589524&amp;usg=AOvVaw3QxLWRaRyHLsXGM3-cAIJu">https://drive.google.com/file/d/1ieGcVPPfgWg__BTDlIGi1TpntdOWwwdn/view?usp=sharing</a></span><span>&nbsp;(14GB 7z)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/record/3338373%23.Yr2x0aQ9eyU&amp;sa=D&amp;source=editors&amp;ust=1765035744589801&amp;usg=AOvVaw0EpvB8E_wdHL3XlR8uBmbr">https://zenodo.org/record/3338373#.Yr2x0aQ9eyU</a></span><span>&nbsp;(mirror, 22GB zip, it can be slow at times)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Slakh2100</span><span class="c0">&nbsp;(2100 tracks), mono, guitar + piano, and a LOT of other stems, no vocals</span></p><p class="c1"><span class="c0">If we were to ever train a multiple-source Demucs model, it would be greatly helpful </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1baMOSgbqogexZ5VDFsq3X6hgnIpt_bPw/view&amp;sa=D&amp;source=editors&amp;ust=1765035744590624&amp;usg=AOvVaw0IU6qeyhGriHXEte70JoDv">https://drive.google.com/file/d/1baMOSgbqogexZ5VDFsq3X6hgnIpt_bPw/view</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ethman/slakh-utils&amp;sa=D&amp;source=editors&amp;ust=1765035744590792&amp;usg=AOvVaw2AEezV3v7gCEnPzZm_HXQr">https://github.com/ethman/slakh-utils</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1sxdNk0kekvv8FwDvzNypYe6Nf7d40Iek/view?usp%3Ddrivesdk&amp;sa=D&amp;source=editors&amp;ust=1765035744591093&amp;usg=AOvVaw3n2Q-Z2AJ3m_dR6HBOApAQ">https://drive.google.com/file/d/1sxdNk0kekvv8FwDvzNypYe6Nf7d40Iek/view?usp=drivesdk</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Jammit </span><span>(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1yL_ni6ENH9g9gJF4APCNwni7KiJTlZ1k/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744591361&amp;usg=AOvVaw1YilSNbguqQ4tJnZjH5fwJ">torrent</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">&quot;the audio files can&#39;t be mixed directly. You need to apply a gain reduction of 0.77499997615814209 (in dB : -2.2139662170837942) on each track to get a perfect mixdown. This factor is about to set a 0dB on the original jammit mixtable.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">MoisesDB</span><span><br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://music.ai/blog/news/introducing-moisesdb-the-ultimate-multitrack-dataset-for-source-separation-beyond-4-stems/&amp;sa=D&amp;source=editors&amp;ust=1765035744592229&amp;usg=AOvVaw0azeJIfqWNYEC86fv2TpI_">https://music.ai/blog/news/introducing-moisesdb-the-ultimate-multitrack-dataset-for-source-separation-beyond-4-stems/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;Total tracks: 240</span></p><p class="c1"><span class="c0">How often folders exists for track: (&#39;vocals&#39;, 239), (&#39;drums&#39;, 238), (&#39;bass&#39;, 236), (&#39;guitar&#39;, 222), (&#39;other_keys&#39;, 110), (&#39;piano&#39;, 110), (&#39;percussion&#39;, 99), (&#39;bowed_strings&#39;, 45), (&#39;other&#39;, 39), (&#39;wind&#39;, 26), (&#39;other_plucked&#39;, 7)&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Script to convert MoisesDB in MusDB18 format:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://gist.github.com/kiselecheck/df62174c5d986afcc5875300fd38bf9a&amp;sa=D&amp;source=editors&amp;ust=1765035744593066&amp;usg=AOvVaw3DJCKTuQpgN_-8W6msNvxx">https://gist.github.com/kiselecheck/df62174c5d986afcc5875300fd38bf9a</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Cambridge Multitrack Library</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://multitracksearch.cambridge-mt.com/ms-mtk-search.htm&amp;sa=D&amp;source=editors&amp;ust=1765035744593415&amp;usg=AOvVaw1TAINnKIFKOxPVUDHoOV33">https://multitracksearch.cambridge-mt.com/ms-mtk-search.htm</a></span></p><p class="c1"><span class="c0">A nice collection of legally available multitracks.</span></p><p class="c1"><span class="c0">&quot;I believe about 2/3rds of musdb18&#39;s tracks are taken from this.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Great for dataset for creating stem specific models like acoustic guitars, electric guitars, piano, etc. You will just get the stem file you want and combine the rest</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">DAMP-VSEP</span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/record/3553059&amp;sa=D&amp;source=editors&amp;ust=1765035744594243&amp;usg=AOvVaw0ZFVi_MMqAMKWy6smLxDBV">https://zenodo.org/record/3553059</a></span></p><p class="c1"><span class="c0">Smule Digital Archive of Mobile Performances - Vocal Separation</span></p><p class="c1"><span class="c0">seems to be a really big dataset of instrumental-amateur vocal-mix with compression and such triplets.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Metapop</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://metapop.com/competitions?p%3D1%26status%3Dended%26type%3Dall&amp;sa=D&amp;source=editors&amp;ust=1765035744594893&amp;usg=AOvVaw26zPxY6rwE26H7-cMUOwHp">https://metapop.com/competitions?p=1&amp;status=ended&amp;type=all</a></span></p><p class="c1"><span class="c0">&ldquo;Most of them have a click through to download stems. You might need to automate downloads using Simple Mass Downloader browser extension or something. Some are remix competitions, some a production, but all have stems.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Guitar Hero / Rockband stems</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://remixpacks.ru&amp;sa=D&amp;source=editors&amp;ust=1765035744595533&amp;usg=AOvVaw0qebs6FnELDQzMyLyuBruX">remixpacks.ru</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://remixpacks.club/&amp;sa=D&amp;source=editors&amp;ust=1765035744595631&amp;usg=AOvVaw3LMTdbeAy6OQsJlNDeN2yM">remixpacks.club</a></span><span>&nbsp;(taken down, now it&rsquo;s under </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://remixpacks.net/&amp;sa=D&amp;source=editors&amp;ust=1765035744595766&amp;usg=AOvVaw0PwMybv5oim63DDfoxnm_x">https://remixpacks.net/</a></span><span class="c0">&nbsp;address [not sure if the site content is the same)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1hQFEqotf1JDraxScCIMOxIDTWqNokiFk/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744596042&amp;usg=AOvVaw1d63ZYF5wg_JjeHc6cF7JL">Python script</a></span><span>&nbsp;by MissAllure for downloading stems from: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1BtUSgPffbcaW4bMuGClYi8FGvaYmYyc1p4SkfpNty-U/edit?gid%3D0%23gid%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035744596384&amp;usg=AOvVaw19jFvjwP-10jDPIIblPcr_">https://docs.google.com/spreadsheets/d/1BtUSgPffbcaW4bMuGClYi8FGvaYmYyc1p4SkfpNty-U/edit?gid=0#gid=0</a></span><span class="c0">&nbsp;(only 10, but you can change it; saves you from having to open links; written by AI)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Remix packs master post (removed dead links) - still has like 2000+ stems </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/11NrElQSjrXT_DbTL00r9OeMrrEBral3V/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744596993&amp;usg=AOvVaw3SVtqQdljfjEEuCVHPWZJx">https://drive.google.com/file/d/11NrElQSjrXT_DbTL00r9OeMrrEBral3V/view?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Torrent:</span></p><p class="c1"><span class="c0">or here:</span></p><p class="c1"><span class="c0">magnet:?xt=urn:btih:45a805dbd78b8dec796a0a127c4b4d2466ddbb9a</span></p><p class="c1"><span class="c0">(list with names:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1uCWmuAUfvVLonbXp9sQUb9dEODYTHmPAOyvGxulMOCA/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744597614&amp;usg=AOvVaw2r48dxY5fq7f9VNxvr0C-r">https://docs.google.com/spreadsheets/d/1uCWmuAUfvVLonbXp9sQUb9dEODYTHmPAOyvGxulMOCA/edit?usp=sharing</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">Renamer - python script</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/gEgwwaaB%23BCDDMpl-VcIZDnNYQziyklOV9Vpf43wuc76hsS3JTlw&amp;sa=D&amp;source=editors&amp;ust=1765035744597924&amp;usg=AOvVaw08QW8Sxeb0Hc_mWJN8dFob">https://mega.nz/file/gEgwwaaB#BCDDMpl-VcIZDnNYQziyklOV9Vpf43wuc76hsS3JTlw</a></span></p><p class="c1"><span class="c0">Showcase</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D95Q31HjU04E&amp;sa=D&amp;source=editors&amp;ust=1765035744598142&amp;usg=AOvVaw2prD6glhnIDtWTgidTr8f1">https://www.youtube.com/watch?v=95Q31HjU04E</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Archive.org copy</span></p><p class="c1"><span class="c68"><a class="c3" href="https://www.google.com/url?q=https://web.archive.org/web/20230105142738/https://telegra.ph/Remixpacks-Collection-Vol-01-04-12-25&amp;sa=D&amp;source=editors&amp;ust=1765035744598541&amp;usg=AOvVaw3MLKShAWBexgVRY7ZIubBD">https://web.archive.org/web/20230105142738/https://telegra.ph/Remixpacks-Collection-Vol-01-04-12-25</a></span></p><p class="c1"><span class="c0">Or here (but you can&rsquo;t access all the sections at the bottom and after some time you get &ldquo;Unable to load&rdquo; error; probably using the old Manifest uBlock with blocking specific site element would work, not sure):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://web.archive.org/web/20230521064118/https://docs.google.com/spreadsheets/d/1_dIFNK3LC8A40YK-qCEHhxOCFIbny7Jv4qPEoOKBrIA/edit&amp;sa=D&amp;source=editors&amp;ust=1765035744599258&amp;usg=AOvVaw1X8-aB1cQU-xcAfwUy4kcw">https://web.archive.org/web/20230521064118/https://docs.google.com/spreadsheets/d/1_dIFNK3LC8A40YK-qCEHhxOCFIbny7Jv4qPEoOKBrIA/edit</a></span></p><p class="c1"><span class="c0">(separate downloads) <br>OG subreddit source along with the file was deleted, and back when it was online, probably it was locked from downloading and scrapping it was difficult.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Q: </span><span class="c68"><a class="c3" href="https://www.google.com/url?q=https://web.archive.org/web/20230105142738/https://telegra.ph/Remixpacks-Collection-Vol-01-04-12-25&amp;sa=D&amp;source=editors&amp;ust=1765035744599978&amp;usg=AOvVaw13Ts6h37euq8Vsm67UJD_h">https://web.archive.org/web/20230105142738/https://telegra.ph/Remixpacks-Collection-Vol-01-04-12-25</a></span><span class="c0">&nbsp;contents list? I don&rsquo;t want to download all of them just to find one thing (genie in a bottle stems) </span></p><p class="c1"><span class="c0">A:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1eN2-l0OBD3R8AHRGjKuHpxTHbevYi0kg1O7zJZHvylY/edit?usp%3Ddrivesdk&amp;sa=D&amp;source=editors&amp;ust=1765035744600600&amp;usg=AOvVaw280VZbrjau5e1L8xRK7u-E">https://docs.google.com/spreadsheets/d/1eN2-l0OBD3R8AHRGjKuHpxTHbevYi0kg1O7zJZHvylY/edit?usp=drivesdk</a></span></p><p class="c1"><span class="c0">If there are no seeds, so the torrent is dead, &ldquo;a major part of these stems are on the songstems telegram chat, including new stems that aren&#39;t in these packs&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/%2BmrluHEcfixwwNzRk&amp;sa=D&amp;source=editors&amp;ust=1765035744601073&amp;usg=AOvVaw16_D3PbBTBubXtz0q_knSp">https://t.me/+mrluHEcfixwwNzRk</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;For those that aren&#39;t able to d/l the torrents anymore, or just want to d/l some of the remixpacks content,</span></p><p class="c1"><span>I uploaded all 26 collections (~3TB) here: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://remixpacks.multimedia.workers.dev/&amp;sa=D&amp;source=editors&amp;ust=1765035744601549&amp;usg=AOvVaw3ejk762uihwWkk1kn_1DpW">https://remixpacks.multimedia.workers.dev/</a></span></p><p class="c1"><span class="c0">DM me to request username/password.&rdquo; Bas Curtiz#5667</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://clubremixer.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744601883&amp;usg=AOvVaw0pCcpsK7ON5RbQqIgXBeip">https://clubremixer.com/</a></span><span class="c0">&nbsp;- outrageously big database, probably reuploads from remixpacks too (but on slow Nitroflare or simply paid irc)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://songstems.net/&amp;sa=D&amp;source=editors&amp;ust=1765035744602195&amp;usg=AOvVaw3PdBfBHWFQmyG5WUySTAvm">https://songstems.net/</a></span><span class="c0">&nbsp;- lots of remixpacks stuff reuploaded from masterposts of clubremixer.com to Yandex (free Nitroflare is 20KB/s)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c34 c42 c36 c33 c30 c50">Mega collection of stems/multitracks (remixpacks - Guitar Hero, Rock Band, OG)</span></p><p class="c1"><span class="c68"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1_dIFNK3LC8A40YK-qCEHhxOCFIbny7Jv4qPEoOKBrIA&amp;sa=D&amp;source=editors&amp;ust=1765035744603054&amp;usg=AOvVaw1f-7cwEitLPe7E3r3wLKg-">https://docs.google.com/spreadsheets/d/1_dIFNK3LC8A40YK-qCEHhxOCFIbny7Jv4qPEoOKBrIA</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Rock Band 4 stems (free Nitroflare mirror)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://clubremixer.com/rb4-stems/&amp;sa=D&amp;source=editors&amp;ust=1765035744603391&amp;usg=AOvVaw1sivXA1b-96mwl2U9nqyMY">https://clubremixer.com/rb4-stems/</a></span></p><p class="c1"><span>D</span><span class="c0">ifferent mixing of the RB tracks was a factor in models trained by the community. &ldquo;Also, RB tracks never fade out. They are also never brickwalled.&rdquo;</span></p><p class="c1"><span>&ldquo;brickwall audio has negative influence on waveform based archs, but on spectrogram based one like all recents one, it doesn&#39;t seem to have big impact on results quality&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>GH stems from X360 instead of Wii for better quality </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.fretsonfire.org/forums/viewtopic.php?f%3D5%26t%3D57010%26sid%3D3917a8e390f65097f07d69595dd5ba55&amp;sa=D&amp;source=editors&amp;ust=1765035744604379&amp;usg=AOvVaw2gX0s_SyJrT32ZWwwqjC8N">https://www.fretsonfire.org/forums/viewtopic.php?f=5&amp;t=57010&amp;sid=3917a8e390f65097f07d69595dd5ba55</a></span></p><p class="c1"><span class="c0">(free registration required, basically content of all zippyshare links of the PDF below:)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">PDF with separate RB3-4 stems description and DL (lots of links are offline as zippyshare is down), page 6 shows some table of content with evaluation progress.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1ku9KB0GQGkxh1a6z7Wm2WteMWeCyTkFV/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744605128&amp;usg=AOvVaw3gEN-ksNr8Ysgfvuj00QpT">toaz.info-stemspdf-pr_7a1e446f01c9b1666a9bebe9fd51f419.pdf</a></span><span class="c0">&nbsp;(reupload)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Huge database (probably contains some of the above)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://songstems.net/&amp;sa=D&amp;source=editors&amp;ust=1765035744605422&amp;usg=AOvVaw2Z9a0I0lMeJJmznVZMl6F9">https://songstems.net/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Others</span><span class="c0">:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Multitracks&rsquo; section of rutracker (requires free account):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rutracker.org/forum/tracker.php?f%3D2492&amp;sa=D&amp;source=editors&amp;ust=1765035744605949&amp;usg=AOvVaw3UdynibXUfxeONBQ8QcIKF">https://rutracker.org/forum/tracker.php?f=2492</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Multitracks/multitrack queries on The Pirate Bay</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://thepiratebay.org/search.php?q%3Dmultitrack%26all%3Don%26search%3DPirate%2BSearch%26page%3D0%26orderby%3D&amp;sa=D&amp;source=editors&amp;ust=1765035744606423&amp;usg=AOvVaw3ronlbTlpOENIZqPwVVsov">https://thepiratebay.org/search.php?q=multitrack&amp;all=on&amp;search=Pirate+Search&amp;page=0&amp;orderby=</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://thepiratebay.org/search.php?q%3Dmultitracks%26all%3Don%26search%3DPirate%2BSearch%26page%3D0%26orderby%3D&amp;sa=D&amp;source=editors&amp;ust=1765035744606717&amp;usg=AOvVaw1qcjyEnBSu4tYoAtRAS9Rf">https://thepiratebay.org/search.php?q=multitracks&amp;all=on&amp;search=Pirate+Search&amp;page=0&amp;orderby=</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;You can just go here </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rutracker.org/forum/tracker.php?f%3D1674&amp;sa=D&amp;source=editors&amp;ust=1765035744607026&amp;usg=AOvVaw3RDHJR9A7k9Cvuk1EbzlI2">https://rutracker.org/forum/tracker.php?f=1674</a></span><span class="c0">&nbsp;(sample libraries category) and type the instrument you want, it will pop all the sample packs.</span></p><p class="c1"><span class="c0">Maybe add &quot;loop&quot; to the search too, will filter out some weird packs&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Maybe you find something useful on sharemania.us too (160 lossy/261 lossless)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Seems &#39;acapella tools&#39; or &#39;instrumental tools&#39; are good key-words to search for.</span></p><p class="c1"><span class="c0">Some are covers of original tracks, but that shouldn&#39;t matter, since they represent the same.</span></p><p class="c1"><span class="c0">This is on Deezer, but u might find others on Tidal.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There&rsquo;s also some stuff available on Soulseek (P2P service)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>frp.live</span><span class="c0">&nbsp;instrumentals/acapellas</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1NuQV8cfFPehvIwPBUGOMbiC4FSei2p923qC6af5tCV8/&amp;sa=D&amp;source=editors&amp;ust=1765035744608606&amp;usg=AOvVaw19bke_brmPC6WktnCAVR3U">https://docs.google.com/spreadsheets/d/1NuQV8cfFPehvIwPBUGOMbiC4FSei2p923qC6af5tCV8/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>22 instrumental albums and some single tracks (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://disk.yandex.com/d/Y3qPsnphNoKM2Q&amp;sa=D&amp;source=editors&amp;ust=1765035744608835&amp;usg=AOvVaw1tgr_mlTgJugl2VoyiKsZj">DL</a></span><span>) - hard to align for inversion, even for lossless, sometimes time shifts every verse, possible artefacts/bleeding after inversion to be cleaned further with </span><span class="c4"><a class="c3" href="#h.tv0x7idkh1ua">models</a></span><span>.<br><br>127 hip-hop instrumentals with vocal chops (duplicates from the above), and 80 with scratches or harmonies (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://buzzheavier.com/bjbhhr92sd8d&amp;sa=D&amp;source=editors&amp;ust=1765035744609353&amp;usg=AOvVaw1ZVx1PWr6DBlDKlbGmVFol">DL</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Giliaan stems</span><span class="c0">&nbsp;for 4 songs (EDM/Dance/House) and Mainstream Dataset with 20 songs:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JbQRMYH9DT_vUHpf4jHwD80eC6VvpDZX&amp;sa=D&amp;source=editors&amp;ust=1765035744609806&amp;usg=AOvVaw2M8ap41WxTdyV1rOMS_3aM">https://drive.google.com/drive/folders/1JbQRMYH9DT_vUHpf4jHwD80eC6VvpDZX</a></span></p><p class="c1"><span class="c0">Mirror (with messages below)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1286052299931652106/1304884347492372580&amp;sa=D&amp;source=editors&amp;ust=1765035744610161&amp;usg=AOvVaw27gQZ7M3bKoy-oBwxtctui">https://discord.com/channels/708579735583588363/1286052299931652106/1304884347492372580</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>50 Produce Like a Pro multitracks<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://producelikeapro.com/blog/happy-new-year-2022-3/&amp;sa=D&amp;source=editors&amp;ust=1765035744610471&amp;usg=AOvVaw3Dutpc-XHlU4pvEL7K7Q7e">https://producelikeapro.com/blog/happy-new-year-2022-3/</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://producelikeapro.lpages.co/keep-truckin-multitracks-form/&amp;sa=D&amp;source=editors&amp;ust=1765035744610739&amp;usg=AOvVaw0LxQlpHVdSNnE02W588qyP">https://producelikeapro.lpages.co/keep-truckin-multitracks-form/</a></span></p><p class="c1"><span>Potentially more: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/playlist?list%3DPLnLOmVwRMCqS1ia3o9Vv0nG5sMgcFR9Tc&amp;sa=D&amp;source=editors&amp;ust=1765035744611120&amp;usg=AOvVaw357GnP6TwsOsAGgShY5D-_">https://www.youtube.com/playlist?list=PLnLOmVwRMCqS1ia3o9Vv0nG5sMgcFR9Tc</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sites:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://promodj.com/tools&amp;sa=D&amp;source=editors&amp;ust=1765035744611526&amp;usg=AOvVaw3vfn74JOn7KEgBjBhIitWc">https://promodj.com/tools</a></span></p><p class="c1"><span class="c0">There is a lot of filtered trash, but you can also find official acapellas.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.acapellas4u.co.uk/&amp;sa=D&amp;source=editors&amp;ust=1765035744611924&amp;usg=AOvVaw3t-EqIRfsGg7NhJbrp1hBD">https://www.acapellas4u.co.uk/</a></span></p><p class="c1"><span class="c0">Collection of 40K instrumentals and accapellas (lossy, rather avoid using such files for training, and search for lossless if possible)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://isolated-tracks.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744612375&amp;usg=AOvVaw260RlPaUftM2sa2xG9nRYV">https://isolated-tracks.com/</a></span></p><p class="c1"><span class="c0">Multitracks. Looks like paid, but it has also few pages with some free ones (e.g. Fleetwood Mac, not sure if free)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.multitracks.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744612839&amp;usg=AOvVaw0asg9Z2pY-BSQp3Q-Zq3cT">https://www.multitracks.com/</a></span></p><p class="c1"><span class="c0">This is also paid, but it has less known music</span></p><p class="c1"><span class="c0">&ldquo;those are covers from famous songs, but all in multitracks.</span></p><p class="c1"><span class="c0">And from what I&#39;ve listened to so far, is that they are pretty conservative.</span></p><p class="c1"><span class="c0">The vocals all seem to be dry and none seem to contain bleed so far.</span></p><p class="c1"><span class="c0">Also, the instrument stems are proper / not mixed up with other instrumentals.</span></p><p class="c1"><span class="c0">The stems are the exact same duration. </span></p><p class="c1"><span class="c0">All in all, a solid dataset right off-the-bat imo.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I should&#39;ve calculated it prior, what the better subscription was, the 10GB or 20GB a day one vs. price vs. content approx. in total.</span></p><p class="c1"><span class="c0">52mb (wav) * 12 (multitracks) = 624mb per song</span></p><p class="c1"><span class="c0">4.766 songs * 624 = 2973984 mb = 2.97tb</span></p><p class="c1"><span class="c0">weekly limit = 70gb * 4 (weeks) = 280gb = 280000mb</span></p><p class="c1"><span class="c0">2973984 / 280000 = 10,6 weeks in total.</span></p><p class="c1"><span class="c0">10,6 / 4 = 2,65 so 3 months x $30 = 90 bucks&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.epidemicsound.com/music/search/&amp;sa=D&amp;source=editors&amp;ust=1765035744614987&amp;usg=AOvVaw17p3oX9ctdqKaPAziTeiHC">https://www.epidemicsound.com/music/search/</a></span></p><p class="c1"><span class="c0">Can be ripped. Some tracks there will be a subject to rule out due to bleeding. Plenty of genres. Might be good for diverse dataset.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://bleep.com/stream/stems&amp;sa=D&amp;source=editors&amp;ust=1765035744615436&amp;usg=AOvVaw3CxQHg-grSZ5Hn4ti_zPZb">https://bleep.com/stream/stems</a></span></p><p class="c1"><span class="c0">Looks like official stems for sale. ~45 songs in total.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">FullSOL</span><span class="c0">&nbsp;(only for premium users; min. 200EU for year)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://forum.ircam.fr/projects/detail/fullsol/&amp;sa=D&amp;source=editors&amp;ust=1765035744615985&amp;usg=AOvVaw33JlDTHQ70H8sveapqV5BY">https://forum.ircam.fr/projects/detail/fullsol/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">19,91 GB of audio samples. No percussion.</span></p><p class="c1"><span class="c0">Instruments: Bass Tuba, Horn, Trombone, Trumpet in C, Accordion, Harp, Guitar, Violin, Viola, Violoncello, Contrabass, Bassoon, Bb Clarinet, Flute, Oboe, Alto Saxophone</span></p><p class="c1"><span class="c0">(jarredou have it)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c42 c12 c15 c33">Vocals/speech</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">MedleyVox dataset </span><span>(for separating different singers)</span><span class="c22">&nbsp;</span><span>of </span><span class="c0">which they refrain from releasing the model for (and Cyrus eventually did it single-handedly):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/CBeast25/MedleyVox&amp;sa=D&amp;source=editors&amp;ust=1765035744617383&amp;usg=AOvVaw3IVOfTTqD9O1md-UvEXTbv">https://github.com/CBeast25/MedleyVox</a></span><span class="c0">&nbsp;(13 different singing datasets of 400 hours and 460 hours of LibriSpeech data for training)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/record/7984549&amp;sa=D&amp;source=editors&amp;ust=1765035744617798&amp;usg=AOvVaw3rRH_FQSBazP5zPrIU2BZY">https://zenodo.org/record/7984549</a></span></p><p class="c1"><span class="c0">k_multisinger:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/18evyY82ec4IdNT2z8q76zm30EWhfc-9j/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744618152&amp;usg=AOvVaw2uG7Js76xJf6UiBoLl3eWR">https://drive.google.com/file/d/18evyY82ec4IdNT2z8q76zm30EWhfc-9j/view?usp=sharing</a></span></p><p class="c1"><span class="c0">k_multitimbre / K_multitembre:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Ic4P8gCGwbLshR118N8V3tbAU-D9Us-i/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744618516&amp;usg=AOvVaw1OrAUecce7rrXLmwe6apzX">https://drive.google.com/file/d/1Ic4P8gCGwbLshR118N8V3tbAU-D9Us-i/view?usp=sharing</a></span></p><p class="c1"><span class="c0">Potentially more here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://sites.google.com/site/shinnosuketakamichi/home&amp;sa=D&amp;source=editors&amp;ust=1765035744618795&amp;usg=AOvVaw0VcJYoY85_MgoIvR3BybOP">https://sites.google.com/site/shinnosuketakamichi/home</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that the only one MedleyVox dataset which remains unobtainable to this day is TONAS, but it&rsquo;s small, esp. compare to the Korean datasets. Besides this one, queer and Cyrus have them all on our Discord, but they&rsquo;re huge. Ksinger and Ktimbre takes ~300GB unzipped for both.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Jarredou&rsquo;s (@rigo2) dataset with screaming, cheering, applause, whistling, mumble, etc... collected from all the sources I&#39;ve found, to help model creation:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">+5000 stereo wav files, 44100hz</span></p><p class="c1"><span class="c0">~37 hours of audio data</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- &rdquo;Ultimate </span><span class="c22">laugh</span><span>&nbsp;tracks for sitcoms, game shows, talk shows, and comedy projects (available on Amazon Music and Apple Music (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/1Nsh1YZa%23laCLTYV1Rx_LpMQX63hT4hk_76ajw0sOLrVfqjLt42Y&amp;sa=D&amp;source=editors&amp;ust=1765035744620237&amp;usg=AOvVaw3RFtaEdP3Cy6yTOKRVxxVI">ripped</a></span><span class="c0">, YT upload has similarly looking spectrograms)</span></p><p class="c1"><span>- Laughter-Crowd Dataset #2.zip </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://terabox.com/s/1xLuZWvpGX0LTQypO1p7u_g&amp;sa=D&amp;source=editors&amp;ust=1765035744620615&amp;usg=AOvVaw1pkaI_02NAg61Z17EyJoPE">https://terabox.com/s/1xLuZWvpGX0LTQypO1p7u_g</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://multitracks.pages.dev/&amp;sa=D&amp;source=editors&amp;ust=1765035744620892&amp;usg=AOvVaw0kMw7lNsrTzr7OnXVyVyNc">https://multitracks.pages.dev/</a></span><span class="c0">&nbsp;(only a list, no DL links)</span></p><p class="c1"><span class="c0">English and Spanish multitracks</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Around 30GB of T.Swft stems (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/file/o8wRmZBR%231-XGfJ-051o8JUL10wRth4dskPnvI7jf6qc22zloZ0w&amp;sa=D&amp;source=editors&amp;ust=1765035744621294&amp;usg=AOvVaw2zHnXgLtKluJAXC6A6K87H">1</a></span><span>&nbsp;(not necessarily mirror) | </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/folder/JPtSFLTB%238IQTBnSgUnnwwWBKvt_VCA&amp;sa=D&amp;source=editors&amp;ust=1765035744621476&amp;usg=AOvVaw1azg0Zgd8BJKTZUab3s0U_">2</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- There is 768.44 GB of K-pop stems somewhere in the wild (maybe ask .mikeyyyyy)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Gabox karaoke dataset (2GB)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://gofile.io/d/TyzaH8&amp;sa=D&amp;source=editors&amp;ust=1765035744622181&amp;usg=AOvVaw0dNI2QbihCC2THN8lFH0EC">https://gofile.io/d/TyzaH8</a></span></p><p class="c1"><span class="c0">&ldquo;(may need a check, iirc there were songs without bv, also it doesn&#39;t have the vocals part)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- RawStems</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/datasets/yongyizang/RawStems&amp;sa=D&amp;source=editors&amp;ust=1765035744622755&amp;usg=AOvVaw3zJUaxlsTtSlC2RQuJ8cax">https://huggingface.co/datasets/yongyizang/RawStems</a></span><span class="c0">&nbsp;(DL)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/yongyizang/music-source-restoration/blob/main/preprint.pdf&amp;sa=D&amp;source=editors&amp;ust=1765035744623215&amp;usg=AOvVaw1v53o9o_pO11xCoCOXzvOw">https://github.com/yongyizang/music-source-restoration/blob/main/preprint.pdf</a></span><span class="c0">&nbsp;(paper)</span></p><p class="c1"><span class="c0">&ldquo;A dataset annotation of 578 songs with unprocessed source signals organized into 8 primary and 17 secondary instrument groups, totaling 354.13 hours. To the best of our knowledge, RawStems is the first dataset that contains unprocessed music stems with hierarchical categories&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">- </span><span class="c20">Expressive Anechoic Recordings of Speech (</span><span class="c12">EARS</span><span class="c6">) dataset.</span></p><ul class="c9 lst-kix_6pgojrjbxqei-0 start"><li class="c16 c1 c25 c48 li-bullet-0"><span class="c22">100 h</span><span>&nbsp;of speech data from </span><span class="c18 c15">107 speakers</span></li><li class="c16 c1 c25 c48 li-bullet-0"><span>high-quality recordings at </span><span class="c22">48 kHz</span><span class="c0">&nbsp;in an anechoic chamber</span></li><li class="c16 c1 c25 c48 li-bullet-0"><span class="c22">high speaker diversity</span><span class="c0">&nbsp;with speakers from different ethnicities and age range from 18 to 75 years</span></li><li class="c16 c1 c25 c48 li-bullet-0"><span class="c22">full dynamic range</span><span class="c0">&nbsp;of human speech, ranging from whispering to yelling</span></li><li class="c16 c1 c25 c48 li-bullet-0"><span>18 minutes of </span><span class="c22">freeform monologues</span><span class="c0">&nbsp;per speaker</span></li><li class="c16 c1 c25 c48 li-bullet-0"><span>sentence reading in </span><span class="c22">7 different reading styles</span><span class="c0">&nbsp;(regular, loud, whisper, high pitch, low pitch, fast, slow)</span></li><li class="c16 c1 c25 c48 li-bullet-0"><span>emotional reading and freeform tasks covering </span><span class="c22">22 different emotions</span><span class="c0">&nbsp;for each speaker</span></li></ul><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/ears_dataset&amp;sa=D&amp;source=editors&amp;ust=1765035744625366&amp;usg=AOvVaw30j5N7oPUMepA3Aprgpt7_">https://github.com/facebookresearch/ears_dataset</a></span></p><p class="c1"><span class="c23 c15 c30">DL:</span></p><p class="c1"><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/ears_dataset/releases/download/dataset/p001.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744625560&amp;usg=AOvVaw2k_EqXs_beC0HPvPOcU9DF">1</a></span><span>&nbsp;| </span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/ears_dataset/releases/download/dataset/p002.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744625682&amp;usg=AOvVaw3Ai1n28Hx7GWdEum5iheAq">2</a></span><span>&nbsp;| </span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/ears_dataset/releases/download/dataset/p003.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744625795&amp;usg=AOvVaw3swBMw7i-FWasmH1I8eab5">3</a></span><span>&nbsp;| </span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/ears_dataset/releases/download/dataset/p104.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744625919&amp;usg=AOvVaw2OsPOT5sjtU5cHeVtcW8ZZ">4</a></span><span>&nbsp;| </span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/ears_dataset/releases/download/dataset/p105.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744626034&amp;usg=AOvVaw1xnS39TjhOGUZTUdsupzlq">5</a></span><span>&nbsp;| </span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/ears_dataset/releases/download/dataset/p106.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744626143&amp;usg=AOvVaw1x6N5gzg7Xgmcxs7gNGNt_">6</a></span><span>&nbsp;| </span><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/ears_dataset/releases/download/dataset/p107.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744626254&amp;usg=AOvVaw2mxVKKEONbHVQ8rQPVghd5">7</a></span><span class="c23 c15 c30">&nbsp;&ldquo;The dataset is made of 107 zip files that you can download one by one manually&rdquo;</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c23 c15 c30">&ldquo;What is great with this dataset is that it was recorded in anechoic chamber, so no reverb, no echo, with high-end hardware. You can use it as baseline for reverb removal, speech enhancing, etc...&rdquo; jarredou</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c23 c15 c30">- Metal dataset</span></p><p class="c1"><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/records/8406322&amp;sa=D&amp;source=editors&amp;ust=1765035744626975&amp;usg=AOvVaw2OjuqQDBk_E8J33it_iD9x">https://zenodo.org/records/8406322</a></span></p><p class="c1"><span class="c23 c15 c30">760 audio excerpts from 1 to 30 seconds in mono.</span></p><p class="c1"><span class="c23 c15 c30">&ldquo;iirc, the audio samples can be very short, it may need pre-processing (merging multiple samples in 1 file) to be used for training&rdquo;- &nbsp;jarredou</span></p><p class="c1"><span class="c23 c15 c30">I think mesk did the job already for his dataset (it&rsquo;s uploaded later below).</span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c23 c15 c30">Around a hundred of Eminem&rsquo;s acapellas leaked:</span></p><p class="c1"><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/141t33Qa2h3rEi2T0lYokvBPiiDBbC6dQ&amp;sa=D&amp;source=editors&amp;ust=1765035744627877&amp;usg=AOvVaw072slYsRzzJR8XR8ss_FsJ">https://drive.google.com/drive/folders/141t33Qa2h3rEi2T0lYokvBPiiDBbC6dQ</a></span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c23 c15 c30">Official and unofficial Eminem instrumentals (single links):</span></p><p class="c1"><span class="c4 c31"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1x9tTOOqH5WpKOoptdQzABSN_x8oZbMgzIGlGH9w1IKA/edit?gid%3D965054462%23gid%3D965054462&amp;sa=D&amp;source=editors&amp;ust=1765035744628485&amp;usg=AOvVaw087GPR9vKMTjm8esW5p2Hh">https://docs.google.com/spreadsheets/d/1x9tTOOqH5WpKOoptdQzABSN_x8oZbMgzIGlGH9w1IKA/edit?gid=965054462#gid=965054462</a></span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c18 c15">Piano</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;</span><span class="c22">MAESTRO</span><span class="c0">&rdquo; is a dataset composed of about 200 hours of virtuosic piano performances captured with fine alignment (~3 ms) between note labels and audio waveforms.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://magenta.tensorflow.org/datasets/maestro&amp;sa=D&amp;source=editors&amp;ust=1765035744629180&amp;usg=AOvVaw3i4v0Cwd2t1r8mCn9-vD8T">https://magenta.tensorflow.org/datasets/maestro</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">GiantMIDI-Piano</span><span class="c0">&nbsp;is a classical piano MIDI dataset contains 10,855 MIDI files of 2,786 composers. The curated subset by constraining composer surnames contains 7,236 MIDI files of 1,787 composers. GiantMIDI-Piano are transcribed from live recordings with a high-resolution piano transcription system</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/bytedance/GiantMIDI-Piano&amp;sa=D&amp;source=editors&amp;ust=1765035744629904&amp;usg=AOvVaw1XepFo9kk7arjZ59DFhKSb">https://github.com/bytedance/GiantMIDI-Piano</a></span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1 c7"><span class="c23 c15 c30"></span></p><p class="c1"><span class="c18 c15">SFX</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Datasets for potential SFX separation</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cocktail-fork.github.io/&amp;sa=D&amp;source=editors&amp;ust=1765035744630355&amp;usg=AOvVaw1mPHO4QA605OIvuRYhvt3O">https://cocktail-fork.github.io/</a></span><span class="c0">&nbsp;(SPEECH-VOICE-SFX (3 stems), 174GB)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.sounds-resource.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744630622&amp;usg=AOvVaw3AraFfMXexV8Ros4nIpWWb">https://www.sounds-resource.com/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mixkit.co/free-sound-effects/game/&amp;sa=D&amp;source=editors&amp;ust=1765035744630863&amp;usg=AOvVaw0jbrvUyaprszn6lv9AYdsv">https://mixkit.co/free-sound-effects/game/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://opengameart.org/content/library-of-game-sounds&amp;sa=D&amp;source=editors&amp;ust=1765035744631132&amp;usg=AOvVaw2-RG_xLr4XDFDuSeDV2PQj">https://opengameart.org/content/library-of-game-sounds</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pixabay.com/sound-effects/search/game/&amp;sa=D&amp;source=editors&amp;ust=1765035744631371&amp;usg=AOvVaw3VlvN92UsR-XUcCo6qsJxV">https://pixabay.com/sound-effects/search/game/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.boomlibrary.com/shop/?swoof%3D1%26pa_producttype%3Dfree-sound-effects&amp;sa=D&amp;source=editors&amp;ust=1765035744631663&amp;usg=AOvVaw1RSbeEbNTDf1nx_SbLAyJf">https://www.boomlibrary.com/shop/?swoof=1&amp;pa_producttype=free-sound-effects</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Spongebob stems (500MB) </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.usercontent.google.com/download?id%3D1P19Diyw7CRteqeLs0beDpCaexFyZJiDs%26export%3Ddownload%26authuser%3D0&amp;sa=D&amp;source=editors&amp;ust=1765035744632092&amp;usg=AOvVaw01GW0wmY5TYjsfmYBAyczV">https://drive.usercontent.google.com/download?id=1P19Diyw7CRteqeLs0beDpCaexFyZJiDs&amp;export=download&amp;authuser=0</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Nickelodeon leak (2024 Nick Giga Leak7.zip/nick.7z) (10.7GB)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://myrient.erista.me/files/Miscellaneous/Nickelodeon%2520Leaks/&amp;sa=D&amp;source=editors&amp;ust=1765035744632484&amp;usg=AOvVaw3NoVKrNeeXkzZOQqj94aej">https://myrient.erista.me/files/Miscellaneous/Nickelodeon%20Leaks/</a></span></p><p class="c1"><span class="c0">(not a full leak, as it has 500GB and only some people have it)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Sound effects HQ by soniss 2024 (</span><span class="c41">27.5GB+)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://gdc.sonniss.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744632901&amp;usg=AOvVaw09gle8u4CK5rb52PxTHZe1">https://gdc.sonniss.com/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;Free sound FX samples packs from Adobe&rdquo;:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.adobe.com/products/audition/offers/adobeauditiondlcsfx.html&amp;sa=D&amp;source=editors&amp;ust=1765035744633293&amp;usg=AOvVaw35yv_3mQKarLOPYECfnaJD">https://www.adobe.com/products/audition/offers/adobeauditiondlcsfx.html</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Drums</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/records/7860223&amp;sa=D&amp;source=editors&amp;ust=1765035744633696&amp;usg=AOvVaw0MN_-Avssvz0QEKeUsFSNf">StemGMD: A Large-Scale Audio Dataset of Isolated Drum Stems for Deep Drums Demixing</a></span></p><p class="c1"><span class="c0">(although drumsep used bigger dataset consisting of MIDI sounds to avoid bleeding, with XLN only)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Virtual drumkits</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The &ldquo;advantage is that you can have zero bleed between elements, which is not possible with real live drums.</span></p><p class="c1"><span class="c0">You can create &ldquo;more than 300 drumkits as virtual instruments (toontrack, kontakt, xln, slate, bfd, XLN ones are nice too (from their trigger and drums VST) + a Reaper framework to multiply that by 10 (using heavily different mixing processes for each drum elements), so potentially 3000 different sounding drumkits &ldquo;</span></p><p class="c1"><span class="c0">&ldquo;one could use producer sample packs/kits for more modern samples&rdquo; there are tons of packs around the net.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">jarredou (rigo2):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;For those interested, I&#39;m sharing on demand my drums separation dataset.</span></p><p class="c1"><span class="c0">It&#39;s not a final version. I&#39;ve realised after generating 130h of audio data that I&#39;ve made a mistake in routing, leading to some occasional cowbell in snare stems. So it&#39;s &nbsp;[Kick/Snare-cowbell/Toms/HiHat/Ride/Crash] stems. </span></p><p class="c1"><span class="c0">I&#39;ve stopped it&#39;s rendering and will not make the final &quot;mastering&quot; stage that was planned.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I will make a clean no-cowbell version, but as I&#39;m lacking free time, I don&#39;t know when, and as this one is here and already great sounding why not using it in the meantime.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Just don&#39;t mind the cowbell!&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Looks like it&rsquo;s the thing:</span></p><p class="c1"><span class="c68"><a class="c3" href="https://www.google.com/url?q=http://rigaudio.fr/datasets/DrumsDataset.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744636667&amp;usg=AOvVaw0jGhd7eMXmyN3G_ODjjTqL">http://rigaudio.fr/datasets/DrumsDataset.zip</a></span><span class="c34 c42 c36 c33 c30 c50">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Newer version in a better formatted version, with train/valid separated parts, generated mixtures and a fixed filename that was containing an extra space:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rigaudio.fr/datasets/DrumsDatasetv2.zip&amp;sa=D&amp;source=editors&amp;ust=1765035744637190&amp;usg=AOvVaw0YHjb0fuORpVsHm6kCLLYj">https://rigaudio.fr/datasets/DrumsDatasetv2.zip</a></span><span class="c0">&nbsp;(25GB)</span></p><p class="c1"><span class="c0">(still the same issues with some occasional cowbell in snare stems. &ldquo;There are also few other percussions here and there on some little parts for some tracks (like tambourine in ride stem).&rdquo;)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I realise now that I totally forgot to lowercase all filenames before reuploading the dataset.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To avoid issues where some awaited filenames are hardcoded in ZFTurbo&#39;s script, the best way is so to lowercase all filenames in train/valid parts, convert the valid part to .wav files (no need for the train part that can handle flac correctly).</span></p><p class="c1"><span class="c0">And lowercase the stem names in training part of the config file accordingly.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;Can probably be useful to create electro drums separation dataset, free 50,000 drums MIDI files:&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://abasynthphony.gumroad.com/l/50000MIDIFilesforDanceMusicDrum?layout%3Dprofile&amp;sa=D&amp;source=editors&amp;ust=1765035744638745&amp;usg=AOvVaw3XrXK1I5tcaLXOTiKNOtn3">https://abasynthphony.gumroad.com/l/50000MIDIFilesforDanceMusicDrum?layout=profile</a></span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">mesk&rsquo;s metal drums dataset (drums in one stem):</span></p><p class="c1"><span>(dead) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.proton.me/urls/5PGCB22KKC%230koU5OEx71f4&amp;sa=D&amp;source=editors&amp;ust=1765035744639175&amp;usg=AOvVaw3hRDsKyRfg1Smc55PO8Jc0">https://drive.proton.me/urls/5PGCB22KKC#0koU5OEx71f4</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;resharing my metal dataset for people to claw their hands on</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1ajlzmyAuX-fsiKiaypN8y2GT8EYBAws5?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035744639636&amp;usg=AOvVaw1t-cKJKcMLWxy7vXvLvxbW">https://drive.google.com/drive/folders/1ajlzmyAuX-fsiKiaypN8y2GT8EYBAws5?usp=drive_link</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">this consists of:</span></p><p class="c1"><span class="c0">official instrumentals, straight from my stems, what&#39;s not labelled with my name are official as well [remixpacks stuff were curated]</span></p><p class="c1"><span class="c0">vocal folder has official vocals (from the stems again), remixpacks (curated), inverted vocals and some weird whispery sh!t from yours truly&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">---</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.monotostereo.info/&amp;sa=D&amp;source=editors&amp;ust=1765035744640424&amp;usg=AOvVaw3ePv6v0imzVL3-Zsjjoy5_">https://www.monotostereo.info/</a></span></p><p class="c1"><span class="c0">&ldquo;Helped me find not only tools but also other resources like research papers, etc on audio source separation in general. A fantastic resource for anyone into audio source separation&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">DnR</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c6">Divide and Remaster v3: Multilingual Validation &amp; Test Set</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/records/12658755&amp;sa=D&amp;source=editors&amp;ust=1765035744641198&amp;usg=AOvVaw3rwuWrmGm6IfFpGp3UPzCR">https://zenodo.org/records/12658755</a></span></p><p class="c1"><span class="c0">&ldquo;but there are a bunch of other versions of v3 for specific languages, I&#39;m not sure what is the difference.</span></p><p class="c1"><span class="c0">There are separate versions for English, Spanish, French, etc.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/communities/opencass/records?q%3D%26l%3Dlist%26p%3D1%26s%3D10%26sort%3Dnewest%3D&amp;sa=D&amp;source=editors&amp;ust=1765035744641817&amp;usg=AOvVaw1a-yEpmgEFewetxIxUCzW5">https://zenodo.org/communities/opencass/records?q=&amp;l=list&amp;p=1&amp;s=10&amp;sort=newest=</a></span><span class="c0">&rdquo;</span></p><p class="c1"><span class="c0">In fact, you can train on validation too, but it&rsquo;s not necessary anymore as the dataset was published already:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/kwatcharasupat/divide-and-remaster-v3/wiki/Getting-the-Dataset&amp;sa=D&amp;source=editors&amp;ust=1765035744642324&amp;usg=AOvVaw06lMuGmcCwrqA4SqGpXWX1">https://github.com/kwatcharasupat/divide-and-remaster-v3/wiki/Getting-the-Dataset</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Rhythm and lead guitar</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.mrtabs.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744642661&amp;usg=AOvVaw3SzaC7VYFMFDvZjgMT9cZ2">https://www.mrtabs.com/</a></span></p><p class="c1"><span class="c0">&ldquo;He has isolated tracks for his videos that he makes, and it&#39;s free (or he does not know how to properly Patreon lock certain content on his website).</span></p><p class="c1"><span class="c0">You can navigate to any tab page and look for the header: &quot;Isolated TRACKS (mp3)&quot; and find the textbox below where it says:</span></p><p class="c1"><span class="c0">&quot;Please sign up on Patreon, or if you are already a member, please login.&quot;</span></p><p class="c1"><span class="c0">The last word links to a Patreon signup page, and if you sign in, it does not check if you are subscribed to his Patreon or not, it will give you access regardless.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Boom! Now you have access to 250+ Lead and rhythm guitar pairs. There is a goldmine worth of metal stuff in there too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">This is probably the closes we could ever get to having a contemporary rhythm/lead guitar dataset that is both relatively large, the rhythm and lead has their own tracks, its diverse, and actually includes songs that we like/listen to.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Only problem is all of them are exported in mp3 with a cutoff of 16khz, so it is equivalent 128 kbps, and the denoising that was done in post is pretty lazy.</span></p><p class="c1"><span class="c0">However, I think if these parts are upscaled with FlashSR it would be great.</span></p><p class="c1"><span class="c0">Or maybe Re-Amp a low pass filter version of the stems with the Ampltibe 5 presets that he also attaches to all tabs, and ensemble the remaining frequencies that way.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I personally would not recommend using the drum and bass stems, only the guitar parts, since the drum and bass are both programmed and are uniform.</span></p><p class="c1"><span class="c0">The tone for every video is unique and tone matched to their respective albums and tracks. Even if it&#39;s not dead on, it&#39;s better than trying to use some yayhoos guitar doodles that uses the same amp/cabinet/simulator for every track.&rdquo; Vinctekan</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ernhu</span></p><p class="c1"><span class="c0">[China traditional music instrument dataset]</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/records/8012071&amp;sa=D&amp;source=editors&amp;ust=1765035744646164&amp;usg=AOvVaw26hkqjt0BUim2S2oHyDlR2">https://zenodo.org/records/8012071</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Instrumentals/vocals/stems</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Metal genre dataset</span></p><p class="c1"><span class="c0">Contact @33meskvlla33 (iirc 2K unique songs)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Here is a smaller version of the metal dataset + the validation dataset (there is also not metal in there, but lots of the data is metal oriented)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">302 vocals + 802 instrumentals</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1TlY1FXP54sVA9T0Kfq0oOXJXq03czxrv?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035744647391&amp;usg=AOvVaw2Sg4yCcE9NI76Nz1mfWpsF">https://drive.google.com/drive/folders/1TlY1FXP54sVA9T0Kfq0oOXJXq03czxrv?usp=drive_link</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If anybody wants to train an instrumental/vocal model on metal, this can get you started (I&#39;m severely limited by my hardware).</span></p><p class="c1"><span class="c0">A lot of the instrumentals are official instrumental versions of albums</span></p><p class="c1"><span class="c0">the stuff with my username is from my stempacks except for Omega Virus, Behold the Void and Rings of Saturn (IDK why I named these with that xd)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Index of ~7,5K songs in multitracks in the wild - 13.03.2023 (updated link above)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://krakenfiles.com/view/XiDE82aLOR/file.html&amp;sa=D&amp;source=editors&amp;ust=1765035744648449&amp;usg=AOvVaw35CWjxrgtKw4EthIaXENse">https://krakenfiles.com/view/XiDE82aLOR/file.html</a></span></p><p class="c1"><span class="c0">No download links. Probably some will be available around the net if you search well.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Here&rsquo;s a magnet link with some stems:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://web.archive.org/web/20200606113408/https://pastebin.com/6bZtpvur&amp;sa=D&amp;source=editors&amp;ust=1765035744648991&amp;usg=AOvVaw2smXtkcn2cowEDRSpQMa-r">https://web.archive.org/web/20200606113408/https://pastebin.com/6bZtpvur</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;From the 90s hit maker Moby himself, 500 multitracks (unreleased songs, copyright free):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mobygratis.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744649369&amp;usg=AOvVaw3WGPELDJX_txWqphw3pOy5">https://mobygratis.com/</a></span><span class="c0">&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Official accapellas, instrumentals and stems</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://infinity101.wolf.usbx.me/filebrowser/share/Q9HHlUB6&amp;sa=D&amp;source=editors&amp;ust=1765035744649729&amp;usg=AOvVaw2n7GxNuP9Kpn8M_jHyFgYM">https://infinity101.wolf.usbx.me/filebrowser/share/Q9HHlUB6</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;beatmania the rhythm game makes charts very interestingly because they are all keysounded, but what&#39;s interesting is that someone made a chart to reaper project converter</span></p><p class="c1"><span>and essentially it just gives you stems. I think people could probably export a shit ton of electronic stems and improve models because there are a LOT of bms charts&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1286052299931652106/1368998765507252254&amp;sa=D&amp;source=editors&amp;ust=1765035744650475&amp;usg=AOvVaw0wEvkqqWTmiQ_Ebmo3rS5x">src</a></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://songstems.net&amp;sa=D&amp;source=editors&amp;ust=1765035744650610&amp;usg=AOvVaw16EY6bcXoqL6a-7Nh_JasH">Songstems.net</a></span><span class="c0">&nbsp;Telegram group where you might find some music stems</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://t.me/%2BmrluHEcfixwwNzRk&amp;sa=D&amp;source=editors&amp;ust=1765035744650834&amp;usg=AOvVaw3lCBDGDh8yuHV9jinfLAVB">https://t.me/+mrluHEcfixwwNzRk</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Lots of instrumentals (sometimes with backing vocals) - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://warnermusic.disco.ac/playlist-new/13287836?date%3D20230412%26user_id%3D871447%26signature%3DWiCwv1XExpGMH98TrQ9f9HKdK7M%253Ab6EnfZ2f&amp;sa=D&amp;source=editors&amp;ust=1765035744651164&amp;usg=AOvVaw3TpFZs7jSm3uGkxOFJ9BxG">click</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- The Spheres Dataset</span></p><p class="c1"><span class="c0">(orchestral)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/records/17347681&amp;sa=D&amp;source=editors&amp;ust=1765035744651599&amp;usg=AOvVaw3g6UzrW14PI2Sk7iReeAur">https://zenodo.org/records/17347681</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_______</span></p><p class="c1"><span>For more links, check </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/773763762887852072&amp;sa=D&amp;source=editors&amp;ust=1765035744651928&amp;usg=AOvVaw3QmIXfh1qqMw8UUTp0eEq8">#resources</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1286052299931652106&amp;sa=D&amp;source=editors&amp;ust=1765035744652050&amp;usg=AOvVaw0j4jVIPG0Z7hQaZz7kiWnw">#datasets</a></span><span>&nbsp;and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/40&amp;sa=D&amp;source=editors&amp;ust=1765035744652171&amp;usg=AOvVaw3euJBuDVq1TsCbc1pUEbzo">Post dataset</a></span><span class="c0">&nbsp;(you may encounter duplicates)</span></p><p class="c1"><span class="c0">____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h2 class="c29 c27" id="h.5haztbxg91rt"><span>List of </span><span class="c42 c15 c22 c46 c30">cloud services with a lot of space </span></h2><h2 class="c29 c27" id="h.h1njxoe7uas4"><span>or for temporary storage</span></h2><p class="c1"><span class="c0">Unlimited</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://filegarden.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744652816&amp;usg=AOvVaw1hXZkJMocfix9I-ugt58Cs">https://filegarden.com/</a></span></p><p class="c1"><span>No info on any limits, URL shortener, browser bar player, open </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/filegarden&amp;sa=D&amp;source=editors&amp;ust=1765035744653047&amp;usg=AOvVaw2DlR6MliizuiBqXy-2iox-">source</a></span><span>, registration required.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unlimited</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.gg/&amp;sa=D&amp;source=editors&amp;ust=1765035744653293&amp;usg=AOvVaw2ObaEyKx8KVjVfTLyGa_5Q">https://imgur.gg/</a></span></p><p class="c1"><span class="c0">500MB/file and 5GB/file for registered users, no expiration, no registration required.</span></p><p class="c1"><span class="c0">Audio files previewing. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Unlimited<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://krakenfiles.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744653710&amp;usg=AOvVaw3zgGfzzI1Psm1dBxwPJSfD">https://krakenfiles.com/</a></span></p><p class="c1"><span>1GB/file and 5GB/file for premium users, no registration required.<br>Audio files previewing. <br>You can accidentally download a virus without having any adblocker, esp. on iOS - be aware (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1337956279624274022&amp;sa=D&amp;source=editors&amp;ust=1765035744654180&amp;usg=AOvVaw1kHuEXzo3Whf6t3-c_wyf6">example</a></span><span>).<br><br>Unlimited<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pillows.su/&amp;sa=D&amp;source=editors&amp;ust=1765035744654288&amp;usg=AOvVaw1PPQLFzrRqD5ZosPk0A6E4">https://pillows.su/</a></span></p><p class="c1"><span class="c0">200MB/file and 500MB/file for registered</span></p><p class="c1"><span class="c0">Perhaps not the best solution out of all. &ldquo;It had issues during December and January 2025&rdquo; it might have a problem with uploading not working randomly. Even in August 2025 someone had issues with accessing pillowcase uploads.</span></p><p class="c1"><span class="c0">Only for audio files (also zip for registered users) - allows playing audio files, shows spectrograms. I&rsquo;ve met with a case when some files uploaded one by one couldn&rsquo;t be played or downloaded (HTTP 500 error) at least after some period. &nbsp;For at least 503 error, it was enough to reload on a page the error appeared on to start the download.</span></p><p class="c1"><span>(formerly </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://pillowcase.su&amp;sa=D&amp;source=editors&amp;ust=1765035744655415&amp;usg=AOvVaw15pPgeW2tuaRuAw4kAjO9A">pillowcase.su</a></span><span>, thx Nick088</span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">?Unlimited</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://vocaroo.com/upload&amp;sa=D&amp;source=editors&amp;ust=1765035744655715&amp;usg=AOvVaw2qi1Nr-CmSwDLFmJE0TyZV">https://vocaroo.com/upload</a></span></p><p class="c1"><span class="c0">Not sure on file size limit or expiration</span></p><p class="c1"><span class="c0">For audio files only, no registration option</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unlimited</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://buzzheavier.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744656189&amp;usg=AOvVaw26sMXjn4Fb6vS3BicKGiTu">https://buzzheavier.com/</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span>(mirrors: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://trashbytes.net/&amp;sa=D&amp;source=editors&amp;ust=1765035744656340&amp;usg=AOvVaw3Ui89EwlvHJWZOTE4s7l1T">https://trashbytes.net/</a></span><span>&nbsp;/ </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://flashbang.sh/&amp;sa=D&amp;source=editors&amp;ust=1765035744656441&amp;usg=AOvVaw1TrdgAshaIeH7ugDNFrrlD">https://flashbang.sh/</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">Files kept &ldquo;forever&rdquo;. Almost 600 Mbit/s of upload speed.<br>It optionally creates not only download link, but also torrent file and seeds it. Optional expiration (with also &ldquo;never&rdquo;). &ldquo;The owner doesn&#39;t give a damn about DMCA.&rdquo; On unstable connections, it might break the download in the middle, forcing to start from scratch. Then you must refrain from using the connection during the download, or potentially using Free Download Manager might fix the issue too. Be aware that first download click on the site redirects you to advertisement without uBlock Origin, and it might lead to starting downloading malicious files instead. Also, uploading stops on 0% from certain hosts.<br>No audio previewing.<br></span></p><p class="c1"><span class="c0">Unlimited </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://qiwi.gg/&amp;sa=D&amp;source=editors&amp;ust=1765035744657706&amp;usg=AOvVaw1Vjooyr3-_kQHO-UMyoWBM">https://qiwi.gg/</a></span></p><p class="c1"><span class="c0">(at least any info about limits in the account panel cannot be found)<br>Registration required</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unlimited</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pd.heracle.net/drive&amp;sa=D&amp;source=editors&amp;ust=1765035744658146&amp;usg=AOvVaw1LHuIeyw1vvPE1Zmyo6f7j">https://pd.heracle.net/drive</a></span><span class="c0"><br>No file size limit (999TB Storage). No download speed limit. </span></p><p class="c1"><span class="c0">Slow upload (around 5 Mbit/s), registration required. Unlimited file size upload and storage space.</span></p><p class="c1 c7"><span class="c0"><br></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Expiring/temporary or problematic</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Unlimited</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://catbox.moe/&amp;sa=D&amp;source=editors&amp;ust=1765035744658817&amp;usg=AOvVaw1TGZ1QVA2FSDbnTgPtv7cZ">https://catbox.moe/</a></span></p><p class="c1"><span class="c0">200MB max file size,</span></p><p class="c1"><span class="c0">files kept forever, donations.</span></p><p class="c1"><span>Don&rsquo;t use it. Some providers block the site and its subdomains: &ldquo;litter.catbox.moe&rdquo; (domain for downloading files uploaded with litterbox.catbox.moe), and litterbox.catbox.moe (expiring, with up to 1GB file limit) and e.g. not everyone on our server are able to download files from there. Also, not all VPNs work with it. Possible issues: SSL errors, DNS block (then using 108.181.20.36 might work) or IP block (then use VPN, but same issues may occur at times), timeouts, also be aware that deleted files by users or which already went offline have weird old school &ldquo;404 Not Found nginx/1.18.0 (Ubuntu)&quot; which might be misleading that there&rsquo;s something wrong with their provider, but it&rsquo;s just a file being offline. Countries blocking the site: Australia, UK, Ireland, Afghanistan, Iran. Providers: Verizon, Spectrum, Rogers, Quad9 DNS, Comcast/Comcast Business. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://catbox.moe/faq.php&amp;sa=D&amp;source=editors&amp;ust=1765035744660341&amp;usg=AOvVaw29MVyE25yrcPvms15KvQ-Z">More</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unlimited</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://transfer.it/&amp;sa=D&amp;source=editors&amp;ust=1765035744660651&amp;usg=AOvVaw1hg-tCyxVtLCwi9sJQRZlH">https://transfer.it/</a></span></p><p class="c1"><span class="c0">No file size limit, up to 90 days expiration<br>&ldquo;New file upload service hosted by MEGA&rdquo;, no account required, MEGA opt. integration</span></p><p class="c1"><span><br>8 minutes/25MB for free, 5 hours/250MB for pro accounts<br>For audio files only, it compresses all non-mp3 files to mp3 320kbps (mp3s remain untouched). Files uploaded without an account expire after 24 hours.<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://whyp.it/&amp;sa=D&amp;source=editors&amp;ust=1765035744661536&amp;usg=AOvVaw1hJRDo9tjnLy8NR7l_fxPy">https://whyp.it/</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">2GB max file size, free, expiring up to 7 days (or paid), now requires email</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://wetransfer.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744661977&amp;usg=AOvVaw3KD0rdBG429OZDmGfg0Ilh">https://wetransfer.com/</a></span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">2,5GB max file size, free, no account, expiring</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://send.vis.ee/&amp;sa=D&amp;source=editors&amp;ust=1765035744662290&amp;usg=AOvVaw1TmkipiX4AwQZT2TS0UzUL">https://send.vis.ee/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5GB max file size/storage</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.sendgb.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744662535&amp;usg=AOvVaw0nwZ48RBMoLRCWO8gQA3gg">https://www.sendgb.com/</a></span></p><p class="c1"><span>Expiring after 1-90 days, paid 1TB storage and 500GB max file size<br><br>15 GB, expiring<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://fileditch.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744662819&amp;usg=AOvVaw0-xwVf4oOyvLYBNqPa5aXH">https://fileditch.com/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">10 GB, expiring</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://tmp.ninja/&amp;sa=D&amp;source=editors&amp;ust=1765035744663088&amp;usg=AOvVaw13Hl4ABx1a6aIT8hV94Gj0">https://tmp.ninja/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unlimited, but usually 14GB (10 day expiry date till last DL):</span></p><p class="c1"><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://gofile.io&amp;sa=D&amp;source=editors&amp;ust=1765035744663376&amp;usg=AOvVaw3DOuLm8HCqVrRpQ2mMDWmK">https://gofile.io</a></span></p><p class="c1"><span class="c6">Don&rsquo;t use it,</span></p><p class="c1"><span class="c0">as certain files, e.g. with 1GB size (at least in some cases), can be only downloaded with premium account if servers are overloaded - you can visit the link for 10 days till it expire in hope of the server being offloaded, but still not be able to download the file at all. GFY, WS.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unlimited (till their server space is full, which sadly is often the case,</span></p><p class="c1"><span class="c0">files get deleted after 6 days):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://filebin.net/&amp;sa=D&amp;source=editors&amp;ust=1765035744664312&amp;usg=AOvVaw0BuYqG_IN1nMN-Vi2lqpPv">https://filebin.net/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2TB (once you used your mobile app)</span></p><p class="c1"><span class="c0">Baidu Pan</span></p><p class="c1"><span>Users outside of China are restricted from registering, but there are ways to circumvent the issue with </span><span class="c4 c38"><a class="c3" href="https://www.google.com/url?q=https://www.infinityfolder.com/how-to-create-a-baidu-account-from-outside-china/&amp;sa=D&amp;source=editors&amp;ust=1765035744664840&amp;usg=AOvVaw3r34Vy0_ZqyOOgdFGiPUnM">Baidu Cloud</a></span><span class="c38 c56">&nbsp;or </span><span class="c4 c38"><a class="c3" href="https://www.google.com/url?q=https://www.gizdev.com/create-baidu-account-without-china-number-and-vpn/&amp;sa=D&amp;source=editors&amp;ust=1765035744664976&amp;usg=AOvVaw2UVYdz5fMKEA-xkQS5_3yt">duspeaker</a></span><span>.</span><span>&nbsp;Guides: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.baiduinenglish.com/baiduyun-pan-baidu-cloud-wangpan-disk.html&amp;sa=D&amp;source=editors&amp;ust=1765035744665106&amp;usg=AOvVaw0PGzlHVb6qBeYZjiQDh2a7">1</a></span><span>&nbsp;| </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/junh1024/junh1024-Documents/blob/master/Computers/How%2520to%2520use%2520Baidu%2520Pan.md&amp;sa=D&amp;source=editors&amp;ust=1765035744665227&amp;usg=AOvVaw3wnckpnhEHQBv-b1JTjcVo">2</a></span></p><p class="c1"><span class="c0">&ldquo;I don&#39;t recommend it, unless you pay, you&#39;re stuck with 150KB/s downloads maximum&rdquo; plus</span></p><p class="c1"><span class="c0">&ldquo;a requirement to use their app to actually download (at least if you decide to share your files)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">100GB (files expire after 21 days/50 downloads, max 6GB per file) </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://filetransfer.io&amp;sa=D&amp;source=editors&amp;ust=1765035744665870&amp;usg=AOvVaw3kgWJVxkbeaEr1gbZsmWAH">https://filetransfer.io</a></span></p><p class="c1"><span class="c0">It could mess up with filenames after downloading from direct link which was also possible [at least in the past] and could be used e.g. in Google Colab, there was some sneaky method of extracting direct links clicking on download buttons instead of sharing classic links</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">50GB without registration (up to 30 days of expiry date)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.swisstransfer.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744666593&amp;usg=AOvVaw3ACfOZfxmGh_W4gQaUR0lv">https://www.swisstransfer.com/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">50GB without registration (up to 14 days expiry date):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://dropmefiles.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744666877&amp;usg=AOvVaw31tXPl6KqUt0FiQanbb9hs">https://dropmefiles.com/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">250GB (expires 15/45 days after last download [un/reg], or never for 1TB 6$ per month)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://filelu.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744667228&amp;usg=AOvVaw2Q5_wfZPdQ7gdkFmGRvjfj">https://filelu.com/</a></span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1000GB</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.terabox.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744667445&amp;usg=AOvVaw39nNHDk_nFo1c7AqKdq3ra">https://www.terabox.com/</a></span></p><p class="c1"><span class="c0">(but I have some reports that after uploading X amount of data (it depends) they block the account and tell you to pay)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">100GB</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://degoo.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744667852&amp;usg=AOvVaw3DdnvGkfF3g4f7UTpXbMhV">https://degoo.com/</a></span></p><p class="c1"><span class="c0">(but Degoo has bots which look for DCMA content, and they close even paid accounts in such cases or even some files without any reason)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unlimited</span></p><p class="c1"><span>Depositfiles (now </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://dfiles.eu/&amp;sa=D&amp;source=editors&amp;ust=1765035744668294&amp;usg=AOvVaw37m7_vwV9j2-7S-cbx7H8v">dfiles.eu</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">10GB/file, FTP</span></p><p class="c1"><span class="c0">They exist since forever (2006) and probably didn&#39;t collapse so far due to nightmarishly slow download speeds (20 or even 50KB/s, can&#39;t remember) for at least non-Gold accounts. But links get offline there occasionally too (maybe less frequently than some other services). Registration required.</span></p><p class="c1"><span class="c0"><br>Unlimited</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://chomikuj.pl/&amp;sa=D&amp;source=editors&amp;ust=1765035744668971&amp;usg=AOvVaw2qCn21v2D5CYuzoElEAZDw">Chomikuj.pl</a></span></p><p class="c1"><span class="c0">Only 50MB of downloading for free (even for your own files)<br>Be aware that it happened in the past, that along years, among very big collection of files, someone had I think some even encrypted private files deleted, but usually only DCMAed files are taken out.<br>Since around the end of 2023, they started sending PMs to users warning about deleting some of the files on their account, moving them to special folders with deletion date. You can reupload your file after deletion date again. The same action needs to be repeated at least once a year.</span></p><p class="c1"><span class="c0">Also, the site exists since &ldquo;forever&rdquo; (2006), and didn&#39;t collapse despite many court cases, probably due to creative changes of owners from specific countries. It can be also used as public sharing disk with points of transfer for downloaded content from your disk.</span></p><p class="c1"><span class="c0"><br>Unlimited</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pixeldrain.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744670432&amp;usg=AOvVaw3w9G_bCPE3f_k_dB1fJKvj">Pixeldrain.com</a></span><span class="c0"><br>20GB/file, expiring for free accounts (4 months) or till the pro account is valid (min. 8 months?)<br>6 GB per day downloading cap for free, then it downloads with 1 MiB/s.</span></p><p class="c1"><span class="c34">Some files uploaded on Pixeldrain are only available for Pro users. <br>On some files it will just tell you that servers are overloaded, and the error will last for days, weeks even, and not let you download. So I&#39;d rather refrain from using it.</span><span>&nbsp;</span><span class="c0">I think I confused it with an issue with gofile I once had.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">How to download faster from sites like PixelDrain:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pixeldrain-bypass.cybar.xyz/&amp;sa=D&amp;source=editors&amp;ust=1765035744671928&amp;usg=AOvVaw1JRkxYAFbfF7nwqeOJCP_d">https://pixeldrain-bypass.cybar.xyz/</a></span><span class="c0"><br></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">50GB</span></p><p class="c1"><span class="c0">No registration required, 7 days expiry time for free</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://fex.net/en/&amp;sa=D&amp;source=editors&amp;ust=1765035744672257&amp;usg=AOvVaw1dnqce7m-tZV_eSbTnEN4D">https://fex.net/en/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">32GB</span></p><p class="c1"><span>(down) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.transferfile.io/&amp;sa=D&amp;source=editors&amp;ust=1765035744672489&amp;usg=AOvVaw2N4tjLNqSqnf_enCoYKRjx">https://www.transferfile.io/</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">Decentralized file hosting. If it goes down, perhaps the link can be replaced by ipfs.io</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Code/datasets/models repository sites</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744672944&amp;usg=AOvVaw04hRjcNWPBgxTqYi3KYdQP">GitHub </a></span></p><p class="c1"><span class="c0">2GB/file</span></p><p class="c1"><span class="c0">On the release page of (at least) public repositories, you can upload any files, and also bigger than directly in repositories (e.g. encrypted to avoid any problems - copyrighted content, even one music file in the repository can get taken down after some time).</span></p><p class="c1"><span class="c0">You can split your archive into parts if necessary.</span></p><p class="c1"><span>It&rsquo;s perfect to use in Colab notebooks. Very reliable and fast.<br><br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/&amp;sa=D&amp;source=editors&amp;ust=1765035744673688&amp;usg=AOvVaw06Z2XPhSVc9avWw2qbwRCC">Huggingface</a></span><span class="c0"><br>Lot of big models are stored there nowadays too. Probably there weren&rsquo;t any problems with their hosting in the past. Prob. 50GB file limit.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://zenodo.org/&amp;sa=D&amp;source=editors&amp;ust=1765035744674024&amp;usg=AOvVaw0DXUw0Def4MnPhXzLzNGt7">Zenodo</a></span></p><p class="c1"><span class="c0">We had some issues with slow downloading from there in Colabs in the past, but tons of big datasets are stored there.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Bigger popular cloud services<br>(size provided for total storage space per account)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">20 GB</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mega.nz/&amp;sa=D&amp;source=editors&amp;ust=1765035744674674&amp;usg=AOvVaw2-bzsR6gWiprwZ7H6_zQk5">mega.nz</a></span></p><p class="c1"><span class="c0">No expiry, usual DCMAs<br>One user from my other community had his whole account deleted years ago. It happened after a few file takedowns on his account before. That time he uploaded all music segments, basically assets extracted from a computer game publicly on a forum, and shortly later he was banned. It wasn&rsquo;t even arranged and ready for a normal release. Probably the publisher was snitching on him for quite some time already.</span></p><p class="c1"><span class="c0"><br>15GB<br>Google Drive<br>Big, suddenly popular files can become suddenly either offline or with some other error disappearing later during the day.<br>Also, it happened in the past that very popular, bigger files started being limited as visible only for the owner due to reaching quota. You could circumvent it by adding the file into your own GDrive (if you had enough space) - not sure if the trick still works.<br>Google reserves the right to delete the account after 2 years of inactivity. From what I&rsquo;ve found, they don&rsquo;t delete accounts which have YouTube account with at least one video uploaded (not sure if it must be online and public). I had a case few times with revoked privileges to some documents on GDoc, which were changed to private without my knowledge. Can&rsquo;t guarantee if the same cannot happen with GDrive files.<br><br>15GB</span></p><p class="c1"><span class="c0">Mediafire<br>I&rsquo;ve seen very old uploads from there.<br><br>15GB</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.4shared.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744676791&amp;usg=AOvVaw1CCJ1eSM8o-fXKeMAZ30hH">4shared.com</a></span></p><p class="c1"><span class="c0">Max 3GB of daily traffic, 30GB per month</span></p><p class="c1"><span class="c0">(Once I got my account deleted over years, maybe due to inactivity, but even if I was warned, messages were coming into Gmail spam)</span></p><p class="c1"><span class="c0"><br>15 GB</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://fileditch.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744677261&amp;usg=AOvVaw0bWJ8nS4twZLISXPPWuw7V">fileditch.com</a></span></p><p class="c1"><span class="c0">It allows sharing direct links like from FTP or GitHub when you upload file on release page where also bigger files can be uploaded vs 50MB in source files. I see 9 months old links still active from fileditch. Download can however be slow, 5 mbits, on old files that have not been accessed in 30 days.</span></p><p class="c1"><span class="c0"><br>10.2 GB</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://safe.fiery.me&amp;sa=D&amp;source=editors&amp;ust=1765035744677926&amp;usg=AOvVaw1UiJB2_UDRmUOhLVkG78Jv">safe.fiery.me</a></span></p><p class="c1"><span class="c0">I think this has no expiration, not sure</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">10GB</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://box.com&amp;sa=D&amp;source=editors&amp;ust=1765035744678248&amp;usg=AOvVaw0jKV_SQnwidVzGRoQfD_XW">https://box.com</a></span></p><p class="c1"><span class="c0">250MB file limit for free</span></p><p class="c1"><span class="c0"><br>11GB</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://disk.yandex.com/client/disk&amp;sa=D&amp;source=editors&amp;ust=1765035744678547&amp;usg=AOvVaw36quEG89HcZDcebw-ezD2N">yandex.com/client/disk</a></span></p><p class="c1"><span class="c0">At least after the war, some users started to report very slow downloads. <br>Rare DCMAs vs Mega. <br>Since 2022 difficult registration without a phone, and/or when you use public SMS receiving gate and/or VPN e.g. Russian - they can prevent you from access to a disk right after registration if they detect something suspicious during registration process, after the war they decreased max file size limit to 1GB iirc. <br>Also, there are very little means to recover your account in case your secret name miraculously get changed, and using new ISP or after long inactivity, you&rsquo;re asked for it (I had such situation in the past, and IDK how long the files are stored on inactive accounts). Attempts of using automated forms to fill for account recovery are vain (esp. if you don&rsquo;t know precise account creation dates, didn&rsquo;t use their email, etc.). Even if you&rsquo;re logged into their Disk app on the phone, you cannot change any account related information like secret question or password without being redirected to their page and having to log into the account which you forgot the secret question (or it got suspiciously changed; quite honestly - I got it changed either by them after long inactivity of around 2 years, or by some attacker [but it would require secret question]).<br></span></p><p class="c1"><span class="c0">5GB<br>OneDrive<br>MS have taken some space expansions given away for free once (some older accounts might be still bigger than that)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5GB</span></p><p class="c1"><span class="c0">Proton Drive</span></p><p class="c1"><span class="c0">End-to end encryption working also for sharing (although mega has probably the same)</span></p><p class="c1"><span class="c0"><br>2GB<br>Dropbox </span></p><p class="c1"><span class="c0">With some options to expand it for free and also with referrals</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">20GB/month</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://files.fm/&amp;sa=D&amp;source=editors&amp;ust=1765035744681370&amp;usg=AOvVaw3gu-Sx-LQEvL4JyPwdNCgl">files.fm</a></span></p><p class="c1"><span class="c0">5GB upload per file limit/5GB zip file download limit,</span></p><p class="c1"><span class="c0">information on expiring not provided (iirc possible to set manually at least);</span></p><p class="c1"><span class="c0">unregistered up to 60 days.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Temporary file uploads that expire anytime (by HV):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://litterbox.catbox.moe/&amp;sa=D&amp;source=editors&amp;ust=1765035744682314&amp;usg=AOvVaw3ztTmlZ2QDvJblz8VW81Np">https://litterbox.catbox.moe/</a></span><span class="c0">&nbsp;(don&rsquo;t confuse with catbox.moe)</span></p><p class="c1"><span class="c0">(1 GB)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pomf.lain.la&amp;sa=D&amp;source=editors&amp;ust=1765035744682534&amp;usg=AOvVaw0ySd5xjbMnJp3mMd3NJrQo">https://pomf.lain.la</a></span></p><p class="c1"><span>(512 MiB)<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cockfile.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744682676&amp;usg=AOvVaw17t87og4eL2uUpofYuK244">https://cockfile.com/</a></span></p><p class="c1"><span>(128 MiB, IK funny name, but)<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://uguu.se/&amp;sa=D&amp;source=editors&amp;ust=1765035744682830&amp;usg=AOvVaw2cZ7ystAq4n1uCwmoD3fHN">https://uguu.se/</a></span></p><p class="c1"><span class="c0">(128 MiB)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://sicp.me/&amp;sa=D&amp;source=editors&amp;ust=1765035744682991&amp;usg=AOvVaw2n1yOKOI-bFbk6dRg-DYYn">https://sicp.me/</a></span></p><p class="c1"><span class="c0">(114 MB)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.moepantsu.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744683167&amp;usg=AOvVaw15CuIUejF-tvTR3apykhvE">https://www.moepantsu.com/</a></span></p><p class="c1"><span class="c0">(128 MiB)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Hint. In the case of some free, not very well-known services which can even disappear after some longer period of time (do you remember RapidShare, copy.com, hotfile or megaupload, catshare, freakshare, uploaded.to, fileserve, share-online.biz, odsiebie, hostuje.net?) it&rsquo;s better to keep your files in more than one service (I recommend 3 copies for important data kept long), or stick to some popular big tech companies which are unlikely to disappear soon (if they don&rsquo;t take your upload down) or if another war will break out and increasing energy costs will make smaller services unprofitable like not long ago.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Paid:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">- You can get 1TB OneDrive with an .edu email</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you sign up for the Google Workspace (it was called G Suite until recently) version of Google Drive, you can get 1TB for ~$10 USD a month, but here&#39;s the thing... I have been way over 1tb for a couple of years now, and they have never charged me anymore. I am over 4tb now and have been for ~3 months, and it is still only ~$10. If you do it, just create a 1 user account and just keep filling it up until they say you need to add more users or pay more.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Well it looks like it is $12 now, but it&#39;s for 2tb and maybe that is what they change my plan to and are charging me now too&hellip; I thought there was some kind of surcharge and tax (never really paid attention to the exact amount) but guess it is just $12 + tax now...</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://workspace.google.com/pricing.html&amp;sa=D&amp;source=editors&amp;ust=1765035744685711&amp;usg=AOvVaw1TEgrreaVV-TFETZVEogzN">https://workspace.google.com/pricing.html</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It looks like they might have gotten rid of it, but it used to be $50/month for unlimited storage, but I think as long as you do what I do, I think it is probably close to unlimited for $12/month</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s pretending you&#39;re in a college and college drives have infinite storage</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I used to have one for 1-2 years, but it suddenly got removed, so it&#39;s not safe. All the files are gone too, without notice</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">BTW. For workspace you still need to have your own domain (with the possibility of changing DNS entries, so free ones are out). Yearly cost is negligible, but you have to remember about it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Also, if you have ProtonVPN on the Proton Unlimited plan, you get 500GB of storage on Proton Drive for free. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Also, Google Pixel 1 phones used to have like unlimited or at least bigger GDrive plans iirc (it was withdrawn from later Pixel phones). Some people bought these phones just for the space.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- You can get very cheap 2TB (around 16$) for a year on Google Drive in Lyres (I think they only changed it in methods of payment, not necessarily whole region), but some people say it&#39;s better to get it in Brazil due to fewer problems.</span></p><p class="c1"><span class="c0">I heard it&#39;s better to not buy it in Lyres on your main account, because your apps can get regional lock (e.g. Tidal). Some people even had problems with currency in their other accounts, and you can change it only once for a year on an account, and in case of some emergency, you might have to be forced using Revolut cards. There is a lot of misinformation about that promo trick so verify it all, but there should be some reasonable amount of info scattered around the net already (e.g. hotukdeals, pepper.pl, or the site&rsquo;s German counterpart).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- 50GB on Dropbox from some Galaxy phones (e.g. S3) can no longer be redeemed (since ~2016 I believe)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.multcloud.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744689055&amp;usg=AOvVaw0nVnlzRQ6mkShPOcZESp4l">https://www.multcloud.com/</a></span></p><p class="c1"><span class="c0">Service allowing moving files across various cloud accounts and services for free</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">____________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Pitch detection and to midi convert</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1019280811461181510&amp;sa=D&amp;source=editors&amp;ust=1765035744689731&amp;usg=AOvVaw3yhLIkyytctN9TmNWIWivQ">https://discord.com/channels/708579735583588363/708579735583588366/1019280811461181510</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_________________________________________________________________________</span></p><p class="c1"><span class="c0">(outdated)</span></p><p class="c1"><span class="c0">(for old MDX SDR 9.4 UVR model):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(input audio file on Colab can be max 44kHz and FLAC only). </span></p><p class="c1"><span class="c0">Original MDX model B was updated and to get the best instrumental - you need to download invert instrumental from Colab.</span></p><p class="c1"><span class="c0">Model A is 4 stem, so for instrumental, mix it, e.g. in Audacity without vocals stem (import all 3 tracks underneath and render). Isolation might take up to ~1 hour in Colab, but recently it takes below 20 minutes on 3.00 min+ track.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you want to use it locally (no auto inversion):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/887455924845944873/887464098844016650&amp;sa=D&amp;source=editors&amp;ust=1765035744691206&amp;usg=AOvVaw3zWO0YgSIZFpRPeDU1_INV">https://discord.com/channels/708579735583588363/887455924845944873/887464098844016650</a></span></p><p class="c1"><span class="c0">B 9.4 model: </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/releases/tag/MDX-Net&amp;sa=D&amp;source=editors&amp;ust=1765035744691502&amp;usg=AOvVaw1DlOkY8AhrFcmp5e1nqRN2">https://github.com/Anjok07/ultimatevocalremovergui/releases/tag/MDX-Net</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Or remotely (by CyberWaifu):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1R32s9M50tn_TRUGIkfnjNPYdbUvQOcfh?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744691889&amp;usg=AOvVaw3vU6X0kWe0MDFPzYplYMXP">https://colab.research.google.com/drive/1R32s9M50tn_TRUGIkfnjNPYdbUvQOcfh?usp=sharing</a></span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">Site version (currently includes 9.6 SDR model):</span></p><p class="c1"><span class="c0">https://mvsep.com/</span></p><p class="c1"><span class="c0">You can choose between MDX A or B, Spleeter 2/4/5 Stems), UnMix 2/4 stems, but output is mp3 only)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">New MDX model released by UVR team on mvsep is currently also available. If you have any problems with separating in mobile browser (file type not supported) add for a file additional extension: trackname.flac.flac.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MDX is really worth checking. Even if you have some bleeding, and UVR model cuts some instruments in the background.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">CyberWaifu Colab troubleshooting</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you have a problem with noise after a few seconds of the result files, try to use FLAC. After an unsuccessful attempt of isolation, you can try restoring default runtime to default state in options. The bug happened a few days after releasing the Colab suddenly one day and the is prevailing to this day (so WAV no longer works). If you run the first cell to upload, and afterwards after opening file view, one of the 001-00X wav files is distorted (000 after few second) it means it failed, and you need to start over till you get all the files played correctly. But after longer isolation, it may cause reaching GPU limit, and you will not be able to connect with GPU. To fix it, switch to another Google account. If you have a problem, that your stems are too long, and mixed with a different song, restore default runtime settings as well, or delete manually </span></p><p class="c1"><span class="c0">_________________________________________________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c8"><span class="c0">(outdated, deleted feature from HV Colab) Be aware that normalization turned on in Colab for instrumentals achieved with invertion may lead to occurrence of some artifacts during inversion, but general mix quality and snare in the mix might be more loud and sound more proper with normalization on, though it&rsquo;s not necessarily universal solution in every case when the track might sound a bit off than more flat sound of normalization turned off (at least in some parts of it). </span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c7 c8"><span class="c0"></span></p><h2 class="c29 c27" id="h.37hhz9rnw7s8"><span class="c42 c15 c22 c46 c30">AI-killing tracks - difficult ones to get instrumentals (or vocals) - a lot of e.g. vocal (or instrumental) leftovers in current models</span></h2><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;instrument-wise, the problematic ones I can remember are: </span></p><p class="c1"><span class="c0">alto sax, soprano sax, any type of flutes/whistles (including synths), trombone slides, duduk, some organ sounds (close to sine wave sound)&quot; plus harmonica, erhnu, theremin. </span></p><p class="c1"><span class="c0">&quot;even if some models do a bit better job than others, these instruments are still problematic because their timbres are close to [human] voice&quot;</span></p><p class="c1"><span class="c0">And in general - songs heavily sidechained, with robotic, heavily processed vocals, sometimes with lots of weird sounding overdubs where some are missed (e.g. in trap), also laughs and moans.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Anjok stated that the hardest genre for separation is metal and vocal-centered mixes. If the instrumental has a lot of noise, e.g. distorted guitars, the instrumental will come out muddier.</span></p><p class="c1"><span class="c0">Tracks from the 70-80s can separate well. The 50-60s will be harder, e.g. recorded in mono. Early stereo era gets a little better.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Open </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1umHpYbh1NzXIkoLj_7aM2tFwX5SHFMdaxJnhe75j8bA/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744697405&amp;usg=AOvVaw0qMTupoO1cks2HAFjP98tl">GSheet</a></span><span class="c0">&nbsp;with more songs for everyone with a Google account to contribute (we kinda tried not to duplicate any songs in both places too much).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instrumentals</span></p><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_t6x6ie377r4u-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Childish Gambino - Algorithm (robotic vocal effects, autotune, echoes, specific processing plugins on vocals, constant audible vocal residues for all current models)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">tatu - Not gonna get us / Nas ne dogonyat (&quot;This song is impossible to quality separate by any model. Our dataset contains several songs by this artist, but this did not improve the result in any way. Just forget about it for a few years&quot;) - IRC, the result was enhanced by slowing down, a.k.a. soprano option on x-minus.</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Eric Prydz - Call On Me (aggressive sidechain compression &ldquo;It&#39;s literally ditching the vocal part [and instruments] out to make room for the kick. So yeah, good luck in getting that vocal back.&ldquo;)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamaroquoi - Virtual Insanity (&quot;One of the most difficult challenges of all my experience has been that is not very well handled even when maxing out quality in v5.&quot;)</span></li></ul><p class="c1 c8"><span class="c0">Others:</span></p><ul class="c9 lst-kix_t6x6ie377r4u-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Beyonce - I&#39;m that girl</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Half Alive - Still feel</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Queen - White Queen</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Queen - Bohemian Rhapsody (very complicated song; mix of various vocals and guitars)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Queen - These Are The Days Of Our Lives - to evaluate BVE model and how it reacts with harmonies. If it works on this track, probably all the others will work.</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">J Dilla - Don&#39;t Cry (lots of so-called lo-fi &ldquo;cuts&rdquo; or chops of vocals from old vinyls, characteristic for hip-hop productions which are sometimes harder to separate)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Lots of Juice WRLD (his tracks have leftovers here and there, e.g. in &quot;Off the rip (Gamble)&quot;)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Eminem - No regrets (constant low-volume vocal leftovers)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Louis The Child - Better not (problem with vocals with currently the best MDX23 MVSEP beta model, and also Demucs ft and Kim model)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">A$AP Rocky - Fashion Killa (same as for &ldquo;Night Lovell - Dark Light&rdquo; - &quot;almost every AI can&#39;t separate the main vocals from the melody, the melody has a part that sounds like vocals, so just about every AI picks some of it up in the vocals section instead of the instrumental section&quot;)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Porcupine - Trees Don&#39;t Hate Me (&quot;Quiet bits, loud bits, flutes and strings, things I can&#39;t even name plus all the usual suspects, drums etc, and Steven Wilson has a crisp clean voice a lot of the time&quot;)</span></li></ul><ul class="c9 lst-kix_awlaex77cpwh-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thomas Anders - You Will Be Mine (vocal residues in instrumentals using all current models for April 2023)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Modern Talking - One in a million (also minimum vocal residues)</span></li><li class="c1 c8 c25 li-bullet-0"><span class="c0">Modern Talking - Mrs. Robota (too many synthesizer effects bleed in vocals of MVSEP MDX23 10.04.23 Ensemble [so consisting of only kim vocal 2, kim inst and Demucs 4 yet)</span></li></ul><ul class="c9 lst-kix_wrdk3q33keus-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Crush 40 - Live &amp; Learn&#39;</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">JPEGMAFIA - HAZARD DUTY PAY! (hard to get vocals from rapping section; Kim vocals 1)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Bjork - All Is Full Of Love (2:06, 2:12, 2:50 and throughout from that point, the vocals partially still bleed. <br>The song was tested on MDX Inst 3, Inst HQ_1 and 3, Inst Main, Kim Inst, HTDemucs, HTDemucs_FT and 6S, and ensembles including (Kim vocal 2, Kim Inst, Inst Main, 406, 427, HTDemucs FT) and (Kim Inst, Voc FT, Inst HQ 3)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Stray Kids - GO&#29983; (GO LIVE)</span></li><li class="c1 c25 c8 li-bullet-0"><span>Royce da 5&#39;9&quot; - I&#39;m The King (Vinyl rip</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D2fKW6q8tcVs&amp;sa=D&amp;source=editors&amp;ust=1765035744703120&amp;usg=AOvVaw3YoO9Nn-59RXjLJTH27Khc">)</a></span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Mike Mareen - Love Spy</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Bomfunk MC&#39;s - &nbsp;Freestyler</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Lasgo - Something</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_wrdk3q33keus-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">South Park - Chocolate Salty Balls (bad results with most models)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Tally Hall - Never meant to know (the almost impossible goal for now is to remove &quot;with&quot; in 2:39).</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">WWE - Demon in Your Dreams - (here&#39;s a track that sounds bad - the parts where the vocals usually are sound muffled and dull, guitars are barely audible - HQ_3, Demucs 6s tested)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Taylor Swift - Better Than Revenge (Taylor&#39;s Version) (background vocals in all models including HQ3 and voc_ft - using Dolby Atmos version, and (I think just) muting (?vocal) channel(s) helped)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Bon Jovi - I believe</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Twenty One Pilots - The Hype (&ldquo;voc_ft leaves too many perc/drums/synths [in vocals] that sounds like t&#39;s and s&#39; or just sound like vocals, and it&#39;s really annoying, also because of this nearly no other model can separate it either because they think it&#39;s part of the vocals, but it&#39;s mostly just synths, Ripple put a lot of echo into the other stem&rdquo;)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">The Weeknd - Until I Bleed Out &nbsp;(vocal stem includes a bunch of drum and synth bleeding. Tested on htdemucs_ft, VocFT, Inst HQ 3, InstVoc HQ 2, Kim 1, Kim 2, Kim inst, and ensembles (htdemucs_ft, VocFT, Inst HQ 3, InstVoc HQ 2), (Kim 2, Kim inst, Inst Main, 406, 427, htdemucs_ft) and (Kim inst, VocFT, Inst HQ 3))</span></li><li class="c1 c25 c8 li-bullet-0"><span>Travis Scott - Nightcrawler (vocal residues in 1:27, 2:24, 3:56, and 4:50 using BS-Roformer 1296 in UVR beta and overlap 2/8 - less than in other ech models though it&#39;s more muddy, though 04.24 model on MVSEP less, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/773763762887852072/1229378741226963005&amp;sa=D&amp;source=editors&amp;ust=1765035744705916&amp;usg=AOvVaw0unnbj0f2K4aZ4Von_QvqW">discussion</a></span><span class="c0">)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Shaft - Mambo Italiano </span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Yello - Oh Yeah (both Aufr33 suggestions)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">song_45_vocals in the multisong dataset have some weird effects which some models struggle with</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Black Gryph0n - Jester (Pomni&#39;s Song) (feat. Lizzie Freeman) &ldquo;the vocoded vocals in the drop of this song [are] impossible to isolate with current models either&rdquo; </span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Isabela Souza - Tu color para pintar - violin put in vocal stem in a lot of models (e.g. Bas Curtiz FT 25.10.24)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">George Michael - Amazing (Vocal bleed starting at 3:52 with zfturbo mel roformer 2024.10, residues with Dango too)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Eminem - The Warning (quite laugh residue at 0:04; instr unwa v1)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Gregory Brothers - Dudes a Beast (trumpets in vocal stem at 0:51; unwa&rsquo;s beta4 and inst v1e, fixed in Gabox voc_fv5)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">DJ Krust / Saul Williams - Coded Language (&ldquo;I can hear a light bleed of the lowcutted bassline at times&rdquo; becruily Mel)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Dayseeker - Sleeptalk (&ldquo;serious volume clipping issues throughout when removing vocals (...) I&#39;ve tried every model and several ensembles, edited UVR settings, and also tried Dango.&rdquo; - comfortable couch)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Darko - Starfire (almost everything can&#39;t remove that particular scream; shift conversion pitch method kinda did - mesk)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Meshuggah - Ayahuasca Experience</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Fredrik Thordendal&#39;s Special Defects - Vitamin K Experience (A Homage to The Scientist / John Lilly)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Culture of Fear (&ldquo;only supported by MDX Kar v2 to have an instrumental with backing vocals, all the other karaoke models/bve fail&rdquo; dca)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Inside Out &middot; Bad Suit (&ldquo;all UVR models I&#39;ve tried (all that jarredou had on his Colab) struggle with the slap bass. Slap sounds (which contains mid to high frequencies) goes into guitar stem, so that&#39;s still hard&rdquo; - 03.2025)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&ldquo;Songs that were produced at Cheiron Studios from the 90s/00s still don&#39;t isolate well</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">the mixes are so d**n complex&rdquo; - JadDeluxe</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Yello - Oh Yeah</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Duck Sauce - Barbra Streisand (Radio Edit) (sidechain is the problem I assume)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Al Bano &amp; Romina Power - Sharazan</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Billie Eilish - L&rsquo;AMOUR DE MA VIE [OVER NOW EXTENDED EDIT] (&ldquo;it seems like none of the existing models can pick up those high pitched vocals&rdquo; - black_as_night)</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c6">Complex vocals and vocoder - severe bleeding on every model tested as of 06.12.24 including Dango (dca100fb8 contributions)</span></p><p class="c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_wrdk3q33keus-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Tame Impala - One More Year</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daft Punk - Around the World </span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daft Punk - Television Rules the Nation</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daft Punk - Doin&#39; it Right</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daft Punk - Human After All</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daft Punk - Get Lucky</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daft Punk - Lose Yourself to Dance</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daft Punk - Robot Rock</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Deep Forest - Sweet Lullaby (Version 1992) (yodelling difficult to remove; BV bleed starting at ~1:21)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Radiohead - The National Anthem (vocal effects difficult to separate; LV effects bleed starting at ~1:36)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Moby - One Last Time (vocal bleed in instrumental; LV effects bleed starting at 1:39)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Air - Run</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Kodex - Do jutra (esp. at 1:30 vocals bleeding in a lot of models with low bleedless metric)</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c20">Bleeding on every model tested as for 06.12.24 incl. Dango - <br>not so severe, but containing vocal pop-ins (dca100fb8):</span><span class="c0"><br></span></p><ul class="c9 lst-kix_wrdk3q33keus-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Supersonic&quot; by Jamiroquai (BV bleed starting @~0:07)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Amazing&quot; by George Michael (BV bleed starting @~3:45)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;El lilady&quot; by Samo Zaen (BV bleed starting @~3:30)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Here Comes the Rain Again&quot; by Eurythmics (BV bleed starting @~1:17)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Sun is Shining&quot; by Bob Marley &amp; The Wailers (BV bleed starting @~1:52)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Sun is Shining (Kaya 40 Mix)&quot; by Bob Marley &amp; The Wailers (BV bleed starting @1:52)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Road to Zion&quot; by Damian Marley (BV bleed starting @~0:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Les Rubans&quot; by Daniel Masson (LV bleed starting @~2:13)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Remember&quot; by Air (BV bleed starting @~0:46 + LV bleed starting @~0:58)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Strangers&quot; by Portishead (LV bleed starting @~0:30)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Samsam (Chanson du g&eacute;n&eacute;rique)&quot; (BV bleed starting @~0:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Aicha&quot; by Khaled (BV bleed starting @~3:45)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Forest Hymn&quot; by Deep Forest (BV bleed starting @~0:33)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;33 Degree&quot; by Thievery Corporation (LV effects bleed starting @~1:44)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Run&quot; by Air (BV bleed starting @~1:08)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;An Indian Summer&quot; by Al-Pha-X (BV effects bleed starting @~3:13)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;Forest Hymn&quot; by Deep Forest (BV effects bleed starting @~0:33)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">&quot;In The Air Tonight&quot; by Phil Collins (LV effects bleed starting @~3:03)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Goldfrapp - Utopia (BV bleed starting @~0:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Depeche Mode - Sacred (BV bleed starting @~0:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Seal - Love&#39;s Divine (BV bleed starting @~3:26)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Da Lata - Alice (No Pais Da Malandragem) (LV or BV bleeding at a different time with each model)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">ABBA - Gimme! Gimme! Gimme! (A Man After Midnight) (BV bleed starting @1:22)</span></li><li class="c1 c25 c8 li-bullet-0"><span>311 - Beyond the Gray Sky (LV effects bleed @~1:24)</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Vocal bleed in instrumentals using MVSEP MelRoformer 2024.10 model which Dango fixes (dca100fb8)</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">- &quot;For You&quot; by Coldplay (BV bleed starting @1:32 --&gt; v1e, Kim Mel or even Dango doesn&#39;t have this issue)</span></p><p class="c1 c8"><span class="c0">- &quot;L&#39;&eacute;t&eacute; indien&quot; by Joe Dassin (BV bleed starting @0:24 --&gt; v1e or Dango fixes the problem)</span></p><p class="c1 c8"><span class="c0">- &quot;Porcelain&quot; by Moby (LV bleed starting @2:10 --&gt; Dango and SCNet XL high fullness models on MVSEP fix the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Night Bird&quot; (from &quot;Essence of the Forest&quot; album) by Deep Forest (BV bleed starting @0:28 &nbsp;--&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Desert Walk&quot; (from &quot;Essence of the Forest&quot; album) by Deep Forest (BV bleed starting @0:03 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Desert Walk (Version 1992)&quot; by Deep Forest (BV bleed starting @0:07 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Love Is Gone (Fred Riester &amp; Joachim Garraud Radio Edit Remix)&quot; by David Guetta (BV bleed starting @0:49 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Attention Mesdames et Messieurs&quot; by Michel Fugain &amp; Le Big Bazar (BV bleed starting @0:50 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Everything In Its Right Place&quot; by Radiohead (BV bleed starting @0:52 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Sweet Dreams (Are Made Of This)&quot; by Eurythmics (BV bleed starting @0:48 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Lebanese Blonde&quot; by Thievery Corporation (BV bleed starting @0:52 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Lift Me Up&quot; by Moby (LV chops starting @2:45 --&gt; Dango fixes the problem)</span></p><p class="c1 c8"><span class="c0">- U.S.A. for Africa - We Are The World (BV bleed starting @5:34, fixed using v1e)</span></p><p class="c1 c8"><span class="c0">- Led Zeppelin - Kashmir (LV bleed starting @2:16, fixed using v1e)</span></p><p class="c1 c8"><span class="c0">- Jamiroquai - White Knuckle Ride (LV bleed starting @0:15, fixed using v1e)<br></span></p><p class="c1 c62"><span>Duplicates from the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1umHpYbh1NzXIkoLj_7aM2tFwX5SHFMdaxJnhe75j8bA/edit?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744719333&amp;usg=AOvVaw1oBrJGKr0jT2Z46txD2PWT">GSheet</a></span></p><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_t6x6ie377r4u-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Moby - Porcelain (in Gsheet; in instrumental, vocal reverb bleeding at 1:00, and bleed at 2:10/20, all good MDX models, GSEP, MDX23 by ZFTurbo tested, still getting more or less the same results, Dango and SCNet XL fixes the issue)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Queen - March Of The Black Queen (always causes issues, the best result on Full Band 8K FFT, as for 06.08.23, but still lot of BV is missed)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Night Lovell - Dark Light (&quot;almost every AI can&#39;t separate the main vocals from the melody, the melody has a part that sounds like vocals, so just about every AI picks some of it up in the vocals section instead of the instrumental section&quot;)</span></li></ul><ul class="c9 lst-kix_wrdk3q33keus-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Bob Marley - Sun is Shining (all current models bleed in the same timestamps: 1:02, 1:42, 1:54, 1:57, 2:50)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daft Punk - Give back life to music (problem with vocoder in the vocals rendering bad instrumental results)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daft Punk - Within (robotic voices)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Frank Ocean - White Ferrari</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">List of songs where all the current Mel-Roformer instrumental models fail in recognizing some instruments correctly in the instrumental track (they mainly struggle with sax and harmonica), whereas not the case with SCNet XL except for talkbox, theremin and erhu (SCNet still fail at it for these) by dca100fb8</span></p><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_hc732m8hksyq-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Cowboy Junkies - I Don&#39;t Get It (harmonica picked up in vocal, starting @00:12)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Pink Floyd - Shine On You Crazy Diamond (Parts I-V) (saxophone picked up in vocal, starting @11:09)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Travis - Sing (FX picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Revolution Solution (FX picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Safar (The Journey) (instrument picked up in vocal, starting @00:02)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Samsam Song (International Version) (flute picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Portishead - Humming (FX and theremin picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Asian Dub Foundation - Tu Meri (instrument picked up in vocal, starting @02:33)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Goldfrapp - Horse Tears (organ picked up in vocal, starting @00:00 + elec guitar @01:28 + talkbox @01:22)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Goldfrapp - Lovely Head (talkbox picked up in vocal, starting @01:15)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Goldfrapp - Pilots (talkbox picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Moby - Lift Me Up (synth picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Phil Collins - In The Air Tonight (elec guitar picked up in vocal, starting @02:10)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Pink Floyd - Money (saxophone picked up in vocal, starting @02:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Radio Retaliation (FX picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thierry David - Huong Vietnam (erhu picked up in vocal, starting @00:35)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Supertramp - The Logical Song (saxophone picked up in vocal, starting @01:52)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Supertramp - School (harmonica picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Archive - Again (harmonica picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Deep Forest - Desert Walk (Version 1992) (flute picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Deep Forest - Dignity (elec guitar picked up in vocal, starting @00:36)</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Vocal bleeding not existing on MVSEP&rsquo;s SCNet XL high fullness vs Roformers</span></p><ul class="c9 lst-kix_hc732m8hksyq-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Tame Impala - On Track</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">You can visit our </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1020514529601409084&amp;sa=D&amp;source=editors&amp;ust=1765035744725809&amp;usg=AOvVaw0rgtJuA-TUqNypb9rKkNjF">#request-separation</a></span><span class="c20">&nbsp;channel to look for some interesting cases of people seeking help with some specific songs they struggle with and a new </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1325284456382075041&amp;sa=D&amp;source=editors&amp;ust=1765035744726208&amp;usg=AOvVaw1dnfzWnTg9_4oyxGXnmk-q">#your-bad-results</a></span><span class="c6">&nbsp;channel.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1"><span class="c0">Songs to compare weaker vs more effective models in instrumentals (e.g. inst 464/Kim inst or HQ_2/3 or 4 vs all others)</span></p><p class="c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_t6x6ie377r4u-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">O.S.T.R. - Incognito (non Snap Jazz version) (lo-fi Polish hip-hop with constant vocal leftovers in all models and AIs except MDX-UVR inst 1-3, main where inst 3/464 performs the best, it&rsquo;s also good to test an influence of various chunks settings at 1:53. Publicly available songs for datasets usually don&#39;t include hip-hop at all, especially not from some low, weird sounding languages with loud, bassy, over processed voices. In Snap Jazz version also in 464 there are e.g. less vocal residues than on GSEP - still slightly hearable).</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Kaz Ba&#322;agane - Stara Bida (constant vocal leftovers in all models and AIs except MDX-UVR inst 1-3 and inst main where inst 3/464 performs the best [good to test weaker models or specific epochs], flute from 1:11 gets deleted on MDX-UVR HQ models).</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">The Weeknd - Hardest To Love (htdemucs_ft did well here).</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">NNFOF - Je&#347;li masz nier&oacute;wno pod sufitem (all MDX-UVR instrumental models will filter out inconsistently flute from the track, while GSEP handles that song well - it happens for all kinds of songs containing flute and oriental instruments in these models)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Ace of Base songs (&ldquo;any of them have those flute-ish synthetic instruments which have always been a nightmare in terms of getting a flawless a cappella&rdquo;).</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">R&oacute;&#380;ewicz Interpretacje (Sok&oacute;&#322;) - Wicher (very deep and low rap voices cause problems with weaker models, e.g. original MDX23 on mvsep1.ru (now MVSEP.com)/ZFTurbo MDX23 Colab; you can also try out also Sok&oacute;&#322; - Nic and Sok&oacute;&#322; - Wojtek Sok&oacute;&#322; albums)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Chaos (O.S.T.R., Hades) - Powstrzyma&#263; Ci&#281; (lots of bleeding in e.g. MDX23 model on MVSEP in 2:00. Not that much in Kim inst)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">DJ Skee &amp; The Game (from 2012 mixtape) or Tyler the Creator (album version from 2011) - Yonkers (same beat prod. by Tyler the Creator) </span></li></ul><p class="c1 c8"><span class="c0">(the first is from mixtape with more cuts/vocal chops difficult to get rid of. HQ models usually confuse vocal chops with vocals, but here it might be useful)</span></p><ul class="c9 lst-kix_t6x6ie377r4u-0"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Avantasia - The Scarecrow (HQ3 generally has problems with (here bowed) strings. mdx_extra from Demucs 3 had better result, sometimes 6s model can be good compensation for these lost instruments)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Static Major - CEO (if someone wants to test out isolation of many vocal layers using e.g. Melodyne)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">oikakeru yume no saki de - sumikeke (here vocal layers extraction Karaoke models and Melodyne fail)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Dizzy Wright - No Writer Block (hard track to keep hi-hats consistent throughout the whole output with even some snares - it can all get easily washed out, also more vocal leftovers in MDX23C ensemble on MVSEP1.ru vs MDX23 2.1 Colab [despite better SDR], not bad GSEP result, but it makes hi-hats like a bit out of rhythm probably due to some built-in processing in GSEP)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Dariacore - will work for food (generally that whole Dariacore album can be tasking due to its loudness and &ldquo;craziness&rdquo;)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Centrala Katowice - Reprezentowice (first version of GSEP in 192kbps was consistently failing in picking up vocals and also leaving strong vocal residues)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Cher - The Music&#39;s No Good Without You (&ldquo;there is progress on removing Cher&#39;s vocals. Previously, this song was an AI killer, but the mel-rofomer model removes the vocals almost completely (...) Removing vocals from &quot;Believe&quot; is no problem either.&rdquo; Aufr33)</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1"><span class="c0">A list of songs which have vocal bleed in the instrumental using unwa&#39;s v1e model<br>&ldquo;These songs also present issues after using Mel 2024.10 and BS 2024.08 from MVSEP, but the timestamps where the bleed occurs might be different&rdquo; plus Mel 2024.10 model might have less of these residues by dca100fb8</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">- &quot;Supersonic&quot; by Jamiroquai (BV bleed starting @0:07)</span></p><p class="c1 c8"><span class="c0">- &quot;Amazing&quot; by George Michael (BV bleed starting @3:45)</span></p><p class="c1 c8"><span class="c0">- &quot;Here Comes the Rain Again&quot; by Eurythmics (BV bleed starting @1:17)</span></p><p class="c1 c8"><span class="c0">- &quot;Porcelain&quot; by Moby (LV bleed starting @1:00 --&gt; Dango and SCNet XL fix the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Sun is Shining&quot; by Bob Marley &amp; The Wailers (BV bleed starting @1:52)</span></p><p class="c1 c8"><span class="c0">- &quot;Sun is Shining (Kaya 40 Mix)&quot; by Bob Marley &amp; The Wailers (BV bleed starting @1:52)</span></p><p class="c1 c8"><span class="c0">- &quot;Give Life Back to Music&quot; by Daft Punk (LV bleed starting @0:49 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Road to Zion&quot; by Damian Marley (BV bleed starting @0:00)</span></p><p class="c1 c8"><span class="c0">- &quot;El lilady&quot; by Samo Zaen (BV bleed starting @3:30)</span></p><p class="c1 c8"><span class="c0">- &quot;Night Bird&quot; (from &quot;Essence of the Forest&quot; album) by Deep Forest (BV bleed starting @1:12 &nbsp;--&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Desert Walk&quot; (from &quot;Essence of the Forest&quot; album) by Deep Forest (BV bleed starting @0:44 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Desert Walk (Version 1992)&quot; by Deep Forest (BV bleed starting @0:18 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Love Is Gone (Fred Riester &amp; Joachim Garraud Radio Edit Remix)&quot; by David Guetta (BV bleed starting @1:15 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Attention Mesdames et Messieurs&quot; by Michel Fugain &amp; Le Big Bazar (BV bleed starting @0:50 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Strangers&quot; by Portishead (LV bleed starting @0:30)</span></p><p class="c1 c8"><span class="c0">- &quot;Everything In Its Right Place&quot; by Radiohead (BV bleed starting @3:28 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;The National Anthem&quot; by Radiohead (LV effects bleed starting @1:36)</span></p><p class="c1 c8"><span class="c0">- &quot;Samsam (Chanson du g&eacute;n&eacute;rique)&quot; (BV bleed starting @0:00)</span></p><p class="c1 c8"><span class="c0">- &quot;33 Degree&quot; by Thievery Corporation (LV effects bleed starting @1:42)</span></p><p class="c1 c8"><span class="c0">- &quot;Sweet Dreams (Are Made Of This)&quot; by Eurythmics (BV bleed starting @0:48 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Sweet Lullaby (Version 1992)&quot; by Deep Forest (BV bleed starting @1:21)</span></p><p class="c1 c8"><span class="c0">- &quot;Lebanese Blonde&quot; by Thievery Corporation (BV bleed starting @0:52 --&gt; Dango fixes the issue)</span></p><p class="c1 c8"><span class="c0">- &quot;Forest Hymn&quot; by Deep Forest (BV bleed starting @0:33)</span></p><p class="c1 c8"><span class="c0">- &quot;Aicha&quot; by Khaled (BV bleed starting @3:45)</span></p><p class="c1 c8"><span class="c0">- &quot;Run&quot; by Air (BV bleed starting @1:08)</span></p><p class="c1 c8"><span class="c0">- &quot;Remember&quot; by Air (LV bleed starting @0:31)</span></p><p class="c1 c8"><span class="c0">- &quot;Doin&#39; it Right&quot; by Daft Punk (LV bleed starting @1:21)</span></p><p class="c1 c8"><span class="c0">- &quot;Human After All&quot; by Daft Punk (LV bleed starting @0:49)</span></p><p class="c1 c8"><span class="c0">- &quot;Get Lucky&quot; by Daft Punk (BV bleed starting @4:06)</span></p><p class="c1 c8"><span class="c0">- &quot;Lose Yourself to Dance&quot; by Daft Punk (BV bleed starting @1:55)</span></p><p class="c1 c8"><span class="c0">- &quot;Robot Rock&quot; by Daft Punk (LV bleed starting @1:02)</span></p><p class="c1 c8"><span class="c0">- &quot;J&#39;ai demand&eacute; &agrave; la lune&quot; by Indochine (BV bleed starting @1:45)</span></p><p class="c1 c8"><span class="c0">- &quot;Hey Jude&quot; by The Beatles (LV bleed starting @0:00)</span></p><p class="c1 c8"><span class="c0">- &quot;Within&quot; by Daft Punk (LV bleed starting @1:42)</span></p><p class="c1 c8"><span class="c0">- &quot;Lift Me Up&quot; by Moby (LV chops starting @2:45)</span></p><p class="c1 c8"><span class="c0">- &quot;Nothing Else&quot; by Archive (LV effect bleed starting @1:13)</span></p><p class="c1 c8"><span class="c0">- &quot;One More Year&quot; by Tame Impala (BV bleed starting @1:03)</span></p><p class="c1 c8"><span class="c0">- &quot;Around the World&quot; by Daft Punk (LV bleed starting @3:57)</span></p><p class="c1 c8"><span class="c0">- &quot;Television Rules the Nation&quot; by Daft Punk (LV bleed starting @1:49)</span></p><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1"><span class="c0">List of songs which have important crossbleeding of vocals in instrumental using &quot;basic&quot; SCNet XL model from mvsep (don&rsquo;t confuse with undertrained SCNet XL on ZFTurbo GitHub) by dca100fb8</span></p><p class="c1"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><ul class="c9 lst-kix_6m4qu83yomn7-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Where It All Starts (crossbleeding starting @0:15)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Le Monde (crossbleeding starting @0:02)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Lebanese Blonde (crossbleeding starting @0:52)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Canned Heat (crossbleeding starting @0:56)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Black Crow (crossbleeding starting @0:55)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Supersonic (crossbleeding starting @0:07)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Andru Donalds - Mishale (crossbleeding starting @0:50)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Moby - Porcelain (crossbleeding starting @2:10)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">George Michael - Amazing (crossbleeding starting @0:28)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Samo Zaen - El lilady (crossbleeding staerting @3:30)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Zero 7 - In The Waiting Line (crossbleeding starting @0:48)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Coldplay - For You (crossbleeding starting @1:33)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Kool &amp; The Gang - Fresh (Single Version) (crossbleeding starting @0:51)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Kool &amp; The Gang - Too Hot (Single Version) (crossbleeding starting @1:07)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Khaled - Aicha (crossbleeding starting @3:22)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Keane - Put The Radio On (crossbleeding starting @1:30)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Nelly Furtado - Say It Right (crossbleeding starting @0:23)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Black Sabbath - Planet Caravan (crossbleeding starting @0:10)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Groundation - Smile (crossbleeding starting @0:10)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Eurythmics - Here Comes the Rain Again (crossbleeding starting @1:23)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Damian Marley - Road to Zion (crossbleeding starting @0:10)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">David Guetta - Love Is Gone (Fred Riester &amp; Joachim Garraud Radio Edit Remix) (crossbleeding starting @1:15)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Indochine - J&#39;ai demand&eacute; &agrave; la lune (crossbleeding starting @1:47)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Bob Marley &amp; The Wailers - Sun is Shining (crossbleeding starting @1:53)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Morcheeba - Blindfold (crossbleeding starting @0:53)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daniel Masson - Les Rubans (crossbleeding starting @2:13)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Depeche Mode - Sacred (crossbleeding starting @0:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Goldfrapp - Utopia (crossbleeding starting @0:11)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Da Lata - Alice (No Pais Da Malandragem) (crossbleeding starting @0:38)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Joe Dassin - L&#39;&eacute;t&eacute; indien (crossbleeding starting @0:24)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Led Zeppelin - Kashmir (crossbleeding starting @2:16)</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">List of songs which have bleed in the vocal track using the new BS-Roformer Revive v1 experimental vocal model by unwa (dca&rsquo;s contribution as well):</span></p><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_7gk9ayd44tft-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Travis - Sing (FX picked up in vocal, starting @00:09)</span></li></ul><ul class="c9 lst-kix_4ypcpsaj0q6h-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Safar (The Journey) (instrument picked up in vocal, starting @00:03)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Asian Dub Foundation - Tu Meri (instrument picked up in vocal, starting @02:33)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Radio Retaliation (FX picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thierry David - Huong Vietnam (erhu picked up in vocal, starting @00:35)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Deep Forest - Dignity (elec guitar picked up in vocal, starting @00:36)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Zaz - Je veux (whole kazoo solo picked up in vocal, starting @02:08)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Archive - Fool (harmonica picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Portishead - Humming (FX and theremin picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Moby - Lift Me Up (synth picked up in vocal, starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">The Cardigans - My Favourite Game (guitar picked up in vocal, starting @00:10)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Talk Talk - It&#39;s My Life (FX picked up in vocal, starting @00:05)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Radiohead - The National Anthem (various FX and instruments picked up in vocal throughout the song)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Zero 7 - Distractions (synth/FX bleed @00:07/@04:29)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Porcupine Tree - What Happens Now? (synth/FX/guitar bleed @~07:31)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Porcupine Tree - Start of Something Beautiful (synth bleed @04:55)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Porcupine Tree - The Start of Something Beautiful (Live) (synth bleed @04:38)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Porcupine Tree - Don&#39;t Hate Me (guitar bleed @00:29/@03:54)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Porcupine Tree - Dark Matter (synth bleed @03:18/@05:42)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Porcupine Tree - Arriving Somewhere but Not Here (synth bleed @04:12, elec guitar bleed @04:46)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Porcupine Tree - Way out of Here (Live) (synth bleed @00:13, @06:36)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Radiohead - Pyramid Song (FX bleed @00:05/@04:08)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Talk Talk - Happiness is Easy (wind instrument bleed @04:20)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">The Cinematic Orchestra - Evolution (scratching bleed @04:38) </span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Pink Floyd - Dogs (elec guitar/fx/synth bleed at times)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Archive - Again (harmonica/fx/synth bleed at times)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Archive - Lights (fx/synth bleed at times)</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">List of song where Roformer SW and BS 2025.06 solves the problem of vocals/BV crossbleeding in some songs by dca100fb8</span></p><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_xhhdon4tpeu0-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Canned Heat (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">George Michael - Amazing (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Samo Zaen - El lilady (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Coldplay - For You (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Kool &amp; The Gang - Fresh (Single Version) (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Kool &amp; The Gang - Too Hot (Single Version) (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Khaled - Aicha (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Nelly Furtado - Say It Right (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Eurythmics - Here Comes the Rain Again (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Eurythmics - Sweet Dreams (Are Made of This) (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">David Guetta - Love Is Gone (Fred Riester &amp; Joachim Garraud Radio Edit Remix) (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">David Guetta - Love Don&#39;t Let Me Go (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Bob Marley &amp; The Wailers - Sun is Shining (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Bob Marley &amp; The Wailers - Running Away (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Daniel Masson - Les Rubans (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Michael Jackson - Workin&#39; Day And Night (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Radiohead - Morning Bell (from Kid A) (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Radiohead - Scatterbrain (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Portishead - Strangers (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Moby - Lift Me Up (no crossbleeding)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Seal - Love&#39;s Divine (no crossbleeding)</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unwa&rsquo;s BS Roformer Resurrection Inst model fixing crossbleeding of vocals in the instrumental by the first time. So it fixes the crossbleeding problems like BS Roformer SW/2025.06/07 did on these songs, for some reason (dca):</span></p><p class="c1 c7"><span class="c0"></span></p><ul class="c9 lst-kix_upq3ni6ul8eb-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Bob Marley - Running Away (Kaya 40 Mix)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Samo Zaen - Tonight</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Eurythmics - Here Comes The Rain Again</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Eurythmics - Sweet Dreams (Are Made of This)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">George Michael - Amazing</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Kool &amp; The Gang - Fresh (Single Version)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Kool &amp; The Gang - Too Hot (Single Version)</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Songs which can&#39;t be separated to an instrumental with BVs (generally because lead vocals can&#39;t be differentiated from backing vocals) by dca100fb8 (from before becruily karaoke model release) by dca100fb8</span></p><p class="c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_yob9gooqotb-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Nelly Furtado - Maneater (@0:16, LV are counted as BV because of the panning, but using stereo 50% with uvr bve v2 doesn&#39;t solve the issue)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Lenny Kravitz - Low (@1:03, BV are counted as LV by BVEs or Kar models, including Dango and LALAL.AI)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Timbaland - The Way I Are (@0:25, LV are counted as BV by BVEs or Kar models, including Dango and LALAL.AI, uvr bve v2 50% stereo LV panning failed)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Timbaland - Give It To Me (@0:25, LV are counted as BV by BVEs or Kar models, including Dango and LALAL.AI, uvr bve v2 50% stereo LV panning failed)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Timbaland - Morning After Dark (@2:02, BVEs and Kar models couldn&#39;t differentiate LV from BV, including Dango and LALAL.AI, uvr bve v2 50% stereo LV panning failed)</span></li></ul><p class="c1 c8"><span class="c0">Fixed:</span></p><p class="c1 c8"><span class="c0">- Simply Red - Sunrise (@0:45, LV are counted as BV because of the panning, but using stereo 50% with uvr bve v2 doesn&#39;t solve the issue; fixed by Dango Backing Vocal Keeper by processing left then right channel)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">List of difficult songs to extract the BVs with becruily&#39;s karaoke model - divided in three categories by dca100fb8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Very important:</span></p><p class="c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_yxvs6rw7mq1w-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Phil Collins - In The Air Tonight (LVs crossbleeding during the whole song starting @00:52; BVE v2 fixes it)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">UB40 - Red Red Wine (LVs crossbleeding during the whole song starting @00:00</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Supertramp - It&#39;s Raining Again (it still has the lead vocals during the whole song after conversion to Inst w/ BV; MDX Kar v2 fixes the problem)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Phil Collins - I&#39;m Not Moving (LV crossbleeding, It seems Becruily Kar has issues with the way Phil Collins&#39;s voice is often mixed)</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Important:</span></p><p class="c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_f2t507a7xjue-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Charlie Winston - Kick the Bucket (BVs are missing starting @01:42)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Coldplay - Daylight (LVs are still present starting @00:28)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Massive Attack - Spying Glass (LVs are still present in the whole song starting @00:19)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Indochine - J&#39;ai demand&eacute; &agrave; la lune (BVs are missing starting @02:28)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Pierpoljak - Pierpoljak (Radio Edit) (BVs/LVs crossbleeding starting @00:05)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - King for a Day (BVs are missing starting @00:55)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Light Years (BVs are missing starting @00:22)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Rock Dust Light Star (BVs are missing starting @01:42)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">ABBA - Dancing Queen (LVs are still present starting @00:19)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Archive - You Make Me Feel (BVs/LVs crossbleeding starting @00:24)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Justin Timberlake - Rock Your Body (BVs/LVs crossbleeding starting @00:28)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Simply Red - Turn It Up (BVs/LVs crossbleeding starting @00:04)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Justin Timberlake - SexyBack (BVs/LVs crossbleeding starting @00:15)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Demis Roussos - From Souvenirs to Souvenirs (BVs/LVs crossbleeding starting @01:34)</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Less important:</span></p><p class="c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_yk26x5gkc3g4-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Hot Tequila Brown (LVs are still present starting @01:19)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Bee Gees - How Deep Is Your Love (LVs are still present starting @00:47)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Simply Red - How Could I Fall (BVs are missing starting @01:40)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Simply Red - Something Got Me Started (BVs are missing starting @00:53)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Phil Collins - Don&#39;t Let Him Steal Your Heart Away (BVs/LVs crossbleeding starting @01:51)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Phil Collins - Another Day in Paradise (BVs/LVs crossbleeding starting @01:13)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Phil Collins - That&#39;s Just the Way It Is (BVs/LVs crossbleeding starting @00:59)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Groundation - Confusing Situation (LVs bleed starting @00:24 + crosbleeding starting @01:06)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Wham! - Everything She Wants (BVs missing starting @00:41)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Thief Rockers (BVs missing starting @00:00)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Radio Retaliation (BVs missing starting @00:01)</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Due to uncommon panning:</span></p><p class="c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_4voxeic75vm5-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Nelly Furtado - Maneater (@0:16, LV are counted as BV because of the panning, but using stereo LV Panning doesn&#39;t solve the issue)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Lenny Kravitz - Low (@1:03, BV are counted as LV by BVEs or Kar models)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Timbaland - The Way I Are (@0:25, LV are counted as BV by BVEs or Kar models, LV panning failed)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Timbaland - Give It To Me (@0:25, LV are counted as BV by BVEs or Kar models, LV panning failed)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Timbaland - Morning After Dark (@2:02, BVEs and Kar models couldn&#39;t differentiate LV from BV, LV panning failed)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Simply Red - Sunrise (@0:45, LV are counted as BV because of the panning, but using Lead Vocal Panning doesn&#39;t solve the issue)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Automaton (Lead vocal panning didn&#39;t help)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Culture Of Fear (MDX v2 works)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Supersonic (Lead vocal panning didn&#39;t help)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Jamiroquai - Travelling Without Moving (Lead vocal panning didn&#39;t help)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Philip Bailey &amp; Phil Collins - Easy Lover (LVs very difficult to differentiate from BVs)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Thievery Corporation - Sol Tapado (Lead vocal panning didn&#39;t help)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Moby - Landing (LV panning didn&#39;t help)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Moby - We Are All Made of Stars (LV panning didn&#39;t help)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">The Weeknd - Sacrifice (@01:25, LV panning didn&#39;t help)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Nitin Sawhney feat. The London Symphony Orchestra - Songbird (LV panning dind&#39;t help)</span></li></ul><p class="c1 c7 c8"><span class="c0"></span></p><p class="c1 c8"><span class="c0">Uncategorized</span></p><ul class="c9 lst-kix_35hvjwgc3k2f-0 start"><li class="c1 c25 c8 li-bullet-0"><span class="c0">Night Lovell - Dark Light (thx 97chris)</span></li><li class="c1 c25 c8 li-bullet-0"><span class="c0">Supertramp - Dreamer (LVs difficult to distinguish from BVs - dca)</span></li></ul><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c8"><span>Warning. If you upload lots of music in on our server (or any other server), recently our long-term users receive warnings from Discord about possible deletion of their accounts and whole good results channel got deleted </span><span>- we advise sharing only </span><span>links to e.g. GDrive or any other cloud instead of uploading music directly to Discord</span><span class="c0">. So far our user received two warnings from Discord without deleting account yet. The whole good results channel got deleted after linking to uploads instead of uploading after the last clean-up we got. Recently we added bot automatically deleting audio files uploaded directly to Discord instead of links added and the channel has been reopened.</span></p><p class="c1 c7 c8"><span class="c0"></span></p><h2 class="c29 c27 c8" id="h.bg6u0y2kn4ui"><span class="c42 c15 c22 c46 c30">Training models guide</span></h2><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1jUcwiPfrJ8CpHqXIRHuOu70cFDMv_n-UzW53iaFuM9w/edit?tab%3Dt.0&amp;sa=D&amp;source=editors&amp;ust=1765035744762937&amp;usg=AOvVaw13USrBy3k1zZHJsNUY78gG">Read mesk&rsquo;s guide</a></span><span>&nbsp;(new link #2)</span><span class="c0">, then proceed below for arch explanations and more details.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>As for a training code for Roformers and MDX23C, SCNet or adding new archs, most people use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035744763408&amp;usg=AOvVaw0LAZZdB7qGbJjq86Ngs_BT">MSST</a></span><span class="c0">&nbsp;by ZFTurbo. It&rsquo;s also provided with bunch of documentation.</span></p><p class="c1"><span>&ldquo;You can start with Sucial MSST </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/SUC-DriverOld/MSST-WebUI&amp;sa=D&amp;source=editors&amp;ust=1765035744763668&amp;usg=AOvVaw1yi2JAvKgqUYD2aOK_j50l">WebUI</a></span><span>. I use that to train all my models&rdquo; - Gabox</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Introduction</span></p><p class="c1"><span class="c0"><br>&ldquo;There are three components to the model scaling laws. <br>They are the size of the data set, the number of parameters in the model, and the computational resources.&rdquo; unwa<br>For training, depending on model type (explained above), it can be e.g. three files for training e.g. vocal model - vocals, instrumental, and mixture. When you&rsquo;ll try to train without mixture, the results will be &ldquo;terrible&rdquo; (iirc it was said somewhere in times of Mel Kim&rsquo;s model).</span></p><p class="c1"><span class="c0">&quot;You can train any sound you want with any architecture (MDX-Net, Demucs, Spleeter)&quot;</span></p><p class="c1"><span>But don&rsquo;t use Spleeter, it&rsquo;s deprecated since so many archs were released (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/911050124661227542/1158015998318882856/image.png?ex%3D651ab5f0%26is%3D65196470%26hm%3D0fe6a1f080140fe3887c64a34a9475ea353561691151c49dce4ede42f362943d%26&amp;sa=D&amp;source=editors&amp;ust=1765035744765023&amp;usg=AOvVaw2bKFkXz381jcTYgE86CD9V">Kim</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">Just be aware that not every arch is a good choice for some specific tasks or instruments.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">(Among others, the following based also on Anjok&rsquo;s </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D-pcVN54cgw0&amp;sa=D&amp;source=editors&amp;ust=1765035744765472&amp;usg=AOvVaw1pvNzk5hEkHCmufcIMJG7S">interview</a></span><span class="c6">, around 0:40:00)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For training a new model, use at least 200 samples for such a model to achieve any good results. Anything below that might give you the results you might not be happy with, and of course, above that will give better results.</span></p><p class="c1"><span class="c0">For BS/Mel Roformers, 525 songs were not enough to train a good model from scratch at some point.</span></p><p class="c1"><span class="c0">Q: Anyone know how many songs are generally needed to finetune a Mel-Roformer model</span></p><p class="c1"><span class="c0">A: Few thousand - Unwa.<br>Mesk for metal dataset at some point had 2135 instrumentals and 1779 vocals (total 3914 tracks)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For fine-tuning of existing models of these archs, RTX 3070 Ti and 4060 (both 8GB) were used by unwa and Gabox respectively (RTX 2000 series don&rsquo;t support flash attention implementation in ZFTurbo&rsquo;s training </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/&amp;sa=D&amp;source=editors&amp;ust=1765035744766897&amp;usg=AOvVaw1uuY9vrRxHR_STT2hEteJl">repo</a></span><span class="c0">). </span></p><p class="c1"><span class="c0">&ldquo;You COULD train using 8GB of VRAM, it is doable, but not recommended, you at least need 16 or more. Training is difficult because it quickly fills up your VRAM even with gradient checkpointing enabled&rdquo; - mesk</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Training was also tested by unwa and working on RX 7900 XTX 24GB (gfx1100) on Ubuntu 24.04 LTS using Pytorch 2.6 for ROCm 6.3.3, PyTorch 2.6 for ROCm 6.2.4.</span></p><p class="c1"><span class="c0">&ldquo;No special editing of the code was necessary. All we had to do was install a ROCm-compatible version of the OS, install the AMD driver, create a venv, and install ROCm-compatible PyTorch, Torchaudio, and other dependencies on it.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;To install only the minimum necessary items, I first installed PyTorch, then ran train.py many times to install the missing items little by little.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Basically, it is almost no different from PyTorch for CUDA.</span></p><p class="c1"><span class="c0">For example, when specifying a device in your code, you can just use &#39;cuda&#39; as is.</span></p><p class="c1"><span class="c0">Also, Flash Attention can be used by setting the environment variable to &lsquo;TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1&rsquo;.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>For now, the only </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html&amp;sa=D&amp;source=editors&amp;ust=1765035744769009&amp;usg=AOvVaw18RyLv0557GHsRfch_id1q">supported</a></span><span>&nbsp;consumer AMD Radeon </span><span class="c0">GPUs for ROCm on Linux are: </span></p><p class="c1"><span>RX 7900 XTX, RX 7900 XT, RX 7900 GRE and AMD Radeon VII (probably a fuller list of GPUs from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rocm.docs.amd.com/projects/install-on-windows/en/latest/reference/system-requirements.html&amp;sa=D&amp;source=editors&amp;ust=1765035744769406&amp;usg=AOvVaw2kSSkPL1XGfdSO51oeJWvZ">here</a></span><span class="c0">&nbsp;should have working GPUs with ROCm too), </span></p><p class="c1"><span class="c0">but &ldquo;even right now hipcc in ROCm 6.3.3 has gfx1200 and gfx1201 targets [namely RX 9070 and RX 9070 XT]. You&#39;ll still be able to build and run stuff with ROCm. For whatever reason, AMD feels it&#39;s not ready to give its stamp of approval.&rdquo; (EmergencyCucumber905)<br>E.g. RX 6700 XT 12GB seems to work with ROCm too, but its performance might turn out to be not good enough, seeing how ZLUDA based on ROCm performed (more on ZLUDA later below, it&rsquo;s rather not feasible for training even in its fork state). </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The 7900XTX is great but probably no match for the 9070XT, which will be optimized in time; the 7900XTX certainly has more VRAM, but RDNA4 has FP8 support and greatly enhanced performance at FP16/BF16.</span></p><p class="c1"><span class="c0">Also, the 7900XTX is a top-end GPU and generates tremendous heat.</span></p><p class="c1"><span class="c0">The room becomes unbearably hot after running it for a while.&rdquo; Unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unwa half a year later:</span></p><p class="c1"><span class="c0">&ldquo;If you want to use AI properly with an AMD GPU, the MI300X is the best choice.&rdquo;<br>&ldquo;Honestly, I miss how comfortable CUDA is.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">GPU handling</span></p><p class="c1"><span class="c0">&ldquo;I&rsquo;ve reduced mine&#39;s core clock down to 60% with barely any reduction in performance, but it&rsquo;s much cooler now (stays about 55 degrees while training as opposed to 75-80)&rdquo; becruily (iirc it was on 3090 or Ti).</span></p><p class="c1"><span class="c0">Bad thermal paste (e.g. MX-2) can dry out in a year in high temperatures up to 80 degrees.<br>Some GPU brands allow changing thermal paste before warranty period ends.</span></p><p class="c1"><span class="c0">Consider a PC case with good airflow. Thermal pads might degrade after 5 years or when you disassemble them and, in a result, increase temperatures for memory. Then, check specific pad density for your model and replace it. You should be able to monitor VRAM temperature in e.g. GPU-Z. Sometimes it can be good at stock state even longer.</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span>PyTorch supporting ROCm on Windows natively without WSL was unavailable before (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rocm.docs.amd.com/projects/install-on-windows/en/latest/reference/component-support.html&amp;sa=D&amp;source=editors&amp;ust=1765035744772739&amp;usg=AOvVaw1LkUXK_2lfa_m_RUcnqafa">old documentation</a></span><span class="c0">), and for consumer GPUs is now supported with ROCm 6.4.4 for only RX 7000/9000. </span></p><p class="c1"><span>Seeing by e.g. Stable Diffusion WebUI, any potential DirectML forks will be much slower than ROCm (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.theregister.com/2024/06/29/image_gen_guide/?page%3D2&amp;sa=D&amp;source=editors&amp;ust=1765035744773211&amp;usg=AOvVaw0rnKb83JiMzJlRNM33jQPz">src</a></span><span>), so for now, ROCm is the only reasonable way to go on Radeons (probably ZLUDA forks are still too much behind in development to be any useful (for now official repo supports only Geekbench, and further maintained </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lshqqytiger/ZLUDA/releases&amp;sa=D&amp;source=editors&amp;ust=1765035744773630&amp;usg=AOvVaw1MyRDYfeNsxtXRby7CR6RX">fork</a></span><span>&nbsp;of the old base </span><span class="c0">doesn&rsquo;t work with e.g. UVR [or we just haven&rsquo;t tried hard enough yet]).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unwa: &ldquo;The transition from GeForce to Radeon was not too difficult.</span></p><p class="c1"><span class="c0">It may be a bit cumbersome to build the environment.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;So far I have not had any problems. Running the same thing appears to use a little more VRAM than when running on the NVIDIA GPU, but this is not a problem since my budget is not that large and if I choose NVIDIA I end up with 16GB of VRAM (4070 Ti S/4080 S).</span></p><p class="c1"><span class="c0">Processing speeds are also noticeably faster, but I did not record the results on the previous GPU, so I can&#39;t compare them exactly.&ldquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">MDX-Net v2 (not incl. above, see Kim&rsquo;s MDX-Net v2 training repo </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://github.com/KimberleyJensen/mdx-net&amp;sa=D&amp;source=editors&amp;ust=1765035744775021&amp;usg=AOvVaw2SrGZHjNb4zKKt0Ovf35MI">here</a></span><span class="c6">) - lighter and older arch than Roformers, less effective and aggressive, less filtered</span></p><p class="c1"><span class="c0">Turned out to be easier in picking out proper parameters for training than VR.</span></p><p class="c1"><span class="c0">In case of e.g. MDX-Net, you take under consideration how big your model is intended to be by fft parameter determining the cutoff of the model, and also in-out channels (size of the channels long story short) - it increases size of the model and intensifies the resources needed for training.</span></p><p class="c1"><span class="c0">So if you have a smaller dataset, your model doesn&rsquo;t have to be that large.</span></p><p class="c1"><span class="c0">If you crank up the model size too much for a small dataset, you&#39;re putting yourself into a risk of overfitting. It means that the model will work too well on a data which was trained on, but it will not work so well on unknown songs which the model wasn&rsquo;t trained on.</span></p><p class="c1"><span class="c0">In case of situation of having large database with small model size, there won&rsquo;t be much training at all. It will basically forget features of larger dataset. You need to find a balance here.</span></p><p class="c1"><span class="c0">Batch size is the amount of samples that are being fed into the model as it&rsquo;s being trained. Smaller batch sizes will take longer to learn, but you might get a better result at the end. Larger batch size will make the model not so good, because it has to learn bigger passages at once, but the model will train faster.</span></p><p class="c1"><span class="c0">You need to tweak, balance out and find what works for you the best for a model you&rsquo;re training. Also balancing things out might be helpful for end users with slower GPUs, or even CPUs [although bigger MDX23C (v3) models are very difficult to separate on CPU, nearly impossible on the oldest 4 cores and still noticeably slower than MDX-Net models on GPUs like 3050].</span></p><p class="c1"><span class="c0">The section continues later below.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Overfitting</span></p><p class="c1"><span class="c0">&ldquo;Is when a model is still improving on training data but not on unseen data, and if training is push too far, it can even start to perform worse on unseen data.</span></p><p class="c1"><span class="c0">It&#39;s more important issue when you want a model that generalise well&rdquo;, [e.g. targeting only 909 hihats], you want a model which targets one really precise sound (with some variation, but still 909 hihats, so it&#39;s not really about generalisation.&rdquo; jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In terms of training, currently Anjok uses A6000 48GB and Ryzen 7 5800, 128GB RAM, 3TB NVME, you need an SSD for training as the training process in intensive for a massive amount of data.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">MDX23C </span></p><p class="c1"><span class="c0">Noticeably slower for separation than MDX-Net, even for GPUs like 3050.</span></p><p class="c1"><span class="c0">3000 samples of 3-4 minutes length, it&#39;s going to take at least for batch size of 8, a month and a half (?on A6000 and MDX-Net). Anjok didn&#39;t want to make models too big, having end users with not the best hardware in mind (hence the choice of the older arch).</span></p><p class="c1"><span class="c0">(here the interview section ends)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Everything should be trained to min. 200 epochs (at least for a model trained from scratch), and better, for 500 (e.g. MDX-Net HQ_2 was trained to 450 epochs). From e.g. 200 upward, the increase of SDR can be very low for a longer time. Experimentally, HQ_4 was trained to epoch 1149, and it slowly, but consequently progressed further beyond. In general, some people train models up to 750 or 1000 epochs, indeed, but it takes longer.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Somewhere at the beginning of 2023, UVR dataset consisted of 2K songs (maybe for voc_ft, can&rsquo;t remember), and probably more for MDX23C, and 700 pairs for BVE model, but in case of vocal model, the one with 7K songs didn&#39;t achieve much better SDR results than 2K. Could&#39;ve been a problem of overfitting or no cutoff for vocal model or any other problem with dataset creation we will tackle here later.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The best publicly available archs for training instrumentals/vocals which community already used, are: </span></p><p class="c1"><span class="c0">MelBand Roformer (faster and can surpass MDX23C and BS-Roformer SDR-wise with e.g. Kim config below [and not only], and can sound better and less muddy than BS), BS-Roformer (very demanding, better for specific tasks), MDX23C (can produce more residues in instrumentals than MDX-Net v2, but can give a bit more clarity), MDX-Net v2 2021 (instrumentals can get a bit muddy even in fullband models, still more residues than in Roformers), Demucs HT a.k.a. Demucs 4 (Anjok failed at training single stem model for it), vocal-remover (VR) by tsurumeso 5 (good for specific tasks like Karaoke/BVE models or dereverb, and for instrumentals it leaves lots of unpleasant residues), VR 6 (now takes phase under consideration, so there should be less residues, but it&rsquo;s outperformed by newer archs), VitLarge (probably the fastest), SCNet (still faster than Roformers).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I think on example of HQ_3 and 16.xx models, it&rsquo;s safe to say that MDX-Net v2 fullband models have less vocal residues in instrumentals than newer MDX23C arch, but it is also much more muffled, and it depends on specific song what arch will fit the best.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">About BS-Roformer, e.g. the model trained by Bytedance didn&rsquo;t include other stem and is obtained by inversion, and initially the results had lots of vocal residues in instrumentals or instruments in other stem, but it can be alleviated by decreasing volume of input file for separation by 3dB (the best SDR among lots of tested values). Generally, viperx models sounds similar to Ripple. The arch itself has potential for the best SDR currently (although currently there&rsquo;s a small difference between the two best Mel and Rofo models SDR-wise - 2024.08.07 and 2024.10 on MVSep.com, while BS models are more muddy).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There are other good archs like BSRNN which is already better than Demucs, and later released SCNet (but the results weren&rsquo;t as good as Roformers, they had more noise, and training wasn&rsquo;t that straightforward as initially thought). It&#39;s faster, than BS-Roformer, but probably due to arch differences, rather not better, although it might be still decent in some cases (you can hear the results on MVSEP).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Viperx trained on far more demanding arch (BS-Roformer) with 8xA100-80GB (half of what ByteDance used), on 4500 songs, and only on epoch 74 they already surpassed all previous UVR and ZFTurbo&rsquo;s/MVSEP models, including ensembles/weighted results (more info on that later below).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Viperx made a private model with Mel-Roformer which reached an epoch of around even 3100. He uploaded the SDR results to MVSEP, but it has been taken down since [presumably by viperx himself]. And even then, the result was not above 9.7 unfortunately, achieving results not much better than MDX23C SDR-wise, but with probably bigger dataset. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Later Kim fixed the issues with low SDR in Mel with her config and released the model which become the base of all the fine-tunes by Unwa/Gabox/Syh-Aname (more below).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;as training progresses, the metrics will improve slower and slower until a point where it&#39;s too slow = stop training&rdquo; - becruily</span></p><p class="c1"><span class="c0">- I always stop when [loss, avg_loss=] nan</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: it went back to SDR 20 again<br>A: &ldquo;that progress on valid updates per track, so some tracks are 20 SDR some will be like 2 SDR&rdquo; (frazer)</span></p><p class="c1"><span class="c0">Q: yea, some are still at 11 etc</span></p><p class="c1"><span class="c0">A: &ldquo;train until either avg loss nan or fixed sdr (example: 14 for me) with 5.0e-05</span></p><p class="c1"><span class="c0">use best checkpoint from that run with 1.0e-05 to get some boost</span></p><p class="c1"><span class="c0">idk why it works (and if it works im at step 1 rn xD)&rdquo; - mesk</span></p><p class="c1"><span class="c0">Q: is it normal that when i use a checkpoint with 12.53 sdr, then restart training, the results at epoch 0 and 1 drop back to 11.77?</span></p><p class="c1"><span class="c0">A: yes</span></p><p class="c1"><span class="c0">only if u restart with a higher LR</span></p><p class="c1"><span class="c0">so i had a checkpoint that was 12SDR trained with 5e-5, then if i trained that with 1e-5, youd expect it to start at like 11.Xsdr</span></p><p class="c1"><span class="c0">if i had a checkpoint 12SDR trained 1e-5, and i train with 5e-5, id expect it to either start at 12, then drop, then start to increase</span></p><p class="c1"><span class="c0">keep it going 5e-5 for literally as long as u can</span></p><p class="c1"><span class="c0">this is called overfitting - just make sure it doesnt do this</span></p><p class="c1"><span class="c0">its the point where the model begins to not generalize but memorize the training set - happens on finetuning if u train too long</span></p><p class="c1"><span>what u do is just keep the redline score if u still have it (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/POe76dn&amp;sa=D&amp;source=editors&amp;ust=1765035744788695&amp;usg=AOvVaw3OFnxLbFKd2dx7rJ_sZFHD">pic</a></span><span class="c0">) - frazer</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Preparing dataset</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Let&rsquo;s get started.</span></p><p class="c1"><span class="c0">First, check the -</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Repository of stems - </span><span class="c4"><a class="c3" href="#h.k3cm3bvgsf4j">section</a></span><span class="c0">&nbsp;of this document.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There you will find out that most stems are not equal in terms of loudness to contemporary standards, and clip when mixed together. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">About sidechain stem limiting guide by Vinctekan</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>The sidechain limiting method might be not so beneficial for SDR as we thought initially, irc it&rsquo;s explained in the </span><span class="c4"><a class="c3" href="#h.8uxrvfoxzav6">interesting links section</a></span><span>&nbsp;</span><span>with the given </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.18407&amp;sa=D&amp;source=editors&amp;ust=1765035744790118&amp;usg=AOvVaw1DWhsLC2-ACIQsMN22Bga4">paper</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">Other useful links: </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2110.09958.pdf&amp;sa=D&amp;source=editors&amp;ust=1765035744790368&amp;usg=AOvVaw22JVor3QRfA71gU_hCNuPo">https://arxiv.org/pdf/2110.09958.pdf</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/darius522/dnr-utils/blob/main/config.py&amp;sa=D&amp;source=editors&amp;ust=1765035744790601&amp;usg=AOvVaw0TWFn9eCfhJsstB20Qt5sV">https://github.com/darius522/dnr-utils/blob/main/config.py</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;You can also just utilize this </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/darius522/dnr-utils/blob/main/audio_utils.py&amp;sa=D&amp;source=editors&amp;ust=1765035744790954&amp;usg=AOvVaw2neBRyXLudSdiBn_BXEwm0">https://github.com/darius522/dnr-utils/blob/main/audio_utils.py</a></span></p><p class="c1"><span class="c0">and make a script suited to your own, the one already on this repo is a bit difficult to repurpose.</span></p><p class="c1"><span class="c0">I just concatenated a lot of sfx music and speech together into 1hr chunks and used audacity tho (set LUFS and mix)</span></p><p class="c1"><span class="c0">oh and then further split into 60 second chunks after mixing them&rdquo; - jowoon</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Aligned dataset is not a requirement to get performing models, so you can create a dataset with FL/Ableton with random beats for each stem. Or using loops (while they contain only 1 type of sound).</span></p><p class="c1"><span class="c0">You create some tracks with only kick, some others with only snare, other with only...etc...</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">And you have your training dataset to use with random mixing dataloader (dataset type 2 in ZFTurbo script, one folder with all kick tracks, one folder with all snare tracks, one folder with&hellip; etc.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Then you have to create a validation dataset accordingly to the type of stems used in training, preferably with a kind of music close to the kind you want to separate, or &quot;widespread&quot;, with a more general representation of current music, but this mean it has to be way larger.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The only requirements are:</span></p><p class="c1"><span class="c0">44.1Hz stereo audio.</span></p><p class="c1"><span class="c0">Lossless (wav/flac)</span></p><p class="c1"><span class="c0">Only 1 type of sound by file (and no bleed like it would happen with real drums)</span></p><p class="c1"><span class="c0">Audio length longer than 30s (current algos use mostly ~6/12 second chunks, but better to have some margin and longer tracks so they can be used in future when longer chunks can be handled by archs &amp; hardware).&rdquo; jarredou</span></p><p class="c1"><span class="c0">&ldquo;You can use flac too; saves space (though make them 44.1 / 16-bit / stereo, even if u use mp3&#39;s or whatever other format - convert upfront)</span></p><p class="c1"><span class="c0">validation set however needs to remain in wav with mixture included.&rdquo; Bas Curtiz</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;A quite unknown Reaper script to randomize any automatable parameters on any VST/JS/ReaXXX plugin with MIDI notes. It&#39;s REALLY a must-have for dataset creation, adding sound diversity without hassle.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://forum.cockos.com/showthread.php?t%3D234194&amp;sa=D&amp;source=editors&amp;ust=1765035744794811&amp;usg=AOvVaw0z_cRF8eIgRO02PXtcRHuk">https://forum.cockos.com/showthread.php?t=234194</a></span><span class="c0">&rdquo; jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">(Guides for stem limiting moved to the end of the section for archival purposes - rather outdated approaches due to the statements in the paper above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">FAQ</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You shouldn&#39;t compare training data against evaluation data, while those being the same.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can use multisong dataset from MVSEP, and make sure you don&#39;t have any of those songs in your dataset.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Does evaluation data matter for the final quality of the model?</span></p><p class="c1"><span class="c0">A: Absolutely not. It&#39;s merely indication </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">SDR measurement is logarithmic, meaning that 1 SDR is 10x difference.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Why I have negative SDR values (based on HTDemucs)</span></p><p class="c1"><span class="c0">A: Make sure there are no empty stems in any training dataset and or validation dataset </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Below is just a theory for now and probably wasn&#39;t strictly tested on any model yet, but seems promising </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Can you not calculate the average dB of the stems and fit one limiting value to them all?</span></p><p class="c1"><span class="c0">A: the stems are divide-maxed prior</span></p><p class="c1"><span class="c0">meaning they are made so, that when joined together, they won&#39;t clip</span></p><p class="c1"><span class="c0">but are normalized</span></p><p class="c1"><span class="c0">so they will be kinda standardized already</span></p><p class="c1"><span class="c0">based on that, I should be able to just go with one static value for all</span></p><p class="c1"><span class="c0">Example</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DJYwslDs-t4k&amp;sa=D&amp;source=editors&amp;ust=1765035744797777&amp;usg=AOvVaw0FhF-iF4YKiigz5QQb_q4R">https://www.youtube.com/watch?v=JYwslDs-t4k</a></span></p><p class="c1"><span class="c0">Q: This is great, I actually used this method before with a few sets of stems, before I decided to try sidechain compression/ Voxengo elephant method, but I&#39;m not too sure if I am on the right path. However, I&#39;m pretty sure this only works best for evaluation, if the resulting mixture has consistent loudness like in today&#39;s music.</span></p><p class="c1"><span class="c0">A: Yeah, it&#39;s a different approach than compression/voxengo indeed.</span></p><p class="c1"><span class="c0">But the fact it scored high in SDR and UVR dataset is already compressed/elphanted</span></p><p class="c1"><span class="c0">I think it&#39;s a good combo to use both in the set, a bit like new style tracks and oldies [so to use both approaches inside the dataset]</span></p><p class="c1"><span class="c0">some tracks in real life are compressed like fuck - some aren&#39;t</span></p><p class="c1"><span class="c0">so it mimics real life situation</span></p><p class="c1"><span class="c0">Q: if it&#39;s true that&#39;s awesome, with that the model basically has the potential to work in multiple mixing styles, without having to create new data, or changing it, right?</span></p><p class="c1"><span class="c0">While still adding new data</span></p><p class="c1"><span class="c0">A: Yeah, since UVR dataset is already compressed - and then add these one of mines with the more delicate way of mastering (incl. divdemax prior)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Does somebody know the best way to make dataset smaller? I have very huge dataset in flac format, so the one idea is to truncate part in the song where is only music without vocals? Also, I can convert it to opus format, does it worse it? Or maybe there is something better that I don&#39;t know?</span></p><p class="c1"><span class="c0">A (jarredou): If you plan to use random mixing of stems during training (so non-aligned dataset), then you can remove all silent parts from stems pre-training, on instrumental it will not change a lot but for vocals it can save a lot of space (h/t Bas Curtiz for the idea)</span></p><p class="c1"><span class="c0">Q: Currently dataset is aligned, but does this random mixing is standard approach? I am going to train official SCNet model, so maybe it will require modifications for this?</span></p><p class="c1"><span>A: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.18407&amp;sa=D&amp;source=editors&amp;ust=1765035744801381&amp;usg=AOvVaw2mM7aUnjgBpDj9oqOobkzc">https://arxiv.org/abs/2402.18407</a></span><span class="c0">&nbsp;(Why does music source separation benefit from cacophony?)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.merl.com/publications/docs/TR2024-030.pdf&amp;sa=D&amp;source=editors&amp;ust=1765035744801713&amp;usg=AOvVaw2yQ9aYS2Kgw0fLmQ3xFJ8i">https://www.merl.com/publications/docs/TR2024-030.pdf</a></span><span class="c0">&nbsp;(same non-columns formatting)</span></p><p class="c1"><span>&ldquo;It thus appears that a small amount of random mixes composed of stems from a larger set of songs performs better than a large amount of random mixes composed of stems from a smaller set of songs.&rdquo;</span></p><p class="c1"><span>If needed, the training script that ZFTurbo has made does handle random and aligned dataset and has also SCNet implementation: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035744802495&amp;usg=AOvVaw1u-b_V7YnPJ62rqE8ALsXb">https://github.com/ZFTurbo/Music-Source-Separation-Training</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: As I know, SCNet supports only for inference here.</span></p><p class="c1"><span class="c0">A: It does training too, ZFTurbo has recently trained a SCNet-large model on MUSDB18 dataset</span></p><p class="c1"><span>Dataset types doc </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/dataset_types.md&amp;sa=D&amp;source=editors&amp;ust=1765035744803194&amp;usg=AOvVaw2oVLfGtBFyOoQTLdhs6-AF">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/dataset_types.md</a></span></p><p class="c1"><span class="c0">(he only didn&#39;t update help string)</span></p><p class="c1 c7"><span class="c0"></span></p><h3 class="c35 c27" id="h.wyh707wdm55j"><span class="c18 c49">Creating dataset - guide by Bas Curtiz</span></h3><p class="c1"><span>(now also </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DWmt_0zu94L8&amp;sa=D&amp;source=editors&amp;ust=1765035744803613&amp;usg=AOvVaw2EjZBgX6JYgntdMp89AnGF">video</a></span><span>&nbsp;</span><span class="c0">available)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">How to: Create a dataset for training</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1. Download any sample pack that is focused around inst/synth x or y.</span></p><p class="c1"><span class="c0">(sources to seek on: audioz.download, magesy.blog, rutracker.org, freesounds.org, etc.)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2. Use real-debrid.com or alldebrid.com to speed things up DL-wise</span></p><p class="c1"><span class="c0">(costs a few bucks but worth it,</span></p><p class="c1"><span class="c0">so better prepare so u can sign up for a free trial or a 3 bucks access for x amount of days)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3. Unzip all (so they are all in a separate individual folder)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4. Convert all to make it consistent (I use https://www.dbpoweramp.com/ to batch-process)</span></p><p class="c1"><span class="c0">a) Convert all to WAV/16-bit/Stereo &amp; delete any other audio format like AIFF, MP3, OGG.</span></p><p class="c1"><span class="c0">b) Convert all to FLAC (saves space without degrading quality)</span></p><p class="c1"><span class="c0">c) Delete all *.WAV files</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5.</span></p><p class="c1"><span class="c0">a) Move all files to root folder of the individual folder.</span></p><p class="c1"><span class="c0">(I use a python script for that. Hit me up so I can share.)</span></p><p class="c1"><span class="c0">b) Remove empty directories</span></p><p class="c1"><span class="c0">(I use https://sourceforge.net/projects/rem-empty-dir/ to batch-process)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">6. Rename files by adding a prefix of the folder they&#39;re in.</span></p><p class="c1"><span class="c0">For convenience, add a tag like [ORGAN] or so to it:</span></p><p class="c1"><span class="c0">example: `[PERC] - Aaroh South Indian Percussion - AR_SIP_80_percussion_small_nagara_double_rhythm.flac`</span></p><p class="c1"><span class="c0">(I use https://www.bulkrenameutility.co.uk/ to batch-process)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">7. Sort on length. If below 11s, move them elsewhere.</span></p><p class="c1"><span class="c0">(I use Mp3tag to sort and move in batch, but Windows explorer is able to do so too)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">8. Loop those up till 11 seconds.</span></p><p class="c1"><span class="c0">(I use https://www.dbpoweramp.com/ &gt; Loop DSP for that)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">9. Move *.flac files into 1 folder (the looped + untouched audio files) - now u can ditch all unneeded files/folders</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">10. Undupe</span></p><p class="c1"><span>(I use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.similarityapp.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744807675&amp;usg=AOvVaw1_Fe9wuAloEF40YU7Wjmjh">https://www.similarityapp.com/</a></span><span>,</span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.duplicatecleaner.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744807839&amp;usg=AOvVaw1diO5d2naydl0_8ANwPtPu">https://www.duplicatecleaner.com/</a></span><span>&nbsp;</span><span>or </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://dupeguru.voltaicideas.net/&amp;sa=D&amp;source=editors&amp;ust=1765035744808046&amp;usg=AOvVaw1dyJT-3AIABdDKfd8JnVs-">https://dupeguru.voltaicideas.net/</a></span><span>&nbsp;</span><span class="c0">to batch-process)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(optional - only when applicable)</span></p><p class="c1"><span class="c0">11. Sanitize based on SDR</span></p><p class="c1"><span class="c0">a) Process the original files with HTdemucs.</span></p><p class="c1"><span class="c0">Based on whether your dataset should contain bass/drums/other/vocals, set the proper output.</span></p><p class="c1"><span>b) Rename the output so it matches the original filename again (using </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.bulkrenameutility.co.uk/&amp;sa=D&amp;source=editors&amp;ust=1765035744808939&amp;usg=AOvVaw28fGnD6cd4uaYwyBVJKs8r">https://www.bulkrenameutility.co.uk/</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">c) Use SDRCALC.exe like `sdrcalc &quot;c:\organ&quot; &quot;c:\organ-htdemucs&quot; &gt; sdr-organ.txt`</span></p><p class="c1"><span class="c0">d) copy over the output in the text-file to a GSheet for convenience, to sort on SDR</span></p><p class="c1"><span class="c0">e) move all unprocessed/original files above a certain SDR to a new folder</span></p><p class="c1"><span class="c0">(I use a python script for that. Hit me up so I can share.)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">12. Review the content on filename and play some you aren&#39;t sure, what this filename would sound like.</span></p><p class="c1"><span class="c0">They can be hit or miss for your specific dataset. So anything that mentions something unusual or so usual, you know it&#39;s part of something totally different,</span></p><p class="c1"><span class="c0">move them elsewhere, to keep the dataset close to what you try to obtain sound-wise.</span></p><p class="c1"><span class="c0">(example *timpani* is part of percussion, not so much part of a String Dataset)</span></p><p class="c1"><span class="c0">You could try to cluster the samples upfront with s/w like https://www.sononym.net/ - also available at audioz.download</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">13. Zip those and upload, so you can share with those that have the ability/experience to train.</span></p><p class="c1"><span class="c0">Also needed when you&#39;re going to hire a cloud-gpu setup, to copy over the dataset to its server).</span></p><p class="c1"><span class="c0">(I use sharepoint/onedrive for that, but u can use buzzheavier.com for unlimited storage)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Done.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;In some cases when there aren&#39;t clean versions available, you can use a portion of the song where it doesn&#39;t have vocals (but has the bleed instruments) and add random clean vocals </span></p><p class="c1"><span class="c0">it&#39;s not aligned dataset, but works for fine-tuning&rdquo; - becruily</span></p><p class="c1"><span class="c0">even aufr33 admitted that makes models with isolated tracks<br><br>&ldquo;Lossless is always better (and if needed you can use mp3 encoding as an augmentation during training, based on the lossless files)</span></p><p class="c1"><span class="c0">But as 320kbps have quite high cutoff (20khz or something), it would be less problematic than more compressed audio with hard cutoff at 16khz or 17khz.</span></p><p class="c1"><span class="c0">I would say that, like for other less regular stuff in your dataset, make it obvious in filename that it&#39;s not lossless if you share these files </span></p><p class="c1"><span class="c0">Q: So... maybe not? IDK I feel like I could make an entire 20 songs dataset out of those, because the best ones aren&#39;t lossless</span></p><p class="c1"><span class="c0">but would it actually be helpful</span></p><p class="c1"><span class="c0">a lot of leaked stuff is in 320kbps mp3</span></p><p class="c1"><span class="c0">A: I think while codec cutoff is around 20khz or above it&#39;s ok.</span></p><p class="c1"><span class="c0">Because that will not bias model output results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">With first Roformers models from ByteDance on ripple, that were trained on mixed lossless and 128kbps mp3 with hardcutoff around 16~17khz, we could see that bias in separated audio even when it was lossless input.<br>Maybe it&#39;s a question of balance between lossless/compressed content. I remember the first Ripple bsroformer outputs with these incoherencies in high frequencies <br>while we knew it was trained on mixed lossless/128kbps mp3&rdquo; - jarredou<br>Bas: diversity is key we learned from this paper: https://arxiv.org/pdf/2402.18407</span></p><p class="c1"><span class="c0">so I take that literally, and as a starting point. </span></p><p class="c1"><span class="c0">Q: so it should also have compression for it to work better after all?</span></p><p class="c1"><span class="c0">A: so diversity is also in audio compresion</span></p><p class="c1"><span class="c0">we don&#39;t know for sure, but since my model doesn&#39;t seem to perform bad, let&#39;s pretend</span></p><p class="c1"><span class="c0"><br>D: I&rsquo;m not sure if it&rsquo;s really worth to worsen the quality of already lossy stems to create diversity in the dataset artificially. Yes, the model might behave better at lossy inputs, but people should use lossy inputs only occasionally, so I wouldn&rsquo;t sacrifice quality of lossless inputs that way, plus dataset &ldquo;can be degraded in many ways on the fly during training with augmentations if needed&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Can the training files for dataset be mp3</span></p><p class="c1"><span class="c0">I added over 2k tracks and deleted the metadata, it keeps only scanning the original 2k tracks, not the 4k+</span></p><p class="c1"><span class="c0">A: &ldquo;I think you can add &quot;mp3&quot; extension to the list there in dataset.py</span></p><p class="c1"><span>arg... it&#39;s not that simple, there are other places with wav/flac hardcoded... &rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1327685234988417175&amp;sa=D&amp;source=editors&amp;ust=1765035744816078&amp;usg=AOvVaw1XrdOFv89CcPe844DPHxeN">jarredou</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;If you were annoyed by dataset metadata generation step being slow with MSST, update/do that:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/pull/178/files&amp;sa=D&amp;source=editors&amp;ust=1765035744816622&amp;usg=AOvVaw37KyRoof71YOSVzPpvPN90">https://github.com/ZFTurbo/Music-Source-Separation-Training/pull/178/files</a></span></p><p class="c1"><span>it&#39;s like hundred times faster than before&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Bas Curtiz&rsquo; Q&amp;A</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;1. &ldquo;Is it really necessary to have vocals for every track when training?</span></p><p class="c1"><span class="c0">Depends. Do you wanna make a model that can split vocal from instrumental? Or vocal from whatever &#39;other&#39; is?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2. Could adding more instrumental-only data be beneficial for variety?</span></p><p class="c1"><span class="c0">My dataset wasn&#39;t 50/50 either. Does that benefit? No idea.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3. Like is it okay to just fill up the dataset with instrumentals to complete it or is there a risk it&rsquo;ll start underfitting on vocals?</span></p><p class="c1"><span class="c0">Underfitting is always on the lure, so make sure u have plenty of data in general.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4. I know in a lot of songs there are instrumental breaks with no vocals, so I&#39;m just wondering.</span></p><p class="c1"><span>Hence, see video &quot;my how to create a dataset&#39;&#39;: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DWmt_0zu94L8&amp;sa=D&amp;source=editors&amp;ust=1765035744818568&amp;usg=AOvVaw2lb--2p1htJdJPVtzXmgqd">https://www.youtube.com/watch?v=Wmt_0zu94L8</a></span></p><p class="c1"><span class="c0">We ditch the silence parts from start/in between/end, from vocal and instrumental.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you used dataset type 4, then don&#39;t throw away silence, since then there&#39;s no cohesion any longer between the inst/vocal or drums/bass/vocal/other or whatever u training.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Why is my model bleeding the least vocals in the instrumental output?</span></p><p class="c1"><span class="c0">A: Cause I didn&#39;t use pre-processed/cleaned up vocals (I did, but only ~10% of the dataset).</span></p><p class="c1"><span class="c0">[he refers to his fine-tune exclusively on MVSEP]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What has that to do with the absence of vocal bleeding in the instrumental output?</span></p><p class="c1"><span class="c0">A: Cause the full spectrum is being used to determine what is a vocal. Even low rumble and potential noise.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: So why does yours bleeds less compared to other models?</span></p><p class="c1"><span class="c0">A: As stated, aufr33 for ex. used pre-processed vocals to train on.</span></p><p class="c1"><span class="c0">This means, a part of the noise/low rumble is already gone.</span></p><p class="c1"><span class="c0">So it&#39;s trained like that stuff isn&#39;t part of the vocal. And if there is, it is dumped into the other (the instrumental output).</span></p><p class="c1"><span class="c0">This is my gut-feeling why we do hear vocal leftovers in the instrumental output.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: So what is the solution?</span></p><p class="c1"><span class="c0">A: My model &#128578; If... you want clean instrumental output.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: But yours bleeds percussion/noise in the vocal output though...</span></p><p class="c1"><span class="c0">A: Yes. That&#39;s the side-effect of training on non-processed/cleaned up vocals, I think.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Solution?</span></p><p class="c1"><span class="c0">A: Fine-tune my model, but this time based on de-noised vocals (and add a shitload of percussion samples).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">My prediction is that we then have the best of both worlds:</span></p><p class="c1"><span class="c0">The current model as-is = great for instrumentals (as described by the community several times due, using non-processed/cleaned up vocals as input)</span></p><p class="c1"><span class="c0">Another fine-tune based on my current model = great for vocals (due to the lack of noise/low rumble/no bleed percussion)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Warning:</span></p><p class="c1"><span class="c0">This is based on logic and gut-feeling.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Dill: caught it going to nan again when everything was going smoothly very suddenly between epochs|<br>ZFTurbo: I think it&#39;s never happened to me on SCNet, but often on htdemucs as I remember.</span></p><p class="c1"><span class="c0">use_amp: false can help</span></p><p class="c1"><span class="c0">After you can switch back on usage</span></p><p class="c1"><span class="c0">Dry Paint: I can speak from experience that it only kinda helps</span></p><p class="c1"><span class="c0">I have the exact same issue with SCNet</span></p><p class="c1"><span class="c0">making amp=false does solve it but causes the loss to skyrocket to like 3.2e32 around the same time nan loss would appear<br><br>Q: Can I put a 4-hour file in one of the dataset&#39;s songs? Or should I split it?</span></p><p class="c1"><span class="c0">A: During training the script uses chunks anyway, so yes you can feed it a 4 hour file (in theory)<br>A: I did this, but I had to modify the training code to check the file length without loading the whole thing into memory</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c17" id="h.5mtsn5mhgb4o"><span class="c21">Leading architectures</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">MDX-Net (2021) architecture </span><span>(a.k.a. v2) (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/kuielab/mdx-net&amp;sa=D&amp;source=editors&amp;ust=1765035744824443&amp;usg=AOvVaw0SasUPJJ4zCh8aORMCxxWw">https://github.com/kuielab/mdx-net</a></span><span class="c0">). Old.</span></p><p class="c1"><span>From public archs, before MDX v3 2023, </span><span class="c0">it gave us the best results for various applications like vocal, instrumental, single instruments models compared to VR arch. But denoise and dereverb/deecho model turned to be better using VR architecture, the same goes to Karaoke/BVE models where in contrary to 5/6_HP, MDX model sometimes does nothing.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In times of Demucs 3 there was also e.g. custom UVR instrumental model trained, but it didn&rsquo;t achieve that good results vs MDX-UVR instrumental models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Once there was UVR </span><span class="c22">Demucs 4</span><span class="c0">&nbsp;model coming up, but the training was cancelled due to technical difficulties. Looks like ZFTurbo managed to train his model for SDX23 challenge and also vocal model, but &ldquo;[the] problem is that Demucs4 HT [traning is] very slow. I think there is some bug. Bug because sometimes I observe large slow-downs on inference too. And I see high memory bandwidth - something is copying without reason...&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Spleeter might seem to be a good choice, because training is pretty well documented, but it isn&rsquo;t worth it seeing how these models sound (also it was very first AI for audio separation at the time, and even VR arch is better than Spleeter hence UVR team started to train on VR arch with much greater results than Spleeter).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Your starting point to train MDX model would be here: </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/KimberleyJensen/mdx-net&amp;sa=D&amp;source=editors&amp;ust=1765035744827096&amp;usg=AOvVaw0qZcxGrmoSD-LLvlepBmSS">https://github.com/KimberleyJensen/mdx-net</a></span></p><p class="c1"><span class="c0">(visit this repo, it has some instructions and explanations)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">ZFTurbo released his training code for other various archs here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035744827841&amp;usg=AOvVaw3MPo6NDlS5BYl2ks04FSaw">https://github.com/ZFTurbo/Music-Source-Separation-Training</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It gives the ability to train 5 types of models: mdx23c, htdemucs, vitlarge23, bs_roformer and mel_band_roformer.</span></p><p class="c1"><span class="c0">I also put some weights there to not start training from the beginning.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Set up on Colab is simple:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You only have to create one cell for installation with:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">from google.colab import drive</span></p><p class="c1"><span class="c0">drive.mount(&#39;/content/drive&#39;)</span></p><p class="c1"><span class="c0">%cd /content/drive/MyDrive</span></p><p class="c1"><span class="c0">!git clone https://github.com/ZFTurbo/Music-Source-Separation-Training</span></p><p class="c1"><span class="c0">%cd /content/drive/MyDrive/Music-Source-Separation-Training</span></p><p class="c1"><span class="c0">!pip install -r requirements.txt</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">And a cell to run training:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">%cd /content/drive/MyDrive/Music-Source-Separation-Training</span></p><p class="c1"><span class="c0">!python train.py \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; --model_type mdx23c \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; --config_path &#39;configs/config_vocals_mdx23c.yaml&#39; \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; --results_path results/ \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; --data_path &#39;/content/drive/MyDrive/TRAININGDATASET&#39; \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; --valid_path &#39;/content/drive/MyDrive/VALIDATIONDATASET&#39; \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; --num_workers 4 \</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; --device_ids 0</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Don&#39;t forget to edit the config file for training parameters<br><br>You can also resume training from an existing checkpoint by adding </span></p><p class="c1"><span class="c0">--start_check_point &#39;PATH/TO/checkpoint.ckpt&#39; \</span></p><p class="c1"><span class="c0">parameter to the command in the training cell </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">the checkpoints are saved in the path provided by the :</span></p><p class="c1"><span class="c0">--results_path results/ \ parameter of the command, so here, in &quot;results&quot; folder</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">With ZFTurbo&#39;s script, mixtures are needed for validation dataset, to evaluate epoch performance&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;it saves every checkpoint as &quot;last_archname.ckpt&quot; (file is overwritten at each epoch), and also save each new best checkpoint on validation as &quot;archname_epxx_SDRscore.ckpt&quot;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It also lowers the learning rate when validation eval is stagnant for a chosen number of epochs (reduceonplateau), you can tweak the values in model config file.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: what does this gradient accumulation step/grad clip mean exactly?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: &ldquo;Accumulation lets you train with a larger batch size than what you can fit on your GPU, your real batch size will be batch_size multiplied by gradient_accumulation_steps. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">grad_clip clips the gradients, it can stop the exploding gradients problem</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Exploding gradients = model ruined basically, i had this problem with Demucs training, but I used weight decay (AdamW) to solve it instead of grad_clip</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I don&#39;t think grad_clip uses any resources, but accumulation uses a little bit of VRAM, i don&#39;t know the exact number&rdquo; - Kim</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Why can&rsquo;t models have like an auto stop feature or something IDK like if the model stops improving it&rsquo;ll stop automatically</span></p><p class="c1"><span class="c0">or overtraining, but IDK if models can overtrain</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: Nothing stopping you from adding a thing to stop training after seeing SDR (or whatever) is stagnant, some people even represent it in a chart</span></p><p class="c1"><span class="c0">A: That&rsquo;s easy to get it done in PyTorch, just use EarlyStopping after the overall validation loss computation and the training will stop depending on the patience you set on EarlyStopping&hellip;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/17SSjougcnVhX6WewW88QoKKFuFiKNz8t?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744834708&amp;usg=AOvVaw2NKJ20Ouck-TsW4h5sMp17">Colab</a></span><span class="c0">&nbsp;by jazzpear96 for using ZFTurbo&#39;s MSS training script. &ldquo;I will add inference later on, but for now you can only do the training process with this!&rdquo;</span></p><p class="c1"><span class="c0">- Training lots of epochs on Colab might be extremely tasking - for free users they currently only give slow GPU with performance of around RTX 3050 in CUDA but with 11GB of VRAM. It&rsquo;s only good enough for inference.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: how can I train a heavier MDX-NET model with a higher frequency cutoff like recent UVR MDX models?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">KimberleyJSN:</span></p><p class="c1"><span class="c0">A: these are the settings used for the latest MDX models you can change them at configs/model/ConvTDFNet_vocals.yaml and configs/experiment/multigpu_vocals.yaml</span></p><p class="c1"><span class="c0">overlap - 3840</span></p><p class="c1"><span class="c0">dim_f - 3072</span></p><p class="c1"><span class="c0">g - 48</span></p><p class="c1"><span class="c0">n_fft - 7680</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">These seem to be actually parameters for the last Kim ft other instrumental model, while e.g. half of MDX-UVR HQ models without cutoff has n_fft/self n_fft set to 6144.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Alternatively, see this guide:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/kuielab/mdx-net/issues/35%23issuecomment-1082007368&amp;sa=D&amp;source=editors&amp;ust=1765035744836842&amp;usg=AOvVaw18-HIpq1RNpR8OyYEUNMdB">https://github.com/kuielab/mdx-net/issues/35#issuecomment-1082007368</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You also need to be aware of a few additional things:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(Bas Curtiz, and brackets mine)</span></p><p class="c1"><span class="c22">Few [training] key points</span><span class="c0">:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- If you don&#39;t have a monster PC incl. a top range GPU [RTX 3080 min?] (or at work), don&#39;t even consider. [smaller models than good inst/vocs with fewer epochs of around 50 might be still in your range though]</span></p><p class="c1"><span class="c0">- If you don&#39;t have money to spent renting a server instead, don&#39;t even consider.</span></p><p class="c1"><span class="c0">- If you aren&#39;t tech-savy, don&#39;t even consider.</span></p><p class="c1"><span class="c0">- [If training] a particular singer, [then does it have] highly 100 tracks with original instrumental + vocal?</span></p><p class="c1"><span class="c0">- IDK, but I don&#39;t think that will be enough input to get some great results, you could try though [good models so far have varying genres and artists in the dataset, not just one].</span></p><p class="c1"><span class="c0">- If you need some help setting it up, Kimberly (yes, she&#39;s the one who created Kim_vocal_1 model, based on an instrumental model by Anjok),</span></p><p class="c1"><span class="c0">you can ask her (@)KimberleyJSN.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">MDX-Net 2023 (v3) a.k.a. MDX23C</span><span class="c0">&nbsp;(not always better than v2)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035744839317&amp;usg=AOvVaw04IgjqEJn3WZyRrp8EmHRm">https://github.com/ZFTurbo/Music-Source-Separation-Training</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">OG repo:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/kuielab/sdx23&amp;sa=D&amp;source=editors&amp;ust=1765035744839587&amp;usg=AOvVaw3k1J9gvN_2gTfCqHCItOFa">https://github.com/kuielab/sdx23</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Lots of general optimizations to the quality while keeping decent training and separation performance. Theoretically the go-to architecture over MDX-Net v2, although currently SAMI Bytedance reimplementation (under VR section below) has much less bleedy results for much more compute intensiveness. It was used for trained models by ZFTurbo. On the same if not better dataset than previous V1 models, it received not much worse SDR than V1 arch for narrowband, but with much fuller vocals, although with more bleeding (also in instrumentals). For fullband, SDR was high enough to surpass previous models, but SDR stopped reflecting bleeding on multisong dataset.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;It doesn&#39;t need pairs anymore.</span></p><p class="c1"><span class="c0">This... is HUGE.</span></p><p class="c1"><span class="c0">It randomizes chunks of 6 seconds from random instrumental and random vocal to learn from.</span></p><p class="c1"><span class="c0">In other words, no more need to find the instrumental+vocal for track x.</span></p><p class="c1"><span class="c0">Just plump in any proper acapella or instrumental u can find.</span></p><p class="c1"><span class="c0">The downside so far is the validation.</span></p><p class="c1"><span class="c0">It takes way longer.&quot; so you might be able to perform evaluation per only, e.g. 50 epochs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Dataset structure looks like</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- train folder &gt; folders with pairs &gt; other.wav + vocals.wav</span></p><p class="c1"><span class="c0">- validation folder &gt; folders with pairs &gt; other.wav + vocals.wav + mixture.wav&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Libsnd can read FLACs when renamed to WAV. It can save a lot of space.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I think in the old MDX-Net, we didn&#39;t have a model with not worse SDR than epoch greater than 464, although 496 with lower SDR also had its own unique qualities (though more vocal residues at times). Also, frequently training is ended on epoch 300, and might not progress SDR-wise for a long time (maybe till 400+).</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/911050124661227542/1136258986677645362/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035744843238&amp;usg=AOvVaw1sn30f2BPI4LLUl9s3Ruul">https://cdn.discordapp.com/attachments/911050124661227542/1136258986677645362/image.png</a></span><span>&nbsp;(dead)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(written before Roformers) We may already be hitting the wall SDR-wise, as Bas once conducted an experiment with training a model consisting dataset made of the dataset evaluation and the result was only 0.31 higher than the best current ensemble (although it used lower parameters for separation). Generally, to break through that wall, we may need to utilize multi-GPU with batch size &ldquo;16 or even 8&rdquo;.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;If you did this experiment with batch size 16 or even 8 you would see much better performance I think&rdquo; - Kim</span></p><p class="c1"><span class="c0">&ldquo;mhm but that requires multi GPU&rdquo; - Bas</span></p><p class="c1"><span class="c0">&ldquo;yeah that is the wall I think&rdquo; - Kim</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;at least for vocals, using the default 8192 n_fft for mdx23c and reducing hop_length from 2048 to 1024 gave better results (it&#39;s InstVocHQ config iirc).</span></p><p class="c1"><span class="c0">In mdx23c paper, they got better score with higher n_fft/hop_length resolution. <br>Hop_length means the portion of audio that will NOT be overlapped during STFT processing. So the lower, the higher overlap you get in the end. And a bit like the overlap we are doing during inference (which is different, as applied on waveform, on way larger scale) but in the same way, the higher overlap you use, the higher quality you get, but at cost of more resources, and at some point it gets stagnant (or could even reduce quality too if set too high)&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For &ldquo;ringing and unpleasant artifacts at subband edges, (...) more of a dip, that seems to get filled progressively along training&rdquo;</span></p><p class="c1"><span class="c0">&gt; &ldquo;It seems like overlapped subbands is the thing (not surprised about it) but the dips are maybe a bug, I&#39;ll see if I can improve that.</span></p><p class="c1"><span class="c0">I&#39;m still experimenting to find best way to alleviate the subband artifacts of mdx23c, but here&#39;s an already working fork with separatable depthwise convs (model size is divided by &plusmn;6)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1lgZRtKMqzWbbFnpxhn_QWkzH8EAx1HuT/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744846636&amp;usg=AOvVaw2-sF6BfeZ4xWkKYrqLWa-S">DL</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">- &ldquo;[The] opposite to BS/Mel Rofos, the more you have sub-bands with mdx23c the less resources needed to train a model (until quick collapse of the model if too much sub-bands used, from what I&#39;ve experimented until now)&rdquo; - -||-</span></p><p class="c1"><span class="c0">Frazer: &ldquo;wouldn&#39;t another fix be to change how the transposed convolutions work? So that the input to the TConv includes the other bands first or last N indices</span></p><p class="c1"><span class="c0">then crop it out afterward or sum/avg those extra indices </span></p><p class="c1"><span>surely if what&#39;s happening is that as the bands are downsampled either they drop indices at the edges because it&#39;s not a perfect crop or that for whatever reason the latents at the edges don&#39;t receive proper gradients and don&#39;t optimize - then accounting for that by either expanding input bands or allowing the convs to work on the borders maybe fix it. I like your idea more, it&#39;s cleaner, but I&#39;m just trying to come up with some system where it&#39;s cheaper than just having bigger bands, yk. I mean, your system would fix it, but I think you&#39;d need to probably drop some indices right near the border on the expanded bands since those would be broken in the same way as they are currently, if that makes sense&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/TMJCymC&amp;sa=D&amp;source=editors&amp;ust=1765035744848624&amp;usg=AOvVaw1_o6SisHrWZGs_Fu7Yu0ph">artefacts</a></span></p><p class="c1"><span class="c0">[the modified code] Confirmed with vanilla OG mdx23c code, with only that change and nothing else.&rdquo;</span></p><p class="c1"><span class="c0">Q: How about changing it to a depthwise separable convolution + pointwise convolution?</span></p><p class="c1"><span class="c0">A: &ldquo;That&#39;s what I&#39;ve done with my latest version. </span></p><p class="c1"><span>Duplications &ldquo;kinda back, differently but still can lead to similar audible ringing artifacts with some configs. Taking it from the opposite side: if it&#39;s the low band high energy the issue, reduce the low band high energy (using preemphasis and deemphasis - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/BMUrnqM&amp;sa=D&amp;source=editors&amp;ust=1765035744849885&amp;usg=AOvVaw18j2hjOMzcUYmNO1m1KSsk">pic</a></span><span class="c0">). It seems to get rid of the duplicated stuff and ringing artifacts at training start.</span></p><p class="c1 c7"><span class="c0"><br></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.dynxs41r18u3"><span class="c18 c15">Colab for training MDX23C model (on free T4)</span></h6><p class="c1"><span class="c0">&ldquo;Can&#39;t train multistem model because of limited resources of Colab, so it&#39;s one by one.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s only 1x Tesla T4, 15GB VRAM so lots of [GPUs] can be [much] better!</span></p><p class="c1"><span class="c0">I can run batch_size = 8 with it</span></p><p class="c1"><span class="c0">(with n_fft=2048 instead of 8192 in the model config; other archs are using n_fft=2048 too [Demucs, Rofos&hellip;]).</span></p><p class="c1"><span class="c0">When you use full runtime credits one day, the day after, you get only 1h10min GPU time (2 epochs.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1. It&#39;s really boring to do</span></p><p class="c1"><span class="c0">2. You must have multiple Google accounts</span></p><p class="c1"><span class="c0">3. You must have a dataset and host it on GDrive and share it with all the accounts (and making it accessible at root for each account)</span></p><p class="c1"><span>4. Use this fork of ZFTurbo&#39;s training script that is allowing better resuming, which is required for Colab as sessions are deleted after 3h~4h max (often less) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jarredou/Music-Source-Separation-Training/tree/wandb%252Bresume&amp;sa=D&amp;source=editors&amp;ust=1765035744852233&amp;usg=AOvVaw2k87TrtVLWcNLWnHxf5wB8">https://github.com/jarredou/Music-Source-Separation-Training/tree/wandb%2Bresume</a></span></p><p class="c1"><span>5. Edit this config baseline accordingly to your dataset/needs (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1xl7pe8Atv89X6yt0siIqcVBH1S6l9btK/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744852520&amp;usg=AOvVaw028XNwjnwTo-E8k8L9pQeX">click</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">6. Set parameters accordingly, gdrive connection and run.</span></p><p class="c1"><span class="c0">7. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun. When you&#39;ve burnt all credits from one account, switch and rerun.... and do that 7 loop for weeks.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I&#39;ve started this experiment just to see if a lightweight mdx23c model could be trained with free Colab, but as I saw it was quickly achieving higher SDR than drumsep on my tiny eval dataset, I&#39;m continuing the training, it&#39;s almost at 18SDR now for kick&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Any particular reason why the num steps is 1268 instead of 1000? Is that a random number or a calculation?</span></p><p class="c1"><span class="c0">A: I&#39;ve read that it&#39;s better to use a multiple of the number of tracks in the dataset (here 317 * 4) To avoid that some of the tracks are used more than others at each epoch. (jarredou)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">jarredou/Aufr33 drumsep model was trained with 3 seconds chunks.</span></p><p class="c1"><span><br>- Here you can find </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1EZP6tPoaZzm3NjEum4wj6-7E3cVWOHeO?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744855259&amp;usg=AOvVaw2gbpMpPtUcW-GeubvzhOqR">Colab</a></span><span>&nbsp;</span><span class="c0">made by yukunelatyh (dead)<br></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/17SSjougcnVhX6WewW88QoKKFuFiKNz8t?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744855496&amp;usg=AOvVaw0smL7gOk9NHq5Bqg7GNjLU">Colab</a></span><span class="c0">&nbsp;by jazzpear96 (with the OG MSST repo; maybe you could just replace the link)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I think later I quote jarredou on training with extremely low parameters configs on other archs as well.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708912597239332866/1225994922822467674&amp;sa=D&amp;source=editors&amp;ust=1765035744856084&amp;usg=AOvVaw3Gs_OK-D-a6J5QCGxDBxHI">Here</a></span><span>&nbsp;</span><span>the community guide one user on training on 3060 12GB (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/ZPtAU5R6rP&amp;sa=D&amp;source=editors&amp;ust=1765035744856264&amp;usg=AOvVaw3QnuKAfw1TfcJjhgWwbJ9l">invite</a></span><span class="c0">)<br>____</span></p><p class="c1"><span class="c42 c15 c36 c37 c30">JFI -</span></p><p class="c1"><span class="c42 c15 c36 c37 c30">Multi Source Diffusion </span></p><p class="c1"><span class="c4 c37"><a class="c3" href="https://www.google.com/url?q=https://github.com/gladia-research-group/multi-source-diffusion-models&amp;sa=D&amp;source=editors&amp;ust=1765035744856737&amp;usg=AOvVaw2kDCFc8zu0UzS_atvn0_bB">https://github.com/gladia-research-group/multi-source-diffusion-models</a></span></p><p class="c1"><span class="c37">Some results posted by Bytadance were labelled as &ldquo;MSS&rdquo; but it&rsquo;s rather not the same arch. In the original MSS paper above, only </span><span class="c11 c38">Slakh2100</span><span class="c42 c15 c36 c37 c30">&nbsp;was used. </span></p><p class="c1"><span class="c42 c15 c36 c37 c30">ByteDance probably expanded it further, and had it was said they had issues with their legal department with making their work public, so they can equally use unauthorized stems just like us, or looking for ways to monetize their new discovery for TikTok, as their company largely invest in GPUs lately, so something might happen maybe in the end of the year, and maybe it will be released in their exclusive service (Ripple and Capcut were released later indeed). TBH, it&#39;s hard to get a good model using only public datasets. For public archs, it&#39;s even impossible. They probably know it too, so it&rsquo;s kinda grey zone, sadly, and model trained later for Ripple was probably done from scratch and contains only lossy files for training from now on.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Bytedance (Ripple too?) was said to train on 500 songs only + MUSDBHQ </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c18 c15"></span></p><h6 class="c1 c27" id="h.9i8359eysaoe"><span class="c18 c15">BS-Roformer</span></h6><p class="c1"><span>(one of) The best, but the slowest tested arch out of the all in this doc SDR-wise. Once considered as SOTA (state-of-the-art algorithm), but it has its own caveats, like very strong denoising (which is double-edged sword and might give too muddy results frequently), but using Mel-Roformer and proper config tweaks and prioritizing stem there helped for the muddiness issues. Also, Mel-Roformer has a bigger SDR according to the Mel paper (with an exception for bass), and it&rsquo;s better for vocals than BS. Plus, Mel seems to handle creating duet singing separation model better. &ldquo;BS (...) uses more VRAM; unlike Mel, BS has no overlap between bands, so VRAM usage and model size are smaller.&rdquo; Unwa More below.<br><br>&ldquo;I find it cute how they call the Transformer based models (which destroy the older convnets) &quot;Roformers&quot; because they use RoPE embeddings. By that naming scheme, all llama-like models are Roformers too...&rdquo; kalomaze<br>&ldquo;By the way, it wasn&#39;t us who started calling Transformer using RoPE &quot;Roformer.<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2104.09864&amp;sa=D&amp;source=editors&amp;ust=1765035744860287&amp;usg=AOvVaw0-SNbUg9OsbdL1ivBtWJUJ">https://arxiv.org/abs/2104.09864</a></span></p><p class="c1"><span class="c0">MelBand-Roformer and BS-Roformer may also be considered as generative objective models in a sense. The goal of these models is to generate a mask to extract the desired stem from the mixed source&quot; unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lucidrains/BS-RoFormer&amp;sa=D&amp;source=editors&amp;ust=1765035744860831&amp;usg=AOvVaw00SSgOTIrdZPg3uuMc2Aw6">https://github.com/lucidrains/BS-RoFormer</a></span><span>&nbsp;(it incorporates both BS and Mel variants, implemented in MSST training repo)</span></p><p class="c1"><span class="c0">It&rsquo;s safe to say it&rsquo;s SAMI Bytedance arch from MVSEP chart reimplemented from their paper - done by lucidrains. </span></p><p class="c1"><span class="c0">Arch papers:</span></p><p class="c1"><span>BS (band split): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2211.11917&amp;sa=D&amp;source=editors&amp;ust=1765035744861376&amp;usg=AOvVaw1n5pRvBoWEQIsfmMKw_Zfz">https://arxiv.org/abs/2211.11917</a></span></p><p class="c1"><span>Mel (mel scale): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2310.01809.pdf&amp;sa=D&amp;source=editors&amp;ust=1765035744861566&amp;usg=AOvVaw2ll5x5mtexoZMUYU7mHF0d">https://arxiv.org/pdf/2310.01809.pdf</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Bytedance didn&#39;t give any info of training duration for these scores, but in their last [ISMIR2024] paper for Mel-Roformer:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2409.04702&amp;sa=D&amp;source=editors&amp;ust=1765035744862033&amp;usg=AOvVaw0Vn9d_qSjdeANe16JIO_8p">https://arxiv.org/abs/2409.04702</a></span></p><p class="c1"><span class="c0">with L=12, they get 12.08 SDR on vocals with Musdb-only by using :</span></p><p class="c1"><span class="c0">8 Nvidia A-100-80GB GPUs with batch_size=64, and the training stopped at 400K steps (~40 days).&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">32x V100 will require two months of training (most likely for 500 songs only + MUSDBHQ)</span></p><p class="c1"><span class="c0">&ldquo;It&rsquo;s better to have 16-A100-80G&rdquo;, viperx trained BS-Roformer with 4500 songs on 8xA100-80GB and after 4 days achieved epoch 74, and on epoch 162 achieved only 0,0467 better SDR for instrumental.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">ZFTurbo having 4x A6000 gave up training on it, having to face 1 year of training time.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>After the BS variant, </span><span class="c4 c22"><a class="c3" href="https://www.google.com/url?q=https://github.com/lucidrains/BS-RoFormer/tree/main/bs_roformer&amp;sa=D&amp;source=editors&amp;ust=1765035744863319&amp;usg=AOvVaw1itsL0rOOEk13wuZLmZiGD">Mel-Band RoFormer</a></span><span class="c0">&nbsp;based on the band split was released (&ldquo;Mel-Roformer uses a Mel-Band spectrogram whereas BS-Roformer doesn&#39;t&rdquo;), which is faster. Initially it achieved worse SDR than BS-Roformer than on the paper. But it was till Kimberley Jensen released her new Mel model, and by the occasion, tweaked config in a way that it made the SDR on pair with BS variant, but presumably, by training on even smaller dataset.</span></p><p class="c1"><span class="c0">Later, viperx trained drums only model, both on BS and Mel-Roformer, and BS-Roformer was still slightly better, but there wasn&rsquo;t such a difference between both anymore (12.52 vs 12.40 SDR).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Main diff is that BandSplit is using linear Hertz scale for frequency splitting while MelBand is using Mel scale (which is a more close representation of how humans are hearing frequency distances than linear Hertz scale).</span></p><p class="c1"><span class="c0">MelBand matrixing is by design using overlapping frequency bands, while with BS, there&#39;s no overlap in the frequency range.&rdquo; jarredou</span></p><p class="c1"><span class="c0">&ldquo;remember, just because the melscale is more perceptual, it doesn&#39;t necessarily translate into the neural net learning the representation better. It might be a good idea to use a modified zipformer&rdquo; frazer</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">Kim&rsquo;s Mel training</span><span>&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Bx1UpCCtWbANF8V-mGkWrrDpefaO2P4g/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744865482&amp;usg=AOvVaw3dfSFJinkbJPVZpR6B9-6b">config</a></span><span>&nbsp;</span><span class="c0">made for H100 (model on x-minus was trained for 3 weeks) which viperx probably used later for drums model or reworked for his GPU.</span></p><p class="c1"><span class="c0">Kims says 5.0e-05 is already low enough learning rate, setting it too low may make it too slow to train. Kim &ldquo;also said that during the end of her training the loss would plateau but the SDR was improving&rdquo;, &ldquo;no patience, no LRreduceonpleateau at all. While, if set incorrectly, it can ruin your training very quickly&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>With the unwa&rsquo;s inst v1 model it turned out, prioritizing stem in the config matters a lot, so depending on which model you want (other, instrumental, null, multistem like in duality models or vocal) that&rsquo;s what you should set in the config. Although, prioritizing stem to instrumental gave a noise similar to VR or MDX-Net v2 models (but not the same). We ended up with the </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JOa198ALJ0SnEreCq2y2kVj-sktvPePy?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035744867006&amp;usg=AOvVaw3eSUbHo56lKHRkas9JKdNz">code</a></span><span>&nbsp;</span><span>based on Aufr33 idea, recreated by Becruily, that copies phase from Mel-Kim model which is deprived of the noise and doesn&rsquo;t prioritize vocal stem like unwa inst 1/1e/v2 models, and it gets rid of some noise in those models. Aufr33 own implementation is added in ensemble on x-minus.pro/uvronline and in UVR latest patches there&rsquo;s becruily </span><span class="c4"><a class="c3" href="#h.j14b9cv2s5d9">script</a></span><span class="c0">&nbsp;rewrite.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">According to mesk, fine-tuning a fine-tuned model might be a worse solution than simply fine-tuning the Kim&#39;s model (from experience on training on genre-oriented dataset like metal which Mesk tried to train).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;I got an error when I set num_stems to 2.&rdquo; unwa<br>You can use &ldquo;target_instrument: null&rdquo; instead, which is also required for multistem training like on </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/eOSW8I7&amp;sa=D&amp;source=editors&amp;ust=1765035744868392&amp;usg=AOvVaw0fCCJigNNQqISfLZrJf7HY">this</a></span><span>&nbsp;</span><span class="c0">example ~jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;increasing num_stems increases model size&rdquo; &ldquo;multistem is like having multiple checkpoints in one file (1 for each stem). All model types work like that with ZFTurbo&#39;s script AFAIK&rdquo; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">use_torch_checkpoint: true</span></p><p class="c1"><span class="c0">in the current MSST repo will reduce VRAM usage.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Using various chunk_size during different stages of the training can be helpful, and also using different dataset sizes based (e.g. leaving only more clean or official at certain points).</span></p><p class="c1"><span class="c0"><br>___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">First BS-Roformer models were trained on ZFTurbo dataset, later viperx trained on his own, presumably larger dataset (and possibly better GPU) and achieved better SDR, then another model was made from fine-tuning viperx model on ZFTurbo dataset, and Kim&rsquo;s Mel model was trained on Aufr33 dataset from UVR, later Unwa trained on Bas Curtiz&rsquo; dataset (?too).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can use ZFTurbo code as base for training Roformers:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035744870461&amp;usg=AOvVaw1cdVZ9TfqMnAvRS6zx7x_z">https://github.com/ZFTurbo/Music-Source-Separation-Training</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;change the batch size in config tho</span></p><p class="c1"><span class="c0">I think ZFTurbo sets the default config suited for a single a6000 (48gb)</span></p><p class="c1"><span>and chunksize&rdquo; joowon</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So, to sum up, BS-Roformer is the best publicly available arch SDR-wise for now (and in practice, Mel-Roformer scores a bit lower on the same datasets with the same public code we currently have), although both are very, very demanding compared to MDX23C or MDX-Net v2 or VR (voice-remover by tsurumeso).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">E.g. Aufr33 said that BS Roformer turned out to be better for training BVE model. &ldquo;Although I get about zero or even negative SDR with both, the BS does the job better.</span></p><p class="c1"><span class="c0">Maybe it&#39;s not the architecture but the augmentation, I disabled it for BS &rdquo;. Some other explanations:</span></p><p class="c1"><span class="c0">&ldquo;In BS-Roformer they don&#39;t do any downsampling or compression&rdquo; hence it&rsquo;s so slow to train.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I&#39;ve noticed that it separates mono (i.e., panned in the center) harmonies well if the two voices belong to different people, and much worse if it&#39;s the same singer (even though they differ by a third interval). </span></p><p class="c1"><span class="c0">This leads me to believe that the BS architecture would work well for separating female and male voices.&rdquo; (after some problems with SDR being in the region of 0 or 1) &ldquo;I have another thought. Roformer works differently with stereo, not like VR. It&#39;s like it partially merges channels, which is bad for backing vocal detection. It seems to me that using a stereo expander would help.&rdquo; Aufr33. Eventually he later started the training Mel from scratch on 4x RTX 6000 Ada using stereo expander and that lower training rte, and eventually it started to increase SDR, but later negative value was showing, and he continued training BS and SDR was above 1, but it stopped progressing, &ldquo;It seems that 525 songs is not enough to train a [BS/Mel] model.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Some things here can be outdated already, as some optimizations were introduced to the training code (read more below):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">__</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Time-wise, BS vs Mel, instead of 16x a100 in BS-Roformer, it might be like 14x a100 to train in decent time, but at best, without the config tweak, SDR will be only in pair with MDX23 and MDX-Net archs v2 archs, and BS-Roformer will achieve better SDR than Mel-Band. Might be some issue in Mel-Band Roformer reimplementation, maybe paper lacking something. Only in BS-Roformer some of the original authors from Bytedance took part in some reviewing of the reimplementation code made by lucidrains.</span></p><p class="c1"><span class="c0">On Mel-Band, epoch 3005 took 40 days on 2xA100-40GB with the previous viperx model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Viperx trained their own vocal model, using BS-Roformer on +4500 songs (studio stems * +270h) using 8xA100-80GB, and only on epoch 74 they almost surpassed sami-bytedance-v.0.1.1 result (which was actually multistem model iirc), achieving 16.9279 for instrumental, and 10.6204 for vocals.</span></p><p class="c1"><span class="c0">With epoch 162, they achieved 16.9746 and 10.6671, which for instrumental, is now only 0,0017 difference in SDR vs v.0.11 result.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Training settings:</span></p><p class="c1"><span class="c0">chunk_size 7.99s</span></p><p class="c1"><span class="c0">dim 512 / depth 12</span></p><p class="c1"><span class="c0">Total params: 159,758,796</span></p><p class="c1"><span class="c0">batch_size 16</span></p><p class="c1"><span class="c0">gradient_accumulation_steps: 1</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Since epoch 74 there were &ldquo;added +126 songs to my dataset&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Training progress:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://ibb.co/1zfFX82&amp;sa=D&amp;source=editors&amp;ust=1765035744876574&amp;usg=AOvVaw0S5qv8q-Bw1Mc4-4KeyFtb">https://ibb.co/1zfFX82</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Source:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://web.archive.org/web/20240126220641/https://mvsep.com/quality_checker/multisong_leaderboard?sort%3Dinstrum&amp;sa=D&amp;source=editors&amp;ust=1765035744877092&amp;usg=AOvVaw0h3ZxkjvCbrWHANjUaG65F">https://web.archive.org/web/20240126220641/https://mvsep.com/quality_checker/multisong_leaderboard?sort=instrum</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://web.archive.org/web/20240126220559/https://mvsep.com/quality_checker/entry/5883&amp;sa=D&amp;source=editors&amp;ust=1765035744877392&amp;usg=AOvVaw07WY4KJfYhdam-jyjAnzoe">https://web.archive.org/web/20240126220559/https://mvsep.com/quality_checker/entry/5883</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It sounds similarly to the Ripple model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;7 days training on 8xA100-80GB&quot;: 7\*24\*15.12 (runpod 8xa100 pricing) = $2540.16&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">viperx trained on dataset type 2, meaning that he had 2 folders:</span></p><p class="c1"><span class="c0">vocals and other and no augmentations</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;For more detailed infos, you can read ZFTurbo&#39;s doc about dataset types handled by his script </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/dataset_types.md&amp;sa=D&amp;source=editors&amp;ust=1765035744878645&amp;usg=AOvVaw0cp5FuXuETfOe9Ym322WQZ">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/dataset_types.md</a></span><span>&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">viperx trained on faster Mel-Roformer arch variant before, and on epoch 3005 trained 40 days on 2xA100-40GB with 4500 songs, he achieved only 16.0136 for instrumentals, and 9.7061 which is in pair with MDX-Net voc_ft model (2021 arch). </span></p><p class="c1"><span class="c0">&ldquo;Each epoch [in Mel-Roformer] with 600 steps took approximately 7 to 10 minutes, while epochs with 1000 steps took around 14 to 15 minutes. These are estimated times.</span></p><p class="c1"><span>Initially, I suspected that the SDR was not improving due to using only 2xA100- 40GB &nbsp;GPUs. After conducting tests with 8 x 80GB A100 GPUs, I observed that the SDR remained stagnant, suggesting that the issue might be related to an error in the implementation of the Mel-Roformer architecture.&rdquo; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/6019&amp;sa=D&amp;source=editors&amp;ust=1765035744880147&amp;usg=AOvVaw3lXML45v9cFiN9JAWTs4-g">More info</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://web.archive.org/web/20240211181707/https://mvsep.com/quality_checker/entry/6016&amp;sa=D&amp;source=editors&amp;ust=1765035744880309&amp;usg=AOvVaw3wPK7BVGYiyjJJeKOSCJw6">copy</a></span><span>)</span><span class="c0">. Probably it was the issue (at least partially?) fixed by Kim config tweaks.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Later, the viperx&rsquo; BS-Roformer model was further trained from checkpoint by ZFTurbo, and it surpassed all the previously released models, and even ensembles, at least SDR-wise. Then it was finetuned on different dataset. Still, as all Roformers, it might share some characteristic features, like occasional muddiness, and filtered sound at times, but Mel variant seems to be less muddy.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">More insides:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lucidrains/BS-RoFormer/issues/4%23issuecomment-1738604015&amp;sa=D&amp;source=editors&amp;ust=1765035744881840&amp;usg=AOvVaw3BKJr5UkvVJCiN-zsYNhiW">https://github.com/lucidrains/BS-RoFormer/issues/4#issuecomment-1738604015</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1156700109682262129/image.png?ex%3D6516952c%26is%3D651543ac%26hm%3D988a5acc32f075988c1701d41c2090321a25955c4ffedd64516e0062fa1002e0&amp;sa=D&amp;source=editors&amp;ust=1765035744882422&amp;usg=AOvVaw0bolQ8UONadHW2b5XtGB3U">https://media.discordapp.net/attachments/708579735583588366/1156700109682262129/image.png?ex=6516952c&amp;is=651543ac&amp;hm=988a5acc32f075988c1701d41c2090321a25955c4ffedd64516e0062fa1002e0</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1156700305069707315/image.png?ex%3D6516955b%26is%3D651543db%26hm%3Dbf5737f95f3a93fd3e3a23a679e2ad0031e0feb6c622fbb85eafa053ed483e08&amp;sa=D&amp;source=editors&amp;ust=1765035744882950&amp;usg=AOvVaw2lwONJXj0hkeRKbqtEMsdg">https://cdn.discordapp.com/attachments/708579735583588366/1156700305069707315/image.png?ex=6516955b&amp;is=651543db&amp;hm=bf5737f95f3a93fd3e3a23a679e2ad0031e0feb6c622fbb85eafa053ed483e08</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://media.discordapp.net/attachments/708579735583588366/1156700453585829898/image.png?ex%3D6516957e%26is%3D651543fe%26hm%3D06ed766b39c3c7f4a8329420a22bcc572e856116a6e1cea030d158c984c46825&amp;sa=D&amp;source=editors&amp;ust=1765035744883458&amp;usg=AOvVaw0DOwc1m9_GDQDAhs-rcBif">https://media.discordapp.net/attachments/708579735583588366/1156700453585829898/image.png?ex=6516957e&amp;is=651543fe&amp;hm=06ed766b39c3c7f4a8329420a22bcc572e856116a6e1cea030d158c984c46825</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.nhtzgvin9aoh"><span class="c22">More h</span><span class="c18 c15">ints/FAQ for training Roformers</span></h6><p class="c1"><span class="c0"><br>ZFTurbo:</span></p><p class="c1"><span class="c0">&quot;1) Best [BS-Roformer] model with the best parameters can be trained only on A100, and you need several GPUs. The best is use 8. It reduces possibilities of training by enthusiasts. </span></p><p class="c1"><span class="c0">[later it was found out that checkpointing decreased VRAM usage allowing using probably more modest GPUs]</span></p><p class="c1"><span class="c0">All other models like HTDemucs or MDX23C can be trained on single GPU. Lower parameter BS-Roformers don&#39;t give the best results. But maybe it&#39;s possible. Solution: </span></p><p class="c1"><span class="c0">We need to try train smaller version which will be equal to current big version. Lower depth, lower dim, less chunk_size. We need to achieve at least batch 4 for single GPU. Having such model can be useful as starting point for fine-tuning for other tasks/stems</span></p><p class="c1"><span class="c0">[perhaps Unwa&rsquo;s 400MB exp value residue model meets that requirements).</span></p><p class="c1"><span class="c0">2) I also noticed a strange problem I didn&#39;t solve yet. If you try to finetune version trained on A100 on some cards other than A100 then SDR drops to zero after first epoch. Looks like &quot;Flash attention&quot; has some differences (???).</span></p><p class="c1"><span class="c0">3) Training is extremely slow. And I noticed BS-Roformer more sensitive to some errors in dataset.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">[probably for 4090]</span></p><p class="c1"><span class="c0">chunk_size: 131584</span></p><p class="c1"><span class="c0">dim: 256</span></p><p class="c1"><span class="c0">depth: 6</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I think these settings can give batch_size &gt; 4</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For example, I can&#39;t finetune viperx model on my computer with 48GB A6000 because the model is too large.</span></p><p class="c1"><span class="c0">chunk_size is what affect model size the most, I think. And I saw it&#39;s possible to get good result with small chunk size.</span></p><p class="c1"><span class="c0">I put the table here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/bs_roformer_info.md&amp;sa=D&amp;source=editors&amp;ust=1765035744887042&amp;usg=AOvVaw0KJU6EYyyLy8frBeTwHFLe">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/bs_roformer_info.md</a></span><span class="c0">&rdquo; </span></p><p class="c1"><span>[see also </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://lambdalabs.com/gpu-benchmarks&amp;sa=D&amp;source=editors&amp;ust=1765035744887278&amp;usg=AOvVaw36zk3LoCDjcGENvG5V2Ib5">https://lambdalabs.com/gpu-benchmarks</a></span><span class="c0">&nbsp;batch size chosen in Metric, fp16, but ZFTurbo said that training on fp32 is also possible]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The 0 SDR issue was later fixed: &ldquo;the non A100 issue is fixed with latest torch, but I think the general rule is that batch size 1 (like in my case with 3090) won&#39;t give good results on Roformers.</span></p><p class="c1"><span class="c0">But I&rsquo;ve been doing batch size 2-4 with A6000 and A100 and no issues there.</span></p><p class="c1"><span class="c0">But the model is also large, when I finetuned a smaller Mel-Roformer the 3090 worked there&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Full sized Roformers are very heavy to train and unless you have crazy hardware like A6000 (the very minimum), A100 etc, training from scratch will take months to get a good model (with SDR similar to current ones, and this is without considering the dataset).</span></p><p class="c1"><span class="c0">Maybe someone with 4090 can give more insight, but I personally can&#39;t train/finetune a full sized Roformer model with my 3090, it&#39;s way too weak, I&#39;d have to make the model smaller meaning the quality won&#39;t be as good as the original checkpoint&rdquo; becruiily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Can we change model size of existing model and fine tune it? Or it must have been trained from scratch with the same chunk size </span></p><p class="c1"><span class="c0">A: 1) If you just decrease chunk size, it will work almost the same as with larger (as I remember)</span></p><p class="c1"><span class="c0">2) If you decrease dim or depth, score will drop very much&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Don&#39;t forget, each time you change something in dataset, you have to delete metadata_x.pkl file to create new database on training launch taking into account new changes (it made me become crazy during my first tests when forgetting to delete it)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I&#39;ve just checked ZFTurbo&#39;s code, and for dataset type 2, the &quot;.wav&quot; extension is still required for the script to find the files (it doesn&#39;t work with any other)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: It is possible to finetune on 3080 Ti 8GB? unwa did it [on 3070 Ti 8GB]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: &ldquo;By reducing the chunk_size and using AdamW8bit for the optimizer, I was able to train even with 8GB of VRAM.&rdquo; Usually such fine tune on inferior GPU was decreasing SDR. Here it only dropped by 0.1 SDR after few thousands steps of training (so only a few epochs) on musdb18hq+moises+original dataset (41 songs (In total, 432 tracks, 16.5GB, FLAC, very small dataset, OG was trained on 5K songs) ~becruily</span></p><p class="c1"><span class="c0">Used config to finetune:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1gK1_n_bpRHD1i02VA2bgUc3TrpEJUcg9/view?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035744892019&amp;usg=AOvVaw00VKgq6QOjwZFNMruxhfRO">https://drive.google.com/file/d/1gK1_n_bpRHD1i02VA2bgUc3TrpEJUcg9/view?usp=drive_link</a></span></p><p class="c1"><span class="c0">train.py with optimizer (probably it&#39;s already integrated into MSST code):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1jLSTDajYxZRSb5wLOwyVuRJrayNLIWUZ/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035744892533&amp;usg=AOvVaw3upEieBuJN_go_sBpjlem9">https://drive.google.com/file/d/1jLSTDajYxZRSb5wLOwyVuRJrayNLIWUZ/view?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Changes were pushed to ZFTurbo training dataset, but the optimizer turned out to not save too much VRAM (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1268191215875129387&amp;sa=D&amp;source=editors&amp;ust=1765035744892913&amp;usg=AOvVaw20tbywmhg_oXQozxd_5WA9">diagram</a></span><span class="c0">). </span></p><p class="c1"><span class="c0">&ldquo;&#39;adamw8bit&#39; for training.optimizer in config). Also added possibility to provide optimizer parameters in config file using keyword &#39;optimizer&#39;.&rdquo; ZFTurbo<br>Optimizers explained later below.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">And it&rsquo;s not enough to point the model trained by unwa turned out to have the same 0 SDR issue becruily had, but unwa didn&rsquo;t notice it due to lack of validation dataset. So inference worked correctly despite 0 SDR, but the model was getting worse gradually during finetuning.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Frazer suggestion (probably already implemented by ZFTurbo):</span></p><p class="c1"><span class="c0">&ldquo;I think the issue with the checkpointing / 0 SDR bug is due to </span></p><p class="c1"><span class="c0"><br>|At least one input and output must have requires_grad=True for the reentrant variant. If this |condition is unmet, the checkpointed part of the model will not have gradients. The |non-reentrant version does not have this requirement.</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">So I think the fix is either assigning </span></p><p class="c1"><span class="c6">x.requires_grad=True</span></p><p class="c1"><span class="c0">&nbsp;in train.py to the batch tensor before passing into the model </span></p><p class="c1"><span class="c0">or passing </span></p><p class="c1"><span class="c6">use_reentrant=False</span></p><p class="c1"><span class="c0">&nbsp;to all torch.utils.checkpoint.checkpoint calls</span></p><p class="c1"><span class="c0">I think it&#39;s probably better to use the non-reentrant variant, since Pytorch will default to this in later versions</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pytorch.org/docs/2.1/checkpoint.html%23torch.utils.checkpoint.checkpoint&amp;sa=D&amp;source=editors&amp;ust=1765035744895753&amp;usg=AOvVaw1JYsMMEr3gWszdsfIFb70h">https://pytorch.org/docs/2.1/checkpoint.html#torch.utils.checkpoint.checkpoint</a></span></p><p class="c1"><span class="c0">also this point here looks interesting to test whether it causes a significant performance hit or not</span></p><p class="c1"><span class="c0">|The logic to stash and restore RNG states can incur a moderate performance hit depending |on the runtime of checkpointed operations. If deterministic output compared to |non-checkpointed passes is not required, supply preserve_rng_state=False to checkpoint or |checkpoint_sequential to omit stashing and restoring the RNG state during each |checkpoint.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- It was discovered, that using different chunk_sizes at various stages of training can be beneficial (iirc esp. for training time at initial stages without much SDR sacrifice).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;I added code to train using accelerate module:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/train_accelerate.py&amp;sa=D&amp;source=editors&amp;ust=1765035744898122&amp;usg=AOvVaw2D4qQszQtmTeiZL5c4A4ja">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/train_accelerate.py</a></span></p><p class="c1"><span class="c0">It&#39;s useful on multi GPU systems. In my experiments, speed improved ~50%.</span></p><p class="c1"><span class="c0">~1.57 sec per iteration goes down to ~1.07 sec per iteration. </span></p><p class="c1"><span class="c0">But I think the script has some flaws - my validation score during training is lower than in reality. I didn&#39;t find the reason yet.</span></p><p class="c1"><span class="c0">Also, script allows training across multiple machines without changes in code. </span></p><p class="c1"><span class="c0">More information here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/docs/accelerate/index&amp;sa=D&amp;source=editors&amp;ust=1765035744899721&amp;usg=AOvVaw2w_z1nb-ilpYdK121MKDHD">https://huggingface.co/docs/accelerate/index</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/docs/accelerate/quicktour&amp;sa=D&amp;source=editors&amp;ust=1765035744900070&amp;usg=AOvVaw1pdXDo7mWEbR_m369WAPkx">https://huggingface.co/docs/accelerate/quicktour</a></span><span class="c0">&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- What unwa said later in October 2024 what allowed the fine-tunes to be made on 8GB VRAM and RTX 3070, is they used gradient checkpointing - &ldquo;time and space are a trade-off, and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/cybertronai/gradient-checkpointing&amp;sa=D&amp;source=editors&amp;ust=1765035744900772&amp;usg=AOvVaw05hWHWa33sLyJQCKRRr6ag">gradient checkpointing</a></span><span class="c0">&nbsp;saves memory at the expense of computation time&rdquo;</span></p><p class="c1"><span class="c0">Q: And you don&#39;t get the 0 SDR issue?</span></p><p class="c1"><span class="c0">A: &ldquo;Yes. I&#39;m using L1Freq metric now. As it turns out, it was not a failure to train properly, but just a problem with the validation function.&rdquo; - unwa</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/82&amp;sa=D&amp;source=editors&amp;ust=1765035744901426&amp;usg=AOvVaw0p7FE63MCb0t-ZBihB88ya">More</a></span><span class="c0">&nbsp;on the issue. &ldquo;The validation issue should be solved now [in valid.py] but not sure if it was the same issue ZFTurbo was facing&rdquo;<br></span></p><p class="c1"><span>- &ldquo;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/Mel-Band-Roformer-small&amp;sa=D&amp;source=editors&amp;ust=1765035744901915&amp;usg=AOvVaw2BMQVLKoeAiUDAi31JQupO">https://huggingface.co/pcunwa/Mel-Band-Roformer-small</a></span></p><p class="c1"><span class="c0">In the experiments with the Mel-Band Roformer big model, it was confirmed that increasing the number of parameters for the Mask Estimator did not improve performance.</span></p><p class="c1"><span class="c0">Therefore, I conducted an experiment to see if I could reduce the number of parameters while maintaining the performance.</span></p><p class="c1"><span class="c0">It even runs well on 4 GB cards due to the reduced memory used.&rdquo; - unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">ZFTurbo: &ldquo;I looked onto unwa code for small Roformers. Roformers have one parameter mlp_expansion_factor which couldn&#39;t be change[d] from config and fixed as 4. It uses a lot of memory:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&#9474; &nbsp; &nbsp;&#9492;&#9472;MaskEstimator: 2-8 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; [1, 1101, 7916] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; --</span></p><p class="c1"><span class="c0">&#9474; &nbsp; &nbsp;&#9474; &nbsp; &nbsp;&#9492;&#9472;ModuleList: 3-73 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;-- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;201,465,304</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">if set to 1 (memory reduced 10 times 200 MB to 23 MB):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&#9474; &nbsp; &nbsp;&#9492;&#9472;MaskEstimator: 2-8 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; [1, 1101, 7916] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; --</span></p><p class="c1"><span class="c0">&#9474; &nbsp; &nbsp;&#9474; &nbsp; &nbsp;&#9492;&#9472;ModuleList: 3-73 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;-- &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;23,836,120</span></p><p class="c1"><span class="c0">Yesterday I already added in my repository possibility to change mlp_expansion_factor from config.</span></p><p class="c1"><span class="c0">Unfortunately, while overall number of weights is greatly reduced, it won&#39;t allow to greatly increase speed or batch size for training:</span></p><p class="c1"><span class="c0">Mel band (384, 6, chunk: 352800)</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 4, normal training: batch size: 2 (1.27 s/it)</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 3, normal training: batch size: 2 (1.20 s/it)</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 2, normal training: batch size: 2 (1.19 s/it)</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 1, normal training: batch size: 2 (1.16 s/it)</span></p><p class="c1"><span class="c0">Even in last case, batch size 3 is not possible</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- I will check how &quot;checkpointing&quot; method works</span></p><p class="c1"><span class="c0">OMG checkpointing technique impressed me a lot!!</span></p><p class="c1"><span class="c18 c15">It reduced required memory ~20 times</span></p><p class="c1"><span class="c0">Mel band (384, 6, chunk: 352800) Single A6000 GPU 48 GB</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 4, normal training: batch size: 2 (1.27 s/it) - 0.635 sec per image</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 3, normal training: batch size: 2 (1.20 s/it) - 0.600 sec per image</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 2, normal training: batch size: 2 (1.19 s/it) - 0.595 sec per image</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 1, normal training: batch size: 2 (1.16 s/it) - 0.580 sec per image</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">mlp_expansion_factor = 1, low mem training: batch size: 2 (0.60 s/it) - 0.300 sec per image</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 1, low mem training: batch size: 40 (6.32 s/it) - &nbsp;0.158 sec per image</span></p><p class="c1"><span class="c0">mlp_expansion_factor = 4, low mem training: batch size: 40 (6.87 s/it) - &nbsp;0.171 sec per image</span></p><p class="c1"><span class="c6">So my batch size for single GPU grew from 2 to 40 </span></p><p class="c1"><span class="c6">[So maybe there won&rsquo;t be necessary to train a good model without x16 A100]</span></p><p class="c1"><span class="c0">And speed per image increased ~ 4 times.</span></p><p class="c1"><span class="c0">Ok changes in repo. To train with low memory, you need to replace only one thing: mel_band_roformer -&gt; mel_band_roformer_low_mem. And increase batch_size in config. All weights and model parameters are the same. </span></p><p class="c1"><span class="c0">The same can be done for BSRoformer as well (need to add). </span></p><p class="c1"><span class="c0">With current improvements for memory, we can try big depths for training</span></p><p class="c1"><span class="c0">BS-Roformer with depth 12 now has batch_size: 32</span></p><p class="c1"><span class="c0">We can add sum of inputs, for example for every 3 blocks of freq and time transformer blocks. </span></p><p class="c1"><span class="c0">Or even use DenseNet approach.</span></p><p class="c1"><span class="c0">I found a problem. If internal loss calculation for Roformers is used based on FFT. Batch size reduced to 12 instead of 40.</span></p><p class="c1"><span class="c0">Loss calculation inside the model consumes too much memory.&rdquo; - ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">unwa: The core of the model is the Roformer block, and the Mask Estimator probably did not need that many parameters.</span></p><p class="c1"><span class="c0">According to the paper, the entire model has 105M parameters, whereas when the mlp_expantion_factor is 4, the Mask Estimator alone exceeds that number by a wide margin. </span></p><p class="c1"><span class="c0">Sorry, I forgot about this, I had removed 4096 from multi_stft_resolutions_window_sizes.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Is the speed also faster despite the use of gradient checkpointing because memory bandwidth was the bottleneck?</span></p><p class="c1"><span class="c0">A: I don&#39;t know, maybe yes. Now we need to ensure it doesn&#39;t affect the training process. And the quality of models stays the same.</span></p><p class="c1"><span class="c0">So there is no need to decrease mlp_expansion_factor from 4 to 1 currently (may be later for train new models).</span></p><p class="c1"><span class="c0">I will add possibility to train with low mem in my repo in several minutes</span></p><p class="c1"><span class="c0">I think speed up is because of the benefits of large matrix multiplication (because it&#39;s calculated for 40 images at the same time).</span></p><p class="c1"><span class="c0">Q: Can the gradient checkpointing be applied to other architectures? For example SCNet</span></p><p class="c1"><span class="c0">A: I think yes, but maybe with lower benefits.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;One thing to keep in mind too, is that Rofos are using flash attention by default, which is not compatible with all GPUs (not with small ones), and this flash attention is greatly reducing training duration, from what I get. Non-compatible GPUs use lower performing attention.</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Dao-AILab/flash-attention&amp;sa=D&amp;source=editors&amp;ust=1765035744911481&amp;usg=AOvVaw2pd4DNh1f50Mtvsde9CPpP">https://github.com/Dao-AILab/flash-attention</a></span><span class="c0">&rdquo;</span></p><p class="c1"><span>Supported GPUs: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/QGtSuKR&amp;sa=D&amp;source=editors&amp;ust=1765035744911722&amp;usg=AOvVaw1JbJZ4KYl-iavhPaexdIH1">https://imgur.com/a/QGtSuKR</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Dao-AILab/flash-attention%23nvidia-cuda-support&amp;sa=D&amp;source=editors&amp;ust=1765035744911874&amp;usg=AOvVaw1_fgjDMl-2xqJfTEoywY7f">src</a></span><span class="c0">&nbsp;- half a year later, Flash Attention 2 is still unsupported on RTX 2000 series, and FA3 beta is available for Hopper GPUs (e.g. H100)</span></p><p class="c1"><span class="c0">Q: The training script defaults to memory efficiency unless you use A100 though, does this mean ZF didn&#39;t implement flash att for the other GPUs listed there</span></p><p class="c1"><span class="c0">A: I don&#39;t know, I think it&#39;s more related to the custom flash attention module made by lucidrains, he doesn&#39;t use this flash attention repo. frazer and unwa had a discussion about that in devtalk some days ago, I didn&#39;t understand everything, just learnt that it was custom implementation</span></p><p class="c1"><span>anvuew made a pull request (&ldquo;Enable flash attention for compute capability &gt;= 8.0&rdquo; so GPUs from RTX 3000 onward) </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/pull/52&amp;sa=D&amp;source=editors&amp;ust=1765035744913374&amp;usg=AOvVaw1Q7RBO8kc85XZK_v3a-2aQ">https://github.com/ZFTurbo/Music-Source-Separation-Training/pull/52</a></span><span class="c0">&nbsp;(merged already)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Is adam or adamw better for Mel-Roformer?</span></p><p class="c1"><span class="c0">A: &ldquo;This is not particularly relevant if weight decay is not used.</span></p><p class="c1"><span>In Adam it was implemented with L2 normalization; in AdamW it is implemented in its original form.&rdquo; - unwa<br>Bas Curtiz later conducted some experiments on the best optimizer, and the winner is:<br>Prodigy (with LR 1.0) on the same amount of steps (~14K) and ~20 hours in (at least when training from scratch). </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1303100703144804394&amp;sa=D&amp;source=editors&amp;ust=1765035744914495&amp;usg=AOvVaw0YtLExB9SozGNMwd9IpUYn">More</a></span></p><p class="c1"><span class="c0"><br>- Unwa&rsquo;s </span></p><p class="c1"><span class="c0">&ldquo;1) v1e model was trained with a custom loss, if you don&#39;t use the same or similar multi resolution loss, your results will be bad</span></p><p class="c1"><span class="c0">2) because of [the] 1[st], SDR is not the best metric to keep track of how good the model is, SDR will be lower when training with mrstft losses</span></p><p class="c1"><span class="c0">3) you must set the target instrument to other, and yes you need more vocals&rdquo; becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Unwa &ldquo;reduced mask estimator depth from 3 to 2, and he said that it didn&#39;t hurt the quality but reduced the size significantly. also there&#39;s some additional line &#39;mlp_expansion_factor: 1&#39; in his small model config. Maybe that helped somehow too.&rdquo;<br>&ldquo;The mask estimator is already 2 by default on Kim model for example (and in bort&#39;s config too)&rdquo;<br>&ldquo;I have unwa&#39;s beta and duality models and on batch size 1 they don&#39;t eat that much memory&rdquo;<br>&ldquo;inference maxes out the GPU mem and sits at 0%</span></p><p class="c1"><span class="c0">ckpt file is 3GB.</span></p><p class="c1"><span class="c0">Moral of this story is try running inference before you get to epoch 80&rdquo;<br><br>Q: Does anyone here know how much VRAM is required to train a Roformer model with the same specs as Unwa&#39;s and Kim&#39;s models?</span></p><p class="c1"><span class="c0">A: ZFTurbo has made this small benchmark some months ago with BS-Roformer:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/bs_roformer_info.md&amp;sa=D&amp;source=editors&amp;ust=1765035744916986&amp;usg=AOvVaw1dATx_nQGCgQhEHkKt9KKG">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/bs_roformer_info.md</a></span><span class="c0">&nbsp;</span></p><p class="c1"><span>and </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/G97LcMz&amp;sa=D&amp;source=editors&amp;ust=1765035744917175&amp;usg=AOvVaw1IpPbH_io2V537wfPUAocO">newer</a></span><span class="c0">&nbsp;one for Mel-Roformer</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>ZFTurbo experimented with 4 stems Mel model creation on MUSDB18, and struggled with getting good results like in the paper. </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/cWme9ZW&amp;sa=D&amp;source=editors&amp;ust=1765035744917567&amp;usg=AOvVaw25JFfhZ_YWAvJ0ug-6a-J5">Here</a></span><span>&nbsp;he evaluated various parameters and achieved SDR.<br>Eventually, he released checkpoint with different parameters </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/mel_roformer_experiments.md&amp;sa=D&amp;source=editors&amp;ust=1765035744917937&amp;usg=AOvVaw2IAf87a1U5WOUPAawzCpRY">here</a></span><span class="c0">.</span></p><p class="c1"><span class="c0">Later, he trained BS-Roformer 4 stem model on MUSDB18.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Is it not possible to emphasize both SDR and Aura scores?</span></p><p class="c1"><span class="c0">A: &ldquo;Training the model using [l1_freq and AuraMRSTFT] metrics is prone to phase problems. Like my 5e and v1e models&rdquo; Unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;You can enable spectral phase with auraloss (never really tried)&rdquo; J.</span></p><p class="c1"><span class="c0">A: It makes it less stable in training; Loss is more likely to be NaN</span></p><p class="c1"><span class="c0">It is difficult to optimize a phase spectrogram that looks like noise.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: &ldquo;You don&#39;t emphasize a model with them, they&#39;re just metrics, and you&#39;re tracking how well each epoch scores</span></p><p class="c1"><span class="c0">the metrics will go up and down, but it doesn&#39;t specifically emphasize the chosen metric B.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Phase also has a significant impact on sound quality and cannot be ignored. However, these metrics ignore phase; models that emphasize fullness are those that compromise phase optimization to some degree in favor of optimizing the amplitude spectrogram, and clearly these metrics favor such models.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I would endorse the log_wmse metric.</span></p><p class="c1"><span class="c0">It is a relatively new time-domain metric over SDR and SI-SDR that is not overly sensitive to low frequencies like SDR and can accurately evaluate silent intervals.</span></p><p class="c1"><span class="c0">In addition, time-domain metrics can be evaluated for both amplitude and phase.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c22">- LoRA training repository</span><span class="c0">&nbsp;by frazer - for only Mel and BS models at the moment</span></p><p class="c1"><span>(merged into ZFTurbo&rsquo;s MSST training repo already)<br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/fmac2000/Music-Source-Separation-Training-Models/tree/lora&amp;sa=D&amp;source=editors&amp;ust=1765035744921486&amp;usg=AOvVaw0cvB4P0e6u4YVRL9h6jFEv">https://github.com/fmac2000/Music-Source-Separation-Training-Models/tree/lora</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;LoRA could specialize in a particular singer or genre.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;You can use LoRA as a replacement for full-weight fine-tuning</span></p><p class="c1"><span class="c0">for now, all I can say is that it&#39;ll be faster to train and way more memory efficient than fine-tuning - whether the performance competes with full fine-tuning up is yet to be determined&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;did a small test, and it achieved results in hours that took me days to achieve with A100&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;I trained it for a week - 180 epochs </span></p><p class="c1"><span class="c0">I took Kim Melband and just trained a LoRA on the standard MUSDB - it took SDR vocals from 11 to around 12.3 after 100 epochs on batch_size = 1.<br>I didn&#39;t save each epoch so that 100 epoch voc12.3 isn&#39;t there.</span></p><p class="c1"><span class="c0">(...) my bets it sucks ass since it&#39;s overtrained&rdquo; frazer</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- Bytedance and Asriver prepared some </span><span class="c22">enhancements</span><span class="c0">&nbsp;for Roformer arch, and already published white paper which will be presented on ISMIR2024:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2409.04702&amp;sa=D&amp;source=editors&amp;ust=1765035744923582&amp;usg=AOvVaw3CLxAmNDLK9Unpne1-TPcQ">https://arxiv.org/abs/2409.04702</a></span></p><p class="c1"><span class="c0">Iirc, sami-bytedance-v.1.1 model is already some derivative of above with higher parameters, settings and from what I remember, trained on 16xA100, which cannot be even rented. Bas tried to train a model (model_mel_band_roformer_ep_617_sdr_11.5882) better than that, by just training purely on mutlisong dataset, but he couldn&rsquo;t surpass that score.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- At the end of December 2024, Lucidrains implemented &quot;</span><span class="c22">Value Residual Learning</span><span>&quot; into his BS-Roformer </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lucidrains/BS-RoFormer&amp;sa=D&amp;source=editors&amp;ust=1765035744924485&amp;usg=AOvVaw1eF6Vn5zm7i_DH50WfZpmF">repo</a></span><span class="c0">, based on the following paper:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.17897&amp;sa=D&amp;source=editors&amp;ust=1765035744924685&amp;usg=AOvVaw1punzGoTNR21qqbhY-7yI0">https://arxiv.org/abs/2410.17897</a></span></p><p class="c1"><span class="c0">&ldquo;The paper argues that this mechanism can reduce the over-focus of attention and further reduce the vanishing gradient problem.&rdquo;</span></p><p class="c1"><span>Unwa trained a small 400MB experimental instrumental </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/pcunwa/BS-Roformer-Inst-EXP-Value-Residual&amp;sa=D&amp;source=editors&amp;ust=1765035744925207&amp;usg=AOvVaw22LTsKTWrtqqYV5c13x-Oq">model </a></span><span class="c0">based on it. Doesn&rsquo;t work in UVR.</span></p><p class="c1"><span class="c0">Now it&rsquo;s also added into ZFTurbo MSST repo.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">- CFM</span></p><p class="c1"><span class="c0">Before the middle of 2025, somewhere in probably #dev-talk of our Discord server, jarredou </span></p><p class="c1"><span class="c0">&ldquo;posted a repo from the ByteDance team which explained a method but didn&#39;t implement it in the code&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Becruily: &ldquo;Gemini did a quick pseudo implementation, and it trains 4 times slower&rdquo;</span></p><p class="c1"><span class="c0">Frazer :&rdquo;chat models can&#39;t even code javascript let alone AI&rdquo;</span></p><p class="c1"><span class="c0">B: yeah the hallucinations and unnecessary edits are insane but 2.5 pro is prob the best I&#39;ve seen as long as it has all the context</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">F: &ldquo;just standard CFM it doesn&#39;t need something audio specific for it to work 2s</span></p><p class="c1"><span class="c0">time = torch.randn(B, device=device, dtype=dtype).sigmoid()</span></p><p class="c1"><span class="c0">time = time.view(B, 1, 1)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">x = time * OUTPUTTENSOR + (1 - time) * INPUTTENSOR</span></p><p class="c1"><span class="c0">target = OUTPUTTENSOR - INPUTTENSOR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">condition = self.timeembedder(time) </span></p><p class="c1"><span class="c0">condition2 = self.someconditioningembedder(otherinfo here)</span></p><p class="c1"><span class="c0">somecondition = condition + condition2</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">x = model(x, somecondition)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">loss = F.mse_loss(x, target)</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">you need time embeddings for it to work, but it&#39;s copy-paste 10 minutes work&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: what about the train/inference/valid, don&#39;t they have to be adapted to cfm as well or nah</span></p><p class="c1"><span class="c0">F: yeah - so inference will have to be something like this </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; def evaluate(self, x: torch.Tensor, N: int = 50) -&gt; torch.Tensor:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; x = x.transpose(1, 2) #X must be B T C (if thats what bsroformer uses idk)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; t_span = torch.linspace(0, 1, N + 1, device=x.device, dtype=x.dtype)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; dt = t_span[1] - t_span[0]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; for t in t_span[:-1]:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; k = self.forward_eval(x, t)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; x = x + dt * k</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; x = x.transpose(1, 2)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; return x</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">where you then define a new eval forward </span></p><p class="c1"><span class="c0">&nbsp; &nbsp; def forward_eval(self, x: torch.Tensor, time: torch.Tensor):</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; B, T = x.shape[0], x.shape[1]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; time = torch.full((B,), time, device=x.device, dtype=x.dtype)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; time = time.long()</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; time = self.embedding_time(time).view(B, 1, -1)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; conditioning = time #can add in other embeddings here</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; x = self.forward_model(x, conditioning)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; return x</span></p><p class="c1"><span class="c0">if u want different losses you have to adapt them, what ur trying to do is to iteratively change the input by adding something to the latent across N timesteps&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Is there a version of Mel-Roformer without all the nonsense value residuals and stuff like that</span></p><p class="c1"><span class="c0">A: Yeah zfturbo separated those a few weeks ago on a new file</span></p><p class="c1"><span>&ldquo;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/models/bs_roformer/mel_band_roformer.py&amp;sa=D&amp;source=editors&amp;ust=1765035744931184&amp;usg=AOvVaw1ciyMSzWa7auef6UwNlINg">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/models/bs_roformer/mel_band_roformer.py</a></span></p><p class="c1"><span class="c0">or I guess lucidrains file is as bare/og as it gets&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Later, frazer&rsquo;s blocks are written somewhere in #dev-talk.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- More Roformer training insides in far right of </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1pPEJpu4tZjTkjPh_F5YjtIyHq8v0SxLnBydfUBUNlbI/edit?gid%3D1025734018%23gid%3D1025734018&amp;sa=D&amp;source=editors&amp;ust=1765035744931806&amp;usg=AOvVaw0oH53cshoEShzoTgGfEvKA">this</a></span><span class="c0">&nbsp;Bas Curtiz&rsquo; sheet (phase image may overlap the text, navigate by arrows to read it down below).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;bleedless/fullness metrics are stft magnitude-only based and as they are discarding the phase data, they have some kind of blind spots.</span></p><p class="c1"><span class="c0">I guess this noise could be also reduce by using higher n_fft values for model (smaller bins, finer freq separations, but way more ressources needed to train models)&rdquo; - jarredou<br>Q: High n_fft values increase the frequency resolution but decrease the time resolution</span></p><p class="c1"><span class="c0">A: Yeah. But Roformers are trained with 2048, it&#39;s not high value. MDX23C original models are using 8192 by default, with improved results compared to lower values. (ZFTurbo has made some tests back then comparing different n_fft/hop_length config) </span></p><p class="c1"><span class="c0">Q: does it matter that much when the model is trained with multi resolution &#129335;&zwj;&#9794;&#65039; it should cover both low and high nfft values</span></p><p class="c1"><span class="c0">A: n_fft=2048 is around 21.53 Hz resolution per bin (on linear scale) </span></p><p class="c1"><span class="c0">while n_fft=8192 gives 5.39 Hz resolution per bin</span></p><p class="c1"><span class="c0">This should benefit most of the stems types (maybe not drums and transient heavy content tho)</span></p><p class="c1"><span class="c0">We don&#39;t have multi-resolution arch yet, even if it could be interesting. Only the loss in multi-resolution, not the model. - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Does finetuning need to reach hundreds of epochs?</span></p><p class="c1"><span class="c0">A: &ldquo;Not always. Depends on the amount of data - if it&#39;s small you could literally get away with training for a day or half a day&rdquo; 40 hours is enough for just fine-tuning (frazer)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Is there something wrong with the config I&rsquo;m using? I&rsquo;ve already tried training 3 times, and the pattern is always the same, after the training metrics improve about 6 times, it becomes really difficult for them to improve any further in the next epochs. i&rsquo;ve already tried changing the lr to 5e-5 and 1e-5, but it&#39;s still the same</span></p><p class="c1"><span class="c0">A: &ldquo;try fiddling with adam&#39;s betas - change from betas=(0.9, 0.999) to betas=(0.8, 0.99)</span></p><p class="c1"><span class="c0">adamfactor might be a cool thing to test as well</span></p><p class="c1"><span class="c0">add this into the config, it might work&rdquo; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">optimizer:</span></p><p class="c1"><span class="c6">&nbsp; betas: (0.8, 0.99)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(frazer)</span></p><p class="c1"><span class="c0">Ident like in a new line equally with training and inference, placed below training (so actually none)</span></p><p class="c1"><span class="c0">Q: So far the metrics keep improving, unlike the previous training. It didn&#39;t just cap like last time.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Q: After e.g. 14 epochs, you can try out restarting the checkpoint from the best SDR weight because it will do this &quot;it&#39;s weird. The optimizer for whatever reason gets fucked up after a while&quot;: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/41XSTNO&amp;sa=D&amp;source=editors&amp;ust=1765035744936502&amp;usg=AOvVaw0WZ4JBkvIHGyQy6La4yg8v">pics</a></span><span>&nbsp;(</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708912597239332866/1416006626497794048&amp;sa=D&amp;source=editors&amp;ust=1765035744936654&amp;usg=AOvVaw0jhbIos7JkAgT7YXb602rt">src</a></span><span class="c0">)</span></p><p class="c1"><span class="c0">(frazer)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: how to setup this graphs?</span></p><p class="c14"><span class="c0">&mdash;wandb_key YOURKEY</span></p><p class="c14 c7"><span class="c0"></span></p><p class="c14"><span class="c0">- Loss 0 issue </span></p><p class="c14"><span><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1220364005034561628/1416389629866672261&amp;sa=D&amp;source=editors&amp;ust=1765035744937404&amp;usg=AOvVaw1qY7Zrth6jlAIJae4sYy-P">https://discord.com/channels/708579735583588363/1220364005034561628/1416389629866672261</a></span></p><p class="c14 c7"><span class="c0"></span></p><p class="c14"><span class="c0">Q: is this right? i resumed yesterday&rsquo;s training, but it went back to epoch 0</span></p><p class="c14"><span class="c0">A: yea that&#39;s normal because you&#39;re restarting, i think there&#39;s something to make it so that it saves that data but IDK</span></p><p class="c14 c7"><span class="c0"></span></p><p class="c14"><span class="c0">- 2nd epoch takes a long time issue</span></p><p class="c14"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708912597239332866/1415577958646808636&amp;sa=D&amp;source=editors&amp;ust=1765035744938234&amp;usg=AOvVaw320f0-ikGAmEIILUlqxjde">https://discord.com/channels/708579735583588363/708912597239332866/1415577958646808636</a></span></p><p class="c14"><span class="c0">&ldquo;When VRAM runs out and begins using main memory, processing becomes extremely slow.&rdquo;</span></p><p class="c14 c7"><span class="c0"></span></p><p class="c14"><span class="c0">Q: how do i make more metrics show up like this during training?</span></p><p class="c14"><span class="c0">A: --metrics sdr si_sdr log_wmse l1_freq aura_stft aura_mrstft bleedless fullness</span></p><p class="c14 c7"><span class="c0"></span></p><p class="c14"><span class="c0">- &ldquo;inverts can bring good quality shit if you clean the remaining instrumentals in your vocals with a roformer (...) (ofc this only works if you possess both the original songs and instrumental version which you have to align perfectly)&rdquo; - mesk</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>If you already </span><span class="c4"><a class="c3" href="#h.wyh707wdm55j">prepared your dataset</a></span><span class="c0">, here is a step-by-step guide by Bas Curtiz on:</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.frmr6l4q2wo4"><span class="c22 c50">Setting up training on your local machine<br></span><span class="c50">(read also </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1jUcwiPfrJ8CpHqXIRHuOu70cFDMv_n-UzW53iaFuM9w/edit?tab%3Dt.0&amp;sa=D&amp;source=editors&amp;ust=1765035744939886&amp;usg=AOvVaw09XSmM-LVt-NXowTW6hpXR">mesk&rsquo;s guide</a></span><span class="c50">)</span><span><br><br></span><span class="c0">&ldquo;Make sure you have all dependencies installed for ZFTurbo&#39;s Training &amp; Inference script:</span></h5><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md&amp;sa=D&amp;source=editors&amp;ust=1765035744940450&amp;usg=AOvVaw1jkI8LRzDIIrwRKWlv-MyW">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/docs/gui.md</a></span></p><p class="c1"><span>Update Nvidia drivers: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.nvidia.com/en-us/drivers/&amp;sa=D&amp;source=editors&amp;ust=1765035744940733&amp;usg=AOvVaw3B16_HYcZXsb1_D5aNmAac">https://www.nvidia.com/en-us/drivers/</a></span></p><p class="c1"><span class="c0">Set power plan to best performance + never fall asleep.</span></p><p class="c1"><span class="c0">Determine what the fastest drive is on/in your PC:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.guru3d.com/download/crystal-diskmark-download/&amp;sa=D&amp;source=editors&amp;ust=1765035744941231&amp;usg=AOvVaw04srHaigRgjWPL98VDK1Fb">https://www.guru3d.com/download/crystal-diskmark-download/</a></span></p><p class="c1"><span class="c0">Put your dataset on the fastest drive.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Read and apply the steps at:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training?tab%3Dreadme-ov-file%23how-to-train&amp;sa=D&amp;source=editors&amp;ust=1765035744941804&amp;usg=AOvVaw30tIA-TJBt0oLuX3IxXPHH">https://github.com/ZFTurbo/Music-Source-Separation-Training?tab=readme-ov-file#how-to-train</a></span></p><p class="c1"><span class="c0">Notes:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">a) ZFTurbo&#39;s repo has a lot of config files to start with. Pick the one based on the model type, you want to use, inside the folder /configs</span></p><p class="c1"><span class="c0">b) Alternatively, if you are going to fine-tune an existing model, use the .yaml associated</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(unsure, implementation looks unstable or smth wonky)</span></p><p class="c1"><span class="c0">To train locally, assuming you don&#39;t have a powerhouse of a GFX card, add this line in config:use_torch_checkpoint: True</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">a) Learning rate wise, If you are training a model from scratch, you want to set it higher:5.00e-04 is used by ByteDance for example (=0.0005)</span></p><p class="c1"><span class="c0">b) If you are fine-tuning an existing model, set it lower: 5.00e-06 is recommended (=0.000005)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Save the altered config and add your handle for ex.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For full overview of (optional) parameters that can be used:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/train.py%23L106&amp;sa=D&amp;source=editors&amp;ust=1765035744943793&amp;usg=AOvVaw0i0ZXKTJIUlrlOFFo5U9cS">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/train.py#L106</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- optional but recommended- </span></p><p class="c1"><span>Create a free account at </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://wandb.ai&amp;sa=D&amp;source=editors&amp;ust=1765035744944149&amp;usg=AOvVaw3yZ4XmFJ2wHgowkQfHIKk5">https://wandb.ai</a></span><span class="c0">&nbsp;- shows u more insight on the training progress with graphs.</span></p><p class="c1"><span class="c0">A free personal/cloud-hosted account should suffice.</span></p><p class="c1"><span class="c0">Add parameter --wandb_key YOUR_API_KEY (which u can get from https://wandb.ai/authorize)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Save the full command in a text-file, handy for future usage. Hereby mine, which u can alter:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">python train.py --model_type mel_band_roformer --config_path configs/config_musdb18_mel_band_roformer_bascurtiz.yaml --dataset_type 2 --results_path results --data_path datasets/train --valid_path datasets/validation --num_workers 4 --device_ids 0 --wandb_key e304f2CENSOREDSOYOUNEEDTOUSEYOUROWNdecc122e</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Run the command in the root folder with CMD.</span></p><p class="c1"><span class="c0">Check your progress/graphs at https://wandb.ai/[yourusername]/projects </span></p><p class="c1"><span class="c0">Latest update of repo gives u insight into fullness/bleedless too using parameter:</span></p><p class="c1"><span class="c0">&nbsp;--metrics sdr bleedless fullness l1_freq si_sdr log_wmse aura_stft aura_mrstft&rdquo;<br></span></p><p class="c1"><span class="c0">&ldquo;the augmentations help tho</span></p><p class="c1"><span class="c0">even tho it&#39;s slower</span></p><p class="c1"><span class="c0">gives it much more situations for real songs&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;ye if your dataset isn&#39;t from the biggest it will help&rdquo;<br><br>&ldquo;If you plan to stop/resume training many times, it could be interesting to also save optimizer (and scheduler) state with checkpoint, it can help train faster when you stop/resume a lot (as you resume everything in the state it was when you stopped training, instead of restarting optimizer from scratch each time).&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Patience parameter</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;If set too low, it will reduce learning rate way too fast and lead to stagnant learning&rdquo;.</span></p><p class="c1"><span class="c0">So, if &quot;the model did not improve for like 10 epoches (weights did not save)&quot; while patience is set to default 2, &quot;you should set it to like 1000 to disable it for now.&quot;</span></p><p class="c1"><span class="c0">&quot;patience = X means that if during training, X consecutive epochs are not giving improvement (using sdr metric by default), it will reduce learning rate. If not set correctly, it can kill a training run by reducing too fast and too early learning rate.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">When not sure, it&#39;s better to set it to really high value (like 1000 here) so it will be never triggered.&quot; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Made from scratch training script by Dill &ldquo;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/dillfrescott/mvsep-beta&amp;sa=D&amp;source=editors&amp;ust=1765035744948436&amp;usg=AOvVaw03_RNxRp92v_EZE0yCJLix">https://github.com/dillfrescott/mvsep-beta</a></span></p><p class="c1"><span class="c0">&ldquo;it uses a neural operator architecture with something I call Kernel Scale Attention to capture a range of details. I&#39;m training it now. No guarantees tho on the quality</span></p><p class="c1"><span class="c0">but it&#39;s def working&ldquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Troubleshooting of ZFTurbo&rsquo;s training code by Vinctekan</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Issue: GPU isn&#39;t available, using CPU instead it will be very slow</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Turns out that the group and order of specific python packages that Turbo listed in the [.txt] is pretty cursed.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">At the very end, pip just decides to remove your previous instances of torch, torchvision, and torhcaudio for some reason, and replaces it with the CPU versions, even if you decide to install pytorch CUDA beforehand. Tried removing torch==2.0.1 from the requirements but somehow it still stuck.</span></p><p class="c1"><span class="c0">If you try to install pytorch CUDA AFTER installing the requirements, then it register as already installed. I thought about it for a while as to how could that be possible, but I slowly figured out that the CPU versions were installed because of it.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The way I found the fix is by pip uninstalling all 3 packages, and then reinstalling pytorch with the command on the website. It ultimately does not matter if it&#39;s 118 or 121.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: if I change something in the audio, model, training augmentations, inference section, or if I decide to remove augmentations entirely, will that still start training from where it left off, or is it going to start all over again? </span></p><p class="c1"><span class="c0">A: &ldquo;as long as you provide a starting checkpoint in the training code, it will continue where it left off&rdquo; becruily</span></p><p class="c1"><span class="c0">A: &ldquo;Don&#39;t change &quot;audio&quot;, &quot;model&quot; config, this must be the same as base checkpoint when resuming/fine-tuning, I think, but for &quot;augmentations&quot; part, you can edit as you want as it&#39;s pre-processing of the audio and done on the fly. mp3 encoding, pitchshifting and timestretching are quite resource heavy augmentations and can slow down training, other type of augmentations are more lightweighted.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For &quot;inference&quot;, you can reduce overlap value if you want the validation step between each epoch to be a bit faster (overlap=1 will create clicks at chunk boundaries [fixed in newer MSST code]) </span></p><p class="c1"><span class="c0">&quot;Training&quot; part, you&#39;ll probably have to edit batch_size to find the max value your GPU can handle.&rdquo; jarredou</span></p><p class="c1"><span class="c0">Q: Isn&#39;t changing chunk size in audio fine as long as it&#39;s divisible by the hop length?</span></p><p class="c1"><span class="c0">I recently tried a lower chunk size while keeping everything the same (for melband) to help with VRAM issues, and it seemed to work (didn&#39;t train for long, just wanted to try)</span></p><p class="c1"><span class="c0">A: I have never tried, but yeah, I think you&#39;re right, that&#39;s probably why we can also use different chunk_size/dim_t values for inference and the models are still working. </span></p><p class="c1"><span class="c0"><br>___</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>The lightest arch and still performing great seems to be </span><span class="c22">Vitlarge.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;This arch is more tricky than other, even if lighter.&rdquo; jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(?) segm_model in the script (or something like that)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">musdb configs are for 4stem training, vocals ones are for 2stem</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What&rsquo;s the minimum length requirement</span></p><p class="c1"><span class="c0">A: &ldquo;Default segment_size in htdemucs config is 11 seconds audio chunks, so your training audio files should be longer or equal to 11 second length.</span></p><p class="c1"><span class="c0">It can be lower, if there&rsquo;s no other choice.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>- </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708912597239332866/1225994922822467674&amp;sa=D&amp;source=editors&amp;ust=1765035744955113&amp;usg=AOvVaw1Eu33rxQb2of4faksJq2h3">Here</a></span><span class="c0">, one user is being helped with training hi hat model from scratch using ZFTurbo code on an example of RTX 3060 12GB</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;I believe a length of about one minute per song is appropriate for the validation dataset.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &ldquo;My avg loss is always in the 130&ndash;120 range, is it worth the time to keep waiting for the training? The previous training is also like this, never touched 110 or under 100&rdquo;</span></p><p class="c1"><span class="c0">A: Don&#39;t worry about avg loss, look at the SDR on the metrics - is it improving?</span></p><p class="c1"><span class="c0">Q: No improvement so far, the last one was at epoch 9, now I&rsquo;m heading into epoch 13</span></p><p class="c1"><span class="c0">A: &ldquo;Yeah, don&rsquo;t worry, so what you&rsquo;re seeing is the loss curve.</span></p><p class="c1"><span class="c0">You&#39;ve been shooting down that ramp, but it slows improvements after a while&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/GASs52U&amp;sa=D&amp;source=editors&amp;ust=1765035744956635&amp;usg=AOvVaw3mG7f5rzr0mkJzlvV5wN-r">pic</a></span><span class="c0">&nbsp;(frazer)</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.q9s7o8iiiz7x"><span class="c42 c36 c51 c33 c24 c30">How to get fast GPUs for training</span></h5><p class="c1"><span class="c6">By Bass Curtiz</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">&quot;Budget&quot; option - 4090, or</span></p><p class="c1"><span class="c0">Buy A6000, preferably multiple.</span></p><p class="c1"><span class="c0">Or hire them in the cloud.</span></p><p class="c1"><span class="c0">Best bang for your buck for now</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://vast.ai/&amp;sa=D&amp;source=editors&amp;ust=1765035744957523&amp;usg=AOvVaw2TtP1bcrZC6C4qR3zN4qC-">https://vast.ai/</a></span></p><p class="c1"><span>[</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.tensordock.com/&amp;sa=D&amp;source=editors&amp;ust=1765035744957725&amp;usg=AOvVaw087RBIrWBHwnCfn2qbFE1o">https://www.tensordock.com/</a></span><span class="c0">&nbsp;similar prices (although for November 2024, worse for 8xA100]</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.runpod.io/&amp;sa=D&amp;source=editors&amp;ust=1765035744957956&amp;usg=AOvVaw3psY0qsDPtpSUHhoVtTeB7">https://www.runpod.io/</a></span><span><br></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://app.hyperbolic.xyz/compute&amp;sa=D&amp;source=editors&amp;ust=1765035744958085&amp;usg=AOvVaw0wmV3Xzr_7QfvZ5GJWW_ia">https://app.hyperbolic.xyz/compute</a></span><span class="c0">&nbsp;&ldquo;5x and 8x H100 GPU instances with 1.8 TB storage for $5 and $8 per hour&rdquo; - Kim</span></p><p class="c1"><span class="c0">&ldquo;hunder compute - A100XL (80GB) on $1.05/hour - Essid]<br></span></p><p class="c1"><span class="c0">&ldquo;The easiest would be Colab, if you pay for the compute units the v100 is identical to training with 3090 locally, but Colab can get expensive quickly&rdquo; - becruily</span></p><p class="c1"><span class="c0">Paid Colab has now Nvidia A100 vs free Tesla T4. It&rsquo;s also faster than v100 and L4.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Most in-depth and handy article: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/&amp;sa=D&amp;source=editors&amp;ust=1765035744959117&amp;usg=AOvVaw0R9AttNAcf1XRI7CHhl9Gp">https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">GPU performance chart:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/GPUS_Ada_raw_performance3.png?w%3D1703%26ssl%3D1&amp;sa=D&amp;source=editors&amp;ust=1765035744959551&amp;usg=AOvVaw1Go3ast7lt4-gpEJO728MR">https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/GPUS_Ada_raw_performance3.png?w=1703&amp;ssl=1</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>tldr; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://nanx.me/gpu/&amp;sa=D&amp;source=editors&amp;ust=1765035744959752&amp;usg=AOvVaw2EXHaLrbWHpKlKd6ZQwbZM">https://nanx.me/gpu/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">[dtn: Performance in training</span></p><p class="c1"><span class="c0">NVIDIA H100&gt;A100 (40/80GB)&gt;RTX 4090&gt;RTX A6000 Ada&gt;Nvidia L40 (also 18K CUDA cores)&gt;prob. RTX 5000 Ada (12,8K CUDA cores)&gt;RTX 4080 (9728K)&gt;3090 Ti (10752)&gt;V100 (32/16GB)&gt;RTX 3090</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/GPUS_Ada_raw_performance3.png?w%3D1703%26ssl%3D1&amp;sa=D&amp;source=editors&amp;ust=1765035744960547&amp;usg=AOvVaw3kH8BtrMwTTPyOMzYpzdxq">https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/GPUS_Ada_raw_performance3.png?w=1703&amp;ssl=1</a></span><span class="c0">]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Cheaper GPUs for training</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2x GTX 3090s used are cheaper than 4090 (but irc, the performance for multi-GPUs doesn&rsquo;t scale linearly, so might be not that affordable)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">RTX 3090 24GB (CUDA cores: 10496)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4070 Ti Super 16GB (CUDA cores: 8448)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">RTX 4070 Ti 12GB (CUDA cores: 7680, it&#39;s (still) tasking to train on it, and Roformers will achieve worse SDR due to necessity to start training with lower parameters)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2x GTX 1080 (if dual GPU scaling would be decent enough, it&rsquo;s not linear)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Not mentioning these:</span></p><p class="c1"><span class="c0">RTX 2080 Ti (CUDA cores: 4352)</span></p><p class="c1"><span class="c0">RTX 3060 12GB (CUDA cores: 4864)</span></p><p class="c1"><span class="c0">GTX 1080 Ti (CUDA cores: 3584)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Sign up for an account at </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://sites.google.com/site/vultrfreecredit?pli%3D1&amp;sa=D&amp;source=editors&amp;ust=1765035744962441&amp;usg=AOvVaw3DrXtDQ0e_3iZeYxYHArj1">https://sites.google.com/site/vultrfreecredit?pli=1</a></span></p><p class="c1"><span class="c0">Get 250 bucks free. </span></p><p class="c1"><span class="c0">Add 50 bucks. </span></p><p class="c1"><span class="c0">Now GPU rental is unlocked. Start there and vast.ai and wait for a server that has a6000 x8 for a good price.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But if you have enough time at hand, RTX 4090 is cheaper in the long run.</span></p><p class="c1"><span class="c0">Depends on your electricity costs, though, which varies per country.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Training and inference performance for GPU per dollar</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/GPUs_Ada_performance_per_dollar6.png?ssl%3D1&amp;sa=D&amp;source=editors&amp;ust=1765035744963598&amp;usg=AOvVaw2wh4ojj0udrGwKPC4254ma">https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/GPUs_Ada_performance_per_dollar6.png?ssl=1</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Be aware that multi GPU configurations don&rsquo;t scale linearly.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">We had an interesting discussion on the server on the choice between GTX 1080 Ti vs RTX 3060 12GB in training. We&rsquo;re yet to find out the final result, but unwa claims that despite having more CUDA cores, 1080 Ti might turn out to be slower. The possible reasons:</span></p><p class="c1"><span class="c0">- &nbsp;Pascal&rsquo;s are &ldquo;limited by FP16 performance by a factor of 64&rdquo;</span></p><p class="c1"><span class="c0">- No tensor cores (&ldquo;Normally, AMP (Automatic Mixed Precision) is turned on when training a model, but AMP uses Tensor Core to speed up the computation.&rdquo; plus &ldquo;Tensor Core generation is also newer [in 3000 series], with support for more precisions, including BF16.&rdquo;)<br>- &ldquo;3060 is one generation newer than RTX 20xx / GTX 16xx and can use Flash Attention2. This is not very relevant for music source separation model, but may be very useful for LLM inference. (Roformer models have a Flash Attention entry in the configuration, but Memory Efficient Attention is used unless A100 GPU(s) are used.)&rdquo;</span></p><p class="c1"><span class="c0">Bas Curtiz is probably yet to find out the final verdict.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &ldquo;This is an extreme example, but it&#39;s a table comparing video generation times for each GPU under the settings of Wan2.2 Q6 K, 1280x704, 84 seconds, and 8 steps. The 5060Ti 16GB even outperforms the 3090&rdquo; - Unwa</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/6znQaPa&amp;sa=D&amp;source=editors&amp;ust=1765035744966055&amp;usg=AOvVaw2uuDhG-2KeIIVSKv6JFclW">pic</a></span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: How long it takes to train a model?</span></p><p class="c1"><span class="c0">A: &quot;Depends on input and parameters, and architecture.</span></p><p class="c1"><span class="c0">MDX old version:</span></p><p class="c1"><span class="c0">5k input (15k actually: inst/mixture/vocals) + 100 validation tracks (300, same deal), fullband, 300 epochs would have taken 3 months on a RTX 4090.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can speed it up by going multiple GPUs and more memory, therefore:</span></p><p class="c1"><span class="c0">A6000 (48gb) x 8 was like 14 days.</span></p><p class="c1"><span class="c0">Damage on 300 epochs: ~700 bucks.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;7 days training of e.g. BS-Roformer on 8xA100-80GB&quot;: 7\*24\*15.12 (runpod 8xa100 pricing) = $2540.16&rdquo;</span></p><p class="c1"><span class="c0">4 days achieved epoch 74, and on epoch 162 for ~4200/4500 songs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: &ldquo;4070 [8GB] works, but I would only use for testing IMO</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: I&rsquo;ve trained some convtasnet in the past with really decent times [on 4070 8] (the new Ada Lovelace on 40 series makes faster tensor cores, which kinda compensates the less number of cores compared to 30 series)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: [4070 8GB] is fine for non transformers. </span></p><p class="c1"><span class="c0">If mamba blocks are used good it could be fine TBF.</span></p><p class="c1"><span class="c0">The thing with transformers is that it is really reliant on VRAM.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: Depends on what&#39;s inside the transformer, if it&#39;s flashatten then you need Ada.</span></p><p class="c1"><span class="c0">Mamba has custom kernels, but I&#39;m pretty sure 4090 can run it - what&#39;ll be cool is mamba + reversible net, super memory efficient in training, but it ends up being slower per step (around 2x compared to backprop).</span></p><p class="c1"><span class="c0">I guess in reversible net you can have gigantic batch sizes which kinda circumvent the problem of a slow step speed&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There is a potential alternative to GPUs - </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Training using TPU</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://sites.research.google/trc/about/&amp;sa=D&amp;source=editors&amp;ust=1765035744969863&amp;usg=AOvVaw1du8Ta_OR2BTvhW2EpGGcs">https://sites.research.google/trc/about/</a></span></p><p class="c1"><span class="c0">&ldquo;they give you an absolutely ridiculous amount these days by default</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">the on-demand v4s have 1024gb of memory, every 1 chip has 32gb and is roughly equivalent in performance to an a100 </span></p><p class="c1"><span class="c0">i&#39;m not sure how good torch xla support is now, but it might just work out of the box&rdquo; Cyclcrclicly</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">But it turned out to be extremely convoluted to fix compatibility issues, and Bas stuck during fixing it, but here&rsquo;s the convo where he stuck:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Why does training the bs_roformer model with 8s chunksize, 256 dim, 8 depth consume only 13GB of VRAM now, compared to 21GB last time</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Stuck troubleshooting of TPU training by Bas Curtiz (Q) and frazer, DJ NUO, jarredou and Cyclcrclicly (A):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: is it as simple as adding pytorch lightning though?</span></p><p class="c1"><span class="c0">A: try using &quot;xla&quot; as the device instead of cuda and if you&#39;re lucky everything will Just Work&trade;&#65039; </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: The Pytorch&#39;s implementation of stft does not work on the XLA (TPU),</span></p><p class="c1"><span class="c0">because it internally uses some unsupported functions.</span></p><p class="c1"><span class="c0">There are not feasible workarounds for it available.</span></p><p class="c1"><span class="c0">Only some 3x PhD discussion, which discusses the underlying function not working,</span></p><p class="c1"><span class="c0">which would require forking pytorch to get it working, IF the solution was actually even feasible: </span></p><p class="c1"><span class="c0">(hacky super slow workaround, or just &quot;use different shit&quot;).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Only &quot;realistic&quot; solution I&#39;ve found is porting the mel band roformer to tensorflow. </span></p><p class="c1"><span class="c0">Which is bruh, but the thing is in their docs STFT says: </span></p><p class="c1"><span class="c0">Implemented with TPU/GPU-compatible ops and supports gradients.. </span></p><p class="c1"><span class="c0">Also tensorflow is by google, the TPU as well, so yk, it might have better support.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The same error basically is described here:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/pytorch/xla/issues/2241&amp;sa=D&amp;source=editors&amp;ust=1765035744974719&amp;usg=AOvVaw2er66fYv3QsorT_tx8RyuM">https://github.com/pytorch/xla/issues/2241</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: As frazer said, you&#39;ll have better luck with jax than tensorflow</span></p><p class="c1"><span class="c0">A: Can you try putting data to CPU &amp; running it there, and then put the result back on TPU?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I encounter similar issues when running on Mac MPS (GPU), and this code helps to alleviate the issue:</span></p><p class="c1"><span class="c0">stft_repr = torch.stft(raw_audio.cpu() if x_is_mps else raw_audio, **self.stft_kwargs, window=stft_window.cpu() if x_is_mps else stft_window, return_complex=True).to(device)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(of course, in your case the code might be a bit different, but it demonstrates the idea)</span></p><p class="c1"><span class="c0">Q: obviously slow</span></p><p class="c1"><span class="c0">it is called in a loop in the forward function (= very slow)</span></p><p class="c1"><span class="c0">...if it was like only once / before each step, but not inside step.</span></p><p class="c1"><span class="c0">we&#39;ll try anyways, thanks</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Timed-out after 10 mins, 0 steps were finished.</span></p><p class="c1"><span class="c0">Imagine doing 4032 steps.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">JAX is like an optimizer/JIT.</span></p><p class="c1"><span class="c0">STFT of it, is just Scipy&#39;s STFT but running under JAX.</span></p><p class="c1"><span class="c0">Scipy&#39;s implementation is CPU-based.</span></p><p class="c1"><span class="c0">So it expects CPU data. Not Tensor/GPU/TPU data.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: Or this might help (custom implementation of STFT): https://github.com/MasayaKawamura/MB-iSTFT-VITS/blob/main/stft.py</span></p><p class="c1"><span class="c0">A: There&#39;s also https://github.com/qiuqiangkong/torchlibrosa/ that has a stft implementation</span></p><p class="c1"><span class="c0">Q: Hmm both use numpy which is cpu based</span></p><p class="c1"><span class="c0">A: yeah its some weird operation in the torch spec, i use https://github.com/adobe-research/convmelspec anytime incompatibility occurs</span></p><p class="c1"><span class="c0">Q: May be we need to replace mel spec with this in MelRoformer.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I got a boilerplate/minimal produduction ready, but 2 &nbsp;things... </span></p><p class="c1"><span class="c0">no TPU for me right now to test - maybe someone else has better luck / paid Colab sub.</span></p><p class="c1"><span class="c0">Last outcome, which might be fixed by now: RuntimeError: Attempted to call variable.set_data(tensor), but variable and tensor have incompatible tensor type.</span></p><p class="c1"><span class="c0">A: you can use kaggle for tpuv3 with probably better availability</span></p><p class="c1"><span class="c0">Q: https://github.com/qiuqiangkong/torchlibrosa/ result:</span></p><p class="c1"><span class="c0">Calling &quot;torch.nn.functional.fold&quot; just gets stuck, when interrupting, the error stack has mentions of copying to CPU.</span></p><p class="c1"><span class="c0">...smth to do with the fold function.</span></p><p class="c1"><span class="c0">Numpy only in initialization (cpu), so that&#39;s fine.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">https://github.com/MasayaKawamura/MB-iSTFT-VITS/blob/main/stft.py result:</span></p><p class="c1"><span class="c0">Numpy and basically cpu all-the-way, so no/go.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">https://github.com/adobe-research/convmelspec result:</span></p><p class="c1"><span class="c0">Not a STFT library / whole spectrogram, don&#39;t wanna dissect it, the STFT part seems internal, </span></p><p class="c1"><span class="c0">didn&#39;t notice (would have to double-check) the inverse, but wasted 2 days already. done with it.</span></p><p class="c1"><span class="c0">A: Just a guess (have no experience with Tensorflow): what if STFT portion of the code can be executed by TensorFlow code -&gt; convert result to numpy CPU -&gt; convert to PyTorch tensor</span></p><p class="c1"><span class="c0">Q: Problem is... It simply takes too much time, copying to cpu and back is expensive resource-wise</span></p><p class="c1"><span class="c0">A: In some part of torchlibrosa they use a workaround for nn.functional.fold function, maybe that can be reproduced/adapted to the other failing part where fold used.</span></p><p class="c1"><span class="c0">A: line 239 is the drop in, you have to make sure the settings are the same from what i remember https://github.com/adobe-research/convmelspec/blob/main/convmelspec/stft.py</span></p><p class="c1"><span class="c0">Q: It got thru the whole ass forward step. But now it&#39;s stuck at backward step.</span></p><p class="c1"><span class="c0">yk, recalculate the weights based on this step to improve the model.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">replaced the backwards function of stft with empty one, and yet: stuck.</span></p><p class="c1"><span class="c0">so since backwards step of stft/istft is disabled...</span></p><p class="c1"><span class="c0">the problem is elsewhere.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">No idea where, no idea how to debug, out of my expertise.</span></p><p class="c1"><span class="c0">A: I might be 100% wrong here, but I think you should disable the backward pass through that class if it is type nn.Module </span></p><p class="c1"><span class="c0">stft.requires_grad=False</span></p><p class="c1"><span class="c0">or when you call stft use a decorator with indentation </span></p><p class="c1"><span class="c0">with torch.no_grad():</span></p><p class="c1"><span class="c0">&nbsp; x=stft(x)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c1 c27" id="h.4g7vubs5phea"><span class="c6">Other archs</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">SCNet: Sparse Compression Network</span></p><p class="c1"><span class="c0">Large models by ZFTurbo turned out to sound between Roformers and MDX.</span></p><p class="c1"><span class="c0">&ldquo;SCNet is maybe a bit more bleedy than MDX23c&rdquo; and/or possibly noisy, judging by the MVSEP model(s). &ldquo;seemingly impossible&rdquo; to train guitars</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span>[July 10th 2024] &ldquo;</span><span>Official SCNet repo has been updated by the author with training code.</span><span><a class="c3" href="https://www.google.com/url?q=https://github.com/starrytong/SCNet&amp;sa=D&amp;source=editors&amp;ust=1765035744984741&amp;usg=AOvVaw3G3TBH3wWhT6Q2X4wc4wHJ">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/starrytong/SCNet&amp;sa=D&amp;source=editors&amp;ust=1765035744984979&amp;usg=AOvVaw0A8FQUZqFf3i3HAB_rsaAS">https://github.com/starrytong/SCNet</a></span><span class="c23 c15 c30">&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;ZF&#39;s script already can train SCNet, but currently it doesn&#39;t give good results&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/tag/v.1.0.6&amp;sa=D&amp;source=editors&amp;ust=1765035744985586&amp;usg=AOvVaw1s6CKvsCsswTUwRt8OyyOZ">https://github.com/ZFTurbo/Music-Source-Separation-Training/releases/</a></span></p><p class="c1"><span class="c0">The author&rsquo;s checkpoint:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1CdEIIqsoRfHn1SJ7rccPfyYioW3BlXcW/view&amp;sa=D&amp;source=editors&amp;ust=1765035744985948&amp;usg=AOvVaw2N8Nh6oenzDvlJ8h3CiT8X">https://drive.google.com/file/d/1CdEIIqsoRfHn1SJ7rccPfyYioW3BlXcW/view</a></span></p><p class="c1"><span class="c0">June 2025</span></p><p class="c1"><span class="c0">ZFTurbo: &ldquo;I added new version of SCNet with mask in main MSST repository. Available with key &#39;scnet_masked&#39;. Thanks to becruily for help.&rdquo;</span></p><p class="c1"><span>&ldquo;the main thing is removing the SCNet buzzing&rdquo; - Dry Paint<br>How heavily undertrained weights looks on spectrograms with mask vs without: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/ZM0h6tI&amp;sa=D&amp;source=editors&amp;ust=1765035744986710&amp;usg=AOvVaw3BfUufmAjsQtvWJftZUPL-">click</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;One diff I see between author config and ZF&#39;s one, is that dev has used learning rate of 5e-04 while it&#39;s 4e-05 in ZF config. And main issue ZF was facing was slow progress (while author said it worked as expected using ZF training script </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/starrytong/SCNet/issues/1%23issuecomment-2063025663&amp;sa=D&amp;source=editors&amp;ust=1765035744987591&amp;usg=AOvVaw2-9b2TPHQzTsgvL_TRVOgn">https://github.com/starrytong/SCNet/issues/1#issuecomment-2063025663</a></span><span class="c0">)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The author:</span></p><p class="c1"><span class="c0">&ldquo;All our experiments are conducted on 8 Nvidia V100 GPUs.</span></p><p class="c1"><span class="c0">When training solely on the MUSDB18-HQ dataset, the model is</span></p><p class="c1"><span class="c0">trained for 130 epochs with the Adam [22] optimizer with an initial</span></p><p class="c1"><span class="c0">learning rate of 5e-4 and batch size of 4 for each GPU. Nevertheless,</span></p><p class="c1"><span class="c0">we adjust the learning rate to 3e-4 when introducing additional data</span></p><p class="c1"><span class="c0">to mitigate potential gradient explosion.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Q: So that mean that you have to modulate the learning rate depending on the size of the dataset ?</span></p><p class="c1"><span class="c0">I think it&#39;s first time I read something in that way</span></p><p class="c1"><span class="c0">A: Yea, I suppose because the dataset is larger you need to ensure the model sees the whole distribution instead of just learning the first couple of batches&rdquo;</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span>Paper: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2401.13276&amp;sa=D&amp;source=editors&amp;ust=1765035744989758&amp;usg=AOvVaw2qO6rT4ioj79iDjUgysSTU">https://arxiv.org/abs/2401.13276</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1200415850277130250/image.png&amp;sa=D&amp;source=editors&amp;ust=1765035744990238&amp;usg=AOvVaw2rqN4s6dt2llDl3V-PENP1">https://cdn.discordapp.com/attachments/708579735583588366/1200415850277130250/image.png</a></span><span>&nbsp;(dead)</span></p><p class="c1"><span class="c0">On the same dataset (MUSDB18-HQ), it performs a lot better than Demucs 4 (Demucs HT).</span></p><p class="c1"><span class="c0">&ldquo;melband is still sota cause if you increase the feature dimensions and blocks it gets better</span></p><p class="c1"><span class="c0">you can&#39;t scale up scnet cause it isn&#39;t a transformer</span></p><p class="c1"><span>it&#39;s a good cheap alt version tho&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">ZFTurbo &ldquo;I trained small model because author post weights for small. Now I&#39;m training large version of model, but it&#39;s slow and still not reach quality of small version.</span></p><p class="c1"><span class="c0">I use the same dataset for both models</span></p><p class="c1"><span class="c0">My SCNet large stuck at SDR 9.1 for vocals. I don&#39;t know why</span></p><p class="c1"><span class="c0">My small SCNet has SDR 10.2</span></p><p class="c1"><span class="c0">I added config of SCNet to train on MUSDB18:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/configs/config_musdb18_scnet_large.yaml&amp;sa=D&amp;source=editors&amp;ust=1765035744992637&amp;usg=AOvVaw3vjOBK3DSVWq7acPyI4iGb">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/configs/config_musdb18_scnet_large.yaml</a></span></p><p class="c1"><span class="c0">Only changes comparing to small model are these parts:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Small:</span></p><p class="c1"><span class="c0">dims:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 4</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 32</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 64</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 128</span></p><p class="c1"><span class="c0">band_SR:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 0.175</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 0.392</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 0.433</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Large:</span></p><p class="c1"><span class="c0">&nbsp;dims:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 4</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 64</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 128</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 256</span></p><p class="c1"><span class="c0">&nbsp;band_SR:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 0.225</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 0.372</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; - 0.403&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">ZFTurbo eventually trained SCNet large model, but it turned out to sound similar to Roformers, but with more noise. You can test the model on MVSEP.com</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">SCNet Large turned out to be good for piano (vs MDX23C and MelRoformer) and also drums models according to ZFTurbo.</span></p><p class="c1"><span class="c0">&ldquo;He also said SCNet didn&#39;t work that well for strings, Aufr didn&#39;t have luck with BV model as well&rdquo;<br>&ldquo;MDX23c is already looking better on guitar after 5 epochs than scnet after 100 epochs&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;with SCNet I&#39;ve had the fastest results with prodigy [optimizer]&rdquo; becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Later, ZFTurbo released SCNet 4 stems (in his repo) and exclusive bass model on MVSEP.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>There was also an older, an unofficial (not fully finished yet, it seems) implementation of SCNet: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/amanteur/SCNet-PyTorch&amp;sa=D&amp;source=editors&amp;ust=1765035744996415&amp;usg=AOvVaw2q1omo9Owr8WgJjR8ctD0e">https://github.com/amanteur/SCNet-PyTorch</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Experimental </span><span class="c18 c15">BS-Mamba</span></p><p class="c1"><span class="c0">git clone https://github.com/mapperize/Music-Source-Separation-Training.git --branch workingmamba</span></p><p class="c1 c7"><span class="c0"><br></span></p><p class="c1"><span class="c18 c15">TS-BSmamba2</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2409.06245&amp;sa=D&amp;source=editors&amp;ust=1765035744997075&amp;usg=AOvVaw2Vl1GCxFdzZG0vKJLolslD">https://arxiv.org/abs/2409.06245</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/baijinglin/TS-BSmamba2&amp;sa=D&amp;source=editors&amp;ust=1765035744997255&amp;usg=AOvVaw17etyVVIanIROyOxS_ijZQ">https://github.com/baijinglin/TS-BSmamba2</a></span></p><p class="c1"><span class="c0">Added to ZFTurbo training repo:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/&amp;sa=D&amp;source=editors&amp;ust=1765035744997600&amp;usg=AOvVaw3MCmg_jx6kaXbg0ujiOo52">https://github.com/ZFTurbo/Music-Source-Separation-Training/</a></span><span class="c0"><br></span></p><p class="c1"><span class="c0">At this moment, training works only on Linux or WSL. </span></p><p class="c1"><span class="c0">SDR seems to be higher than all the current archs, maybe besides Mel/BS Roformers (weren&rsquo;t tested). &ldquo;It&#39;s in between SCNet and Rofos but maybe more lightweight than them.</span></p><p class="c1"><span class="c0">(...) From the scores from MelBand paper [it seems] the Rofos are still like +0.5 SDR average above the other archs when trained on musdb18 only.</span></p><p class="c1"><span class="c0">But it&#39;s great to finally see some mamba-inspired MSS arch with great performance&rdquo;.</span></p><p class="c1"><span class="c0">As for 22.09.24, ZFTurbo had problems with low SDR during training.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1220364005034561628/1286650425596186645&amp;sa=D&amp;source=editors&amp;ust=1765035744999461&amp;usg=AOvVaw1EoknfP3QV1G0drgSfAbM_">https://discord.com/channels/708579735583588363/1220364005034561628/1286650425596186645</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1220364005034561628/1284221988294099102&amp;sa=D&amp;source=editors&amp;ust=1765035744999911&amp;usg=AOvVaw1blS-3pOdzWnUDAnmOBKBR">https://discord.com/channels/708579735583588363/1220364005034561628/1284221988294099102</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Another three very promising archs for the moment:</span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c22">Conformer</span></p><p class="c1"><span class="c6">&ldquo;performs just as well if not better than a standard Roformer&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2005.08100&amp;sa=D&amp;source=editors&amp;ust=1765035745000524&amp;usg=AOvVaw10sNXO-fniqPlbyGq8JXaU">https://arxiv.org/pdf/2005.08100</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lucidrains/conformer&amp;sa=D&amp;source=editors&amp;ust=1765035745000694&amp;usg=AOvVaw2uuR-b3HPS9GYVmzz6JTn0">https://github.com/lucidrains/conformer</a></span></p><p class="c1"><span class="c0">(people already train with it, and its implementation might be pushed to the MSST repo in not distant future)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/169&amp;sa=D&amp;source=editors&amp;ust=1765035745001135&amp;usg=AOvVaw1w7e7tl8JO_RVLBcxuylPY">https://github.com/ZFTurbo/Music-Source-Separation-Training/issues/169</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Essid pretrain:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/Essid/MelBandConformer/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035745001445&amp;usg=AOvVaw24eR_aEuL8vtPq0ZQJlQFQ">https://huggingface.co/Essid/MelBandConformer/tree/main</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/quality_checker/entry/9087&amp;sa=D&amp;source=editors&amp;ust=1765035745001625&amp;usg=AOvVaw0xXXWJFGKzaqIYlSpFLdXL">https://mvsep.com/quality_checker/entry/9087</a></span></p><p class="c1"><span class="c0">&ldquo;Due to cost issues, I&#39;m discontinuing the Mel-Band-Conformer MUSDB18HQ-based train. I&#39;m sharing the ckpt and config, so anyone who wants to continue can use them.&rdquo;</span></p><p class="c1"><span>It has </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/yk64g2G&amp;sa=D&amp;source=editors&amp;ust=1765035745002113&amp;usg=AOvVaw192AXDuKmuLEwnnPuffWCo">shown</a></span><span class="c0">&nbsp;steady improvement in training in the last 12 hours from epoch 0 to 83 (1 SDR increase on private validation dataset, probably on A100XL (80GB) on &ldquo;thunder compute&rdquo; $1.05/hour) and the shared weight is epoch 200+.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">TF-Locoformer</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2408.03440&amp;sa=D&amp;source=editors&amp;ust=1765035745003016&amp;usg=AOvVaw3ZFXKTTXQHnmyXOupDFbiN">https://arxiv.org/abs/2408.03440</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/merlresearch/tf-locoformer/blob/main/espnet2/enh/separator/tflocoformer_separator.py&amp;sa=D&amp;source=editors&amp;ust=1765035745003436&amp;usg=AOvVaw0tkXetvVDt-sIq_VKl3Tnc">https://github.com/merlresearch/tf-locoformer/blob/main/espnet2/enh/separator/tflocoformer_separator.py</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I see only now that the tf-locoformer repo was updated to include the variants published few months ago (TF-Locoformer-NoPE and BS-Locoformer)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/merlresearch/tf-locoformer&amp;sa=D&amp;source=editors&amp;ust=1765035745004122&amp;usg=AOvVaw3pJRVJsMvSdD58c7SLFxAc">https://github.com/merlresearch/tf-locoformer</a></span><span class="c0">&rdquo; - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">dTTnet</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/junyuchen-cjy/DTTNet-Pytorch&amp;sa=D&amp;source=editors&amp;ust=1765035745004575&amp;usg=AOvVaw06jVVNH5n1vXUDs4RctrfZ">https://github.com/junyuchen-cjy/DTTNet-Pytorch</a></span></p><p class="c1"><span class="c0">&ldquo;They report very good performance on vocals with low parameters&rdquo; - Kim</span></p><p class="c1"><span class="c0">Back in the end of 2023, one indie pop song from multisong dataset (of the two there) received the best SDR - Bas Curtiz</span></p><p class="c1"><span class="c0">&ldquo;better than scnet imo, remains to see if it can beat rofos&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;not fast to train. I&#39;m back with vanilla mdx23c</span></p><p class="c1"><span class="c0">Trying a config to train model with less than 4GB &nbsp;VRAM, almost at 7 SDR for vocals in 8 hours of training (on moisesdb+musdb18, and using musdb18 eval, with my 1080Ti and batch_size=1, chunk_size is around 1.5sec) &rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Modification of the training code for MSST by becruily (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.proton.me/urls/NDNTT9RQQW%23gwYFcDEeQEAD&amp;sa=D&amp;source=editors&amp;ust=1765035745006405&amp;usg=AOvVaw2qnIl5wWNqXqmZLs31Dqad">DL</a></span><span>; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1e2NmyxxJU1h2wGxomBl7D-NXJBYHMXsU?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035745006566&amp;usg=AOvVaw1dVLP3apCZ5bt6cIiP8odT">old</a></span><span class="c0">).</span></p><p class="c1"><span class="c0">Breaks compatibility with the authors&#39; checkpoint. </span></p><p class="c1"><span class="c0">&ldquo;Also keep in mind authors trained with l1 loss only, default in msst is masked loss&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;from what I read, l1 loss when dataset is noisy, mse loss when dataset is clean&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;the loss is defined from msst, but in the original dttnet it was in the code itself</span></p><p class="c1"><span class="c0">you can just --loss l1_loss&rdquo;</span></p><p class="c1"><span class="c0">@jarredou &ldquo;I copied your tfc and tfc_tdf classes to my files (and used that latest stft/istft I sent) - and seems to be better, just like the og dttnet </span></p><p class="c1"><span class="c0">the tfc/tdf fixed the nan issue for me&rdquo; - becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Installation instruction:</span></p><p class="c1"><span class="c0">&ldquo;In the latest MSST [at least for 13.10.25]</span></p><p class="c1"><span class="c0">add the ddtnet folder to &quot;models&quot; and replace your settings file in utils with this&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;The weird thing is, it sounds like a fullness model despite not being one, I barely can find dips in instrumentals</span></p><p class="c1"><span>ddtnet vs kim melband, if anyone is curious </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/12an8wnKC-FKE48gVu9pHvUaLSxzpC6C8?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035745008635&amp;usg=AOvVaw3JeA5Vj27ddVGeg0nONXcl">https://drive.google.com/drive/folders/12an8wnKC-FKE48gVu9pHvUaLSxzpC6C8?usp=sharing</a></span></p><p class="c1"><span class="c0">Keep in mind ddtnet was trained only with musdb and has 10-20x less params while being comparable in quality&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;the authors checkpoints had 16khz cutoff because dim_f was smaller than nfft/2</span></p><p class="c1"><span class="c0">if you want to train model with cutoff it&#39;s fine, if you want fullband then dim_f must be half of nfft + 1&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;I&rsquo;ve found the issue in my DTTNet version leading to the &quot;noisy&quot; outputs. It was just the * changed to a + &nbsp;in forward </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://imgur.com/a/IgiHZkL&amp;sa=D&amp;source=editors&amp;ust=1765035745009581&amp;usg=AOvVaw2d_QoBYaKhpTlYr_nHZT_i">here</a></span><span class="c0">&rdquo; - jarredou<br>Everything uploaded at the top. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Mesk&rsquo;s config for training instrumental model (achieved from SDR 6 to 9.3 in a third epoch [counting the first as 0]:<br></span></p><p class="c1"><span class="c0">python train.py --model_type dttnet --config_path config-ddtnet-other.yaml --start_check_point results/vocalsg32_ep4082.ckpt --results_path results/ --data_path [YOUR DATASET] --valid_path [YOUR VALIDATION DATASET] --dataset_type [TYPE 1/2/3/4/5] --num_workers 8 --device_ids 0 --metric_for_scheduler sdr --metrics fullness bleedless l1_freq</span></p><p class="c1"><span class="c0">change these accordingly:</span></p><p class="c1"><span class="c0">&gt;data_path</span></p><p class="c1"><span class="c0">&gt;valid_path</span></p><p class="c1"><span class="c0">&gt;dataset_type</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">On the side. </span></p><p class="c1"><span class="c22">ZLUDA </span><span>is a translation layer for CUDA allowing to use any CUDA-written app to be used with AMD (and formerly Intel) GPUs, and without any modifications to such app.<br>Weaker GPUs than 7900 XT might show its weeknesses considerably, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.purepc.pl/image/news/2024/02/13_zluda_uklady_graficzne_amd_radeon_moga_skorzystac_z_bibliotek_nvidia_cuda_projekt_porzucony_przez_intela_i_amd_juz_dostepny_4_b.jpg&amp;sa=D&amp;source=editors&amp;ust=1765035745011482&amp;usg=AOvVaw1VuZ2Iwh5Sf-tYvmQNF8P9">compared</a></span><span>&nbsp;to better GPUs. The example came from ZLUDA in Blender, but rather from AMD period code, so before the takedown and rollback to pre-AMD codebase so now ZLUDA is more crippled. <br>With never released code, at certain point it was even made to support Batman Arkham Knight, with general plans to support DLSS, but it will probably never see a day light.<br>Maybe </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lshqqytiger/ZLUDA&amp;sa=D&amp;source=editors&amp;ust=1765035745012161&amp;usg=AOvVaw10621gL2s1b365MPHqspg0">this</a></span><span>&nbsp;repo still has the old base forked - version 3 codebase is still being updated there. Utilizing it on 6700 XT in </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu&amp;sa=D&amp;source=editors&amp;ust=1765035745012487&amp;usg=AOvVaw3H_B9l1gZuT-Pcc9nMHL1k">stable-diffusion-webui-amdgpu</a></span><span>, it was performing slowly like DirectML, but on 7900 XT it sped up the process from 3-4 to ~1 minute. The first execution can be slow due to need of creating cache. Then it can surpass ROCm performance-wise if you manage to make it work. Plus, ZLUDA works on Windows and supports older AMD GPUs, like even RX 500 series (use </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/lshqqytiger/ZLUDA&amp;sa=D&amp;source=editors&amp;ust=1765035745013171&amp;usg=AOvVaw1NGxUfv85kCvtyHfHRwtJ0">lshqqytiger&rsquo;s repo</a></span><span>, check e.g. ROCm 5 version if your app doesn&rsquo;t start, but it might crash anyway), while for ROCm on Linux and older GPUs, e.g. RX 5700 XT should work with some quirks (e.g. HIP 5.7 and ROCm around 5.2.* - </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.reddit.com/r/ROCm/comments/1gcf3x4/comment/ma62qop/&amp;sa=D&amp;source=editors&amp;ust=1765035745013643&amp;usg=AOvVaw1JwXaVEiMoIWXiqpPpY-qn">src</a></span><span class="c0">, although you can try out 6.21 or 6.2.x to ensure, as it could happen that some earlier 6.x wasn&rsquo;t supporting RX 5700 XT correctly, while e.g. for RX 6000 ROCm 6.24 should be used at the moment). <br>It could be interesting to see utilizing training repo using ZLUDA e.g. on Windows instead of ROCm Pytorch on Linux but Unwa notice in the ZLUDA repo fork, &ldquo;PyTorch: torch.stft does not always return correct result.&rdquo; and it might be problematic during training, so ZLUDA might be not a good solution for training currently, but who knows whether for inferencing on e.g. Windows using MSST or UVR, although the latter crashes for me during separation with nvcuda.dll. But I haven&#39;t tried messing with HIP SDK mentioned in the release page or other fork&#39;s ZLUDA versions than the newest. I don&#39;t even have anything in C:\Program Files\AMD\ROCm (if it wasn&rsquo;t even futile without it), but I have amdhip64.dll v. 5.5 in system32 (if 5.7 isn&rsquo;t shipped with newer drivers and required).</span></p><p class="c1"><span class="c0">Also, didn&#39;t follow these instructions yet, and they might be useful and contain some older GPUs workaround:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/vladmandic/sdnext/wiki/ZLUDA&amp;sa=D&amp;source=editors&amp;ust=1765035745015754&amp;usg=AOvVaw2HCor1NxU4_MgcZ8BaSR9t">https://github.com/vladmandic/sdnext/wiki/ZLUDA</a></span></p><p class="c1"><span class="c0">All gfx names with corresponding GPU models:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://llvm.org/docs/AMDGPUUsage.html%23processors&amp;sa=D&amp;source=editors&amp;ust=1765035745016101&amp;usg=AOvVaw28or5oXlB-52lvquB6DC22">https://llvm.org/docs/AMDGPUUsage.html#processors</a></span></p><p class="c1"><span class="c0">More ZLUDA research and workarounds (may work for UVR, not have too):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/comfyanonymous/ComfyUI%23amd-gpus-experimental-windows-and-linux-rdna-3-35-and-4-only&amp;sa=D&amp;source=editors&amp;ust=1765035745016603&amp;usg=AOvVaw09YWLQ7ZoKONOEHdJLD0g9">https://github.com/comfyanonymous/ComfyUI#amd-gpus-experimental-windows-and-linux-rdna-3-35-and-4-only</a></span></p><p class="c1"><span class="c0">(RDNA 3-4 instructions for Python manual installation using DirectML branch of UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/comfyanonymous/ComfyUI%23for-amd-cards-not-officially-supported-by-rocm&amp;sa=D&amp;source=editors&amp;ust=1765035745017125&amp;usg=AOvVaw2JAMCUxF9wZT9zuLOnCPMS">https://github.com/comfyanonymous/ComfyUI#for-amd-cards-not-officially-supported-by-rocm</a></span></p><p class="c1"><span class="c0">(flags for RDNA 2-3)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/patientx/ComfyUI-Zluda&amp;sa=D&amp;source=editors&amp;ust=1765035745017486&amp;usg=AOvVaw3LTAudtmCgpfgR7Dnl6J5z">https://github.com/patientx/ComfyUI-Zluda</a></span></p><p class="c1"><span class="c0">(Instructions for GCN4-RDNA4; </span></p><p class="c1"><span class="c0">RDNA 2 with HIP 6.2.4 and experimental 6.4.2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Using hip 5.7.1 and corresponding ZLUDA should be possible on RDNA2 too</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/CS1o/Stable-Diffusion-Info/wiki/Webui-Installation-Guides%23amd-fooocus-with-zluda&amp;sa=D&amp;source=editors&amp;ust=1765035745018298&amp;usg=AOvVaw3e3gQpExINSr9wQbh2ad1X">https://github.com/CS1o/Stable-Diffusion-Info/wiki/Webui-Installation-Guides#amd-fooocus-with-zluda</a></span></p><p class="c1"><span class="c0">(Step 5 in &quot;Setting up Zluda&quot; a bit below - for GPUs below RX 6800 or 9070/60,</span></p><p class="c1"><span class="c0">and instructions above the point are there for 6800 or higher too</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/CS1o/Stable-Diffusion-Info/wiki/Webui-Installation-Guides%23rocm-hip-sdk-57-with-zluda-setup&amp;sa=D&amp;source=editors&amp;ust=1765035745019020&amp;usg=AOvVaw0bpB3Qgg5xUTdMTBWHuOAp">https://github.com/CS1o/Stable-Diffusion-Info/wiki/Webui-Installation-Guides#rocm-hip-sdk-57-with-zluda-setup</a></span></p><p class="c1"><span class="c0">(Instructions for GCN4 [RX 400/500]; it contains a step with </span></p><p class="c1"><span class="c0">pip install torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1 --index-url https://download.pytorch.org/whl/cu118)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/advanced-lvl-up/Rx470-Vega10-Rx580-gfx803-gfx900-fix-AMD-GPU%23important-notes-on-installation&amp;sa=D&amp;source=editors&amp;ust=1765035745019774&amp;usg=AOvVaw0eLWWKxFG1kJu57Ma5hCKP">https://github.com/advanced-lvl-up/Rx470-Vega10-Rx580-gfx803-gfx900-fix-AMD-GPU#important-notes-on-installation</a></span></p><p class="c1"><span class="c0">(Instructions for GCN4 [GFX803 &amp; GFX900])</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ROCm/ROCm/issues/4749%23issuecomment-3117083336&amp;sa=D&amp;source=editors&amp;ust=1765035745020178&amp;usg=AOvVaw2PIf9CXE7ci_nk962d7g58">https://github.com/ROCm/ROCm/issues/4749#issuecomment-3117083336</a></span></p><p class="c1"><span class="c0">(some old 7900 XTX (gfx11100) troubleshooting</span></p><p class="c1"><span class="c0">- HIP SDK 6.5 might a bit less crashy, </span></p><p class="c1"><span>&quot;Follow the instructions at </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/patientx/ComfyUI-Zluda&amp;sa=D&amp;source=editors&amp;ust=1765035745020689&amp;usg=AOvVaw21nSKoHg_VR2dyk6SVJILr">https://github.com/patientx/ComfyUI-Zluda</a></span><span>&nbsp;then do the patches at </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/patientx/ComfyUI-Zluda/issues/222&amp;sa=D&amp;source=editors&amp;ust=1765035745020930&amp;usg=AOvVaw3900_YJOl40BgOQHWfGu-M">https://github.com/patientx/ComfyUI-Zluda/issues/222</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Possible complement for RX 6600/6700 (if wasn&rsquo;t mentioned in the instructions above already)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/YellowRoseCx/koboldcpp-rocm/releases/download/deps-v6.2.0/rocblas-6.2.0.dll.7z&amp;sa=D&amp;source=editors&amp;ust=1765035745021658&amp;usg=AOvVaw2NsXg-ZaVh0P0WA4Z7oxaE">https://github.com/YellowRoseCx/koboldcpp-rocm/releases/download/deps-v6.2.0/rocblas-6.2.0.dll.7z</a></span></p><p class="c1"><span class="c0">extract that zip file into C:/Program Files/AMD/ROCm/6.1/bin/ it should merge with the &quot;rocblas&quot; folder that&#39;s already in there.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">KAN-Stem</span></p><p class="c1"><span class="c0">That might be interesting to train multistem, it&rsquo;s based on Demucs:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/waefrebeorn/KAN-Stem&amp;sa=D&amp;source=editors&amp;ust=1765035745022467&amp;usg=AOvVaw1hcZ4RkkH4ks-a5bA_8HIf">https://github.com/waefrebeorn/KAN-Stem</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c18 c15"></span></p><p class="c1"><span class="c22">VR architecture </span><span>by tsurumeso</span><span class="c22">&nbsp;</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/tsurumeso/vocal-remover&amp;sa=D&amp;source=editors&amp;ust=1765035745022864&amp;usg=AOvVaw2inDo9Qy0XD-k4KhzE320z">https://github.com/tsurumeso/vocal-remover</a></span></p><p class="c1"><span class="c0">(VR models in UVR, use modified v5 training code in order to support e.g. 4 bands, inferencing v6 models is not yet supported in UVR)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The arch is obsolete for instrumentals - bleeding and vocal artefacts.</span></p><p class="c1"><span class="c0">Not really recommended anymore, unless for specific tasks like de-noise, de-reverb or Karaoke or BVE when MDX V1 wasn&#39;t giving that good results.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(guide by Joe)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: How do I train my own models?</span></p><p class="c1"><span class="c0">A: &nbsp;</span></p><p class="c1"><span class="c0">Model Training Tutorial</span></p><p class="c1"><span class="c0">Requirements:</span></p><p class="c1"><span class="c0">- Windows 10</span></p><p class="c1"><span class="c0">- Nvidia GeForce Graphic card (at least 8 GB of VRAM)</span></p><p class="c1"><span class="c0">- At least 16GB of Ram</span></p><p class="c1"><span class="c0">- Recommend 1 - 2TB of hard drive</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Setup your dataset</span></p><p class="c1"><span class="c0">1. You need to know...</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Attention:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Although you can train your model with mp3, m4a, flac file, but we recommend convent those file to wav file.</span></p><p class="c1"><span class="c0">- For high-resolution audio sources, the samples are reduced to 44.1kHz during conversion.</span></p><p class="c1"><span class="c0">- If possible, match the playback position and volume of the OnVocal and OffVocal sound sources. </span></p><p class="c1"><span class="c0">- The dataset required at least 150 pairs of songs</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">2. Rename the file...</span></p><p class="c1"><span class="c0">Attention:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Create &quot;mixtures&quot; folder with vocals / &quot;instruments&quot; folder without vocals</span></p><p class="c1"><span class="c0">Please separate the sound sources with and without vocals as shown below.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">There is also a rule for file names, please make the file names numbers and add &quot;_mix&quot; / &quot;_inst&quot; at the end.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Example:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Instrumental with vocal: </span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; D:\dataset\mixtures\001_mix.wav</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; D:\dataset\mixtures\002_mix.wav</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; D:\dataset\mixtures\003_mix.wav</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .</span></p><p class="c1"><span class="c0">Instrumental only:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; D:\dataset\instruments\001_inst.wav</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; D:\dataset\instruments\002_inst.wav</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; D:\dataset\instruments\003_inst.wav&hellip;</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">3. Download the vocal-Remover from GitHub</span></p><p class="c1"><span>Link: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/tsurumeso/vocal-remover/releases/&amp;sa=D&amp;source=editors&amp;ust=1765035745028206&amp;usg=AOvVaw3iTYEIwJGg_Di9dlXJ3tLa">https://github.com/tsurumeso/vocal-remover/releases/</a></span></p><p class="c1"><span class="c0">4. Install the program (Use this command down below)...</span></p><p class="c1"><span class="c0">pip install --no-cache-dir -r requirements.txt</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">5. Start learning</span></p><p class="c1"><span class="c0">python train.py --dataset D:\dataset\ --reduction_rate 0.5 --mixup_rate 0.5 --gpu 0</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Attention:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If you want to pause, press Ctrl+Shift+C</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">6. Continue learning</span></p><p class="c1"><span class="c0">Example:</span></p><p class="c1"><span class="c0">python train.py --dataset D:\dataset\ --pretrained_model .\models\model_iter(number).pth --reduction_rate 0.5 --mixup_rate 0.5 --gpu 0</span></p><p class="c1"><span class="c0"><br>__</span></p><p class="c1"><span class="c0">Compared to VR5 arch, VR6 now can handle phase. Although I&rsquo;m not sure if it implements Aufr33 mutliband functionality which models trained for UVR5 on VR5 utilize (I&rsquo;m not sure if that training code is in the old CML UVR5 code).<br><br></span></p><p class="c1"><span class="c6">MedleyVox</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Excellent for training duet/unison and separately main/rest vocals.</span></p><p class="c1"><span class="c0">The original code is extremely messy and broken at the same time, and dataset is big and hard to obtain. Cyrus was to publish their own repository with fixed code and complete dataset at some point.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The problem of the model trained by Cyrus was training cutoff used while training.</span></p><p class="c1"><span class="c0">&quot;The ISR_net is basically just a different type of model that attempts to make audio super resolution and then separate it. I only trained it cuz that&#39;s what the paper&#39;s author did, but it gives worse results than just the normal fine-tuned&quot; ~Cyrus</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Apart from training code, there wasn&#39;t any model released by the authors. Only result snippets.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/JusperLee/TDANet&amp;sa=D&amp;source=editors&amp;ust=1765035745031574&amp;usg=AOvVaw2O3VDbvD39w3pKQ652Nyaf">https://github.com/JusperLee/TDANet</a></span></p><p class="c1"><span class="c0">&quot;I think this arch should worth a try with multiple singer separation, as it&#39;s performing quite well on speaker separation, and it seems it can be trained with a custom number of voices (same usual samplerate &amp; mono limitations tho)&quot; jr</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">MossFormer2 may perform better</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;These archs are not implement in ZF&#39;s script but are really promising for multiple speakers separation, and should be working for multiple singers separation if trained on singing voice:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/dmlguq456/SepReformer&amp;sa=D&amp;source=editors&amp;ust=1765035745033028&amp;usg=AOvVaw0trIQUdtwE7KXTzA-OaCgK">https://github.com/dmlguq456/SepReformer</a></span><span>&nbsp;</span><span class="c0">(current SOTA)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/JusperLee/TDANet&amp;sa=D&amp;source=editors&amp;ust=1765035745033267&amp;usg=AOvVaw3kQWjR1gwRlMw0zVHNmZX2">https://github.com/JusperLee/TDANet</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/alibabasglab/MossFormer2&amp;sa=D&amp;source=editors&amp;ust=1765035745033465&amp;usg=AOvVaw0qcFaAo61ozpWV-NE348va">https://github.com/alibabasglab/MossFormer2</a></span></p><p class="c1"><span class="c0">&rdquo; jarreodu</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Bas Curtiz</span></p><p class="c1"><span>&ldquo;Few takeaways I learned from the issues at its GitHub, </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/dmlguq456/SepReformer/issues&amp;sa=D&amp;source=editors&amp;ust=1765035745033975&amp;usg=AOvVaw241Ko1LxHLQKB_QS2tIxKF">https://github.com/dmlguq456/SepReformer/issues</a></span></p><p class="c1"><span class="c0">currently only supports 8khz sample rate (so downsample your 44.1khz samples to this prior)</span></p><p class="c1"><span class="c0">samples only: max 10-20 seconds input, otherwise potential memory issues (so chunk a full song into such segments prior)</span></p><p class="c1"><span class="c0">Individual samples are not supported (so it&#39;s folder-based, put your samples in there)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, there are various errors which some users tend to encounter, at least on Windows machines.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">New sep algo</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/OliverRensu/xAR&amp;sa=D&amp;source=editors&amp;ust=1765035745034973&amp;usg=AOvVaw3UjG7e44-moHCw9gEsycqJ">https://github.com/OliverRensu/xAR</a></span></p><p class="c1"><span class="c0">[This repository includes the official implementation of our paper &quot;Beyond Next-Token: Next-X Prediction for Autoregressive Visual Generation&quot;]</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">___</span></p><p class="c1"><span class="c6">Might be potentially useful for any training in Colab (by HV, 2021):</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">&ldquo;function ConnectButton(){</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; console.log(&quot;Connect pushed&quot;); </span></p><p class="c1"><span class="c0">&nbsp; &nbsp; document.querySelector(&quot;#top-toolbar &gt; colab-connect-button&quot;).shadowRoot.querySelector(&quot;#connect&quot;).click() </span></p><p class="c1"><span class="c0">}</span></p><p class="c1"><span class="c0">setInterval(ConnectButton,60000);</span></p><p class="c1"><span class="c0">&nbsp;&lt;- enter this on console (not cell)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">and keep Colab on foreground.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s not really good to train in Colab at all, due to its limitations.</span></p><p class="c1"><span>If you&#39;re training because you want a better model than v5/v4 mgm models, stop it, you won&#39;t surpass mgm models with just Colab. However, you could subscribe to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cloud.google.com/gcp&amp;sa=D&amp;source=editors&amp;ust=1765035745036854&amp;usg=AOvVaw1EKErjCwv2nyYLeMmWd9hD">https://cloud.google.com/gcp</a></span></p><p class="c1"><span class="c0">and watch some YouTube tutorials how to utilise its resources to Colab.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____________________________________________________________________</span></p><p class="c1"><span class="c0">(archived)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Sidechain stem limiting guide by Vinctekan</span></p><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c0">Hello all, I am here to share the definitive answer to exporting sets of stems with consistent and loudness and brickwall like mixing, when a manual mixture of pairs/stems are too loud or are modified.</span></p><p class="c1"><span class="c0">Even though, pairs like this probably won&#39;t have to be used for training in the future, it&#39;s still going to be super important for evaluation for said models, or techniques that any of you may discover in the future.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I discovered this through this video, the details and specifics behind are explained in this if you would like to recreate it manual</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DHv8nENoNvbk%26t&amp;sa=D&amp;source=editors&amp;ust=1765035745038701&amp;usg=AOvVaw2qOnNdwdUjoyQ0zwDGzyNF">https://www.youtube.com/watch?v=Hv8nENoNvbk&amp;t</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">This is basically a Side Chain Stem Limiting method that uses FabFilter&#39;s Pro-L 2 limiter plugin in the REAPER DAW to mix your stems in a way that when you mix them together in Audacity with the &quot;Mix and Render&quot; option, you get a perfect waveblock like mix, with no clipping and no distortion.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Decided to help you all out and created two REAPER templates where this mixing method is used, so you don&#39;t have to make it manually. I&#39;ll give out a 4 stem template &nbsp;and a 2 stem template for vocals, and instrumental that you all can use to recreate the above.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The steps to make the above happen aren&#39;t exactly the same as in the video, in addition there are a lot of things you don&#39;t need to do (since I have already done it), so here is a step-by-step guide:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Requirements:</span></p><p class="c1"><span class="c0">1. REAPER (DAW) [in the video, it says you can use any DAW]</span></p><p class="c1"><span class="c0">2. FabFilter Pro-L 2 limiter plugin (preferably the regular VST version, instead of VST3)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Steps:</span></p><p class="c1"><span class="c0">1. Open the REAPER Project File of your choice (if you&#39;re exporting 2 stems, use the 2 stem version, if you&#39;re exporting 4 stems, use the 4 stem template)</span></p><p class="c1"><span class="c0">2. Drag your stems into the corresponding channels, you also have to drag it into the channels labeled: __&quot;DUPE&quot;__</span></p><p class="c1"><span class="c0">-Your vocal stem to &quot;VOCALS&quot;, and &quot;VOCALS DUPE&quot;</span></p><p class="c1"><span class="c0">-Your drum stem to &quot;DRUMS, and &quot;DRUMS DUPE&quot;</span></p><p class="c1"><span class="c0">-Your other stem to &quot;OTHER&quot;, and &quot;OTHER DUPE&quot;</span></p><p class="c1"><span class="c0">-Your bass stem to &quot;BASS&quot;, and &quot;BASS DUPE&quot;</span></p><p class="c1"><span class="c0">-Your instrumental to &quot;INSTRUMENTAL&quot;, and &quot;INSTRUMENTAL DUPE&quot; [For the 2 stem template]</span></p><p class="c1"><span class="c0">3. Check the settings of the limiter to make sure it suits your needs.</span></p><p class="c1"><span class="c0">-You can set the gain on the left side of the UI, if you think your mix it still isn&#39;t loud enough.</span></p><p class="c1"><span class="c0">-I used 8x oversampling as default, if you feel like your CPU can handle more or less, you can adjust it to suit your needs.</span></p><p class="c1"><span class="c0">-If the exported stems have distortion (by any chance), you can set the limiting mode to SAFE, which prioritizes transients, and keeps unwanted sounds to ABSOLUTE ZERO.</span></p><p class="c1"><span class="c0">-You can also think about adjusting the attack, release, and channel linking settings if it&#39;s not good enough, but I think the settings in the templates are good for any form of limiting.</span></p><p class="c1"><span class="c0">-Make sure &quot;True Peak Limiting&quot; is always on, if it isn&#39;t, distortion might become a factor again in the final results</span></p><p class="c1"><span class="c0">4. Now it&#39;s time to export the stems in the first track folder individually. You can do this by soloing them with the yellow &quot;S&quot; button next to the tracks.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">4.5 In REAPER: File&gt;Render... and render. Rinse and repeat for all of the stems.</span></p><p class="c1"><span class="c0">These are the settings I recommend using, if you plan to further edit the results, and also for retaining the quality of the sources:</span></p><p class="c1"><span class="c0">-No Tail</span></p><p class="c1"><span class="c0">-44100hz or 48000hz sample rate</span></p><p class="c1"><span class="c0">-Channels: Stereo</span></p><p class="c1"><span class="c0">-Resample mode: r8brain free (highest quality, fast)</span></p><p class="c1"><span class="c0">-Format: WAV</span></p><p class="c1"><span class="c0">-WAV bit depth: 24 bit PCM</span></p><p class="c1"><span class="c0">-Nothing else</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Done!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">+5. You can check your work by opening Audacity, importing the exported stems, and mixing them together by pressing CTRL+A, going inside: Tracks &gt; Mix &gt; Mix and Render.</span></p><p class="c1"><span class="c0">If everything is done correctly, you should have a mix of stems which sound nice to the ears, and has absolutely zero clipping. You can if it clips or not by checking: View &gt; Show Clipping (on/off). Or you can press CTRL+A, go inside Effects &gt; Volume and Compression &gt; Amplify. If it&#39;s correct, the Amplification bar should show 0.0 DB.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Clipping bug workaround</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708579735583588366/1139206772092051496/Instrumental_Fix.mp4&amp;sa=D&amp;source=editors&amp;ust=1765035745046458&amp;usg=AOvVaw138BxaqCu40Ybz4-ebSpT3">https://cdn.discordapp.com/attachments/708579735583588366/1139206772092051496/Instrumental_Fix.mp4</a></span></p><p class="c1"><span class="c0">In addition to Safe Mode, I set the release to the max, and it worked that way, but the dynamic were shite.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">More:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1139189181873143869&amp;sa=D&amp;source=editors&amp;ust=1765035745047310&amp;usg=AOvVaw2x0QAMbbtg4KK8PAaGlBZM">https://discord.com/channels/708579735583588363/708579735583588366/1139189181873143869</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In conclusion to below: The instrumental clipping wasn&#39;t the Fabfilter Pro-L 2 VST&#39;s fault, or any sidechain limiter for that matter. This is just how digital audio works, unfortunately.</span></p><p class="c1"><span class="c0">(And PS. - 32-bit float exporting might prevent clipping).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Trivia</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Ugggh, just checked out both Pedalboard, and DawDreamer, from what it looks like: It&#39;s not really possible to recreate stem limiting with a RAM loaded mixture as a reference/auxiliary input. </span></p><p class="c1"><span class="c0">The only 2 remaining possibilities that I am thinking of is using pydub, librosa, scipy or pyo to do it without the use of a DAW.</span></p><p class="c1"><span class="c0">If that&#39;s not possible, then the only option left is to control REAPER with reapy + reascript.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I also think I now understand why the peak amplitude of the instrumental is decreased when you re-mix the acapella back in to the mix:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Since music is basically just about, 22000 different sine wavs going off at the exact same time with changing amplitudes, the pressure waves of all of these sine waves interfere each other constantly:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">If at any given time the pressure waves of these sine waves have a perfectly aligned value of +1, then they add up together, creating a strong signal</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">On the flip side: there are times when they cancel each other out, because the amplitude are different (e.g 1st being +1 and the 2nd being -1)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I watched a video guide in Fourier Transform, and the concept is visually demonstrated really well:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DspUNpyF58BY%26t%3D50s&amp;sa=D&amp;source=editors&amp;ust=1765035745050671&amp;usg=AOvVaw3JmXtXq6INWfKrxCyP0X2m">https://www.youtube.com/watch?v=spUNpyF58BY&amp;t=50s</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In a nutshell: If you take away the vocals, certain frequencies of the instrumental get amplified, because now the vocal isn&#39;t there to dampen it/cancel it out.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can recreate this by taking a brickwall limited recording of your choice, lowering the DBFS by at least -2. Then you can process it through an MDX model, and then compare the peak amplitudes of:</span></p><p class="c1"><span class="c0">1. the mixture</span></p><p class="c1"><span class="c0">2. the Instrumental</span></p><p class="c1"><span class="c0">3. and the separated instrumental and acapella mixed back together</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jeonchangbin49/musdb-XL/issues&amp;sa=D&amp;source=editors&amp;ust=1765035745052098&amp;usg=AOvVaw10-MK75fLLDWJ6LnR5Wwf_">https://github.com/jeonchangbin49/musdb-XL/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">From what I can understand, they applied a maximizer to all the mixtures, then calculated the differences of amplitude in a sample by samples by basis, and applied the difference to all the stems at once.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I think I could do that.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Update</span></p><p class="c1"><span class="c0">&ldquo;Even though I have found out that using Pro-C 2 [Sidechain compressor, not a limiter] totally fixes the issue of mixes clipping after turning down just about any stem, the trade-off is that the LUFS [short term] suffers by at least -2 DB&ldquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">(older techniques from before the guide above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">jarredou&rsquo;s guide:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Here&#39;s 2 &quot;proof-of-concept&quot; python dynamic range compressor/limiter I&#39;ve made recently and that are working with sidechain and multiple stems inputs:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">1st one &quot;pydub_comp_fork.py&quot; is a fork of pydub&#39;s dynamic range compressor</span></p><p class="c1"><span class="c0">(line79 to change the audio inputs)</span></p><p class="c1"><span class="c0">You can set attack/release/ratio/threshold settings like any other compressor</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">---</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>2nd one &quot;limiter.py&quot; is a fork of this Safety Limiter: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nhthn/safety-limiter/&amp;sa=D&amp;source=editors&amp;ust=1765035745054948&amp;usg=AOvVaw1SngRF1rg4E7pLqxUd9u8t">https://github.com/nhthn/safety-limiter/</a></span></p><p class="c1"><span class="c0">(54line to change the audio inputs)</span></p><p class="c1"><span class="c0">You have &quot;release&quot; and &quot;hold_time&quot; settings.</span></p><p class="c1"><span class="c0">(no threshold here, you just gain the input)</span></p><p class="c1"><span class="c0">---</span></p><p class="c1"><span class="c0">Even if they were sounding &quot;ok&quot; with normal settings, the speed performances were not satisfying for any of them for the planned use, I will not develop them more, consider them as abandonware. But they can maybe be usefull for someone else. </span></p><p class="c1"><span class="c0">from pydub import AudioSegment, effects &nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/773763762887852072/1167555636272316467/limiter.py&amp;sa=D&amp;source=editors&amp;ust=1765035745056069&amp;usg=AOvVaw1nwDU4nSUCB1DlNSDCPo5F">https://cdn.discordapp.com/attachments/773763762887852072/1167555636272316467/limiter.py</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/773763762887852072/1167555635928367265/pydub_comp_fork.py&amp;sa=D&amp;source=editors&amp;ust=1765035745056369&amp;usg=AOvVaw0-e8CpsJ-i6FlXOztZEia4">https://cdn.discordapp.com/attachments/773763762887852072/1167555635928367265/pydub_comp_fork.py</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can use this technique to make the loudness of your stems consistent:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/jeonchangbin49/musdb-XL&amp;sa=D&amp;source=editors&amp;ust=1765035745056755&amp;usg=AOvVaw0WtTPHbwci_EZn5j9a8j67">https://github.com/jeonchangbin49/musdb-XL</a></span><span class="c0">&nbsp;to get better results with your model, where usually there&#39;s a problem with proper isolation of overly compressed music.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">You can also read Aufr33 short guide </span></p><p class="c1"><span>on his approach toward this problem (plus more explanations </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708595418400817162/1107389624717934783&amp;sa=D&amp;source=editors&amp;ust=1765035745057383&amp;usg=AOvVaw0KJ9Jygzl08_LSy8eHRqDY">here</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">For a problem of inconsistent volume in mixture vs stems when a limiter is used, sidechain mixture to a limiter.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Other option, more close to real world processing :</span></p><p class="c1"><span class="c0">* apply (strong) compressor/limiter to individual stems to mimic the mixing process</span></p><p class="c1"><span class="c0">* and then apply (softer/lighter) compressor/limiter on mixture (with sidechain trick) to mimic the mastering process.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Because if you apply too much limiting on the mixture, it will destroy the sound. 2-stage dynamics processing is more transparent.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The only problem with the technique is that there could be clipping if we invert one or more stems over the mixture.</span></p><p class="c1"><span class="c0">Unless the AIs work with [32 bit] floating point (not integer!)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Exemplary step-by-step guide</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I used side-chain on the 2 stems with source 3 as input.</span></p><p class="c1"><span class="c0">Somehow I had to set the threshold to -12db (instead of the OG -24db) i applied to the mixture (prolly coz 12 x 2 stems)</span></p><p class="c1"><span class="c0">Used the same Ratio/Attack/Release settings as used with compressor prior, this time on the side-chain compressor.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Two templates for Reaper. One with better LSP Sidechain Limiter Stereo which is Linux Studio Plugin and the other with free reacomp. Target is around -7.5 ilufs, but anything between 8.5 and 9 will do fine.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1108853386608136252/Pair_Limiter.RPP&amp;sa=D&amp;source=editors&amp;ust=1765035745060207&amp;usg=AOvVaw0t3g5-RtN5_2BHGP3cjE6d">https://cdn.discordapp.com/attachments/708595418400817162/1108853386608136252/Pair_Limiter.RPP</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/708595418400817162/1108861182506455170/Pair_Limiter_-_ReaComp.RPP&amp;sa=D&amp;source=editors&amp;ust=1765035745060576&amp;usg=AOvVaw0Oh4WSl-LMFw2GAVZTqUgW">https://cdn.discordapp.com/attachments/708595418400817162/1108861182506455170/Pair_Limiter_-_ReaComp.RPP</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">These may not be the final files. ReaComp struggled more at some point. Consider using e.g. also iZotope RX9/10 Maximiser IRC IV for more transparent results.</span></p><p class="c1"><span class="c0">E.g. Aufr33 used Voxengo and sometimes ReaXComp in 4 channel mode.</span></p><p class="c1"><span class="c0">_______</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Alternatively, you can experiment with:</span></p><p class="c1"><span class="c20">KSHMR Chain</span><span>&nbsp;</span><span class="c20">method by Sam Hocking</span><span class="c0">&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I too get some residual that doesn&#39;t null when comparing Master Bus v Distributed Stem Mastering.&rdquo;</span></p><p class="c1"><span class="c0">&quot;The way gainmatch works is it exists on your before processing chain and after processing chain and real-time communicates the difference between the two (does the part knock is showing), so the adjustment is made dynamically as a gain match calc, or you can use it as a target match too. While the loudness adjusting could all be an offline one click process, you would still have to set it all up manually in a DAW. There are some cool duplication chain-style solutions in ProTools that could achieve it more easily, however. My personal favourite is a tool called KSHMR Chain which will work in any Stereo DAW and that allows one plugin instance to be effective on hundreds of tracks at the same time but controlled from one master plugin. This way you could actually adjust every single audio to a common master LUFS dynamically and click export stems and all would be dynamically adjusted at once and offline exported.&quot;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.excite-audio.com/kshmr-chain&amp;sa=D&amp;source=editors&amp;ust=1765035745063163&amp;usg=AOvVaw0hGmssB3Csj-M7HUAhkS7u">https://www.excite-audio.com/kshmr-chain</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Short guide of Aufr33 approach</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/900904142669754399/1090876675966894142/sm.png&amp;sa=D&amp;source=editors&amp;ust=1765035745063666&amp;usg=AOvVaw3PBIoJQaLlskY41GTOL_vf">https://cdn.discordapp.com/attachments/900904142669754399/1090876675966894142/sm.png</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;If anyone is wondering how I create pairs. Here&#39;s what my project looks like in REAPER.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Before the master bus is the limiter plugin, which works with 4-channels. After rendering a pair for one dataset (in this case, for Karokee), I swap audio items and render the pairs for other datasets: BVE, Strings, etc.&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;For training, just make sure that all pairs have a margin of about 0.3 dB. Storing pairs larger than 16 bits can be useful for further editing.&rdquo; aufr33</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">______</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.gzsz53bzhmzn"><span class="c21">Local SDR testing script</span></h4><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1GC9pwch0WQXZXwBNTz_QnXE_UyxdKmQF/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035745065151&amp;usg=AOvVaw0p0N774jHgI8pTxNDppc4D">https://drive.google.com/file/d/1GC9pwch0WQXZXwBNTz_QnXE_UyxdKmQF/view?usp=sharing</a></span><span class="c0">&nbsp;by Dill</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1BeqNw3TnRTDMwnoQGMbOqwrcGRwe4Zht/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035745065445&amp;usg=AOvVaw1V5WZbMUqSV1i-lo1HUymK">https://drive.google.com/file/d/1BeqNw3TnRTDMwnoQGMbOqwrcGRwe4Zht/view?usp=sharing</a></span><span class="c0">&nbsp;GUI by zmis (but it scores a bit lower for some reason):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Here&#39;s a handy little python script I made using the help of Ai that can calculate the SDR of a track based off of the actual instrumental or vocal of the song.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You can do python sdr.py --help for an explanation on how to use the script.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You just need numpy and scipy for it to work, and python ofc!</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">I&#39;m not sure if you would like to pin this or not, but I&#39;ve been using this script to help me improve my separation methods. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Audio-separation-models-checker/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035745066832&amp;usg=AOvVaw0h3AyrwvRN_qxR1jQtE5kH">https://github.com/ZFTurbo/Audio-separation-models-checker/tree/main</a></span></p><p class="c1"><span class="c0">Based on MUSDB18-HQ dataset&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;Q: Why SDR goes &lt;0 in silence parts? (song_006)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>A: SDR and SISDR behave weirdly when 1 of the input is silent, and that&#39;s why log_WMSE was made: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/crlandsc/torch-log-wmse/&amp;sa=D&amp;source=editors&amp;ust=1765035745067426&amp;usg=AOvVaw3yYabVGmT6YkS3Hd9TcV6s">https://github.com/crlandsc/torch-log-wmse/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Interestingly, L1freqMag metrics is giving same results than some users here (1296 a bit better for instrumentals, 1297 a bit better for vocals).&rdquo; jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.dus2zjzbt7dg"><span class="c21">Best ensemble finder for a song script</span></h4><p class="c2"><span class="c0">by Vinctekan</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1LUtBsCSym1iDHqADEusmACs-LF2lNYLw/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035745068410&amp;usg=AOvVaw2DC_TF3eDtcxJn7_gD4ZYw">https://drive.google.com/file/d/1LUtBsCSym1iDHqADEusmACs-LF2lNYLw/view?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">Currently, this optimized version can find the best combo of 9, 3 minute audio files in about 2 minutes and 40 seconds in Colab.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c2"><span>Refactored best </span><span class="c20">weighted </span><span class="c0">ensemble finder by jarredou</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Rm09z1wpj0Pi-6bFQ15u767n1XV95pDz/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035745069319&amp;usg=AOvVaw0ryNxMUPnxKLCQUjntnxS6">https://drive.google.com/file/d/1Rm09z1wpj0Pi-6bFQ15u767n1XV95pDz/view?usp=sharing</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c2"><span class="c0">&ldquo;That&#39;s what I&#39;ve used to find optimal weights for my MDX23 fork v2.5 update.</span></p><p class="c2"><span class="c0">It&#39;s still Nelder-Mead based optimizer, but code is way more simple/clean than 1st version.</span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">To use it, you need:</span></p><p class="c1"><span class="c0">A dataset of clean sources (with exact same filename scheme than mvsep multisong dataset).</span></p><p class="c1"><span class="c0">Process dataset mixtures with all the models you want to ensemble and put the outputs in different folders, 1 for each model (and still with exact same filename scheme than mvsep multisong dataset).</span></p><p class="c1"><span class="c0">librosa and scipy python libs</span></p><p class="c1"><span class="c0">then run (for example):</span></p><p class="c1"><span class="c0">weight_finder_v2.py \</span></p><p class="c1"><span class="c0">&nbsp; --ref c:\reference_dataset \</span></p><p class="c1"><span class="c0">&nbsp; --est c:\InstVoc c:\bsrofo1296 c:\kimrofo \</span></p><p class="c1"><span class="c0">&nbsp; --stem vocals \</span></p><p class="c1"><span class="c0">&nbsp; --extension flac \</span></p><p class="c1"><span class="c0">&nbsp; --tracks 100</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">--ref is clean sources&#39; folder path</span></p><p class="c1"><span class="c0">--est is estimates (separations) folder paths (multiple inputs)</span></p><p class="c1"><span class="c0">--stem is stem name (based on multisong dataset filename scheme)</span></p><p class="c1"><span class="c0">--extension is audio file extension (flac/wav...)</span></p><p class="c1"><span class="c0">--tracks is a number of tracks in a dataset.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It will process the datasets many times and change weights each time until it find the best balance. When finished, it will output weights scaled to 10 max value.</span></p><p class="c1"><span class="c0">Warning: it can take hours (or even days, depending on the number of models to ensemble, size of dataset and resources of computer)</span></p><p class="c1"><span class="c0">A python lib to align audio:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nomonosound/fast-align-audio&amp;sa=D&amp;source=editors&amp;ust=1765035745072497&amp;usg=AOvVaw0Lp4bGwQdgKTpYYwhkp6tx">https://github.com/nomonosound/fast-align-audio</a></span><span class="c0">&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><h4 class="c57 c27" id="h.784wd9d5jdkb"><span class="c21">Universal function to make different types of ensembles by ZFTurbo</span></h4><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cdn.discordapp.com/attachments/911050124661227542/1192220574982881320/ensemble.py&amp;sa=D&amp;source=editors&amp;ust=1765035745073052&amp;usg=AOvVaw2nLySJHeXUpxkvFq09eayS">https://cdn.discordapp.com/attachments/911050124661227542/1192220574982881320/ensemble.py</a></span></p><p class="c2"><span class="c0">I think it&rsquo;s the same or newer:</span></p><p class="c2"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/ensemble.py&amp;sa=D&amp;source=editors&amp;ust=1765035745073422&amp;usg=AOvVaw3jLBcMGj3ILIg2vqGJoTsQ">https://github.com/ZFTurbo/Music-Source-Separation-Training/blob/main/ensemble.py</a></span></p><p class="c2 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;In my experiments SDR for avg_wave always the max.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Now also jarredou made his Colab with the above implemented with comfy GUI:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Manual_Ensemble_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035745074152&amp;usg=AOvVaw054repC-cm9eLWqw6VUQtu">https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Manual_Ensemble_Colab.ipynb</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_____________________________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">____________________________________________________________________</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.yhu13dizwjvi"><span class="c42 c36 c51 c33 c24 c30">Volume compensation for MDX v2 models</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">How to automate calculation of volume compensation value for all older MDX models</span></p><p class="c1"><span class="c6">(results are not perfect and need to be fine-tuned)</span></p><p class="c1 c7"><span class="c42 c12 c15 c33"></span></p><p class="c1"><span class="c0">by jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">So, I have maybe a protocol to find accurate volume compensation:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Use a short .wav file of just noise (I&#39;ve used pink noise here) and pass it through the model you wanna evaluate</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Take the resulting audio, the one that will have all the noise in it and compare it to the original noise with this little python script that will give you the difference in dBTP and the quivalent VC ratio (you&#39;ll need to </span></p><p class="c1"><span class="c0">pip install librosa</span></p><p class="c1"><span class="c0">&nbsp;if you don&#39;t have it installed already). The results I&#39;ve found with it are coherent with the ones you&#39;ve found by ears ! (1.035437 for HQ2 / 1.022099 for KimFT other)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Here&#39;s the script :</span></p><p class="c1"><span class="c0">import numpy as np</span></p><p class="c1"><span class="c0">import argparse</span></p><p class="c1"><span class="c0">import librosa</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">def Diff_dBTP(file1,file2):</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; y1, sr1 = librosa.load(file1)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; y2, sr2 = librosa.load(file2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; true_peak1 = np.max(np.abs(y1))</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; true_peak2 = np.max(np.abs(y2))</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; difference = 20 * np.log10(true_peak1 / true_peak2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp; print(f&quot;Diff_dBTP : The difference in true peak between the two audio files is {difference:.6f} dB.&quot;)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; ratio = 10 ** (difference / 20)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; print(f&quot;The volume of sound2 is {ratio:.6f} times that of sound1.\n&quot;)</span></p><p class="c1"><span class="c0">&nbsp; </span></p><p class="c1"><span class="c0">if __name__ == &quot;__main__&quot;:</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; parser = argparse.ArgumentParser(description=&quot;Find volume difference of two audio files.&quot;)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; parser.add_argument(&quot;file1&quot;, help=&quot;Path to original audio file&quot;)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; parser.add_argument(&quot;file2&quot;, help=&quot;Path to extracted audio file&quot;)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; args = parser.parse_args()</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; </span></p><p class="c1"><span class="c0">&nbsp; &nbsp; Diff_dBTP(args.file1, args.file2)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c18 c15">Volume compensation values for various models (in reality they may differ +/- e.g. by 0.00xxxx, but maybe not much more)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">All values according to the script made by **jarredou**</span></p><p class="c1"><span class="c0">*(All default but Spectral Inversion - Off; Denoise Output: On; - the latter shouldn&#39;t affect the results if turned off)*:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; Kim Vocal_1 &nbsp; - &nbsp; 1.012819</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; Kim Vocal 2 - 1.009</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; voc_ft - 1.021 &nbsp; </span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; Kim ft other - 1.020 (Bas&#39; fine-tuned and SDR-validated)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET 1 &nbsp; &nbsp;- &nbsp; 1.017194</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET Inst 2 &nbsp; &nbsp;- &nbsp; 1.037748</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET Inst 3 &nbsp; &nbsp;- &nbsp; 1.043115</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET Inst HQ 1 &nbsp; &nbsp;- &nbsp; 1.052259</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET Inst HQ 2 &nbsp; &nbsp;- &nbsp; 1.047476</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET Inst Main &nbsp; &nbsp;- &nbsp; 1.037812 (actually it turned out to be 1.025)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET Main &nbsp; &nbsp;- &nbsp; 1.002124</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET-Inst_full_292 &nbsp; &nbsp;- &nbsp; 1.056003</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET_Inst_82_beta &nbsp; &nbsp;- &nbsp; 1.088610</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET_Inst_90_beta &nbsp; &nbsp;- &nbsp; 1.151219 (wtf)</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET_Main_340 &nbsp; &nbsp;- &nbsp; 1.002742</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET_Main_406 &nbsp; &nbsp;- &nbsp; 1.001850</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET_Main_427 &nbsp; &nbsp;- &nbsp; 1.002091</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR-MDX-NET_Main_438 &nbsp; &nbsp;- &nbsp; 1.001799</span></p><p class="c1"><span class="c0">&nbsp; &nbsp;- &nbsp; UVR_MDXNET_9482 &nbsp; &nbsp;- &nbsp; 1.007059</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;denoise is just processing twice with the second try inverted, after separation reinverted, to amplify the result, but remove the noise introduced by MDX, and then deamplified by 6dbs, so it still the same volume, just without MDX noise.</span></p><p class="c1"><span class="c0">Basically HV noise removal trick&quot;</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.ntgu6se9g0u5"><span class="c0">UVR-MDX parameters &amp; hashes decoded by Bas Curtiz</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Anjok07/ultimatevocalremovergui/blob/master/models/MDX_Net_Models/model_data/model_data.json&amp;sa=D&amp;source=editors&amp;ust=1765035745082164&amp;usg=AOvVaw3xaH-Y-umY-YzCzjEv5hQZ">https://github.com/Anjok07/ultimatevocalremovergui/blob/master/models/MDX_Net_Models/model_data/model_data.json</a></span><span>&nbsp;- </span><span class="c0">the link with hashes possess MDX models parameters.</span></p><p class="c1"><span class="c0">The above probably still doesn&rsquo;t possess all the models added in the update, e.g. Foxy model, but there are only 4-5 combinations of settings so far.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">File with newer models parameters:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/model_data_new.json&amp;sa=D&amp;source=editors&amp;ust=1765035745082979&amp;usg=AOvVaw2NnMLxS_pWFbnR5OUZIykJ">https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/model_data_new.json</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">All MDX-Net model parameters in UVR consist of these combinations:</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- HQ_4:</span></p><p class="c1"><span class="c0">self.n_fft = 6144 dim_f = 2560 dim_t = 8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- All older HQ fullbands:</span></p><p class="c1"><span class="c0">self.n_fft = 6144 dim_f = 3072 dim_t = 8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- kim vocal 1/2, kim ft other (inst), inst 1-3 (415-464), 427, voc_ft:</span></p><p class="c1"><span class="c0">self.n_fft = 7680 dim_f = 3072 dim_t = 8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- 496, Karaoke, 9.X (NET-X)</span></p><p class="c1"><span class="c0">self.n_fft = 6144 dim_f = 2048 dim_t = 8 (and 9 kuielab_a_vocals only)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Karaoke 2</span></p><p class="c1"><span class="c0">self.n_fft = 5120 dim_f = 2048 dim_t = 8</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- De-reverb by FoxJoy</span></p><p class="c1"><span class="c0">self.n_fft = 7680 dim_f = 3072 dim_t = 9</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.cb6cxq8g7i0v"><span class="c0">UVR model hash decode</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;I&#39;ve made this little script a while back to find those hashes.</span></p><p class="c1"><span class="c0">Use with model_hash_finder.py path_to_model_file.&rdquo; </span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/file/d/1D4TNKjuObNn6MSiss1PtmXPQoR3XJOwJ/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035745085071&amp;usg=AOvVaw2fRwwfnfrGalvLMlvwRxjq">https://drive.google.com/file/d/1D4TNKjuObNn6MSiss1PtmXPQoR3XJOwJ/view?usp=sharing</a></span><span>&nbsp;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It&#39;s a checksum hash but based only on the last 10MB of model files.&rdquo; (jarredou)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">full_band_inst_model_new_epoch_309.onnx fea6de84f625c6413d0ee920dd3ec32f</span></p><p class="c1"><span class="c0">full_band_inst_model_new_epoch_337.onnx 4bc04e98b6cf5efeb581a0f382b60499</span></p><p class="c1"><span class="c0">kim_ft_other.onnx b6bccda408a436db8500083ef3491e8b</span></p><p class="c1"><span class="c0">Kim_Vocal_1.onnx 73492b58195c3b52d34590d5474452f6</span></p><p class="c1"><span class="c0">Kim_vocal_2.onnx 970b3f9492014d18fefeedfe4773cb42</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Voc_FT.onnx 77d07b2667ddf05b9e3175941b4454a0</span></p><p class="c1"><span class="c0">kuielab_a_bass.onnx 6703e39f36f18aa7855ee1047765621d</span></p><p class="c1"><span class="c0">kuielab_a_drums.onnx dc41ede5961d50f277eb846db17f5319</span></p><p class="c1"><span class="c0">kuielab_a_other.onnx 26d308f91f3423a67dc69a6d12a8793d</span></p><p class="c1"><span class="c0">kuielab_a_vocals.onnx 5f6483271e1efb9bfb59e4a3e6d4d098</span></p><p class="c1"><span class="c0">kuielab_b_bass.onnx c3b29bdce8c4fa17ec609e16220330ab</span></p><p class="c1"><span class="c0">kuielab_b_drums.onnx 4910e7827f335048bdac11fa967772f9</span></p><p class="c1"><span class="c0">kuielab_b_other.onnx 65ab5919372a128e4167f5e01a8fda85</span></p><p class="c1"><span class="c0">kuielab_b_vocals.onnx 6b31de20e84392859a3d09d43f089515</span></p><p class="c1"><span class="c0">Reverb_HQ_By_FoxJoy.onnx cd5b2989ad863f116c855db1dfe24e39</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_1.onnx 2cdd429caac38f0194b133884160f2c6</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_2.onnx ceed671467c1f64ebdfac8a2490d0d52</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_3.onnx e5572e58abf111f80d8241d2e44e7fa4</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_full_292.onnx b06327a00d5e5fbc7d96e1781bbdb596</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_full_338.onnx 13819d85cad1c9d659343ba09ccf77a8</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_full_382.onnx 734b716c193493a49f8f1ad548451c48</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_full_386.onnx 2e4fcd9ec905f35d2b8216933b5009ff</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_full_403.onnx 94ff780b977d3ca07c7a343dab2e25dd</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_HQ_1.onnx 291c2049608edb52648b96e27eb80e95</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_HQ_2.onnx cc63408db3d80b4d85b0287d1d7c9632</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_HQ_2.onnx 55657dd70583b0fedfba5f67df11d711</span></p><p class="c1"><span class="c0">UVR-MDX-NET-Inst_Main.onnx 1c56ec0224f1d559c42fd6fd2a67b154</span></p><p class="c1"><span class="c0">UVR-MDX-NET_Inst_187_beta.onnx d2a1376f310e4f7fa37fb9b5774eb701</span></p><p class="c1"><span class="c0">UVR-MDX-NET_Inst_82_beta.onnx f2df6d6863d8f435436d8b561594ff49</span></p><p class="c1"><span class="c0">UVR-MDX-NET_Inst_90_beta.onnx 488b3e6f8bd3717d9d7c428476be2d75</span></p><p class="c1"><span class="c0">UVR-MDX-NET_Main_340.onnx 867595e9de46f6ab699008295df62798</span></p><p class="c1"><span class="c0">UVR-MDX-NET_Main_390.onnx 398580b6d5d973af3120df54cee6759d</span></p><p class="c1"><span class="c0">UVR-MDX-NET_Main_406.onnx 5d343409ef0df48c7d78cce9f0106781</span></p><p class="c1"><span class="c0">UVR-MDX-NET_Main_427.onnx b33d9b3950b6cbf5fe90a32608924700</span></p><p class="c1"><span class="c0">UVR-MDX-NET_Main_438.onnx e7324c873b1f615c35c1967f912db92a</span></p><p class="c1"><span class="c0">UVR_MDXNET_1_9703.onnx a3cd63058945e777505c01d2507daf37</span></p><p class="c1"><span class="c0">UVR_MDXNET_2_9682.onnx d94058f8c7f1fae4164868ae8ae66b20</span></p><p class="c1"><span class="c0">UVR_MDXNET_3_9662.onnx d7bff498db9324db933d913388cba6be</span></p><p class="c1"><span class="c0">UVR_MDXNET_9482.onnx 0ddfc0eb5792638ad5dc27850236c246</span></p><p class="c1"><span class="c0">UVR_MDXNET_KARA.onnx 2f5501189a2f6db6349916fabe8c90de</span></p><p class="c1"><span class="c0">UVR_MDXNET_KARA_2.onnx 1d64a6d2c30f709b8c9b4ce1366d96ee</span></p><p class="c1"><span class="c0">UVR_MDXNET_Main.onnx 53c4baf4d12c3e6c3831bb8f5b532b93</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VR de-reverb models decode</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">UVR-De-Echo-Normal.pth = f200a145434efc7dcf0cd093f517ed52</span></p><p class="c1"><span class="c0">UVR-De-Echo-Aggressive.pth = 6857b2972e1754913aad0c9a1678c753</span></p><p class="c1"><span class="c0">UVR-DeEcho-DeReverb.pth = 0fb9249ffe4ffc38d7b16243f394c0ff</span></p><p class="c1"><span>So they&rsquo;re all &quot;4band_v3.json&quot; &nbsp;config file (from </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/TRvlvr/application_data/blob/main/vr_model_data/model_data.json&amp;sa=D&amp;source=editors&amp;ust=1765035745090956&amp;usg=AOvVaw1tCIqmaK3h6rv7QFU5ZZ1c">here</a></span><span class="c0">)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">More thorough chart by David Duchamp a.k.a. Captain FLAM:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1XZAyKmgJkKE3fVKrJm9pBGIXIcSQC3GWYYI90b_ul1M/edit%23gid%3D366525450&amp;sa=D&amp;source=editors&amp;ust=1765035745091650&amp;usg=AOvVaw3OI0JNFOMHfb70SCY1Miwi">https://docs.google.com/spreadsheets/d/1XZAyKmgJkKE3fVKrJm9pBGIXIcSQC3GWYYI90b_ul1M</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">___</span></p><h5 class="c5" id="h.l5v4dmylg8vo"><span class="c42 c36 c51 c33 c24 c30">Voice Cloning</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;RVC and some of its forks (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://docs.applio.org/&amp;sa=D&amp;source=editors&amp;ust=1765035745092242&amp;usg=AOvVaw180BSOD75Z0o62TXIAKOYA">Applio</a></span><span>, Mangio, etc) are genuine free, open source ones for inference and training. For realtime voice changer that uses RVC models, there&#39;s w-okada: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://rentry.co/VoiceChangerGuide&amp;sa=D&amp;source=editors&amp;ust=1765035745092759&amp;usg=AOvVaw3TpSWwZSJJeZDNZ5lNlB1q">https://rentry.co/VoiceChangerGuide</a></span><span class="c0">&rdquo; no guide for Linux though.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.tryreplay.io/&amp;sa=D&amp;source=editors&amp;ust=1765035745093070&amp;usg=AOvVaw09I3ngjzutQ0Ml2kykIcF5">https://www.tryreplay.io/</a></span></p><p class="c1"><span class="c0">&ldquo;Url downloads, local files, massive database of models, both huggingface and weightsgg, in built separation models, options to skip that part if you have vocals, ability to use multiple ai models for one particular result, and the option to either merge or just get multiple results at the end, plus whatever else, de-reverb and stuff&rdquo; it has voc_ft vocal model from UVR5.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;even my old laptop still can inferencing using applio</span></p><p class="c1"><span class="c0">i3 3217u 1.8ghz</span></p><p class="c1"><span class="c0">intel hd 4000&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>And you&rsquo;re probably aware already that RVC Colabs to train voice cloned models are banned.</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c5" id="h.2jk25wjmsohe"><span class="c42 c36 c33 c24 c30 c51">Stable Audio Open Gen</span></h5><p class="c55"><span class="c0">Available on MVSEP in the Experimental section. It&rsquo;s not for separation, but generating sounds.</span></p><p class="c55"><span class="c0">ZFTurbo: &ldquo;Algorithm based on model:</span></p><p class="c55"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/stabilityai/stable-audio-open-1.0&amp;sa=D&amp;source=editors&amp;ust=1765035745095085&amp;usg=AOvVaw13xoFNkB5elKZ40qeSmHfJ">https://huggingface.co/stabilityai/stable-audio-open-1.0</a></span></p><p class="c55"><span class="c0">Audio is generated in Stereo format with a sample rate of 44.1 kHz and duration up to 47 seconds. The quality is quite high. It&#39;s better to make prompts in English.</span></p><p class="c55"><span class="c36 c58 c76">&nbsp;</span><span class="c0">Example prompts:</span></p><p class="c55"><span class="c0">1) Sound effects generation: cats meow, lion roar, dog bark</span></p><p class="c55"><span class="c0">2) Sample generation: 128 BPM tech house drum loop</span></p><p class="c55"><span class="c0">3) Specific instrument generation: A Coltrane-style jazz solo: fast, chaotic passages (200 BPM), with piercing saxophone screams and sharp dynamic changes</span></p><p class="c55"><span class="c36 c58 c76">&nbsp;</span><span class="c0">Examples:</span></p><p class="c55"><span>Cat meow:</span><span><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612092110-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745096724&amp;usg=AOvVaw0iHNiBl7FfxA9ALqGOnRr4">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612092110-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745097057&amp;usg=AOvVaw14BgTIKnnwyxMJEzmi_kE5">https://mvsep.com/result/20250612092110-b297c082fb-generated.wav</a></span></p><p class="c55"><span>Dog bark:</span><span><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612115517-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745097254&amp;usg=AOvVaw0E0TNp5AqdRJDRsFvbugXK">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612115517-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745097425&amp;usg=AOvVaw3gGPUXNeRChTLPW-3gN2Bc">https://mvsep.com/result/20250612115517-b297c082fb-generated.wav</a></span></p><p class="c55"><span>128 BPM tech house drum loop:</span><span><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612115841-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745097605&amp;usg=AOvVaw2DPi_ULIfIf9ax1RyQpsVA">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612115841-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745097774&amp;usg=AOvVaw1NV5MDaiTE9kYsnQCJKRzO">https://mvsep.com/result/20250612115841-b297c082fb-generated.wav</a></span></p><p class="c55"><span>Violin solo:</span><span><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612120111-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745097935&amp;usg=AOvVaw2uD2i2iu7PWZakrcNCTiCw">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612120111-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745098133&amp;usg=AOvVaw30su-KIss68Npv_yECRU83">https://mvsep.com/result/20250612120111-b297c082fb-generated.wav</a></span></p><p class="c55"><span>Woman sing song &quot;Happy Birthday to you&quot;:</span><span><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612120433-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745098383&amp;usg=AOvVaw1OTbpxMOBneCY7rVGN3050">&nbsp;</a></span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://mvsep.com/result/20250612120433-b297c082fb-generated.wav&amp;sa=D&amp;source=editors&amp;ust=1765035745098656&amp;usg=AOvVaw2sU0Vxp9rRNvWT6edCAA0j">https://mvsep.com/result/20250612120433-b297c082fb-generated.wav</a></span><span class="c0">&rdquo;</span></p><p class="c64"><span class="c0">&nbsp;</span></p><p class="c1"><span class="c0">__________</span></p><h5 class="c5" id="h.8uxrvfoxzav6"><span class="c42 c36 c51 c33 c24 c30">Links for research on separation</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/AudioMAE&amp;sa=D&amp;source=editors&amp;ust=1765035745099281&amp;usg=AOvVaw2nmmeJnkZeVt153NvopWyj">https://github.com/facebookresearch/AudioMAE</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.02802&amp;sa=D&amp;source=editors&amp;ust=1765035745099443&amp;usg=AOvVaw2nDtjzuh75r7MMdcdfFzFt">https://arxiv.org/abs/2310.02802</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/pbelcak/fastfeedforward&amp;sa=D&amp;source=editors&amp;ust=1765035745099617&amp;usg=AOvVaw2o8E0xtcJgeUIJbNs2hcqP">https://github.com/pbelcak/fastfeedforward</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/corl-team/rebased&amp;sa=D&amp;source=editors&amp;ust=1765035745099771&amp;usg=AOvVaw2FslLdJOl5Fg_U9NkDpnu7">https://github.com/corl-team/rebased</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/bowang-lab/U-Mamba/tree/main&amp;sa=D&amp;source=editors&amp;ust=1765035745100007&amp;usg=AOvVaw0amyRsePwRYzmdEY8-lsyN">https://github.com/bowang-lab/U-Mamba/tree/main</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.unite.ai/mamba-redefining-sequence-modeling-and-outforming-transformers-architecture/&amp;sa=D&amp;source=editors&amp;ust=1765035745100305&amp;usg=AOvVaw3RebXqhYeJrzH3jLDRRfJn">https://www.unite.ai/mamba-redefining-sequence-modeling-and-outforming-transformers-architecture/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/state-spaces/mamba&amp;sa=D&amp;source=editors&amp;ust=1765035745100502&amp;usg=AOvVaw151CW5jA-P_edggLsBNUkr">https://github.com/state-spaces/mamba</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/apapiu/mamba_small_bench&amp;sa=D&amp;source=editors&amp;ust=1765035745100679&amp;usg=AOvVaw0egrmeF7pyM9CsP23c9NCG">https://github.com/apapiu/mamba_small_bench</a></span></p><p class="c1"><span class="c0">(&ldquo;this one is actually exciting because it runs faster and leaner than transformers and promises to surpass them in quality</span></p><p class="c1"><span class="c0">&gt;What makes Mamba truly unique is its departure from traditional attention and MLP blocks. This simplification leads to a lighter, faster model that scales linearly with the sequence length &ndash; a feat unmatched by its predecessors. Mamba has demonstrated superior performance in various domains, including language, audio, and genomics...&rdquo;)</span></p><p class="c1"><span class="c0">&ldquo;mamba is real fucking complicated. like reaaaally complicated (...) hyper params do seem hard to adjust tho.&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;mamba is kinda sick but its early days in the SSM space, so lots of the tricks that you can do with transformers you can&#39;t do with SSMs because they haven&#39;t become mainstream</span></p><p class="c1"><span class="c0">but mamba has two very cool properties</span></p><p class="c1"><span class="c0">it has positional information by its nature - i.e. no extra computation is required to embed positional info</span></p><p class="c1"><span class="c0">linear time complexity - so in audio it&#39;s super useful because audio data hits the On^2 complexity (if the chunksize is large enough)&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;i personally don&#39;t trust any of the mamba papers - they either say how mamba is the best thing since sliced bread or worse than 3 year old transformers</span></p><p class="c1"><span class="c0">although the paper I read for that was questionable&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.harvard.edu/kempner-institute/2024/02/02/repeat-after-me-transformers-are-better-than-state-space-models-at-copying-2/&amp;sa=D&amp;source=editors&amp;ust=1765035745103363&amp;usg=AOvVaw3zjNuj0-f_1ewcy1u19Tzk">https://www.harvard.edu/kempner-institute/2024/02/02/repeat-after-me-transformers-are-better-than-state-space-models-at-copying-2/</a></span><span class="c0">&rdquo;</span></p><p class="c1"><span class="c0">&ldquo;they don&#39;t even replace the mask estimator thing in bs-roformer with mamba&rdquo;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.02063&amp;sa=D&amp;source=editors&amp;ust=1765035745103708&amp;usg=AOvVaw2oZDrtEoDILPKHSZ3phCXF">https://arxiv.org/abs/2404.02063</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2401.09417&amp;sa=D&amp;source=editors&amp;ust=1765035745103906&amp;usg=AOvVaw2_OUTiYMn7XgXKQBpViOt7">https://arxiv.org/abs/2401.09417</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/hustvl/Vim&amp;sa=D&amp;source=editors&amp;ust=1765035745104044&amp;usg=AOvVaw02vrvTx3Ej4eqfKQ1omTVj">https://github.com/hustvl/Vim</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/RobinBruegger/RevTorch&amp;sa=D&amp;source=editors&amp;ust=1765035745104209&amp;usg=AOvVaw04KJXz8PZ40weRi7mauRN1">https://github.com/RobinBruegger/RevTorch</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://huggingface.co/blog/rwkv&amp;sa=D&amp;source=editors&amp;ust=1765035745104357&amp;usg=AOvVaw0jaq-3lLJb7u2deteDsyJl">https://huggingface.co/blog/rwkv</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Why does music source separation benefit from cacophony?</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.18407&amp;sa=D&amp;source=editors&amp;ust=1765035745104658&amp;usg=AOvVaw16NfzXIFKfn0EJfBlYx6KY">https://arxiv.org/abs/2402.18407</a></span></p><p class="c1"><span class="c0">It makes our side chain stem limiting thing irrelevant.</span></p><p class="c1"><span class="c0">&ldquo;As the paper demonstrate that using only randomly mixed stems is more efficient for training than using only real paired stems (from the same song and sync), in that random mix config, the individual stems will never be against the mixture that was used to limit them, so making that process irrelevant&rdquo; jarredou</span></p><p class="c1"><span class="c0">MDX23C training code by ZFTurbo has the mix randomization feature built-in - dataset type 1 is random mix, dataset type 4 is the real mix (aligned).</span></p><p class="c1"><span class="c0">&ldquo;I think now after reading that paper that once you have a dataset large enough and using the random mixing with some simple augmentations like gain changes/channel swap/phase inversion/EQ/soft-clipping(tanh), you&#39;re good to good and can forget more ressource intensive augmentations like pitch shifting and time stretching, that can really slow down training. Maybe just reverbs can be still usefull even if it need more resources than simple math processing.</span></p><p class="c1"><span class="c0">So really go fast/minimal on pre-processing in fact.&rdquo; -||-</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;The only good paper about SDR I have in mind is &quot;SDR - half-baked or well done?&quot; </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/1811.02508&amp;sa=D&amp;source=editors&amp;ust=1765035745106902&amp;usg=AOvVaw1azr26RPzjSJXkyCfR-i4u">https://arxiv.org/abs/1811.02508</a></span></p><p class="c1"><span class="c0">from 2018, but maybe there are some more recent ones on the subject</span></p><p class="c1"><span>There&#39;s also that thesis that is interesting but maybe also outdated now (as based on the old OpenUnmix), about loss functions effect on source separation learning: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1191134740284190750&amp;sa=D&amp;source=editors&amp;ust=1765035745107725&amp;usg=AOvVaw1c_Ec0__8kimABWMPH6aD_">https://discord.com/channels/708579735583588363/911050124661227542/1191134740284190750</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">My go-to URLs to follow publications:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/list/cs.SD/pastweek?show%3D2000&amp;sa=D&amp;source=editors&amp;ust=1765035745108118&amp;usg=AOvVaw1wOAr3KY6SuhJn4U62cV4N">https://arxiv.org/list/cs.SD/pastweek?show=2000</a></span></p><p class="c1"><span class="c0">(weekly list)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/list/eess.AS/pastweek?show%3D200&amp;sa=D&amp;source=editors&amp;ust=1765035745108381&amp;usg=AOvVaw0kprQ9R0EFVZr7VzSPcK_3">https://arxiv.org/list/eess.AS/pastweek?show=200</a></span></p><p class="c1"><span class="c0">(weekly list)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>I&#39;ve registered to </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.scholar-inbox.com&amp;sa=D&amp;source=editors&amp;ust=1765035745108656&amp;usg=AOvVaw3yNhyjPaQVnz6nhyP9u6Qg">https://www.scholar-inbox.com</a></span></p><p class="c1"><span class="c0">recently (it&#39;s free), which can be handy (but lots of duplicate if you follow already arxiv publications above)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>and also: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://twitter.com/csteinmetz1/&amp;sa=D&amp;source=editors&amp;ust=1765035745109064&amp;usg=AOvVaw36T3ajgQ3P7jy8J0zBkZha">https://twitter.com/csteinmetz1/</a></span></p><p class="c1"><span class="c0">for sure&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Griffin: Mixing Gated Linear Recurrences with Local Attention for E&hellip;</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.19427&amp;sa=D&amp;source=editors&amp;ust=1765035745109434&amp;usg=AOvVaw0FJCoAp-8u9ejydWM3ihOb">https://arxiv.org/abs/2402.19427</a></span></p><p class="c1"><span class="c0">new tweak to a modern transformer architecture improves performance</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/IAHispano/gdown&amp;sa=D&amp;source=editors&amp;ust=1765035745109749&amp;usg=AOvVaw2W1jyglZnx1aykA8KxKElg">https://github.com/IAHispano/gdown</a></span></p><p class="c1"><span class="c0">If you have some issues with downloading files from GDrive on Colab</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Can you recommend something to automate adding effects (and if possible randomized)</span></p><p class="c1"><span>A: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://pytorch.org/audio/stable/generated/torchaudio.io.AudioEffector.html%23torchaudio.io.AudioEffector&amp;sa=D&amp;source=editors&amp;ust=1765035745110396&amp;usg=AOvVaw0nZx39A2ljHJDnzgiHP5vR">https://pytorch.org/audio/stable/generated/torchaudio.io.AudioEffector.html#torchaudio.io.AudioEffector</a></span></p><p class="c1"><span>maybe even </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://ccrma.stanford.edu/planetccrma/man/man1/sox.1.html&amp;sa=D&amp;source=editors&amp;ust=1765035745110643&amp;usg=AOvVaw113_80F8fkq9PkdtvF1EDB">http://ccrma.stanford.edu/planetccrma/man/man1/sox.1.html</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/iver56/audiomentations&amp;sa=D&amp;source=editors&amp;ust=1765035745110879&amp;usg=AOvVaw02jOPD9eID0Vq-o3OrmaFm">https://github.com/iver56/audiomentations</a></span></p><p class="c1"><span class="c0">&nbsp;(which uses random parameters by design)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/spotify/pedalboard&amp;sa=D&amp;source=editors&amp;ust=1765035745111188&amp;usg=AOvVaw3DBgQblf-tQbfL8n5Bki5P">https://github.com/spotify/pedalboard</a></span></p><p class="c1"><span class="c0">(take a look at the augmentations in ZFTurbo script (dataset.py), it uses both libs with randomized parameters also for pedalboard) </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Q: What Transformer and Mamba is</span></p><p class="c1"><span>A: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DXfpMkf4rD6E&amp;sa=D&amp;source=editors&amp;ust=1765035745111733&amp;usg=AOvVaw2FBVPicSRpF9vLE0Km2HcT">https://www.youtube.com/watch?v=XfpMkf4rD6E</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D9dSkvxS2EB0&amp;sa=D&amp;source=editors&amp;ust=1765035745111920&amp;usg=AOvVaw3_I89isynpUMpI1pY-6PUh">https://www.youtube.com/watch?v=9dSkvxS2EB0</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Side-note: with a bit of tweaking, ZFTurbo training script can be edited to train a reverb model, generating the randomized reverb on the fly with pedalboard.Reverb (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://spotify.github.io/pedalboard/reference/pedalboard.html%23pedalboard.Reverb&amp;sa=D&amp;source=editors&amp;ust=1765035745112519&amp;usg=AOvVaw1ZNcRV7arDRhqViTLtfALu">https://spotify.github.io/pedalboard/reference/pedalboard.html#pedalboard.Reverb</a></span><span class="c0">) and using reverbs IRs to have more diversity</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://openaccess.thecvf.com/content/CVPR2022/papers/Mangalam_Reversible_Vision_Transformers_CVPR_2022_paper.pdf&amp;sa=D&amp;source=editors&amp;ust=1765035745112994&amp;usg=AOvVaw2utpd5_3uo4FCiMA23O111">https://openaccess.thecvf.com/content/CVPR2022/papers/Mangalam_Reversible_Vision_Transformers_CVPR_2022_paper.pdf</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2306.09342&amp;sa=D&amp;source=editors&amp;ust=1765035745113147&amp;usg=AOvVaw3G7mScNX9beUxIU0sYAvqO">https://arxiv.org/abs/2306.09342</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Fork of ZFTurbo training code, but I don&rsquo;t know with what changes (by frazer):</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/fmac2000/Music-Source-Separation-Training-Models/tree/revnet&amp;sa=D&amp;source=editors&amp;ust=1765035745113611&amp;usg=AOvVaw3wPSFm0Vs6IcxmM6ZTcZez">https://github.com/fmac2000/Music-Source-Separation-Training-Models/tree/revnet</a></span></p><p class="c1"><span class="c0">Another (by joowon)</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/mapperize/Music-Source-Separation-Training&amp;sa=D&amp;source=editors&amp;ust=1765035745113899&amp;usg=AOvVaw0rp5_t63bGcR59y3fZQA4g">https://github.com/mapperize/Music-Source-Separation-Training</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Another (not so new) paper with maybe interesting concept improving separations quality that couldb may be reproduced:</span></p><p class="c1"><span class="c0">VocEmb4SVS: Improving Singing Voice Separation</span></p><p class="c1"><span class="c0">with Vocal Embeddings</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://www.apsipa.org/proceedings/2022/APSIPA%25202022/TuAM1-7/1570836845.pdf&amp;sa=D&amp;source=editors&amp;ust=1765035745114631&amp;usg=AOvVaw04o1JpJ1QmSOjYEUM0s8SJ">http://www.apsipa.org/proceedings/2022/APSIPA%202022/TuAM1-7/1570836845.pdf</a></span></p><p class="c1"><span>There&#39;s also a demo site for the 4-stem version, but I haven&#39;t found any publication/code </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://cathy0610.github.io/2023-SrcEmb4MSS/&amp;sa=D&amp;source=editors&amp;ust=1765035745114970&amp;usg=AOvVaw0Qsom88EwFUSunuUWuLyDP">https://cathy0610.github.io/2023-SrcEmb4MSS/</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&quot;Demucs employs a combination of L1 loss and deep clustering loss to optimize source separation.&quot; (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/demucs/issues/458&amp;sa=D&amp;source=editors&amp;ust=1765035745115351&amp;usg=AOvVaw0lbNAEmtZ8YHk_Ks0pCjOI">https://github.com/facebookresearch/demucs/issues/458</a></span><span>) I&#39;ve found this paper few months ago, its findings are based only on openunmix arch, the observed behaviour could be different with other archs, but it&#39;s still very interesting: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2202.07968&amp;sa=D&amp;source=editors&amp;ust=1765035745115736&amp;usg=AOvVaw2dy6Zuvc1aSA_fUHg7pUuf">https://arxiv.org/abs/2202.07968</a></span><span class="c0">&rdquo;</span></p><p class="c1"><span class="c0">Not really in MDX23 code made by ZFTurbo:</span></p><p class="c1"><span class="c0">&ldquo;By default, my code uses loss proposed by kueilab team. They use MSE but skip sample with worst loss (to avoid problems in dataset). mse loss can be used directly with --mse_loss &nbsp;argument.</span></p><p class="c1"><span class="c0">Also, auraloss is included in my code too. I experimented with it, but it didn&#39;t allow to gain additional profit comparing to standard loss function.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Useful lib to experiment with different loss functions:</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/csteinmetz1/auraloss&amp;sa=D&amp;source=editors&amp;ust=1765035745116779&amp;usg=AOvVaw3JKMjgyrbjckIxOya-yNzV">https://github.com/csteinmetz1/auraloss</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>I&#39;ve seen that paper in my feed last month, doing real-time source separation (23ms latency): </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.17701&amp;sa=D&amp;source=editors&amp;ust=1765035745117143&amp;usg=AOvVaw3i-ZYI9In43hLitUmV1GOj">https://arxiv.org/abs/2402.17701</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Mamba: Linear-Time Sequence Modeling with Selective State Spaces</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D9dSkvxS2EB0&amp;sa=D&amp;source=editors&amp;ust=1765035745117548&amp;usg=AOvVaw0d72vpCRfkXq-T-HdTCSlU">https://www.youtube.com/watch?v=9dSkvxS2EB0</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Vocal restoration research</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/facebookresearch/AudioMAE&amp;sa=D&amp;source=editors&amp;ust=1765035745117927&amp;usg=AOvVaw3yoF6HXlafVT7oLPSaChAa">https://github.com/facebookresearch/AudioMAE</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://carlosholivan.github.io/demos/audio-restoration-2023.html&amp;sa=D&amp;source=editors&amp;ust=1765035745118169&amp;usg=AOvVaw3CIHrbPd2oh_A8ry8Zq4zb">https://carlosholivan.github.io/demos/audio-restoration-2023.html</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://google.github.io/df-conformer/miipher/&amp;sa=D&amp;source=editors&amp;ust=1765035745118360&amp;usg=AOvVaw0Ulm2QK-JW0QqlojOCY-hJ">https://google.github.io/df-conformer/miipher/</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2403.05393&amp;sa=D&amp;source=editors&amp;ust=1765035745118531&amp;usg=AOvVaw0ZiAOqiChT9kdaSKv7fY8d">https://arxiv.org/abs/2403.05393</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/vikastokala/bcctn&amp;sa=D&amp;source=editors&amp;ust=1765035745118704&amp;usg=AOvVaw32MD_tKlqJpE9EkU412ACi">https://github.com/vikastokala/bcctn</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/espnet/espnet&amp;sa=D&amp;source=editors&amp;ust=1765035745118867&amp;usg=AOvVaw35yHiSq-3j_onsVzoP5oIm">https://github.com/espnet/espnet</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/manosplitsis/hifi-gan-bwe/tree/train_with_music&amp;sa=D&amp;source=editors&amp;ust=1765035745119131&amp;usg=AOvVaw0NwnxDrCI1mma-B-u8gcCs">https://github.com/manosplitsis/hifi-gan-bwe/tree/train_with_music</a></span></p><p class="c1"><span class="c0">&ldquo;new vocoder replacing hifi-gan, vocos, bigvgan etc</span></p><p class="c1"><span class="c0">compared to other ones, high freq smearing practically doesn&#39;t occur&rdquo;</span></p><p class="c1"><span class="c0">EVA-GAN - another breakthrough over HiFi-GAN</span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.00892&amp;sa=D&amp;source=editors&amp;ust=1765035745119757&amp;usg=AOvVaw00bZZvU--XH7czsARXoAMM">https://arxiv.org/abs/2402.00892</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://arxiv.org/pdf/2402.00892.pdf&amp;sa=D&amp;source=editors&amp;ust=1765035745119969&amp;usg=AOvVaw0YsOOZy0n9kWijMWlYoVk4">https://arxiv.org/pdf/2402.00892.pdf</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">What can potentially help on training on inferior GPUS with large model size is LORA.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;especially since bsrofromer is transformer</span></p><p class="c1"><span class="c0">then you can allow users to finetune even the largest</span></p><p class="c1"><span class="c0">loras work by going through a model and replacing all the linear projections with a wider projection (then i think projecting back to the original size)</span></p><p class="c1"><span class="c0">so imagine you got a linear projection thats trained, ie its 4 neurons in 4 neurons out - lora works by adding X neurons either side of the projection (i cant really remember but its somethign like this) </span></p><p class="c1"><span class="c0">then you freeze all the other stuff around the linears and only train the new linears (the lora)</span></p><p class="c1"><span class="c0">if you open up the lora source code you&#39;ll see what i mean, theres a loop that just iterates all the weights and replaces the linears with a loralinear (and thats the entire method)</span></p><p class="c1"><span class="c0">lora will allow for better SDR on whatever you trained (albeit a small sample set)</span></p><p class="c1"><span class="c0">so itd be super smart to treat it like how image gen treats it, so u can say make a lora for crowd removal mixed with the lora for vocals</span></p><p class="c1"><span class="c0">then ppl in this disc can try create the best lora for their specific usecase and mix match with other&#39;s&quot; frazer</span></p><p class="c1"><span class="c0">More: https://radekosmulski.com/how-to-fine-tune-a-tranformer-pt-2/</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&quot;I think here it can be useful if we will have very great multistem model and after finetune it on rare instruments.&quot; ZFTurbo</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/Human9000/nd-Mamba2-torch&amp;sa=D&amp;source=editors&amp;ust=1765035745122804&amp;usg=AOvVaw1YwkbmUR1yHnHIuFsa1uph">https://github.com/Human9000/nd-Mamba2-torch</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">Visit our </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/1220364005034561628&amp;sa=D&amp;source=editors&amp;ust=1765035745123107&amp;usg=AOvVaw1wPY9DdXuRsHMOSg5X9XPo">#dev-talk</a></span><span class="c6">&nbsp;channel for more</span></p><p class="c1 c7"><span class="c0"></span></p><h5 class="c59 c27" id="h.6brljt8lbd7b"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D-pcVN54cgw0&amp;sa=D&amp;source=editors&amp;ust=1765035745123333&amp;usg=AOvVaw3VzetCZwxVvHeuyj6LDnCO">Anjok&rsquo;s interview </a></span><span class="c42 c36 c51 c33 c24 c30">on YT</span></h5><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">TL;DW: UVR&rsquo;s documentary + training, archs and demudder explained</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Anjok is the developer of Ultimate Vocal Remover 5 (UVR5 GUI).</span></p><p class="c1"><span class="c0">He intended UVR to be a Swiss army tool - to contain everything you need for separation, and also contain models made by the community (e.g. dereverb/denoise/deecho).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">History of UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Anjok in times where Spleeter was still a thing, found a VR arch made by Japanese developer, tsurumeso, and received better results than Spleeter. He started to make his own model on laptop 1060 6GB on 100 or 150 pairs with the absolute minium parameters, and it turned out to be a better model than tsurumeso&#39;s one. Later he transitioned to faster GPU (probably before 3090 yet).</span></p><p class="c1"><span class="c0">Anjok wanted GUI for VR, and found BoskanDilan on Fiver and simply contracted him, paying to build the foundations of what UVR is today. BoskanDilan turned out to be a very good and talented coder.</span></p><p class="c1"><span class="c0">They put the work on GitHub, and Aufr33 contacted Anjok with ideas on how the VR models can be improved etc.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Then BoskanDilan left in mid 2021 for personal reasons. Then the GUI work was taken by Anjok who was mentored by BoskanDilan to improve on understanding the coding. Anjok started to working on UVR exclusively, spending 10 hours a day for UVR in 2022. </span></p><p class="c1"><span class="c0">He decided to make a simple installer in one package, as he received lots of issues on GutHub, from people not knowing how to install it. He also re-coded the UVR to make the code easier to maintain. Then Bas Curtiz helped Anjok on design aspects of UVR, e.g. designed new logo, and gave some advice, and good amount of feedback from UVR user perspective. Early 2022 phase of UVR development took a lot of advice from early users of UVR.</span></p><p class="c1"><span class="c0">In May 2022 there was a first installer released to make UVR more accessible without e.g. installing Python or other dependencies and specialized programming knowledge to set up a proper environment.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Anjok was still in charge of introducing other archs than VR into UVR, being simply the only one behind the process, while normally bigger teams work on projects of that scale, when e.g. different archs could be coded into UVR by different developers. It was a stressful period of time, because Anjok intended to make the software which is free of bugs, and still not fully rely on the community in terms of bug reporting.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Then the Mac version came out and M1/M2/M3 support for faster GPU acceleration. Anjok found out in Demucs repo a part of the code, making it easier to port UVR to Macs, and it is used by every model. Music community is pretty Mac-centered, and he devoted a considerable amount of time to make it work reliably on Macs too.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In the new UVR version there&#39;s a planned demudder to be introduced (described later), and possibly translations.</span></p><p class="c1"><span class="c0">Anjok currently trains a new model coming in several weeks.</span></p><p class="c1"><span class="c0">It&#39;s intended to be a little smaller in order to be not so resource intensive, but also better than the best current MDX-Net model.</span></p><p class="c1"><span class="c0">Update 01.03.24</span></p><p class="c1"><span class="c0">&ldquo;I&#39;m going to allow HQ4 to continue training beyond 1500+ epochs as an experiment (it&#39;s currently at 1200), and interestingly, the SDR has been steadily increasing. It has significantly surpassed HQ3 in terms of SDR and listening tests, and it also outperformed MDXC23 in listening tests, though not in SDR (yet!). The most recent evaluation on the multi-dataset showed a score of 15.85, using the default settings. Clearly, there&#39;s a limit to how much further training can enhance performance, but up to this point, improvements are still being observed. This model has been in training since October! I&#39;m chipping away at the next GUI update as well, and the demudder will be in it.&rdquo;</span></p><p class="c1"><span class="c0">The model was released, with already HQ_5 scheduled in following month/s.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">The archs in UVR and their technicalities summarized</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">VR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">VR uses audio spectrograms and converts them to FFT spectrograms.</span></p><p class="c1"><span class="c0">VR uses only magnitude spectrograms, not phase.</span></p><p class="c1"><span class="c0">Phase represents timing where the data is, while magnitude represents the intensity of each frequency.</span></p><p class="c1"><span class="c0">Phase is much harder to predict.</span></p><p class="c1"><span class="c0">Actually VR uses original phase from the mixture and saves it during the process &quot;and it just does the magnitude&quot;.</span></p><p class="c1"><span class="c0">That&#39;s the reason why VR tends to have more artefacts in it. The smearing in instrumentals of VR is because the phase from the mixture is still in there.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Aufr33 later introduced 4 bands support for UVR.</span></p><p class="c1"><span class="c0">Let&#39;s say for first of three bands between 0-700Hz there will be different resolution, for all other frequency ranges there will be different. E.g. knowing that vocals are in specific frequency range, you can optimize it further.</span></p><p class="c1"><span class="c0">That feature made UVR and VR arch much better.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Later they introduced - </span></p><p class="c1"><span class="c6">Ensembling</span></p><p class="c1"><span class="c0">So a way to use multiple models to potentially get better results.</span></p><p class="c1"><span class="c0">The three ways of ensembling:</span></p><p class="c1"><span class="c0">avg - gets the average of vocals/instrumentals</span></p><p class="c1"><span class="c0">max - is maximum result of each stem, e.g. in a vocal you&#39;ll get the heaviest weighted vocal from each model, and the same goes for instrumental, giving a bit cleaner results, but more artefacts</span></p><p class="c1"><span class="c0">min</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">MDX-Net</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Uses full spectrogram with phase and magnitude</span></p><p class="c1"><span class="c0">Tradeoff is muddier results, but natural, cleaner sound.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Training</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Anjok separated on nearly every genre you can think of, and stated that the hardest genre for separation is metal and vocal-centered mixes. Also, if the instrumental has lot of noise, e.g. distorted guitars, the instrumental will come out muddier.</span></p><p class="c1"><span class="c0">MDX-Net was the arch, addressing lots of VR issues in its core.</span></p><p class="c1"><span class="c0">Tracks from 70-80s can separate well. 50-60s will be harder, e.g. recorded in mono. Early stereo era gets a little better.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A good model needs to be as good as the dataset for a model.</span></p><p class="c1"><span class="c0">There was lots of work scrapping it from the internet.</span></p><p class="c1"><span class="c0">Aufr33 was the mastermind behind Karaoke model and its dataset.</span></p><p class="c1"><span class="c0">Demucs model wasn&#39;t as successful, as probably was more meant for more stems, and MDX-Net gave better results for 2 stems.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Training details covered in this interview can be found at the top of </span><span class="c4"><a class="c3" href="#h.bg6u0y2kn4ui">Traning models guide </a></span><span class="c0">section of the doc</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The biggest issue in terms of archs and the source of muddiness, is phase. Currently, in audio separation there&#39;s not a great way to calculate phase in a model like the phase spectrogram as it&#39;s not as obvious as the magnitude spectrogram.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">You take the vocal out of a heavy rock track, but the process is not perfect, so it will take some part of the instrumental with it. Even if you don&#39;t hear instrumental in vocals, there&#39;s still instrumental data in there in the phase of that vocal track.</span></p><p class="c1"><span class="c0">In the end of the day, source separation is prediction. It&#39;s predicting where it thinks it is, but there will be always some imperfections, e.g. whenever you hear muddier sound in a track which has more noise like metal tracks.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Anjok emphasizes on (currently) lack of correlation between SDR and the fact that bigger SDR metric doesn&rsquo;t necessarily mean better. He tried some top of the SDR chart result before, and wasn&rsquo;t quite happy about them.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Because phase is a big part of the issue, now the new upcoming -</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.bviye361m0v"><span class="c6">Demudder</span></h6><p class="c1"><span>A UVR </span><span class="c0">feature incoming (it was also explained before on the server by Anjok - if something is not clear, try to find his messages there)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It uses lots of phasing tricks. It processes the track twice. The first takes instrumental from the first go around and compares it against the original mixture. It chops the mixture into 3 seconds chunks and ?inerts over that lists of chunks and for each segment, it cuts out where that segment is in the instrumental, and it finds similar events that aren&#39;t at the exact same place. It takes those chunks, and it analyses them against the instrumental that was generated, and it tries to find the most similar events it can from the instrumental, that aren&#39;t at the same place from that segment, and it finds similar events, and then it phases it, it does a phase invert of that instrumental </span></p><p class="c1"><span class="c0">(56:30) If the volume or DB threshold isn&#39;t past the certain point because it&#39;s too loud then it means it does not cancel out and doesn&#39;t make phase invert, if it reaches a certain threshold like if it is below certain threshold it&#39;ll phase that, and then it will basically stitch together a new mixture that is kind of phased from that original instrumental output, and it reprocesses that new stitch together, mixture with the phase with the instrumental phase changed, and it processes that through the second pass, and then it takes that vocal and then phase inverts it with the mixture, with the original mixture and then what you end up having is some of the parts that are similar from the other parts of the track, you end up having those fill in the spectral holes.</span></p><p class="c1"><span class="c0">Sam remarks find some similarity with probably how Izotope Imager works.</span></p><p class="c1"><span class="c0">Anjok says: I&#39;m trying to get a similar part, but also try to take it and phase it with that segment. Because it&#39;s not the exact same part of the segment, it&#39;s not gonna be a perfect phase, because it would be an original vocal output.</span></p><p class="c1"><span class="c0">So it&#39;s kind of still finding the bit of instrumental that is still in the vocal.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Sam remarks about frequent situations where you perform separation, and it can lead to decrease of e.g. hihat volume levels in instrumental, referring to what information separated vocal stem can wear. It&#39;s part of the muddiness Anjok tried to address with the feature.</span></p><p class="c1"><span class="c0">Anjok didn&#39;t want to compromise vocal quality, and in some cases it makes vocal better too, but it also depends on how the track was mixed originally. If it&#39;s analog track recorded in one session or even live track, it won&#39;t work so good. The problem is with e.g. 10 minutes track, when demudder won&#39;t find phase similarities so effectively. It will work the best on music made with samples. If the track is digital, it is more likely to work better.</span></p><p class="c1"><span class="c0">Anjok currently works on it to make it work for all tracks. </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">The more he works on it, the more breakthroughs are made, but due to his day job, he had less time to work on it lately.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Anjok gives his appreciation on the group of very talented developers who made MDX-Net arch in the University of Korea. It&#39;s his favourite network. He&#39;s a big fan of Woosung Choi work.</span></p><p class="c1"><span class="c0">_____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Later, Aufr33 invented his own:</span></p><h6 class="c2 c27" id="h.sv6j1ndk4oq5"><span class="c0">Simpler demudder</span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Published for paid users of x-minus.pro (when you pick Roformer model for instrumentals, buttons with methods appear; it is only applied for instrumentals, not vocals)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">In his own words:</span></p><p class="c1"><span class="c0">&ldquo;</span></p><p class="c1"><span class="c0">1. Separate the song into vocals and music</span></p><p class="c1"><span class="c0">2. Invert the phase of the vocal and mix it with the music</span></p><p class="c1"><span class="c0">3. Now separate this mix</span></p><p class="c1"><span class="c0">4. Mix the vocals with the input song</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">It actually works more complicated than that. I added a high pass filter since the demudder is not needed at low frequencies.&rdquo;</span></p><p class="c1"><span class="c0">Probably something from the 100-250 Hz range. </span></p><p class="c1"><span class="c0">Actually Aufr33 used following ffmpeg command:</span></p><p class="c1"><span class="c0">&ldquo; -filter_complex &quot;[0:a]highpass=f=900[hp1];[0:a][hp1]amerge,pan=stereo|c0=c0-c2|c1=c1-c3[lp];[1:a]highpass=f=900[hp2];[lp][hp2]amix=inputs=2:duration=longest:normalize=0[out]&quot;&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Rephrased by becruily</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;use roformer on a song</span></p><p class="c1"><span class="c0">phase invert the vocal file and combine it with the instrumental</span></p><p class="c1"><span class="c0">separate again using the same model</span></p><p class="c1"><span class="c0">combine the original song and vocals (no inversion or anything) and you will get demudded inst</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">this is for instrumental, if you want demudded vocals just switch the two words (acapella and instrumental)&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/708579735583588366/1265218940695740498&amp;sa=D&amp;source=editors&amp;ust=1765035745145246&amp;usg=AOvVaw0GlbYHv0X63B7c4D-BuY_Z">Video</a></span><span class="c0">&nbsp;how to apply demudder method</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c6">Notes </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- For HQ 4 and at least denoise model enabled, the method seems to produce more vocal residues, so it might be feasible more for Roformers (it&rsquo;s used optionally for Kim Mel-Roformer on x-minus).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- &quot;xminus demudder is more pleasing to the ears&quot; isling</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">- Some people might still prefer max_mag ensemble on x-minus or mel-roformer + bs-roformer ensemble in UVR</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Phase fixer on x-minus for unwa inst v1 model copies phase from Kim Mel-Roformer model.</span></p><p class="c1 c7"><span class="c0"></span></p><h6 class="c2 c27" id="h.t8ntb5endb8y"><span>UVR Demudders released in </span><span class="c4"><a class="c3" href="#h.6y2plb943p9v">beta Roformer patch</a></span></h6><p class="c2"><span>(in Anjok&rsquo;s words)</span></p><ul class="c9 lst-kix_6ltb10qoez57-0 start"><li class="c16 c1 c25 c48 li-bullet-0"><span class="c22">Phase Rotate</span><span class="c0">:<br>The fullest sounding, but can leave a lot of artifacts with certain models. I only recommend that method for the muddiest models. Otherwise, Combined Methods is the best&rdquo;<br></span></li></ul><ul class="c9 lst-kix_6ltb10qoez57-1 start"><li class="c16 c1 c25 c66 li-bullet-0"><span class="c0">First, a filtered instrumental is created, and the left and right channels are swapped.</span></li><li class="c16 c1 c25 c66 li-bullet-0"><span class="c0">The phase is shifted by 90 degrees.</span></li><li class="c16 c1 c25 c66 li-bullet-0"><span class="c0">This modified filtered instrumental is then inverted with the original mixture, and another inference pass is performed on the resulting mixture.</span></li><li class="c16 c1 c25 c66 li-bullet-0"><span class="c0">Finally, the vocal from the second pass is phase-inverted and combined with the original mixture, creating a cleaner instrumental.</span></li></ul><p class="c16 c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_6ltb10qoez57-0"><li class="c16 c1 c25 c48 li-bullet-0"><span class="c22">Phase Remix</span><span class="c0">&nbsp;(similar to X-Minus):<br>I don&#39;t recommend using phase remix on the Instrumental v1e model. I recommend combined methods or phase rotate for models producing fuller instrumentals.<br></span></li></ul><ul class="c9 lst-kix_6ltb10qoez57-1 start"><li class="c16 c1 c25 c66 li-bullet-0"><span class="c0">The mixture is first separated into stems.</span></li><li class="c16 c1 c25 c66 li-bullet-0"><span class="c0">The phase of the vocal stem is inverted and mixed with the filtered instrumental to produce a modified &quot;mixture.&quot; Another inference pass is performed on this new mixture.</span></li><li class="c16 c1 c25 c66 li-bullet-0"><span class="c0">The vocal stem extracted from the modified mixture is then reintroduced into the original mixture, creating a cleaner instrumental.</span></li><li class="c16 c1 c25 c66 li-bullet-0"><span>This method is </span><span class="c20">only</span><span class="c0">&nbsp;recommended for models that produce very muddy instrumentals!</span></li></ul><p class="c16 c1 c7 c8"><span class="c0"></span></p><ul class="c9 lst-kix_6ltb10qoez57-0"><li class="c16 c1 c25 c48 li-bullet-0"><span class="c22">Combine Methods</span><span class="c0">:<br></span></li></ul><ul class="c9 lst-kix_6ltb10qoez57-1 start"><li class="c16 c1 c25 c66 li-bullet-0"><span class="c0">It&#39;s basically a weighted mix of the final instrumentals generated by &quot;Phase Rotate&quot;, &quot;Phase Remix,&quot; and the initial instrumental.<br></span></li></ul><p class="c16 c1 c8"><span class="c0">Demudder in UVR doesn&rsquo;t on 4GB VRAM Intel/AMD GPUs.</span></p><p class="c16 c1 c7 c39"><span class="c0"></span></p><h6 class="c16 c2 c27 c8" id="h.j14b9cv2s5d9"><span class="c20">Phase fixer/swapper</span><span class="c0"><br>(decreases vocal residues in instrumentals)</span></h6><p class="c16 c1"><span class="c0">The method was invented by Aufr33 to fix noise in Roformers models trained with instrumental stem target. It copies phase from a model trained with vocal stem target which usually gives muddy instrumentals (e.g. Kim&rsquo;s or becruily&rsquo;s vocal) and copies it into the instrumental model. Initially it was added only to x-minus, and later becruily wrote his own script doing the same (torch and librosa implementations). </span></p><p class="c16 c1"><span>Later Anjok implemented it into one of the UVR Roformer beta patches (Tools&gt;Phase Swapper), although there it only allows changing high and low cutoff, but no high frequency weight, and santilli_ found out that increasing it from 0.8 to 2 is beneficial for phase swapping from becruily vocal to instrumental model and that it&rsquo;s much better than manipulating with high and low cutoff, you can use their forked Colab </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/1uDXiZAHYk7dQajOLtaq8QmYXL1VtybM2?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765035745151201&amp;usg=AOvVaw2dYNrMYgDcH_-A_82ivmYo">here</a></span><span class="c0">. </span></p><p class="c16 c1"><span>You can use and edit original phase swap Python scripts for previously separated files </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://drive.google.com/drive/folders/1JOa198ALJ0SnEreCq2y2kVj-sktvPePy?usp%3Ddrive_link&amp;sa=D&amp;source=editors&amp;ust=1765035745151541&amp;usg=AOvVaw0QdvuPma0smejxlsHbIOzP">here</a></span><span>.</span><span class="c0">&nbsp;The result is - less noise in the instrumental, but a bit more muddiness (usage is described in the link).</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c0">Optionally, in Phase Fixer you could set 420 for low and 4200 for high or 500 for both and Mel-Kim model for source; and bleed suppressor (by unwa/97chris) to alleviate the noise further (e.g. phase fixer on its own works better with v1 model to alleviate the residues). Besides the default UVR default 500/5000 and Colab default 500/9000 values, you could potentially &ldquo;even try like 200/1000 or even below for 2nd value.&rdquo; &nbsp;&ldquo;I would say that the more noisy the input is, the lower you have to set the frequency for the phase fixer.&rdquo; - jarredou</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c0">&ldquo;The optimal FFT size I found is 896 or maybe 1024. The default that UVR and MSST uses is 2048. At least for ensembling different versions of a song in different codecs (like from YT or SoundCloud). I haven&#39;t actually tried this with stem outputs, but I probably will tomorrow.&rdquo;</span></p><p class="c16 c1 c7"><span class="c0"></span></p><h6 class="c16 c2 c27" id="h.8rocw7cwj55"><span class="c0">Phase-fixed output used in UVR&rsquo;s Manual ensemble</span></h6><p class="c16 c2"><span class="c0">(method explained by objectbed)</span></p><p class="c16 c2 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c0">On example of dca&rsquo;s &quot;0) Unwa BS Roformer Resurrection Inst (BS 2025.07 as a reference for phase fix) + MVSEP BS Roformer 2025.07 (Max Spec)</span></p><p class="c16 c1"><span class="c0">&nbsp;&mdash;-&gt; the least vocal crossbleeding. </span></p><p class="c16 c1"><span class="c0">Alternatively, you can use becruily vocal model instead of 2025.07 for the ensemble -</span></p><p class="c16 c1"><span class="c0">&ldquo;Becruily vocal correctly recognize instruments far better than the instrumental one&rdquo; - dca100fb8&quot;</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c0">&ldquo;This would equate to the following steps:</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c0">1. Separate your mixture using the Unwa BS Roformer Resurrection Inst model.</span></p><p class="c16 c1"><span class="c0">&nbsp; &bull; Output: inst_unwa.wav (instrumental) + optional vocal.</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c0">2. Separate your mixture using the MVSEP BS Roformer 2025.07 model.</span></p><p class="c16 c1"><span class="c0">&nbsp; &bull; Output: inst_mvsep.wav + vox_mvsep.wav.</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c0">3. Phase fix with UVR&rsquo;s Phase Swapper:</span></p><p class="c16 c1"><span class="c0">&nbsp; 3a. Target Audio = inst_unwa.wav (from Step 1).</span></p><p class="c16 c1"><span class="c0">&nbsp; 3b. Reference Audio = vox_mvsep.wav (from Step 2).</span></p><p class="c16 c1"><span class="c0">&nbsp; 3c. Click Start Processing.</span></p><p class="c16 c1"><span class="c0">&nbsp; 3d. Note the resulting new file (inst_unwa_phaseswapped.wav or similar).</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c0">4. Build the ensemble with UVR&rsquo;s Manual Ensemble mode:</span></p><p class="c16 c1"><span class="c0">&nbsp; 4a. Inputs =</span></p><p class="c16 c1"><span class="c0">&bull; inst_unwa_phaseswapped.wav (from Step 3d)</span></p><p class="c16 c1"><span class="c0">&bull; inst_mvsep.wav (from Step 2)</span></p><p class="c16 c1"><span class="c0">&nbsp; 4b. Set Algorithm = &ldquo;Max Spec.&rdquo;</span></p><p class="c1 c16"><span class="c0">&nbsp; 4c. Click Start Processing.</span></p><p class="c16 c1 c7"><span class="c0"></span></p><p class="c16 c1"><span class="c0">The resulting file = your final instrumental stem (the one referenced in the Google Doc instructions as having the least cross-bleed).&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Question about MVSEP BS Roformer 2025.07. Is this a model I can download, or do I have to do it online on their site? I can&#39;t find it.</span></p><p class="c1"><span>A: It&#39;s mvsep site only. No download. So you want to use this model, must go </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://mvsep.com&amp;sa=D&amp;source=editors&amp;ust=1765035745156715&amp;usg=AOvVaw3H_bsFeKhzFPH1Sr0jmOky">mvsep.com</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: What exactly are we doing with a Phase Fixer/Swapper? As an audio engineer, I understand phase as how it relates to frequency over time. When a vocal stem is used as a &quot;reference&quot; for the target instrumental stem, what&#39;s actually happening?</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: &ldquo;There is phase in waveform domain, like audio engineers experience it every day, and there is phase in STFT domain. In STFT domain phase means how each STFT bins content is organized with other bins.</span></p><p class="c1"><span class="c0">The math concept is similar to phase in waveform domain, but instead of having 1 phase value for 1 waveform, you have 1 value for each STFT bin and for each STFT frame, so it&#39;s way more complex... (to make it really short).</span></p><p class="c1"><span class="c0">The phase fixer/swapper thing is operating in the STFT domain, so for each STFT bins, it will use the magnitude data of 1 model, and it will use the phase data from another model, and hopefully this can improve the final result&rdquo;. - jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;In short, what the script does is blend the stft phase of the &quot;donor&quot; file into the target, it uses different blending scales for different frequencies so that it&#39;ll only affect the parts that are directly related to the perceived noise&rdquo; - santilli_ / Michael </span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: Apparently the original Resurrection model only has two models (BS-Roformer 1296/1297 by viperx and BS Large V1 by unwa) that work for phase fixer, but the Gabox one says to use 2025.7 for phase fixer (which works almost perfectly) How does that happen? How did the working models change for Gabox&#39;s fine tune?</span></p><p class="c1"><span class="c0">A: ML models are black boxes. You never know what you&#39;ll get. Like in Forrest Gump. It depends on specific instrumental model, which vocal model as source for phase fixer will work the best.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">__</span></p><h6 class="c2 c27" id="h.uy1eml9xi0lx"><span>P</span><span class="c6">itch shifting algorithms&#39; comparison</span></h6><p class="c1 c7"><span class="c6"></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DgaSFt0tT2u4&amp;sa=D&amp;source=editors&amp;ust=1765035745159964&amp;usg=AOvVaw00AFT3tCOuzKyzc9LoCau3">https://www.youtube.com/watch?v=gaSFt0tT2u4</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Ds-5g4I30_eY&amp;sa=D&amp;source=editors&amp;ust=1765035745160158&amp;usg=AOvVaw0W6AC_C4qf5phsB8lPt31s">https://www.youtube.com/watch?v=s-5g4I30_eY</a></span></p><p class="c1"><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DWH8KDQALYQY&amp;sa=D&amp;source=editors&amp;ust=1765035745160330&amp;usg=AOvVaw3urpus3T1-ucDGs32vK9gL">https://www.youtube.com/watch?v=WH8KDQALYQY</a></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>&ldquo;I&#39;ve had much better results with Izotope RX than Studio One for example for stretching.&rdquo;</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Also, Bitwig can be good.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>You can also try out paid Lossless Pitch AI on dango.ai (</span><span class="c4"><a class="c3" href="https://www.google.com/url?q=http://tuanziai.com&amp;sa=D&amp;source=editors&amp;ust=1765035745160928&amp;usg=AOvVaw03tJGHhu9pe-ojKB_u_vQt">tuanziai.com/en-US</a></span><span>).</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span>Research: </span><span class="c4"><a class="c3" href="https://www.google.com/url?q=https://discord.com/channels/708579735583588363/911050124661227542/1303058610934382675&amp;sa=D&amp;source=editors&amp;ust=1765035745161280&amp;usg=AOvVaw388iDAwp66zsdsewPZhOKi">https://discord.com/channels/708579735583588363/911050124661227542/1303058610934382675</a></span></p><h6 class="c5" id="h.3j9hmk1ri4di"><span class="c20">Restoring hi-end in pitched-down tracks - </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/1GLWvwNG5Ity2OpTe_HARHQxgwYuoosseYcxpzVjL_wY/edit?tab%3Dt.0%23heading%3Dh.gko0a4vvgwqs&amp;sa=D&amp;source=editors&amp;ust=1765035745161547&amp;usg=AOvVaw1DhUpsD3d30GL9ZGsNFhxU">click</a></span></h6><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">____</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c20">What does changing batch_size from 1 to 2</span><span class="c0"><br>(it wasn&rsquo;t used in Rofo beta UVR for 9 Jan 2025, but maybe it got changed)</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">&ldquo;if your input is batch time sequence, it looks like this:</span></p><p class="c1"><span class="c0">[ batch1-&gt;[time-&gt;[sequence],time2-&gt;[sequence]..], batch2-&gt;[time-&gt;[sequence],time2-&gt;[sequence]..] ]</span></p><p class="c1"><span class="c0">As you increase batch_size you increase the amount of data the model gets to churn through.</span></p><p class="c1"><span class="c0">So higher batch_size allows the model to see more data before you do a thing called backward prop which calculates another thing called gradients,</span></p><p class="c1"><span class="c0">which are used to improve the model by tuning loads of little values inside the neurons so that the next pass through is more accurate&rdquo; frazer</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Q: They told me that increasing batch size to 2 makes it process faster</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: &ldquo;So when that user says you can increase the batch_size what they mean is you can use more than one song to process - i.e. instead of running a single song at batch_size = 1 you can run 2 at the same time (batch_size = 2)</span></p><p class="c1"><span class="c0"><br>Q: Ah so batch_size param is used for the amount of chunks of the input, so if I set [batch_size] to 4 my audio is chunked into 4&rdquo;</span></p><p class="c1"><span class="c0"><br>A: &ldquo;No, the chunks are split based on defined chunk_size in config (which is more related to STFT settings), and then the script is stacking &#39;batch_size&#39; number of chunks in same tensor to process them at same time (for inference).&rdquo; jarredou</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">A: &ldquo;Increasing the batch size increases the number of chunks that can be processed at one time, which may speed up processing, but also increases memory usage.</span></p><p class="c1"><span class="c0">It will probably not affect quality.&rdquo; unwa</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Inference Colab by jarredou forces batch_size=1. Iirc the clicking issue with such value was fixed in MSST repo later, and you can stick to it. Probably in UVR too, since latest patches where newer inference code from MSST was implemented.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">Someone was once telling that value not bigger than 2 takes no more than 4GB of VRAM, but it will rather differ from AMD/Intel when the VRAM usage is higher due to lack of garbage collector present in CUDA.</span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1 c7"><span class="c0"></span></p><p class="c1"><span class="c0">_______</span></p><p class="c1"><span class="c0">Done by deton24, 2021-2025</span></p><p class="c1"><span class="c20">Special thanks to </span><span class="c4 c20"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/ZPtAU5R6rP&amp;sa=D&amp;source=editors&amp;ust=1765035745165526&amp;usg=AOvVaw1i5djCH2ty54uWBm0__rAo">Audio Separation</a></span><span class="c20">&nbsp;Discord<br>(and all the people mentioned in the credits section)</span></p><div><p class="c1"><span class="c0">_____________________</span></p><p class="c1"><span class="c11">For help and discussion, visit our Audio Separation Discord: </span><span class="c4 c11"><a class="c3" href="https://www.google.com/url?q=https://discord.gg/ZPtAU5R6rP&amp;sa=D&amp;source=editors&amp;ust=1765035745166001&amp;usg=AOvVaw11DKewLcYO3NqvT3FZ7oOE">https://discord.gg/ZPtAU5R6rP</a></span><span class="c11">&nbsp;| Download </span><span class="c4 c11"><a class="c3" href="#h.6y2plb943p9v">UVR</a></span><span class="c11">&nbsp;or</span><span class="c4 c11"><a class="c3" href="#h.2y2nycmmf53">&nbsp;MSST-GUI</a></span><span class="c11">&nbsp;</span></p><p class="c1"><span class="c11">For inst/voc separation in cloud, try out free Colabs: </span><span class="c4 c11"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/jarredou/Music-Source-Separation-Training-Colab-Inference/blob/main/Music_Source_Separation_Training_(Colab_Inference).ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035745166437&amp;usg=AOvVaw19deTtUZfrGm2DSzwDbZHm">BS/Mel-Roformer</a></span><span>&nbsp;| </span><span class="c4 c11"><a class="c3" href="#h.jmb1yj7x3kj7">MDX23</a></span><span class="c11">&nbsp;(2-4 stems) | </span><span class="c4 c11"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/github/NaJeongMo/Colab-for-MDX_B/blob/main/MDX-Net_Colab.ipynb&amp;sa=D&amp;source=editors&amp;ust=1765035745166646&amp;usg=AOvVaw2MnKoajG95wXIn9WlBZTze">MDX-Net</a></span><span class="c11">&nbsp;| </span><span class="c4 c11"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/16Q44VBJiIrXOgTINztVDVeb0XKhLKHwl&amp;sa=D&amp;source=editors&amp;ust=1765035745166761&amp;usg=AOvVaw3Gp6mJMeQK-_UYDCRIxBhC">VR</a></span><span class="c11">&nbsp;</span><span class="c11">| </span><span class="c4 c11"><a class="c3" href="https://www.google.com/url?q=https://colab.research.google.com/drive/117SWWC0k9N2MBj7biagHjkRZpmd_ozu1&amp;sa=D&amp;source=editors&amp;ust=1765035745166917&amp;usg=AOvVaw0-4jFn3Wcd4QC_v_smJbVF">Demucs 4</a></span><span class="c11">&nbsp;(2-6)</span></p></div></body></html>